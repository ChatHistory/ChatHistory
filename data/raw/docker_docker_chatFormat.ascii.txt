[2016-01-04 19:59:51] <mickadoua> hi all, i would like to connect docker to an external network, I’m on windows 10I try to change the Virtual Box interface from Nat to Bridge but still not work
[2016-01-04 20:45:50] <mickadoua> ps : docker-machine active     show a TIMEOUT err
[2016-01-05 10:29:22] <mickadoua> okay, I found the solution, I change the 2nd network (and not the first one) interface to bridge
[2016-01-06 13:30:16] <rlegrand> Hi to all, I have a newbie question for you, the following command:\'\'\' docker run \\-v $(pwd):/home/guest/training \\-p 8081:8080 \\\'\'\'returns me the following error:invalid value "C:\\Users\\training;C:\\Program Files\\Git\\home\\guest\\training" for flag -v: bad mode specifiedI run this from windows with git shell... I see that folders are translated  when they should probably not (/home/guest/training) but I\'m not sure to understand fine and I absolutely don\'t know how to work arround this (the same command works fine on osx)If someone has any idea, thanks by advance :)
[2016-01-06 18:12:12] <matthughes> Anyone here ever get docker-compose to successfully read in environment variables? [<-CODE->] 
[2016-01-06 18:12:34] <matthughes> Does it only use environment variables from your bash_rc?
[2016-01-06 18:20:36] <Majkl578> matthughes: works fine here, both$ FOO=123 script-with-docker-composeand on our CI (pre-set env)
[2016-01-06 18:23:54] <matthughes> hmm; I don’t see anything different here: [<-CODE->] I’m running 1.5.2 which is the latest on Centos 7.2.
[2016-01-06 18:24:43] <matthughes> I’ve tried $FOO/${FOO}/“$FOO”/"${FOO}"
[2016-01-06 18:25:42] <matthughes> compose clearly sees it as a variable to be replaced, but someone doesn’t see the environment variable
[2016-01-06 18:27:00] <matthughes> What version are you running?
[2016-01-06 18:27:19] <Majkl578> I just use$BUILD_VCS_NUMBERin docker-compose.yml
[2016-01-06 18:27:43] <Majkl578> I use it inside container_name though
[2016-01-06 18:29:29] <matthughes> Yeah tried that too with no luck.
[2016-01-06 18:30:02] <Majkl578> just tried this: [<-CODE->] -> [<-CODE->] 
[2016-01-06 18:30:47] <ksylvan> Yeah, this seems to imply that what you are trying should work: [<-LINK->] 
[2016-01-06 18:32:59] <matthughes> wtf.  Copied your example verbatim: [<-CODE->] 
[2016-01-06 18:50:58] <matthughes> This is also supposed to work: [<-CODE->] 
[2016-01-06 19:09:36] <matthughes> So the problem was I installed docker-compose via the run.sh script, not the binary.  Since I’m launching another shell, it’s not getting my environment variables.
[2016-01-06 19:19:06] <ksylvan>  [<-CODE->] 
[2016-01-06 22:45:08] <nafg> matthughes: I guess you can solve it withexportthen?
[2016-01-07 16:12:51] <rlegrand> Sorry to ask you again, just in case I\'m more lucky this time , any idea about the use of the -v flag on windows. It returns me invalid value "C:\\Users\\training;C:\\Program Files\\Git\\home\\guest\\training" for flag -v: bad mode specified  when I use it this way: [<-CODE->] docker run \\-v $(pwd):/home/guest/training \\-p 8081:8080    ```
[2016-01-07 20:03:32] <nafg> rlegrand: it's handled by the docker daemon
[2016-01-07 20:03:51] <nafg> so it has to be able to interpret the host path
[2016-01-07 20:03:54] <nafg> i.e. within the linux VM
[2016-01-08 11:02:18] <rlegrand> nafg: Ok, thanks,  but how to make docker daemon interpret the host path correctly? I don't know, it tries to replace/home/byc:...\\Git\\home\\(shouldn't it be the folder in the container? Why does it try to convert it to an host folder). Does it mean that on windows, I should do this from the docker VM?
[2016-01-08 11:22:59] <nafg> rlegrand: the left side of : needs to be the path inside the VM. You can share a folder into the VM independently but it\'s 2 "hops"
[2016-01-08 12:50:48] <rlegrand> Ok thanks, I will do some tests
[2016-01-10 15:24:12] <joaodavidbrito> Hi, I need some help here. When I run my docker-compose command it says  'ERROR: Cannot start container 4a117cdcef0f8579e0cbd24dfaf3e80e21bae9b905dadd2119cda10310264e21: [8] System error: no such file or directory' The source files are in my github repo [<-LINK->] 
[2016-01-10 15:24:43] <joaodavidbrito> Anyone? Thanks
[2016-01-10 15:28:46] <LukeHowellDev> Trying to access that repo and I get 404.
[2016-01-10 15:31:12] <LukeHowellDev> Foudn it
[2016-01-10 15:31:42] <LukeHowellDev> Can you verify that your directories for your volumes are accurate.
[2016-01-10 15:51:41] <joaodavidbrito> snumb130: yes they are correct. It mounts the volume if I don't specify a host directory (like volumes: /home/xwiki_home) I really don't understand. :(
[2016-01-10 15:55:22] <joaodavidbrito> if I run it without a host mount volume, when I inspect the container I get this source: /var/lib/docker/volumes/44f167eeb0f9213548d44494a7f4ac3df3b0d19175c1760a5d179ce3e780af34/_data
[2016-01-10 15:55:49] <joaodavidbrito> and inside that are the data that I can't mount to my host...
[2016-01-10 15:56:41] <LukeHowellDev> If know one else resonds I'll check again in a little while. When I am back at computer.
[2016-01-10 15:56:52] <LukeHowellDev> *responds
[2016-01-11 12:30:54] <wdullaer> I'm trying to run some containers with the awslogs logging driver on ubuntu
[2016-01-11 12:31:05] <wdullaer> but I'm having issues supplying the credentials to the docker daemon
[2016-01-11 12:31:54] <wdullaer> so far I've tried putting them in/root/.aws/credentials and set them as export statements in/etc/default/dockerbut I keep on getting theNoCredentialProviders: no valid providers in chain
[2016-01-11 12:32:15] <wdullaer> I'm running out of ideas to try, anyone with suggestions?
[2016-01-11 17:56:47] <lukasojd> hi I have volume in application container and I share volume to other continer and i have problem with deploy. After deploy (recreate aplication container) stay volume in nginx and php contatiner same... i must remove all container and create again after that is all ok. Do you not know what the problem?
[2016-01-11 22:02:11] <LukeHowellDev> joaodavidbrito: I was looking back at your problem.  You are installing everything in your Dockerfile to/home/xwiki_home, but when you mount a directory from your host system the host takes preference.  So when you mount the emptyxwiki_homedirectory from your project the Docker container ends up having/home/xwiki_homeas empty.
[2016-01-11 22:03:46] <LukeHowellDev> This is the expected behavior.
[2016-01-11 22:04:37] <joaodavidbrito> thanks@snumb130, but there is a way of doing what I want? Populate the host directory with the container's xwiki_home content?
[2016-01-11 22:11:28] <LukeHowellDev> @joaodavidbrito I am pretty sure that you would have to have your files on your host system to begin with and then mount that to your container.  I am not an expert here by any means, but I believe the volume functionality of docker works like (or is based on) unix mounts and this is not possible with mounts.So to make it work I believe you will have to extract the files on your local system and mount the directory.  Maybe someone else can weigh in and there is some way to do this, but I do not think there is to accomplish what you are shooting for.
[2016-01-11 22:15:15] <joaodavidbrito> OK, thank you again@snumb130. I'm trying to copy the behaviour from other images (eg: jenkins) and when I mount a volume from host (empty folder) it gets populated with the data from the container. But perhaps what is happening is that that content is generated after the container is created and not before like I'm trynig to do...
[2016-01-11 22:15:53] <joaodavidbrito> But that's ok! Thank You very much!!
[2016-01-11 22:26:57] <LukeHowellDev> joaodavidbrito: I took a look at the jenkins docker image and your assumption appears to be correct.  Its entrypoint is/usr/local/bin/jenkins.sh.  Inside [<-LINK->] you can see where files are being created in/var/jenkings_homewhen the container is started.
[2016-01-11 22:31:54] <joaodavidbrito> snumb130: I'm gonna try that. I will get the zip file after the container has started, unzip it and then execute my actual entrypoint file to start the server etc. I'will let you know if it works. :)
[2016-01-11 22:33:06] <LukeHowellDev> What might be better instead of download the zip file on run, is to have the zip file extracted to a tmp directory during the build.  Then during the first part of the run you can copy the contents to/home/xwiki_home.  This will save startup time on run.
[2016-01-13 01:58:06] <LukeHowellDev> Looking for a little general input here.  I have a project that uses a data container, nginx container, php container and a redis container.  Right now I have these containers managed on a particular instance using docker-compose.  All works well.  My thought is that I would like in the project, there to be configuration so that developers could easily pull the project and run it with minimal configuration.  I can use a .env file in the docker-compose for specifics, so my thought would be to include docker-compose.yml and multiple Dockerfiles (eg: Dockerfile.data, Dockerfile.nginx, etc) in the git repo.  Are there any other suggestions for doing this.
[2016-01-13 02:13:34] <fin09pcap> Separate directories with dockerfiles that allow you to override the default configurations? This especially works with nginx and redis if there are defaults away the norms. Does that sound about right?
[2016-01-13 02:16:34] <LukeHowellDev> Possibly. That has been an idea. I have though about have the docker configgs in one directory and src in another. Basically looking for developers to be able to spin up app with as close to one command as possible.
[2016-01-13 02:18:14] <rbuckland> I am experiencing a strange "ERROR: Service ‘dockerX\' failed to build: lstat target/somefile: no such file or directory"
[2016-01-13 02:18:35] <rbuckland> the file exists, I am trying to push it in with a simple ADD or COPY.
[2016-01-13 02:18:59] <rbuckland> I am using docker-compose. sometimes when I build it directly (docker build .. ) it works.
[2016-01-13 02:19:43] <rbuckland> any suggestions to the issue ? I thought perhaps the path could be too long (so shortened that) have renamed the source file, moved it around .. but with no luck
[2016-01-13 02:19:50] <LukeHowellDev> rbuckland: Do you have code example anywhere?
[2016-01-13 02:20:06] <rbuckland> Yes :-)
[2016-01-13 02:20:46] <rbuckland>  [<-CODE->] 
[2016-01-13 02:21:03] <rbuckland> That is the Dockerfile in it’s entirety.
[2016-01-13 02:21:45] <rbuckland>  [<-CODE->] 
[2016-01-13 02:21:55] <rbuckland> That is the file in question.
[2016-01-13 02:22:44] <rbuckland> And this is an example of building it [<-CODE->] 
[2016-01-13 02:24:56] <rbuckland> If I move thatbfwbinary to the “root” of the project, and change the Dockerfile entryADD bfw /usr/local/binthen it works.. [<-CODE->] 
[2016-01-13 02:25:26] <rbuckland> But then it fails under the “docker-compose” model (where I have 6 or so other dockers defined)
[2016-01-13 02:28:55] <rbuckland> Things I notice are: it’s 26M (that should not matter) - the full project path is longish, its is vmware mounted (OSX folder mounted into “this” vmware Ubuntu linux box)
[2016-01-13 02:30:59] <rbuckland> It also happens with another Dockerfile is the “same folder” for a different binary .. smaller in size - 12M …
[2016-01-13 02:32:19] <rbuckland> moving it to the “root” of the project and making it a small filename (three letters)  gets it in there
[2016-01-13 02:32:21] <rbuckland> ODD
[2016-01-13 02:36:49] <LukeHowellDev> Try adding/to end of path [<-CODE->] 
[2016-01-13 09:29:22] <bad5anta> hey. could any1 help? how do I run convoy on docker machine (virtualbox)? all plugins got erased after restart
[2016-01-13 10:19:47] <kaharlichenko> Hi. I want to use the same Dockerfile for several different git repos, I also want the content of the git repo to be available within the image that I build. What is the best practice for doing that?
[2016-01-13 10:20:59] <kaharlichenko> When I try to keep the Dockerfile separate from the repo whenever I rundocker build --path=path/to/Dockerfile path/to/repoit complains that the Dockerfile is not within the build context
[2016-01-13 11:53:33] <rbuckland> madkinder: - would creating a “master” Dockerfile and then having each project haveFROM mymasternot work ? regarding adding the “project” into the Image.. justADD . /some/path
[2016-01-13 11:54:09] <kaharlichenko> rbuckland: , no, it probably wouldn't
[2016-01-13 11:54:31] <kaharlichenko> the thing is that I have several Dockerfiles and several projects
[2016-01-13 11:54:43] <kaharlichenko> so basically I have AxB combinations
[2016-01-13 11:55:56] <kaharlichenko> the set of Dockerfiles reflects the building pipeline I use to build the distro specific packages (rpm and deb), I use Docker mainly as a sane clean environment + depenency cache
[2016-01-13 11:56:55] <kaharlichenko> the thing gets worse as each of the master files would need to start from different base for different distros and their versions, while the rest of the Dockerfile content would be pretty much the same
[2016-01-13 11:58:25] <rbuckland> got you.
[2016-01-13 11:59:01] <kaharlichenko> also, the rest of the team is no happy about adding Docker dependency in the code base, even if is expressed as Dockerfile and .dockerignore files
[2016-01-13 11:59:21] <kaharlichenko> so the Dockerfiles and the upstream projects would evolve independently
[2016-01-13 11:59:39] <rbuckland> I would perhaps go outside of “docker” tooling to solve it - use templates and just composite them together to make (and checkin) final Dockerfile
[2016-01-13 11:59:54] <rbuckland> what is the “lang/build pipe line in use now ? "
[2016-01-13 11:59:57] <kaharlichenko> now I'm trying to wrap my head around all the requirements
[2016-01-13 12:00:46] <kaharlichenko> we have lots of projects written in Scala, Python, PHP and Erlang, each using its own build tooling
[2016-01-13 12:01:02] <rbuckland> cool - and any over-arching ci ?
[2016-01-13 12:01:23] <kaharlichenko> could you please rephrase? I'm not sure I got your question
[2016-01-13 12:01:51] <rbuckland> so .. are all the various projects using git (or something else for that matter ? )
[2016-01-13 12:01:53] <kaharlichenko> for each of the projects I need to get an RPM
[2016-01-13 12:01:59] <kaharlichenko> yes, all of them use git
[2016-01-13 12:02:29] <rbuckland> and do you have any continuous integration tooling in use (e.g.: drone, or travism jenkins etc)
[2016-01-13 12:02:36] <kaharlichenko> we have jenkins
[2016-01-13 12:02:41] <kaharlichenko> that's the idea to employ it
[2016-01-13 12:02:59] <kaharlichenko> we already have the build pipeline, which I'm not happy with
[2016-01-13 12:04:11] <rbuckland> (as an aside I have been looking and using with a lot of liking - drone.ci  - it uses docker as a first class “build” citizen)
[2016-01-13 12:04:58] <kaharlichenko> two main complaints I got to the existing pipeline is that:it is not reproducible - jars/pythom wheels/php packages are fetched from an uncontrolled source; the environment setup is not documented and enforced;\nit is very slow due to redownloading all the deps each build
[2016-01-13 12:05:36] <rbuckland> yes - common problems.
[2016-01-13 12:05:44] <kaharlichenko> to my mind docker is a good fit since Dockerfile can serve as a code-as-documentation for the build environment, the images created could be pushed to the registry and reused by Jenkins and devs
[2016-01-13 12:05:58] <rbuckland> yep.
[2016-01-13 12:06:11] <kaharlichenko> also it can speed up the package build times tremendously by pre-caching the build dependencies
[2016-01-13 12:06:35] <rbuckland> yes - a well engineered docker image saves many many minutes
[2016-01-13 12:06:48] <kaharlichenko> and I would only need to rebuild the pre-cached docker image upon the change tosetup.pyorbuild.sbtor whatever file is used for specifying the deps in the language ecosystem
[2016-01-13 12:07:49] <rbuckland> does each project have a “same” set of Dockers ? i.e. all projects target debian/centos/a.another .. so need three Docker builds ?
[2016-01-13 12:08:05] <kaharlichenko> I also considered using LXC as an alternative, but it doesn't have good facilities for sharing the images like docker registry
[2016-01-13 12:08:23] <kaharlichenko> currently we run on OpenSUSE (which also doesn't run on LXC)
[2016-01-13 12:08:41] <kaharlichenko> several versions of OpenSUSE
[2016-01-13 12:08:46] <kaharlichenko> so I need to build packages for each of them
[2016-01-13 12:09:04] <kaharlichenko> the plan is to migrate to Ubuntu, again at least the LTS versions (14.04 and upcoming 16.04)
[2016-01-13 12:09:24] <kaharlichenko> so that yields at least 4 differentFROMclauses
[2016-01-13 12:10:09] <kaharlichenko> I crafted a set of shell scripts that represent the package build pipeline
[2016-01-13 12:10:40] <kaharlichenko> now the problem is that how to cut those scripts into pieces, put them into the dockerfiles so that I could benefit from Docker's caching
[2016-01-13 12:11:08] <kaharlichenko> and also make it possible to evolve the build pipeline (the Dockerfiles) separately from the upstream code
[2016-01-13 12:11:29] <kaharlichenko> that's why putting the Dockerfiles into the repo of the upstream code of each project is probably not a good idea
[2016-01-13 12:18:43] <kaharlichenko> so any ideas how to mix and match N Dockerfiles with M git repos would be appreciated
[2016-01-13 13:06:26] <bad5anta> questionIs there any way to save docker plugins on docker machine (virtualbox)?
[2016-01-13 13:07:18] <bad5anta> mb somehow with saving state of virtualbox machine?
[2016-01-13 19:03:01] <maseev> Hi there! I'm just curious, is there any chance I could run a bunch of docker containers on the single host and having the access to the application, which is going to be inside those containers through the individual pairs of host/port? What I'm trying to achieve is to set up a testing environment for distributed application, so I would be able to test it on split-brain problem and stuff like that by killing and running the docker containers again.
[2016-01-13 19:04:38] <kaharlichenko> maseev: you can get the different ports easily, as for the hostnames I'm not sure
[2016-01-13 19:05:30] <kaharlichenko> well, you can set the--hostnameparameter indocker runinvocation, if that helps
[2016-01-13 19:05:38] <maseev> madkinder: yep, I think it's pretty straightforward solution to this problem.
[2016-01-13 19:05:52] <maseev> that's interesting. I'll have a look.
[2016-01-13 19:06:01] <maseev> thanks.
[2016-01-13 19:11:05] <lukasojd> hi I have volume in application container and I share volume to other continer and i have problem with deploy. After deploy (recreate aplication container) stay volume in nginx and php contatiner same... i must remove all container and create again after that is all ok. Do you not know what the problem?
[2016-01-13 19:18:36] <maseev> madkinder: can't figure out how to use this argument. I'm trying to run a docker container httpd with a simple web server inside. It seems that the web server is only accessible by ip address that docker sets for the running container (in my case - 172.17.0.2).
[2016-01-14 07:16:09] <kangur69> is this the homosex chatroom?
[2016-01-14 07:16:54] <maseev> nope, you are in the wrong chatroom.
[2016-01-14 07:17:14] <kangur69> :(
[2016-01-14 07:31:06] <lukasojd> :-D
[2016-01-14 09:31:20] <kaharlichenko> maseev: initially you asked whether the hostname could be changed, not the ip address
[2016-01-14 10:04:14] <nafg> Can anyone help? Docker 1.9.1, inside a docker build it can't resolve archive.ubuntu.com
[2016-01-14 10:22:21] <kaharlichenko> nafg: what's in yourFROMclause of the Dockerfile?
[2016-01-14 11:45:32] <maseev> madkinder: sorry, my bad.  Actually I solved this problem in another way. I run a bunch of docker containers and then call docker inspect on them in order to get their ip addresses. By doing so, I'd be able to access them through some application code.
[2016-01-14 13:23:52] <nafg> madkinder: even this fails:
[2016-01-14 13:24:07] <nafg> docker run --rm -ti busybox wget google.com
[2016-01-14 13:24:16] <nafg> that is, it hangs for a while,
[2016-01-14 13:25:21] <nafg> wget: bad address 'google.com'
[2016-01-15 15:11:24] <oleksdovz> Hi, Needs help with docker registry V2.  I want to delete docker image and all data.  What I should to do ? how I can get digest id of image ?https://docs.docker.com/registry/spec/api/  but  it\'s not clear for meHow i can  delete   all blobs  ?`curl -X GET http://centos-esx.ddns.com:5000/v2/base-sun-jdk-16-25-rhel6u5/tags/list{"name":"base-sun-jdk-16-25-rhel6u5","tags":["latest"]}curl -X GET http://centos-esx.ddns.com:5000/v2/base-sun-jdk-16-25-rhel6u5/manifests/latest  | grep -i blobSum | cat -n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current                                 Dload  Upload   Total   Spent    Left  Speed100 93684  100 93684    0     0  1690k      0 --:--:-- --:--:-- --:--:-- 1694k     1             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"     2             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"     3             "blobSum": "sha256:3fb24384c58fd15e9b554bf0d48322e4b6f20f6b96e9590e43cc24ee690640b9"     4             "blobSum": "sha256:ab0f5ec8b8bdbd4f8c6a0eaeff324374b54259483b2f42a30bd7af0423cacdaf"     5             "blobSum": "sha256:d300dea3f858adcfa62875175f7955dbbe834cd88cac445c7d9cdfc9a00eb921"     6             "blobSum": "sha256:66efd42f1e4db58c45d4cf082ab8d6cc7055c6e39be51f5d9e31597eeb0649ca"     7             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"     8             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"     9             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    10             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    11             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    12             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    13             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    14             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    15             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    16             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    17             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    18             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    19             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    20             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    21             "blobSum": "sha256:4edd9f4e4e53c6c60a27be654bc4b08943707ec688bcf35c1750a040e88159af"    22             "blobSum": "sha256:aabe29b4ae1c747ca47ebd9d3d0b774a6379d8972cd1b8577cfb6dd75b1fb2a8"    23             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    24             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    25             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    26             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"    27             "blobSum": "sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4"At second time curl -X DELETE  \'http://centos-esx.ddns.com:5000/v2/base-sun-jdk-16-25-rhel6u5/blobs/sha256:fc2a7a72d7c9fa636ca5af2f248eb1c4628828a8c10b55e13e4b1d65b27c0ed5\'{"errors":[{"code":"BLOB_UNKNOWN","message":"blob unknown to registry"}]}`
[2016-01-15 17:43:40] <liphvf> Hello guys, for docker, how the best ci service?
[2016-01-15 18:06:43] <nafg> liphvf: what do you need it to do?
[2016-01-15 18:09:19] <liphvf> tests and re-deploy 1 container
[2016-01-15 18:09:43] <liphvf> using git file, i preferer.
[2016-01-15 18:49:54] <nafg> liphvf: I've heard good things about drone
[2016-01-15 21:45:22] <ghost~540393fe163965c9bc2018ce> hi, I just realised I'd been using the wrong docker images for debian for a while, so I started from scratch
[2016-01-15 21:45:45] <ghost~540393fe163965c9bc2018ce> but the .deb now installs multiple startup scripts for docker and I don't know which one is being used. Certainly my old config in /etc/defaults/docker is being ignored
[2016-01-15 21:46:09] <ghost~540393fe163965c9bc2018ce> where do I now edit to set my config, which was-g /home/docker --exec-opt native.cgroupdriver=cgroupfs
[2016-01-15 21:47:43] <ghost~540393fe163965c9bc2018ce> as far as I can tell, sysv stuff has been installed in the usual places
[2016-01-15 21:47:49] <ghost~540393fe163965c9bc2018ce> and an upstart setup has been installed
[2016-01-15 21:47:53] <ghost~540393fe163965c9bc2018ce> but no systemd
[2016-01-15 21:48:22] <oleksdovz> what os and ver ?
[2016-01-15 21:48:31] <ghost~540393fe163965c9bc2018ce> oh there is a systemd too, /etc/systemd/system/multi-user.target.wants/docker.service
[2016-01-15 21:48:46] <ghost~540393fe163965c9bc2018ce> oleksdovz: debian testing and the latest .deb in the install instructions
[2016-01-15 21:49:02] <oleksdovz> you need to work with config for systemd file
[2016-01-15 21:49:19] <ghost~540393fe163965c9bc2018ce> oleksdovz: I don't have much experience with that, where do I put that?
[2016-01-15 21:49:28] <ghost~540393fe163965c9bc2018ce> and is there any command I need to run?
[2016-01-15 21:50:30] <oleksdovz> systemctl status -l  docker   - will show status and file what was loaded  at  service start
[2016-01-15 21:50:40] <ghost~540393fe163965c9bc2018ce> ok, I just changed /etc/systemd/system/multi-user.target.wants/docker.service and that seems to have picked up the changes after a systemctl daemon-reload
[2016-01-15 21:50:49] <oleksdovz> +
[2016-01-15 21:51:09] <ghost~540393fe163965c9bc2018ce> that's looking good
[2016-01-15 21:52:03] <oleksdovz> all these changes in docker service can   by made by  docker-machine
[2016-01-15 21:52:19] <ghost~540393fe163965c9bc2018ce> ok
[2016-01-15 21:52:48] <oleksdovz> also will  good to have docker repo configured
[2016-01-15 21:52:57] <ghost~540393fe163965c9bc2018ce> btw, I have a container that I want to run on startup on another machine (Ubuntu LTS). It uses upstart, same .deb. What is the best way to do that? docker-machine again?
[2016-01-15 21:53:27] <ghost~540393fe163965c9bc2018ce> actually, before we get on to that... what is the best way to set up docker with docker-machine?
[2016-01-15 21:53:36] <ghost~540393fe163965c9bc2018ce> I need to give instructions to our downstream users
[2016-01-15 21:53:45] <oleksdovz> yes, add ssh keys  and  run docker-machine with  generic drive
[2016-01-15 21:53:53] <ghost~540393fe163965c9bc2018ce> who are exposing SSL docker servers, and everything has changed since the last time I did all this
[2016-01-15 21:54:05] <ghost~540393fe163965c9bc2018ce> ssh keys?
[2016-01-15 21:54:10] <ghost~540393fe163965c9bc2018ce> generic drive?
[2016-01-15 21:55:11] <oleksdovz>  [<-LINK->] 
[2016-01-15 21:55:59] <ghost~540393fe163965c9bc2018ce> oleksdovz: that doesn't sound like what I want. These are the instructions we give contributors currently [<-LINK->] 
[2016-01-15 22:02:09] <oleksdovz> fommil: maybe i do not have all info about your targets , but  I have about ~50 VMS.All these vms configured as remote  docker nodes  for clusterUsing docker-machine I  have  connection with tls and all other options for docker service was set  too, like trust private docker registry and use some dns servers
[2016-01-16 13:53:49] <emj365> Please help~ how can I test my memcache docker is working.ncdocker inspect -f '{{.NetworkSettings.IPAddress}}' memcached11211noresponse
[2016-01-16 14:07:03] <emj365> nc 192.168.99.100 11211this works
[2016-01-16 19:36:21] <Majkl578> emj365: is it listening on correct address, e.g. not only on loopback?
[2016-01-16 19:45:17] <emj365> Majkl578: 192.168.99.100 is docker-machine ip
[2016-01-16 19:45:42] <emj365> docker inspect -f '{{.NetworkSettings.IPAddress}}'got docker container ip
[2016-01-16 19:46:25] <emj365> _: @
[2016-01-16 19:46:55] <Majkl578> emj365: but is the memcache itself configured to listen on anything else than 127.0.0.1? it is not by default (on debian at least), due to security risks
[2016-01-16 19:48:49] <emj365> Majkl578: I think I got it, thank you.
[2016-01-18 14:25:15] <ke20> Hi, someone knows how to provision a volume from existing files ?
[2016-01-20 09:37:29] <ilkka> is anybody by any chance using Ansible to install Docker Engine? I guess this is more of an Ansible problem, but theget_urlmodule fails to validate get.docker.com’s SSL cert for some reason
[2016-01-20 09:55:39] <DieterReuter> ilkka: you should install the latest certificates on your system, on Debian/Ubuntu just use: "sudo apt-get ca-certificates". This should do the trick
[2016-01-20 10:55:05] <ilkka> I’ll double-check that I did, thanks
[2016-01-20 10:59:08] <ilkka> crud, doesn’t help. this is a trusty machine and the latest is 20141019ubuntu0.14.04.1 0, wily would have a 2015 version but that doesn’t help me
[2016-01-20 11:00:17] <ilkka> walp, maybe I’ll just fallback to curl, that has a good chain
[2016-01-20 15:14:22] <genseric> Hello, i have a setup including jenkins and apache. basically jenkins makes a new build from git, then updates the data container volume which is also mounted to the apache host. but there are symlinks involved and before using docker i was using apache graceful restart. now that has to be triggered from the jenkins container, to the apache containers.
[2016-01-20 15:15:43] <genseric> so my question is how can i trigger an apache restart, or access the host’s docker binaries to restart the apache container..
[2016-01-20 15:15:55] <genseric> thanks
[2016-01-20 15:17:32] <Majkl578> I think you'll need a privileged container for that
[2016-01-20 15:18:07] <Majkl578>  [<-LINK->] 
[2016-01-20 15:18:26] <Majkl578> but it may be dangerous : )
[2016-01-20 15:19:08] <genseric> yes, i know. i m 2 days into the docker, can’t think straight now )
[2016-01-20 15:19:36] <genseric> everything around me now seems to belong to a box now
[2016-01-20 15:25:26] <genseric> it seems privileged is not the answer. i can use a shared data volume with incron to trigger any event on the server. but i m just looking for a more legal way.
[2016-01-20 19:16:34] <l15k4> hey, how come that when building Dockerfile,  theRUN apt-get ...commands are cached because they haven't changed butRUN git checkoutorRUN mvn installare always triggered even though they haven't changed either ?
[2016-01-20 19:24:45] <nafg> I didn't know any RUN can be cached
[2016-01-20 19:34:56] <l15k4> yeah, just the command string itself is used to find whether it should be run again (it changed) or not
[2016-01-20 19:36:08] <l15k4> but for instance like 51 is executed always, even though nothing changed in the whole Dockerfile [<-LINK->] 
[2016-01-20 19:37:11] <l15k4> so you have to split the images intobase-appandappto avoid that
[2016-01-20 19:37:23] <l15k4> I'd like to figure out why that happens
[2016-01-21 18:19:18] <liphvf> hello guys, how the best in yours opinian, CoreOs or RancherOs?
[2016-01-21 22:02:46] <ropstah> I'm currently installing DockerToolbox, I allowed for many actions through my firewall, even a false positive Cloudscanner Trojan alert
[2016-01-21 22:03:40] <ropstah> It also asked for internet access and is now trying to install a certificate. Is this all correct?
[2016-01-21 22:04:01] <ropstah> It's a windows installation btw
[2016-01-22 10:41:48] <webmutation> Hi all, I manually setup a Docker Swarm cluster last nigth, but tonigth I found that the nodes are unhealthy and I cant run any container on them anymore.
[2016-01-22 10:42:39] <webmutation> Any ideas on what might be the issue? Do i need to change the daemon default settings... I am going to move to consul for the registration currently using token
[2016-01-22 10:55:22] <webmutation> liphvf: RancherOS is built to run container, it is probably one of the lightest you can use.
[2016-01-22 11:52:05] <liphvf> webmutation: What the best use case for CoreOs and RancherOs?
[2016-01-22 14:26:10] <webmutation> liphvf: I would say if you only need to run container RancherOS is very lightweight and was built for that use case. CoreOS also replaces typical package manager with running containers. I think the best you can do is test both of them and see witch one you see more at home. CoreOS also support rkt for containers but since rkt images are supposed to become fully compatible with docker that really is not much of a selling point.
[2016-01-22 14:27:42] <webmutation> The main thing is that these OSs replace stuff like Ubuntu and other fatter OSes, the main disavantage is that you have to run everithing in containers with fuller OSes you can run them on the system or as containers
[2016-01-22 14:32:06] <webmutation> Perhaps you have more specific questions? Because what I provided was a very generic anwser ;)
[2016-01-22 16:13:35] <mickadoua> hi all, i have maybe a stupid question, Anyone know if Docker is made to be in production ?
[2016-01-22 16:58:20] <Rodenastyle> mickadoua: What exactly means "made to be in production" ?
[2016-01-22 16:59:49] <Rodenastyle> mickadoua: I think there are "stable" versions of Docker, the problem could be prepared staff
[2016-01-22 17:05:55] <mickadoua> Rodenastyle: I have a linux server, and i would like to run different  image, (wordpress & other HTTP website,  redmine, ruby  server, ftp ...)but i dont know how can i access to the different instance  from outside
[2016-01-22 17:08:25] <Rodenastyle> mickadoua: When you set up the docker container, you're able to set the   port that will be listening on the host and target it to a port on the container
[2016-01-22 17:09:24] <Rodenastyle> mickadoua: If you're a begginer, as me, I really recommend you to use a interface like Rancher to work with Docker
[2016-01-22 17:09:51] <mickadoua> Rodenastyle: okay, i would like Rancher ;) realy thanks you
[2016-01-22 17:10:13] <jasisk> Hey all. Wondering if I can get a couple of opinions: I have a container that, during build, effectively seeds the application (specifically, it's couchdb and I publish a couchapp into it). Because of how volumes work, I can use a named or anonymous volume and it's seeded, but if I use a bind mount, it won't be. So these are my options:
[2016-01-22 17:11:26] <Rodenastyle> mickadoua: To understand Docker logic and freedom at the first time could be a bit mindfucking
[2016-01-22 17:11:42] <jasisk> 1) move the publishing step into the cmd (prohibitively slow). 2) use a bind mount, backup the seeded data, restore it into the mounted folder. 3) use a named or anonymous volume. I've gone with 3 so far but I want to move the docker volume to another physical volume and setting a specific location for a named or anonymous volume seems like something that goes against named/anonymous. :)
[2016-01-22 17:12:53] <Rodenastyle> mickadoua: NP, to change command line on icons will make you see the idea (:
[2016-01-22 17:16:34] <Rodenastyle> jasisk: I don't have idea what I'm saying, but option 2 seems safer for me. Anyway, you could check if sidekicks could help you in that ;)
[2016-01-23 04:18:01] <ztratar> Hey ya\'ll. I\'m working on a Docker worker right now and am curious what best practice is in terms of Dockerfile location? It seems I can\'t ADD, COPY, etc anything that is a path like "../../app/models", but I need to access the models from my standard application (in ../../app). Theoretically I see the only other option as sticking the Dockerfile in the entire applications root directory, but that\'s terrible as I\'m going to create a new image for every single worker and I already need to create 5+ of them. Can\'t have 1 Dockerfile for 5 works... yeah? Can\'t seem to find any discussion/documentation around this, so figured I\'d ask for some help here! Much appreciated if you can point me in the right direction. :)
[2016-01-23 19:45:08] <GastroGeek> ztratar: - not really looked into 'workers' but I would either have multiple Dockerfiles in the root and chose which one at build time (so you can have variations) - or I would use/make a build tool that would compile a Dockerfile for me using switches/json-conf? I might be way off but thought I would reply.
[2016-01-23 20:50:43] <ksylvan> Have aMakefileorGulpfileor some sort of way of specifying which image you are building at the root, with adocker/directory with multiple different namesDockerfiles and usedocker build -fto build the images.
[2016-01-25 14:31:24] <bsideup> Hey! We've just released a tool, it allows you to load environment variables from different sources like URL, Consul, Etcd, Redis, DynamoDB:https://github.com/zeroturnaround/configoWorks great with a Docker containers =)
[2016-01-25 19:36:45] <mnordine> I'm having trouble getting my private registry to work with https
[2016-01-25 19:37:01] <mnordine> It launches with http, even though I point it to a valid cert
[2016-01-25 19:37:16] <mnordine> I followed the instructions here - [<-LINK->] 
[2016-01-25 19:37:39] <mnordine> but when I launch it, the logs say:
[2016-01-25 19:37:43] <mnordine> [1] [INFO] Listening at: http://0.0.0.0:5000 (1)
[2016-01-25 19:38:07] <mnordine> and I can't see anywhere in the logs where it complains about my cert or anything
[2016-01-25 19:38:22] <mnordine> do I have to explicity enable https somehow?
[2016-01-25 19:38:56] <mnordine> I used this command:docker run -d -p 5000:5000 --restart=always --name registry \\\n  -vpwd/certs:/certs \\\n  -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \\\n  -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \\\n  registry:2
[2016-01-26 12:16:34] <elgalu> Hi guys, what do you thing about [<-ISSUE->] to be able to pull images by metadata lablel filtering? i.e.
[2016-01-26 12:16:35] <elgalu>  [<-CODE->] 
[2016-01-26 16:20:10] <birkof> Guys, beware of this shit -> [<-LINK->] 
[2016-01-27 10:47:08] <geertvanheusden> Hi I was just reading about docker-compose 1.6 and I was wondering how the scale function fits into the new networking part?
[2016-01-27 10:47:42] <geertvanheusden> containers will take the hostname as defined in the docker-compose.yml file
[2016-01-27 10:48:04] <geertvanheusden> e.g. web, but what happens if you scale up?
[2016-01-27 10:48:32] <geertvanheusden> will it do some kind of Load balancing?
[2016-01-27 10:49:51] <geertvanheusden> In the earlier versions the hostnames would contain a number (web_1, web_2) if I am correct?
[2016-01-27 15:44:44] <uzkikh> Hello! I have a problem. When I try to pull image from docker hub'docker pull mongo:latest’I have the error:'Pulling repository [<-LINK->] ;'Get [<-LINK->] : dial tcp: lookup registry-1.docker.io: no such host'
[2016-01-27 15:45:07] <uzkikh> docker pull mongo:latest
[2016-01-27 15:45:23] <uzkikh> And errorGet https://registry-1.docker.io/v1/repositories/library/mongo/tags/latest: dial tcp: lookup registry-1.docker.io: no such host
[2016-01-27 16:10:43] <geertvanheusden> dinamit: are you using boot2docker?
[2016-01-27 16:13:18] <uzkikh> geertvanheusden: Docker toolbox
[2016-01-27 16:14:19] <geertvanheusden> can you try to restart your docker host? docker-machine restart <machine>
[2016-01-27 16:17:24] <uzkikh> I've already tried it. Not work.
[2016-01-27 16:18:34] <geertvanheusden> are you able to ping registry-1.docker.io from within the host? (docker-machine ssh <machine>)
[2016-01-27 16:22:49] <uzkikh> No ping this host.
[2016-01-27 16:23:04] <geertvanheusden> Are you able to ping [<-LINK->] ?
[2016-01-27 16:23:47] <uzkikh> Yes. Google is ok.
[2016-01-27 16:24:26] <geertvanheusden> are you able to access [<-LINK->] from your client machine?
[2016-01-27 16:25:01] <uzkikh> 404 page not found
[2016-01-27 16:26:38] <geertvanheusden> strange, do be honest I think you should move your question to #docker on freenode
[2016-01-27 16:27:07] <uzkikh> Ok. Thank you!
[2016-01-27 16:27:10] <geertvanheusden> this channel is reserved for contributors
[2016-01-27 20:10:43] <nafg> geertvanheusden: are you a maintainer?
[2016-01-28 05:34:13] <ColbertHasson> docker runs great on raspberry pi!
[2016-01-28 10:01:31] <lolmaus> I've got a project provisioned by docker-compose. How do I tell it to remove everything and rebuild everything from scratch?
[2016-01-28 13:53:11] <LukeHowellDev> lolmaus: docker-compose stop && docker-compose rm -f
[2016-01-28 21:02:36] <lolmaus> snumb130: Thank you.
[2016-01-28 21:12:39] <LukeHowellDev> The -f flag I had on there will remove without confirmation.  If you want to be safer don’t use it.  I put it by habit.
[2016-01-28 22:23:42] <viebig>  [<-LINK->] 
[2016-01-28 22:29:55] <viebig> Sorry. wrong gist... I just created a bash, ssh, rsync shell script to deploy a docker application easily. Can you guys, review, fork or improve it? [<-LINK->] 
[2016-01-31 14:28:37] <lukasojd> Hi i have problem a want pull image from hub.docker... and get me error [<-CODE->] 
[2016-01-31 14:29:06] <lukasojd> Where is problem?
[2016-01-31 14:31:56] <lukasojd> I try delete docker images and container...
[2016-01-31 14:34:45] <lukasojd> its better problem was maybe cache
[2016-02-01 00:17:28] <dmitriz> Hey there. Is this a known problem?
[2016-02-01 00:17:30] <dmitriz>  [<-CODE->] 
[2016-02-01 00:20:06] <nafg> dmitriz: it reads like one ;)
[2016-02-01 00:28:47] <dmitriz> nafg: And what is the solution?
[2016-02-01 00:29:51] <nafg> dmitriz: upgrade your server?
[2016-02-01 00:30:04] <nafg> What versions are your client and server? (rundocker version)?
[2016-02-01 00:57:19] <jpetazzo> dmitriz: : the easiest option is to upgrade the server. But if you can’t, you can also downgrade the client. If you can’t do that either, then you could run an older client in a container (i.e.docker run -e DOCKER_HOST docker:1.8.3 ps)
[2016-02-01 01:00:56] <dmitriz> nafg:  [<-CODE->] 
[2016-02-01 01:02:02] <dmitriz> jpetazzo: How can I upgrade the server? Or downgrade the client?
[2016-02-01 01:02:47] <dmitriz> jpetazzo: I can't run any docker container getting the same error every time.
[2016-02-01 01:27:54] <dmitriz> Found it here: [<-LINK->] 
[2016-02-01 01:58:57] <nafg> dmitriz: what kind of docker daemon do you have?
[2016-02-01 01:59:49] <dmitriz> nafg: how can i see it?
[2016-02-01 02:00:28] <nafg> dmitriz: how did you get it? Is it local on linux? On a VM with docker-machine? On a cloud server you created? That someone else created?
[2016-02-01 02:00:57] <dmitriz> nafg: on my Mac
[2016-02-01 05:41:45] <jpetazzo> dmitriz: you could trydocker-machine lsto see if your Docker is visible that way; and thendocker-machine upgrade VM-NAME
[2016-02-01 05:41:48] <jpetazzo> (if I remember well)
[2016-02-01 13:39:40] <dstepanov> Hi, is there a way how to mount a volume like ".:/data" but create a folder /data/node_modules inside of the container that is not going to be propagate to host?
[2016-02-01 13:40:08] <dstepanov> Oh I see it's not for user help, sorry
[2016-02-01 19:44:10] <dmitriz> jpetazzo: @nafgTrieddocker-machine upgrade defaultwith no success. Managed to fix it installingdvmand downgrading viadvm use 1.8.1. However, when pulling some images (but not all), docker keeps switching to1.9.1and nothing is shown underdocker images.
[2016-02-02 20:09:21] <liphvf> hello guys, what this option:stdin_openin docker-compose make.
[2016-02-02 20:18:32] <nafg> Is there any way to connect to a docker daemon behind a NAT from the cloud?
[2016-02-02 20:47:11] <syeduguri> liphvf: it is equivalent to "docker run -a stdin”. ‘-a’ option will attach standard streams selectively.
[2016-02-02 21:13:45] <liphvf> syeduguri: thanks for your help.
[2016-02-04 00:14:49] <tstirrat15> hey all
[2016-02-04 00:15:01] <tstirrat15> i'm still pretty new to docker and trying to wrap my head around it
[2016-02-04 00:15:17] <tstirrat15> one of the things that I still don't understand is a typical workflow for getting code into a docker container
[2016-02-04 00:15:43] <tstirrat15> are people typically using git for this? editing within the container? editing from outside of the container?
[2016-02-04 00:16:13] <tstirrat15> how does it work?
[2016-02-04 00:20:08] <camilb> tstirrat15: I'm using local folders and mount them as volumes in containers, depends a lot of your needs. Sometimes you can add the code directly into your containers, or create small containers with code and mount them as volumes in other containers
[2016-02-04 00:20:54] <tstirrat15> huh
[2016-02-04 00:21:29] <tstirrat15> then the idea is that you\'d be able to move your code into the "live" version of the container using
[2016-02-04 00:21:33] <tstirrat15> mt
[2016-02-04 00:21:54] <fin09pcap> tstirrat15: , depends entirely on how you are planning to user the container in your development environment or production, “I” generally put the code, application, etc in the container and run it with the single purpose
[2016-02-04 00:22:35] <tstirrat15> but then how does editing go?
[2016-02-04 00:22:42] <tstirrat15> that's the part i'm most curious about
[2016-02-04 00:23:04] <tstirrat15> or do people tend to develop locally and then push to the container for testing and deployment?
[2016-02-04 00:23:08] <tstirrat15> or does it really just depend?
[2016-02-04 00:23:17] <fin09pcap> make a change in the source, and rebuild, test, push
[2016-02-04 00:24:44] <fin09pcap> when it comes to configs, this can be introduced at build time in CI
[2016-02-04 00:27:12] <tstirrat15> hmm... so docker is typically used when it comes time to build/deploy, rather than while you're coding?
[2016-02-04 00:28:15] <camilb> there are a lot of ways:in my setup I have local folders mounted as volumes and a webhook that pulls the code automatically, all the edits are made on my local machine.  You can also have a container (like a toolbox, with all the apps you need) and run it with attached volumes from another container, you can execute a container and install a editor, but this is a rare case
[2016-02-04 00:30:05] <camilb> tstirrat15: you can mount local folders and edit locally
[2016-02-04 00:30:19] <tstirrat15> ah, kk. that's pretty damn cool.
[2016-02-04 00:30:32] <fin09pcap> i would think of it as, you are building a container to run an application, so run the application from within the container, this allows the individual to see how the applications operates from in the container during the development process, and then when your ready to push the container to be used elsewhere, it’s ready to be used without modification
[2016-02-04 00:30:51] <tstirrat15> fin09pcap: , that makes sense to me
[2016-02-04 00:31:19] <tstirrat15> camilb: , is it possible to do those mounts across a network?
[2016-02-04 00:31:58] <tstirrat15> i'm doing this development at my workplace, where I have an ubuntu vm available to me via ssh, or my windows machine
[2016-02-04 00:32:09] <tstirrat15> i hate windows as a development environment, though
[2016-02-04 00:32:48] <fin09pcap> does the vm have the http or https exposed?
[2016-02-04 00:33:24] <camilb> tstirrat15: take a look at docker-machine
[2016-02-04 00:33:50] <camilb> it makes the process a lot easier
[2016-02-04 00:34:45] <camilb> you should install docker toolbox on your windows machine first
[2016-02-04 00:35:55] <tstirrat15> yeah, i have access to network config for the vm
[2016-02-04 00:39:25] <tstirrat15> ooh... I didn't realize there was a docker toolbox for windows
[2016-02-04 00:39:27] <tstirrat15> that's hella cool
[2016-02-04 00:39:30] <tstirrat15> i'll definitely check that out
[2016-02-05 00:02:41] <mitramejia> Is it possible to sync to myql containers with docker?One container on a local development laptopAnd the other on a cloud service like Digital Ocean
[2016-02-05 07:27:34] <camilb> mitramejia: take a look at this: [<-LINK->] 
[2016-02-05 08:40:09] <akleiber> whats the easiest way to speed up a docker dev environment under osx? i.e. whats the easiest way to mount host folders via nfs?
[2016-02-05 11:55:25] <MikeMichel> want to try the new seccomp option
[2016-02-05 11:55:28] <MikeMichel>  [<-CODE->] 
[2016-02-05 11:55:59] <MikeMichel>  [<-CODE->] 
[2016-02-05 11:58:37] <MikeMichel> docker 1.10
[2016-02-05 12:14:42] <MikeMichel> don't know whats wrong here
[2016-02-05 14:05:43] <raphi> hi guys. I have a question about Docker and couldn't find an answer:  in my repo, I just change a line of code, then build the image and tag it v1, then another line change, build tag v2. When I pull v1 and v2, its redownloading all layers, when just one line changed. It's like 600Mo download for one line change. Why is it not detecting that just the last layer changed on download this one? Like when you pull the :latest tag, its just downloading the outer layers change, why is it not doing the same thing for tagged images? What I am missing?
[2016-02-05 21:18:36] <alaverty> How are you guys doing docker continuous deployment? So far I can check a dockerfile into source control and recompile it in teamcity and push to a docker registry, but now I want to use ansible to detect if the image in the registry is different to the running container and if so remove the running docker container and redeploy the updated container. I'm trying to find examples of an elegant way to do this. What methods are you guys using to do this, or what orchestration tools are you using in this space?
[2016-02-06 13:09:32] <AlexTelon> raphi: did you change 1 line early in the Dockerfile?  If your change between v1 an v2 was at the very top they dont have anything in common anymore as I have understod it. Even if all but the top line are identical docker cannot know if the first line did change anything that would make something crash later on, so it cannot reuse things after the line change.
[2016-02-06 13:53:11] <AlexTelon> it fixed itself?@nlhkh
[2016-02-06 13:53:33] <AlexTelon> if it did its still interesting to know, that the migration takes some time or whatever
[2016-02-06 22:59:43] <drasko> Hi all, I am gettin "Error response from daemon: Could not get container for orion" when I try:docker run --link orion:orion fiwareiotplatform/lightweightm2m-iotagent
[2016-02-06 23:00:56] <drasko> just foud it, I did not readdocker pscorrectly
[2016-02-06 23:02:41] <AlexTelon> trivia: you can use --link orion  when doing things like <name or id>:<alias >
[2016-02-06 23:03:22] <AlexTelon> bad explanation, when name = alias you dont have to repeat them
[2016-02-06 23:03:29] <drasko> AlexTelon: yep,docker run --link orion_orion_1:orion fiwareiotplatform/lightweightm2m-iotagentdid the job
[2016-02-06 23:04:22] <AlexTelon> oh, docker-compose hid it for you I see :P
[2016-02-06 23:06:54] <AlexTelon> Anyone have a good docker-in-docker solution btw? I want to be able to run the host docker from the container so I dont have to do docker-in-docker for real. I managed to do that with a nasty couple of  -v flags but i would love for it to have a nicer solution..
[2016-02-06 23:07:41] <AlexTelon> run -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/bin/docker -v /lib/x86_64-linux-gnu/libdevmapper.so.1.02.1:/lib/x86_64-linux-gnu/libdevmapper.so.1.02.1 -it lxc bashlxc is the images, its ubuntu:14.04 and apt-get install update && apt-get install -y lxc
[2016-02-07 01:12:56] <atrauzzi> Would anyone here happen to know if there's a special trick to getting cron working in a container?  Specifically using an ubuntu image...
[2016-02-07 01:15:47] <ropstah> atrauzzi: : this might help: [<-LINK->] 
[2016-02-07 01:15:52] <ropstah> uses devcron
[2016-02-07 01:17:23] <atrauzzi> ropstah: Awesome, I'll check it out.  Thanks!
[2016-02-07 01:17:35] <ropstah> np
[2016-02-07 09:37:43] <hanhao44> hello
[2016-02-08 09:24:35] <MakanTaghizadeh> Hello everybody, I’m new to this room.  and very glad to be here.
[2016-02-08 09:56:41] <AlexTelon> Hi! Welcome :)
[2016-02-08 09:59:01] <MakanTaghizadeh> Thank you so much@AlexTelon
[2016-02-09 04:09:39] <nafg> Any idea why this isn't working / how to do such a thing? [<-CODE->] 
[2016-02-09 04:12:53] <nafg>  [<-CODE->] 
[2016-02-09 04:13:30] <nafg>  [<-CODE->] 
[2016-02-09 09:16:14] <MakanTaghizadeh>  [<-LINK->] @nafgIsapp-lrbcolaSymbolic Link?
[2016-02-09 09:17:15] <MakanTaghizadeh> Or any other components of the pathapp-lrbcol/target/app-lrbcol-2.1.war?
[2016-02-09 09:19:10] <MakanTaghizadeh> COPYrequires, you have that data you’re going to copy, exists exactly within the build context.
[2016-02-09 09:22:46] <MakanTaghizadeh> This means that,COPYdoes not follow the sym links.
[2016-02-09 12:41:59] <aafa> Hi everyone! :)   Im trying to install docker withbrew cask install dockertoolboxand I gotError: Cask 'dockertoolbox' definition is invalid: Bad header line: parse failedanyone else having this?
[2016-02-09 12:44:52] <aafa> Looks like that cask is broken..
[2016-02-09 13:00:11] <MakanTaghizadeh> Hi@aafa, Is there any specific reason why you’re trying to install withCask? Why don’t you install the official package fromDotCloud?
[2016-02-09 13:13:01] <aafa> Well, I tend to keep everthing grouped within homebrew as long as there are means for that.For now I guess I will settle with official install guide
[2016-02-09 13:26:22] <MakanTaghizadeh> Oh, I see. That would be really great if possible. However, there're sometimes outdated and take long time to get updated.But, yeah, I agree with you.
[2016-02-09 19:34:48] <nafg> MakanTaghizadeh: thanks for responding. Actually there is no symlink involved
[2016-02-09 19:37:05] <MakanTaghizadeh> nafg: You're welcome my friend. I'll search for it and let you know if I found anything useful.
[2016-02-09 20:08:09] <nafg> However I ruled out it being an issue related to build args. I replaced $WARFILE with the actual file and it still fails
[2016-02-09 20:09:06] <nafg> What islstat???
[2016-02-09 20:27:05] <nafg> seems to be a C function
[2016-02-09 20:27:08] <nafg> Any ideas anyone?
[2016-02-09 20:27:19] <MakanTaghizadeh> It's somehow strange behaving this way.stat,lstatandfstatare Linux kernel syscalls for getting information about a file like the modified date and tons of other information. You can get more info by runningman lstatin terminal.
[2016-02-09 20:27:23] <nafg> It worked before with a different file, produced the same way
[2016-02-09 20:27:36] <nafg> Yeah I did
[2016-02-09 20:28:25] <nafg> (man that is)
[2016-02-09 20:30:13] <MakanTaghizadeh> It might be due to wrong permissions also. Did you checked the folder and file permissions?
[2016-02-09 20:31:13] <MakanTaghizadeh> Maybe, the file is created with another user anddockercommand is being executed with another one.
[2016-02-09 20:34:17] <MakanTaghizadeh> Well, It seems, it's not a permission issue, too. (As I can see in   [<-LINK->] )
[2016-02-09 20:36:09] <MakanTaghizadeh> I've had many issues with Docker but never faced with such an issue 
[2016-02-09 21:51:52] <nafg> MakanTaghizadeh: the permissions are 0664
[2016-02-09 22:10:43] <MakanTaghizadeh>  so strange!
[2016-02-10 18:06:20] <MakanTaghizadeh> nafg: Could you find the workaround to that issue?
[2016-02-10 21:31:21] <oleksdovz> what is wrong with latest version docker for CentOS? I have download 3 images,  what created from each one and have  3  images like flat.  when ran docker images -a  I saw only 3 images without slices.
[2016-02-10 21:31:54] <nafg> MakanTaghizadeh: so far not
[2016-02-10 21:35:00] <oleksdovz> I have about 50 docker hosts and faced with free space issue. All hosts went down after downloading all images. After some time I found when using previous version,  images take about 40Gb, after install latest and pull -  present problem with free space. All our images based on RHEL6.5
[2016-02-10 21:43:45] <oleksdovz> maybe i'm wrong, loss some arguments with pull command but I spent about 4 days to solve this issue
[2016-02-10 21:45:39] <oleksdovz> who can help me with this issue?
[2016-02-10 21:49:08] <MakanTaghizadeh> Well,@oleksdovzI do really like to help you if I can, however I didn't quiet get your issue.
[2016-02-10 21:51:04] <oleksdovz> it is not big problem now. But I think all needs to know about this or I miss something
[2016-02-10 21:52:21] <MakanTaghizadeh> Ok, let see. If I'm correct, you pulled 3 images, but they're not layered. In other words, you pulled 3 huge one-parted images which acquired about 40GB of disk space. Am I right?
[2016-02-10 21:56:46] <oleksdovz> No, we have  ~15 images ~ 4-7 GB.Registry is private v2.2.Images: 1 - base, 2- latest java on base, 3- jboss on 2when I run docker images -a  - I see 3 images onlywhen I check space via df - I see global sum of 3 images.when after   image 3 , I run   pull  images 2 I see  -was  not downloaded 2-3 slices.but I know slices must be more
[2016-02-10 21:58:58] <MakanTaghizadeh> Oh, I see.
[2016-02-10 22:00:24] <oleksdovz> when you are using few small images - it's ok, but when node goes offline after images sync - it's really brake  my  head
[2016-02-10 22:01:54] <MakanTaghizadeh> I'm afraid I have no idea about it.
[2016-02-10 22:02:11] <oleksdovz> used devicemapper
[2016-02-10 22:02:32] <oleksdovz> ok,  just info for all
[2016-02-11 19:48:48] <ripper2hl> hi, what is the url to use docker for download the containers? i need add to my proxy please
[2016-02-11 19:51:41] <gwmoura> the public images can be downloaded from [<-LINK->] , if you have a private docker registry you nedd know your server url and the port when registry is running
[2016-02-11 19:55:45] <ripper2hl> i need only public containers, but when i try download any images docker cli throws an error check this. [<-CODE->] 
[2016-02-11 19:57:23] <gwmoura> ripper2hl: you can list the images usingdocker images?
[2016-02-11 19:58:20] <ripper2hl> i cant download any image```
[2016-02-11 19:58:52] <ripper2hl>  [<-CODE->] 
[2016-02-11 20:01:01] <gwmoura> you try restart a docker service?
[2016-02-11 20:01:53] <ripper2hl> I am behind a fortiguard proxy
[2016-02-11 20:02:20] <ripper2hl> i try this and update docker toolbox, any ideas :( ?
[2016-02-11 20:03:39] <gwmoura> Your problem is not proxy, is a certificate... but I don't have idea what can be
[2016-02-11 20:08:39] <gwmoura>  [<-CODE->] 
[2016-02-11 20:08:53] <gwmoura> this my config file for docker
[2016-02-11 20:09:16] <gwmoura> try add a dns...
[2016-02-11 21:04:34] <ripper2hl> okay i try
[2016-02-11 21:08:20] <ripper2hl> but i use a docker toolbox and my docker runs over an virtual machine
[2016-02-11 21:09:22] <oleksdovz> docker-machine, you can recreate VM and add your repo to trusted
[2016-02-11 21:11:19] <ripper2hl> i need access to public images or what repo your refer ?@oleksdovz
[2016-02-11 21:13:23] <oleksdovz> forget about docker-machine. Can run docker-machine ssh and do ping hub.docker.com ?
[2016-02-11 21:15:21] <ripper2hl> i cant [<-CODE->] 
[2016-02-11 21:18:20] <gwmoura> ripper2hl: you can do login with commanddocker login?
[2016-02-11 21:19:30] <ripper2hl> yes, i can login D: [<-CODE->] 
[2016-02-11 21:21:51] <gwmoura> ripper2hl: try this: [<-LINK->] 
[2016-02-11 21:22:04] <gwmoura> access your docker vm with ssh
[2016-02-11 21:22:07] <oleksdovz> https://forums.docker.com/t/x509-certificate-signed-by-unknown-authority/137/6"x509: certificate signed by unknown authority" can occur when using docker behind an proxy system that does ssl inspection (repleaces ssl certificates).Edit the docker sysconfig file to add the proxy settings and then add the proxy root certificate to the trusted certificates of the docker host and restart the docker service.http://www.devops-insight.com/2014/11/using-docker-with-a-proxy.html
[2016-02-11 21:23:53] <gwmoura> the@oleksdovzlink can help you too
[2016-02-11 21:25:34] <ripper2hl> okay okay i try it this, excuse me for the slow on my responses but my english is very basic xD
[2016-02-11 21:33:44] <oleksdovz> sorry i can not help more. [<-LINK->] is ofline : (
[2016-02-11 21:34:21] <ripper2hl> stackoverflow its online
[2016-02-11 21:36:34] <ripper2hl> i cant found proxy-host and other data for configure proxy on docker, the  proxy is fortinet
[2016-02-11 21:37:04] <oleksdovz>  [<-LINK->] 
[2016-02-11 21:38:02] <ripper2hl> postimg its blocked for me xD
[2016-02-11 21:38:38] <oleksdovz> from  Ukraine stackoverflow is down :(
[2016-02-11 21:40:37] <oleksdovz>  [<-LINK->] 
[2016-02-11 21:41:23] <oleksdovz>  [<-LINK->] 
[2016-02-11 21:41:30] <oleksdovz> ok, bye
[2016-02-11 21:56:22] <ripper2hl> proxy test says i not have a proxy and my conclusion is my proxy is a transparent proxy D:
[2016-02-12 01:13:23] <Rodenastyle> Someone who understands sidekicks there?
[2016-02-12 05:28:42] <rbuckland> Hi, I am working within a company that runs a corporate MITM proxy server. We have the ROOT CA that is signing the SSL connections, and I am trying to get the docker engine to recognise it (for index.docker.io)
[2016-02-12 05:29:22] <rbuckland> the ROOT CA is placed in/etc/docker/certs.d/index.docker.io:443/ca.crt(PEM format)
[2016-02-12 05:30:16] <rbuckland> but docker still complains
[2016-02-12 05:30:26] <rbuckland> Any suggestions ?
[2016-02-12 05:33:48] <rbuckland> have also tried--insecure-registry=index.docker.ioand--insecure-registry=index.docker.io:443
[2016-02-12 05:34:38] <rbuckland> specifically the error isx509: certificate signed by unknown authority
[2016-02-12 07:08:19] <kkarolis> Hey all, Is it possible to have docker cached steps shared accross multiple hosts. Use case:Assume theres a repository with a Dockerfile inside.dev-1 clones a repository, builds the resulting image and pushes it to registry \ndev-2 pulls the image from the registry. \ndev-2 makes a small change to the end of the Dockerfile. (need to rebuild only a small part)\ndev-2 commits the change and rebuilds the image using the changed Dockerfile\ndev-2 has no on-host cache so the image is built from scratch.\ndev-2 pushes the built image to the registry\ndev-1 pulls the new image. All image layers now have a different hash (built on different host) hence the cache is busted for dev-1 and the whole image is downloaded.So the pain points are steps 4-7: multiple-host collaboration on the same image is not possible in incremental manner.Is there some way to overcome this ? multiple-host cache? some other strategy ? Thanks!
[2016-02-12 11:33:38] <bcroq> Hi all, today I cannot start the docker daemon (1.10.1 on archlinux) [<-CODE->] Do you know if there is something I can do to fix this? Thanks.
[2016-02-12 12:25:05] <Rodenastyle> Hi all,  someone knows how to make an stackable apache on docker?
[2016-02-14 04:47:41] <tstirrat15> hey all
[2016-02-14 04:47:54] <tstirrat15> i've got a question about networking
[2016-02-14 04:48:06] <tstirrat15> i'm trying to use a docker stack as a development environment for a web app
[2016-02-14 04:48:18] <tstirrat15> where the stack is running on a VM that I don't have gui access to
[2016-02-14 04:48:33] <tstirrat15> i'd like to be able to access the dev server from outside the VM
[2016-02-14 04:49:38] <tstirrat15> with webpack (what I'm using to develop the front end), I'm able to access the server from the outside world by setting the server's IP to the static IP associated with the VM
[2016-02-14 04:50:24] <tstirrat15> but i haven\'t had the same luck with setting ports: - "my.ip.add.ress:3000:3000" in my docker-compose file
[2016-02-14 04:51:00] <tstirrat15> when I run with the above configuration, the port shows up as listening in netstat, but not in nmap
[2016-02-14 06:02:04] <MakanTaghizadeh> Rodenastyle: May I ask what do you mean by stackable?
[2016-02-14 06:04:06] <MakanTaghizadeh> tstirrat15: What VM Hypervisor are you using? VirtualBox, VMWare, KVM, QEMU or anything else?
[2016-02-14 06:11:28] <MakanTaghizadeh> tstirrat15: The reason why I’m asking this question is that, sometimes network interface configuration of guest in VM Hypervisor is not set correctly. I mean not the IP Adress or anything else, but the type of interface’s attachment to the host. Make sure that you’re bridging guest’s network interface with the host’s one. Not NAT, Internal Network or anything else.
[2016-02-14 06:17:51] <MakanTaghizadeh> Hey @kkarolis, rebuilding a Dockerfile with a small change at the end of it, doesn’t change hashes of all cached layers! for, all previous commands remain unchaged and Docker faces with an unchanged, chached command layer, then it doesn’t touch them at all. So all cached layer should remain untouched.So, in step 4 only new built small layers are going to be pushed to the registry.Then I guess step 7 only pulls those small new layers pushed to the registry not the whole stack.
[2016-02-14 12:54:57] <oleksdovz> Hi, Could you, please share links how-to configure   registry and using cache  and do private  docker registry mirror
[2016-02-14 12:58:51] <MakanTaghizadeh> It’s quiet simple. Have you tried [<-LINK->] and [<-LINK->] ?
[2016-02-14 12:59:25] <MakanTaghizadeh> One is Docker.com page, another one is GitHub page. Check both of them.
[2016-02-14 12:59:44] <MakanTaghizadeh> They have the same content though.
[2016-02-14 13:00:21] <MakanTaghizadeh> Was that helpful?
[2016-02-14 13:01:51] <oleksdovz> Second. I'm try to implement Redis Cache but I did found any links about configuring  redis image as Redis Cache Server  for docker private registry
[2016-02-14 13:03:57] <oleksdovz> Also I found Private Docker  registry cannot be mirrored. But I want to find some solution. I have about 50 Docker hosts and when they start to pull, registry has some overload
[2016-02-14 13:10:01] <oleksdovz> I  found Docker Registry v2 GUI   - hyper/docker-registry-web  but it support only one Registry server, Who can recommend other Docker Registry v2 GUI, what can list more than one Registry?
[2016-02-15 16:10:38] <Rodenastyle> MakanTaghizadeh: As stackable I mean that I'm able to create multiple instances with just one configuration
[2016-02-15 23:03:00] <alaverty> How do I increase swap space on the docker-machine virtual? I'm currently running it on MacOS.
[2016-02-16 00:54:44] <tstirrat15> 'evening. is anyone on?
[2016-02-16 01:04:03] <nafg> You can see in the right sidebar
[2016-02-16 11:01:43] <andrefreitas> Hi there, is there any variant of busybox with SSL support? (root certificates)
[2016-02-16 11:19:43] <jp-gorman> Can someone tell me the link between docker disk and ssh ? I have a default machine works fine - I remove .vmdk disk and add another I have with many images. Docker fails to start due to ssh issues? The disk with images was working fine on original machine until I upgraded docker, but somehow appears to corrupt the docker host when attached.
[2016-02-16 17:15:51] <nlhkh> I am using the DockerCloud HAProxy image, but I cannot use the SSL cert as I used to with TutumCloud HAProxy
[2016-02-16 17:16:03] <nlhkh> has anyone been able to use SSL with DockerCloud HAProxy
[2016-02-16 17:16:19] <nlhkh> the instruction is here [<-LINK->] 
[2016-02-16 23:58:13] <ropstah> Anyone here familiar with Redis and Websockets (PubSub), I'm trying to connect to ws://[ip]:7379, whereas normally I would connect my multiplexer (for key/value store) to :6379. I tried exposing both ports but keep getting ERR_CONNECTION_REFUSED when I try to connect to ws://
[2016-02-17 00:46:03] <ropstah> Never mind, Redis doesn't support websockets directly
[2016-02-17 14:56:51] <WillSkates> Is there a way of specifying how many containers you would like inside your docker-compose.yml file without having to call docker-compose scale?
[2016-02-19 13:54:23] <basiclaser> hey yall
[2016-02-19 13:55:42] <basiclaser> im unable to reach the external port for elasticsearch (docker ps lists it as localhost:9200), but it appears to not exist. I can access other external docker ports, e.g. for mongoDB without problems.
[2016-02-19 13:56:04] <basiclaser> is there something extra i need to do to get docker to work with elasticsearch
[2016-02-19 14:24:00] <basiclaser> the ‘internal’ docker elasticsearch IP is also available and running@192.168.99.100:9200/
[2016-02-19 14:24:21] <basiclaser> any recommendations?
[2016-02-19 14:52:45] <basiclaser> I’ve also tried installing an elasticsearch issue automatically through kitematic, same issue
[2016-02-19 21:49:03] <staffanselander> Anyone here using docker with a team?
[2016-02-19 21:50:01] <oleksdovz> like [<-LINK->] cloud9 ?
[2016-02-19 21:52:39] <staffanselander> hehe, No like a “company” team, but i found what i was looking for xDI’m just scratching the surface of docker. It aint the easiest think to read through.I was woundering how the entire team could have the same “images” without linking them all togheter every single time
[2016-02-19 21:53:05] <staffanselander> Although i saw that you can create a .yml file right?
[2016-02-19 21:55:54] <oleksdovz> are you about docker-compose.yml  ? yes, you can share this file and get similar env for all Dev
[2016-02-19 21:59:42] <staffanselander> That sure seems to be very nice
[2016-02-19 21:59:55] <staffanselander> We are using Vagrant at the moment
[2016-02-19 22:00:08] <staffanselander> But it becomes a bit clumpsy
[2016-02-19 22:02:19] <oleksdovz> you can check this [<-LINK->] 
[2016-02-20 08:57:38] <FranckyU> Hi All, just joining the room today, have a nice Saturday !
[2016-02-20 09:13:54] <MakanTaghizadeh> Welcome@FranckyU
[2016-02-20 11:21:45] <basiclaser> is anyone able to shed light on my elasticsearch issue? [<-LINK->] 
[2016-02-20 11:22:09] <basiclaser> in short, the external port aint workin 
[2016-02-20 11:22:41] <basiclaser> though the elasticsearch instance is available at its docker virtual IP
[2016-02-20 11:24:32] <MakanTaghizadeh> Ok@basiclaser, Maybe I could help you with that. Can you check whether the port is being published to the host correctly or not?
[2016-02-20 11:24:39] <MakanTaghizadeh> Usingnetstat -lnp
[2016-02-20 11:25:25] <MakanTaghizadeh> Do you want the elasticsearch be available at your host’s external IP?
[2016-02-20 11:25:44] <basiclaser> I would like it at localhost:9200
[2016-02-20 11:27:17] <MakanTaghizadeh> Oh, I see. So what do you get withnetstat -lnp?
[2016-02-20 11:27:18] <basiclaser> (using OSX , trying to work out equivalent netstat command)
[2016-02-20 11:27:40] <MakanTaghizadeh> Oh, you’re Mac. Ok let me see.
[2016-02-20 11:28:27] <MakanTaghizadeh> Ok, omitp. This onenetstat -ln.
[2016-02-20 11:28:52] <MakanTaghizadeh> Or better to runnetstat -ln | grep 9200
[2016-02-20 11:29:26] <basiclaser> result was blank
[2016-02-20 11:29:34] <basiclaser> you want the whole -ln dump?
[2016-02-20 11:30:12] <MakanTaghizadeh> Umm, not now. Could you try this one, too?netstat -an | grep LISTEN | grep 9200
[2016-02-20 11:30:48] <MakanTaghizadeh> If it has any result, write it here.
[2016-02-20 11:30:49] <basiclaser>  [<-CODE->] 
[2016-02-20 11:31:35] <basiclaser> ah thats interesting
[2016-02-20 11:31:40] <MakanTaghizadeh> Ah, great. So it seems that the port is being correctly published to host.
[2016-02-20 11:32:10] <basiclaser> cool :D
[2016-02-20 11:32:10] <basiclaser> yesterday i could access mongos external port (0.0.0.0:27017), but can’t get that either now.
[2016-02-20 11:32:57] <basiclaser> both mongo & elastic virtual IPs are still available
[2016-02-20 11:33:19] <MakanTaghizadeh>  Well, you can check that, too. First check, if the port is open on your machine.
[2016-02-20 11:33:51] <MakanTaghizadeh> Aha, so you say you can access them using their virtual IPs?
[2016-02-20 11:34:00] <basiclaser> the listen - grep yielded nothing for mongo
[2016-02-20 11:34:19] <basiclaser> yes thats right - [<-LINK->] & 9200 yield mongo and elastic
[2016-02-20 11:34:31] <MakanTaghizadeh> This means that the port is not published to the host.
[2016-02-20 11:34:48] <MakanTaghizadeh> Make sure you run docker container with-pswitch.
[2016-02-20 11:35:13] <MakanTaghizadeh> Like this:docker run -p localhost:27017:27017 mongo …
[2016-02-20 11:35:19] <basiclaser> i run docker containers by double clicking XD using some ‘kitematic’ contraption
[2016-02-20 11:35:50] <MakanTaghizadeh> Aha, so you’re using kitematic. Let me check on that.
[2016-02-20 11:36:33] <basiclaser> i tried running as you said, ‘invalid hostPort’, also tried ‘0.0.0.0'
[2016-02-20 11:37:11] <MakanTaghizadeh> yeah, you can try 127.0.0.1 instead of localhost
[2016-02-20 11:37:39] <basiclaser> invalid dowg
[2016-02-20 11:37:40] <basiclaser> :(
[2016-02-20 11:38:39] <basiclaser> also@MakanTaghizadehim not sure OSX can run containers like this anyway, as the linux kernels required dont exist for OSX. we have to use something called ‘docker-machine’ i believe
[2016-02-20 11:38:54] <MakanTaghizadeh> let me see, can you give me the command you’re running. If there is not secrets in it.
[2016-02-20 11:39:35] <MakanTaghizadeh> also  @MakanTaghizadeh im not sure OSX can run containers like this anyway, as the linux kernels required dont exist for OSX. we have to use something called ‘docker-machine’ i believeNo idea :-)
[2016-02-20 11:39:39] <basiclaser> im not running any particular command at the moment, i have nothing to share sorry :D
[2016-02-20 11:40:20] <basiclaser> just want mongo and elastic to work on OSX 
[2016-02-20 11:40:29] <basiclaser> thanks a lot for your help though
[2016-02-20 11:41:26] <MakanTaghizadeh>  Right,You’re welcome my friend. I’m gonna search more, and let you know If I found anything useful.
[2016-02-20 11:41:49] <basiclaser> thanks! yeh the OSX situation is confusing atm IMO
[2016-02-20 11:42:07] <basiclaser> we even have to use a special ‘docker terminal’ to run docker commands on a command line
[2016-02-20 11:45:42] <MakanTaghizadeh> I’m using El Capitan. But never had any experiences of handing with docker on it. You know, my old MB Air just has 2GB of memory.  I can’t, I simply can’t 
[2016-02-20 11:45:58] <basiclaser> ha ok :P
[2016-02-20 12:07:35] <mitzkia> Hi, Can be a bug in docker if I can not stop or kill a container where I run 1 process? I have a following docker log (we can see the docker kill -s 9):
[2016-02-20 12:07:38] <mitzkia>  [<-CODE->] 
[2016-02-20 12:09:27] <MakanTaghizadeh> It seems that you’re container is already stopped!! And you’re trying to exec a command in a stopped container.
[2016-02-20 12:10:23] <MakanTaghizadeh> But, first let me ask, the command you’re passing to docker to run in that container is/bin/bas?!
[2016-02-20 12:10:35] <MakanTaghizadeh> Shouldn’t it be/bin/bash?
[2016-02-20 12:10:45] <mitzkia> Thx,  But I can list this container with  docker ps, and it shows it is already running
[2016-02-20 12:11:38] <mitzkia> Yes, you are right. I will reproduce it one more time.
[2016-02-20 12:12:03] <MakanTaghizadeh> I see, What is you’re host OS? Are you in OS X?
[2016-02-20 12:13:00] <MakanTaghizadeh> I mean how are you running this container?
[2016-02-20 12:15:39] <mitzkia> So, my host machine is Ubuntu 15.10, the container is based on Ubuntu 14.04
[2016-02-20 12:16:15] <mitzkia> here is my new docker log, where I want to stop the container withdocker stop:
[2016-02-20 12:16:25] <mitzkia>  [<-CODE->] 
[2016-02-20 12:18:07] <mitzkia> After I executed this docker stop command it stucked (I mean did not return), and if i rundocker psI can see the container still running
[2016-02-20 12:19:30] <MakanTaghizadeh> Ok, that is completely natural. It happens when you run a process which needs any signal other than SIGTERM to be terminated.Docker engine first sends SIGTERM and waits up to 10 secs. If nothing happens, then attempts to kill the process.
[2016-02-20 12:19:48] <MakanTaghizadeh> For instance, consul, needs SIGINT to be terminated correctly.
[2016-02-20 12:19:57] <MakanTaghizadeh> Are you running such a process?
[2016-02-20 12:20:16] <MakanTaghizadeh> What is the command or process you’re trying to run within the container?
[2016-02-20 12:20:52] <mitzkia> I can upload my image to reproduce it. Just a moment.
[2016-02-20 12:21:24] <MakanTaghizadeh> Right
[2016-02-20 12:27:36] <mitzkia> But I think it is not healthy if thedocker stopcommand is stuck.
[2016-02-20 12:29:58] <MakanTaghizadeh> If it’s stuck forever, yep you’re definitely right.
[2016-02-20 12:30:29] <mitzkia> yes it is still stucked.
[2016-02-20 12:31:08] <MakanTaghizadeh> Oh, I see. That’s too bad.
[2016-02-20 12:32:31] <mitzkia> I am thinking about a github issue...
[2016-02-20 12:34:30] <MakanTaghizadeh> Right, go for it
[2016-02-20 12:39:28] <MakanTaghizadeh> mitzkia: Same issue, [<-LINK->] 
[2016-02-20 12:41:00] <MakanTaghizadeh> There’s already an issue out there, and still open. [<-ISSUE->] 
[2016-02-20 12:43:08] <mitzkia> oh thx, i will check it
[2016-02-20 12:44:18] <MakanTaghizadeh> mitzkia: 
[2016-02-20 12:44:53] <MakanTaghizadeh> basiclaser: I found something useful, worth to check it. [<-ISSUE->] 
[2016-02-20 12:48:51] <MakanTaghizadeh> basiclaser: that’s exactly problem of port forwarding, and as the docker engine is running withboot2dockerin VirtualBox, then If you expose any port, the port is in fact being mapped on VirtualBox guest (runningboot2docker) IP.By using VirtualBox NAT Port Forwarding, you can workaround this.
[2016-02-20 12:54:09] <MakanTaghizadeh> basiclaser: This one too, which is still open. [<-ISSUE->] 
[2016-02-20 13:35:12] <basiclaser> MakanTaghizadeh: thanks bud!
[2016-02-20 14:07:54] <MakanTaghizadeh> np  
[2016-02-20 14:37:12] <intellix> possible to specify the prefix for your container names with docker-compose?
[2016-02-20 14:37:54] <intellix> I have a project structure like: <name>/www <name>/api <name>/docker... so all my containers are prefxied with dockerinstead of <name>
[2016-02-20 16:34:44] <MakanTaghizadeh> intellix: I don’t think so (I tested it and no success) however you can use “/“ in your image names.
[2016-02-20 16:35:35] <intellix> how does "/" help? :D
[2016-02-20 16:36:22] <intellix> I mean instead of doing /konoro/docker/konoro/docker-compose.yml, would be nice to just have /konoro/docker/docker-compose.yml and specify the prefix to be "konoro"
[2016-02-20 16:39:24] <MakanTaghizadeh> Slashes help somewhere where you’re going to have multiple types of that image. Say, we have Oracle Java and OpenJDK/JRE, then you’re gonna havejava/oracle-jre:latestandjava/open-jre:latest.
[2016-02-20 16:39:57] <MakanTaghizadeh> but let me see, you’d like to use prefix for the container name. Great, but how do you wanna use it?
[2016-02-20 16:40:24] <MakanTaghizadeh> Honeslty I didn’t quiet get your issue.
[2016-02-20 16:40:48] <intellix> becauuseeeee I have multiple applications that I work on, with different names and they use similar services
[2016-02-20 16:41:00] <intellix> flatscanner_nginxkonoro_nginxsomethingelse_nginx
[2016-02-20 16:41:11] <intellix> I have a directory structure for my projects like:
[2016-02-20 16:41:38] <intellix>  [<-CODE->] 
[2016-02-20 16:42:09] <MakanTaghizadeh> Oh, great.  Sorry for that.
[2016-02-20 16:42:43] <intellix> so I've gotta add an extra directory inside /docker so the service is prefixed with the project name :D
[2016-02-20 16:43:19] <intellix> seems like the prefix should be configurable. Guessing it's not at the moment
[2016-02-20 16:45:30] <MakanTaghizadeh> Got it.
[2016-02-20 16:58:02] <MakanTaghizadeh> Why don’t you explicitly set [<-LINK->] in your compose file?
[2016-02-20 17:01:49] <MakanTaghizadeh> like: [<-CODE->] And then run: [<-CODE->] 
[2016-02-20 18:00:40] <intellix> ah, you can explicitly set container_name, didn't know that
[2016-02-20 18:28:50] <rogeralsing> are there any dashboards/UI's for Docker Swarm/Docker Compose that lets you see where and how many instances you have running of each img?
[2016-02-20 18:29:26] <rogeralsing> oh, maybe this is the wrong channel for those kind of questions(?)
[2016-02-20 18:34:59] <MakanTaghizadeh> I guess [<-LINK->] might be good choice.
[2016-02-20 18:42:18] <rogeralsing> ty
[2016-02-20 21:57:57] <oleksdovz> Hi, needs help with subscribers of  "docker-machine share" [<-ISSUE->] We really need this feature. :)
[2016-02-21 10:15:52] <mootezbessifi> i am running a spring boot application into docker container using eureka netflix service discovery with@enablediscoveryclientannotation. Running my application, it registers itself into eureka with a specific ip address (that of the docker container). i want to change this ip to the host machine ip address, so that my application will be registered into eureka with the host ip address were my container is running. fast answer pleeeeease!!!!!
[2016-02-21 10:17:33] <MakanTaghizadeh> mootezbessifi: If there is no security concerns, you can run your docker container with host network stack. In other words, run your docker container with--net=hostswitch.
[2016-02-21 10:20:17] <mootezbessifi> may you explain to me a little bit ? because i am new in docker@MakanTaghizadeh
[2016-02-21 10:20:50] <fowliena> Other option might be to run a reverse proxy on the host and route traffic through that so eureka picks up the host ip.
[2016-02-21 10:21:08] <mootezbessifi> MakanTaghizadeh: i am running my container in one host machine in our datacenter
[2016-02-21 10:21:34] <mootezbessifi> fowliena: how can i do that
[2016-02-21 10:21:37] <mootezbessifi> ?
[2016-02-21 10:22:41] <mootezbessifi> i found this issue exactly what i want [<-ISSUE->] but nothing util :  (
[2016-02-21 10:24:40] <fowliena> I haven't tried this myself, but it looks it might achieve what you want [<-LINK->] 
[2016-02-21 10:27:18] <MakanTaghizadeh> mootezbessifi: Sorry I got interrupt in my internet connection.
[2016-02-21 10:28:20] <mootezbessifi> no problem ;  )
[2016-02-21 10:29:10] <MakanTaghizadeh> Every single docker container has its own network stack. Thus, any connection departed from a container is started from a virtual network stack.
[2016-02-21 10:29:54] <MakanTaghizadeh> However, if you attack host’s network stack to container, then every connection started inside the container is departed from Host’s network stack as if the application is running purely inside the host outside any virtual env.
[2016-02-21 10:30:55] <mootezbessifi> i want to use just the ip address of the host machine to publish the container with it into eureka
[2016-02-21 10:30:58] <MakanTaghizadeh> This is the simplest workaround. However there are more complex solutions using linux netfilter module (aka firewall or iptables) or other utils like the nginx/haproxy@fowlienamentioned.
[2016-02-21 10:31:30] <mootezbessifi> what is the security issue with this solution ?
[2016-02-21 10:31:57] <mootezbessifi> because you told me "If there is no security concerns,"
[2016-02-21 10:32:13] <MakanTaghizadeh> Well, nothing really dangerous, but you’ve got have firewalling on top of that, nothing else.
[2016-02-21 10:33:08] <mootezbessifi> containers are running in our datacenter, is there a security issue ?
[2016-02-21 10:33:20] <MakanTaghizadeh> `Cause all ports your app is going to open, is directly openned up on host network.
[2016-02-21 10:34:30] <MakanTaghizadeh> Well, I assume no, your datacenter definitley implementing security concepts.
[2016-02-21 10:34:47] <MakanTaghizadeh> So I guess, there won’t be any problem.
[2016-02-21 10:35:03] <MakanTaghizadeh> Or better to say, security glitches.
[2016-02-21 10:36:10] <MakanTaghizadeh> Should you encounter any trouble, let me know.
[2016-02-21 10:37:09] <intellix> just looked at that again, I guess custom name is even worse :)Because Docker container names must be unique, you cannot scale a service beyond 1 container if you have specified a custom name. Attempting to do so results in an error.. Thought it would just append -1, -2 etc but seems not
[2016-02-21 10:37:10] <mootezbessifi> now when i added the --net host option to docker run ..... it says:  docker: Error response from daemon: Conflicting options: custom host-to-IP mapping and the network mode.
[2016-02-21 10:37:55] <mootezbessifi> MakanTaghizadeh: now when i added the --net host option to docker run ..... it says:  docker: Error response from daemon: Conflicting options: custom host-to-IP mapping and the network mode.
[2016-02-21 10:38:21] <MakanTaghizadeh> mootezbessifi: May I ask what is the exact command you’re running?
[2016-02-21 10:39:12] <mootezbessifi> this is my command :[root@Training-dev-env~]#  docker run -d  -v /var/lib/jenkins/jobs/Training-MicroService/workspace/target/:$(pwd)/trainingHome -v $(pwd):/home/ -v /ctcshare:/ctcshare -v /etc/localtime:/etc/localtime --name Training_Integ  -it -p 8195:8190  -p 4022:22 --net host --add-host gnet.edu.sa:10.104.1.1  corvis/java8 &
[2016-02-21 10:40:36] <MakanTaghizadeh> mootezbessifi: It seems--net hostconflicts with--add-host …
[2016-02-21 10:41:14] <mootezbessifi> what should i do ?
[2016-02-21 10:41:23] <MakanTaghizadeh> intellix: Definitely true, you’re not able to scale service if you use custom names.
[2016-02-21 10:43:22] <MakanTaghizadeh> mootezbessifi: Well …I guess you can add the host:ip pair to host's/etc/hostsinstead of adding to that of container.But let me google it, just a sec
[2016-02-21 10:44:21] <mootezbessifi> okey
[2016-02-21 10:45:04] <mootezbessifi> i need  this option when i run a container --add-host "gnet.edu.sa:10.104.1.1"
[2016-02-21 10:45:55] <mootezbessifi> to identify my eureka server
[2016-02-21 10:48:13] <intellix> created an issue for the ability to override the prefix :) [<-ISSUE->] 
[2016-02-21 10:50:02] <MakanTaghizadeh> mootezbessifi: Ok, you’ve got to do something.
[2016-02-21 10:51:20] <mootezbessifi> what ?
[2016-02-21 10:52:00] <MakanTaghizadeh> Omit--add-host "gnet.edu.sa:10.104.1.1”and instead run the following command in the host: [<-CODE->] 
[2016-02-21 10:52:44] <MakanTaghizadeh> --add-hostadds that combination to container’s/etc/hosts
[2016-02-21 10:53:07] <mootezbessifi> not in the host, you mean in the container ;  )
[2016-02-21 10:53:21] <mootezbessifi> using docker exec command
[2016-02-21 10:53:29] <MakanTaghizadeh> and now that container is using host’s network stack, no need to do that in container
[2016-02-21 10:53:44] <MakanTaghizadeh> No, when you use--net host,
[2016-02-21 10:54:19] <mootezbessifi> ah okey i understand, even /etc/hosts of the host is used by the container
[2016-02-21 10:54:21] <mootezbessifi> ??
[2016-02-21 10:54:42] <MakanTaghizadeh> host’s/etc/hostsis gonna be linked to container’s
[2016-02-21 10:54:45] <MakanTaghizadeh> Exactly
[2016-02-21 10:54:56] <mootezbessifi> i wanna test it now
[2016-02-21 10:55:13] <MakanTaghizadeh> Sorry for delay in responding, my connection is so slow
[2016-02-21 10:55:27] <MakanTaghizadeh> Right, let me know what happened
[2016-02-21 10:57:21] <mootezbessifi> in my host machine, when i ping X.gnet.edu.sa it  works
[2016-02-21 10:57:49] <mootezbessifi> do you think that i need to execute  echo “10.104.1.1 gnet.edu.sa” >> /etc/hosts
[2016-02-21 10:57:51] <mootezbessifi> ?
[2016-02-21 10:59:55] <MakanTaghizadeh> WTH!! This internet is just a sh*t!!
[2016-02-21 11:02:07] <MakanTaghizadeh> Sorry, no if you have ping response from that, then not needed.
[2016-02-21 11:03:38] <MakanTaghizadeh> But if you ran your app, and it failed with the error of “gnet.edu.sahost not found”, you’ve got to add that to /etc/host.
[2016-02-21 11:05:43] <MakanTaghizadeh> Any success?
[2016-02-21 11:08:35] <mootezbessifi> when i run my java application inside my container it fails with next error:  java.net.UnknownHostException: Training-dev-env: unknown error
[2016-02-21 11:09:23] <MakanTaghizadeh> Ah, this is exactly the reason why you’ve got to add that ip:host pair to /etc/host
[2016-02-21 11:09:52] <MakanTaghizadeh> Oh, no wait a minute
[2016-02-21 11:11:08] <MakanTaghizadeh> Your app is trying to communicate withTraining-dev-env?
[2016-02-21 11:11:13] <MakanTaghizadeh> Where is that?
[2016-02-21 11:12:01] <mootezbessifi> it is my hostname
[2016-02-21 11:12:36] <MakanTaghizadeh> I see
[2016-02-21 11:13:56] <MakanTaghizadeh> Could you successfully run your app with previous config?
[2016-02-21 11:14:07] <MakanTaghizadeh> I mean without--net host
[2016-02-21 11:15:21] <mootezbessifi> yeahh
[2016-02-21 11:15:55] <mootezbessifi> but it is registered into eureka with the container ip address
[2016-02-21 11:16:01] <mootezbessifi> this is my problem
[2016-02-21 11:16:29] <mootezbessifi> i want  it to be  registered with the host ip
[2016-02-21 11:16:58] <mootezbessifi> is it clear or i you want more explanation ?
[2016-02-21 11:25:46] <mootezbessifi> any answer ?
[2016-02-21 11:25:51] <mootezbessifi> MakanTaghizadeh: 
[2016-02-21 11:26:29] <MakanTaghizadeh> I disconnected again!
[2016-02-21 11:26:45] <MakanTaghizadeh> I quiet understand what you say.
[2016-02-21 11:27:55] <mootezbessifi> i wanna explain again ;  )
[2016-02-21 11:28:07] <mootezbessifi> Eureka is a service discovery
[2016-02-21 11:28:38] <mootezbessifi> i am running a spring boot application inside a docker container
[2016-02-21 11:28:54] <MakanTaghizadeh> Right :-)
[2016-02-21 11:28:58] <mootezbessifi> when i run my application
[2016-02-21 11:29:23] <mootezbessifi> it will be registered into eureka
[2016-02-21 11:29:51] <MakanTaghizadeh> Correct
[2016-02-21 11:29:55] <mootezbessifi> with the container ip and port to be accessible by other application
[2016-02-21 11:30:04] <mootezbessifi> applications*
[2016-02-21 11:30:49] <mootezbessifi> the container ip is not visible outside (by default 172.17.0.x)
[2016-02-21 11:31:24] <MakanTaghizadeh> Your app registers itself into Eureka, right?
[2016-02-21 11:31:49] <joehecn> anyone please tell me how run polymer-starter-kit test in docker
[2016-02-21 11:31:51] <mootezbessifi> exactly
[2016-02-21 11:32:19] <mootezbessifi> so when my container is registered in eureka
[2016-02-21 11:32:19] <MakanTaghizadeh> And its IP and Port is not hard coded anywhere, right?
[2016-02-21 11:32:33] <mootezbessifi> no
[2016-02-21 11:32:54] <MakanTaghizadeh> Great, so when your app is executed in Host’s network stack,
[2016-02-21 11:33:00] <mootezbessifi> the 172.17.0.x is not visible outside
[2016-02-21 11:33:23] <mootezbessifi> so it can not be accessible from other applications
[2016-02-21 11:33:29] <MakanTaghizadeh> True,
[2016-02-21 11:33:45] <MakanTaghizadeh> But when you attack host’s network stack to the container
[2016-02-21 11:34:03] <MakanTaghizadeh> Every single TCP connection instantiate from the container
[2016-02-21 11:34:11] <MakanTaghizadeh> is done with host’s network stack
[2016-02-21 11:34:14] <mootezbessifi> i want my container will be registered with the host ip
[2016-02-21 11:34:25] <MakanTaghizadeh> Fantastic
[2016-02-21 11:34:35] <mootezbessifi> into eureka
[2016-02-21 11:34:44] <mootezbessifi> that is the hole story ;  0
[2016-02-21 11:34:47] <mootezbessifi> ;  )
[2016-02-21 11:35:12] <MakanTaghizadeh> this is the reason why I’m suggesting you to attach Host’s network stack to the container, so that you achieve this
[2016-02-21 11:35:49] <MakanTaghizadeh> Am I correct?
[2016-02-21 11:35:54] <mootezbessifi> but this does not working with us
[2016-02-21 11:36:05] <mootezbessifi> yeah i seams be a solution
[2016-02-21 11:36:11] <mootezbessifi> it*
[2016-02-21 11:36:17] <MakanTaghizadeh> Right, Another question.
[2016-02-21 11:36:27] <mootezbessifi> yeah it seems be a solution
[2016-02-21 11:36:34] <MakanTaghizadeh> Your app needs to communicate to itself?
[2016-02-21 11:36:42] <mootezbessifi> go ahead
[2016-02-21 11:36:55] <mootezbessifi> how ?
[2016-02-21 11:37:20] <mootezbessifi> what do you mean by  "communicate to itself"
[2016-02-21 11:37:21] <mootezbessifi> ?
[2016-02-21 11:37:48] <MakanTaghizadeh> It seems in here  [<-LINK->] that your app is trying to connect to a host named
[2016-02-21 11:38:04] <MakanTaghizadeh> Training-dev-env
[2016-02-21 11:38:26] <MakanTaghizadeh> Right?
[2016-02-21 11:39:08] <mootezbessifi> i dont know the origin of this problem
[2016-02-21 11:39:48] <mootezbessifi> when i delete --net host option
[2016-02-21 11:40:05] <mootezbessifi> i works like a sharm
[2016-02-21 11:40:11] <mootezbessifi> it*
[2016-02-21 11:40:28] <MakanTaghizadeh> Right, but it registers itself with container’s virtual IP, correct?
[2016-02-21 11:41:08] <mootezbessifi> yeah
[2016-02-21 11:42:00] <MakanTaghizadeh> Ok, just give me a moment to think about that once more.
[2016-02-21 11:42:24] <mootezbessifi> ok ;  )
[2016-02-21 11:42:55] <MakanTaghizadeh> I do really like to help you with that, but so sorry for this delay.
[2016-02-21 11:43:04] <mootezbessifi> in the meantime, i wanna do some researches
[2016-02-21 11:54:36] <MakanTaghizadeh> I still believe that, this is your solution.
[2016-02-21 11:54:53] <mootezbessifi> ??
[2016-02-21 11:59:46] <MakanTaghizadeh> for the last attempt, may I ask what happens when you run the container with--net hostand without--add-host …?
[2016-02-21 12:01:46] <mootezbessifi> without --net host when i used to run "java -jar blabla.war"  my application starts without any issue
[2016-02-21 12:03:24] <mootezbessifi> but when i add --net host option,  an exception is running
[2016-02-21 12:03:38] <mootezbessifi> 2016-02-21_11:51:05.403 [ERROR] net.sf.ehcache.Cache - Unable to set localhost. This prevents creation of a GUID. Cause was: Training-dev-env: Training-dev-env: unknown errorjava.net.UnknownHostException: Training-dev-env: Training-dev-env: unknown error
[2016-02-21 12:03:58] <mootezbessifi> at java.net.InetAddress.getLocalHost(InetAddress.java:1484) ~[na:1.8.0_45]
[2016-02-21 12:05:28] <MakanTaghizadeh> It’s so strange, adding that is nothing but attaching container to host net, why this happens!
[2016-02-21 12:05:38] <MakanTaghizadeh> May I ask you to do one more thing?
[2016-02-21 12:05:53] <mootezbessifi> okey
[2016-02-21 12:05:58] <Russell-IO> mootezbessifi: try with --pid=host too
[2016-02-21 12:06:32] <MakanTaghizadeh> right
[2016-02-21 12:07:16] <MakanTaghizadeh> Or something at last, which is not good at all, try adding--privileged
[2016-02-21 12:08:01] <mootezbessifi> what --privileged do ?
[2016-02-21 12:08:13] <MakanTaghizadeh> It runs the container in privileged mode
[2016-02-21 12:09:45] <mootezbessifi> and what --pid does ?
[2016-02-21 12:10:02] <MakanTaghizadeh> Without any sandboxes or any limitations on accessing to host devices
[2016-02-21 12:10:24] <MakanTaghizadeh> It attaches PID namespace of the host to the container
[2016-02-21 12:10:38] <mootezbessifi> so ?
[2016-02-21 12:10:47] <mootezbessifi> how can this help me ?
[2016-02-21 12:11:53] <MakanTaghizadeh> PID namespace provides separation of processes.
[2016-02-21 12:12:10] <MakanTaghizadeh> in [<-LINK->] 
[2016-02-21 12:12:37] <mootezbessifi> do you want to run --net host with  --pid host option ?
[2016-02-21 12:12:59] <MakanTaghizadeh> It removes some limits of process ID separation, as a result more permission to the container.
[2016-02-21 12:13:50] <MakanTaghizadeh> Yep, and if it didn’t succeed try adding--net hostwith--privileged
[2016-02-21 12:16:43] <mootezbessifi> one sec
[2016-02-21 12:20:22] <mootezbessifi> noooo waaayyyyyyy
[2016-02-21 12:20:40] <mootezbessifi> the same problem persists
[2016-02-21 12:20:54] <mootezbessifi> MakanTaghizadeh: 
[2016-02-21 12:21:20] <MakanTaghizadeh> Russell-IO: Do you have any idea about it?
[2016-02-21 12:23:18] <MakanTaghizadeh> mootezbessifi: How important this matter is to you?
[2016-02-21 12:23:32] <mootezbessifi> veeeeeeeery important
[2016-02-21 12:23:52] <MakanTaghizadeh> So let’s fix it mate
[2016-02-21 12:24:32] <mootezbessifi> is there an other way to fix it without using --net host !
[2016-02-21 12:25:02] <MakanTaghizadeh> Yep there are, but let me think about that
[2016-02-21 12:25:14] <mootezbessifi> (y)
[2016-02-21 12:29:25] <MakanTaghizadeh> Ok,@mootezbessifiTraining-dev-envis the service to be registered?
[2016-02-21 12:34:17] <mootezbessifi> noo, it is my hostname
[2016-02-21 12:34:42] <mootezbessifi> in the host machine where my container runs
[2016-02-21 12:35:01] <mootezbessifi> when i type $hostname command
[2016-02-21 12:35:15] <mootezbessifi> it prints Training-dev-env
[2016-02-21 12:35:25] <MakanTaghizadeh> Can you dump /etc/hosts of host in here, if there is no secret in it?
[2016-02-21 12:37:03] <MakanTaghizadeh> Otherwise, do the following
[2016-02-21 12:37:10] <MakanTaghizadeh> make sure there is
[2016-02-21 12:37:18] <MakanTaghizadeh> something like this in that file
[2016-02-21 12:37:31] <MakanTaghizadeh> 127.0.1.1 Training-dev-env
[2016-02-21 12:37:44] <mootezbessifi> 127.0.0.1 audit-redmine.gnet.edu.sa  localhost localhost.localdomain localhost4 localhost4.localdomain4::1       audit-redmine.gnet.edu.sa  localhost localhost.localdomain localhost6 localhost6.localdomain6127.0.1.1       TVTC-audit.gnet.edu.sa TVTC-audit
[2016-02-21 12:38:40] <MakanTaghizadeh> look, your host’s hostname isTraining-dev-envbut there is no IP resolution to the hostname in /etc/hosts
[2016-02-21 12:38:46] <MakanTaghizadeh> you’ve got to add one
[2016-02-21 12:39:23] <MakanTaghizadeh> you can edit the file and change it like the following:
[2016-02-21 12:39:50] <MakanTaghizadeh>  [<-CODE->] 
[2016-02-21 12:40:20] <MakanTaghizadeh> Pay attention to end of the line
[2016-02-21 12:40:26] <MakanTaghizadeh> Training-dev-envis added there
[2016-02-21 12:40:47] <MakanTaghizadeh> Right?
[2016-02-21 12:42:03] <mootezbessifi> same problem persists
[2016-02-21 12:42:11] <mootezbessifi> :   (
[2016-02-21 12:42:39] <MakanTaghizadeh> Exactly the same exception?
[2016-02-21 12:46:22] <MakanTaghizadeh> java.net.UnknownHostException again?
[2016-02-21 12:49:40] <Russell-IO> can you run
[2016-02-21 12:49:51] <Russell-IO> docker exec $CONTAINER cat /etc/hosts
[2016-02-21 12:50:00] <Russell-IO> it's probally missing localhost
[2016-02-21 12:50:23] <Russell-IO> try addding in
[2016-02-21 12:50:29] <Russell-IO> --add-host localhost:127.0.0.1
[2016-02-21 12:51:59] <MakanTaghizadeh> Russell-IO: He’s running the container with--net=host. Host’s /etc/hosts file is shared with the container.
[2016-02-21 12:59:30] <MakanTaghizadeh> I’m afraid that’s beyond my knowledge anymore 
[2016-02-21 13:00:49] <mootezbessifi> yeah UnknownHostException again
[2016-02-21 13:03:08] <MakanTaghizadeh> For which host? Training-dev-env again?
[2016-02-21 13:11:26] <mootezbessifi> yeah
[2016-02-21 13:16:21] <mootezbessifi> any help !!!!!!!
[2016-02-21 13:19:03] <MakanTaghizadeh> Unfortunately not!
[2016-02-21 13:19:12] <MakanTaghizadeh> I have no idea
[2016-02-21 13:20:03] <MakanTaghizadeh> There are some other solutions like having VPN or IPSec Tunnel imo
[2016-02-21 13:20:10] <mootezbessifi> MakanTaghizadeh: i succeeded to resolve the problem. when i modified /etc/hosts (adding  127.0.1.1 TVTC-audit.gnet.edu.sa TVTC-audit Training-dev-env) the container doesnt take the modification
[2016-02-21 13:20:41] <mootezbessifi> so i removed it and i run another one
[2016-02-21 13:20:53] <MakanTaghizadeh> Great!!
[2016-02-21 13:21:05] <MakanTaghizadeh> Grats bud 
[2016-02-21 13:21:21] <mootezbessifi> the bad news now
[2016-02-21 13:21:29] <MakanTaghizadeh> But let me see, you ran with--net host?
[2016-02-21 13:21:42] <mootezbessifi> yep yep
[2016-02-21 13:21:48] <MakanTaghizadeh> Great
[2016-02-21 13:22:01] <MakanTaghizadeh> Without--privileged?
[2016-02-21 13:22:19] <mootezbessifi> yeah
[2016-02-21 13:22:39] <MakanTaghizadeh> fantastic
[2016-02-21 13:22:49] <MakanTaghizadeh> But what is the bad news?
[2016-02-21 13:22:52] <mootezbessifi> into the server it shows me :
[2016-02-21 13:23:05] <mootezbessifi> Local: [<-LINK->] External: [<-LINK->] 
[2016-02-21 13:23:25] <mootezbessifi> local and external ip addresses are the same
[2016-02-21 13:23:31] <mootezbessifi> fixed to local host
[2016-02-21 13:24:03] <mootezbessifi> and when i went to eureka to see with what address my application is registered
[2016-02-21 13:24:50] <mootezbessifi> it shows me 172.17.0.1
[2016-02-21 13:25:18] <mootezbessifi> not the host ip :  ((
[2016-02-21 13:25:55] <MakanTaghizadeh>  after tons of jobs, we’re in the first point
[2016-02-21 13:26:07] <MakanTaghizadeh> Ok don’t worry we’re gonna fix it
[2016-02-21 13:26:27] <MakanTaghizadeh> please tell me the exact command you ran your container with
[2016-02-21 13:27:44] <mootezbessifi> docker run -d  -v /var/lib/jenkins/jobs/Training-MicroService/workspace/target/:$(pwd)/trainingHome -v $(pwd):/home/ -v /ctcshare:/ctcshare -v /etc/localtime:/etc/localtime --name Training_Integ2  -it -p 8196:8190  --net host  corvis/java8 &
[2016-02-21 13:33:56] <MakanTaghizadeh> Ok, in yourhostsfile, add another line like the following:
[2016-02-21 13:34:29] <MakanTaghizadeh>  [<-CODE->] 
[2016-02-21 13:34:41] <MakanTaghizadeh> and restart your container
[2016-02-21 13:38:45] <mootezbessifi> Training-dev-env will exists in two lines !!
[2016-02-21 13:39:02] <mootezbessifi> localhost and host ip
[2016-02-21 13:39:31] <MakanTaghizadeh> It’s ok, but you can optionally remove localhost one
[2016-02-21 13:39:53] <MakanTaghizadeh> just let the "host ip > Training-dev-env" exist
[2016-02-21 13:51:49] <mootezbessifi> i did
[2016-02-21 13:51:56] <mootezbessifi> but nothing changes
[2016-02-21 13:53:22] <MakanTaghizadeh> Which IP is registered in Eureka?
[2016-02-21 13:53:39] <mootezbessifi> 172.17.0.1
[2016-02-21 13:53:50] <MakanTaghizadeh> What is your host ip?
[2016-02-21 13:54:13] <mootezbessifi> a wonder from where  eureka got this address
[2016-02-21 13:54:25] <MakanTaghizadeh> Yep, so strange!
[2016-02-21 13:54:50] <MakanTaghizadeh> It’s normally the address for docker0 bridge which docker brings up
[2016-02-21 13:55:17] <MakanTaghizadeh> but it’s so surprising that this IP is get registered!!
[2016-02-21 13:59:15] <MakanTaghizadeh> mootezbessifi: I’ve got to go out unfortunately. I think you’d better to play with it to find the solution. Sorry mate.
[2016-02-21 14:04:20] <mootezbessifi> with --net option
[2016-02-21 14:04:57] <mootezbessifi> when i run docker inspect@containerto see ip address
[2016-02-21 14:05:07] <mootezbessifi> no ip address found
[2016-02-21 14:05:16] <mootezbessifi> !!!!!!!!!!!!!!
[2016-02-21 14:07:28] <staffanselander> docker run --name some-nginx -v /Users/staffanselander/Documents/DockerTesting/static:/usr/share/nginx/html -v /Users/staffanselander/Documents/DockerTesting/nginx/nginx.conf:/etc/nginx/nginx.conf -p 32768:80 -d nginx
[2016-02-21 14:07:33] <staffanselander> Anyone knows why im getting
[2016-02-21 14:07:40] <staffanselander> [9] System error: not a directory.
[2016-02-21 14:08:31] <MakanTaghizadeh> That’s true, because container doesn’t have any virtual net stack for itself, it’s attached to host’s stack.
[2016-02-21 14:09:02] <MakanTaghizadeh> If you run "docker exec@containerifconfig” you’ll get all host’s addresses.
[2016-02-21 14:09:45] <MakanTaghizadeh> LadyVipEx: Make sure all your volume (-v) directories exist.
[2016-02-21 14:10:29] <MakanTaghizadeh> LadyVipEx: Make sure/Users/staffanselander/Documents/DockerTesting/staticand/Users/staffanselander/Documents/DockerTesting/nginx/nginx.confexist
[2016-02-21 14:10:46] <MakanTaghizadeh> Got to go
[2016-02-21 14:11:18] <staffanselander> Yhea they exists :(
[2016-02-21 14:13:47] <oleksdovz> LadyVipEx: with sudo ?
[2016-02-21 14:35:25] <staffanselander> oleksdovz: then i get docker: Cannot connect to the Docker daemon. Is the docker daemon running on this host?.
[2016-02-21 14:35:42] <oleksdovz> LadyVipEx: sudo -Eand check file permissions to  files
[2016-02-21 14:36:50] <staffanselander> oleksdovz: Same :/ [9] System error: not a directory.
[2016-02-21 14:37:06] <staffanselander> It’s on the config it failed
[2016-02-21 14:37:37] <oleksdovz> LadyVipEx: you are using boottodocker ?
[2016-02-21 14:39:59] <staffanselander> I installed it via Toolbox ;3
[2016-02-21 14:40:07] <staffanselander> So yea(?)
[2016-02-21 14:40:15] <staffanselander> OSX
[2016-02-21 14:41:19] <oleksdovz> LadyVipEx: I think you  have to add shared drive to VBOX  with same path and after try to mount
[2016-02-21 14:41:48] <oleksdovz> LadyVipEx: Check [<-LINK->] 
[2016-02-21 14:48:28] <staffanselander> oleksdovz: But the static work? :/
[2016-02-21 15:32:23] <rogeralsing> Maybe a super naive question, but are the VM's running your docker engine supposed to have static IP's? when using Docker-machine to run VirtualBox machines,  they are assigned new IP's when restarted. I assume the same is true for cloud scenarios, e.g. Azure patching a machine..   how should I deal with this kind of things?
[2016-02-21 15:36:08] <ppisljar> would it make sense to put mailserver in a seperate docker image ? (my app is apache2 + php, but i need to send mail and i use msmtp at the moment)
[2016-02-21 16:00:16] <staffanselander> docker run --name some-nginx -v /Users/staffanselander/Documents/DockerTesting/static/nginx.conf:/etc/nginx/nginx.conf:ro -d nginx
[2016-02-21 16:00:23] <staffanselander> This gives me
[2016-02-21 16:00:23] <staffanselander> [9] System error: not a directory.
[2016-02-21 16:00:42] <staffanselander> But it creates a directory called nginx.conf
[2016-02-21 20:13:54] <intellix> Makan, found out how to change the project "prefix"
[2016-02-21 20:14:13] <intellix>  [<-ISSUE->] 
[2016-02-21 20:14:20] <MakanTaghizadeh> Great! How is it possible?
[2016-02-21 20:14:41] <intellix> you can use -p or the COMPOSE_PROJECT_NAME environment variable for that.
[2016-02-21 20:15:07] <intellix> and there are a few people already saying we should have a property inside docker-compose.yml, like I was proposing
[2016-02-21 20:15:58] <MakanTaghizadeh> Fantastic  Thanks for sharing
[2016-02-21 20:16:34] <MakanTaghizadeh> Yep, you were totally right.
[2016-02-21 20:16:48] <MakanTaghizadeh> Great 
[2016-02-21 20:17:47] <MakanTaghizadeh> The issue is still open, I hope they put it to work sooner. I mean make it a property inside the compose file. That would be really nicer and less error prune.
[2016-02-22 07:06:50] <mootezbessifi> MakanTaghizadeh: i found suitable solution and more secure.
[2016-02-22 07:07:27] <mootezbessifi> i just added my hostname of the host machine to the dns server
[2016-02-22 07:11:42] <MakanTaghizadeh> Right, that’s truely better solution.
[2016-02-22 07:11:47] <mootezbessifi> now when i mount the application inside the container i mention (in eureka config side ) the hostname of the host machine as well as switching "preferIpAddress" option to false
[2016-02-22 07:12:18] <MakanTaghizadeh> Great, fantastic.
[2016-02-22 07:13:27] <mootezbessifi> now while a docker container is executed into a host machine  as a process witch can be accessed via his exposed port number
[2016-02-22 07:14:18] <mootezbessifi> the application will be registered in eureka with the host's hostname and its own port number
[2016-02-22 07:14:22] <mootezbessifi> and bingo
[2016-02-22 07:14:33] <mootezbessifi> it works like a sharm
[2016-02-22 07:15:03] <MakanTaghizadeh> Congrats mate.  That’s definitely a better solution.
[2016-02-22 07:15:11] <mootezbessifi> i found this solution the most safe and easy to implement
[2016-02-22 07:15:25] <MakanTaghizadeh> Yep, right.And thanks for sharing. I’m gonna learn it and use it myself.
[2016-02-22 07:17:00] <mootezbessifi> after some documentations, the --net option is a real damage
[2016-02-22 07:17:56] <mootezbessifi> the container notion is broken
[2016-02-22 07:18:14] <mootezbessifi> added to security issues
[2016-02-22 07:18:39] <MakanTaghizadeh> Totally true
[2016-02-22 07:19:30] <mootezbessifi> and stability ( not enough)
[2016-02-22 07:20:00] <mootezbessifi> some processes may crashes with no explanation
[2016-02-22 07:20:14] <mootezbessifi> and it may cause network conflicts
[2016-02-22 07:20:18] <mootezbessifi> well
[2016-02-22 07:21:36] <mootezbessifi> big thanks to those whom helped me
[2016-02-22 07:21:44] <mootezbessifi> bye
[2016-02-22 07:21:45] <MakanTaghizadeh> Without a doubt that’s not a reasonable solution, you’re right
[2016-02-22 11:16:31] <basiclaser> any tips on NAT Port Forwarding@MakanTaghizadeh? :D
[2016-02-22 11:20:28] <basiclaser> anyone had to deal with docker NAT on OSX ?
[2016-02-22 14:49:39] <MakanTaghizadeh>  Honestly I couldn’t manage to play around well with Docker in OS X, However we use it quiet seriously in our production and development Linux envs.Support for Docker in OS X (and Windows also), is somehow partial. With the help of VM Hypervisor (VirtualBox) and boot2docker this could come to life in both OSs.In this case, when you publish a container port, this is actually the guest in VBox acting as the host for that container. The guest has two interfaces:Adapter 1: configured as Internal Network\nAdapter 2: configured as Host-only NetworkWhen you publish a container port, that port is published on all interfaces of the guest vm. And of course that is accessible at Adapter 2’s IP address (which is in range of 192.168.99.0/24 by default) from your OS X.However, there is an option out there that helps you to gain access to that port using your OS X IP address. This can be achieved with NAT PF (Port Forwarding) feature that VBox gives us at some easy peasy steps.You only need to follow the following simple steps:Open up VirtualBox\nFind a guest machine named default and from the right side find a section named *Network. Then click on its title.\nIn Adapter 1 tab, find Advanced section. Openning that section reveals some advanced options including Port Forwarding. Click on it.\nIn the openned page clicking on the + button in the top right, adds a new row and you can configure the port you’d like to be forwarded to the guest. Pay attention that the direction is from OS X to the guest not the reversed one.That was piece of cake, was it not? 
[2016-02-22 17:54:17] <staffanselander> I’m so stuck
[2016-02-22 17:54:20] <staffanselander> Can anyone help me, 1 on 1 chat maybe?
[2016-02-22 17:57:35] <staffanselander> I try here then
[2016-02-22 17:57:41] <staffanselander> I have a dockerfile
[2016-02-22 17:57:44] <staffanselander> "FROM nginxRUN mkdir /etc/nginx/logs && touch /etc/nginx/logs/static.logADD ./nginx.conf /etc/nginx/conf.d/default.confVOLUME /Users/staffanselander/Documents/Docker/MyFirstDocker/src /www"
[2016-02-22 17:58:17] <staffanselander> Shouldnt the files i create in src end up in www, or havent i understood it correctly?
[2016-02-22 18:18:22] <MakanTaghizadeh> VOLUME statement in Dockerfile is for advertising directories which might be binded to a folder of host upon start.In other words, it doesn’t do as you expected. You’ve got have this in your Dockerfile: [<-CODE->] and this when you run your container: [<-CODE->] 
[2016-02-22 18:36:30] <MakanTaghizadeh> Or optionally you could usedocker-compose.ymlif you’d like to omit writing the volume binding statement everytime you run the container.
[2016-02-22 20:21:07] <staffanselander> MakanTaghizadeh: YES, that was it. Also found a great article on the matter.
[2016-02-22 20:21:10] <staffanselander> Thank u alot!
[2016-02-22 20:21:21] <staffanselander> U dont happen to have a good article on docker compose?
[2016-02-22 21:10:59] <MakanTaghizadeh> np bud Well, not anything other than official one in here Docker Compose. I found it pretty self explanatory.But, pay attention that:Compose is still primarily aimed at development and testing environments. Compose may be used for smaller production deployments, but is probably not yet suitable for larger deployments.As officials say in here.
[2016-02-23 11:03:44] <basiclaser> hi all
[2016-02-23 11:03:49] <basiclaser> can anyone help me?
[2016-02-23 11:05:06] <basiclaser> im trying to run docker containers for mongoDB, and also ElasticSearch on OSX
[2016-02-23 11:06:33] <basiclaser> my current solution im working on is running the containers inside a virtualbox ubuntu instance. How can i communicate with software from inside ubuntu to my program which needs the databases on my osx?
[2016-02-23 13:48:14] <basiclaser> ok i managed to get all my software stack running in the VM , problem solved ! LOL
[2016-02-23 18:26:26] <ksylvan> basiclaser: you are running docker toolbox on your OS X? If so you can just talk to the IP address returned bydocker-machine ip defaultand the port(s) exposed by your docker containers.
[2016-02-23 21:22:46] <staffanselander> What is the best way of supplying nginx with a config file?
[2016-02-23 21:23:37] <staffanselander> For the moment when i build the image i use “ADD ./nginx.conf /etc/nginx/conf.d/default.conf"
[2016-02-23 21:23:58] <staffanselander> But then i have to rebuild the images everytime i want to change the config right?
[2016-02-24 00:08:04] <alaverty> yep
[2016-02-24 00:08:18] <alaverty> just mount the config with a volume
[2016-02-24 00:08:52] <alaverty> -v $PWD/nginx.conf:/etc/nginx/conf.d/default.conf
[2016-02-24 00:09:25] <alaverty> then edit on the fly and then nginx -s reload
[2016-02-24 02:53:35] <torquemad> How do you do if statements in dockerfiles? I am not having a good time (simply trying to compare an environment var to a string.
[2016-02-24 02:54:50] <torquemad> RUN if  "${BRANCH}" == "master"; then echo "master"; else echo "dev"; fi
[2016-02-24 03:39:22] <nafg> torquemad: Dockerfile doesn't parse it, it's run by bash, so it's a bash question
[2016-02-24 03:41:46] <torquemad> nafg: ah, fair enough
[2016-02-24 04:34:30] <ksylvan> torquemad: if your snippet above is what you are trying to run, I think you want=and not==
[2016-02-24 06:59:43] <basiclaser> ksylvan: thanks bud :)
[2016-02-24 06:59:58] <basiclaser> does anyone have experience with digital ocean here?
[2016-02-24 07:49:11] <staffanselander> alaverty: But do i have a git repository with the configs and so on? Or what is the best way to share this configuration in the team? :)
[2016-02-24 08:39:10] <nafg> basiclaser: what sort of experience?
[2016-02-24 15:55:33] <basiclaser> nafg: nothing man i solved it, just a ssh key issue
[2016-02-24 16:07:57] <andrefreitas> Hi, is there any simple way of duplicate a running container?
[2016-02-24 16:08:19] <andrefreitas> (not the same as docker commit container new_image)
[2016-02-24 17:14:02] <4gekkman> Greetings from green newcomer
[2016-02-24 17:14:06] <4gekkman> Could you advice me fresh docker tutorial (how-to for nginx/php/mysql developer)?Like that:http://www.newmediacampaigns.com/blog/docker-for-php-developersbut fresher
[2016-02-24 17:14:55] <staffanselander> I think it’s good aside from the boot2docker thingy :#
[2016-02-25 09:08:27] <rogeralsing> I have a weird problem with docker-machine... it seems to time out after some idle time..  and most often it cant be fixed by restarting VM, I have to reboot my physical machine before the docker machines get back online... is that a known issue or just local for me?
[2016-02-25 13:35:31] <LukeHowellDev> I sometimes have a similar issue when my host machine sleeps.  But I just have to usedocker-machine restart.  Could sleeping have anything to do with it?
[2016-02-25 16:16:59] <atrauzzi> Does anyone know if it's possible to only mountspecificvolumes from one container inside another?  Something likevolumes_from, except with the behaviour of a bind mount?
[2016-02-25 16:17:32] <atrauzzi> (I have a configuration file in one container and I\'d like another to be able to "use" it via this process)
[2016-02-25 21:36:35] <web20opensource> Any hand to a friend here please : [<-LINK->] 
[2016-02-26 04:37:22] <4gekkman> Hello
[2016-02-26 04:37:56] <4gekkman> Anybody know, where is the folder with images on host machine ?
[2016-02-26 04:39:15] <4gekkman> When we use "docker images", what folder is used by this command ?
[2016-02-26 07:15:37] <gregorygtseng> 4gekkman: the docs are here: [<-LINK->] 
[2016-02-26 07:16:20] <gregorygtseng> if you typedocker info, you can see what storage driver you’re using
[2016-02-26 07:16:45] <gregorygtseng> by default, docker’s local storage area is/var/lib/docker
[2016-02-26 16:02:44] <4gekkman> gregorygtseng: Thank u 4 answer
[2016-02-26 16:05:22] <4gekkman> Now i can't mount folder with files from windows host to container =(When i try, folder appears in container, but it's empty.For example (in powershell): [<-CODE->] Folder /german exists in container, but it's empty.And there is no sync between these folders when i make chenges.Any ideas how to do with it?In docker inspect of this container we have: [<-CODE->] 
[2016-02-27 06:47:23] <fkautz> mmm, i was just removed from the docker org, i was part of it so that i can make changes to gordon
[2016-02-27 06:47:27] <fkautz> any way of getting access to gordon back?
[2016-02-27 13:14:55] <basiclaser> I successfully have mongo and elastic running with a docker-compose script. Where can I find external ports?
[2016-02-27 13:20:37] <basiclaser> or the docker/docker-compose IP ?
[2016-02-29 06:00:18] <AsanovRuslan> HelloHelp me to understandSo errorERROR: No command specifiedWhen run sudo docker-compose up -ddocker-compose.yml [<-CODE->] 
[2016-02-29 08:17:17] <staffanselander> What does it output without sudo ?
[2016-02-29 08:40:20] <AsanovRuslan> LadyVipEx: docker: Cannot connect to the Docker daemon. Is the docker daemon running on this host?.
[2016-02-29 22:08:46] <thaJeztah> AsanovRuslan: that image does not have a default command set (theres noCMD, and the base image also doesnt have a default CMD) [<-LINK->] 
[2016-02-29 22:09:51] <thaJeztah>  [<-LINK->] 
[2016-02-29 22:11:41] <thaJeztah> What are you trying to run in that docker-compose stack? If you only want to start an interactive container,docker run -it alpine shshould do the trick
[2016-03-01 02:45:27] <michaeldye> I'm using docker 1.10.1 and expecting to find a content-based hash in metadata in my local repo that I can compare with others' hashes of the same image to ensure we're using the same version. It looks like image ids (as reported bydocker inspect --format='{{.Id}}') are not stable between systems. Are the digests supposed to be consistent between systems? (Unfortunately, it seems a bug even in the latest docker client version prevents making use of them: [<-LINK->] 
[2016-03-01 21:33:08] <rkhunter> Hey folks, so I am trying to install let's encrypt on nginx official image container
[2016-03-01 21:33:24] <rkhunter> and one of the steps involves closing 80 port
[2016-03-01 21:34:01] <rkhunter> when I run service nginx stop the container restarts. how can I prevent it from doing it?
[2016-03-01 22:27:38] <LukeHowellDev> rkhunter: I’m not sure how to prevent that particular image from retarting on shutting down nginx, however you can look into the other method for letsencrypt where you place a file in the root of your server.
[2016-03-01 23:57:57] <Nezteb>  [<-LINK->] 
[2016-03-02 00:02:07] <ghost~54edf88e15522ed4b3dc76d8> rkhunter: keep the container alive, you can do an exec  bash on the container to ensure your container will continue to run even while you restart nginx.I'll consider rebuilding the image though and bake the process in a Dockerfile
[2016-03-02 00:04:31] <rkhunter> dorwardv: so to exec shell in another window
[2016-03-02 00:04:43] <ghost~54edf88e15522ed4b3dc76d8> yes
[2016-03-02 00:05:01] <rkhunter> dorwardv: I am using as@snumb130suggested a different solution, but it's good info for future
[2016-03-02 00:05:05] <rkhunter> thanks
[2016-03-02 00:05:48] <ghost~54edf88e15522ed4b3dc76d8> (y)
[2016-03-02 20:34:44] <ksylvan> Anyone know how to use sails.io.js in node to connect to the sails backend? I'm using the instructions in the Docs and the the repo, and I see this: [<-ISSUE->] 
[2016-03-02 20:54:51] <ahmedbaracat> Hi,The company I am working for is working on a project for a major cloud provider and looking for people willing to participate in a study about containers. The sessions are 1-hour individual sessions (not focus groups) and will be run online in the next couple of weeks using GoToMeeting or something similar. In the session, you will be asked to provide your feedback and opinions about certain tools and services that you may or may not be currently using.For the sake of keeping the sample unbiased, we can't reveal the name of the client commissioning the research just yet, but if you're chosen to participate and you'd like to know, we would be happy to tell you. It's no secret, it just helps keep the research more structured and findings more reliable.If you are interested in participating, please fill out the following screener: http://goo.gl/forms/0Gatjqbyq6If you are selected to participate in the study, you will be compensated $125 for your time.Thanks.
[2016-03-03 13:17:14] <staffanselander> Hey guys!
[2016-03-03 13:17:18] <staffanselander> I have a docker file
[2016-03-03 13:17:36] <staffanselander>  [<-CODE->] 
[2016-03-03 13:18:25] <staffanselander> Then i build a image and then i run a container
[2016-03-03 13:18:27] <staffanselander> however
[2016-03-03 13:18:51] <staffanselander> When i bash into the container it dosent seem like php5-fpm is neither running or installed
[2016-03-03 13:19:04] <staffanselander> What is happening? :(
[2016-03-03 13:19:58] <fruitl00p> LadyVipEx: whats your run command like? Is there any output from the php-fpm script? or any startup logs from php-fpm that might indicate an error?
[2016-03-03 13:22:35] <staffanselander> oooooh myyy f** good
[2016-03-03 13:23:10] <staffanselander>  [<-CODE->] 
[2016-03-03 13:23:14] <staffanselander> problem found….
[2016-03-03 13:23:19] <fruitl00p> are you correctly linking from nginx -> fpm as your backend? :)
[2016-03-03 13:23:30] <fruitl00p> wrong image? :)
[2016-03-03 13:23:36] <staffanselander> Haha yhea :’)
[2016-03-03 15:04:37] <hantc> hello, GITLAB: I need to import my mysql dump in docker to start app tests in CI, and I'm not able to google it anywhere. Has anyone experience?
[2016-03-03 17:09:21] <ksylvan> hantc: The GitLab docs are pretty good on how to run GitLab and GitLab-runner in containers.
[2016-03-03 17:11:21] <hantc> ksylvan: If I use service, there are mentions about something like docker-entrypoint-initdb.d which should be used to init .sql files
[2016-03-03 17:11:24] <hantc> but it doesn't work
[2016-03-03 18:24:52] <ksylvan> hantc: I upgraded an existing gitlab instance to a dockerized one by simply using-vvolume mount flags to map my host dirs to directories inside the container. So I would assume you have to put your SQL dump in a directory and mount it via-vto wherever the image expects it to be.
[2016-03-03 18:38:37] <robertwtucker> @hantc @ksylvan is correct. here's an example of a docker compose file i use: [<-CODE->]  [<-CODE->] 
[2016-03-04 01:07:32] <fredyfx> what kind of applications is not able to run under docker?
[2016-03-04 01:07:47] <fredyfx> what kind of applications are not able to run under Docker?
[2016-03-04 02:05:26] <wmfairuz> Hi, my container is assigned with 2 IPs, how can I know which IP is assigned to which interface? (et0 or eth1) thanks
[2016-03-04 02:05:37] <wmfairuz> docker inspect doesn't seem to provide this info
[2016-03-04 07:21:56] <vsuharnikov> wmfairuz: you can log in into a container viadocker exec -it container_id shand runifconfig -aor something like this
[2016-03-04 20:16:44] <josdotso> I'm trying to find a clever way to consume Consul's service discovery with a standard issue Docker daemon.  DNS A records are easy enough, but how can I smartly convince container X (e.g. Wordpress official container) to leverage Consul's DNS SRV record for mysql.service.consul?  Is it a shell thing, perhaps?  Use a $(dig) to get the port whilst booting the container?
[2016-03-04 20:25:04] <josdotso> I guess shell is the least common denominator, because 12-factor app environment variables creed.
[2016-03-07 07:42:10] <MakanTaghizadeh> josdotso: There is also one solution other than using DNS interface. You can useconsul-template. It gives you tons of features, however it has more efforts to setup than using DNS interface.
[2016-03-07 09:07:08] <staffanselander>  [<-CODE->] 
[2016-03-07 09:07:31] <staffanselander> But when i bash into the container, php5-fpm is nowhere to be found
[2016-03-07 09:36:20] <staffanselander> Nvm
[2016-03-07 09:36:24] <staffanselander> I got it working
[2016-03-07 09:36:28] <staffanselander> <3
[2016-03-07 13:57:18] <staffanselander> Yhea retard me is going to spam here with questions
[2016-03-07 13:57:26] <staffanselander>  [<-CODE->] 
[2016-03-07 13:57:54] <staffanselander> When i do nmap php in my nginx container
[2016-03-07 13:58:03] <staffanselander> it sayes all my ports on php are closed
[2016-03-07 13:58:36] <staffanselander> Im trying to connect nginx with php fpm but im just getting connection refused
[2016-03-07 20:57:09] <ahmedbaracat> I am reposting this because the last one had formatting issues
[2016-03-07 20:57:24] <ahmedbaracat> My company is looking for participants for Docker UX research. The research said this:“I’m a user researcher working on a project for a major cloud provider and looking for people willing to participate in a study about containers. The sessions are 1-hour individual sessions (not focus groups) and will be run online in the next couple of weeks using GoToMeeting or something similar. In the session, you will be asked to provide your feedback and opinions about certain tools and services that you may or may not be currently using.For the sake of keeping the sample unbiased, I can't reveal the name of the client commissioning the research just yet, but if you're chosen to participate and you'd like to know, I'd be happy to tell you. It's no secret, it just helps keep the research more structured and findings more reliable.If you are selected to participate in the study, you will be compensated $125 for your time.A little bit about me...I've been a user researcher about 15 years and have a consultancy in Austin called Userade (www.userade.com) that specializes in UX research and design. Previously, I worked at Dell and SolarWinds. If you have any questions, I'd be happy to answer them. Thanks.If you are interested in participating, please fill out the following screener: http://goo.gl/forms/0Gatjqbyq6 ”
[2016-03-08 04:11:00] <nlhkh> I need to dynamically generate/reconfigure a config file when environment variables change. This can be done withj2cli. However, some images that I use do not have python, and because the apt-list has been removed, it is hard to install python. Is there another best practice regarding config generation for Docker?
[2016-03-08 09:25:22] <alaa> nlhkh: I think this approach of solving the problem is wrong. You could use some service-discovery backend that stores your Key-Value pairs, and the populates the values on your file-system the way you wanted. take a look at (etcd, consul, etc..)
[2016-03-08 12:54:06] <nlhkh> alaa: This is a different issue. It's not about service discovery or KV lookup. The problem is some software, like in my case Logstash, requires a config file to run, but the config does not not accept external parameters. In other words, I need to generate a config file for the app to run, be it that the config values come from consul, etcd or whatever.
[2016-03-08 12:54:47] <nlhkh> However, I solved the issue by instead of using Python, I installed Jython (it's a java based image) and continue usingj2cli.
[2016-03-08 17:39:25] <fredyfx> hi there! I have a question and I would like to have your help to solve it: What kind of applications are not able to run under Docker?
[2016-03-08 18:26:13] <nafg> fredyfx: maybe kinds that can't run in linux?
[2016-03-08 18:26:26] <nafg> Do you have anything specific in mind?
[2016-03-08 23:00:57] <fredyfx> hi@nafgit is just an idea I have in mind, Dockers looks so good but it has a limit. I was thinking about the applications that set up a Windows Service or a Linux Daemon
[2016-03-09 07:39:32] <fruitl00p> fredyfx: we've been running various tools (GUI, daemons, servers, heck we even ported a complete VM into a single container just to be able to move it to another host and be deconstructed there into several containers) I might see the problem with running windows services... (natively, due to the linux kernel) but other than that, i haven't come across anything that can't be dockerized yet... Some services might require more time to setup or might be difficult to automate, but it is doable...
[2016-03-09 19:06:34] <staffanselander> Hello
[2016-03-10 13:28:58] <webmutation> Hi, I am currently experiencing some issues connecting to an insecure private repository (artifactory), it always tries to connect using https. This used to work, but upgraded to latest version of Artifactory and Docker and now the insecure repositories no longer work... was the docker client disabled the ability to connect over http basic auth? I can curl and get my docker credentials but using docker login it always tries to use http. Is this a bug on docker client?
[2016-03-10 13:29:35] <webmutation> Is there a simple way to add self-signed certificates to a boot2docker machine, the current solutions circuling around the net don't seem to apply to the latest version.
[2016-03-10 15:23:21] <ArunkumarRamanan> roles of data structure and algorithm in open source?
[2016-03-10 16:43:03] <elmalto> Hi guys, I am running into docker setup issues.Running on CentOS 7.2 on Azure: Volume group "sda1" not found. Cannot process volume group sda1. No volume group has been specified and root device volume group could not be determined. Exiting.Any idea how I can fix this?
[2016-03-10 22:26:00] <fredyfx> fruitl00p: thank you so much for response, my curiosity is so happy at this moment :)
[2016-03-11 09:32:35] <GoNode5> Hello, a have a basic question. If I have  ubuntu 14.04LTS   with 3 dockers (Redis, Mysq,Nginx) and the dockers all three are based on ubuntu 14.04LTS, how many time ubuntu is actually loaded?  I mean memory wise (I dont care about diskspace)
[2016-03-11 10:40:34] <fruitl00p> GoNode5: memory wise: it depends on the processes running inside each container. As long as you have single processes per container (Mysql, Nginx, Redis) the memory usage won't differ that much from running those same processes without docker in between on anativeUbuntu 14.04 instance
[2016-03-11 10:40:39] <fruitl00p> (if i'm not mistaken)
[2016-03-11 10:49:08] <GoNode5> fruitl00p: ok, so the OS itself is not loaded in memory 3times but act like as if I installed mysql/ubuntu/redis on the native 1404 instance (like my current setting)
[2016-03-11 10:58:04] <fruitl00p> Basicallly yes: since the OS memory footprint is mostly determined by active services and background processes... Thus if you only run (i.e.) a ssh-daemon in a container that would be the only memory using process. All the other OS--image-related stuff is just a file in the container... (which on host level might be reused between containers and such thanks to the AUFS/overlay stuff... from what i understand)
[2016-03-11 10:59:44] <fruitl00p> bear in mind though that because you're only running that single process (i.e. NGINX) the other stuff the OS might normally do for you (like syslogging, cron et al) you'd have to do yourself or outside of the container... (i.e. logging via stdout and using docker log engines to move that elsewhere for processing, storage and archival)
[2016-03-11 11:08:24] <GoNode5> ok understand thank you, so if you base redis on centos, nginx on redhat and mysql on debian, you get 3 OS
[2016-03-11 11:09:19] <fruitl00p> as files on disk, but not necessarily  as memory footprint / processlisting...
[2016-03-11 11:16:29] <GoNode5> ok still not sure If I have Native Ubuntu 1404 and start a container test with Redis on Ubuntu1604 what happens
[2016-03-11 11:17:54] <fruitl00p> GoNode5: it shouldnt matter for the memory usage. I've been running a centos image  on debian, ubuntu and even coreos hosts... just keep to the mantra of a single process container ;)
[2016-03-11 11:22:10] <GoNode5> Ok will try to the chanting single process :-)
[2016-03-11 11:22:23] <fruitl00p> good luck ;)
[2016-03-11 11:23:02] <GoNode5> well trying to kill the luck process ;-) thnx for your help
[2016-03-11 11:24:21] <fruitl00p> np... just experiment... a simpledocker run --rm -d nginxon various hosts is an easy test for trying out the various differences ;)
[2016-03-11 11:26:24] <GoNode5> ok will try
[2016-03-11 17:02:52] <graingert> why does "docker push" not stop after the first "Image already exists"
[2016-03-11 17:03:09] <graingert> like if a child image exists on a repo, then all the parent images must already exist
[2016-03-11 17:03:17] <graingert> it takes a few seconds each time to verify
[2016-03-11 17:03:31] <fruitl00p> with image they actually mean 'layer' thus the base layer might exist but ones ontop of that might not?
[2016-03-11 17:04:13] <graingert> docker push pushes images from top to base
[2016-03-11 17:05:07] <graingert> ah yes I see what you mean
[2016-03-11 17:05:31] <graingert> should use the git has/need algorithm
[2016-03-11 17:28:04] <marcelmfs> Does someone also
[2016-03-11 23:59:41] <stcalica> Hey is anyone else get some weird issues when using Docker on a debian system, specifically mint?
[2016-03-12 00:01:57] <stcalica> For instance I use docker exec on a container I have but it states that container does not exsist, but when i run docker ps i can obviously see that container and that it is up
[2016-03-12 00:03:19] <stcalica> oops wrong place to ask , just saw the header above sorry
[2016-03-13 17:26:06] <nafg> How should Idocker loginon a deployment server?
[2016-03-13 17:26:23] <nafg> Should I create a separate docker hub login for each server?
[2016-03-13 17:26:48] <nafg> Should I user my personal login, and give all the servers the same permission sets as each other and myself?
[2016-03-14 21:14:23] <uptownhr> when running docker outside docker, docker.sock volumized inside the containr. How does docker build work inside the directory? Does docker build, look from the host machine for files or are files from inside the container used?
[2016-03-14 21:14:43] <uptownhr> if the host files are used, any idea on how the path works?
[2016-03-14 21:15:06] <uptownhr> ie: Dockerfile contains,ADD ./ /app
[2016-03-14 21:15:19] <uptownhr> where would ./ be in the host computer?
[2016-03-14 22:46:55] <thaJeztah> uptownhr: by default, its relative to the location of the Dockerfile. Its good practice to create a new directory, containing your Dockerfile, and all the files needed inside your Dockerfile/container.
[2016-03-15 06:05:17] <uptownhr> thaJeztah: I understand, but i'm currenlty running docker build from inside a container that has docker.sock exposed from the host
[2016-03-15 06:05:53] <uptownhr> so the question i guess really is, in this case, does build use the container filesystem or the host file system. If it is the host, how does the path work?
[2016-03-15 09:36:22] <uptownhr> ctmnz: welcome to the channel
[2016-03-15 09:41:21] <ctmnz> Hello@uptownhr
[2016-03-15 10:16:34] <uptownhr> Given that you are using docker-compose and using the "build" field to build your container images. How do you handle cases when one of the Dockerfile reliess on another image being built and available. For example, I have a Base Dockerfile that my other Dockerfiles uses in the FROM definition. But is failing due to the build not having been built into an image.
[2016-03-15 10:17:07] <uptownhr> I understand it can be in a repository as an image but is this the only way?
[2016-03-16 09:02:33] <fiunchinho> what would be the best way to test a restart policy? Should the container get restarted when I’ve set restart=always and I stop the container?
[2016-03-16 12:41:54] <LukeHowellDev> @fiunchinho No, if you stop the container then it does not get restarted.  I did a little test and seemed to at least be able to tell me that the restart was working.  You might could try the following in your container [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2016-03-16 13:46:27] <fiunchinho> thanks
[2016-03-16 13:46:40] <fiunchinho> I tried killing the process running inside the container
[2016-03-16 13:46:42] <fiunchinho> and that worked too
[2016-03-17 03:22:02] <timcharper> There seem to be errors on this page:https://docs.docker.com/swarm/install-manual/#step-4-set-up-a-discovery-backend [<-CODE->] Secondly, the instructions for setting up a consul cluster are to copy the IP addresses, and then... do absolutely nothing with them? Step 4.1 and Step 4.5 are identical.
[2016-03-17 03:26:21] <timcharper> I think the intention was to add a-joinflag on there
[2016-03-17 16:16:26] <nlhkh> I am experiencing Docker.io outage, I cannot push or pull any image. Is anyone having the same problem?
[2016-03-17 21:13:48] <rkhunter> hey folks, I have cranked up wordpress container by \'fixing\'permissions on / directory instead of . Yeah i know i am stoopid  How can I grab "wp-content" from container that shuts down after 5-10 seconds from MySQL Connection Error: (2002) php_network_getaddresses: getaddrinfo failed: Name or service not known ?
[2016-03-17 21:14:30] <rkhunter> I plan to delete this container and make a new one and just throw in a folder in there
[2016-03-17 21:14:45] <rkhunter> mysql container will be left untocuhed
[2016-03-17 21:20:42] <rkhunter> Okay, found a way, turns out you can docker cp from now running container
[2016-03-17 22:33:31] <timcharper> I can't find the repo for the docs so I can make the suggestions I posted yesterday... can someone point me in the right direction?
[2016-03-18 06:28:29] <brijeshamin> Hello, when I am running docker build it runs npm install from my docker file. npm install gets stuck at certain point and nothing happens after that. Any suggestion on how to fix this problem?
[2016-03-19 21:35:48] <subfuzion> brijeshamin: This generally happens to me when I've switched networks. I simply restart the machine. The other time it happens is when I've run out of inodes and need to recreate the machine.
[2016-03-19 21:37:01] <subfuzion> Anyone else beside me wish there was a logging driver for kafka?
[2016-03-19 21:40:01] <subfuzion> I've proposed a potential solution to make it easy to let developers add custom logging support with a logging driver that allows you to specificy an image to run to handle a log stream and do whatever you want with it (such as forward it to kafka) here: [<-ISSUE->] Any thoughts from anyone as to how reasonable of a solution this is, vs. having to add new logging drivers and release them with the engine itself?
[2016-03-19 22:59:58] <otbe> Im using fluentd + kafka Plugin. Works like a charm :)
[2016-03-19 23:00:56] <subfuzion> oh? great tip!
[2016-03-19 23:04:50] <subfuzion> so how does this work? Ideally, i'm looking for a no-impact approach on the docker host and one that doesn't require an intermediary proxy service.
[2016-03-19 23:24:07] <subfuzion> otbe: I suppose you have a fluentd collector somewhere with the kafka plugin, so you have the logging driver sending json to the collector, and then the collector forwarding to kakfa, correct?
[2016-03-19 23:27:56] <subfuzion> This may be the approach I have to use for the time being. Ideally, I could skip the intermediary. My proposal is to have a logging driver that lets you specify an image to pull and run that docker then streams the logs to. The logging driver would pass on the configuration options to the container, which implements whatever logic you want for what to do with logs. In my case, the container would forward the logs directly to kafka, skipping the intermediary (such as the fluentd collector).
[2016-03-19 23:29:51] <subfuzion> Does anyone see any problems with this proposal?
[2016-03-20 11:44:40] <brijeshamin> Thanks@subfuzionI agree looks like something to do with networks
[2016-03-20 11:45:20] <brijeshamin> It works now..
[2016-03-20 11:45:38] <brijeshamin> I have recreated default machine with some changes and it works
[2016-03-20 18:11:58] <danielmahon> hello all, can you create a new docker base from a system image? For example id like to create a new base using the image listed here: [<-LINK->] 
[2016-03-21 01:59:50] <subfuzion> @danielmahon I don't know the answer to your question, but if you haven't seen these links, perhaps these will help you get going.Creating a base image from scratchhttps://docs.docker.com/engine/userguide/eng-image/baseimages/Some of the actual scripts used here:https://github.com/docker/docker/tree/master/contribImporting a rootfshttps://asciinema.org/a/23024 [<-CODE->] 
[2016-03-21 12:09:11] <simplicbe> Hey guys, have any one tried dot-net-core using docker? Seems to be a cool thing. Is this already ready for productive usage?
[2016-03-21 18:03:50] <neilsoult> I\'m trying to convert to an organization and keep getting the error "User must first leave all organizations and groups."
[2016-03-21 18:04:41] <neilsoult> How do I make sure the account I'm trying to give ownership to doesn't belong to any orgs or groups
[2016-03-21 18:11:52] <alexlongshaw> Has anyone created a ECS task definition using volumes. Trying to convert  docker run -d -p 80:80 -v /var/run/docker.sock:/tmp/docker.sock -t jwilder/nginx-proxy  from http://jasonwilder.com/blog/2014/03/25/automated-nginx-reverse-proxy-for-docker/Into a task definition but can't find any examples that setup volumes in the same way
[2016-03-22 13:27:38] <note89> i started using docker cloud yesterday and im wondering if there is a easy way to set the timezone in the containers ?I use postgres and now all dates are of  by one hour compared to sweden.
[2016-03-22 16:45:47] <Daxten> hey guys, I\'m having a problem on windows:Started Quickstart Terminal\nswitched to /d/folderond\n$ ls => shows bunch of files\n$ docker run -d -p 80:80 --name test -v "$PWD":/var/www/html php:5.6-apache\n$ docker exec test ls /var/www/html => shows nothing
[2016-03-22 16:45:52] <Daxten> anyone can help me with this?
[2016-03-22 16:46:40] <Daxten> this is straight after installing docker on windows, nothing custom here
[2016-03-22 16:50:38] <alexlongshaw> No experience on a windows host...Does docker ps show your container running?
[2016-03-22 16:52:41] <alexlongshaw> And is your volume listed   docker inspect -f '{{ (index .Mounts 0).Source }}' CONTAINER_ID_HERE
[2016-03-22 16:56:40] <Daxten> sec i will check
[2016-03-22 16:57:15] <Daxten> container is running, and apache is working on port 80 (but returns no files, since there  are no)
[2016-03-22 16:57:56] <Daxten> $ docker inspect -f '{{ (index .Mounts 0).Source }}' carneval-test\nTemplate parsing error: template: :1: unexpected unclosed action in command
[2016-03-22 16:58:41] <Daxten> hm I will check if it works if I'm not using one of the windows shared folders
[2016-03-22 17:00:01] <alexlongshaw> My bad,  think that is a unix search. docker inspect CONTAINERYou should get a big json dump. Paste from "Mounts": [
[2016-03-22 17:01:00] <Daxten> So Docker is mounting the windows-user folder to ~/ and all drives to /c/, /d/ etc.
[2016-03-22 17:01:13] <Daxten> sharing ~/test with a docker container works
[2016-03-22 17:01:20] <Daxten> /c/, /d/ etc. doesnt work
[2016-03-22 17:01:38] <Daxten> inside the docker container the folder is just empty then for me
[2016-03-22 17:02:32] <Daxten>  [<-CODE->] 
[2016-03-22 17:03:08] <Daxten> doing the same inside of /c/test returns no file (even though there is one when I enter ls directly)
[2016-03-22 17:04:09] <Daxten>  [<-CODE->] 
[2016-03-23 02:12:30] <mxab87ucgjf46heo> @Daxten Try this instead of using the "$PWD", [<-CODE->] 
[2016-03-23 02:12:40] <mxab87ucgjf46heo> Daxten: Let me know if that works?
[2016-03-23 04:43:31] <robertwtucker> I believe that, for Windows, you can only mount paths under /c/Users
[2016-03-23 08:30:44] <Daxten> braderhart: no already tried that
[2016-03-23 08:30:52] <Daxten> robertwtucker: Yeah I think so too
[2016-03-23 10:22:44] <whitecolor> hi, has anyone used Windows and managed to map folder form host to virtualbox guuest? i.e.D:\\Code (on windows host) -> /code (on linux guest)?
[2016-03-23 10:25:56] <JeffryGonzalez> Hey@whitecolorthis article helped me: [<-LINK->] 
[2016-03-23 10:30:36] <whitecolor> JeffryGonzalez: Thanks that works, great)
[2016-03-23 10:42:33] <fiunchinho> We are having a discussion here in the office about what should a container contain inside. Should the Dockerfile install build tools (compile java or whatever), or should only be able to run the already compiled code? I think it makes sense to only have the compiled code, since I see docker as a tool to run processes, what do you guys think?
[2016-03-23 10:43:04] <fiunchinho> I’m googling around, and I see nodeJS guys using images with npm to build the application in the Dockerfile
[2016-03-23 10:43:44] <fruitl00p> I'd agree and have a seperate box used for building the app.. That not only seperates the dependencies but also lowers the actual production image size (probably) (and thus keeping its surface area as small as possible)
[2016-03-23 10:46:07] <fiunchinho> at the moment we use Jenkins for the builds, but since we have apps in node, java and what not, the problem is that Jenkins needs all the different build tools for every kind of project
[2016-03-23 10:46:32] <fiunchinho> but I think this is a problem we have to solve at the build phase, instead of changing our containers to include build tools
[2016-03-23 10:47:02] <fiunchinho> the thing is that googling a bit , I see that almost everybody wants java images with gradle/maven/sbt , or node images with npm, etc
[2016-03-23 10:47:12] <fiunchinho> so I don’t know if that’s the usual way of doing it
[2016-03-23 10:48:45] <fruitl00p> i'd suggest having seperate images with the build tools in them... each for a different project... (they might inherit from the same build tool base image type thing) that way: jenkins might indeed have alot of different projects to fetch build-images for... but that would be a one time thing... after the first pull of the project-x-build image (with java and what not included) this would be solved ;)
[2016-03-23 10:51:44] <fiunchinho> so Jenkins will execute a docker container to run npm, another container to execute gradle, and so on
[2016-03-23 10:52:10] <fiunchinho> but our Dockerfiles would be minimal, with only the platform needed to run the built artifact
[2016-03-23 10:52:13] <fiunchinho> right?
[2016-03-23 10:53:03] <fruitl00p> yup... you might even only need the 'base' / 'official' images for that... (i.e. the node/5-slim et al)
[2016-03-23 10:54:55] <fiunchinho> yep, ok
[2016-03-23 13:10:31] <fiunchinho> I’ve lost the discussion with my team mates heheh
[2016-03-23 13:10:58] <fiunchinho> their defense was that after you execute docker build, you must be able to execute docker run, and that will work
[2016-03-23 13:11:25] <fiunchinho> if the docker container doesn’t have the build tools, and it depends on other process to build/compile
[2016-03-23 13:11:35] <fiunchinho> unless you have executed that other process before
[2016-03-23 13:11:43] <fiunchinho> docker run won’t work after docker build
[2016-03-23 16:24:45] <note89> so i have deployed our app in docker cloud im wondering how select my own URL for the Service endpoint ?I pinged it and i got the IP address of the node that contains the load balancer.And this will work for now, but if i add multiple load balancers or move nodes around how to i keep the URL pointing to something consisten ?
[2016-03-23 16:55:01] <likered> Anyone know how to run a docker image with a PHP application on my local box?
[2016-03-23 17:34:16] <note89> likered: should be pretty simple.docker run -p 80:80 your_php_image
[2016-03-23 17:34:55] <note89> or am i misunderstanding what you want to do ?
[2016-03-23 17:36:14] <likered> note89: sorry, that was a bit of a general question
[2016-03-23 17:36:44] <likered> so the situation is that i have a PHP application that should be in /var/www/html of an instance
[2016-03-23 17:36:58] <likered> i used a Dockerfile, pushing it up. and i wanted to check if the PHP app works
[2016-03-23 17:39:41] <note89> so you have already built the image and tested it locally ?
[2016-03-23 17:40:07] <likered> i built and ran it
[2016-03-23 17:40:20] <note89> and it works ?
[2016-03-23 17:40:23] <likered> the repo i had was copied over successfully
[2016-03-23 17:40:31] <likered> but i don't know how to access it on localhost
[2016-03-23 17:40:40] <note89> ahh okey i got you
[2016-03-23 17:40:49] <note89> have you started the container ?
[2016-03-23 17:41:00] <note89> docker ps
[2016-03-23 17:41:14] <likered> doesn't show up
[2016-03-23 17:41:29] <note89> okey you also have to start if after you have built it :)
[2016-03-23 17:41:40] <likered> with the command you provided?
[2016-03-23 17:41:40] <note89> so try the thing i wrote above
[2016-03-23 17:42:11] <likered> ok i tried a different port, since 80 was taken
[2016-03-23 17:42:26] <likered> docker ps doesn't show anything
[2016-03-23 17:42:49] <note89> okey probably your container just turns of since it has nothing to do
[2016-03-23 17:43:44] <likered> as for my Dockerfile, this is the contents
[2016-03-23 17:43:52] <note89> try thisdocker -it -p 811:80 -v ./:/var/www/html your_docker_image
[2016-03-23 17:44:05] <note89> guessing you are in the folder of you php project
[2016-03-23 17:44:07] <likered>  [<-CODE->] 
[2016-03-23 17:44:16] <note89> ahh okey i see
[2016-03-23 17:44:23] <note89> you container does nothing
[2016-03-23 17:44:28] <likered> just downloads php and "git clones" a project
[2016-03-23 17:44:32] <likered> from local to image
[2016-03-23 17:44:40] <likered> just copies
[2016-03-23 17:44:50] <note89> docker -it -p 811:80 -v ./:/var/www/html your_docker_image bash
[2016-03-23 17:44:53] <note89> do that
[2016-03-23 17:45:09] <note89> now you have a interactive shell inside your container
[2016-03-23 17:45:15] <likered> -it  flag provided but not defined
[2016-03-23 17:46:36] <note89> docker run -it -p 811:80 -v ./:/var/www/html your_docker_image bash
[2016-03-23 17:46:40] <note89> i missed run
[2016-03-23 17:47:23] <likered> Error response from daemon: adq-demo/AdQ-Demo includes invalid characters for a local volume name, only [a-zA-Z0-9][a-zA-Z0-9_.-] are allowed
[2016-03-23 17:47:44] <note89> but you need apache or nginx to run your app
[2016-03-23 17:48:54] <note89> you can skip thevits just makes it so any localchanges are also made in the container to simplify it
[2016-03-23 17:48:58] <note89> which is pretty nice
[2016-03-23 17:49:04] <likered> should i add that to my dockerifle?
[2016-03-23 17:49:23] <likered> steps to download apache/nginx
[2016-03-23 17:49:27] <note89> you can install apache when you in the container and se that it works first
[2016-03-23 17:49:31] <note89> then include it
[2016-03-23 17:50:53] <note89> also i failed you have to writedocker run -it -p 811:80 -v $(pwd):/var/www/html your_docker_image bash
[2016-03-23 17:50:57] <note89> to mount current directory
[2016-03-23 17:51:28] <note89> install apache and see if anything turns up on you localhost:811
[2016-03-23 17:52:54] <likered> should i do it int he docker container?
[2016-03-23 17:52:59] <likered> yes i should
[2016-03-23 17:53:02] <likered> what's the easiest way to do that
[2016-03-23 17:53:39] <note89> do what ?
[2016-03-23 17:53:47] <note89>  [<-LINK->] 
[2016-03-23 17:54:02] <note89> you could use the offial repo instead that comes with apache
[2016-03-23 17:54:07] <note89> just read the guide
[2016-03-23 17:54:24] <likered> oh i see FROM php:5.6-apache
[2016-03-23 17:57:06] <likered> note89: just a small caveat/piece of info
[2016-03-23 17:57:11] <note89> precisely :) never used it myself but it should work well :)
[2016-03-23 17:57:16] <likered> i am currently working an EC2 instance
[2016-03-23 17:57:20] <likered> for drone
[2016-03-23 17:57:38] <likered> not really locally
[2016-03-23 17:57:53] <likered> not sure if that will impact how i access the image that's ran
[2016-03-23 17:57:55] <likered> on 811
[2016-03-23 17:59:04] <note89> im not sure what best practices are here so i will refrain from telling you what to do
[2016-03-23 18:00:18] <likered> let me just set this up locally
[2016-03-23 18:00:20] <likered> will save me the PAIN
[2016-03-23 18:00:55] <note89> The other containers that is run by drone se how they are accessed.
[2016-03-23 18:01:18] <note89> check that out do the same.
[2016-03-23 18:01:54] <note89> where i work i just used to bind to all interfaces but now we route localy
[2016-03-23 18:02:06] <note89> -p 0.0.0.0:811:80
[2016-03-23 18:02:21] <note89> i think that is the command
[2016-03-23 18:02:34] <note89> allso you can pass in--net=host
[2016-03-23 18:02:54] <note89> but as i said i can tell you what you should do. this are probably just hacks for lazy people and not really suitable for production
[2016-03-23 18:03:23] <likered> yeah i think i'll just make it work locally
[2016-03-23 18:03:32] <likered> i'm not working with anything specifically production yet
[2016-03-23 18:06:25] <likered> alright building the imag elocally
[2016-03-23 18:06:35] <likered> thanks for your time btw!
[2016-03-23 18:06:38] <likered> appreciate it...
[2016-03-23 18:08:37] <likered> is there any other intermediate steps?
[2016-03-23 18:08:59] <likered> i ran the docker run command for port 811, using an image from php:5.6-apache
[2016-03-23 18:10:18] <likered> ahhh just had to start apache
[2016-03-23 18:10:21] <likered> it works :)
[2016-03-23 19:16:45] <note89> Nice :)
[2016-03-23 19:42:55] <likered> note89: any RIGHT way to pass sensitive environment variables to a docker container?
[2016-03-23 19:43:04] <likered> like S3 credentials
[2016-03-23 19:43:07] <likered> AWS S3*
[2016-03-23 19:43:13] <likered> or should i just -e it
[2016-03-23 19:43:51] <Daxten> -e it or for aws, u can also save them to a file and share the folder with the container
[2016-03-23 19:44:21] <note89> haha i dont know but that seems like a good approach
[2016-03-23 19:44:29] <Daxten> if u are on aws, you can also just give the server an IAM role which has access to the data on s3 for example
[2016-03-23 19:44:58] <likered>  cool
[2016-03-23 19:44:59] <likered> thanks
[2016-03-23 20:33:22] <likered> Daxten: any reason why the ENV VARS wouldn't be recognized? i added the ENV and could see it when i runprintenv, also tried the .aws/credentials method as well. but my app doesn't find the S3 credentials
[2016-03-25 07:13:07] <xinity> hi there :)
[2016-03-25 07:13:44] <xinity> little question about compose , i'm knocking my head on trying to make docker-compose not update/pull newest images , can i achieve that ?
[2016-03-25 13:33:35] <robertwtucker> xinity: are you already using a specific version number for the image(s)? if so, one option would be to host your own private registry so that you control when the images get updated
[2016-03-25 13:34:47] <xinity> robertwtucker: problem is we are pushing updates to our own registry, we just want to "control" updates on client side, so that docker-compose won\'t update containers itself
[2016-03-25 13:36:35] <robertwtucker> use two registries? one for dev/builds and the other that the clients use (like production)
[2016-03-25 13:49:49] <xinity> why not, so there\'s no way to "block" compose from updating containers ?
[2016-03-26 11:20:12] <wsantos> When a container created with—volumes-fromget the updated volume ? I need to recreate the container to get the updated volume version ?
[2016-03-28 12:44:15] <caarlos0> hey, does anyone know if is there a log driver implementation that works with logentries?
[2016-03-28 18:31:41] <chahn1138> This is just a request for a pointer into the docs....We used root to deploy containers that I would like to work with as some other user.but that user only sees:$ docker psCannot connect to the Docker daemon. Is the docker daemon running on this host?===> Is there a way to set up "shared" environments for Docker?  What is best practice here?  TIA! :0)
[2016-03-29 10:18:04] <theshadowx> chahn1138: I think you have to add the user to the group of docker
[2016-03-29 10:26:14] <theshadowx> I have a problem with environment variables in dockerfile. I set a bunch of variables using ENV but then while compiling an app that uses these variables I got : [<-CODE->] but when I use echo to print what the variable contains : [<-CODE->] by the way here is the log : https://hub.docker.com/r/theshadowx/dockerfile_tests/builds/bj9hrv2lzsuwu6tz4fu8wj4/
[2016-03-29 14:34:13] <chahn1138> Thank you shadow.I think that you need to "export" those vars....this will ensure that subshells inherit them.
[2016-03-29 14:34:54] <theshadowx> chahn1138: how can I do that?
[2016-03-29 14:35:25] <chahn1138> set FOO=BARmakes FOO available to the current shell whereexport FOO=BARmakes it available to subshells.
[2016-03-29 14:35:37] <chahn1138> or the combo:FOO=BARexport FOO
[2016-03-29 14:36:58] <theshadowx> shall I add them to .bashrc and then> source .bashrc
[2016-03-29 14:37:34] <chahn1138> that would work fine....and would ensure that they are defined in future shells.
[2016-03-29 14:38:02] <chahn1138> (that is the only question as to "where to put them"....i.e. "where and when do you want them enforced?")
[2016-03-29 14:40:54] <theshadowx> What I 'm doing is compiling Qt with android sdk, the problem is that when I execute ./configure  with variables, it translate them correctly but then I receive this : [<-CODE->] 
[2016-03-29 14:42:02] <theshadowx> something to do with shell
[2016-03-29 14:42:21] <chahn1138> Just run:export ANDROID_NDK_TOOLCHAIN_PREFIX={value}etcetcand then re-run your configure on that same command line (same shell)
[2016-03-29 14:42:28] <chahn1138> that should get you past that issue.
[2016-03-29 14:42:41] <theshadowx> ok I'll try
[2016-03-29 14:46:36] <theshadowx> I got the same error. I don\'t the error comes from the variables themselves but I think from shell as it uses "dash" and not "bash" and it considers ANDROID_NDK_TOOLCHAIN_PREFIX as the name of an executable
[2016-03-29 14:53:14] <theshadowx> chahn1138: anyway thanks I think I need to dig more, btw has your problem been solved ?
[2016-03-29 15:20:27] <chahn1138> Well, that is weird then....need to clarify what it means when it says "not found"As to my problem, it looks like I will need to get IT support for expanding my access.  Not to worry, as I ought to be able to make a business case.
[2016-03-29 15:20:43] <chahn1138> Good luck!
[2016-03-29 16:01:40] <marnikvde> hi, silly question maybe, but when i use "docker run ...", i get an "exec format error", how can I debug that to see what command goes wrong in the dockerfile?
[2016-03-29 16:02:38] <fruitl00p> marnikvde: you might want to specify the cmd to run inside the container... (i.e. docker run ubuntu/14.04 bash) Is the image public your testing?
[2016-03-29 16:03:11] <fruitl00p> marnikvde: sorry typ0: ubuntu:14.04 ;)
[2016-03-29 16:03:33] <marnikvde> yes, but I think I know what noobie mistake I made. I\'m trying to do "docker run resin/rpi-raspbian", which is an arm based architecture, so it\'s probably failing on my x86 cpu
[2016-03-29 16:04:02] <fruitl00p> that could also be a problem indeed ;)
[2016-03-29 16:04:23] <marnikvde> which leaves me a little puzzled on how I can test any of what I'm trying to do on anything else than the actual raspberry pi board. Can I simulate in some way?
[2016-03-29 16:04:51] <fruitl00p> you could look for virtualbox type simulations... ?
[2016-03-29 16:05:07] <marnikvde> ah, the internet to the rescue, "QEMU" could do the trick
[2016-03-29 16:05:27] <fruitl00p> marnikvde: yup, should work like a charm!
[2016-03-29 16:13:13] <theshadowx> @marnikvde here is what you can dofirst you should install qemu-arm-static  package [<-CODE->] so you can start docker ARM image in x86 machine
[2016-03-29 22:40:15] <hlfshell> So am I wrong to say that putting environment variables inside a dockerfile isn't going to work? IEADD $SSH_KEY ~/.ssh/id_rsawon't add the env variable into the dockerfile
[2016-03-29 22:43:56] <theshadowx> from what I read it would be stored in the history of the image but I'm not sure
[2016-03-29 22:44:33] <hlfshell> Every test ive tried has failed, but im also working in docker toolbox on windows so it's unclear where its a docker limitation and a janky environment issue.
[2016-03-30 00:59:20] <hlfshell> OK you're expected to use ARG instead as of 1.09, but it claims not to use this for git credentials or secrets.
[2016-03-30 00:59:24] <hlfshell> SO - why is that?
[2016-03-30 01:55:46] <hlfshell> Not that it matters apparently, since RUN and CMD are not supported with variable replacement. Oh boy. Hmm
[2016-03-30 02:47:18] <unipheas> Quick question. I’m trying to do docker commit to make an new image of my nginx server. However, I want to include the volumes I bound to the container. if I do a docker commit with that be included and if not how can I include them without having to docker cp everything?
[2016-03-30 02:47:46] <unipheas> *will that be included
[2016-03-30 02:59:06] <Spittal> You basically need to docker CP everything unfortunately
[2016-03-30 03:07:41] <unipheas> Can’t use a Dockerfile or anything…ugh
[2016-03-30 03:17:48] <unipheas> maybe make a container for the storage…idk…thank kinda sucks
[2016-03-30 08:10:10] <coelhoricardo> Hi, running my app page on Wamp take 500ms. but with docker-machine (nginx,php 5.6, mysql 5.7), it takes 6s (!!!!). where can i find some help to boost it ?
[2016-03-30 11:17:57] <xdmiodz> Hi! How can I say docker/compose to not start containers after reboot, but in the same time I need to restart the containers on failures in normal operations.
[2016-03-30 11:19:37] <xdmiodz> It's kinda controversial, so I try to describe my setup.  I have several docker-compose.yml files and a script, which starts one of them depending on environment variables. The variables are set at boot time and may differ between reboots. In the compose files all the containers haverestart: on-failure. So here the issue I'm trying to solve. At the first boot let say compose1.yml is started. The computer goes to reboot, starts with another set of variables, and the starting scripts decides to start compose2.yml. But here comes docker and starts compose1.yml too, and it's the issue.
[2016-03-30 11:26:11] <xdmiodz> Maybe its possible to clean all containers on docker start? It would solve my issue I think
[2016-03-30 11:28:31] <bjorneven> hi guys, what is the syntax for DNS in config.json on Docker Toolbox ? I'm trying to set --dns to the docker engine
[2016-03-30 11:28:54] <bjorneven> "EngineOptions": {\n            "ArbitraryFlags": [],\n            "Dns": null,
[2016-03-30 11:29:14] <bjorneven> I tried replacing null with my DNS, but then quickstart terminal crashed
[2016-03-30 11:29:53] <bjorneven> eh okey perhaps this is the wrong chat , i see the topic now
[2016-03-30 11:30:00] <bjorneven> sry for the spam
[2016-03-30 11:32:59] <xdmiodz> oops, wrong chat)
[2016-03-30 13:00:23] <aios> Hi all
[2016-03-30 13:00:37] <aios> how i can push all my images to my own registry
[2016-03-30 13:00:51] <aios> cant understand how its working
[2016-03-30 13:02:05] <fruitl00p> aios: doesnt this help you? [<-LINK->] Just use the full url for your private registry?
[2016-03-30 13:03:43] <fruitl00p> docker pull ubuntu; // pull from the public hubdocker tag ubuntu myregistrydomain.com:5000/ubuntu; // tag on the registry runing at  myregistrydomain.com:5000docker push myregistrydomain.com:5000/ubuntu; // push to the registry runing at  myregistrydomain.com:5000docker pull myregistrydomain.com:5000/ubuntu; // pull from the registry runing at  myregistrydomain.com:5000
[2016-03-30 13:05:09] <aios> fruitl00p: NICE))) Thanks Very match!
[2016-03-30 13:05:26] <aios> i dont use tags before...
[2016-03-30 13:05:41] <aios> that is copying images or linking?
[2016-03-30 13:28:12] <aios> how i can push all images with one command and without create one image for all exists images on commit
[2016-03-30 14:05:22] <fruitl00p> aios: tags is just a feature you dont have to use, but could ;)a tag on an image is just that: a tag. A way to refer to an image version / name / state at some point. If you leave out tags docker will default to the tag 'latest' (thus the imageubuntuis the same asubuntu:latestbut could differ fromubuntu:14.04orubuntu:15.10etc
[2016-03-30 14:06:06] <fruitl00p> aios: pushing images is a per image event. You could script it, but the docker command itself is per image... (docker push imageA; docker push imageB; etc)
[2016-03-30 14:40:29] <josdotso> When running a container non-interatively, for example in Kubernetes, is there a predictable tty device where I can send syslog ?
[2016-03-30 14:40:40] <josdotso> (to output on stdout/stderr)
[2016-03-30 14:41:58] <josdotso> Graph would be ... Container ( app -> syslog -> tty device ) to Host (watching tty device -> logging infrastructure)
[2016-03-30 14:43:31] <fruitl00p> Why not just log app -> stderr -> stdout and take it from there using another container? (and using the logging driver options on the host to direct those elsewhere?)
[2016-03-30 14:46:13] <josdotso> fruitl00p: Not a bad idea, but we were planning on using supervisord inside the container.. I suppose I could use supervisord to output only syslog, suppressing other services which are directed to write to syslog.  :)
[2016-03-30 14:47:30] <josdotso> Point being, supervisor is the entrypoint
[2016-03-30 14:48:23] <josdotso> I found this: [<-LINK->] 
[2016-03-30 14:56:17] <fruitl00p> josdotso: "whatever floats your boat" :)
[2016-03-30 15:00:05] <josdotso> :) [<-LINK->] 
[2016-03-30 15:01:05] <josdotso> I guess my point is that apps like to write logs outside of their stderr/stdout.. most apps support writing most everything to syslog however.  That's the motive
[2016-03-30 15:03:37] <fruitl00p> true, and there are cogs in the machine that can transport those elsewhere (logstash et al) as you said, there are alot of apps that do alot of logging and there are several stragies being applied... (stdout / (r)syslog / /dev/null etc)
[2016-03-30 15:04:47] <josdotso> agreed.  Yes logstash would work too, but my experience with it hasn't been very positive.  It's tailing of named logs for example leaves a lot to be desired
[2016-03-30 15:05:47] <fruitl00p> agreed... it just seems to be more of an accepted transport vs the mentioned solutions for piping the stdout stuff elsewhere ;)
[2016-03-30 15:08:20] <josdotso> :) no arguing with that.
[2016-03-30 21:09:54] <Spittal> Hey guys, I have a quick question around changing ownership of generated files that end up in a volume.
[2016-03-30 21:10:08] <Spittal> so I run my tests in my container all in my CI
[2016-03-30 21:10:26] <Spittal> And it reports some coverage that I want to upload to AWS.
[2016-03-30 21:10:30] <Spittal> so all in all it looks like this
[2016-03-30 21:11:12] <Spittal>  [<-CODE->] 
[2016-03-30 21:11:36] <Spittal> you can see I’m using a volume to get the coverage “out” of the container before syncing it up.
[2016-03-30 21:11:51] <Spittal> this is all well and good, but those files I pulled out of the container via the volume aren’t the correct permissions.
[2016-03-30 21:12:06] <Spittal> So my CI fails during cleanup because it can’t remove those files.
[2016-03-30 21:12:48] <Spittal> So instead of the command to the docker run beingnpm run testI’ve now made it/bin/bash -c “npm run test && chown -R 1001:1001 /var/www/apps/hennessyhammocks.com/doc”
[2016-03-30 21:12:59] <Spittal> but chown is failing saying there’s no directory.
[2016-03-30 21:13:15] <Spittal> (1001:1001 is my CI user did:gid)
[2016-03-30 21:14:06] <Spittal> any suggesstions on how to either “delete” the files from the volume folder on host, or making them the right permissions in the long run?
[2016-03-30 22:49:16] <marnikvde> does anyone know how to apt-get a program that needs dbus to run? I guess that before apt-get installing that program, i need to apt-get install dbus, which is OK. But how do I make sure that the dbus service is started? Is that even possible using docker?
[2016-03-31 08:55:13] <unipheas> hey guys.. i’m having trouble with my nginx/docker images
[2016-03-31 08:55:18] <unipheas> It’s not showing my css
[2016-03-31 08:55:58] <unipheas> actually.. it is on my localhost but not on the vultr server
[2016-03-31 09:08:53] <unipheas> Anyone use docker/nginx & vultr? I’m trying to get a site up and it works perfectly on my localhost. However, when I upload it to my server (vultr) it’s not showing the css
[2016-03-31 17:24:17] <webus> hey guys!
[2016-03-31 19:11:58] <marnikvde> I have a Dockerfile that I need to modify (slightly) when a) cross building and b) building on the actual device (i'm using an x86 machine to build for arm). The difference is a few ENV, COPY and RUN commands. Is there any way to make this conditional so that I can use the same Dockerfile on both machines, but behave in a different way?
[2016-04-01 04:02:18] <soapoperator> Hello, i'm started to use and understand docker. As first excercice, i try to install camo ( [<-LINK->] ) with docker.  Is there a tuto? I do :git clone https://github.com/atmos/camo.gitcd camodocker build -t camo .Then get an error
[2016-04-01 08:33:11] <marnikvde> Sudo?
[2016-04-01 08:33:18] <marnikvde> What error?
[2016-04-01 11:36:58] <theshadowx> marnikvde: I think you should write a script that generate Dockerfile and then execute it, as  a configure file
[2016-04-01 11:39:44] <marnikvde> Hmm, maybe I could use an ENV parameter in the dockerfile, and use indeed the RUN of script.sh where I do or do not do certain stuff based on that ENV param. Worth a try
[2016-04-01 17:06:07] <soapoperator> @marnikvde thanks for the reply. I do it as root.About the error, i get [<-CODE->] Then i check: [<-CODE->] 
[2016-04-01 17:24:48] <uptownhr> soapoperator: does directory /app exist?
[2016-04-01 17:35:50] <andrewhoff> hey guys, I'm running docker 1.10.2 on my Mac, (docker-machine), and I keep running into an issue where the VM is holding on to my physical disk space. Even after I remove all stopped containers and unused images, no space is freed. The obvious only way I've been able to free it up again is by totally nuking the VM from virtualbox. Any ideas how to get my disk space back from boot2docker's greedy hands without blowing it away?
[2016-04-01 18:01:26] <LukeHowellDev> With VirtualBox even when using dynamic storage size, I don’t believe the size will ever go down.  It will start low and go up but won’t go back down.
[2016-04-01 18:02:20] <andrewhoff> oh, that's bad...
[2016-04-01 18:07:15] <LukeHowellDev> This might help you [<-LINK->] 
[2016-04-01 18:21:41] <andrewhoff> thanks, I'll read
[2016-04-01 19:47:05] <necrose99> marnikvde [<-LINK->] it uses  bin format and qemu-arm-static   , like wise qemu-arm64-static binary will run it under amd64
[2016-04-01 20:39:57] <soapoperator> uptownhr: i clones camo in a directory but i didn't touch on the docker config... what do you mean? (sorry for my gap)
[2016-04-01 20:41:11] <uptownhr> does your Dockerfile look like this? [<-LINK->] 
[2016-04-01 20:41:44] <uptownhr> and what os are you running docker from?
[2016-04-01 20:41:52] <uptownhr> did you make any docker configuration changes?
[2016-04-01 20:41:58] <uptownhr> like change the /var/lib/docker path?
[2016-04-02 11:46:20] <soapoperator> uptownhr: to answerthe dockerfile is the same as i clone the git repo.\ni am running docker on ubuntu 14.04 with nginx (1.4.6) installed\ni didn't change any thing to docker after installation (Client version: 1.6.2), neither /var/lib/docker nor anything else.  Maybe i miss something.
[2016-04-03 19:42:36] <Bajix> What’s the recommended way to Docker + SSL Keys + AWS KMS
[2016-04-03 20:40:44] <zs-zs> Hi guys, I\'m new to Docker, is here anybody who knows why I get this error when I try to create an overlay network? [<-CODE->] On the same Vagrant VM (boot2docker) I have Consul and Swarm manager running and I tried to join this very simple "cluster" with the VM using these commands. Is it possible that in order to use Swarm I have to join the cluster from another VM?
[2016-04-05 00:20:41] <selvik> zs-zs: Yes, to use Swarm you need a master and 1 or more slaves. I\'ve seen that error message when my swarm slave takes a few seconds to report to the master and I\'ve tried to start a container too soon. If you try "docker -H tcp://0.0.0.0:3375 info", you\'ll see Swarm report how many healthy nodes it has.
[2016-04-05 12:22:53] <bad5anta> hi. i'm having a bug with memory leaks on docker v1.10.3: [<-LINK->] 
[2016-04-05 12:23:57] <bad5anta> mysqld and docker daemon processes are everywhere in top
[2016-04-05 12:24:37] <bad5anta> how can i fix this?
[2016-04-05 14:36:30] <viebig> Greetings! Anyone have a clue about "Error response from daemon: Could not find container for entity id" .... I\'m stuck at this point... other containers are working
[2016-04-05 14:48:49] <chahn1138> what action produced that error?
[2016-04-05 14:49:07] <viebig> docker build
[2016-04-05 14:49:10] <bwoodlt> How do I install Forever on a docker container?
[2016-04-05 14:50:29] <viebig> bwoodlt: ... you don't need forever. Run with -d option
[2016-04-05 14:51:57] <viebig> bwoodlt: -d --restart=unless-stopped
[2016-04-05 14:52:50] <bwoodlt> ah brilliant! Thanks@viebig
[2016-04-05 14:52:53] <viebig> If the node application exists, docker will restart the container. Way better than forever... I prefer pm2 over forever for standalone
[2016-04-05 15:04:16] <viebig> chahn1138: docker build...
[2016-04-05 15:10:38] <chahn1138> I am a new, but was hoping to see what you were referring to on your command line.
[2016-04-05 15:11:05] <chahn1138> i.e. I have had issues when referring to the proper container/image on the command line.
[2016-04-05 15:11:51] <chahn1138> what "entity" did you refer to?
[2016-04-05 15:12:20] <chahn1138> start with that, then check the ps to see what has been created....
[2016-04-05 15:12:38] <chahn1138> (fumbling toward the light....good luck!)
[2016-04-05 16:53:22] <zs-zs> selvik: Thanks for the explanation! But isn't it possible that the master and the slave are the same? :)
[2016-04-05 16:55:26] <zs-zs> BTW, does anyone know how to execute a shell script / export some environment variables under boot2docker on every login?
[2016-04-05 16:55:53] <zs-zs> I'd like to provision a boot2docker-based machine with Vagrant but I don't know how to do it
[2016-04-05 16:57:11] <zs-zs> I tried to append ~/.profile or /etc/profile.d/boot2docker.sh ...the last is more or less working but something reset this file everytime...
[2016-04-05 16:57:29] <zs-zs> it's probably a noob question, I'm not a shell scripting expert
[2016-04-05 17:18:41] <viebig> chahn1138: docker run \\--name=app-name \\-p 5101:5101 \\-d \\--restart=unless-stopped $appname"
[2016-04-05 17:22:33] <LukeHowellDev> zs-zs: I would think putting htme in ~/.profile would do it.
[2016-04-05 17:24:01] <andrei-tanasache> Hey there ! I am a developer and am exploring the world of Docker :) .. but start to hit some walls. More to the point, I would like to how can zero down time deployments be done with docker. Is there some framework on top of docker swarm that can do this ? Also .. is it possible to do auto scaling with the container ?
[2016-04-05 17:26:49] <andrei-tanasache> I am more concerned on rolling an application update, directing traffic to new versions of the app.
[2016-04-05 17:39:00] <LukeHowellDev> andrei-tanasache: Web applications.
[2016-04-05 17:39:25] <andrei-tanasache> snumb130: yes
[2016-04-05 17:41:17] <zs-zs> snumb130: Thanks, I just checked again. It seems something is reseting my ~/.profile ...but I don\'t know what...? So it works on the first "vagrant up", not after I halt the VM...
[2016-04-05 17:43:38] <LukeHowellDev> I’m not sure if the is the best way (doubt it is) but here is what I do.I use jwilder/nginx-proxy as the proxy.  This proxy allowes for you to have two containers running with same domain name.  With more than one container it does a round robin to pick the container.  So you could have different visitors with different versions momentarily.  This allows you to start the new container and then once it is up completely you can stop the other.
[2016-04-05 17:44:11] <LukeHowellDev> andrei-tanasache: 
[2016-04-05 17:45:02] <LukeHowellDev> zs-zs: What is your purpose for needing the exports?
[2016-04-05 17:48:13] <andrei-tanasache> That sounds great for small scale applications. But what about a large scale microservice based application. This would have to be automated in a way ...
[2016-04-05 17:48:14] <zs-zs> snumb130: I would like to install [<-LINK->] which is Docker version manager for the Carina hosting service. Their installation experience is a bit crap, but it's a good tool BTW. At the end of the installation you have to call shell script and export an environment variable to use the tool. (This somehow puts it on the PATH)
[2016-04-05 17:48:56] <brunoban> Does anyone get this error when installing docker on OSX for the first time? Could not load X509 key pair: crypto/tls: private key does not match public key. Make sure the key is not encrypted
[2016-04-05 17:49:11] <andrei-tanasache> snumb130: up
[2016-04-05 17:50:34] <andrestc> andrei-tanasache: you could try taking a look at Tsuru ( [<-LINK->] )
[2016-04-05 17:50:44] <zs-zs> snumb130: I see there is a $HOME/.ashrc file... wow, there is a massive diversity of profile and rc files under Linux and I don't know which is which :( if someone has a good reference which explains which folder contains what...please share it with me! :)
[2016-04-05 17:54:05] <andrei-tanasache> andrestc: thanks. Do you have any experience with it ? Do you have any feedback ? :)
[2016-04-05 17:57:57] <zs-zs> snumb130: I have /root/.profile, $HOME/profile, $HOME/.ashrc, /etc/profile, /etc/profile.d/boot2docker.sh, /etc/init.d/tc-config, and everything does something...huh... :)
[2016-04-05 18:05:18] <andrestc> andrei-tanasache: I used it for some time on my last company and now I've joined tsuru development team :)
[2016-04-05 18:06:00] <andrestc> andrei-tanasache: its a really good project, we have a chat here if you want to ask questions and talk to more experienced ppl from the team
[2016-04-05 18:22:00] <chahn1138> viebig: OK, do you see "app-name" in the output of "docker ps -a"  (i.e. is there a container with that name?)
[2016-04-05 18:22:17] <chahn1138> (sorry, I was pulled away...and will be again shortly.... ;0)
[2016-04-05 18:25:21] <andrei-tanasache> andrestc: Thanks for your input ! I will look into it :)
[2016-04-05 19:14:19] <tstirrat15> say I've got a container running nginx that serves a javascript app and then reverse-proxies to a python webserver container for requests made from that app. do you have to worry about CORS, or does the fact that you're using a reverse proxy take care of that?
[2016-04-05 22:14:33] <viebig> chahn1138: app-name is a given name to facilitate stop logs by name instead of contianer id
[2016-04-06 04:16:08] <LukeHowellDev> tstirrat15: Usingproxy_passwith an alias in nginx should allow you to ignore CORS since it is the same domain.
[2016-04-06 10:21:22] <deniskrishna> hello! can somebody help me? i have a docker compose file with two containers - elasticsearch and django. container with django, when building, depends on elasticsearch (it should be already running). but elastic doesnt seem to start before container with django starts to build. how can i set timeout or wait for elastic to start?
[2016-04-06 11:29:10] <tstirrat15> snumb130: awesome! thank you.
[2016-04-06 11:31:07] <cortwave> deniskrishna: very common issue. You can find some decisions here [<-ISSUE->] 
[2016-04-06 14:12:53] <deniskrishna> DmitryPranchuk: thanks! looks like a long term issue)
[2016-04-06 15:19:59] <a-donskoy> Hi guys, I have a docker container with keepalived, that requires extra privileges--cap-add=NET_ADMIN --net=host. When I’m doing force reboot of host machine container deleted (docker ps -ado not show it) or stopped, and you can start it. Another containers are running as usual. So it possibly related to--cap-add=NET_ADMIN --net=host. Can anyone suggest why that happen or how to debug this?
[2016-04-06 16:53:35] <mustafakosker> Hi guys, I'm looking for ui app for docker registry, so that I can pull any image from the registry and deploy it. It's going to be similar to docker cloud, but I want to able to deploy it locally and point it to any docker registry that I want. Do you know an open source app like this? I've seen this one: [<-LINK->] but you're not able to deploy your image with this tool.
[2016-04-06 18:35:32] <a-donskoy>  [<-CODE->]  [<-CODE->] 
[2016-04-06 22:03:09] <zs-zs>  [<-CODE->]  [<-CODE->] But if I want to automate then how can I decide when to re-run and when not?It's also a bit annoying if I have only one node, it cannot recreate (stop & start) the web application because of a port clash - this is what I get when I have one 1 node on the cluster: [<-CODE->] It seems compose first want to deploy the new one (to another node) and only then stop the old one... OK, so I added a new node just because of this, I don't get this error anymore, but of course this wouldn't work if I want to register my IP for DNS.Can anyone tell me am I misusing these products (swarm + compose) or are these tools not really production ready at least for this use-case (deployment to swarm)? Thanks for your help!
[2016-04-07 19:33:22] <mohamedhaleem> mustafakosker: - have you looked [<-LINK->] 
[2016-04-08 01:35:55] <deniskrishna> hi there guys! i've got a problem. in a container with ubuntu i try to start cron, simply run CMD cron -f. it works fine, but when i use this container in docker compose, and have a 'command' option, which for instance just starts web server, it seems to override CMD in dockerfile, or im mistaken. So, cron daemon not starting. Can somebody help me, where i am wrong? thanks
[2016-04-08 04:00:46] <Bajix> Any way to make this work?COPY ./lib/*/package.json ./tmp/lib/*/package.json
[2016-04-08 14:45:28] <ghost~54c81a24db8155e6700f279e> deniskrishna: that's the way that docker-compose files work, they overwrite the CMD of the dockerfile
[2016-04-08 18:29:37] <benoahriz> hi is there a chat room for the docker for mac beta?
[2016-04-08 18:47:54] <mario21ic> hello, someone have the beta docker on mac os? I have error 408 on docker pull
[2016-04-08 18:54:20] <benoahriz> trying to install it and it asks to install helper but never does
[2016-04-09 10:28:35] <satdav> Hi is their a channel for doctor for server
[2016-04-09 14:41:34] <wsantos> Bajix: have you triedCOPY ./lib/**/package.json ./tmp/lib/**/package.json?
[2016-04-11 00:29:29] <Bajix> wsantos: No I hadn’t; I actually ended up instead just using the optionalDependencies property to circumvent the issue entirely
[2016-04-11 19:00:56] <noisy> hi. Is there a way to define a different dockerfile name for dockerhub?
[2016-04-11 19:01:18] <brunoban> With the -f flag you can define whatever dockerfile name you want
[2016-04-11 19:01:36] <noisy> yeah... but I think dockerhub do not support that
[2016-04-11 19:01:50] <noisy> it only gets path
[2016-04-11 19:03:07] <brunoban> I dont think I got what your question is then… You want different builds for the same project path?
[2016-04-11 19:03:12] <noisy> so if I want to have 2 dockerfiles, I cannot do that. Even if I will place two dockerfiles in different directories,  because I cannot reach context from directory above.. I cannot build those dockerfiles
[2016-04-11 19:03:39] <noisy> I know that this can be done with pure docker
[2016-04-11 19:04:25] <noisy> I can specify a dockerfile with-fand context with.as last argument, but the question is how do that with dockerhub or docker-cloud
[2016-04-11 19:05:18] <brunoban> Yeah that will build the image. You are asking how to push it separately to your docker hub?
[2016-04-11 19:05:44] <brunoban> Sorry, english is not my first language =D I may have misunderstood you
[2016-04-11 19:06:31] <noisy> I wanted to have an automated build, but it seems I will have to do that manually
[2016-04-12 14:30:45] <revisualize> So, what is the best way to actually learn Docker?
[2016-04-12 14:41:10] <chahn1138> The PDF book is quite good.  Hands on examples is probably the best answer.
[2016-04-12 14:42:50] <jimschubert> Not the best way to learn, but this just came out and has some good additional information after you’ve spent a week or so learning the basics: [<-LINK->] 
[2016-04-12 14:43:53] <zs-zs> chahn1138: Which PDF book? I'm also interested in some good resources. I ordered this book because I it has good reviews and not so old: [<-LINK->] 
[2016-04-12 14:46:03] <chahn1138> Oh yeah, I went O\'Reilly too, but want to also recommend "The Docker Book" by James Turnbull.  Very easy to follow, tho I am still in it.
[2016-04-12 15:35:14] <revisualize> Thanks.
[2016-04-12 15:52:56] <chahn1138> Glad to help.  The real best answer is "just run it"....the tutorials around this things are utterly brilliant, incorporating github and dockerhub to spin up whole test worlds.
[2016-04-12 15:53:24] <chahn1138> (of course, cannot name on at this instant....but they are out there ;0)
[2016-04-12 15:53:55] <chahn1138> FYI: http://www.oreilly.com/webops-perf/free/files/docker-networking-and-service-delivery.pdf(looked interesting)
[2016-04-12 15:54:29] <brunoban> The best advice is to just run it, really. =D You’ll learn a lot more by fixing mistakes you make. Then go back to the literature. You’ll look at it with better eyes imo.
[2016-04-12 15:54:44] <jbirdkerr>  [<-LINK->] 
[2016-04-12 15:54:50] <jbirdkerr> these videos were invaluable
[2016-04-12 15:55:03] <jbirdkerr> I'm by no means an expert, but I feel like I have a much better handle after watching those
[2016-04-12 15:55:20] <chahn1138> Thank you both
[2016-04-12 16:50:30] <fcosrno> Anyone know of a good recent resource for a production ready Docker workflow? I say recent because a lot of Google/StackOverflow results are from mid-2015 or earlier and much maturing has happened since, ie Swarm and Compose.
[2016-04-12 16:51:19] <zs-zs> fcosrno: I would also be interested in that. I'm currently working on my own workflow...
[2016-04-12 16:54:33] <fcosrno> zs-zs: Me too! We should collaborate. My focus is on LEMP stacks. Been building on top of this: [<-LINK->] 
[2016-04-12 16:55:27] <zs-zs> I'm a Docker newbie, I make a lot of mistakes :)
[2016-04-12 16:56:09] <fcosrno> Sometimes it feels like Docker is a newbie itself, so it's hard not to be mistaken plenty, along with it. 
[2016-04-12 16:56:38] <zs-zs> my goal is to create a workflow for Node.JS development
[2016-04-12 16:57:21] <zs-zs> it should be cross-platform workflow, so I use Vagrant with boot2docker - so I can develop from Windows
[2016-04-12 16:57:53] <zs-zs> hm maybe i send you a pm
[2016-04-12 17:06:29] <chahn1138> Go go!  :0)
[2016-04-13 21:17:18] <likered> hi guys
[2016-04-13 21:17:25] <likered> good afternoon
[2016-04-13 21:18:09] <likered> i was wondering if anyone knew an easy way to get a log file from a Docker container into the Docker's host (the instance) through AWS ECS.
[2016-04-13 21:18:59] <likered> after looking at the docker volumes, it seems to be one-way. from source (host) to destination (docker container)
[2016-04-14 07:06:25] <RaunoVV> Hey
[2016-04-14 07:06:47] <RaunoVV> what's the permanent workaround/fix for [<-ISSUE->] ?
[2016-04-14 08:01:35] <gponsu> Hello, good morning, I had a doubt, how I can deploy docker containers to production? With docker-machine?
[2016-04-14 08:41:54] <RaunoVV> gponsu: docker export/import
[2016-04-14 09:51:23] <gponsu> RaunoVV: mmm interesting... thank you very much!
[2016-04-14 12:29:21] <chahn1138> Interesting bug there R.  ...are they moving away from AUFS?  (it sounds like it was rejected by yhe wider community)
[2016-04-14 12:40:11] <RaunoVV> not sure, but having similar issues (using rm in build process)
[2016-04-14 12:40:28] <RaunoVV> althou i'm using overlay xfs
[2016-04-14 15:14:47] <fandyy> How can i use chmod command in docker container? I want to start ssh service, but it said the private key too open!
[2016-04-14 15:20:43] <chahn1138> exec a shell there. (google "docker exec bash")
[2016-04-14 15:24:34] <fandyy> chahn1138: thanks
[2016-04-14 16:57:10] <minid33> Can I make the total storage used by docker for mac larger? I've made maybe 10 images  and 10 containers and i've consistently run out of space even though my disk has 190GB free
[2016-04-15 18:51:14] <timcharper> geez, how big are your container?
[2016-04-15 18:51:22] <timcharper> s/container/containers
[2016-04-15 19:07:28] <duck1123> minid33: Looks like there's an option for create. I assume that if you have an already created machine you could just look into resizing a VirtualBox image. [<-ISSUE->] 
[2016-04-15 19:20:05] <tecnobrat> minid33: I suggest youdestroyyour docker machine and dodocker-machine create --driver virtualbox --virtualbox-disk-size "150000" default
[2016-04-15 19:20:20] <tecnobrat> That'll create a dynamically expanding drive, up to 150GB
[2016-04-15 19:20:25] <timcharper> tecnobrat: the default is 200GB.
[2016-04-15 19:20:34] <tecnobrat> it didn't used to be.
[2016-04-15 19:20:45] <tecnobrat> It used to be like 8GB or something.
[2016-04-15 19:20:52] <timcharper> okay. Oh that's horrible.
[2016-04-15 19:21:14] <duck1123> that doesn't take very long to fill up
[2016-04-15 19:21:23] <tecnobrat> So I could be wrong with newer versions ofdocker-machine, but if you have a machine from an old version, yea, recreate it.
[2016-04-15 19:21:24] <timcharper> There may be a way to get Virtualbox to resize the drive, as well, so you don't have to toss everything on it
[2016-04-15 19:21:30] <tecnobrat> I'll test what the current one is....
[2016-04-15 19:23:10] <tecnobrat> Default is 20GB
[2016-04-15 19:24:12] <timcharper> I got a 200GB drive by default on Mac OS X, maybe I did something special. Or... what if I'm special?
[2016-04-15 19:24:22] <timcharper> timcharper: considers the possibility with an elated feeling of self-importance
[2016-04-15 19:24:37] <tecnobrat> Unsure, I just created a new machine, and it came up at 20GB
[2016-04-15 19:25:18] <tecnobrat> Oh, I've got 1.10 on this machine
[2016-04-15 19:28:08] <tecnobrat> still 20GB on 1.11 ...
[2016-04-15 19:28:10] <tecnobrat> tecnobrat: shrugs
[2016-04-15 19:29:51] <tecnobrat>  [<-LINK->] 
[2016-04-15 19:29:54] <tecnobrat> Definitely 20GB :)
[2016-04-15 21:01:43] <faultable> Hi, is it exist a Linux app for docker in GUI? Thanks :D
[2016-04-15 21:02:21] <chahn1138> A Docker GUI....not that I know of....
[2016-04-15 21:06:00] <faultable> yeah maybe it's like kitematic or panamax for linux hehe
[2016-04-15 21:42:33] <samlavery> hi!
[2016-04-16 07:06:36] <faultable> hi
[2016-04-16 13:39:13] <rinetd> hhi
[2016-04-16 15:42:40] <faultable> gue ganteng, thanks.
[2016-04-17 16:53:38] <karlfloersch> Hey all, what are your favorite docker dev environment workflows? [<-CODE->] 
[2016-04-17 17:17:02] <karlfloersch> I'm especially interested in running tests. It seems to me that rebuillding docker images is too slow for running unit tests, so you'd need some kind of lightweight solution, either usingbashordocker exec
[2016-04-17 17:24:07] <karlfloersch> rebuillding docker images is too slowIt seems I may be wrong here. I guess it may be worth the weight because it provides guaranteed clean environments.
[2016-04-18 07:56:40] <zs-zs> hi@karlfloersch, I'm trying to build my own workflow, since i don't know about any widely used one...probably@fcosrnois also interested in this topic.
[2016-04-18 11:14:11] <semenovDL> Hi guys! I use docker on mac through docker-machine. How i can setup it to make docker containers available by ip from my host machine?
[2016-04-18 11:16:24] <aios> You should use expose and edit hosts for 192.168.99.100
[2016-04-18 11:56:13] <semenovDL> aios: it is not what I am looking for. I write ansible playbooks for updating of our clusters. And I try to find way to run it on mac using same hosts file like:[mains]main-01main-02[drivers]drv-01drv-01...
[2016-04-18 13:17:13] <BlessYAHU> Anyone get Docker to work with Windows 10?
[2016-04-18 13:50:00] <lcnascimento> [
[2016-04-18 15:09:18] <bernex> Hi! I'm using docker-compose, I wanna start mysql with volume(hello for example). And I wanna drop all changes after stopping.... Now I make changes stop & start - changes here. How to do it?
[2016-04-18 15:09:59] <bernex>  [<-CODE->] 
[2016-04-18 16:03:14] <sebhoss> bernex: trydocker-compose downfollowed up bydocker volume ls -qf dangling=true | xargs -r docker volume rm
[2016-04-18 16:03:31] <sebhoss> sorry my client was lagging..
[2016-04-18 16:04:15] <duck1123> Now there's a command I'm going to have to alias
[2016-04-18 16:04:22] <sebhoss> haha
[2016-04-18 16:04:44] <sebhoss> i'm using it on our build server as the last part of the build
[2016-04-18 16:52:59] <bernex> sebhoss: docker volume ls -qf dangling=trueis nothing...
[2016-04-18 16:53:26] <bernex> hellois volume, created and prepeared before(docker volume create hello)
[2016-04-18 18:07:10] <Andre-Gomes> Hi guys, I'm trying to configuring http proxy inside a docker container. The proxy e configured at host. Can I share this configuration with the containers!?
[2016-04-18 18:07:25] <Andre-Gomes> *The proxy is
[2016-04-18 18:08:08] <Andre-Gomes> I've tried that: [<-LINK->] 
[2016-04-18 18:08:25] <Andre-Gomes> But I'm not using systemd to start docker service
[2016-04-18 18:08:53] <Andre-Gomes> So, it doesn't work
[2016-04-18 18:20:50] <Andre-Gomes> Someone could help me with this?
[2016-04-18 22:31:30] <hungerregnuh> Hey All, trying to run my own registry, followed the instructions here: [<-LINK->] , then i created my own image, tagged then pushed it to localhost:5000/myImage, but when i do adocker search localhost:5000i just get empty results, any what i may be doing wrong?
[2016-04-18 22:43:18] <hungerregnuh> oops, ignore my question i know what's going on
[2016-04-19 03:45:54] <bernex> Hi, I can't do
[2016-04-19 03:47:01] <duck1123> do what?
[2016-04-19 03:47:09] <bernex> I have created container via busybox for mysql data - everything ok. But I run via compose - it's empty
[2016-04-19 03:47:33] <bernex> I wanna make permanent data for mysql to run tests
[2016-04-19 03:48:10] <bernex>  [<-CODE->] 
[2016-04-19 03:49:21] <bernex> Mysql_datastore: [<-CODE->] 
[2016-04-19 03:50:52] <bernex> Build:docker built -t mysql_datastore .anddocker run --name mysql_datastore mysql_datastore trueand filldocker run -it --volumes-from mysql_datastore -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123 -e MYSQL_DATABASE=test -t mysql
[2016-04-19 03:50:57] <duck1123> I'm not too familiar with type 1 syntax, but in type 2, I'd do: [<-CODE->] 
[2016-04-19 03:51:48] <bernex> duck1123: ERROR: Named volume "db_data:/var/lib/mysql:rw" is used in service "db" but no declaration was found in the volumes section.
[2016-04-19 03:52:43] <bernex> anddocker commit mysql_datastore data2
[2016-04-19 03:52:49] <bernex> But not work
[2016-04-19 03:53:01] <duck1123> ahh, then at the end of the file add: [<-CODE->] 
[2016-04-19 03:53:33] <duck1123>  [<-LINK->] 
[2016-04-19 03:54:52] <duck1123> if the first part is a relative path, you can mount it somewhere without needing to create a named volume.
[2016-04-19 03:55:14] <duck1123>  [<-CODE->] 
[2016-04-19 03:55:18] <bernex> I don't understand how make it non-rersistent
[2016-04-19 03:55:42] <bernex> Reset after stop
[2016-04-19 03:56:08] <duck1123> if you don't want it to persist, don't put it in a volume
[2016-04-19 03:56:09] <bernex> Now two things: or always empty or persis
[2016-04-19 03:56:30] <duck1123> volumes are for the data you want to save
[2016-04-19 03:57:17] <bernex> If  I want restore db each time, I must restore it from dump?
[2016-04-19 03:57:29] <bernex> it is slow (
[2016-04-19 03:58:32] <duck1123> if you want the db data to be persisted, you have to map the place that mysql is toring your data to a volume and then tell your containers to all use that same volume
[2016-04-19 03:59:04] <duck1123> if you want a fresh db, then don't put it in a volume and build it up however you normally would
[2016-04-19 03:59:28] <duck1123> for a DB, you probably want it in a volume
[2016-04-19 04:06:04] <bernex> duck1123: thanks I will try
[2016-04-19 07:38:07] <bernex> docker run -it --volumes-from data2 -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123 -e MYSQL_DATABASE=test -t mysqlstarts with data - very good
[2016-04-19 07:42:11] <bernex> I'm trying repeat it: [<-CODE->] Db is empty!
[2016-04-19 09:50:07] <abudargo> Anybody k
[2016-04-19 09:50:54] <abudargo> Anybody know how to set, and view open file by container??
[2016-04-19 09:52:48] <pozgo> abudargo: Hi, can you elaborate a bit more on this?
[2016-04-19 12:26:31] <abudargo> pozgo: hm i mean to view files on docker host that being opened by the container. Is it Like lsof -c docker? Currently i stress test my web service run as container but the performance looks poor, is it because the limited resource the could be used by container?
[2016-04-19 12:48:18] <elewis787> abudargo: I might not be following. But you could attach to the container and do a lsof to see the open files. If you are running into resource limits you can start the container in privileged mode as well. If you trying to view a log file or trace file of the application I would expose the file to the host so you can debug outside of the container.
[2016-04-19 17:03:59] <Furdarius> Hi all, can somebody say, how to attach domain to docker container in dev-environment?(Now all my containers available separately via localhost, but i need more than one application available in one time)
[2016-04-20 06:06:00] <vigneshhere> Hi
[2016-04-20 06:06:20] <vigneshhere> how to run call back jar on docker container?
[2016-04-20 06:07:03] <timcharper> ??
[2016-04-20 06:07:39] <vigneshhere> my requirement is generate response dynamically
[2016-04-20 06:08:11] <timcharper> ?? ??
[2016-04-20 06:08:20] <vigneshhere> in java I used
[2016-04-20 06:08:22] <vigneshhere> java -Dfile.encoding=UTF-8 -cp mockserver-netty-3.10.4-jar-with-dependencies.jar:my-callback-dependency.jar org.mockserver.cli.Main -serverPort 1080
[2016-04-20 06:08:41] <vigneshhere> is it possible to do in docker container?
[2016-04-20 06:09:10] <timcharper> I don't see any reason why you couldn't
[2016-04-20 06:09:13] <timcharper> Docker is just a way to run java
[2016-04-20 06:10:45] <timcharper> (in this case)
[2016-04-20 06:11:38] <vigneshhere> i don't know how to do it in docker
[2016-04-20 06:11:44] <vigneshhere> is there any example
[2016-04-20 06:12:26] <timcharper> I would recommend that you go through the docker tutorial
[2016-04-20 06:12:39] <vigneshhere> ohh okk
[2016-04-20 06:12:47] <vigneshhere> thanks for spend your time
[2016-04-20 06:12:54] <vigneshhere> will check
[2016-04-20 06:13:14] <timcharper>  [<-LINK->] or [<-LINK->] 
[2016-04-20 06:13:48] <timcharper> good luck!
[2016-04-20 06:14:30] <vigneshhere> my question is how to start mock server with my-callback-dependency.jar  on docker container
[2016-04-20 06:15:14] <timcharper> it is possible. You should invest some time and learn docker.
[2016-04-20 06:15:37] <vigneshhere> okk good
[2016-04-20 07:31:37] <kakawait> Hi is there a right place to speak about some issues on Docker for Mac beta?
[2016-04-20 07:33:00] <kakawait> (about volume mounting even on common namespace/tmpor/Users)
[2016-04-20 09:42:23] <kozie> hi all :)
[2016-04-20 09:46:26] <kozie> I am looking for a summarized explanation about docker containers, like what it is. For me, it looks like it\'s some kind of package (like a zip) container a file structure that "merges" with the host it\'s running on
[2016-04-20 09:47:15] <RaunoVV>  [<-LINK->] 
[2016-04-20 09:48:33] <kozie> i think that wraps it all up. So it seems it;s all (or mostly) files
[2016-04-20 09:48:38] <kozie> thanks@RaunoVV
[2016-04-20 10:00:42] <svenno> Hi, anybody out there having advise with which Kernel version docker starts to work? Is it supposed to work on 2.6 Kernels at all?
[2016-04-20 10:01:45] <kakawait> https://docs.docker.com/engine/installation/binaries/A 3.10 Linux kernel is the minimum requirement for Docker. Kernels older than 3.10 lack some of the features required to run Docker containers.
[2016-04-20 10:04:38] <selavam> Hi all,is it able to run centos6 docker image on centos 7 docker?
[2016-04-20 10:06:37] <kakawait> Do you mean container based oncentos6(like [<-LINK->] centos6) can be run on docker hosted oncentos7?  If what you mean yes! You can run whatever, evenubuntubased container on yourcentos7
[2016-04-20 10:07:50] <selavam> ok@kakawaitthanks much buddy
[2016-04-20 10:08:14] <satdav> I am wondering if you can assist is their a channel for Discourse on here
[2016-04-20 10:08:29] <satdav> or is this the best channel to ask questions regarding it
[2016-04-20 10:32:33] <bsideup> Hi! [<-CODE->] Is it known issue?
[2016-04-20 23:24:35] <vladaionescu> Does anyone else experience problems with network connections when usingdocker network connect?  Active connections are mysteriously being closed when issuing the command. Wireshark shows a TCP FIN sent by the docker network bridge to both sides of the connection for some reason (without any side initiating the close).
[2016-04-20 23:46:47] <rfielding> When usingdocker-compose scale zk=3to launch 3 images called zk (basic zookeeper setups), I can't figure out a way for the running container to be aware of what name it was assigned, likezk_1orzk_2.  I need to extract this_2number from the end to plug it into a config file inside the container.  I see neither environment variables for it (triedsetfrom bash), and see no way to get the equivdocker inspectfrom inside the container itself.  Is there some way to get the docker-compose assigned name from inside the host?
[2016-04-21 02:45:41] <wanghaisheng> anyone encounter host volume mounting issues when use latest docker-machine and docker-engine ,boot2docker
[2016-04-21 02:46:33] <wanghaisheng>  [<-ISSUE->] 
[2016-04-21 06:02:42] <svenno> I'm courious about docker support on ARM 7 achitectures. Anyone have experience with it? For embedded or mobile devices docker could be really interesting!
[2016-04-21 06:18:37] <marnikvde> It works on arm. Check resin.io btw
[2016-04-21 07:15:04] <otbe> rfielding: do you need this name for ip/hostname things?
[2016-04-21 07:16:50] <svenno> Thanks a lot@kakawaitand@marnikvde!
[2016-04-21 08:53:49] <Furdarius> Hi all, could somebody say, should cron be executed inside docker-container or it's better to start cron jobs from host?
[2016-04-21 13:30:02] <rfielding> @otbe I got a hideous workaround.  i abandoned docker-compose for raw docker commands.  when you scale a container, there were no environment variables passed in that would tell us which scaled instance were were (i.e.: no ZK_NAME=zk_3 or something like that).  After that, when setting up p2p clusters like zookeeper, the links implicitly assume that there are no cycles.this limitation comes from injecting into /etc/hosts rather than registering ip addresses with an internal dns.  so i launch all machines in one pass so i can get their network info, then run docker exec to give them all complete /etc/hosts files and other configuration, then another pass to start them all.docker1.10 fixes a lot of these issues (stuck on 1.9) in the raw commands, but i don't know if they are sufficient to keep using docker-compose.  without passes, there are other issues that need to be solved.  in our setup, nothing can really start until they have certificates (with the actual hostname).  we need to glue together a bunch of scaled instances to make a zookeeper url like:   zk_1:2181,zk_2:2181,zk_3:2181  (i.e.: generated by knowing how many zks we scaled).  docker doesn't like multiple pass launching, but you need this in realistic setups.
[2016-04-21 15:06:21] <semenovDL> Hi, guys! I need help with native docker on mac os x.I'm now on 1.11.0-beta8 trying to run simple Ruby on Rails app in container, but cant connect to it by ip:port. What IP should I use? Try 0.0.0.0:3000, localhost:3000, 192.168.64.1:3000... [<-CODE->] my Dockerfile [<-CODE->] docker ps [<-CODE->] path of ifconfig -a: [<-CODE->] docker network inspect bridge: [<-CODE->] 
[2016-04-21 15:27:00] <semenovDL> right network inspec bridge [<-CODE->] 
[2016-04-21 15:34:45] <semenovDL> so stupidd run -p "3000:3000" --name some-rails-app -d my-rails-app
[2016-04-21 18:27:56] <seanauriti> I'm running docker on windows with a node container, I have a mounted directory with the code, it works fine when the volume is not mounted, however when I mount the volume and run it, it doesn't find the modules.  Any ideas?
[2016-04-21 18:31:55] <seanauriti> I'm also copying the mount point before RUN happens, my guess is that the run command is running before all of the node update and build commands run and doesn't install the modules, and mounts the clean directory afterwards and everything done during the build is gone...
[2016-04-21 18:32:31] <seanauriti> is there a way to ensure the volume gets mounted before RUN?
[2016-04-21 20:08:11] <seanauriti> I've confirmed that this is what is happening.  npm install installs the modules int node_modules then the volume gets mounted and clobbers the modules and everything created through the install...   Additionally the method in the comment on this page fixed it!
[2016-04-21 20:08:11] <seanauriti>  [<-LINK->] 
[2016-04-22 06:31:36] <uptownhr> that is true
[2016-04-22 11:32:47] <cortwave> Does somebody worked with ipv6 with docker? I ran docker daemon next way: [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2016-04-22 17:17:58] <smith64fx> Hello there
[2016-04-22 17:18:19] <smith64fx> Does anybody know how to tell docker to mount the local directory with another user inside the host?
[2016-04-22 17:18:23] <smith64fx> e.G
[2016-04-22 17:18:30] <smith64fx> local_folder belongs to smith:staff
[2016-04-22 17:18:48] <smith64fx> inside_docker: local_folder belongs to postgres:postgres
[2016-04-22 17:23:54] <hungerregnuh> i\'m still new to docker myself, so ymmv, but [<-LINK->] scroll down to "Mount a host directory as a data volume" i think i what you\'re looking for
[2016-04-22 17:37:27] <smith64fx>  [<-ISSUE->] 
[2016-04-22 17:37:33] <smith64fx> hungerregnuh: thx
[2016-04-23 03:50:31] <fernandofleury> Hey, can anyone help me with a docker image?
[2016-04-23 03:50:46] <fernandofleury> I have a large folder (3gb) which I want to use inside of it
[2016-04-23 03:50:59] <fernandofleury> But, it takes to long to move to docker context
[2016-04-23 03:51:09] <fernandofleury> Is there any way to just copy the folder?
[2016-04-23 03:51:22] <fernandofleury> I if put it on.dockerignoreI can no longer copy it
[2016-04-23 03:53:39] <LukeHowellDev> Do you mean copy usingdocker cp
[2016-04-23 03:54:23] <fernandofleury> well, i mean something like
[2016-04-23 03:54:43] <fernandofleury>  [<-CODE->] 
[2016-04-23 03:54:46] <fernandofleury> or setting as a volume
[2016-04-23 03:55:59] <LukeHowellDev> Without it in the context there is no way to add it using theCOPYcommand.  Volumes would help because only would be added on run so it would not take the build context so long.
[2016-04-23 03:56:24] <fernandofleury> I'm runningdocker buildatm
[2016-04-23 03:56:31] <fernandofleury> and it is passing the context
[2016-04-23 03:56:38] <fernandofleury> taking a bit long now
[2016-04-23 03:57:18] <fernandofleury>  [<-CODE->] 
[2016-04-23 03:57:23] <LukeHowellDev> Does the folder change often or it is normally static?
[2016-04-23 03:57:23] <fernandofleury> this is just a sample I'm running
[2016-04-23 03:57:31] <fernandofleury> well, the big folder is static
[2016-04-23 03:57:36] <fernandofleury> It will eventually build the server on it
[2016-04-23 03:57:42] <fernandofleury> But I wont be changing files on it
[2016-04-23 03:58:03] <fernandofleury> But i need to map a folder to a folder inside of it
[2016-04-23 03:58:09] <fernandofleury> for example
[2016-04-23 03:58:18] <LukeHowellDev> I was about to say that ordering it differently might help, but the build context will still take a while each time.
[2016-04-23 03:58:19] <fernandofleury> the static (3gb) folder is something like
[2016-04-23 03:58:43] <fernandofleury> big folder > folder > folder (this folder will be mapped)
[2016-04-23 03:59:00] <fernandofleury> so, whenever I run docker-compose run?
[2016-04-23 04:00:30] <fernandofleury> Oh, actually no
[2016-04-23 04:00:33] <fernandofleury> this is good :)
[2016-04-23 04:00:50] <LukeHowellDev> so, is the only thing you need is in the third depth folder?
[2016-04-23 04:00:50] <fernandofleury> I'm learning a bit about low level, how should I treat theCMDcommand on dockerfile?
[2016-04-23 04:01:03] <fernandofleury> I think i've managed to make it work :)
[2016-04-23 04:01:10] <fernandofleury> not everytime ):
[2016-04-23 04:01:14] <fernandofleury> The "third" level folder
[2016-04-23 04:01:30] <fernandofleury> is where the other team will kinda clone the repo to it
[2016-04-23 04:01:34] <fernandofleury> but wont use docker
[2016-04-23 04:01:42] <fernandofleury> So the repo just have the folders inside of it
[2016-04-23 04:01:49] <fernandofleury> I mapped the volume, and I think it worked
[2016-04-23 04:02:20] <LukeHowellDev> Makes sense.
[2016-04-23 04:04:34] <fernandofleury> right now I'm trying to figure out what I should expose forCMD
[2016-04-23 04:04:53] <LukeHowellDev> expose?
[2016-04-23 04:05:18] <fernandofleury> I think it's more related to the project itself, rather than docker
[2016-04-23 04:05:38] <fernandofleury> If i cd insiderunwill the directory stay the same after it?
[2016-04-23 04:06:32] <LukeHowellDev> I do not believe so.  I believe that the context there goes back to the WORKDIR on each new RUN command.
[2016-04-23 04:07:12] <fernandofleury> ok :)
[2016-04-23 04:07:16] <fernandofleury> thank you for the tips :)
[2016-04-23 04:08:05] <LukeHowellDev> I did verify a couple of things
[2016-04-23 04:08:57] <LukeHowellDev> The directory resets on new RUN commands.  So [<-CODE->]  [<-CODE->] 
[2016-04-23 04:09:22] <fernandofleury> sweet :)
[2016-04-23 04:10:23] <LukeHowellDev> Also, is this the idea of the directory structure you were talking about earlier?   You don’t need the large files, but you do need the needed files? [<-CODE->] 
[2016-04-23 04:14:08] <fernandofleury> well, i will use a bunch of files inside of it
[2016-04-23 04:14:13] <fernandofleury> there are a couple ofinstall.shrunning
[2016-04-23 04:14:42] <LukeHowellDev> I guess my question is do you need the large files or just files from deeper directories?
[2016-04-23 04:14:43] <fernandofleury> I'm trying to migrate a java hybris project to docker, so I don't have to install it on my machine
[2016-04-23 04:14:49] <fernandofleury> both
[2016-04-23 04:15:01] <fernandofleury> because deeper directories files, will use a few of the large ones
[2016-04-23 04:15:56] <LukeHowellDev> gotcha.  I was going to suggest the following, but that won’t work if you needed the larger files. [<-CODE->]  [<-CODE->] 
[2016-04-23 04:16:48] <LukeHowellDev> Voluming them is probably the way to go for you as long as you don’t need he during build time.
[2016-04-23 04:17:28] <fernandofleury> yeah, i had some trouble with it
[2016-04-23 04:17:41] <fernandofleury> i will go mapping, there isn't much else to do as I check the docs
[2016-04-23 04:17:56] <LukeHowellDev>  Good luck with it.
[2016-04-23 04:18:12] <fernandofleury> thank you :)
[2016-04-23 04:27:40] <fernandofleury> Hey, I have one more question actually
[2016-04-23 04:27:55] <LukeHowellDev> I’ll do my best to answer.
[2016-04-23 04:28:02] <fernandofleury> the mapped volume only seems "visible" on the docker-compose run, but not on docker build
[2016-04-23 04:28:04] <fernandofleury> is it right?
[2016-04-23 04:28:17] <LukeHowellDev> yes.  the mapped volume only happens on run
[2016-04-23 04:28:39] <fernandofleury> so how can I use a mapped file on build?
[2016-04-23 04:29:21] <LukeHowellDev> You cannot.  It must be in the DockerfileADDorCOPYwhich is going to make the build context large for your situation.  Volumes are only mounted on run.
[2016-04-23 04:29:48] <fernandofleury> it is already large, actually
[2016-04-23 04:30:00] <fernandofleury> `volumes: [<-CODE->] 
[2016-04-23 04:30:01] <fernandofleury> well, the . has the large folder on it
[2016-04-23 04:30:14] <fernandofleury> it ishybris-v6
[2016-04-23 04:30:39] <fernandofleury> I was hoping to access during the build process as./hybris-v6
[2016-04-23 04:30:51] <fernandofleury> this point i'm not getting right
[2016-04-23 04:31:18] <fernandofleury> how can I copy a root folder to the root folder of the image?
[2016-04-23 04:31:28] <fernandofleury> or in this caseroot/hybris
[2016-04-23 04:31:42] <fernandofleury> justcopy ./hybris-v6 /root/hybris/?
[2016-04-23 04:31:52] <LukeHowellDev> yes.  that should work.
[2016-04-23 04:32:19] <fernandofleury> alright, trying that now
[2016-04-23 04:32:30] <fernandofleury> it takes a couple minutes to run it :P
[2016-04-23 14:20:00] <fernandofleury> Hey, how do I clean the space from old images ondocker-machine
[2016-04-23 14:20:11] <fernandofleury> I have clean tons of images, but I'm still running out of space on docker
[2016-04-23 14:20:28] <fernandofleury>  [<-CODE->] 
[2016-04-23 14:22:44] <hungerregnuh> have you tried to clean up the volume dir? by default when you whack images, docker won't remove volumes, i would assume docker-machine works the same way
[2016-04-23 14:31:45] <fernandofleury> yeah, I'm doing that right now :)
[2016-04-23 14:31:55] <fernandofleury> I just checked that after posting it
[2016-04-23 14:32:11] <fernandofleury> is there any way to create an image without associating a container to it? I'm tinkering around a bit
[2016-04-23 14:32:12] <hungerregnuh> :D fun times
[2016-04-23 14:32:32] <hungerregnuh> <=== still new myself, so i'm not sure
[2016-04-23 14:38:33] <fernandofleury> you can use--rmalong withdocker run
[2016-04-23 14:38:34] <fernandofleury> sweet
[2016-04-23 14:38:42] <fernandofleury> this will remove the container after running it
[2016-04-23 14:42:50] <fernandofleury> I have a question about directories
[2016-04-23 15:07:23] <fernandofleury> I'm getting an error from a copy operation
[2016-04-23 15:07:27] <fernandofleury> where it says I have no space
[2016-04-23 15:07:40] <fernandofleury> but running df -h, it says I have 10gb on dev still free
[2016-04-23 15:37:48] <hungerregnuh> 10gb free on which device? or is it one massive mount?
[2016-04-24 08:06:01] <marnikvde> Question: a docker container and its host share the kernel. So what if my host has a certain kernel version, and I want to run a socket image based on a newer kernel? How would that work?
[2016-04-24 08:06:46] <marnikvde> /s/socket/docker
[2016-04-24 09:19:33] <xinity> marnikvde: can you give more details?
[2016-04-24 10:39:53] <marnikvde> it\'s just about the concept, I\'m not sure I understand how you can run an ubuntu 16.04 in a container, running on an ubuntu 12.04 host for example. I would imagine that there are some kernel dependencies. I read about the fact that docker is just using the host kernel for system calls, and that "running ubuntu 16.04" is about providing files/binaries. I can imagine that some "new" binaries expect certain kernel versions, so i don\'t understand how that would work
[2016-04-24 10:43:54] <hairyhenderson> marnikvde: you’re right in concept -ifthere are kernel dependencies that the host kernel can’t fulfil, there may be an issue. But in reality this hardly ever comes up, because most apps these days run just fine with any relatively modern kernel.
[2016-04-24 10:44:14] <xinity> hairyhenderson: 
[2016-04-24 10:51:08] <marnikvde> thanks, makes sense
[2016-04-24 12:08:06] <fiunchinho> is there a better way to get the docker machine's private IP other thandocker-machine inspect consul01 | jq -r .Driver.PrivateIPAddress?
[2016-04-24 12:26:07] <LukeHowellDev> docker-machine ip consul01
[2016-04-24 12:32:05] <fiunchinho> that gives the public ip
[2016-04-24 12:32:12] <fiunchinho> I need the private IP
[2016-04-24 12:53:09] <LukeHowellDev> Hmm. Not sure. What is case for needing private ip?
[2016-04-24 12:55:19] <fiunchinho> using docker-machine on AWS, I want my nodes to connect to each other through the private IP’s, so when I pass the discovery node to create a swarm node, I want to pass the private IP
[2016-04-24 12:55:22] <fiunchinho> does it makes sense?
[2016-04-24 21:07:50] <lvegerano> Hi all Im using docker on a mac and Im experimenting with builds. Im getting an error not sure why [<-CODE->] 
[2016-04-24 23:27:25] <lvegerano> wow so it would help if I usedocker buildSMH
[2016-04-25 01:41:06] <lvegerano> What’s the best way to addinit.sqlto the postgres container. I’ve tried theRUNcommand and [<-CODE->] 
[2016-04-25 05:33:00] <david-guenault> lvegerano: use volume. acording to the entrypoint source you can use sh, sql or sql.gz files. so first create a folder and put your file in it then docker run -v $(pwd)/sql:/docker-entrypoint-initdb.d ... should do the job
[2016-04-25 08:02:14] <lykhouzov> @lvegerano yeah, as David said, you need to define a volume in your build from where sh script will take a list of sql scripts. so you just need to check if that folder is exist. you can look at such script in official mysql buildit would be something like following [<-CODE->] insilde you entrypoint script.
[2016-04-25 08:02:33] <lykhouzov> hm . there is official build of postgress [<-LINK->] 
[2016-04-25 08:02:49] <lykhouzov> and they use the same script:)
[2016-04-25 15:25:29] <amaltson> hello all, had a question about Docker Beta for Mac, is this the place to ask?
[2016-04-25 16:14:07] <amaltson> went to IRC, sorry for the trouble.
[2016-04-25 16:39:37] <RaunoVV> Has anyone else ran into issues with centos 7 and containers reported about not being able to allocate memory?
[2016-04-25 16:40:03] <RaunoVV> Somewhy almost all memory is available and cached/in buffers on host
[2016-04-25 16:40:53] <david-guenault> check on docker issues on github. I think i saw something about that but not sure.
[2016-04-25 16:49:46] <timcharper> RaunoVV: running centos here and haven't encountered that yet. 7.2
[2016-04-25 17:01:35] <RaunoVV> hum okay,@david-guenaultyep saw something also but not anything solid
[2016-04-25 20:49:22] <marnikvde> if I fiddle with modprobe inside a docker container, for example, blacklisting a certain module
[2016-04-25 20:49:27] <marnikvde> does it have any effect?
[2016-04-25 20:49:45] <marnikvde> since the host and container share the kernel, I'm not sure how kernel modules are affected
[2016-04-25 20:50:52] <jjn2009> You cannot fiddle with the kernel in a container
[2016-04-25 20:51:09] <marnikvde> you can in privileged mode if I trust google
[2016-04-25 20:51:20] <jjn2009> well then you can but it becomes system wide
[2016-04-25 20:51:42] <marnikvde> indeed
[2016-04-25 20:51:42] <jjn2009> it doesnt have its own kernel, so whatever changes you make to the kernel happen to your whole system
[2016-04-25 20:51:51] <marnikvde> that's what I thought, thanks for confirming
[2016-04-25 20:53:31] <jjn2009> np
[2016-04-25 20:53:56] <jjn2009> this is why you really shouldn't do privileged mode, you can easily root the whole machine
[2016-04-25 20:54:09] <marnikvde> yup
[2016-04-26 03:47:20] <lvegerano>  [<-CODE->] I’m getting an parsing erroryaml.scanner.ScannerError: mapping values are not allowed hereon line 5
[2016-04-26 03:47:39] <lvegerano> not sure what it could be
[2016-04-26 05:12:00] <david-guenault> lvegerano: the context must not be on line build. add a context: . line above dockerfile
[2016-04-26 05:12:32] <david-guenault> lvegerano:  [<-LINK->] 
[2016-04-26 13:06:29] <phaniram> does any one has an example of version 2 compose file having volumes container mapping localhost folder?
[2016-04-26 13:11:08] <phaniram>  [<-CODE->] I tried this, it complains that code container  "must be a mapping not a string"
[2016-04-26 13:13:29] <phaniram> build-run needs to use code in volume to do the build [<-CODE->] 
[2016-04-26 14:00:45] <lvegerano> david-guenault: thanks I misread the docs.
[2016-04-26 20:18:04] <ivoribeiro> Hi guys , love docker :) thanks
[2016-04-27 06:07:10] <testharryi3t> hey need help with getting tagImageId using Docker API v2currently it gives [<-CODE->] I am reading the api docs here https://docs.docker.com/registry/spec/api/
[2016-04-27 06:14:09] <phaniram> I have a service which starts up the interactive shell. Which I want to use it in docker-compose, but somehow it is getting exited when ever the interactive shell starts up in that services
[2016-04-27 06:34:55] <phaniram> any idea how to make sure the services that start interactive shell on their own doesn't exit during docker-compose up -d ?
[2016-04-27 06:36:48] <asuter-savvi> phaniram: command: tail -f /dev/null
[2016-04-27 06:59:15] <vigneshhere> Hi how to add classpath of my-callback-depndency.jar on docker
[2016-04-27 13:31:28] <vinayak> Can I link private docker registry to docker cloud for deployment?
[2016-04-27 15:14:41] <smith64fx> hey guys
[2016-04-27 15:14:59] <smith64fx> somebody knows how to map my local folder to another user inside a container?
[2016-04-27 15:15:31] <smith64fx> let's say i want to map my folder /test (root:root) inside the docker to /test (ftp:ftp)
[2016-04-27 15:15:42] <smith64fx> on my mac with Docker Beta it works, but linux behaves different..
[2016-04-27 15:17:50] <alaa> You can pass the uid of the user inside the container via - u option i think
[2016-04-27 15:27:13] <smith64fx> ````
[2016-04-27 15:27:18] <smith64fx>  [<-CODE->] 
[2016-04-27 15:27:25] <smith64fx> when i run this command on my mac
[2016-04-27 15:27:43] <smith64fx> Inside the container: the /test folder belongs to ftp:ftp
[2016-04-27 15:27:49] <smith64fx> when I run this command on linux
[2016-04-27 15:28:00] <smith64fx> Inside the container: the /test folder belongs to root:root
[2016-04-27 15:31:42] <hungerregnuh> no idea if this is the best way(s) to do it but, afaik, there's two ways to do it, you create a ftp user on the host (uid: 101), do the same on your container... the other way i did it was in the container, RUN mkdir /test && chown ftp:ftp /test, then mount to /test on the container
[2016-04-27 15:32:19] <hungerregnuh> i've been puttering around with this myself and the latter was the only way i could get things to work :\\
[2016-04-27 15:40:30] <smith64fx> thank you
[2016-04-27 15:40:45] <smith64fx> but the problem is that after doing this the docker container cannot run on every machine anymore
[2016-04-27 15:40:46] <smith64fx>  [<-ISSUE->] 
[2016-04-27 15:41:13] <hungerregnuh> nodnot ideal, just gets ya moving along
[2016-04-27 15:42:17] <smith64fx> I opened an issue on docker
[2016-04-27 15:42:29] <smith64fx> it's really weird because on my mac with Docker Beta I don't have any problems
[2016-04-27 15:43:18] <hungerregnuh> odd, lemme try on my server
[2016-04-27 15:43:46] <smith64fx> ok thanks bro
[2016-04-27 15:48:35] <alaa> I think you should pass the user id not the username
[2016-04-27 15:49:36] <hungerregnuh> didn't quite work for me either, i tried uid and that didn't work either...
[2016-04-27 15:50:05] <hungerregnuh> in the container, the mount had a uid:gid of 1000:1000, even though i did -u 999:999
[2016-04-27 15:51:08] <alaa> Are you sure there is user with id 999 in the container
[2016-04-27 15:52:01] <hungerregnuh> yep, checked /etc/passwd to be sure
[2016-04-27 15:58:38] <alaa> then probably the UID is different on the container for the user
[2016-04-27 15:59:08] <alaa> you could use something like this:docker run --rm -it -e USER=$USER  -e USERID=$UID -v $(pwd)/folder:/folder ubuntu
[2016-04-27 15:59:54] <hungerregnuh> i'll wait for smithi to figure it out :D gotta get back to my normal work myself
[2016-04-27 16:00:09] <alaa> same here, :D bye
[2016-04-27 16:03:01] <smith64fx> ok
[2016-04-27 16:03:06] <smith64fx> i will use my good ol' script
[2016-04-27 16:03:13] <smith64fx> i will provide it to you for testing
[2016-04-27 16:03:32] <smith64fx> Gru nach Berlin :D
[2016-04-27 17:49:16] <karimovic19> hello every one
[2016-04-27 20:28:46] <phaniram>  [<-CODE->] during this, I would like to build the project from volume/folder, and then deploy it. [<-CODE->] right now, I had to build, deploy and run all at once during upas you know it is unnecessary to have  the code built up everytime, even when it's not necessary at all
[2016-04-27 20:51:01] <jjn2009> You cannot mount volumes during a build
[2016-04-27 20:51:17] <jjn2009> you add files into your container through theADDandCOPYcommand
[2016-04-27 20:51:22] <jjn2009> which have to be in your workspace
[2016-04-27 20:52:08] <jjn2009> so if you point to the directory where your dockerfile is for a particular service that folder is the files which you have access to forADDorCOPYcommands inside of the docker file
[2016-04-27 20:53:33] <jjn2009> build: [some folder where your docker file is and files for your container]then in your dockerfileADD [my files or folders]
[2016-04-28 06:17:51] <phaniram> @jjn2009 Yah, but having the need to have required files in the same dockerfile folder is a backdropIs it possible through volume container? [<-CODE->] 
[2016-04-28 11:23:15] <thejpanganiban> Hello
[2016-04-28 11:24:38] <thejpanganiban> I have a question: We're currently using docker 1.6.2. What are the possible causes for the container to suddenly lose internet connection (it's on production).
[2016-04-28 11:26:20] <phaniram> I don't think it will happen, as long as host machine as stable connection, docker should be able to
[2016-04-28 11:56:21] <atmosx> Hello, I want to share some config data from a repository with several running containers. I don't want to store that data to the filesystem directly. Can I use--volumes-fromto load a directory (share?) from a linked container? or should I use something else to dirs between containers?!
[2016-04-28 11:58:42] <elewis787> atmosx: You can create a data volume container or a directory on the host that the config data you need. Then yes you can use --volumes-form "your_data_container" or mount the host directory to the container.
[2016-04-28 12:01:49] <elewis787> This is a great tutorial on host mounted volumes vs data volume containers ... Hope it helps. [<-LINK->] 
[2016-04-28 12:28:25] <atmosx> elewis787: that's a good idea, I can create a data container and then remove everything usingdocker rm -v <img_name>which is handy in my case.
[2016-04-28 14:48:40] <abudargo> Hello, need to ask a thing, is it able to get the image tag from latest pushed image to repository using docker regitry API??
[2016-04-28 19:56:03] <jjn2009> phaniram: I don't understand the use case for having code in a volume, it should be in the image. It sounds like your build process is not inline with the docker way. If you do the build process correctly then you will have caching and you won't be building the container each time.
[2016-04-28 19:56:37] <jjn2009> thejpanganiban: probably someone messing with iptables on the machine. That will do it. Otherwise its a problem with the host, or if your are using a network drive maybe a problem with the driver.
[2016-04-28 21:48:16] <remram44> Alright I'm writing a Dockerfile. How do I copy a bunch of files and directories to the container?
[2016-04-28 21:48:32] <remram44> bothCOPYandADDappear to just skip directories
[2016-04-28 21:48:57] <remram44>  [<-CODE->] 
[2016-04-28 21:54:59] <remram44> Surely someone at Docker is good enough to implementcp -r?
[2016-04-29 07:23:26] <lykhouzov> remram44: hi. according to manual [<-LINK->] it should copy files and dirs... also you can use wildcards
[2016-04-29 07:24:41] <lykhouzov> remram44: i think you need to use / at the end of you dir if you want to copy a directory
[2016-04-29 09:34:32] <sam543381> Hi. I'm new to docker (and gitter too), I have some questions about this soft. How much docker use ram and cpu for itself ? (sorry for my french-based english :D)
[2016-04-29 09:37:47] <sam543381> Oh, sorry I had to read the title. #docker on freenode will be more helpful. Have a nice day.
[2016-04-29 10:27:34] <unipheas> Hey! So I’m trying to deploy a server. I built a WP site on my localhost and it works perfectly. I did a “-v” for a local directory. However, I wanted to build an img so I can download it onto the host server. So i created a new clean img and linked it to the old DB and then did a “docker cp” and put all the files into the container. I then did a “docker commit”, “docker push” & “pull”… I found on the host server that the files aren’t actually there…. However, the new img on my local host has the files and it’s not linked with “-v”… I’m a bit confused. Could someone help me out?
[2016-04-29 12:24:34] <unipheas> 1595 people and no one is on?
[2016-04-29 12:48:49] <theshadowx> 1595 people and no one is on?that's the situation on IRC/chat, and even you can see the people that have seen your problem ;) just by hovering on the ''accepted'' iconanyway, Have you tryed to do a dockerfile and then in it take the original image and add COPY the build the images [<-CODE->] 
[2016-04-29 12:53:11] <david-guenault> unipheas: no sure to understand. if there was a volume on the commited container, data from volume will not be commited at all (same as using volume in a dockerfile)
[2016-04-29 12:54:04] <remram44> lykhouzov: The problem is that this doesn't copy dirs
[2016-04-29 12:54:19] <remram44> I have to do them separately:
[2016-04-29 12:54:27] <remram44>  [<-CODE->] 
[2016-04-29 12:54:29] <unipheas> david-guenault: I copied the files into the container.. there was no mounted volumes
[2016-04-29 12:54:48] <remram44> wow the gitter mobile is terrible
[2016-04-29 12:54:55] <david-guenault> unipheas: but you said " I did a “-v” for a local directory."
[2016-04-29 12:55:34] <unipheas> and then i wanted to build an image so I can move everything to the host. I then created a new container and “docker cp” everything into the container. After that I did a “docker commit”
[2016-04-29 12:55:52] <unipheas> I then do docker push to my repo… and on the host server docker pull
[2016-04-29 12:56:01] <remram44> COPY file1 file2 /dest/,COPY dir1 /dest/dir1,COPY dir2 /dest/dir2
[2016-04-29 12:56:12] <unipheas> then I do a docker run and name the containers and link them and everything and it’s completely empty
[2016-04-29 12:56:12] <remram44> basically, bs
[2016-04-29 12:57:22] <david-guenault> unipheas: ooook ;-) may be you are pulling the bad tag or something like that ? what i don't understand is why did you do that manualy, why not create a dockerfile and build the image ?
[2016-04-29 12:58:43] <unipheas> no tags so it’s all “latest”I haven’t learned about dockerfiles yet.. i kinda like typing in everything because that’s how I remembered it…. i know… i will learn it.. nonetheless.. I did a commit and the img is there but when I pull and run it it’s empty??
[2016-04-29 12:59:26] <theshadowx> weird
[2016-04-29 13:00:04] <david-guenault> unipheas: what is reported on the created column when you do a docker images
[2016-04-29 13:00:09] <theshadowx> are you sure you selected the corrected container
[2016-04-29 13:00:31] <david-guenault> unipheas: does it match with the time you commited ?
[2016-04-29 13:05:38] <unipheas> Here are my steps.docker run —name xirangdb -e MYSQL_ROOT_PASSWORD=[password] -P -d mysql\ndocker run —name xirangwp —link xirangdb:mysql -p 80:80 -P -v "$PWD/":/var/www/html -d wordpress\nsite works so i then do this\ndocker stop xirangwp\ndocker run —name xirangwp2 —link xirangdb:mysql -p 80:80 -P -d wordpress\ndocker cp /html xirangwp2:/var/www\nchecked and everything worked\ndocker commit [xirangwp2 ID number] liulanghan/xirang\ndocker commit [xirangdb ID number] liulanghan/xirangdb\non host server now\ndocker pull liulanghan/xirangdb\ndocker pull liulanghan/xirang\ndocker run —name xirangdb -e MYSQL_ROOT_PASSWORD=[password] -P -d liulanghan/xirangdb\ndocker run —name xirangwp —link xirangdb:mysql -p 80:80 -P -v “$PWD/“:/var/www/html -d liulanghan/xirang\ngo to the site and it wants to install and nothing is there\ndocker exec -it xirang bash (none of my files are there)\ndocker exec -it xirangdb bash (my entire db is empty too)
[2016-04-29 13:07:37] <unipheas> oh sorry… i do the docker push too for each img
[2016-04-29 13:07:46] <unipheas> right after commit
[2016-04-29 13:08:01] <unipheas> and it pushes, no error or anything
[2016-04-29 13:08:07] <david-guenault> unipheas: ^^
[2016-04-29 13:08:42] <david-guenault> unipheas: got it
[2016-04-29 13:08:48] <unipheas> am i doing something wrong?
[2016-04-29 13:08:48] <david-guenault> unipheas: step 14
[2016-04-29 13:08:59] <unipheas> k
[2016-04-29 13:09:01] <unipheas> ….
[2016-04-29 13:09:19] <david-guenault> if you mount a local volume it will try to mount it INTO the container
[2016-04-29 13:09:30] <unipheas> !ah… no -v sorry… typing to fast and frustrated
[2016-04-29 13:09:31] <david-guenault> so it will erase all of the site
[2016-04-29 13:09:46] <unipheas> right
[2016-04-29 13:09:57] <unipheas> 14 no -v
[2016-04-29 13:10:29] <unipheas> docker run —name xirangwp —link xirangdb:mysql -p 80:80 -P -d liulanghan/xirang
[2016-04-29 13:10:56] <david-guenault> ook
[2016-04-29 13:11:16] <unipheas> and on my development machine i docker exec into the xirangwp2 container and the files are there
[2016-04-29 13:11:16] <david-guenault> could you do a docker inspect on each container on the server host  ?
[2016-04-29 13:11:49] <david-guenault> prety sure there is a volume related problem here .....
[2016-04-29 13:12:06] <unipheas> you want to see the son?
[2016-04-29 13:12:08] <unipheas> json
[2016-04-29 13:12:34] <david-guenault> yup do a pastebin and remove confidential
[2016-04-29 13:12:39] <david-guenault> data
[2016-04-29 13:15:41] <unipheas> hope i got it all
[2016-04-29 13:15:41] <unipheas>  [<-LINK->] 
[2016-04-29 13:15:43] <unipheas> that’s on the wp part
[2016-04-29 13:15:52] <unipheas> you want the db too?
[2016-04-29 13:16:03] <david-guenault> wait a second
[2016-04-29 13:20:26] <david-guenault> this inspect is based on wordpress image not yours
[2016-04-29 13:20:41] <david-guenault> unipheas: 
[2016-04-29 13:21:00] <unipheas> … so when i did a docker commit it didn’t do my image it did the wp img?
[2016-04-29 13:21:32] <david-guenault> i'm doing some tests
[2016-04-29 13:21:40] <unipheas> I appreciate your help
[2016-04-29 13:21:44] <david-guenault> np
[2016-04-29 13:21:49] <unipheas> I really don’t want to have to redo this site!
[2016-04-29 13:22:30] <david-guenault> gona do the same as you and check it out
[2016-04-29 13:34:28] <hungerregnuh> unipheas: @david-guenaultdocker newbie and a lil new to the convo, but wouldn't a docker tag <image id> namespace/image then a push push his changes to docker hub?
[2016-04-29 13:35:37] <david-guenault> yup but you need to commit first (you push images to the hub, not containers) ;-)
[2016-04-29 13:36:05] <hungerregnuh> oooh right ;D
[2016-04-29 13:39:41] <david-guenault> unipheas: i think i got something
[2016-04-29 13:39:49] <unipheas> yea?
[2016-04-29 13:40:56] <david-guenault> unipheas: not resolving everything but when you did the cp there are some remaining files (install) in the new container, so it start again the installation
[2016-04-29 13:41:18] <unipheas> should i go through with the install or what do i do?
[2016-04-29 13:41:46] <david-guenault> why not commit the first container ? you don't need the xirangwp2
[2016-04-29 13:41:55] <david-guenault> nor the db2
[2016-04-29 13:42:06] <david-guenault> oh yes you need it
[2016-04-29 13:42:14] <david-guenault> because of the volume
[2016-04-29 13:42:15] <unipheas> because the first container has a mounted volume
[2016-04-29 13:43:05] <david-guenault> what you need to do in the xirangwp2 container is first rm the /var/www/html/* and then cp the site
[2016-04-29 13:43:23] <david-guenault> this way you bypass the installation procedure
[2016-04-29 13:44:01] <unipheas> ah easy enough
[2016-04-29 13:44:18] <unipheas> so recopy the site?
[2016-04-29 13:45:23] <david-guenault> this is not a docker related problem, but a wordpress image one
[2016-04-29 13:45:28] <david-guenault> ^^
[2016-04-29 13:45:46] <david-guenault> what i suggest is using a dockerfile a rebuild your image from it
[2016-04-29 13:46:25] <unipheas> haha yes! I need to learn that pronto!
[2016-04-29 13:46:26] <unipheas> thanks… it gives me some sort of direction
[2016-04-29 13:46:26] <unipheas> okay cool
[2016-04-29 13:46:26] <unipheas> I thought it was docker but it’s not great!
[2016-04-29 13:46:50] <unipheas> I really appreciate it. I’ll give that a try now
[2016-04-29 13:47:13] <remram44> So should I keep my current workaround and hope that the Docker devs get to a usable interface someday? [<-CODE->] 
[2016-04-29 15:20:37] <hungerregnuh> anyone know if it's possible to ssh into a docker host from a container?
[2016-04-29 15:21:51] <theshadowx> yes it is possible
[2016-04-29 15:22:05] <theshadowx> 172.17.0.1
[2016-04-29 15:22:27] <hungerregnuh> hmmm i thought that IP isn't guaranteed and it would change
[2016-04-29 15:22:51] <theshadowx> in your host do ifconfig
[2016-04-29 15:23:14] <theshadowx> and check for docker ip
[2016-04-29 15:24:49] <hungerregnuh> facepalmmust've read the documentation wrong - thanks for the help
[2016-04-29 15:25:08] <remram44> I don't think it's guaranteed no
[2016-04-29 15:25:21] <remram44> you can change the IP on your host via configuration
[2016-04-29 15:25:39] <remram44> Also, if using something like docker-machine, you'd connect to the boot2docker VM and not the host
[2016-04-29 15:26:19] <hungerregnuh> thanks, this helps... now to figure out how to configure gitlab runners with this info
[2016-04-29 15:26:30] <theshadowx> or in the container check for the gateway
[2016-04-29 15:29:05] <hungerregnuh> checking the gateway in the container did the trick :D
[2016-04-29 15:30:23] <theshadowx> yep
[2016-04-29 15:30:39] <hungerregnuh> sadly, i read all of this already, none of it clicked until you guys said it lol
[2016-04-29 18:37:22] <josdotso> Working with Docker Compose (v2).  Given the two containers, gitlab and drone, how can i start gitlab to generate a value that is then exposed as an environment variable and then pass it into drone's container?  Must I create two docker-compose pods or can I achieve this in one?
[2016-04-29 18:37:55] <josdotso> (oauth secrets)
[2016-04-29 18:38:45] <josdotso> Seems almost like a good time to try Terraform
[2016-04-29 18:38:48] <josdotso> (for this)
[2016-04-29 18:41:51] <theshadowx> I think there is something called depends_on
[2016-04-29 18:42:19] <theshadowx>  [<-LINK->] 
[2016-04-29 18:43:28] <theshadowx>  [<-LINK->] 
[2016-04-29 19:40:45] <lykhouzov> remram44: why you can't put all required files into one dir and then copy it instead of copy separate resources?
[2016-05-02 02:31:13] <lvegerano> Hi all I’m trying to setup a compose file for wordpress/mysql and keep getting the error [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2016-05-02 02:38:05] <timcharper> lvegerano: if you read that error message, it looks like it's  telling you what's wrong.
[2016-05-02 02:38:23] <timcharper> you haven't specifiedWORDPRESS_DB_HOSTorMYSQL_PORT_3306_TCP
[2016-05-02 02:42:06] <lvegerano> timcharper: the wordpress docs states-e WORDPRESS_DB_HOST=... (defaults to the IP and port of the linked mysql container)as far asMYSQL_PORT_3306_TCPI did not see any documentation on either image
[2016-05-02 13:46:17] <andrestc> Hi! Are the stats for network IO suposed to work when I'm running a container with --net=host ?
[2016-05-02 15:02:10] <aios> hi all
[2016-05-02 15:03:26] <aios> i have two docker-compose, one for private registry  - one for nginx.How i can make an nginx can resolve name "registry"?
[2016-05-02 15:05:33] <cortwave> Create network and run docker compose with your new network
[2016-05-02 15:05:37] <cortwave> more info here [<-LINK->] 
[2016-05-02 15:07:47] <aios> DmitryPranchuk: ok how i can edit configuration in compose.yml?
[2016-05-02 15:10:35] <cortwave> I don’t understand your question
[2016-05-02 15:14:30] <aios> DmitryPranchuk: i found docker network ls and inspect - what i must add to compose.yml for connect two containers in network
[2016-05-02 15:15:08] <aios> i can ping from containers linked services. maybe i need to add depends?
[2016-05-02 15:17:32] <cortwave> For name resolving your containers should be in common network. If you already has network with namentwe.g.  just add it to your service: [<-CODE->] 
[2016-05-02 15:20:17] <aios> DmitryPranchuk: thanks
[2016-05-02 15:30:14] <aios> DmitryPranchuk: so i added network to container
[2016-05-02 15:30:40] <aios> DmitryPranchuk: and docker network inscpect show me containers in Containers: object
[2016-05-02 15:31:03] <aios> but i cant ping from container nginx and resolve name registry
[2016-05-02 15:45:00] <cortwave> attach please your docker-compose files
[2016-05-02 15:46:15] <cortwave> There are names indocker network inspectsame as your containers names?
[2016-05-02 15:48:58] <cortwave> also you should specify external networks in  your docker compose: [<-CODE->] 
[2016-05-02 15:51:55] <aios> i use 1 version of compose.
[2016-05-02 15:52:24] <aios> and param net
[2016-05-02 15:55:50] <cortwave> No matter, just verify that output ofdocker network inspect your-networkcontains both your containers. Then it should ping by container name (Also check container names in inspect output)
[2016-05-02 15:57:06] <aios> yes i have container name in docker inspect output
[2016-05-02 15:58:44] <cortwave> There is container with nameregistryin them?
[2016-05-02 15:59:54] <aios> cortwave: yep
[2016-05-02 16:00:08] <aios>  [<-CODE->] 
[2016-05-02 16:00:48] <cortwave> anddocker exec -it php-nginx ping registryfails?
[2016-05-02 16:01:27] <aios> root@:~/docker# docker exec -it php-nginx ping registryping: unknown host registry
[2016-05-02 16:01:48] <cortwave> interesting
[2016-05-02 16:02:31] <cortwave> attach pleasedocker exec -it php-nginx cat /etc/hostsoutput
[2016-05-02 16:03:13] <aios>  [<-CODE->] 
[2016-05-02 16:04:49] <cortwave> Doesc16a862fcac1id of your registry container?
[2016-05-02 16:05:12] <aios> no
[2016-05-02 16:09:59] <aios> this is php-nginx
[2016-05-02 16:11:49] <cortwave> Try to ping your nameserver (/etc/resolv.conf) from php-nginx
[2016-05-02 16:12:10] <aios> cortwave: is it happening because i use first version of compose file and use links?
[2016-05-02 16:12:22] <aios> linked service are mysql and redis
[2016-05-02 16:15:34] <cortwave> May be, I don’t work much with links but in documentation says that it’s deprecated and better to use named networks
[2016-05-02 16:15:55] <aios> nameserver 8.8.8.8nameserver 8.8.4.4
[2016-05-02 16:16:15] <aios> this is name servers) so i dont ping that thinking that is works)
[2016-05-02 16:18:37] <cortwave> Is it nemeserver from your container?
[2016-05-02 16:19:45] <aios> cortwave: yep
[2016-05-02 16:29:18] <cortwave> It explains your problem, your container uses only google DNS, for example In my/etc/resolv.conf: [<-CODE->] 
[2016-05-02 16:29:46] <josdotso> I have two docker compose v2 files started each on its own network.  I would like to expose a port in the first docker compose session to localhost of the docker engine, so that compose [<-ISSUE->] 's containers can connect to that port.. Is this possible?
[2016-05-02 16:31:01] <josdotso> I see external links, but can I use that to share localhost?
[2016-05-02 16:38:55] <aios> cortwave: so what name server should i use?
[2016-05-02 16:42:06] <cortwave> aios: try to run any container with—net=your-networkand—dns=127.0.0.11and ping registry or nginx
[2016-05-02 16:42:43] <aios> cortwave: thanks - i will remake files to v2 and try that.
[2016-05-02 17:21:16] <aios> cortwave: so i updated yml files to v2
[2016-05-02 17:21:58] <aios> and things got worse
[2016-05-02 17:22:55] <aios> if on first version i can attach containers and doesnt resolve  - for version 2 i cant attach two containers from different composes in one network
[2016-05-02 17:23:27] <aios> when i make networks: - default  - docker creates two different networks like that
[2016-05-02 17:23:36] <aios>  [<-CODE->] 
[2016-05-02 17:24:22] <cortwave> How do you specify network in docker-compose?
[2016-05-02 17:24:59] <aios>  [<-CODE->] 
[2016-05-02 17:25:35] <cortwave> you should specify your default network as external
[2016-05-02 17:26:10] <aios> i cant answer for that because i don't know...
[2016-05-02 17:26:23] <cortwave>  [<-CODE->] 
[2016-05-02 17:27:09] <cortwave> in your casenetwork-name-in-this-composeisdefault
[2016-05-02 17:27:48] <aios> it looks like [<-CODE->] 
[2016-05-02 17:27:56] <cortwave> yes
[2016-05-02 17:28:10] <cortwave> in both docker-compose files
[2016-05-02 17:28:18] <aios> i will try - hold on 5 minutes.
[2016-05-02 17:28:42] <cortwave> and docker_defauld should already exists before docker-compose up
[2016-05-02 17:29:30] <aios> cortwave: its exists
[2016-05-02 17:33:25] <aios> cortwave: HOLY SHIT!
[2016-05-02 17:33:35] <aios> cortwave: Я хрен его знает понимаешь ты на русском НО СПАСИБО!!!!!!
[2016-05-02 17:33:43] <aios> cortwave: ThANKS!!!!!
[2016-05-02 17:33:57] <cortwave> great!
[2016-05-02 17:35:55] <aios> ITS REALLY WORKING!!!! AWESOME!!!
[2016-05-02 17:36:47] <josdotso> aios: could you share a paste of the working config?  I\'m working on connecting two compose sets as well. I was thinking of using "host" network to share
[2016-05-02 17:39:32] <aios> josdotso: hold on 10 minutes
[2016-05-03 15:50:54] <aios> hi all
[2016-05-03 15:51:05] <aios> cant find some error with docker iptables
[2016-05-03 16:05:26] <josdotso> Using Docker Compose v2 for single-VM cluster of Dockerized services.  I have Direct LVM setup to use a discrete block device (Openstack volume).  Is it better to use a Data Volume Container (which I presume would create a LV on the VG) than to use a volume based on a host path?
[2016-05-03 16:05:45] <josdotso> (for production usage)
[2016-05-03 16:06:06] <josdotso> e.g. MySQL container
[2016-05-03 16:07:30] <josdotso> Just read the room info.. Ah.. Will take my question to IRC.  Thanks!
[2016-05-03 17:14:24] <aios> anybody there?
[2016-05-04 00:36:13] <josdotso> How do I create a Named Volume on Direct LVM (devicemapper)?Error response from daemon: create hello: create hello: Error looking up volume plugin devicemapper: plugin not found
[2016-05-04 06:44:11] <fredrikaverpil> What's a good method to force a container to run via some arbitrary command so that I can make sure I can always 'docker exec -ti <containername> bash' into it?
[2016-05-04 07:46:16] <fredrikaverpil> fredrikaverpil: ended up using supervisord -n (runs in foreground)
[2016-05-04 08:10:58] <rismos> Hello all, I was wondering if some of you are willing to help me with my BSc thesis by answering my survey. I am not a contributor to Docker, however my thesis is about improving the process of developers new to a project such as Docker understanding the project's codebase. More info about it is in the survey, thank you in advance!https://docs.google.com/forms/d/1lYETtxBiS5jjiUb41yDu0mRDvEhcJDLt3oGAK849gc4/viewform
[2016-05-04 21:30:55] <brunofitas>  [<-CODE->]  [<-CODE->] Thanks
[2016-05-04 21:33:44] <SeanSassenrath> Hi everyone! I have a docker-machine that stopped running and I can't get it to start again. It uses thegenericdriver. Any help would be greatly appreciated!
[2016-05-04 21:37:41] <aios> SeanSassenrath: any logs?
[2016-05-04 21:39:57] <SeanSassenrath> aios: can't eval into the machine to get the logs unfortunately
[2016-05-04 21:40:25] <SeanSassenrath> Error running connection boilerplate: content is not running. Please start it in order to use the connection settings
[2016-05-04 21:43:09] <aios> SeanSassenrath: look in pm
[2016-05-05 08:40:20] <brunofitas> I really need to know the IP address of that container.  My app cannot resolve the DNS , so I need to pass an IP. I cannot find it in /etc/hosts neither. Any suggestions?
[2016-05-05 09:37:45] <AjeetK> Hey guys, I am trying to use docker for my rails app. However, stuck in installing gems mentioned inGemfilewith ssh url. Below is my complete problem (Any help would be appreciable) [<-LINK->] 
[2016-05-05 13:25:36] <unipheas> Anyone here?
[2016-05-05 13:27:30] <Tyga76> brunofitas: use  docker inspect --format '{{ .NetworkSettings.IPAddress }}’ <conatiner_name>
[2016-05-05 13:34:58] <unipheas> I’m looking for a private tutor for docker. I’m willing to pay for your time. There are just some things I don’t understand and I really want to learn this technology. Would anyone be interested? Please send me a private message.
[2016-05-05 13:45:05] <brunofitas> @Tyga76 thanks, but that doesnt work inside the container, right? I\'m using InetAddress to resolve the dns into an IP. V2 dropped the env variables created by "links", and its ok in most cases, but in this case I needed an IP. [<-CODE->] This works
[2016-05-05 14:09:06] <chahn1138> Brian, this seems like a place for announcements, or what-really-I-am-unsure, but it seems that the bulk of the conversation is happening in IRC.  (too bad fo rme...IRC never fit my brain for some reason)
[2016-05-05 14:26:35] <Tyga76> brunofitas: sorry..misunderstood your question
[2016-05-05 20:17:39] <rivaturi> Hello, any suggestions on how to get this error fixed during docker -compose up?  Error writing to output file - write (28: No space left on device)
[2016-05-05 21:44:30] <cortwave> Today I had this problem. On my VM was really not enough free space for image running.
[2016-05-06 05:16:54] <robbyoconnor> IRC is dead
[2016-05-06 08:23:26] <otbe> Hi everyone. Im playing around with docker swarm and Im a little bit confused. I have a containerized app that needs a host directory. So I rundocker -H cluster-manager:4000 run -v ~/myDir:/dir imagefrom my laptop. The app complains aboutPermission deniedwhile reading this folder. If I ssh intocluster-managerand execute the same command it works as expected.~/myDiris available on all nodes but not on my laptop and not on the manager itself. Whats the reason for this?
[2016-05-06 14:06:52] <unipheas> chahn1138: do you know which server or channel? I’d love to communicate with people about this..
[2016-05-06 17:16:28] <bharath-cchmc> How should I dockerize interdependent python scripts.Say there is a function in script 1 which calls script 2 and script 3 in the run process and then produces an output.Even when I have copied all the scripts inside the docker, it searches for the script2 and script3 outside the docker.Is there an example for this particular problem?
[2016-05-06 17:28:03] <dissipate> does anyone know ifdocker-compose downfollows the constraints of the docker-compose file, and only takes down the containers that match the constraints?
[2016-05-06 17:36:06] <dissipate> bharath-cchmc: how is it searching for the scripts outside docker? if all the scripts are in the docker container, you should be fine
[2016-05-06 17:38:50] <dissipate> whoops, didn't read the room description
[2016-05-06 17:49:26] <nafg> How would you run docker-machine from within a CI? I created it via docker-machine from my laptop.
[2016-05-06 18:19:59] <bharath-cchmc> dissipate: : [<-LINK->] 
[2016-05-09 09:03:12] <strages> how would i go about building a docker image on which i can install pandoc and latex with several extra packages
[2016-05-09 11:38:03] <cristim> strages: I think there's one already, have a look at [<-LINK->] 
[2016-05-09 11:39:17] <cristim> strages: and here's how it's done under the hood: [<-LINK->] 
[2016-05-10 02:16:44] <bharath-cchmc> I am trying do a patch after finding diff in the code. So when I use RUN diff -Naur file1 file2 > patch.patch dockerfile throws me an error, 'Command returned a non-zero code': 2.  Base image: Ubuntu 15:10
[2016-05-10 11:11:26] <eamonwoortman> Hello!
[2016-05-10 11:14:47] <eamonwoortman> Can anyone verify thatvolume_fromworks on Docker Cloud when scaling up?Considering this first setup(the data and mysql containers): [<-LINK->] When I try to scale that up in Docker Cloud using the scale slider, it fails because of the following error: [<-CODE->] 
[2016-05-10 11:17:46] <eamonwoortman> I realize this isn't a valid use-case since you probably don't want to share the same volume across database servers, but I try to achieve something similar with web servers instead
[2016-05-10 12:58:19] <Tintweezl> Ah. Geek speak. I'm home.
[2016-05-10 12:58:42] <sean9999> grok! :)
[2016-05-10 12:59:36] <Tintweezl> if it's a herd of nerds is it a freak of geeks?
[2016-05-10 13:00:11] <Tintweezl> something only a nerd or geek would ponder
[2016-05-10 13:01:02] <Tintweezl> i'm on the cusp actually. A neek. Or a gerd.
[2016-05-10 13:01:33] <Tintweezl> got it
[2016-05-10 13:01:43] <Tintweezl> I'm a gneek.
[2016-05-10 13:01:53] <Tintweezl> silent g
[2016-05-10 13:02:08] <Tintweezl> Gneek out.
[2016-05-10 18:19:35] <jariangibson> Is it possible to run Windows containers in Mac beta app?
[2016-05-10 18:20:36] <nafg> I doubt it
[2016-05-10 18:21:01] <jariangibson> Figured but thought i would ask
[2016-05-10 18:27:10] <otbe> Would love to have an invite to docker for mac :)
[2016-05-10 19:14:46] <strages> how can i run something in the pandoc container?
[2016-05-10 19:35:14] <strages> i want to run [<-LINK->] ;)
[2016-05-10 22:22:38] <kkindaface> I just got started using docker and i need some guidance. I am trying to setup a private registry behind firewall. I am trying to create my own docker image and then push it to my private registry. I don't see any documentation on how to do it. whatever I found so far only talks about pulling from docker hub and pushing to private repo. If I don't want to go via Docker Hub, Can't I use docker at all?
[2016-05-10 22:29:42] <nafg> kkindaface: sure. What are you pulling?
[2016-05-10 22:30:03] <kkindaface> I don't need to pull anything from the hub
[2016-05-10 22:30:26] <kkindaface> I tried to create my own docker file that runs a springboot application
[2016-05-10 22:30:47] <kkindaface> my target machine already has centos and java installed
[2016-05-10 22:30:54] <kkindaface> is my approach wrong?
[2016-05-10 22:32:15] <kkindaface> if I have to pul something from hub first, I can pull Java:8 and go from there....but still that leaves me with the question....how do i edit my own docker file and push it to my private repo
[2016-05-10 22:33:54] <pierregermain> strages: I think you will need to modify the dockerruncommand so that you use what is in the make file [<-LINK->] 
[2016-05-10 22:34:46] <kkindaface> nafg: , I have the following in my dockerfile:
[2016-05-10 22:35:08] <kkindaface>  [<-CODE->] 
[2016-05-10 22:36:16] <cristim> strages: assuming you're in the boilerplate directory after you cloned it, you should be able to compile it using docker run
[2016-05-10 22:36:54] <cristim> strages: something like this:docker run -v `pwd`:/source jagregory/pandoc -f latex -t pdf myfile.tex -o myfile.pdf
[2016-05-10 22:48:47] <cristim> strages: I tried to run it and it seems the image is missing some stuff, like the lmodern font
[2016-05-10 22:49:02] <cristim> you may need to extend it and include more stuff inside it
[2016-05-10 22:52:32] <timothyjlaurent> I am just trying out docker for mac beta. I'm wondering how I find the IP address of the docker host. I need to map this in/etc/hostsso that oauth will work.
[2016-05-10 22:53:06] <timothyjlaurent> Is this the best place to get live support for docker mac beta?
[2016-05-10 22:58:38] <cristim> strages: it's then missing the Hoefler Text font, which is commercial. You will need to buy it and install it inside the extended docker image or switch to another font
[2016-05-10 23:00:03] <cristim> strages: the font costs $299, so you may want to change to something else
[2016-05-10 23:00:57] <cristim> strages: docker run -it -v `pwd`:/source --entrypoint /bin/bash jagregory/pandoc
[2016-05-10 23:02:12] <pierregermain> offtopic:@stragesI use "pandoc_resume" to create resumes, really easy to use (never tried to use it with docker thought)
[2016-05-10 23:05:14] <nafg> kkindaface: so what is the issue? Basically you need to dodocker login ... <registry>,docker build -t <registry>/<name> ..., anddocker push <registry>/<name>
[2016-05-10 23:23:58] <kkindaface> I think I may have understood docker incorrectly. I did a yum install of docker on centos and I just pulled the docker registry image and started the docker registry for a localregistry (private registry). I dont have any docker login credentials. Can I use docker on premise without having a docker account?
[2016-05-10 23:27:27] <kkindaface> I was trying to build my dockerfile locally with an intention to push it into my private registry running on port 5000. But the build command did not succeed.
[2016-05-10 23:28:32] <cristim> kkindaface: you don't need a docker account to build or run a private registry
[2016-05-10 23:30:33] <kkindaface> Any document that explains the steps to run a private registry? The docs on [<-LINK->] only seem to talk about a private/public registry in the cloud.
[2016-05-10 23:31:43] <cristim> kkindaface: did you see this? [<-LINK->] 
[2016-05-10 23:33:03] <kkindaface> cristim: yes, i used that to start my private registry. but I cant seem to build my own dockerfile  that I want to push to this private registry on localhost
[2016-05-10 23:33:43] <cristim> you may have errors in the Dockerfile
[2016-05-10 23:34:09] <necrose99> i'd not mind a lan private proxie registry ie  bound to public account.
[2016-05-10 23:34:51] <kkindaface> cristim: , my docker file is on this chat
[2016-05-10 23:35:06] <kkindaface> Do you see any issues with it, it is pretty simple one.
[2016-05-10 23:37:15] <cristim> you may want to use WORKDIR instead of RUN cd
[2016-05-10 23:38:02] <kkindaface> cristim: , I will try workdir, but my error seems to be referring to an invalid repository/tag
[2016-05-10 23:38:43] <cristim> docker pull java:8
[2016-05-10 23:39:41] <kkindaface> if my dockerfile name is \'mydockerfile\' and my private registry is running on localhost:5000. What would my build command be? I dont have any repo on the cloud, nor have I pulled anything from the cloud. Im trying "docker build -t localhost:5000/MyApp mydockerfile"
[2016-05-10 23:40:56] <kkindaface> Error I see :invalid value "localhost:5000/MyApp" for flag -t: Error parsing reference: "localhost:5000/MyApp" is not a valid repository/tag\nSee \'docker build --help\'.
[2016-05-10 23:41:00] <cristim> you forgot the -t, which is needed if using a custom dockerfile name instead of the default Dockerfile
[2016-05-10 23:42:18] <cristim> also you need a directory as last argument, . (the dot) is often used to include everything from the current directory
[2016-05-10 23:42:29] <kkindaface> i see
[2016-05-10 23:42:59] <cristim> try this :docker build -t localhost:5000/MyApp -t mydockerfile .
[2016-05-10 23:43:16] <kkindaface> I do have the -t flag, and the error I see is talking about something more basic.....lemme try your command
[2016-05-10 23:44:10] <cristim> also switch to WORKDIR if not already done
[2016-05-10 23:44:41] <kkindaface> still same error
[2016-05-10 23:45:24] <kkindaface> the error seems to be much basic and I dont think its even getting to the dockerfile yet, Its complaining about repo not being valid
[2016-05-10 23:45:36] <cristim> it's  -f mydockerfile, my bad
[2016-05-10 23:46:00] <kkindaface> same error 
[2016-05-10 23:46:05] <cristim> have a look at docker build -h
[2016-05-10 23:47:20] <kkindaface> I think the error is happening even before its getting into the contents of the dockerfile, "invalid value "localhost:5000/MyApp" for flag -t"
[2016-05-10 23:48:09] <cristim> it may need to be all-lowercase
[2016-05-10 23:48:47] <kkindaface> oh yeah...that was it!
[2016-05-10 23:48:57] <cristim> yay!
[2016-05-10 23:48:59] <kkindaface> it built it now :)
[2016-05-10 23:49:14] <kkindaface> Thanks!
[2016-05-10 23:49:17] <cristim> stupid error message
[2016-05-10 23:49:22] <cristim> you're welcome
[2016-05-10 23:49:27] <kkindaface> yeah tell me about it!
[2016-05-10 23:49:42] <kkindaface> 3 hours down the drain
[2016-05-10 23:49:48] <cristim> create an issue/pull request 
[2016-05-10 23:50:32] <kkindaface> yeah I should do that
[2016-05-11 10:58:54] <strages> pierregermain: thanks for the tip! its actually almost the same, pandoc_resume uses markdown, the one I asked about uses yaml
[2016-05-11 10:58:55] <strages> ;)
[2016-05-11 11:07:16] <strages> cristim: thanks! I will play around with it!
[2016-05-11 11:43:19] <christobill> Hi. Any idea why this diff is so big? And how to get rid of it? [<-CODE->] I removed as many old containers/images as possible with: [<-CODE->] 
[2016-05-11 12:53:39] <eamonwoortman> nvm, was a silly question
[2016-05-11 13:44:43] <chahn1138> How to start docker so that it uses /data in place of /var ?i.e. I have gobs of space in /data where /var is causing:docker load -i saved-container.tarUntar re-exec error: exit status 1: output: write /66d162553131e8cc5af48008418af924a5c1f4fd4b66b7a8ac4b855609886bef/layer.tar: no space left on device
[2016-05-11 13:48:06] <chahn1138> ...and, as a side-note, what sort of file says that it is 100Gb's but it lives on an 8 Gb HDD?The disk:[root@cdswebserver devicemapper]# df -h .Filesystem              Size  Used Avail Use% Mounted on/dev/mapper/centos-var  8.0G  5.3G  2.8G  66% /varThe file:[root@cdswebserver devicemapper]# ls -l /var/lib/docker/devicemapper/devicemapper/data-rw-------. 1 root root 107374182400 May 11 03:47 /var/lib/docker/devicemapper/devicemapper/dataI must be missing something.  :0)
[2016-05-11 13:53:11] <strages> hey guys what do you think of hyper.sh
[2016-05-11 13:53:41] <strages> what is the clear upside to digital ocean?
[2016-05-11 13:53:55] <strages>  [<-LINK->] 
[2016-05-11 13:59:31] <chahn1138> unipheas: I am so sorry to have missed that mention.  I will look up that IRC channel.  (it seems that I need to ask my question there as well)
[2016-05-11 14:00:06] <chahn1138> This site exposes existing chats: [<-LINK->] 
[2016-05-11 14:02:52] <chahn1138> I used this: https://webchat.freenode.net/ and just chose the docker channel.Good luck!
[2016-05-11 16:40:29] <cristim> chahn1138: regarding qour question " what sort of file says that it is 100Gb\'s but it lives on an 8 Gb HDD?" - the answer may be "sparse file"
[2016-05-11 16:40:58] <cristim> chahn1138:  [<-LINK->] 
[2016-05-11 19:53:40] <timcharper> I've been experiencing an issue withdocker pushfor a local, ipv4 only registry. Every once in a while, it'll fail, with5b46d4: dial tcp: lookup registry.weave.local: no such host, only to succeed after.
[2016-05-11 19:54:20] <timcharper> I've run wireshark and have confirmed that Docker is issuing anAandAAAADNS query simultaneously, and when theAAAAresponse comes back first, I get the error. Most of the time, theAresponse comes back first.
[2016-05-11 19:54:35] <timcharper> Also, I\'ve confirmed thatAAAAis responding correctly with "No answer".
[2016-05-11 19:55:15] <timcharper>  [<-LINK->] 
[2016-05-11 19:56:09] <timcharper> The DNS server behavior is in compliance with the RFC spec on how DNS should respond. It seems that whatever Docker is doing with DNS resolution is in error. It should ignore theAAAAno answer response and wait for theAresponse, rather than abort immediately .
[2016-05-11 20:03:51] <timcharper> related to [<-ISSUE->] ?
[2016-05-12 10:13:38] <strages> is pushing to docker hub slow?
[2016-05-12 10:13:47] <strages>  [<-LINK->] 
[2016-05-12 10:13:54] <strages> this is going to take forever
[2016-05-12 10:14:22] <strages>  [<-LINK->] 
[2016-05-12 10:25:05] <strages> also should this gitter channel not be synced with freenode #docker?
[2016-05-12 10:28:48] <atmosx> should it?!
[2016-05-12 10:34:14] <strages> its good for people not accustomed to irc so much
[2016-05-12 10:34:22] <strages> plus you have automatic history
[2016-05-12 10:34:31] <strages> but what about the slow upload speeds
[2016-05-12 10:34:50] <strages>  [<-LINK->] 
[2016-05-12 10:34:54] <strages> so slow :O
[2016-05-12 13:06:10] <cristim> is there a way to run a private dockerhub UI that points to a private registry?
[2016-05-12 13:09:20] <strages> ?
[2016-05-12 13:13:51] <dimitrieh> test
[2016-05-12 17:00:36] <caarlos0> Hey people!I opened a PR with adding a logdriver for logentries... does anyone know a easy way to test it - maybe one that don't require the rebuild of the entire project?
[2016-05-12 17:00:54] <caarlos0> BTW: the PR link is: [<-ISSUE->] 
[2016-05-12 17:38:28] <chahn1138> cristim: Thank you for taking the time.
[2016-05-12 20:55:19] <mevatron> Is there a way to conditionally add devices if they exist to the docker-compose file, or would that need to be done via an external script?
[2016-05-12 21:30:24] <dimitrieh> how long does it take you guys to upload an image to docker? 3,5 gb?
[2016-05-12 21:31:16] <dimitrieh>  [<-LINK->] 
[2016-05-12 21:32:52] <cristim> docker works best with small images, and likely if your images are so large you are doing something wrong
[2016-05-12 21:33:02] <dimitrieh> mmh
[2016-05-12 21:33:14] <dimitrieh> i can explain :)
[2016-05-12 21:33:44] <dimitrieh> its basically this image : [<-LINK->] 
[2016-05-12 21:34:05] <dimitrieh> but with these changes
[2016-05-12 21:34:08] <dimitrieh>  [<-ISSUE->] 
[2016-05-12 21:35:02] <dimitrieh> basically this image
[2016-05-12 21:35:11] <dimitrieh>  [<-CODE->] 
[2016-05-12 21:35:57] <dimitrieh> cristim: i got it working with these changes
[2016-05-12 21:36:01] <cristim> ok, then it makes sense
[2016-05-12 21:36:15] <dimitrieh> yeah so my image has become big...
[2016-05-12 21:36:16] <cristim> you can only wait
[2016-05-12 21:36:22] <dimitrieh> but i need to upload si so slow
[2016-05-12 21:36:30] <dimitrieh> really? :O
[2016-05-12 21:36:50] <cristim> are you perhaps hitting any upload limits with your ISP?
[2016-05-12 21:36:56] <dimitrieh> mmh
[2016-05-12 21:38:05] <dimitrieh>  [<-LINK->] 
[2016-05-12 21:38:23] <dimitrieh> shouldn't be the problem is it?
[2016-05-12 21:39:26] <dimitrieh> is there a service from which i can upload it to docker hub, so my computer doesn;t have to stay online?
[2016-05-12 21:40:47] <cristim> try this [<-LINK->] 
[2016-05-12 21:41:19] <mevatron> What upload speed are you getting on the push?
[2016-05-12 21:41:57] <mevatron> In theory it should take 1 hour: [<-LINK->] 
[2016-05-12 21:42:16] <dimitrieh> 9,7mb in 634seconds
[2016-05-12 21:42:32] <dimitrieh> cristim: looks promising
[2016-05-12 21:42:59] <mevatron> Yeah 15 KBps doesn't sound right
[2016-05-12 21:43:23] <dimitrieh> any ideas how to improve upon this?
[2016-05-12 21:43:33] <dimitrieh> or you say i should go with automated builds?
[2016-05-12 21:44:06] <mevatron> Do you have a VPS you can run a private registry as a test case on?
[2016-05-12 21:44:31] <dimitrieh> mmh no..
[2016-05-12 21:45:03] <mevatron> Or, workbox/homebox to push to?
[2016-05-12 21:45:17] <dimitrieh> whats that if i may ask?:)
[2016-05-12 21:45:43] <mevatron> Just a machine you can run docker registry and connect over the internet to :)
[2016-05-12 21:45:44] <dimitrieh> not a total pro yet at docker
[2016-05-12 21:45:58] <mevatron> You can host your own docker registry just like docker hub
[2016-05-12 21:46:13] <dimitrieh> ah no :P
[2016-05-12 21:46:20] <mevatron> And, it will help isolate where the bottleneck might be
[2016-05-12 21:46:33] <dimitrieh> i get where you are aiming at...
[2016-05-12 21:46:55] <dimitrieh> isn't there a simple cli to pipe my traffic through a vpn
[2016-05-12 21:47:01] <dimitrieh> free ? for testing
[2016-05-12 21:47:06] <mevatron> Or, Google's GCR is pretty dang cheap
[2016-05-12 21:48:17] <mevatron> One month for Digital Ocean VPS is $5 :)
[2016-05-12 21:48:55] <mevatron>  [<-LINK->] 
[2016-05-12 21:50:56] <dimitrieh> using docker beta for mac btw
[2016-05-12 22:09:46] <dimitrieh> for now i will use the automatic building process
[2016-05-12 22:09:47] <dimitrieh> ;)
[2016-05-12 22:27:54] <wormen> Hellotell me, somehow I can close code my  application in docker from external interference?
[2016-05-13 07:54:55] <cristim> wormen: you may need to ship the binaries and keep the source code out of it, but it all depends on the language you're coding in
[2016-05-13 07:57:48] <cristim> wormen: one way would be to mount the source code into the container using volumes, compile it and move the results into the Docker image's filesystem which will be captured in the image you're going to distribute
[2016-05-13 07:58:50] <cristim> wormen: or maybe you can use two different containers, one for building the code, and another for distributing to your users
[2016-05-13 08:02:29] <wormen> cristim: I have a situation suchthere nodejs application, and I need to so that users can not get access to the source code
[2016-05-13 09:23:22] <cristim> wormen: that's not really a docker issue, have a look here: [<-LINK->] 
[2016-05-13 09:27:47] <wormen> cristim: this post I've seenI considered docker, as one of the options for protecting the code, now it is clear that he can not protect
[2016-05-13 09:28:38] <cristim> the contents of the docker image can be trivially read
[2016-05-13 09:47:37] <jondubois> Do you HAVE to have a CMD or ENTRYPOINT instruction inside your Dockerfile?
[2016-05-13 10:20:06] <dimitrieh> any idea how to fix/bin/bash: /bin/bash: cannot execute binary file
[2016-05-13 10:20:47] <dimitrieh> jondubois: i believe it not to be so!
[2016-05-13 10:21:04] <dimitrieh> see [<-LINK->] 
[2016-05-13 10:21:28] <dimitrieh> maybe the awesome@cristimcan help me ^^ almost got it running now heh :P
[2016-05-13 10:21:32] <cristim> dimitrieh: remove /bin/bash and leave just the binary you are trying to run with it as CMD
[2016-05-13 10:23:39] <cristim> jondubois: does it fail without them?
[2016-05-13 10:26:08] <cristim> jondubois: they don't seem to be required, but you will need to pass a command when 'docker run'-ing the container from your image, unless done by some of your image's base layers
[2016-05-13 10:27:38] <dimitrieh> thanks@cristim
[2016-05-13 10:28:12] <dimitrieh> it works now... it seems gitlab-ci automatically adds entrypoint /bin/bash
[2016-05-13 10:28:34] <cristim> cool
[2016-05-13 12:24:03] <jondubois> dimitrieh: @cristimah thanks. Yeah the base image already has a CMD. I have it working now.
[2016-05-13 13:32:46] <dimitrieh> Nice
[2016-05-13 13:58:28] <jondubois> I'm getting a new issue now: I'm trying to create and run a container for Postgres preloaded with some data. My Dockerfile looks like this:
[2016-05-13 13:58:39] <jondubois>  [<-CODE->] 
[2016-05-13 13:58:55] <jondubois> It builds fine
[2016-05-13 13:59:50] <jondubois> but when I run it withdocker run -d --name some-sns-postgres -p 5432:5432 sns-postgres:v1- It fails with this error:postgres cannot access the server configuration file "/var/lib/postgresql/data/postgresql.conf": No such file or directory
[2016-05-13 14:00:24] <jondubois> but the strange thing is...
[2016-05-13 14:00:44] <jondubois> If I run the exact same image using this commanddocker run -d --name some-sns-postgres -p 5432:5432 -ti sns-postgres:v1 /bin/bashthen it works fine
[2016-05-13 14:00:58] <jondubois> I know the -d and -ti shouldn't be used together (that was accidental)
[2016-05-13 14:01:06] <jondubois> but it works...
[2016-05-13 14:01:33] <jondubois> Is there a way to get it to work without attaching /bin/bash?
[2016-05-13 14:02:49] <jondubois> What is the -ti flag doing which is causing it to behave differently?
[2016-05-13 14:35:39] <jondubois> Nevermind I guess trying to copy the raw postgres data wasn't a good idea (probably encrypted)... I just used a SQL dump instead and it works
[2016-05-13 17:09:19] <soapoperator> Hello, i try to install piwik using docker-compose and the issue trick indiehosters/piwik#4Finally i get an error with the cron container: [<-CODE->] Any advice to solve it. Maybe i could simply remove the cron container .
[2016-05-14 02:07:25] <dominicphillips> Hey, sorry for the noob question: Trying the osx beta for the first time, when I forward port 80 can I access it on localhost:80 ?
[2016-05-14 02:14:18] <dominicphillips> Cool its working :)
[2016-05-14 19:30:52] <soapoperator> Hello another similar question: if i start a nginx container,  could i get a conflict with the classic installation of nginx with the port 80 or 443?
[2016-05-14 20:59:06] <jpapejr> soapoperator: yep
[2016-05-14 21:07:39] <soapoperator> jpapejr: so i have to remove the classic nginx... Or change the docker nginx port,  or use another container ? It is not easy to switch multi apps in prod to docker.
[2016-05-14 21:07:56] <soapoperator> Thank you for the answer.
[2016-05-14 22:35:55] <jpapejr> soapoperator: in prod you'd probably let docker pick the port when you start the container and use a proxy (nginx or haproxy) to route traffic to the nginx containers. or maybe thisisyour proxy container? But yeah, you'll have to swap some ports around if you have nginx going on the docker host already. Or bind to another host ip, if multi homed.
[2016-05-15 08:04:25] <cristim> soapoperator: you can also keep the nginx on the same port, and have docker map that port to another port on the host machine. [<-LINK->] 
[2016-05-15 14:03:59] <chrisber> Runningi386/ubuntu:latestonubuntu 16.04throws errorTemporary failure resolving  archive.ubuntu.comanyone knows how to solve it.
[2016-05-15 14:05:41] <chrisber> Also tools likepingandnetstat,ipifconfigare not available
[2016-05-15 14:08:44] <aios> hi all
[2016-05-15 14:08:54] <aios> any body can explain how works nginx-proxy
[2016-05-15 15:01:36] <igladun> Hello
[2016-05-15 15:02:07] <igladun> How to set tags for node duringdocker-cloud node byo? Thanks
[2016-05-15 16:36:46] <thohal> chrisber: as a workaround you can make use of the hostsfile... Something like should do the trick...echo -en "91.189.91.26 archive.ubuntu.com" >> /etc/hosts
[2016-05-15 18:23:02] <lukaville> Hi! Is there any ways to automatically run one specific container (in my case - consul registrator container) on each swarm node with docker compose?
[2016-05-15 18:30:10] <lukaville> Something like deploy strategy daemon in kontena: [<-LINK->] 
[2016-05-15 18:43:53] <thohal> lukaville: Yes, docker has restart policies such asdocker run --restart=alwaysthat will handle this. This is also available in the compose.yml config file asrestart: always
[2016-05-15 18:59:22] <chrisber> thohal: thanks ,  unfortunately it doesn't work, docker run --privileged works but not  with docker build -t :(
[2016-05-15 19:01:24] <lukaville> thtoal: Thanks, but it's not what I am looking :( I want to run one container on each node. Here I have founded [<-LINK->] a bit hacky method (using negative affinity + docker-compose scale to the # of cluster nodes)
[2016-05-15 21:04:39] <thohal> @lukaville If i got you right, you are looking for some kind of "global scale option" for your docker boxes to spread your load... There are several tools with global scheduling options out there, like flocker, rancher, dcos, kubernetes, mesos $whatever.. No idea, how "enterprisey" your current setup is looking, but lazy guys make use of the init-system and call their compose-cmd.. [<-CODE->]  [<-CODE->]  [<-CODE->] So - choose your weapons first :-)flocker seems well integrated into docker, is pretty easy to setup and should be a good enough as a starting point.. [ 1 ] is a worth read. Many cool kids use kubernetes, while we\'re using rancher for decades. rancher supports kubernetes, swarm or cattle as cluster scheduler, ship their own "compose" implementation, which was enriched with hotness and has some quite impressive features/concepts like the "global service" [2], which could be translated into Always run one instance of this container on every host And finally some of our customers preferred dcos, which was open sourced in the meanwhile and they seem happy too....https://clusterhq.com/2016/03/09/fun-with-swarm-part1/\nhttp://docs.rancher.com/rancher/latest/en/rancher-compose/scheduling/#global-service\nhttps://dcos.io/
[2016-05-16 07:45:05] <pdonorio> thohal: that is very interesting and informative, thanks for writing!
[2016-05-16 10:58:43] <hameedullah> thohal: thanks for the detailed information on this. a non docker question: is there any way in gitter where we can mark msgs? like a favorite or star thing?
[2016-05-16 11:09:02] <leon> with a docker-compose.yml file, can I somehow disable a service with an environment variable?My setup is, I’ve got a couple of spring boot micro services in a development setup. and sometimes I want to be able to run on of the services with intellij idea instead of launching the service via docker. But at the moment, i need to comment out the service from the docker-compose.yml file which doesn’t seem right.Any suggestions?
[2016-05-16 11:12:20] <aleksandarbasara> I am running Rails 4.2.6 with an Ruby.2.2.3 Image and have issues to install npm for bower. (npm: not found) How can I setup my Dockerfile build with npm and bower?
[2016-05-16 22:38:41] <gnomonunes> Hi, I want to run a Docker container with a user that have fewer privileges than root, but without adding user creation commands to the Dockerfile. Is there some documentation about the best practices regarding that matter?
[2016-05-16 22:41:15] <uptownhr> i'd like to know this as well :)
[2016-05-17 00:07:56] <timcharper> gnomonunes: look at the grafana docker image, which runs the process as non root using gosu
[2016-05-17 00:48:51] <gnomonunes> I'll take a look@timcharper, thank you.
[2016-05-18 10:58:04] <chmandrade>  [<-LINK->] 
[2016-05-18 11:51:16] <roblundiehill> Hopefully this isn\'t totally the wrong forum for this (please suggest one if not). I need a quick way to test that internet connectivity from docker containers is working.  I\'m creating a system that needs to be deployable on an assortment of awkward platforms like OSX / Windows, running docker over whichever VM, where the host is often infested with routing-table-scrambling VPN crapware, Cisco I\'m looking at you). Even a simple "ping some well-known servers and quit, with error if they all fail" image would be enough, I\'ll create this if it doesn\'t exist already. I know I can\'t always work around the problem (in fact sometimes you need to rewrite your routing table after stopping VPN or just give up and reboot), but I want to be able to provide a meaningful error message.
[2016-05-18 13:40:16] <cristim> roblundiehill: you can ping 8.8.8.8, one of google's DNS servers
[2016-05-18 22:04:55] <timcharper> roblundiehill: I trust you know aboutdocker exec -it?
[2016-05-18 22:05:01] <timcharper> you can shell in to most containers that way
[2016-05-18 22:05:08] <timcharper> and possibly install thenet-toolspackage
[2016-05-18 22:07:31] <timcharper> I want to usedocker execto run some command in a running container, and I don't have aTTY. Apparently, without aTTY, there's no way to get the output. This seems like a frustrating limitation. Is this true?
[2016-05-18 22:08:41] <timcharper> docker exec -iwill keep outputting to STDOUT so long as STDIN is open. So, a really stupid workaround is to pipeyesinto it
[2016-05-19 07:29:05] <waghanza> hi all, i'm usingdockerto compile my apps. but sometimes apt-get failes (network unreacheable)
[2016-05-19 07:29:24] <waghanza> does something has the same problem ?
[2016-05-19 11:47:07] <vtajzich> Hi, I'm using docker beta for mac, wondering where are images physically stored?
[2016-05-19 11:52:33] <cristim> I'm not a mac user, but I guess you can see its open files  in lsof
[2016-05-19 12:10:36] <vtajzich> cristim: you're right!  it seems it stores it at ~/Library/Containers/com.docker.docker/Data/com.docker.driver.amd64-linux/Docker.qcow2
[2016-05-19 12:11:47] <cristim> vtajzich: I'm glad it worked
[2016-05-19 12:53:25] <Paul-Ascher> Hi I'm using docker beta for windows
[2016-05-19 12:53:52] <Paul-Ascher> Until some days ago it would not work while on a vpn
[2016-05-19 12:54:02] <Paul-Ascher> Now it does work
[2016-05-19 12:54:19] <Paul-Ascher> But my Vpn disconnects all the time
[2016-05-19 12:54:27] <Paul-Ascher> Any insights?
[2016-05-19 12:56:52] <Paul-Ascher> It's like it broke my ability to stay on my vpn
[2016-05-19 12:57:06] <vtajzich> no, I having issues with pulling from our private insecure registry.  VPN on mac works fine :-)
[2016-05-19 12:57:24] <Paul-Ascher> I use openvpn btw
[2016-05-19 12:57:31] <vtajzich> me too
[2016-05-19 12:58:12] <Paul-Ascher> It stopped working after I did a reboot
[2016-05-19 13:01:50] <vtajzich> using anyone docker beta for mac with private repo and vpn connection?
[2016-05-19 16:24:59] <Paul-Ascher> Sorry it was a false alarm, the issue was at my router
[2016-05-19 16:25:08] <Paul-Ascher> Von
[2016-05-19 20:02:59] <jzt> When I look at the contents of/var/lib/docker/image/aufs/distribution/v2metadata-by-diffid/sha256/5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef, I see a list of digests and associated source repositories for each image I have pulled. Every digest is the same,a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4- is this the sha256 sum of the “scratch” image?
[2016-05-19 20:50:22] <RaunoVV> RaunoVV: Hey guys, i have a serious problem, i'm using docker-gluster-plugin (to integrate glusterfs volumes with docker) it seems to work fine but with one specific container it won't mount it.Just getting this: docker: Error response from daemon: VolumeDriver.Mount: exit status 1.Any ideas how to debug it ?
[2016-05-20 03:52:44] <mysterytree> Is anybody here?
[2016-05-20 05:34:30] <xiaods> yeah
[2016-05-20 06:23:57] <Vergily> Hi, guys. I’m failing to dig out where to download docker for mac. Can anybody share a link or instructions where to get it? I want to give it a try
[2016-05-20 06:26:21] <vtajzich> Vergily: you can get it here [<-LINK->] , however you have to apply for beta access token
[2016-05-20 06:37:28] <sprasad18> hi,I'm having trouble installing Docker on RHEL 7.2Can some one help me please?
[2016-05-20 06:37:33] <sprasad18> thanks in advance
[2016-05-20 06:38:17] <sprasad18> [root@scsor0003442001~]# which curl/usr/bin/curl[root@scsor0003442001~]# sudo apt-get updatesudo: apt-get: command not found[root@scsor0003442001~]# curl -fsSL [<-LINK->] | sh [<-CODE->] 
[2016-05-20 06:50:00] <vtajzich> sprasad18: did you follow [<-LINK->] ?
[2016-05-20 07:04:26] <sprasad18> hi@vtajzichyes I tried the steps in the link [<-LINK->] 
[2016-05-20 07:04:28] <sprasad18> [root@scsor0003442001~]# sudo yum install docker-engineLoaded plugins: langpacks, product-id, search-disabled-repos, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.dockerrepo                                                                                                                                                                                                 | 2.9 kB  00:00:00Resolving Dependencies--> Running transaction check---> Package docker-engine.x86_64 0:1.11.1-1.el7.centos will be installed--> Processing Dependency: docker-engine-selinux >= 1.11.1-1.el7.centos for package: docker-engine-1.11.1-1.el7.centos.x86_64--> Processing Dependency: libltdl.so.7()(64bit) for package: docker-engine-1.11.1-1.el7.centos.x86_64--> Running transaction check---> Package docker-engine.x86_64 0:1.11.1-1.el7.centos will be installed--> Processing Dependency: libltdl.so.7()(64bit) for package: docker-engine-1.11.1-1.el7.centos.x86_64---> Package docker-engine-selinux.noarch 0:1.11.1-1.el7.centos will be installed--> Processing Dependency: policycoreutils-python for package: docker-engine-selinux-1.11.1-1.el7.centos.noarch--> Finished Dependency ResolutionError: Package: docker-engine-1.11.1-1.el7.centos.x86_64 (docker-main-repo)Requires: libltdl.so.7()(64bit)Error: Package: docker-engine-selinux-1.11.1-1.el7.centos.noarch (docker-main-repo)Requires: policycoreutils-pythonYou could try using --skip-broken to work around the problemYou could try running: rpm -Va --nofiles --nodigest[root@scsor0003442001~]#
[2016-05-20 07:15:17] <vtajzich> could you try uname -a ?
[2016-05-20 07:16:00] <sprasad18> [root@scsor0003442001~]# uname -aLinux scsor0003442001.xxxxxxxx. 3.10.0-229.el7.x86_64 [<-ISSUE->] SMP Thu Jan 29 18:37:38 EST 2015 x86_64 x86_64 x86_64 GNU/Linux
[2016-05-20 07:17:41] <vtajzich> follow this thread, it seems they’ve solved itdocker/docker#20484
[2016-05-20 07:19:11] <sprasad18> Thanks@vtajzich. check the link now
[2016-05-20 12:54:27] <otbe> Hi guys. If I'm using the remote API of docker and inspect an image. Is there any way to determine if it's dangling or not?
[2016-05-20 12:56:56] <otbe> Inspect by GET /images/{name}/json
[2016-05-20 22:10:55] <gsmoraes> Howdy. Is it possible to run the boot2docker distro on Azure (I guess they use Hyper-V)? I tried following the instructions toddthe contents of the ISO into a partition inside aVHDfile, and it works on Virtualbox, but I can't get it to boot on Azure (the portal doesn't give any logs or error traces, sadly).
[2016-05-21 14:18:47] <jondubois> In the Dockerfile, does theRUNinstruction execute inside the container (which is being created) or on the host machine?
[2016-05-21 14:19:52] <jondubois> So for example, do I need toCOPYsome files into the container's file system beforeRUNis invoked (performing some operation on these files) or should it be the other way round?
[2016-05-21 14:25:48] <gsmoraes> jondubois: RUNis invoked inside the container
[2016-05-21 14:28:47] <gsmoraes> So, if you want a specific file (or files, or directories) from yourcontext(the directory where you're runningdocker build, and its subdirectories ) to be copied to the container, so that you can use it inside the container during the build phase, you need toCOPYorADDthe file (or dir) before invokingRUNon it from inside the container.
[2016-05-21 15:44:29] <jondubois> gsmoraes: Thanks :) That was my initial interpretation but someone else on my team thought it was the other way around and that really confused me :p
[2016-05-21 15:45:11] <jondubois> Reading the Dockerfile specs it is a bit ambiguous I have to admit
[2016-05-21 15:48:54] <gsmoraes> jondubois: Yeah, sometimes the specs are confusing. Glad to help.
[2016-05-21 17:47:57] <gudron> Hi guys. Huston, i have a problem.I trying to makhuston, i have a probleme a docker container with cron.My docker file [<-CODE->] docker-entrypoint.sh: [<-CODE->] 
[2016-05-21 17:49:08] <gudron> ps aux [<-CODE->] 
[2016-05-21 17:50:48] <gudron> but Ctrl+C  is not working...anddocker stop- kill container by SIGKILL after 10 sec.
[2016-05-21 22:12:11] <thohal> hameedullah: i stumpled over gitter after installing Franz [meetfranz.com], so i'm completly new to gitter and slack (what the***is it good for?)... sorry, but what about the folks in here? any advice forhighlightning my messageswould be helpful :-)
[2016-05-21 22:31:12] <thohal> @gudron Houston here :-) Just guessing, since you obfuscated the content of the *task-files.... Maybe you just forget the leading /bin/$whatever_shell_u_r_using? What does does a simple [<-CODE->] relative to your Docker-Builddir return? What about adding something like [<-CODE->] into your crontab-entries?
[2016-05-22 12:55:16] <gudron> @thohal cron-tasks works fine. i checked it.in docker logs [<-CODE->] cron process is immortal (((
[2016-05-22 15:44:41] <soapoperator> Heelo, i try to use docker-compose on a fresh ubuntu server... I try to install nginx with php-fpm for a static site but i constantly get an error:ERROR: for web  rpc error: code = 2 desc = "oci runtime error: could not synchronise with container process: not a directory". What could be wrong with my config [<-CODE->] 
[2016-05-22 23:05:33] <uptownhr> when are you getting this error
[2016-05-22 23:21:45] <Risto-Stevcev> how are you supposed to use volumes indocker-compose?
[2016-05-22 23:22:38] <Risto-Stevcev>  [<-CODE->] 
[2016-05-22 23:23:12] <Risto-Stevcev> I rundocker-compose upand there's nothing in the/srcdirectory, even though./srccontains files on the host
[2016-05-22 23:24:28] <Risto-Stevcev> docker inspectshows"Volumes": nullunder network settings
[2016-05-22 23:25:18] <Risto-Stevcev> I tried absolute paths for./srctoo and it still didn't work. I can't find much on this issue except  this: [<-ISSUE->] 
[2016-05-22 23:33:43] <uptownhr> what os are you on?
[2016-05-23 00:07:03] <Risto-Stevcev> arch linux
[2016-05-23 00:07:15] <Risto-Stevcev> I found this [<-LINK->] 
[2016-05-23 00:07:34] <Risto-Stevcev> Which helped me backtrack my steps
[2016-05-23 00:07:56] <Risto-Stevcev> I'm still in the process I'll update where I found the mistake
[2016-05-23 02:24:47] <Risto-Stevcev> got it to work finally...
[2016-05-23 02:38:48] <Risto-Stevcev> There were a lot of things that went wrong. I spend a decent amount of time on the docs, but I never found anything on a bunch of stuff I spent a couple hours discovering
[2016-05-23 02:39:34] <Risto-Stevcev> Like how the cache will sometimes not detect changes that I made, and so wouldn't update -- spent a long time with this one. I eventually had to dodocker-compose build--no-cacheto make sure it's fine
[2016-05-23 02:40:41] <Risto-Stevcev> Or how ./web:/web actually maps to/usr/src/webinstead of/webon the docker instance. Nowhere did I find this on the multiple pages of docker volume docs I read
[2016-05-23 02:41:27] <Risto-Stevcev> Or that volumes aren't available at build time, and that you have to copy whatever you need as an initially bootstrap usingCOPYin your Dockerfile
[2016-05-23 02:41:48] <Risto-Stevcev> Oh well, it was worth it though. Learned a lot
[2016-05-23 02:43:47] <Risto-Stevcev> Docker-compose is still really new though, so I wouldn't expect the docs to be all there anyway. But it's awesome enough that it was worth itt
[2016-05-23 03:43:15] <soapoperator> uptownhr: i get this error afterdocker-compose up -d
[2016-05-23 03:45:02] <sprasad18> (Replying to an old query)Thanks@vtajzich [<-ISSUE->] - this thread helped me fix my issue.i'm able to install & start using docker now
[2016-05-23 04:39:36] <uptownhr> are you able to show the entire output?
[2016-05-23 05:07:01] <RaunoVV> Hey does anyone have experience with docker glusterFS plugin?
[2016-05-23 05:07:18] <RaunoVV> I'm running into some anomalies
[2016-05-23 05:21:48] <soapoperator> @uptownhrFinaly, i get it works: i add the file nginx.conf before i run docker-compose with: [<-CODE->] Unfortunaltly i get an ERR_CONNECTION_CLOSED when i get the url. But i guess it's an error in my nginx configuration.
[2016-05-23 05:44:03] <soapoperator> If i run another docker-compose.yml with another nginx.conf (for another domain but on the same port 80/443), do i have a conflict between the nginx.conf?
[2016-05-23 17:39:49] <graingert> does anyone know a workaround for [<-ISSUE->] ?
[2016-05-23 17:40:10] <graingert> the build cache now cannot be shared between CI nodes
[2016-05-23 17:40:21] <graingert> and so it results in hour long builds
[2016-05-23 22:29:05] <d3cay1> does anyone know of a way to provide access to a local host resource (in this case a database running on the actual host and not in a container) to a docker container running via docker-machine which is being setup using docker-compose?
[2016-05-23 22:42:10] <d3cay1> I found a similar unanswered question in the forums: [<-LINK->] 
[2016-05-23 22:44:56] <ccit-spence> where is a good place for getting support adding a node to docker cloud?
[2016-05-24 16:38:23] <graingert> can you run docker 1.11 images on docker 1.9 ?
[2016-05-24 16:38:38] <graingert> (Building 1.11 on Bamboo deploying on Amazon elastic beanstalk)
[2016-05-24 19:35:12] <soapoperator> Hello, with docker-compose, i get an errorfailed: port is already allocated, isn't it normal to use the same port if i connect multi app to nginx container?
[2016-05-24 20:44:43] <otbe> soapoperator: do you useportswithin your compose file?
[2016-05-24 21:14:42] <soapoperator> otbe: yes i use for my basic static site: [<-CODE->] 
[2016-05-24 21:15:47] <otbe> soapoperator: so on this host there will be only one web container...
[2016-05-24 21:17:03] <soapoperator> for my second confi with mysql i use ports also : [<-CODE->] 
[2016-05-24 21:18:14] <soapoperator> otbe: i just use web (nginx with ports) + php (fpm) for this first host
[2016-05-24 21:19:10] <otbe> soapoperator: you need a load balancer in front of this two services
[2016-05-24 21:21:06] <soapoperator> otbe: ok, i am just starting to learn about docker, step by step, i will investigate in this way
[2016-05-24 21:21:21] <otbe> problem is: bothwebcontainers try to use port 80/443 on the same host
[2016-05-24 21:23:01] <soapoperator> yes , it's a concept i didn't understand well, i have in mind, the same container was used for all the config... Sorry
[2016-05-24 21:55:02] <kandarpdesai_twitter> Hello ! I am new to docker and want to know if anyone using docker to host micro-services on AWS in production environment . If yes, how is the experience so far ? Overcoming basic challenges such as networking, etc ?Any tools suggestion. I read many articles and forums though I want to hear from personal experience.  Thanks.
[2016-05-25 08:01:29] <cristim> we're still preparing for that but running it for build and dev environments for a year now and it's quite nice
[2016-05-25 08:04:34] <cristim> on the prod env we're building we try to keep networking simple, but we do use consul, a custom wrapper on top of ECS , as well as some custom nginx-based reverse proxies that are added to the ELB and then they point to our containers based on consul service definitions.
[2016-05-25 08:05:49] <cristim> but I expect ECS to eventually make most of that reduntant at some point
[2016-05-25 12:57:55] <JnMik> soapoperator: You can have multiple container on the same host exposing the same port (exemple having 4-5 containers with web server inside exposing port 80), but on the host you have to bind all these 80 ports to different ports.
[2016-05-25 13:02:09] <JnMik> kandarpdesai_twitter: I've been using Google cloud instead of AWS, with Kubernetes built-in. Really easy to get running because you can pop VM already ready for containers with Kubernetes installed. There's an additionnal fee tho. I've built a kubernetes cluster locally at home as well and it's not very difficult. The documentation is a bit outdated so sometimes you try something in a doc that doesn't work, but you end up finding what you want somewhere on the net :P
[2016-05-25 14:56:18] <kyptin> Howdy folks. I\'m trying to mount a volume in docker, and it\'s silently failing to do so. I wanted to check to see if I\'m missing something obvious. Here\'s my command and the ensuing output: [<-CODE->] If this shouldn\'t work, what am I doing wrong? If it should work, is there some way I can get more information about what\'s going on, like a debug flag or something? Thanks for the help!(I\'m running this command on FreeBSD, whose docker support is allegedly "experimental". So that may be the problem. I just want to be sure I\'m not doing something wrong.)
[2016-05-25 15:04:20] <rkgade> No @kyptin . I can\'t see anything that you might have done in a wrong way.Works for me on Cent OS:[rkgade@docker-machine temp]$ docker run --volume "$PWD":/mnt/dummy_folder centos:latest ls /mnt/dummy_folderdm.no_warn_on_loop_devices=true` to suppress this warning.hi[rkgade@docker-machine temp]$
[2016-05-25 15:05:39] <rkgade> Sorry,[rkgade@docker-machine temp]$ lshi[rkgade@docker-machine temp]$ docker run --volume "$PWD":/mnt/dummy_folder centos:latest ls /mnt/dummy_folderhi[rkgade@docker-machine temp]$
[2016-05-25 15:05:49] <kyptin> OK, thanks for checking me,@rkgade. It must be something with FreeBSD then. Thanks!
[2016-05-25 15:06:28] <rkgade> But the container you are trying to mount to is a cent OS container.
[2016-05-25 15:07:18] <kyptin> Right, but my host OS is FreeBSD. I'm guessing it's a problem with FreeBSD's docker support, but who knows!
[2016-05-25 15:10:35] <rkgade> Yeah. Only docker folks can answer that.
[2016-05-25 15:11:35] <kyptin> Well, I'm asking now on#freebsd-dockeron freenode. Perhaps they'll have an answer. Anyway, thanks for your help!
[2016-05-25 15:13:58] <rkgade> Ok. I too shall try and look up. Welcome buddy, always.Anyone running FreeBSD on host, please try answer this.
[2016-05-25 15:17:31] <JnMik> kyptin: Does it work if you run the container with --privileged=true?
[2016-05-25 15:17:52] <JnMik> Not recommanded, but just curious
[2016-05-25 15:19:18] <kyptin> JnMik: - Good idea, but alas, that doesn't change anything.
[2016-05-25 15:19:23] <rkgade> @kyptinYou can also try mounting under a non privileged directory, try /home/dummy.@JnMikgood point. might be privilege issue.
[2016-05-25 15:20:11] <JnMik> I had problem like this on centos host because of Selinux
[2016-05-25 15:20:30] <kyptin> rkgade: - Another good idea, but that didn't help either.
[2016-05-25 15:20:34] <JnMik> Running chcon -Rt svirt_sandbox_file_t /path/to/file.ext  on the local file fixed my things
[2016-05-25 15:21:11] <JnMik> but running as privileged fixed the selinux problem I think (been a while, i'm not sure)
[2016-05-25 15:21:53] <kyptin> I don't have achconbinary available (and I've never seen that command), so I can't try that. But interesting!
[2016-05-25 15:22:08] <rkgade> JnMik: Yes. running as privileged would bypass Selinux.
[2016-05-25 15:35:52] <InfoSec812> Hi all, have a weird issue since upgrading from 1.9.1 to 1.11.1... We use BTRFS on CentOS 7. When I initially performed the upgrade, I had issues with some of our images and with docker not starting, so I cleaned out the/var/lib/dockerdirectory. Now, one of my containers is referencing a BTRFS subvolume which does not exist and I cannot figure out how to remove that reference. I've tried usingdocker rmito remove all containers which reference that subvolume, but when I rebuild the container the reference returns?!?!? Any help would be MOST appreciated!
[2016-05-25 16:22:27] <rkgade> InfoSec812: did you migrate using migration tool ?
[2016-05-25 16:41:11] <kyptin> rkgade: ,@JnMik- To follow up, I figured out my problem. FreeBSD's docker doesn't currently support volume mounting. If you're interested: [<-LINK->] 
[2016-05-25 16:41:51] <JnMik> kyptin: Good to know thx !
[2016-05-25 16:42:37] <JnMik> I would not use it then lol
[2016-05-25 16:43:08] <kyptin> Heh, yeah, that's a pretty big feature to miss out on!
[2016-05-25 16:43:18] <rkgade> Ha.@kyptinGood to know. thanks. But then the error msg should have been different. If a tag is not supported, container shouldn't get started.
[2016-05-25 16:43:34] <rkgade> Please check if container got started or not. I believe it would have started.
[2016-05-25 16:44:16] <kyptin> It did start, for sure. I can fire up a shell in an interactive session even when I specify a--volumeoption. No error message or anything which is definitely not ideal.
[2016-05-25 16:45:09] <rkgade> Yes.@kyptin. Please raise it in issues at docker repo. Team shall get back to you on it.
[2016-05-25 16:58:29] <kyptin> rkgade: - Is that the appropriate place? I was thinking it was more an issue for the FreeBSD team to resolve, rather than the docker team.
[2016-05-25 16:59:23] <rkgade> Does docker has a separate team/forum for FreeBSD ?@kyptin
[2016-05-25 17:00:06] <kyptin> It would appear so, yes: [<-LINK->] 
[2016-05-25 17:01:29] <rkgade> That should help.
[2016-05-25 17:06:57] <bwoodlt> Hi Guys. I'm having trouble using nginx redirect in my docker container - I'm using '' in my server_name, e.g server_name:.example.com, this makes it return 404 by showing ' [<-LINK->] . Please assist where I'm missing something. Thanks alot.
[2016-05-25 17:09:34] <JnMik> bwoodlt: If you want to make sure servername is really your issue, use the wildcard characterand see if it works
[2016-05-25 17:09:51] <JnMik> wildcard == underscore (gitter strip it from the chatbox)
[2016-05-25 17:12:00] <bwoodlt> so it'll be something like '_.example.com' rather than '*.example.com' in server_name block?@JnMik
[2016-05-25 17:12:30] <JnMik> bwoodlt: I would run a test with only an underscore
[2016-05-25 17:12:34] <JnMik> remove .example.com
[2016-05-25 17:14:21] <JnMik> I believe the asterix can be use, see examples here [<-LINK->] 
[2016-05-25 17:15:49] <bwoodlt> OK thanks@JnMik
[2016-05-25 17:16:38] <bwoodlt> Just checking
[2016-05-25 17:23:27] <bwoodlt> Thanks. I just manually enter the url i need to capture e.g example.com, [<-LINK->] and that works@JnMik
[2016-05-25 17:24:37] <JnMik> bwoodlt: great :)
[2016-05-25 17:26:01] <bwoodlt> Much appreciated!
[2016-05-25 17:45:09] <kandarpdesai_twitter> JnMik: make sense. We have locked into AWS. So, I am trying to understand pro/cons etc in production. I have read many articles. But, handful mentions running in production succesfully with complex networking. I want to use my existing mesos+marathon to control containers. But, facing some questions related to aws networking schema
[2016-05-25 17:47:07] <kandarpdesai_twitter> cristim: Based on what read using Docker swarm or Mesos+Marathon is recomended over ECS. Don’t have personal experience
[2016-05-25 17:47:44] <JnMik> kandarpdesai_twitter: We never played with Mesos & marathon where I work, my collegue had fun with OpenShift and some python docker-py component to control each node individually, On my end I played with Swarm and Kubernetes and ended up using kubernetes at home.
[2016-05-25 17:47:49] <JnMik> You ain't lucky on this one xD
[2016-05-25 17:48:14] <JnMik> Sorry, good luck !
[2016-05-25 17:49:20] <kandarpdesai_twitter> JnMik: Thanks. Let’s see how the experiment will go
[2016-05-25 17:50:48] <JnMik> I know Openshift had complex networking, kubernetes was pretty easy tho. I think this was the tutorial I followed [<-LINK->] 
[2016-05-25 17:51:24] <JnMik> Maybe there was some stuff that I needed to lookup the web, but it wasn't too much difficult ;)
[2016-05-25 17:51:54] <kandarpdesai_twitter> JnMik: You used cloud based registry or hosted your own private repo
[2016-05-25 17:52:37] <JnMik> kandarpdesai_twitter: Did both, but cloud based on google cloud, with "container engine", kubernetes is already ready to go, very simple
[2016-05-25 17:52:55] <JnMik> The doc I gave you would not be necessary if you use google container engine
[2016-05-25 17:53:46] <JnMik> But you still have to ask yourself if you want to use a 3-party container orchestration tool, that might not be updated as frequently as docker swarm, the native product of Docker team.
[2016-05-25 17:54:07] <kandarpdesai_twitter> JnMik: got it. Thanks. Let me go through it. Yes. AWS is similar. if you use their ECS, everything comes as bundled. Though I already have mesos running and want to use it if possible
[2016-05-25 17:54:08] <JnMik> You need to consider pros / cons ;)
[2016-05-25 18:32:26] <sbromberger> Hi all
[2016-05-25 18:33:01] <sbromberger> I’m running the beta for OSX behind a transparent SSL proxy that MITMs our connections. How do I get docker to disregard certificate errors?
[2016-05-25 19:40:21] <rkgade> kandarpdesai_twitter: Mesos+Marathon will help you deploy your frameworks/applications on Docker. However, no matter what orchestration tool you use, as long as you are running containers, it wouldn't make much difference. However, with Kubernetes and Oenshift,
[2016-05-25 19:40:39] <cristim> We actually started with mesos/marathon initially but it turned out to have some issues and it was dropped so we ended up with ECS nowadays.
[2016-05-25 19:43:16] <cristim> We have a pretty nice integration of consul and ECS, maybe it will be open sourced at some point
[2016-05-25 19:43:49] <rkgade> kandarpdesai_twitter: Mesos+Marathon will help you deploy your frameworks/applications on Docker. However, no matter what orchestration tool you use, as long as you are running containers, it wouldn't make much difference. However, with Kubernetes and Openshift, management of thousands of containers becomes easy. That is where Kubernetes and Openshift help. However, Mesos+Marathon was basically not designed to work as container orchestration but as framework/application orchestration across data center.  So, you cannot directly compare Mesos+Marathon with Swarm or Kubernetes. If the question is between Swarm and Kunernetes, I would go for Kubernetes. Though Swarm is a native docker one, Kubernetes orchestration is better.
[2016-05-25 19:45:55] <rkgade> cristim: yes. Orchestration is still O.K but Recovery of nodes with Mesos+Marathon has issues.
[2016-05-25 19:47:38] <kandarpdesai_twitter> rkgade: Thanks for detailed explanation. we are going to have hybrid stack where few services will use containers and few won’t. I heard that Kubernetes is preferred only if you are using google stack . It sounds like not the case based on your comment
[2016-05-25 19:53:34] <rkgade> kandarpdesai_twitter: no. Definitely not. You can have a local deployment of Kubernetes and scale it your way. Kubernetes with its pod service and route design can help you manage containers very well. Even OpenShift is designed leveraging Kubernetes and Docker. The orchestration style of OpenShift is that of Kubernetes, just that it filled in more white spaces of Docker and Kubernetes.
[2016-05-25 19:55:08] <rkgade> But as@JnMikmentioned, Kubernetes is integrated and you just have to use it, with GCE, hence people prefer it that way.
[2016-05-25 20:46:57] <swade1987> is anyone able to help me with my consul server cluster setup?
[2016-05-25 21:15:09] <soapoperator> JnMik: thank you for the tip, i use "8050:80" and the container were build without error. Unfortunatly now i get an error with the ssl config: the error said that the certif from the other container which is loaded... Still investigating...
[2016-05-25 21:27:49] <soapoperator> Actually, i didn't add port for 443?
[2016-05-26 10:56:10] <rubycrafter> Hi everyone.May someone please explain me, what for docker creates second interface, something like br-c14775b71e0f?
[2016-05-26 10:56:25] <rubycrafter>  [<-CODE->] 
[2016-05-26 10:57:54] <rubycrafter> It prevents me to use the internal network of the company.
[2016-05-26 11:18:00] <gwmoura> rubycrafter: docker create this interface for security. To provide complete isolation for containers. You don't use internal company network because the br-c1... interface?
[2016-05-26 11:19:18] <rubycrafter> br-c14775b71e0f use inet addr:172.17.0.1, it broke internal network for me)
[2016-05-26 11:20:08] <gwmoura> You can try change this ip, I'm gonna find a solution for you test
[2016-05-26 11:21:21] <rubycrafter> gwmoura: , thanks a lot!)
[2016-05-26 11:23:06] <rubycrafter> fyi, I alredy have some workaround for this problem: [<-CODE->] It works with docker0 interface, but doesnt with br-halabalala
[2016-05-26 11:31:23] <gwmoura> rubycrafter: you tryed add this flag:--fixed-cidr=CIDR
[2016-05-26 11:31:47] <gwmoura>  [<-LINK->] 
[2016-05-26 11:46:31] <rubycrafter> I have... A lot of problems now) How can I purge docker configs?)) [<-CODE->] I dont know how to reset it... [<-CODE->] Its totally broken.
[2016-05-26 11:49:21] <gwmoura> This occour some times
[2016-05-26 11:49:34] <gwmoura> You add your user in docker group?
[2016-05-26 11:50:22] <gwmoura> When you restart a docker service some problem is showed?
[2016-05-26 11:51:25] <rubycrafter> Yes, I added. No, nothing shows: [<-CODE->] 
[2016-05-26 11:53:04] <gwmoura> Add this in your /etc/default/docker
[2016-05-26 11:53:11] <gwmoura> DOCKER_HOST="/var/run/docker.sock"
[2016-05-26 11:53:41] <gwmoura> Restart the docker service
[2016-05-26 11:55:06] <rubycrafter> OK, docker resurrected when i returned [<-CODE->] 
[2016-05-26 11:55:36] <rubycrafter> But i still have 3 br-... interfaces)
[2016-05-26 11:55:52] <rubycrafter>  [<-CODE->] 
[2016-05-26 11:59:42] <gwmoura> rubycrafter: I think you will go to create your custom interface. First Try remove all br-* interface
[2016-05-26 12:00:26] <gwmoura> Add the line in your/etc/default/docker
[2016-05-26 12:00:39] <gwmoura> Restart the docker service
[2016-05-26 12:01:10] <rubycrafter> gwmoura: , what line? -)
[2016-05-26 12:02:11] <gwmoura> DOCKER_HOST="/var/run/docker.sock"
[2016-05-26 12:03:07] <rubycrafter> br-* interfaces resurrects with docker restart.
[2016-05-26 12:04:49] <gwmoura> All 3  ? After you remove?
[2016-05-26 12:06:52] <rubycrafter> yep
[2016-05-26 12:09:44] <gwmoura> You addes a flag --fixed-cidr?
[2016-05-26 12:11:30] <rubycrafter> Yes, no changes, still 3 br-...
[2016-05-26 12:13:59] <gwmoura> rubycrafter: I don't has how to simulate your problem now...
[2016-05-26 12:16:23] <rubycrafter> Few days ago I installed flocker, maybe it is the problem.So, is there really no way to reset docker configurations to default?)) Reinstall gives nothing.
[2016-05-26 12:16:30] <gwmoura> But I think this problem can be resolved in this way
[2016-05-26 12:18:51] <gwmoura> Read this docs - [<-LINK->] 
[2016-05-26 12:24:10] <rubycrafter> gwmoura: , I'm reading it right now) But looks like I have not enough network skills to understand everything.  Anyway, thank you!)
[2016-05-26 12:26:36] <gwmoura> Rsrsrsrs normal, when i simulate your problem, return with a solution
[2016-05-26 12:37:59] <rubycrafter> This bridges creates by docker-compose
[2016-05-26 12:42:47] <JnMik> soapoperator: Yeah you would need to map it in your docker-compose.yml file, but also the Dockerfile on your would need to EXPOSE it.
[2016-05-26 17:56:34] <bala-v> I am wondering if you could give me some pointers on a docker issues that I am facing. I am trying to increase the default fs size for containers created on OEL 7.1/docker 1.6.1 combination. I have tried settingDOCKER_STORAGE_OPTIONS= --storage-opt dm.basesize=20Gin /etc/sysconfig/docker-storageand also followed the instructions on the below link for reseting the sparse file sizehttps://jpetazzo.github.io/2014/01/29/docker-device-mapper-resize/but even after the above, my 'docker info' is showing 'Data Space Total: 107.4 GB’ and new container’s default size is 10G. Any pointers?.
[2016-05-26 20:15:29] <swade1987> hey all
[2016-05-26 20:15:41] <swade1987> is there a recommend way to setup swarm with consul?
[2016-05-26 20:15:54] <swade1987> currently i have 3 EC2 hosts each running a consul container
[2016-05-26 20:15:57] <swade1987> these are clustered
[2016-05-26 20:16:06] <swade1987> should swarm be clustered
[2016-05-26 23:18:05] <dissipate> swade1987: swarm uses consul to set up its clustering
[2016-05-27 06:48:43] <otbe> swade1987: if you meanswarm manageryes they should be replicated for HA
[2016-05-27 12:17:32] <rkgade> Hi All, any best practices to get Docker into production? We are planning to set up.
[2016-05-27 12:17:46] <rkgade> Any pointers/suggestions are much appreciated.
[2016-05-28 17:12:04] <zhongdj> Hey Guys, I met a troubles while seting up Percona on CentOS 7’s docker environment, i tried too much effort, and still got no idea, i posted the issue on [<-LINK->] Is here the correct place to find help?
[2016-05-29 08:08:38] <rkgade> Hi Team, unable to mount windows Drive in Docker Containers for Beta trial of Windows.
[2016-05-29 08:09:14] <rkgade> The moment I click apply after checking the checkbox for C dirve, it goes into "not responding" state. Any pointers?
[2016-05-29 09:02:35] <rkgade> Posted at [<-LINK->] .
[2016-05-29 10:30:52] <rkgade> Resolved. Had to start sharing service from Windows. Was confused as this wasn't mentioned in the documentation.
[2016-05-30 14:28:36] <fiunchinho> if your Dockerfile usesFROM some_image, Docker will download the latest version ofsome_image, but if new versions ofsome_imageare released, your Docker image won't get these versions unless manually executingdocker pull some_image
[2016-05-30 14:28:47] <fiunchinho> any solution for this?
[2016-05-30 14:29:38] <fiunchinho> even though I use an specific version likeFROM some_image:3, if the maintainers push patches to the3tag, I won't get them
[2016-05-30 14:29:47] <gilacost> fiunchinho: Como estas?
[2016-05-30 14:30:10] <gilacost> Has probado :latest?
[2016-05-30 14:31:28] <fiunchinho> yep, I've triedlatestbut all tags work the same way: if that tag already exists locally, Docker won't check for new updates for that tag when referring to it in a Dockerfile
[2016-05-30 17:29:42] <snario> Is there any easy way to include.gitin.dockerignorebut .. somehow .. be able to get the latest commit inside a docker container?
[2016-05-30 17:29:57] <snario> (perhaps ignoring the minimal amount of stuff)
[2016-05-30 21:26:33] <dimitrieh> does somebody know how to apt-get install "stretch" debian packages ?
[2016-05-30 21:26:55] <dimitrieh> those are the not yet stable declared packages
[2016-05-31 02:05:47] <ellerbrock> dimitrieh: you can change your apt.conf file and change there for example to testing
[2016-05-31 02:06:25] <ellerbrock>  [<-LINK->] 
[2016-05-31 08:14:59] <dimitrieh> thanks!
[2016-05-31 17:02:28] <danielbucher> Hi guys, is there a community standard for portforwarding exposed ports to the host machine for docker-machine users? I'd like to be able to access the application with localhost:<port> since the app is configured to use localhost to comunicate with other serviced in the development environment. I've seen many solution, but I'd like to know if there's one that's best accepted by the community.
[2016-05-31 19:24:24] <tuxity> Ohai ! Quick question, in my Dockerfile I'm downloading something that can take a little while,  it works when I rundocker buildbut when I push to git and the build on docker is triggered, it looks like the container build can't download it for some reason
[2016-05-31 19:25:22] <tuxity> What I'm missing ? should I create a repo where I push an image than running an automated build repo ?
[2016-06-01 06:05:20] <aohorodnyk> hi all
[2016-06-01 06:14:46] <aohorodnyk> I have links between containers in docker-compose.yml file [<-LINK->] but after docker-compose up I don\'t getting any information about linked containers (env variables, cant ping by hostname, etc...) also when I wrotedocker inspect nginx_letsencrypt_1I got"Links": nulland don\'t see any mention about linked container
[2016-06-01 07:52:02] <StephenLee1985> bulid only  in agent?  v0.5
[2016-06-01 09:33:39] <aohorodnyk> ping hostname was fixed by shared network between containers, but I don't know how to share env variables
[2016-06-01 10:02:18] <swade1987> can anyone help me with this - [<-LINK->] 
[2016-06-01 10:02:29] <swade1987> swarm thinks the node is pending
[2016-06-01 10:21:41] <swade1987> swarm can't find the images on docker hub, even though they exist
[2016-06-01 11:27:30] <DominicBoettger> How can i remove a volume on commit? I only found a way to add volumes
[2016-06-01 11:43:15] <AbdullaM5> Hi there! How can I remove all volumes data from docker containers? I’m using Docker mac
[2016-06-01 12:15:49] <aohorodnyk> AbdullaM5: docker volume ls?
[2016-06-01 12:28:50] <AbdullaM5> it gives me a huge list of volumes
[2016-06-01 12:29:58] <aohorodnyk> In my case I got volume with namecontainername_data
[2016-06-01 12:31:34] <AbdullaM5> aohorodnyk: finddocker volume rm, will try it. Thanks )
[2016-06-01 12:47:43] <aohorodnyk>  [<-LINK->] 
[2016-06-01 13:26:43] <gkapkowski> Hello, can anyone tell me if i can create a network configuration in docker that will use one container as a source of internet connection. The situation is that I have RaspberryPi with docker running and application container, but internet is provided either by ethernet cable, wifi, or ppp connection. so I want to create a container that would abstract the source of the internet and just set the network to use proper interface, so the other containers would not have to worry about it.   Actually I have no idea where to start looking so any pointers are appriciated.
[2016-06-01 14:47:09] <StephenLee1985>  [<-LINK->] 
[2016-06-01 14:47:50] <StephenLee1985> there are no logs for build
[2016-06-01 14:48:12] <StephenLee1985>  [<-LINK->] 
[2016-06-01 14:49:43] <StephenLee1985>  [<-LINK->] 
[2016-06-01 14:50:29] <StephenLee1985>  [<-LINK->] 
[2016-06-01 19:07:04] <chahn1138> why would this run not yield a running container:docker run -d --name=contname  -p 3306:3306 mysql:5.6(Believe me: mysql did not need a long-running command before...and trying to add one did nothing)
[2016-06-01 19:21:45] <swade1987> can i ask a docker-compose via swarm question?
[2016-06-01 19:22:59] <swade1987>  [<-LINK->] 
[2016-06-01 19:24:16] <swade1987> it works fine for the first deploy
[2016-06-01 19:24:23] <swade1987> however the second deploy, this happens - [<-LINK->] 
[2016-06-02 11:47:10] <nite> hey - I'd like to spin up a spark cluster using docker - ie across multiple machines - is this possible? (can spin up the machines using vagrant, and they're on an esx server in-house)
[2016-06-02 17:43:25] <tuxity> It's possible to download something when building an image in docker hub ?
[2016-06-02 17:43:37] <tuxity> I've an error, like there is no network
[2016-06-02 18:17:47] <rchodava> chahn1138: you'll probably be able to get an error in the logs for the container?
[2016-06-02 18:20:25] <rchodava> Tuxity: you can download while building to make it part of the image, and then can push to docker hub - what do you mean?
[2016-06-02 20:25:49] <tuxity> Yep@rchodavaI think I'm gonna do that in fact
[2016-06-02 20:26:18] <tuxity> because actualy I push the new Dockerfile, and docker hub build the image
[2016-06-03 18:14:55] <dimorinny> Hi, I had some problems with docker-machine and azure driver after OSX reinstallation ( [<-ISSUE->] ).I compiled docker-machine from HEAD manually and this problem was "solved". But now, when I trying to create new instance I had problem with certs. Here\'s end part of my docker-machine\'s create debug log. I am confused by line: "open : no such file or directory". [<-LINK->] Thanks.
[2016-06-03 18:22:01] <dimitrieh> question
[2016-06-03 18:22:14] <dimitrieh> i have a repo with some symbollic linked dirs in it
[2016-06-03 18:22:39] <dimitrieh> when starting my docker container it does see my normal files and dirs, but not my symlinked ones
[2016-06-03 18:22:55] <dimitrieh> how would I go about this, as I need them but they should not be in the repo
[2016-06-03 18:36:38] <dimitrieh> i think this does not work.. cant get it working [<-LINK->] 
[2016-06-03 18:43:46] <dimitrieh> did the symlink the other way around XD
[2016-06-04 17:10:10] <WillSkates> Hey everyone, none of my container's can access the internet for some reason (can't even ping google's dns - 8.8.8.8). Where should I look to solve it? I'm running Centos 7.2.1511 and docker 1.11.2.
[2016-06-04 17:10:27] <WillSkates> I've also turned my firewall off to see if it's that.
[2016-06-05 11:06:21] <eahmedshendy> If I have a software that will accept 10000 per second, docker will be good or I just complete using VMware solution
[2016-06-05 15:58:42] <FredLackeyOfficial> eahmedshendy: : that's somewhat vague ... what is the app (node.js, for exxample)?  ... can it be scaled (maybe with nginx)?  if so, then, yeah, docker will do just fine.
[2016-06-05 20:04:49] <mohamedhaleem> anyone here using docker for couchbase cluster?
[2016-06-06 17:00:47] <dissipate> mohamedhaleem: i'm not running couchbase, but this is an interesting example of running a couchbase cluster in docker: [<-LINK->] 
[2016-06-06 18:06:32] <chahn1138> rchodava: Thank you for the time!
[2016-06-06 18:08:02] <mohamedhaleem> dissipate: thanks!
[2016-06-06 18:38:02] <ajbeach2> WORKDIR  doesn't work with *,  ie: [<-CODE->] creates a directory called 'mstorsjo-fdk-aac*' as the working directory, when the working directory should be mstorsjo-fdk-aac-15b128d
[2016-06-06 18:38:12] <ajbeach2> how to i match any with WORKDIR?
[2016-06-06 18:42:48] <ajbeach2> aka, how do you get wildcards to work with docker workdir? RUN 'cd..../*' doesn't work either
[2016-06-06 18:55:42] <ajbeach2> anyone? why don't wildcards work with docker WORKDIR?
[2016-06-06 19:45:43] <edmondo1984> newbie question, after I run a docker image
[2016-06-06 19:46:16] <edmondo1984> of Ubuntu 14.04 which is connected to the bridge network, I can ping but I can't connect to a port. Do I need to open ports?
[2016-06-06 20:01:08] <ignaciomosca> you might, how did you start your container?
[2016-06-06 20:01:41] <ignaciomosca> I use -p to expose ports
[2016-06-06 20:03:38] <ignaciomosca> docker run -p x:y
[2016-06-06 20:03:45] <ignaciomosca> I think x is the port of the host
[2016-06-06 20:03:48] <ignaciomosca> and y the port of the container
[2016-06-06 20:04:20] <ignaciomosca> example docker run -d -p 8080:8080 -p 1521:1521 alexeiled/docker-oracle-xe-11g
[2016-06-07 20:21:21] <staffanselander> Hello guys!
[2016-06-07 20:21:32] <staffanselander> Quick question
[2016-06-07 20:22:29] <staffanselander> Is it possible in a way to pull down a Jenkins docker container, setup jenkins task to run tasks like “docker-compose -f docker-compose.yml”?
[2016-06-07 20:23:12] <staffanselander> This might even be a bad idea, open for suggestions. I’m basiclly figureing out how to deploy a docker application the best way
[2016-06-07 20:23:17] <staffanselander> :)
[2016-06-07 20:23:43] <staffanselander> Maybe wasen’t a quick question though… Sorry for that one haha…
[2016-06-07 21:13:43] <chahn1138> I am just starting on this, and might just have to clobber everything and start over, but I have begun (out of the blue, or so it seems) to see this failure when trying to cp a file out of a container:docker cp ContName:/tmp/proparse .Error response from daemon: lstat /data/docker/devicemapper/mnt/f026a95035ddda726d32c653f88fc69b6c1efe909859d375e03d96608297c61b/rootfs/tmp/proparse: not a directoryI did have to relocate the /var/lib/docker folder, using a symlink, but this was weeks ago and that change has been working fine.I can run the docker cp command to push files in....no error results, but no files are actually xferred.  TIA!!
[2016-06-07 21:58:32] <dissipate> LadyVipEx: this might not help you at all, but we rejected Jenkins for actual deployment. initially, we were using Rundeck and now we are setting up Ansible to run docker-compose for deploy.
[2016-06-08 05:58:54] <dvirf>  [<-CODE->] However, if the db was not up, then its container starts, and my app tries to query it but fails (since it takes a few seconds before the db is responsive).what is the recommended way to overcome this problem?p.s the db is the official couchbase image, and the component on my app that queries the db is a third party plugin that i can't configure.
[2016-06-08 06:11:55] <staffanselander> dissipate: Well it was intressting though :) Are you running Rundeck inside of a container? On the server os? Maybe it isn’t even a installable application? :’)
[2016-06-08 06:12:30] <staffanselander> dissipate: How come you didn’t go for Jenkins? : )
[2016-06-08 08:13:04] <makersu> hi could we already have docker for mac? not use virtual-box instead?
[2016-06-08 08:13:57] <staffanselander> makersu: Do you mean you want to use Docker without Virtual-box?
[2016-06-08 08:14:25] <makersu> LadyVipEx: yes
[2016-06-08 08:17:01] <staffanselander> makersu: I haven’t heard of it. I could imagine not. It depends on the Linux kernel if im not misstaken. Are you using Docker toolbox?
[2016-06-08 08:18:04] <makersu> how could i get Docker For Mac Beta?
[2016-06-08 08:18:46] <RizziCR> beta.docker.com
[2016-06-08 08:19:06] <RizziCR> but it’s not running on all mac's
[2016-06-08 08:20:05] <RizziCR> my mid 2011 iMac has a not supported i7 CPU :(
[2016-06-08 08:20:22] <RizziCR> sorry mid 2010 iMac
[2016-06-08 08:21:46] <staffanselander> Awesome!
[2016-06-08 08:21:50] <staffanselander> Signed up!
[2016-06-08 08:23:17] <Daniyal8876_twitter> i am getting error with mysql while using nodejs with ORM
[2016-06-08 08:23:28] <Daniyal8876_twitter> docker is not migrating
[2016-06-08 08:24:30] <Daniyal8876_twitter> @LadyVipEx  Does any one have idea about why migrate:"alter" and drop is not running on Docker i am creating application with NODEJS +MYSQL using waterline orm```> ExpressSite@0.0.0 start /var/www [<-CODE->] 
[2016-06-08 10:06:42] <staffanselander> @Daniyal8876_twitterbalderdashy/waterline#887Seems like is an error regarding waterline
[2016-06-08 10:07:05] <staffanselander> Answer seems correct:Ah! Gotchya. In that case, my take would be to,\nSet default to "safe".\nPrevent users from using alter/drop in production by throwing an error. That way they can fix their config. Given that the default is "safe", the error would only occur if their configuration is broken.\n\nIf we weren\'t changing the default, it would be more unclear to me whether to throw an error or silently skip migration. Since we are changing the default, an error seems appropriate.
[2016-06-08 10:12:00] <mkunikow> Hi, I have question. What is licence for docker beta ?. Can I find somewhere info? I wanted to use it in my company.
[2016-06-08 11:36:18] <Daniyal8876_twitter> @LadyVipEx  when i use safe in production then it stops on loading model and didnt creat schema`2016-06-08T06:32:25.979403114ZExpressSite@0.0.0 start /var/wwwnode ./bin/wwwLoad model daniM`
[2016-06-08 12:36:22] <chahn1138> FWIW, that most-odd-thing above was never really understood.  I restarted all involved containers and the matter resolved itself.
[2016-06-08 16:53:30] <dissipate> LadyVipEx: initially we were using Jenkins for build/test and then Rundeck for deployment, and now we are going with Ansible for build, test and deploy. I am personally not going for Jenkins because I don't really like it. it seemed overly complex just to set up a single project, and I don't really like the UI anyways.
[2016-06-08 16:54:41] <staffanselander> dissipate: Alright, Gonna take a look at Ansible and Rundeck, Rundeck though is it something that you install in the server?
[2016-06-08 16:55:22] <dissipate> LadyVipEx: yep, it's a separate server
[2016-06-08 16:57:07] <staffanselander> dissipate: Quick peek at it, it looks nice. Do you run Rundeck inside it’s own container on the other server? :’)
[2016-06-08 16:57:19] <staffanselander> Trying to figure out how much i can keep in my containers hehe
[2016-06-08 16:58:45] <dissipate> LadyVipEx: yes, there shouldn't be an issue running it in a container. of course, you will probably want to run it either with a volume container + database engine, or with some other datastore that you have running, since it needs persistence.
[2016-06-10 12:17:22] <marimysh>  [<-CODE->] All directory are exist. And files have mod 655.
[2016-06-10 12:19:05] <matteyeux> When permiss
[2016-06-10 12:19:29] <matteyeux> When permission denied run as root
[2016-06-10 12:20:30] <marimysh> -rw-r-xr-x. 1 docker dockerand this comand exec from 'docker' user
[2016-06-10 18:55:24] <dissipate> does anyone know if you can set default resource restrictions in the daemon's DOCKER_OPTS env variable? or any other way otherwise...
[2016-06-10 19:15:08] <Engineero> Hey all, I\'m having a little trouble with a use case and I was hoping somebody could help. I am trying to get tensorflow up and running on my Windows 10 machine, and am able to get it working with [<-CODE->]  [<-CODE->]  [<-CODE->] So I really need help with #1 and #2. Possibly #3 still as I am not at all sure that I did that in the "correct" way. Any help would be greatly appreciated!
[2016-06-10 19:43:37] <Engineero> PS: I have tried mounting a volume by adding-v /c/Users/path/to/my/files:/notebooks/my_files/to thedocker runcommand. I get a volume calledmy_filesshowing up, but it is empty. I also tried-v /c/Users/path/to/my/files/*:/notebooks/my_files/. Still empty.
[2016-06-12 06:09:43] <abner2015> hello all ,i \'am havaing a trouble with use spring-boot  with docker,in the dockerfile  the CMD run jar is：CMD ["java","-jar","sping-docker-1.0-SNAPSHOT.jar","--spring.config.location=Myapplication.properties"]. it does not work, whether the CMD is wrong? how can i do ,if i want to use the cmd run spring-boot Myapplication.properties
[2016-06-12 08:14:22] <mjbright> Engineero: For your volume mount problem, as you see an empty directory that suggests that the source directory doesn't exist.  Seeing your path starts with /c/Users/path makes me think that you're on Windows, probably running Cygwin.   Try -v /cygdrive/c/Users/path/to/my/files:/notebooks/my_files/  ... I'd have suggested also c:/Users.... but I don't expect docker will like that extra colon ....
[2016-06-12 08:17:00] <mjbright> Engineero: re-reading your earlier post, sounds like you're sharing the file system from Windows to your VM to Docker.  So make sure your VM sees that /c/Users/path already ...  How are you running your VM, VirtualBox?  Docker for Windows?
[2016-06-12 08:19:22] <mjbright> Engineero: I guess your VM has a private ip on the same subnet as your WIndows PC, so form the VM you should (if not blocked by firewall) be able to connect to that <ip>:<mysqlport>.   Look at your VM ip address with /sbin/ip a, then look at your Windows ip form the command-line with ipconfig, you should have an address on that same private  subnet.
[2016-06-12 08:20:12] <mjbright> Engineero: For your point 3. sounds good.  I wonder if you can't just append your changes to the tensorflow Dockerfile (thus building your own image still), or maybe you need those packages installed before the tensorflow installation?
[2016-06-12 11:04:56] <brunopereira27> Hello everyone, I have some permissions troubles using docker-compose. I'm building a django app and in my docker-compose file I use volumes to share data between my host and my django container. As soon as docker creates the volume, the shared folder is owned by root, and my django app cannot write on it. I tried to chown the folder in my dockerfile but it does not work, sharing the folder restores the folder to root. Of course, it is not possible to use chown to fix that once the container has started. I found some SO questions about it, but none of them seem to clearly fix the problem (or sometimes by some tricks as changing the user-id from the host, but I would like to avoid that). Has anyone a suggestion to my problem? Thanks!
[2016-06-13 02:23:44] <zerocoolback> brunopereira27: I was having   same issue because of selinux.  I guess you docker daemon is running with —selinux-enabled ??  Did you try to mount  the volume with  :z option?
[2016-06-13 03:41:10] <timcharper> How is it that bridged networking is an unsolved problem in Docker? This is the 2nd thing I learned how to do when creating lxc containers.
[2016-06-13 03:52:02] <timcharper> Sorry... unhelpful venting of frustration
[2016-06-13 03:53:16] <timcharper> I'm trying to get a container to get a LAN routable IP but not have DNS resolution break (which, by default, is being configured over the Docker host network.) Using pipework to assign an IP seems to break all the routes that Docker sets up to do port-forwarding and other things.
[2016-06-13 03:53:43] <timcharper> I tried macvlan support (did a experimental of 1.10.2 with experimental features turned on) on Centos 7.2 and was met by perplexing errors.
[2016-06-13 04:53:03] <alexforever86_twitter> One quick questionwhere to update docker insecure registry in coreos-4.5.1
[2016-06-13 04:57:25] <alexforever86_twitter> sorry not coreos.. alpine 3.4
[2016-06-13 05:22:52] <timcharper> ? list of registries allowed to be used as insecure ?
[2016-06-13 05:23:02] <timcharper> that's a flag that needs to be specified when launching docker daemon
[2016-06-13 19:30:07] <ghalenir> I have installed docker on my macbook and its running on some local ip
[2016-06-13 19:30:17] <ghalenir> how do I make it work with my localhost
[2016-06-13 19:57:56] <ghalenir> Is anything broken here ? [<-LINK->] 
[2016-06-13 22:37:55] <brunoban> Has anyone ever had a docker hang when the host if out of disk space and not go back up when you free up some space?
[2016-06-14 11:14:41] <Daniyal8876_twitter> hi i am trying to push my image to docker hubbut it start preparing and waiting then said unauthorizatedwhat i do now ??
[2016-06-14 12:42:23] <aohorodnyk> Daniyal8876_twitter: did you do [<-LINK->] ?
[2016-06-14 12:48:54] <Daniyal8876_twitter> aohorodnyk: yes i did , after login successfully when i use commanddocker push [imagename]after thisunauthorized: authentication required
[2016-06-14 15:00:37] <Engineero> mjbright: thanks! I am running my VM through Docker so far, but the file sharing was giving me lots of problems, so I just installed Ubuntu on a partition and now have a real dev environment. I appreciate the help!
[2016-06-14 15:04:13] <Engineero> ghalenir: I struggled with something similar a bit. I think it will only run on localhost (usually 127.0.0.1) on Linux. Otherwise it runs on its own IP, but you can still connect to it by IP/port. You just have to get the docker-machine's IP withdocker-machine ip.
[2016-06-14 15:18:41] <chahn1138> @marimyshI know that the unix cp command will allow multiple arguments, with the last being a directory...but does docker cp insist on just two args....let me check....[root@cdswebserver data]# docker cp foo bar lpiTomcat-P170:/tmpdocker: "cp" requires 2 arguments.Yup....your "*" expanded into more than one thing to copy.
[2016-06-14 19:16:44] <marimysh> hi,@chahn1138I found how docker can copy all files on directory (/path/to/files/ - without "*"). Docker cannot use regexp in this command(. Or do you know how make this? exemple: `docker cp /path/to/.java name_container:/psth/to/`
[2016-06-14 21:22:33] <tuxity> Does docker hub have a push size limit ? :/
[2016-06-14 21:23:38] <tuxity> I always get an error 500 when pushing my image
[2016-06-14 21:34:32] <tuxity> maybe deploying my own docker registry could fix that no ?
[2016-06-15 03:21:51] <Daniyal8876_twitter> Tuxity: could you help me to authorize my account i also want to push image on docker hub
[2016-06-15 03:22:10] <Daniyal8876_twitter> when i use commanddocker push [imagename]after thisunauthorized: authentication required
[2016-06-15 04:15:23] <Koleok> hey folks, anyone have experience using docker-cloud with aws?
[2016-06-15 04:16:07] <Koleok> i am having an ultra miserable time with this pair, I know there are some simple things unknown to me that are causing the issue
[2016-06-15 04:16:36] <Koleok> but no amount of tutorial and doc reading over the last week has uncovered the answers for me
[2016-06-15 11:01:04] <smith64fx>  [<-LINK->] 
[2016-06-15 15:15:24] <tuxity> Daniyal8876_twitter: maybedocker login?
[2016-06-15 15:16:00] <tuxity> I still can't understand how to fix my problem with docker guys :/
[2016-06-15 17:07:25] <lobocode> hi
[2016-06-15 17:07:52] <lobocode> Someone use docker with xenserver? Or...better, xenserver with openstack for example?
[2016-06-15 18:29:50] <thebuccaneersden> i know what xen is, but whats xenserver and how is it different than installing xen on top of your favourite linux disto?@lobocode
[2016-06-15 18:30:28] <JnMik> One of my collegue is having a hard time with docker-compose, issues that I don't have on my machine
[2016-06-15 18:30:42] <JnMik> He always end up with some weird errors like :
[2016-06-15 18:30:44] <JnMik> requests.packages.urllib3.exceptions.ProtocolError: ('Connection broken: IncompleteRead(0 bytes read)', IncompleteRead(0 bytes read))docker-compose returned -1
[2016-06-15 18:30:50] <JnMik> while building image
[2016-06-15 18:31:17] <thebuccaneersden> sounds like a network issue?
[2016-06-15 18:31:25] <JnMik> I found this thread, not sure if this is related [<-ISSUE->] 
[2016-06-15 18:31:53] <JnMik> well we're on the same office network, working well for me
[2016-06-15 18:31:59] <JnMik> he can ping different hosts from his VM
[2016-06-15 18:32:10] <JnMik> I don't think their is any issue with the network atm
[2016-06-15 18:32:28] <thebuccaneersden> are you on the same version of docker?
[2016-06-15 18:32:32] <JnMik> yes
[2016-06-15 18:32:36] <JnMik> We had this error at first
[2016-06-15 18:32:37] <JnMik> File "<string>", line 3, in <module>File "compose/cli/main.py", line 63, in mainAttributeError: \'ProjectError\' object has no attribute \'msg\'docker-compose returned -1
[2016-06-15 18:32:51] <JnMik> So I yum update -y docker-engine and download the most recent version of docker-compose
[2016-06-15 18:33:10] <JnMik> now he's at Docker 1.11.2 and docker-compose 1.7.1
[2016-06-15 18:33:13] <JnMik> (like me)
[2016-06-15 18:33:47] <JnMik> It's funny because while building the image, it failed at step 4, then he relaunched it, it failed at step 5, and now at step 6
[2016-06-15 18:33:51] <JnMik> We're always going a bit further...
[2016-06-15 18:35:05] <JnMik> I from time to time receive weird python error of my docker-compose but usually I reboot the VM and it works, I feel like the latest version is a bit unstable
[2016-06-15 18:35:14] <JnMik> Are we alone facing this kind of issues ?
[2016-06-15 18:38:23] <thebuccaneersden> seems pretty sketchy. dont have an answer for that, but i have to wonder if this is related to environment and not docker itself
[2016-06-15 18:39:49] <JnMik> Wish I knew..
[2016-06-15 18:39:55] <JnMik> We have VMs running CentOS
[2016-06-15 18:40:40] <JnMik> I also had weird issues at home on Ubuntu as well, but it's very more stable (Linux is on the computer, not into a vm)
[2016-06-15 18:40:53] <thebuccaneersden> (°_o)/
[2016-06-15 18:40:56] <JnMik> Never stopped me from getting shit done and finding workaround =/
[2016-06-15 18:41:07] <JnMik> Allright, thx for trying
[2016-06-15 18:41:12] <JnMik> Maybe someone else will have an idea
[2016-06-15 18:41:13] <thebuccaneersden> docker has been pretty stable for me
[2016-06-15 18:41:28] <thebuccaneersden> i didnt really do much, heh sorry
[2016-06-15 18:42:29] <JnMik> Here's more
[2016-06-15 18:42:30] <JnMik> docker-compose up -dERROR: An HTTP request took too long to complete. Retry with --verbose to obtain debug information.If you encounter this issue regularly because of slow network conditions, consider setting COMPOSE_HTTP_TIMEOUT to a higher value (current value: 60).
[2016-06-15 18:42:40] <JnMik> Or this one
[2016-06-15 18:42:41] <JnMik> Traceback (most recent call last):File "<string>", line 3, in <module>File "compose/cli/main.py", line 58, in mainFile "compose/cli/main.py", line 109, in perform_commandFile "compose/cli/main.py", line 734, in upFile "compose/project.py", line 380, in upFile "compose/service.py", line 299, in ensure_image_existsFile "compose/service.py", line 722, in buildFile "compose/progress_stream.py", line 18, in stream_outputFile "compose/utils.py", line 52, in split_bufferFile "compose/utils.py", line 28, in stream_as_textFile ".tox/py27/lib/python2.7/site-packages/docker/client.py", line 225, in _stream_helperFile ".tox/py27/lib/python2.7/site-packages/requests/packages/urllib3/response.py", line 271, in readrequests.packages.urllib3.exceptions.ProtocolError: (\'Connection broken: IncompleteRead(0 bytes read)\', IncompleteRead(0 bytes read))
[2016-06-15 18:43:20] <JnMik> Maybe some external dependencies having glitches right now ?
[2016-06-15 18:43:53] <thebuccaneersden> its possible i guess
[2016-06-15 18:43:57] <thebuccaneersden> not seeing it myself though
[2016-06-15 18:44:28] <JnMik> Not sure what these requests.packages is for, not a pro of python
[2016-06-15 18:44:42] <JnMik> Not sure if docker-compose needs to connect to external endpoints to run some build locally either.. I thought not
[2016-06-15 18:45:02] <thebuccaneersden> i believe urllib3 is the equivalent of curl
[2016-06-15 18:45:21] <thebuccaneersden> its saying it is getting 0 bytes
[2016-06-15 18:45:36] <thebuccaneersden> so it seems to me that when its making an http request, stuff is timing out
[2016-06-15 18:45:52] <thebuccaneersden> almost like there is a firewall blocking stuff or a bad network connection configuration
[2016-06-15 18:49:28] <JnMik> Well, his VMs just got destroyed and rebuilt, using the same vagrantfile we have for months, we have no internet issue either, and on my VMs it\'s working well.. so I guess it eliminates the "external dependency flapping" issue
[2016-06-15 18:49:36] <JnMik> Mann I don'T get it aha, we'll dig more
[2016-06-15 18:49:57] <thebuccaneersden> :|
[2016-06-16 00:05:32] <iceycake> I am wondering if anyone can help here.  We have pretty knowledge on Docker in linux system but We are trying to build a very basic docker image for Windows.  Question is... does FROM scratch work on Windows ?  Or we have to use FROM windowservercore ?
[2016-06-16 00:10:39] <iceycake> i guess i can answer my own question.. Just found this: http://ezeeetm.github.io/Docker-Engine-for-Windows-Server-Walkthrough/However, if anyone has some good readings, please send along.  Thanks.
[2016-06-16 07:16:34] <Madlexx> Hi guys. I have a few docker-compose containers(They are the same: php-fpm, nginx, mysql). How I can connect to one docker-compose container to another(external) for execute curl request. The external_links doesn't work, and brige network beetween containers doesn't help - they are have pings, but curl request is empty.
[2016-06-16 07:18:41] <aohorodnyk> Madlexx: use networks for that, for now you shouldn't use links never
[2016-06-16 07:23:02] <Madlexx> aohorodnyk: in documentation( [<-LINK->] ) says use external links for connect different docker-compose instance. But it isn't work for me. Also i tried create bridge between one docker container php-fpm(form fist docker-compose instance) to external docker container web-server(nginx), this network has connect, but curl doesn't work.
[2016-06-16 07:25:09] <aohorodnyk> Madlexx:  [<-LINK->] 
[2016-06-16 07:25:40] <aohorodnyk> Madlexx: I had the same problems :) I think that it's outdated documentation, but not sure
[2016-06-16 07:27:03] <Madlexx> aohorodnyk: thanks for help, i will try create network. Maybe it can help)
[2016-06-16 07:27:16] <aohorodnyk> Madlexx: it will help you
[2016-06-16 07:27:24] <aohorodnyk> 100%
[2016-06-16 08:41:23] <Madlexx> aohorodnyk: it's work. Problem was with magento - baseurl was 0.0.0.0:8181 . It's redirected any request to this ip - and problem was happen. Thanks!
[2016-06-16 16:50:23] <meonkeys> Anyone know if it is possible to teach Docker Hub to re-tag an image (say, latest & vX.X) rather than rebuild? [<-LINK->] 
[2016-06-16 20:08:09] <tuxity> There is a way with a reverse proxy on my regsitry to remove the port from the syntax ?
[2016-06-16 20:08:53] <tuxity> likeregistry.domain.com/myrepoand notregistry.domain.com:443/myrepo
[2016-06-17 03:38:04] <soapoperator> Tuxity: i have the same question
[2016-06-17 05:40:05] <soapoperator> I have try to play with server_name_in_redirect for example, but it doesn't solve the issue.
[2016-06-17 14:32:05] <tuxity> I'm gonna try@soapoperator
[2016-06-17 14:32:19] <tuxity> but I'm sure :/
[2016-06-17 14:32:47] <tuxity> It's not the first time I do a reverse proxy on a app, but with the registry it's weird
[2016-06-17 14:44:01] <tuxity>  [<-LINK->] btw there is typo here in the nginx conf with the variables
[2016-06-17 14:44:12] <tuxity> there is a \\ before the $
[2016-06-17 14:44:38] <tuxity> I copy pasted it and nginx complains
[2016-06-17 14:46:03] <tuxity> Idk where is the file to do a PR
[2016-06-17 17:12:38] <programmerq> Tuxity: that doc lives here: [<-LINK->] 
[2016-06-17 17:12:57] <tuxity> Yep I saw that after, I've done a PR :P
[2016-06-17 20:22:37] <sbromberger> has there been any progress in allowing users to disable certificate checking fordocker pullrequests?
[2016-06-17 20:24:42] <freefood89> hello i'm new here. I was wondering if anyone is aware whether the aws log driver is able to assume role and use STS tokens to interact with cloudwatch. I haven't been able to find any issues or pull requests regarding this. From the source code it looks like this is not something that is supported
[2016-06-17 20:24:45] <sbromberger> (that is,Version 1.11.1-beta13 (build: 7975))
[2016-06-17 21:27:54] <dissipate> sbromberger: did you try the--insecure-registryflag?
[2016-06-17 22:59:35] <YaraaMohamed> hello everybody I'm trying to enable Docker remote API I modified the script on /etc/init/docker.conf locally and it worked but when I did the same on a droplet in digital ocean it didn't work can anyone help?
[2016-06-18 06:46:02] <soapoperator> Tuxity: finally,  you make it work.  I will check the doc when i will be back at home...
[2016-06-18 12:35:44] <tuxity> Yep@soapoperatori was stucked before i didnt read correctly the doc to setup the registry
[2016-06-18 12:36:45] <tuxity> If you use nginx for tls and auth, don't add any params when you're launching the registry
[2016-06-18 12:37:01] <tuxity> let that part to nginx
[2016-06-18 12:37:48] <tuxity> certs params and auth are only if you expose the app to the outside world without nginx
[2016-06-18 12:38:09] <tuxity> And i was doing both
[2016-06-19 01:19:46] <testlab9000> Guys, I need urgent help. My server is going to be shut down in 30 minutes. I don't know anything about docker, but I need to transfer 2 images to another server quick, without losing any settings. Could somebody help me? The images consist of node.js app and MongoDB connected between each other somehow (don't know how, but need to save that connection)
[2016-06-19 01:21:47] <cristim> docker save image > image.tar
[2016-06-19 01:22:15] <testlab9000> is that the correct syntax? Will it save network settings between 2 images?
[2016-06-19 01:23:06] <cristim> it depends how the network is configured
[2016-06-19 01:23:30] <cristim> you should also have a look at how the containers were launched
[2016-06-19 01:23:48] <testlab9000> cristim: how can I check that?
[2016-06-19 01:24:13] <cristim> can you see the command used to start them in the first place?
[2016-06-19 01:24:36] <testlab9000> I got root, but I don't know how to see that command
[2016-06-19 01:25:16] <cristim> try to capture the docker ps output in a text file
[2016-06-19 01:25:41] <cristim> also ps waux | grep docker may be helpful
[2016-06-19 01:26:59] <cristim> having those you should be able to re-run them in the same way
[2016-06-19 01:27:16] <testlab9000> geekdave: ok I got this info [<-LINK->] what do I do with it?
[2016-06-19 01:27:28] <cristim> (unless they are also mounting volumes from the container host)
[2016-06-19 01:27:40] <cristim> in which case you also need to migrate the volume data
[2016-06-19 01:29:00] <testlab9000> Is there a step-by-step guide I can read to quickly transfer it?
[2016-06-19 01:29:39] <cristim> you can transfer in many ways,  there's not a single universal way
[2016-06-19 01:30:08] <cristim> once you have the tar files  you can copy them over SSH/SCP
[2016-06-19 01:30:11] <testlab9000> I really don't know anything about docker. But I need to transfer it fast.
[2016-06-19 01:30:25] <testlab9000> What is corect syntax to execute the command?
[2016-06-19 01:30:34] <cristim> that has nothing to do with docker, it's just SSH
[2016-06-19 01:31:20] <testlab9000> So just tar /var/lib/docker/ install docker on another server and untar it?
[2016-06-19 01:31:21] <cristim>  [<-CODE->] 
[2016-06-19 01:31:54] <testlab9000> but what is the file? how do I create it properly?
[2016-06-19 01:31:58] <charles-m-knox> docker save: [<-LINK->] 
[2016-06-19 01:32:27] <charles-m-knox> for your mongodb image you'll want to dodocker save 737355142e67 > mongocontainer.tar
[2016-06-19 01:32:38] <charles-m-knox> give that a try
[2016-06-19 01:32:50] <charles-m-knox> then scp it out
[2016-06-19 01:33:17] <testlab9000> -bash: mongocontainer.tar: Permission denied
[2016-06-19 01:33:25] <charles-m-knox> become root
[2016-06-19 01:33:26] <charles-m-knox> sudo su
[2016-06-19 01:33:29] <testlab9000> did that as sudo
[2016-06-19 01:33:34] <charles-m-knox> you ahve to be root
[2016-06-19 01:33:39] <charles-m-knox> the > won't work w/ sudo
[2016-06-19 01:34:10] <charles-m-knox> and for your meteorhacks container, do the same thing:docker save 2cbdf576994d > meteorcontainer.tar
[2016-06-19 01:34:22] <testlab9000> No such image: 737355142e67
[2016-06-19 01:34:38] <testlab9000> Error response from daemon: No such image: 2cbdf576994d
[2016-06-19 01:34:51] <cristim> use meteorhacks/meteord:base
[2016-06-19 01:35:04] <cristim> the save command expects your image name
[2016-06-19 01:35:09] <cristim> not the container ID
[2016-06-19 01:35:13] <charles-m-knox> ah yes@cristimis right
[2016-06-19 01:35:20] <charles-m-knox> if you want to save the container, usedocker export
[2016-06-19 01:35:27] <charles-m-knox> image export isdocker save
[2016-06-19 01:36:04] <testlab9000> maybe the other way around? what do I want? I think export
[2016-06-19 01:36:15] <charles-m-knox> as a safest bet you'll probably want to dodocker exportfor the 737 and 2cb containers, and also dodocker save <image names>
[2016-06-19 01:37:25] <cristim> export captures the current state, save gets you the state used when first starting them
[2016-06-19 01:37:39] <testlab9000> Then save
[2016-06-19 01:38:00] <charles-m-knox> are you sure? if you need to save the state of the containers as they are right now, it sounds like export is the right choice
[2016-06-19 01:38:14] <cristim> it depends what you want to achieve, I'd do both if I were you
[2016-06-19 01:38:25] <charles-m-knox> but if the containers have volumes attached, neither option will help you
[2016-06-19 01:38:33] <testlab9000> When you say "first starting" you mean after boot? my boot happend 15 min ago
[2016-06-19 01:38:53] <cristim> then there may be no difference
[2016-06-19 01:43:47] <testlab9000> Alright the transfer of .tar is done. Nowsudo apt-get install docker.iothendocker import mongo.tar?
[2016-06-19 01:47:18] <charles-m-knox> You need to know how the containers were originally orchestrated in order to deploy them again
[2016-06-19 01:47:31] <testlab9000> How can I find out?
[2016-06-19 01:48:01] <charles-m-knox> Hmm... Well first suggestion is to reach out to whomever deployed the containers
[2016-06-19 01:48:08] <testlab9000> Not possible
[2016-06-19 01:48:31] <testlab9000> Server is shutting down in 10 min
[2016-06-19 01:48:45] <charles-m-knox> Is it going to come back online afterwards?
[2016-06-19 01:48:56] <testlab9000> Yes, but downtime is no good
[2016-06-19 01:49:39] <charles-m-knox> I hear ya...
[2016-06-19 01:50:19] <charles-m-knox> ok let's try something
[2016-06-19 01:50:26] <charles-m-knox> do this
[2016-06-19 01:50:37] <charles-m-knox> cd to the root (cd /
[2016-06-19 01:50:38] <charles-m-knox> )
[2016-06-19 01:50:48] <testlab9000> Doing it
[2016-06-19 01:51:09] <charles-m-knox> well, first try this in a couple easy spots:cd /home && find . | grep docker-compose
[2016-06-19 01:51:24] <testlab9000> no reaction
[2016-06-19 01:51:30] <testlab9000> just empty line
[2016-06-19 01:51:43] <testlab9000> It executed though
[2016-06-19 01:51:45] <charles-m-knox> tryfind . | grep docker-composein/optor perhaps/etc
[2016-06-19 01:51:51] <charles-m-knox> we're really playing some guessing games here : )
[2016-06-19 01:52:27] <charles-m-knox> if we can find the docker-compose file, we can copy the orchestration and re-deploy on your new server
[2016-06-19 01:52:52] <testlab9000> nothing
[2016-06-19 01:52:53] <charles-m-knox> but it's possible there is no docker-compose file at all, and it was deployed remotely through docker machine. if that's the case then you are SOL as far as I can tell
[2016-06-19 01:53:05] <testlab9000> /var/lib/docker# lsaufs  containers  image  network  tmp  trust  volumes
[2016-06-19 01:53:19] <charles-m-knox> cd into volumes and what do you see?
[2016-06-19 01:53:33] <testlab9000> 4803501030c01d1c3f58c632c7f6404329bcbf73a0bb447b1a34b9b33c0e8c126afac95415baaa5352d3049ee68997376fec54ec56772b0fba58c2591003005aa5f6614d3f95f765bf0610f664d16219aebee13eeab01d364d490746f6e23377bd1b3f6f69b3100db7685104fdfde679494122269840890b33947a80a7adff20bd217fc374520d137a3a4c4177852847c605c1a942903e3344036f0413c14a48metadata.db
[2016-06-19 01:53:36] <testlab9000> oops
[2016-06-19 01:53:52] <charles-m-knox> hm
[2016-06-19 01:54:30] <charles-m-knox> ok so there are some mounted volumes... Docker has instructions on how to get volumes from a container
[2016-06-19 01:56:23] <charles-m-knox> I've never tried this before but try this:docker run --rm --volumes-from 737355142e67 -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata, it will create this:/backup/backup.tar
[2016-06-19 01:56:47] <charles-m-knox> in your current directory , it looks like. then you can SCP the tar files off
[2016-06-19 01:57:07] <charles-m-knox> do the same thing again but with 2cbdf576994d instead of 737355142e67
[2016-06-19 01:57:21] <charles-m-knox> that's my last ditch effort for you@testlab9000,  following this guide [<-LINK->] 
[2016-06-19 01:57:58] <charles-m-knox> your data will be saved but there is no way to bring your containers back up on a new server without downtime as far as I can tell, sorry
[2016-06-19 01:58:32] <charles-m-knox> ultimately you need to find out how the containers were originally orchestrated, whomever was responsible for causing this problem for you needs a slap on the wrist : )
[2016-06-19 01:58:36] <testlab9000> Screw data in voulumes. Didn't docker save saved it all?
[2016-06-19 01:58:53] <charles-m-knox> docker save does not capture data in externally mounted volumes
[2016-06-19 01:58:56] <charles-m-knox> iirc
[2016-06-19 01:59:31] <charles-m-knox> but as far as we know, the entire contents of your mongodb container could be in that volume
[2016-06-19 02:00:04] <testlab9000> Myabe just try to restore it on the target server and see if it works?
[2016-06-19 02:00:22] <charles-m-knox> sure, you can definitely try and hope it works!
[2016-06-19 02:00:31] <testlab9000> Is there a guide for that?
[2016-06-19 02:01:07] <charles-m-knox> a guide for restoring your containers?
[2016-06-19 02:01:12] <testlab9000> Yes
[2016-06-19 02:01:52] <charles-m-knox>  [<-CODE->] and for restoring from docker volume backup look here: https://docs.docker.com/engine/userguide/containers/dockervolumes/#backup-restore-or-migrate-data-volumes
[2016-06-19 02:01:58] <charles-m-knox> best of luck
[2016-06-19 02:02:12] <testlab9000> chuck-knox: thank you very much!
[2016-06-19 02:02:38] <charles-m-knox> you're welcome... make sure to have a nice conversation with whomever engineered your systems when you get the chance... documentation is important
[2016-06-19 03:03:15] <Koleok> anyone around and have a minute to talk aws/docker-cloud?
[2016-06-19 06:26:06] <dconroy> better odds of getting an answer by just asking the specific question
[2016-06-19 06:26:41] <testlab9000> I have one! Why after mupx setup my app doesn't start? and Docker ps shows nothing on port 80. Just Mongodb  image on port 27017
[2016-06-19 06:30:15] <dconroy> what do the logs say
[2016-06-19 06:30:36] <testlab9000> dconroy: there was no error messages. Is there a way to check logs?
[2016-06-19 06:33:43] <dconroy> yes. they are available in a few different places depending on your setup.
[2016-06-19 06:35:00] <testlab9000> dconroy: would you tell me where to look? I'm on Ubuntu 16.04 and this are the only commands I executed on a fresh server [<-LINK->] 
[2016-06-19 07:54:03] <MedoHaleem> Guys I have been reading about docker and i wanted to ask question, Suppose that I have 150 servers, running the same code base, can I for example change one Image ( pulling new code from github, installing new dependencies ) in one image and then push these changes to other 150 which automate these tasks ?
[2016-06-19 09:17:04] <testlab9000> Guys, what is the fastest way to move 2 images from 1 server to another, for a person who has never seen docker before?
[2016-06-19 10:02:20] <akaashanky> Hi! Any suggestions on how host environment variables can be accessed from a container? I've managed to dockerise some of our apps, but we follow a practice of storing sensitive data such as API keys, DB connection creds, etc. in env variables on our servers.
[2016-06-19 10:04:02] <akaashanky> If there's no way to do the above, what're some secure practices for building images with such data in the image's env variables?
[2016-06-19 10:11:56] <akaashanky> When I say secure, I mean not specifying the sensitive data in the dockerfile/compose yml.
[2016-06-19 14:01:30] <ksylvan> See [<-LINK->] about using the-eflag when usingdocker run@akaashanky
[2016-06-19 15:41:17] <akaashanky> ksylvan: Thanks a lot! Will need to play with it, but looks like this should do the trick! :)
[2016-06-19 17:00:10] <Koleok> Specific question: I am trying to use docker cloud to put up an express API that is basically just a CRUD interface to a DB. I created a node cluster with docker-cloud connected to my aws account but the only way i was able to accomplish that was by assigning the node to an awsVPC. As far as i know a vpc is a way to connect a bunch of services together in a safe isolated place, but i need to hit this API from the outside, I am utterly in the dark as to how I might accomplish this
[2016-06-19 17:02:05] <Koleok> I read about giving the VPC an internet gateway, and I indeed can find this in the VPC console, but i seriously can’t find any specific info about what the internet gateway does, how to configure it, how it works, or really anything. There is some baseline of implicit devops knowledge all of the aws and docker-cloud documentation assumes that I am clearly not up to par with
[2016-06-19 17:03:28] <Koleok> This is a particularly pressing matter for me as I am doing a contract project for someone and I am basically to the point where I have had to start eating hours because I have burned so many on this deployment
[2016-06-19 17:06:30] <Koleok> Context: I am very much on theacademic-y programmerside of things, i am a software engineer and have the luxury of living completely in local dev environments and offloading all infrastructure work of this type to the devops department at my dayjob, so while i am an experienced engineer, i am basically a newb when it comes to deployment domain knowledge
[2016-06-19 17:07:08] <Koleok> this information is to try and quell any rage awakened in you all by my nerve in coming in here with such a RTFM type problem
[2016-06-19 17:08:03] <Koleok> I assure you I have been googling and forum searching and walkthrough reading for a week solid and for whatever reason the kernel of understanding that will allow me to deploy this app remains elusive
[2016-06-19 17:10:13] <Koleok> So basically the summary isI need to grok how one actually creates a docker cloud node on aws VPC that is publicly accessible
[2016-06-19 18:40:21] <satdav> IS their a django room on here
[2016-06-20 00:28:38] <arunma> Koleok: before the experts come up to answer your question (definitely not me) , did you get a chance to try this out [<-LINK->] 
[2016-06-20 00:30:40] <arunma> I also
[2016-06-20 00:34:05] <arunma> I also vaguely remember that we could create a public ip for VPC nodes on creation of nodes but that's not generally what you want.
[2016-06-20 06:03:02] <testlab9000> Guys, I'm a total docker noob, but I need to transfer Web application that is Dockerized to another server. Is there a fool-proof step-by-step guide for this kind of cases?
[2016-06-20 06:04:07] <necrose99> undocker perhaps ?
[2016-06-20 06:04:27] <necrose99> or you could just copy and stored data
[2016-06-20 06:06:35] <testlab9000> necrose99: I don't know what undocker is. Should I do that? By copying stored data, do you mean copy /var/lib/docker ?
[2016-06-20 06:07:17] <necrose99> the data for your application , as you can just let docker regenrate
[2016-06-20 06:07:25] <necrose99> reload data
[2016-06-20 06:07:47] <necrose99> undocker squashes docker into more of a tarball state
[2016-06-20 06:08:00] <testlab9000> I understand. But I don't know syntax and how to do it. Could you recommend a good guide, please?
[2016-06-20 06:08:27] <necrose99> Sabayon Linux uses it to smash docker layers into ISO or tarballs ie chroot
[2016-06-20 06:09:34] <necrose99> if anyting you could load your docker image on another server . and rsync over any missing data
[2016-06-20 06:10:00] <testlab9000> This is perfect! How do I do that?
[2016-06-20 06:10:40] <necrose99> rync -??? myold.server.com >>>> new.server.net
[2016-06-20 06:10:51] <necrose99> just like a tradinal box
[2016-06-20 06:11:21] <necrose99> undocker however will smash into a traditinal tarball
[2016-06-20 06:11:22] <testlab9000> I've never done this. So, install docker on a source server, then rsync  /var/lib/docker/ folder?
[2016-06-20 06:11:38] <necrose99> docker file import
[2016-06-20 06:11:42] <necrose99> new server
[2016-06-20 06:12:00] <necrose99> thiers a few guides however i've not used them of yet
[2016-06-20 06:12:26] <necrose99> mainly  package data lives and docker is expendable
[2016-06-20 06:13:00] <testlab9000> I'm sorry, I don't understand what you wrote 
[2016-06-20 06:13:03] <necrose99> ie build Gentoo packages , nuke the rest on close
[2016-06-20 06:13:24] <testlab9000> That too 
[2016-06-20 06:13:55] <necrose99>  [<-LINK->] 
[2016-06-20 06:14:53] <necrose99>  [<-LINK->] 
[2016-06-20 06:15:11] <testlab9000> I don't know what that is and how to use it. I'm asking for a guide with an example how it is done.
[2016-06-20 06:15:57] <necrose99>  [<-LINK->] 
[2016-06-20 06:16:18] <necrose99> tools and guides one of them might make for live
[2016-06-20 06:16:30] <necrose99> undocker converts to a live tarball
[2016-06-20 06:16:40] <testlab9000> necrose99: thank you!!!
[2016-06-20 06:17:14] <testlab9000> Are this kind of questions not welcome here? Should I have used stackoverflow?
[2016-06-20 06:17:14] <necrose99> docker-sync would do much the same but dont need to tar etc
[2016-06-20 06:17:27] <testlab9000> Thanks!
[2016-06-20 06:17:48] <necrose99> unpack into new docker container also if clustering or mirroring ... works too
[2016-06-20 06:18:12] <testlab9000> Unpacking how?
[2016-06-20 06:18:52] <necrose99> tar >ftp local host > ftp new host tar -xzvf or etc
[2016-06-20 06:19:15] <cristim> testlab9000: the move part is not detailed there but if I remember correctly, a couple of days ago  I gave you a scp command example that you could use to transfer the data
[2016-06-20 06:19:17] <necrose99> the rsync skipps all that just looks for missing files and clones them
[2016-06-20 06:19:47] <testlab9000> geekdave: yes! This was the first scp command that worked for me! Thank you for that!
[2016-06-20 06:21:17] <cristim> You can also use rsync over SSH to make it incremental in case you want to repeat the transfer
[2016-06-20 06:23:00] <cristim>  [<-LINK->] 
[2016-06-20 06:27:29] <cristim> That is just a way to move any data over between machines, there are lots of options and it has nothing to do with docker, you just happen to be transferring docker container dumps with the purpose of restoring them on the second machine, but it would work for any type of data you may have to transfer.
[2016-06-20 06:28:14] <cristim> I  guess that is why nobody else documented that step in detail
[2016-06-20 06:28:32] <dissipate> Koleok: I don't use 'docker cloud', but i do use a VPC at work on AWS. the way we expose things to the public is through an elastic load balancer. you should be able to set it to 'public'.
[2016-06-20 06:32:25] <cristim> Koleok: Another way if you have just a few machines is to attach an elastic IP to each of the private nodes, or to move them to the public subnet where you get a dynamic one attached out of the box
[2016-06-20 07:01:05] <dissipate> cristim: could it be possible that his VPC was not configured to have public subnets?
[2016-06-20 07:02:46] <cristim> Yes, it's possible
[2016-06-20 07:40:41] <sbromberger> dissipate: : [<-CODE->] 
[2016-06-20 07:41:07] <sbromberger> (sorry for the delayed response.)
[2016-06-20 15:03:01] <dissipate> sbromberger: I think it isdocker --insecure-registry $(your insecure registry host) pull
[2016-06-20 15:03:44] <dissipate> sbromberger: but you are probably going to want to put the--insecure-registryoption in your docker config so you don't have to keep typing it on the CLI
[2016-06-20 15:04:55] <dissipate> sbromberger: see: [<-LINK->] 
[2016-06-20 16:10:39] <jameshulse> hi all, my local docker is acting strangely on Windows. Runningdocker build -t name .doesn't show any output and just seems to do nothing, but strangelydocker build -t name - < Dockerfiledoes show output (it just doesn't work because the context/working directory is wrong). Any ideas?
[2016-06-20 16:14:00] <sbromberger> dissipate: - I’m trying to use the global (default) docker repo - not my own
[2016-06-20 16:14:19] <sbromberger> dissipate: - what’s the repo address I should use?
[2016-06-20 17:00:15] <dissipate> sbromberger: i don't understand. why would you be trying to connect to the Docker Hub repo insecurely?
[2016-06-20 17:00:42] <sbromberger> dissipate: because my company MITMs our SSL connections.
[2016-06-20 17:00:46] <dissipate> sbromberger: your docker daemon should attempt to pull an image from Docker Hub by default (if the image isn't available from another repo)
[2016-06-20 17:02:09] <dissipate> sbromberger: i see. i'm not sure if Docker Hub allows for insecure connections at all. it is possible they do not. :(
[2016-06-20 17:02:54] <sbromberger> which would suck.
[2016-06-20 17:03:23] <sbromberger> basically it means that most $gov orgs and $financial orgs won’t be able to pull images?
[2016-06-20 17:05:08] <dissipate> sbromberger: possibly. your best bet might be to set up an HTTP proxy outside your company network that terminates the SSL with Docker Hub.
[2016-06-20 17:05:38] <sbromberger> I guess. That’d probably require ten different levels of approval though.
[2016-06-20 17:06:08] <dissipate> sbromberger: even though your company MITMS, SSL, that doesn't disable SSL, does it?
[2016-06-20 17:06:38] <sbromberger> dissipate: no, but it results in certificate mismatches since the ssl connection is “broken” at the proxy.
[2016-06-20 17:07:19] <sbromberger> basically, under normal circumstances (web browsing, for example), my browser knows to make an ssl connection to the company proxy, which then initiates its OWN SSL connection to the destination
[2016-06-20 17:07:52] <sbromberger> the problem is that the docker client tries to make its connection directly to the repo.
[2016-06-20 17:08:24] <sbromberger> this results in the client seeing the certificate from the proxy that doesn’t match the certificate being presented by the repo
[2016-06-20 17:13:37] <dissipate> sbromberger: yeah, i think the odds are that Docker Hub requires SSL. on the other hand, you might be able to set up an HTTP proxy within your corporate network that terminates the SSL with Docker Hub. then, you would set that as an insecure registry with Docker.
[2016-06-20 17:20:41] <dissipate> sbromberger: this might help: [<-LINK->] 
[2016-06-20 17:21:10] <sbromberger> yeah. I’m not gonna be able to do this without a ton of paperwork. Not feasible, unfortunately.
[2016-06-20 17:22:28] <dissipate> sbromberger: why is that? the proxy would go through the MITM inside your corporate network, just like a browser. not sure what your company policies are on that, though.
[2016-06-20 17:22:48] <sbromberger> because we’re not allowed to just set up random proxies on the network :)
[2016-06-20 17:24:21] <dissipate> sbromberger: i see. not sure how they could police that, but if that's the case, sounds like things are really locked down
[2016-06-20 17:24:41] <sbromberger> things are really locked down. We have MAC filtering and continuous scanning.
[2016-06-20 17:24:56] <sbromberger> just getting to install docker in the first place was a major effort.
[2016-06-20 17:26:26] <dissipate> sbromberger: sounds like you are just going to have to fill out a bunch of paperwork... 
[2016-06-20 17:26:42] <sbromberger> nope. It means that docker won’t be used here, unfortunately.
[2016-06-20 17:27:19] <sbromberger> I don’t understand why there’s no option to say, “yes, I know it’s bad, but I really don’t want you to worry about validating server certs” - every other client I use has this option.
[2016-06-20 17:27:37] <dissipate> sbromberger: why is that? you could just 'sneakernet' some base images like Ubuntu 14.04 and use those to build your own images off of. or even just create your own base images.
[2016-06-20 17:27:53] <sbromberger> I can, but then there’s the issue of keeping them updated.
[2016-06-20 17:28:03] <sbromberger> not worth the hassle.
[2016-06-20 17:28:32] <sbromberger> easier just to use xen or virtualbox though it’s wasteful.
[2016-06-20 17:29:10] <dissipate> sbromberger: how do you get updates for your xen or virtualbox images?
[2016-06-20 17:29:33] <sbromberger> apt-get can be configured to ignore cert mismatches.
[2016-06-20 17:31:35] <dissipate> sbromberger: i see. bummer you won't be able to use Docker.
[2016-06-20 17:31:41] <sbromberger> yup.
[2016-06-20 17:32:03] <sbromberger> I might file an issue anyway in the hopes that one of the devs can take pity on those of us that live behind MITM proxies.
[2016-06-20 17:35:17] <dissipate> sbromberger: yeah, i would definitely do that. not sure how responsive they are on that stuff, though.
[2016-06-20 17:49:25] <sbromberger> hm
[2016-06-20 17:49:37] <sbromberger> how does one upgrade the mac beta?
[2016-06-20 17:49:49] <sbromberger> I’m still on 1.11, and apparently 1.2 came out today
[2016-06-20 17:55:49] <sbromberger> w00h00!
[2016-06-20 17:55:58] <sbromberger> 1.2 respectsinsecure-registries
[2016-06-20 17:56:16] <sbromberger> problem mooted.
[2016-06-20 17:58:08] <dissipate> sbromberger: link?
[2016-06-20 17:58:20] <sbromberger> dissipate: to what, the beta?
[2016-06-20 17:58:38] <sbromberger> I just downloaded the new beta and testeddocker pulland it worked.
[2016-06-20 17:58:45] <dissipate> sbromberger: the doc that explains theinsecure-registriesoption
[2016-06-20 17:59:02] <sbromberger> oh, dunno. I just tested it.insecure-registriescan be configured in the Settings dialog
[2016-06-20 17:59:08] <dissipate> sbromberger: nice!
[2016-06-20 18:18:10] <dissipate> does anyone have any info as to how docker-compose works with the new Swarm Mode?
[2016-06-20 18:54:23] <meonkeys> honest question (not trying to flame)... why was all the docker orchestration stuff built, rather than working with Kubernetes? The feature overlap seems nearly 1 to 1
[2016-06-20 19:13:44] <Rian0702> Hello, i am a complete noob to docker. Can someone help me before i waste my time reading through 300 internet articles?
[2016-06-20 19:14:11] <Rian0702> i went through this tutorial: [<-LINK->] 
[2016-06-20 19:15:03] <Rian0702> but this does not explain to upload any code to the docker (container?) ... anyone know a site for a good start into docker?
[2016-06-20 19:21:35] <jameshulse> Rian0702: , you can use COPY in your build step
[2016-06-20 19:22:19] <jameshulse> is there a docker debug log somewhere so I can see what is happening?
[2016-06-20 19:22:55] <chahn1138> That is the docker "cp" command, if you are interested in the command line....
[2016-06-20 19:23:22] <chahn1138> docker cp localfilename ContainerName:/path/on [<-LINK->] 
[2016-06-20 19:23:24] <MakanTaghizadeh> Rian0702: Or if you have a remote content you can simply use ADD command, but as@jameshulsesaid for local workspace files you'd better to use COPY
[2016-06-20 19:23:47] <Rian0702> okay thank you
[2016-06-20 19:24:25] <jameshulse>  [<-LINK->] 
[2016-06-20 19:25:35] <jameshulse> its hanging here without saying anything ^ any ideas?
[2016-06-20 19:27:53] <chahn1138> I might add "--log-level=info" to the command line (I have command line on the brain apparently ;0) but am not sure how to get that into a DOCKERFILE...
[2016-06-20 19:28:05] <chahn1138> (but I\'d make that level "debug")
[2016-06-20 19:28:26] <chahn1138> Then see what it says when you re-run
[2016-06-20 19:28:55] <MakanTaghizadeh> jameshulse: Can you dump the Dockerfile?
[2016-06-20 19:34:30] <jameshulse> its literally just 'FROM alpine:latest' at the moment
[2016-06-20 19:34:40] <jameshulse> I had more commands so I've trimmed it right back
[2016-06-20 19:35:00] <jameshulse> ugh. sorry guys, apparently I just had to be patiently
[2016-06-20 19:35:04] <MakanTaghizadeh> I see. Can you run justdocker pull alpine?
[2016-06-20 19:35:21] <jameshulse> I think it just wasn't outputting what it was doing for some reason
[2016-06-20 19:35:30] <MakanTaghizadeh> Great ;-)
[2016-06-20 19:35:45] <jameshulse> I'll try --log-level thanks
[2016-06-20 19:36:02] <jameshulse> I think it was silently downloading
[2016-06-20 19:36:55] <MakanTaghizadeh> I've never used Docker in windows, but it should print the pulling process anyway.
[2016-06-20 19:38:40] <jameshulse> strangely it did yesterday, but stopped without much explanation - obviously something in the configuration changed but I can't tell  what. once it is done doing whatever it is doing i'll try the log-level flag, thats just what I was looking for
[2016-06-20 19:38:59] <jameshulse> it was odd that on the command line I could dodocker build -t ghost-blog - < Dockerfileand see the output
[2016-06-20 19:50:38] <jameshulse> I figured it out -> the dockerfile was in a folder with another giant folder next to it. so it apparently sends the whole working directory to the daemon. The reason the '-' version worked is because it runs from a different context where this giant folder didn't exist.
[2016-06-20 20:11:51] <otbe> Hi *. Is there any way to get docker for mac working with VPN and local DNS servers? Both the docker deamon itself and containers cant resolve any name :( "VPN comatability mode" was one solution, but its not present anymore :/
[2016-06-20 20:17:34] <dissipate> meonkeys: i dunno, but I think Docker Inc. wants to compete with Mesos
[2016-06-21 05:09:54] <eddumelendez> hi guys, I have seendabthe experimental feature at DockerCon. I would like to know which resources from the docker remote api are used when I performdocker deploy. Thanks in advance
[2016-06-21 06:52:08] <aios> Any body knows how i can solve problem with getting ip on virtual machine on docker beta.
[2016-06-21 15:07:24] <SomaticIT> Hi everyone
[2016-06-21 15:07:49] <SomaticIT> I saw Docker 1.12 announcement and I should say it seems awesome
[2016-06-21 15:08:07] <SomaticIT> But I can't see volume configuration example for the newbundleformat
[2016-06-21 15:08:25] <SomaticIT> Do someone know how to do this ?
[2016-06-21 15:21:34] <sbromberger> gah
[2016-06-21 15:21:41] <sbromberger> the TLS verification reared its ugly head again
[2016-06-21 15:21:47] <sbromberger> I guess it wasn’t fixed in 1.12
[2016-06-21 16:00:15] <ehernandez-xk> Hi all,  somebody  here with experience using custom boot2docker with Packer?
[2016-06-21 16:25:46] <BlessYAHU> Is there a benefit to using Docker to deploy a Wordpress site?
[2016-06-21 16:51:49] <ehernandez-xk> BlessYAHU: easy configuration,  easy maintenance,  you will have an isolate site, if something is wrong you can start up another site quickly.
[2016-06-21 17:28:22] <dissipate> SomaticIT: any info on thebundleformat? i haven't seen anything about that
[2016-06-21 17:29:46] <dissipate> SomaticIT: the lack of documentation on all these new features of docker 1.12 is making things very confusing. i'm holding off on 1.12 until there are more docs, especially regarding this new DAP format.
[2016-06-21 20:51:42] <DevBOFH> Has anyone run into "Error response from daemon: missing signature key" when trying to do a docker pull from a private registry?
[2016-06-22 07:31:09] <SomaticIT> dissipate: I found that there is a [<-LINK->] option fordocker service create/updatecommands but I can't see equivalent for theDABformat. Anyone from Docker ?
[2016-06-22 09:10:25] <pravicloud>  [<-ISSUE->] 
[2016-06-22 09:10:31] <pravicloud> check this link
[2016-06-22 10:27:10] <daslicht> hi, I like to use docker as local lamp stack , I installed docker and kitematic under osx and am I instaleld this: [<-LINK->] When I run it I get : [<-CODE->] 
[2016-06-22 10:27:14] <daslicht> whats wrong ?
[2016-06-22 10:31:27] <daslicht> ok i tried another image which works !
[2016-06-22 10:46:46] <daslicht>  [<-LINK->] 
[2016-06-22 10:47:02] <daslicht> how does mapping volumes work here ?
[2016-06-22 10:51:02] <daslicht>  [<-LINK->] 
[2016-06-22 10:51:07] <daslicht> the docs are outdated
[2016-06-22 13:57:19] <mr-rodgers> Hi everyone. Is the guy who answered this right? [<-LINK->] 
[2016-06-22 13:57:47] <mr-rodgers> ELI5 because if he is, I think I'm severely mistaken about how networking works
[2016-06-22 16:16:33] <mr-rodgers> ahhh, just realised I'm in the wrong place
[2016-06-22 19:10:11] <BlessYAHU> I\'m trying to build a container built from the following dockerfile and it tells me it can\'t find apache2ctl:FROM ubuntu:14.04MAINTAINER barakhyahu@gmail.comRUN apt-get update && apt-get upgradeRUN apt-get install -y  apache2EXPOSE 80CMD ["apache2ctl", "-D", "FOREGROUND"]Cany anyone help me spot the issue?
[2016-06-22 20:25:38] <wesleyvicthor> hey guys, not sure why but I always get connection refused after docker-compose
[2016-06-22 20:26:02] <wesleyvicthor> I have used the machine ip but does not work
[2016-06-22 20:26:15] <wesleyvicthor> this is crazy
[2016-06-22 20:42:15] <wesleyvicthor> BlessYAHU: as it is a ubuntu container tryservice apacher start|stop|restart ...
[2016-06-22 20:51:12] <BlessYAHU> Will do. thanks.
[2016-06-22 21:35:52] <BlessYAHU> That didn't work.  Thinking something is wrong with my image maybe?
[2016-06-23 00:08:35] <dignajar> Hi, I'm working on a container, Nginx and PHP-FPM, based on the official Nginx image, [<-LINK->] 
[2016-06-23 00:10:38] <elewis787> Hey ! thats funny I just created one
[2016-06-23 00:11:09] <dignajar> Nice, can I see your Dockerfile ?
[2016-06-23 00:11:47] <dignajar> I want to optimezed both services
[2016-06-23 00:12:22] <elewis787> Yours looks really nice ... mine is way more basic, I'm afraid it wouldn't be much help :/
[2016-06-23 00:12:53] <dignajar> I was working with nginx and php-fpm in separted containers
[2016-06-23 00:13:22] <dignajar> but the problem was the php files shared
[2016-06-23 00:13:37] <dignajar> and I decided to mix both servicies
[2016-06-23 00:13:37] <elewis787> I see.
[2016-06-23 05:36:57] <fracting> Hi folks, could anyone tell me which syntax is correct: 1.SecurityOpt:      []string{"seccomp:unconfined"}, 2.SecurityOpt:      []string{"seccomp=unconfined"}? Should I use:or=as a delimiter when passing argument to  docker.run() ?Thanks!
[2016-06-23 05:39:10] <fracting> sorry, seems wrong channel, this is for contributor only? :)
[2016-06-23 08:08:58] <fracting> ok, answer my own question:SecurityOpt: []string{"seccomp=unconfined"}is correct
[2016-06-23 08:10:53] <daslicht> how does mapping volumes work here ? [<-LINK->] the docs are outdated
[2016-06-23 08:11:20] <daslicht> how to do it programatically please?
[2016-06-23 08:11:37] <daslicht> or even better with kitematic
[2016-06-23 10:29:11] <Egoscio> Hello world! I'm fairly new to the concept of docker, and I was wondering exactly how secure the sandbox is. Say I rundocker run -it debian bash, and I download a script or binary from the internet. Are there any possible negative ramifications to executing said file?
[2016-06-23 10:30:05] <Egoscio> I'm asking this because I've learnt that VM's such as virtualbox can sandbox completely, therefore it is safe to run any code inside. Is the same true for docker?
[2016-06-23 11:55:10] <aios> Hi all. Anybody can explain why docker beta 1.12 when i command docker login https://sample.com/v2 and input login and passtake me an error for [<-CODE->] How i can get response from v2 of my private registry
[2016-06-23 18:32:25] <aios> just was problem with acces to internet
[2016-06-23 18:32:45] <aios> so another question. Any body can help with docker-compose.yml v2
[2016-06-23 18:33:03] <aios> doesnt generate hostname as sevice name
[2016-06-23 18:33:27] <aios> and i have problem withhost not found in upstream "php" in
[2016-06-23 18:33:31] <aios> nginx
[2016-06-23 18:40:45] <Daniyal8876_twitter> i am facing problem on docker cloud i want to set contianer_name as we set docker-compose.yml file but now i want to set container_name in docker-stack file for cloud but docker cloud is not allowing to set this property any solution
[2016-06-23 19:27:11] <aios> volumes not working
[2016-06-23 19:42:17] <Nezteb> Comodo why you do this :( . [<-LINK->] 
[2016-06-23 21:01:55] <yordis> Hello everyone, How can I pass some SSH key to my containers at thebuildtime. This is kind of required for my process right now and I don't want to put myssh keysinside my containers.
[2016-06-23 21:02:21] <yordis> And the docker documentation says that is not recommend to usebuild-argsfor pass any of those information
[2016-06-23 21:11:07] <dissipate> yordis: yeah, if it is at all possible, it is bad practice to have secrets in your docker images. usually what you want to do is have your process pull down private keys via some secrets management system at run time.
[2016-06-23 21:29:11] <yordis> dissipate: but I need this to happen in the build, this come from private Gem repos. 
[2016-06-23 21:30:20] <yordis> I would prefer to just have some proxy that use my SSH keys from my machine that the container doesn't know at all about the ssh keys
[2016-06-23 21:30:40] <yordis> I don't, I am trying to do something that make sense and dont give me security concerns about it
[2016-06-23 21:34:12] <dissipate> yordis: I haven't used them, but I think you can embed environment variables in a Dockerfile
[2016-06-23 21:36:57] <dissipate> yordis: see: [<-LINK->] 
[2016-06-23 21:39:50] <kauhat>  [<-CODE->]  [<-CODE->] E.g. [<-CODE->] Thanks!
[2016-06-23 23:19:53] <Egoscio> Many questions but no answers.
[2016-06-24 06:58:16] <ksylvan> Hi does anyone know when [<-LINK->] will include packages for Fedora 24?
[2016-06-24 08:02:37] <pantonis> I read about dockers and I can say that I am impressed.
[2016-06-24 08:02:47] <pantonis> however I didn't understand if it is free
[2016-06-24 08:03:36] <Egoscio> yeah it's free.
[2016-06-24 08:04:14] <Egoscio> there might be certain corporate aspects thought, but I got a container working fine using the mac toolkit
[2016-06-24 08:04:20] <Egoscio> Didn't even sign up for anything
[2016-06-24 08:04:35] <pantonis>  [<-LINK->] 
[2016-06-24 08:04:39] <pantonis> according to this it is not
[2016-06-24 08:05:01] <Egoscio> "Containers-as-a-Service"
[2016-06-24 08:05:06] <Egoscio> Anything as a service is paid.
[2016-06-24 08:05:11] <Egoscio> You can host it yourself for free.
[2016-06-24 08:05:30] <pantonis> I have a windows server 2012 r2 physical machine
[2016-06-24 08:05:35] <pantonis> can I install it there for free?
[2016-06-24 08:06:25] <Egoscio>  [<-LINK->] 
[2016-06-24 08:07:05] <Egoscio> more information on the service
[2016-06-24 08:07:06] <Egoscio>  [<-LINK->] 
[2016-06-24 08:07:44] <pantonis> I dont understand the difference of the service
[2016-06-24 08:07:51] <pantonis> can you please explain
[2016-06-24 08:09:04] <Egoscio> Essentially, the docker software is free
[2016-06-24 08:09:12] <Egoscio> having it hosted is a paid service
[2016-06-24 08:09:13] <Egoscio>  [<-LINK->] 
[2016-06-24 08:09:47] <Egoscio> so, like, a cloud service
[2016-06-24 08:09:48] <pantonis> you mean me hosting it for others must pay a license to docker inc?
[2016-06-24 08:09:59] <pantonis> but me for personal use it is free?
[2016-06-24 08:11:33] <Egoscio> I'm pretty sure it's not like that. You should be able to use it for free regardless of how it's being used, it's just the convenience of it being a service that makes it paid. But don't take my word for it, I just discovered docker a few of days ago.
[2016-06-24 08:12:55] <pantonis> ok thanks
[2016-06-24 08:13:11] <pantonis> on which os do you use it. Linux or Windows?
[2016-06-24 08:13:57] <Egoscio> Mac
[2016-06-24 08:14:06] <Egoscio> I don't know why I wrote windows, lol
[2016-06-24 08:14:16] <Egoscio> I'm a Mac, and I run Debian on it for the most part.
[2016-06-24 08:14:23] <Egoscio> Sometimes ubuntu
[2016-06-24 08:18:48] <pantonis> ok
[2016-06-24 08:18:50] <pantonis> thanks
[2016-06-24 09:13:56] <pantonis> is there any GUI manager for docker?
[2016-06-24 09:14:37] <kauhat> pantonis:  [<-LINK->] might be what you're looking for
[2016-06-24 09:17:45] <pantonis> Kauhat: thanks. this is more like a container management tool. I was looking for some settings administration software
[2016-06-24 09:18:00] <pantonis> for example I want to change the location that the containers are created..
[2016-06-24 09:22:26] <kauhat> Ah, I see!
[2016-06-24 09:22:52] <pantonis> are you aware of such a software?
[2016-06-24 09:26:26] <kauhat> pantonis: I'm not,  but if anybody mentions anything like that does that I would be interested as well.
[2016-06-24 09:27:31] <pantonis> ok
[2016-06-24 09:29:24] <pantonis> from what I read I cannot move the container path outside of docker installation path. Is that true?
[2016-06-24 10:42:57] <Daniyal8876_twitter> any one working or stack file for cloud
[2016-06-24 10:47:44] <aios> anybody can help - [<-CODE->] doesnt work  on windows and docker beta
[2016-06-24 10:49:01] <cedvan> docker container start on VM, so syntax.don't work
[2016-06-24 10:49:42] <aios> that is way to target folder with code to container
[2016-06-24 10:49:52] <aios> how i can make that?
[2016-06-24 10:50:51] <cedvan> share your folder with docker VM and enter full path to target folder in docker-compose.yml
[2016-06-24 10:52:06] <aios> cedvan: so - that way just worked on virtualbox + boot2docker - on Hyper-V another way ?
[2016-06-24 11:00:03] <aios> cedvan: so with hiper-v i cant share folders
[2016-06-24 11:00:30] <aios> but one folder targets - from code folder - that is logs
[2016-06-24 11:04:31] <kauhat>  [<-LINK->] 
[2016-06-24 11:04:48] <kauhat> aios: Can you make sure that box is ticked?
[2016-06-24 11:07:15] <aios> Kauhat: yep - hold on second
[2016-06-24 11:08:02] <aios> Kauhat: so i will take a full path in compose file?
[2016-06-24 11:08:22] <aios> like C:/apps/app1:/srv  that way is right?
[2016-06-24 11:10:08] <kauhat> I think so, so far I've only seen relative paths used for that sort of thing though, e.g. [<-CODE->] 
[2016-06-24 11:11:00] <kauhat> In that example thedocker-compose.ymlwas in a subdirectory of the main project - handy!
[2016-06-24 11:11:53] <aios> Kauhat: hm - i started docker compose with shared tick in docker settings on drive C:
[2016-06-24 11:12:02] <aios> but behaivor doesnt change
[2016-06-24 11:12:14] <kauhat> Hmm, that's strange.
[2016-06-24 11:13:04] <kauhat> I'm not sure then I'm afraid, I've not got too much experience with Docker!
[2016-06-24 11:13:23] <aios>  [<-LINK->] 
[2016-06-24 11:15:34] <aios> wow surely i found a problem.. that is doesnt in share drives
[2016-06-24 11:33:34] <aios> so that is no solution.
[2016-06-24 11:33:42] <aios> problem still active
[2016-06-24 11:34:00] <aios> docker inspec says normal mounts and binds
[2016-06-24 11:34:15] <aios> ls -la /c/Users/Aios/laradock/docker4/laravel  outputs all files.
[2016-06-24 12:29:59] <arunky> I have many microservices and i want to configure a constant port ex 9090 for all of them and when i start the docker container with it with option --net=host, can docker assign any availalbe port from the host..I do not care which port it assigns as i am using service registration and discovery (eureka).. is there such option in docker?
[2016-06-24 13:11:56] <barnabas-szekeres> Hi everyone! Sorry for the noob question, but i just want to know how possible run windowsservercore on mac with the new beta Docker. Or  i have to forget it because it's not possible? :) I just tried pull the microsoft/iis image but i can't run it. Anyway what i want to achieve is a windows server environment what run .net and IIS on macOS.
[2016-06-24 13:27:07] <diegolameira> Does anybody knows why my nginx container is settings some Syntax error with some invisible chars into my js?
[2016-06-24 15:34:00] <ZiLonn_twitter> barnabas-szekeres: I don't think you can run Windows software in docker yet. However when window server 2k16 hits they wil have container support and likely will be able to run window software in containers.
[2016-06-24 15:35:55] <ksylvan> Hi does anyone know when [<-LINK->] will include packages for Fedora 24?
[2016-06-24 15:56:49] <otbe> Hi everybody! Is there a place where I can file an issue for "Docker for Mac"? (1.12.0-rc2)
[2016-06-24 17:07:44] <remram44> Isn't Docker for Mac still Docker?
[2016-06-24 17:08:22] <programmerq> otbe: what issue do you have?
[2016-06-24 17:09:27] <programmerq> otbe: see [<-LINK->] 
[2016-06-24 17:09:32] <programmerq> post your issue there
[2016-06-24 17:09:36] <programmerq> it’s not an issue tracker per se
[2016-06-24 17:09:49] <programmerq> but the dfm/dfw devs do watch that.
[2016-06-24 22:58:36] <yordis> dissipate: I can’t use those from the doc
[2016-06-24 22:58:44] <yordis>  [<-CODE->] 
[2016-06-25 03:10:45] <dissipate> yordis: yep, i know that, hence, i recommended a secrets management system
[2016-06-25 05:27:33] <ZiLonn_twitter> How do i find the paramaters an already started docker container? Meaning, If i wanted to repoduce how the conatiners started with the right variables/param how would i find it?
[2016-06-25 06:11:31] <dissipate> ZiLonn_twitter: see: [<-LINK->] 
[2016-06-25 06:23:05] <otbe> programmerq: thanks!
[2016-06-25 06:24:52] <otbe> There is an issue with VPN (maybe cisco anyconnect related) and internal services
[2016-06-25 06:30:29] <ZiLonn_twitter> Thank you@dissipate
[2016-06-27 00:51:03] <diegoaguilar> Hello, anyone here alive?
[2016-06-27 00:51:11] <Egoscio> Hardly
[2016-06-27 09:25:39] <hh42> hello
[2016-06-27 09:27:36] <hh42> is there anyone here who has already tried to set up react environment with docker container ?
[2016-06-27 14:18:33] <andrestc> Hi, is there a way to have "links" on docker-compose work on bundles and stacks (1.12-rc2)?
[2016-06-27 21:02:04] <wkoszek> Some Docker images on hub.docker.com have "Dockerfile" link, and some do not. How can I make this link to show up for my image?
[2016-06-27 21:26:35] <dissipate> andrestc: did you try just putting links in your compose file and see what happens when you launch the stack?
[2016-06-27 22:10:29] <alvarolizamam> when the images is generated automatically from a github repository the Dockerfile es omitted  but the repository url is public and there is the Dockerfile
[2016-06-27 22:11:32] <alvarolizamam> when you push directly to hub.docker.com you push the dockerfile too
[2016-06-27 23:07:07] <wkoszek> Hm. So my understanding is that Dockerfile link is there if I register autobuilding?
[2016-06-27 23:07:22] <wkoszek> Right now I'm doing: docker push wkoszek/base for example.
[2016-06-27 23:07:43] <wkoszek>  [<-LINK->] 
[2016-06-27 23:08:30] <alvarolizamam> my bad the dokerfile appear when is an automated build
[2016-06-27 23:08:35] <wkoszek> Yeah.
[2016-06-27 23:08:47] <wkoszek> Otherwise I think there's no way for docker to know when Dockerfile is from.
[2016-06-27 23:09:16] <wkoszek> How about Description etc.. ? Is there a way to submit it automatically from a .md file or something?
[2016-06-27 23:09:38] <wkoszek> I wanted to keep most of my stuff in GitHub and maybe reuse some of the README.md as hub.docker.com documentation.
[2016-06-28 05:10:32] <smebberson> Is anyone using Docker Cloud Build with automated deployments? I'm just wondering how you can synchronise deployments of updates to multiple images within a stack (use case: updated container-A requires updated container-B)...
[2016-06-29 16:49:37] <etolbakov> Hi@/all!I'm pretty new to docker, could you please help me.I've launched mysql image (mysql:latest) and apply necessary migrations with liquibase.So the database itself and all tables inside are fine.Later I've tried to perform an insert operation and it failed with timeout(error 1205 (hy000) lock wait timeout...) Unfortunately, I have no clue what was the reason.Could you please give me hint, how to fix that ?P.S. Environmentcentos 7
[2016-06-29 16:58:51] <driverpt> Hello
[2016-06-29 16:58:53] <driverpt> quick question
[2016-06-29 16:59:02] <driverpt> how do i isolate containers in production
[2016-06-29 16:59:12] <driverpt> i did a docker run to port 8080
[2016-06-29 16:59:23] <driverpt> but i don\'t want to expose it to the "open world"
[2016-06-29 16:59:37] <driverpt> i want all containers to only be acessible locally
[2016-06-29 16:59:45] <driverpt> and i reverse-proxy the ones that i want to be public
[2016-06-29 18:12:28] <dalanmiller> smebberson: From within docker hub you can trigger rebuilds of your images based on rebuilds of other images (ideally ones that yours are dependent on)
[2016-06-29 22:54:43] <smebberson> dalanmiller: Thanks for you response. But I was more interested in how these could be deployed in a synchronised fashion to Docker Cloud.
[2016-06-29 22:55:25] <dalanmiller> From what I’ve seen of  Docker Cloud yet (I went through some of the labs at DockerCon), I’m not sure you can auto trigger builds based on other images, but I could very well be wrong
[2016-06-29 22:57:29] <smebberson> Yeah, I use Docker Cloud quite a bit and I've setup Docker Cloud Build and auto redeploys already. But I can't see anything to do what I require. Thought I'd ask here to see if anyone else has any insights. I imagine it would be a common pattern.
[2016-06-29 22:58:19] <smebberson> driverpt: Try this for a complete example [<-LINK->] 
[2016-06-29 23:36:26] <groundnuty> hey, I've been reading about volumes. Lets say we have a simple compose file with one nginx server and second data only container that serves html files
[2016-06-29 23:36:57] <groundnuty> how would I update the html files in a volume created by a data only container, without restarting nginx
[2016-06-29 23:57:33] <smebberson> groundnuty: Are you mapping the volume in the compose file back to a directory on your host?
[2016-06-30 00:09:18] <groundnuty> smebberson: no the whole idea was to have all the data in docker
[2016-06-30 00:09:21] <groundnuty> example [<-LINK->] 
[2016-06-30 00:10:12] <groundnuty> this creates a volume, seen with 'docker volume ls'
[2016-06-30 00:10:42] <groundnuty> I can't find a way to update the 'documentation' files present in doc container
[2016-06-30 00:11:05] <groundnuty> without doing the whole docker-compose down -v && docker-compose up
[2016-06-30 00:11:45] <smebberson> Are you wanting to do this in production or development?
[2016-06-30 00:12:06] <groundnuty> we wanted to do that in production
[2016-06-30 00:12:48] <groundnuty> idea was to have a nice docker-compose file where everything is nicely connected together
[2016-06-30 00:12:48] <smebberson> So in production, you just build another copy of the volume container and then push it. Restart the container on your production and you're good.
[2016-06-30 00:13:18] <smebberson> In development, you should map the volume to a local path on your host so that you can test/access the files through the web server.
[2016-06-30 00:13:18] <groundnuty> and just change image tags when a new version of a container is publushed
[2016-06-30 00:13:32] <groundnuty> smebberson: I understand however
[2016-06-30 00:13:42] <smebberson> Yeah, or run:lateston production so that it just picks up the latest.
[2016-06-30 00:14:00] <groundnuty> lets say that thos docker compose is running now with docker-compose up -d
[2016-06-30 00:14:09] <groundnuty> new documentation was released
[2016-06-30 00:14:31] <groundnuty> I edited the compose, enterend new tag in place of the old one in the line: image: [<-LINK->] 
[2016-06-30 00:15:02] <groundnuty> now I have the new docker-compose.yml file and the old thing still running
[2016-06-30 00:15:35] <groundnuty> what command woudl you use, to make a documentation updated in nginx without restarting nnginx? :)
[2016-06-30 00:16:29] <groundnuty> smebberson: ^
[2016-06-30 00:17:26] <smebberson> Something likedocker stop doc && dc rm --force doc && dc up -d --no-recreate doc
[2016-06-30 00:22:47] <groundnuty> smebberson: so that's what happened
[2016-06-30 00:23:12] <groundnuty> the component couldnt be stop - since its just a data component - not running (no problem here)
[2016-06-30 00:23:23] <groundnuty> the component was --force removed
[2016-06-30 00:23:40] <groundnuty> the volume it orginally created was left intact attacked to nginx
[2016-06-30 00:23:55] <groundnuty> sory container not component :)
[2016-06-30 00:24:28] <groundnuty> new  doc container was created with new volume for it, but nginx is is still using old volume
[2016-06-30 00:25:18] <smebberson> I'm not sure. I usually ship the files I want to serve with the nginx container itself.
[2016-06-30 00:25:40] <groundnuty> yea, we had a fancy idea of connecting data to services with compose :(
[2016-06-30 00:26:36] <groundnuty> so far I have no found a way to update data in the volume
[2016-06-30 00:26:55] <groundnuty> documentation says that when volume is created data is copied from container to volume
[2016-06-30 00:27:06] <groundnuty> but there is no mention of updating this data
[2016-06-30 00:27:23] <smebberson> Yeah, I guess you actually have to restart the Nginx container.
[2016-06-30 09:48:15] <tsvetann> I have some issues with docker on OSX. all my containers go into timeout state like every 30 mins. so I have to docker-machine restart container. Any idea how to debug whats going wrong with my env? Thx
[2016-06-30 15:00:08] <ventskus-roman> Hi!Is there any possibility to set a link to another docker container, which will be accessible via browser?
[2016-06-30 15:00:44] <ventskus-roman> I mean, there is web application, separated to server and client applications
[2016-06-30 15:00:55] <ventskus-roman> first - just backend
[2016-06-30 15:01:06] <ventskus-roman> second - ui, with angularJS
[2016-06-30 15:01:50] <ventskus-roman> and I need somehow to say angularJS application to call correct backend (docker container)
[2016-06-30 15:02:32] <ventskus-roman> when I use links feature - it unavaileble via browser (because browser is outside docker)
[2016-06-30 15:03:11] <ventskus-roman> now I've just hardcoded url in angular config, but it`s bad way
[2016-06-30 15:04:06] <ventskus-roman> Could you tell me better solution for my situation?
[2016-06-30 21:14:08] <dissipate> ventskus-roman: you need service discovery. a very popular solution for that right now is Consul: [<-LINK->] 
[2016-06-30 21:14:57] <dissipate> ventskus-roman: also check out consul-template for 'on the fly' config changes: [<-LINK->] 
[2016-06-30 21:16:33] <dissipate> ventskus-roman: in addition to service discovery, you will want load balancing as well. check out registrator: [<-LINK->] which can be used with consul-template and nginx to provide 'on the fly' reconfiguration of nginx for load balancing.
[2016-07-01 07:25:13] <ventskus-roman> dissipate: thank you very much!
[2016-07-01 13:09:46] <l15k4> hey, is the size of thedelayconfigurable? [<-LINK->] 
[2016-07-01 13:10:24] <l15k4> I need my container to restart after a few seconds
[2016-07-02 17:32:44] <sebastian-palma> does anybody know what to do when this error appears "Cannot connect to the Docker daemon"?
[2016-07-02 17:33:20] <sebastian-palma> I'm trying to vagrant up the scalingexcellence repository from the book Learning Scrapy
[2016-07-04 03:23:27] <bitsofinfo> Using 1.12 beta for mac. Created a networkdocker network create mynetand launched one container in it. This container needs to connect to mysql running on my Mac laptop. What IP should I give it? I tried the gateway listed fordocker network inspect mynetbut it does not work...
[2016-07-04 04:03:03] <bitsofinfo> figured it out ignore
[2016-07-04 05:10:56] <brendo-m> Hi all. I'm running a docker registry inside a VM using the --insecure-registry flag. My VM host has IP 10.100.198.200. I can ping it and [<-LINK->] returns {}, as expected, but I get TLS errors trying to push to it: [<-CODE->] 
[2016-07-04 05:11:05] <brendo-m> Any thoughts?
[2016-07-04 09:54:35] <ventskus-roman> Did someone tryed to debug java container via Windows machine?
[2016-07-04 09:54:53] <ventskus-roman> I`m getting just an error all time
[2016-07-04 09:55:11] <ventskus-roman> ENTRYPOINT ["java","-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8000 -Djava.security.egd=file:/dev/./urandom","-jar","/app.jar"]
[2016-07-04 09:55:34] <ventskus-roman> and I`ve forwarded 8000 port throught docker-compose
[2016-07-04 09:56:08] <ventskus-roman> trying to connect 192.168.99.100:8000 for debug via Intellij Idea, but it fails
[2016-07-04 17:48:47] <swapnilsm> How to specify thedocker runcommand parameters indocker service createcommand?
[2016-07-05 14:09:59] <sachinpk> I've a gitlab server(dev.git.example.com) and a private docker registry (dev.docker.example.com). I would like to control my docker registry through gitlab server, if it is possible please let me know how to do it?
[2016-07-05 14:21:24] <elewis787> brendo-m: Failing…Failing to configure the Engine daemon and trying to pull from a registry that is not using TLS will results in the following message:
[2016-07-05 14:21:36] <elewis787> FATA[0000] Error response from daemon: v1 ping attempt failed with error:Get [<-LINK->] : tls: oversized record received with length 20527.If this private registry supports only HTTP or HTTPS with an unknown CA certificate,please add--insecure-registry myregistrydomain.com:5000to the daemon's arguments.In the case of HTTPS, if you have access to the registry's CA certificate, no need for the flag;simply place the CA certificate at /etc/docker/certs.d/myregistrydomain.com:5000/ca.crt
[2016-07-05 14:23:39] <elewis787> brendo-m: the insecure registry flag needs to be added to the both docker daemons I believe.. so your local running docker daemon and the VM's docker daemon.
[2016-07-05 14:23:45] <elewis787> could be wrong tho :P
[2016-07-05 16:14:54] <DominicBoettger> I am using docker on a remote machine. Can i map ports from localhost under windows to the remote machine?
[2016-07-05 19:06:45] <DominicBoettger> by the way netsh is your friend to proxy ports ....
[2016-07-05 23:56:34] <lindsaymarkward> Hi@dissipate- I have the same question as@ventskus-roman. Is there a tutorial or example online for consul.io that either of you would recommend? Thanks :)
[2016-07-06 04:55:48] <stevezau> anyone know an easy way to get docker 1.11.2 on amazon linux??
[2016-07-06 04:55:54] <stevezau> they a really slow to update their repos
[2016-07-06 04:58:01] <stevezau> screw it.. moving to ubuntu
[2016-07-06 07:47:00] <asperling> DominicBoettger: Yes, by establishing one or more SSH tunnels. How you do so is Windows specific and I don\'t have a clue but utilizing google with the term "SSH tunnel windows" shows promising results.
[2016-07-06 14:02:02] <zhongdj> Hey Guys, who knows where is the docker beta for mac channel, i have a friend, who just updated to latest version, and docker engine seems to be crashed:diagnosis gives failure: docker ps failed: Failure("docker ps: timeout after 10.00s")
[2016-07-06 17:32:12] <dissipate> lindsaymarkward: this might get you started: [<-LINK->] 
[2016-07-06 21:53:55] <BlessYAHU> I have a wordpress and mysql container on a digital ocean droplet.  Both are running disconnected, but the MySql container keeps stoping.  I still need to check the logs, but has anyone come across this before?
[2016-07-07 06:49:39] <nojaf> Hi
[2016-07-07 06:50:28] <nojaf> I\'m playing with the latest docker beta for Windows and I\'m trying to hook my source code inside a nodejs container.PS > docker run -p 8080:8300 -v /c/Users/Me/Projects/hello-node:/var/www -w "/var/www" node node index.js
[2016-07-07 06:51:01] <nojaf> Somehow the volume doesn't contain my files, [<-CODE->] 
[2016-07-07 06:51:35] <nojaf> What am I missing here?
[2016-07-07 06:54:11] <nojaf> My bad, turns out my C:\\ drive wasn't shared
[2016-07-07 11:09:43] <oleksiidrobiazko> Hi, guys.Anybody could help me with the problem of connection to the postgres that's run in container.Actually I have written the question on stack overflow but without answer.http://stackoverflow.com/questions/38199747/how-to-connect-to-postgresql-server-thats-run-on-dockerThanks any.
[2016-07-07 17:32:50] <DominicBoettger> asperling: it was quite easy there is a awesome proxyport option in netsh
[2016-07-07 22:32:10] <andersonkyle> Should anyone extend Official Docker Images for use in Production since Tags are Mutable?  If we extend an Official Docker Image, how do we know that nothing has changed?  For example, let's say we have a Java application and we extend java:8-jre That will currently bring down version 8u91 but in a few months time it could bring down a new version, 8u127...  My understanding is that the only way to control the environment is to build all images from scratch and then only extend your own custom images.  This definitely takes the fun out of it, but since Tags are updated all the time, it is out of my control at that point... Any thoughts on this?
[2016-07-08 00:24:17] <rajiff> Hi, any one knows if i can base my image based on two different base images
[2016-07-08 00:24:27] <rajiff> i.e., my Dockerfile will begin like this
[2016-07-08 00:25:10] <rajiff>  [<-CODE->] 
[2016-07-08 02:10:14] <rajiff> Googling, suggests, its not be done like, that Docker file reference say you can have multiple FROMs. What would be the correct way to do this?
[2016-07-08 03:13:38] <justinhj_twitter> Wouldn't it be better to have two Dockerfiles
[2016-07-08 03:14:19] <justinhj_twitter> First one would be the base image with your modifications, second one would take the image created by the first one and modify it further as needed
[2016-07-08 04:48:32] <rajiff> true, but not all time we will have a modification to create a intermediate image
[2016-07-08 07:42:39] <matanshukry> What is the suggested way to create database schemes for an app? (the database and the app are each containers, yet I did not build any of them, so I can't change code)
[2016-07-08 13:20:15] <birkof> Hey guys! How can I have multiple containers on diferente IPs but in the same port. Lets say I have two nginx containers which expose port 80. How can I have one container per IP? Im using Docker for Mac (beta version).
[2016-07-08 13:23:44] <birkof> Right now I am having only one container exposing on port 80 on ip address 0.0.0.0
[2016-07-08 13:27:25] <isalcedo> Maybe I'm wrong but, I think the main problem here is the port on the host. There is just one 80 port per host. That's a conflict.
[2016-07-08 13:27:56] <birkof> So it is not posibile
[2016-07-08 13:28:17] <birkof> ..possible to have one IP per container
[2016-07-08 13:29:41] <isalcedo> Actually, you can run one container with the two services inside it, exposing port 80. You can have individual IP per container, but you can't  use the same port on host two times at the same time.
[2016-07-08 13:30:25] <birkof> I cannot attach a running container to a virtual network interface?
[2016-07-08 13:30:55] <birkof> I guess by default its attached to lo0
[2016-07-08 13:31:39] <isalcedo> Just for example. You can run MySQL in one container and PHP in another or the two running in just one that serve ports 80 (for Apache) and 3306 (for MySQL).
[2016-07-08 13:32:00] <isalcedo> About your last question, sorry but I don't know the answer.
[2016-07-08 13:32:31] <birkof> Thats my question, in the end :D
[2016-07-08 13:33:40] <isalcedo> I'm sorry. I don't know about it. 
[2016-07-08 13:41:30] <birkof> Ok. Thanks anyway!
[2016-07-08 14:28:13] <isalcedo> How long it takes in Hub.Docker to index in the search results a public repo?
[2016-07-09 00:58:10] <youcandanch> Got a wonky question I'm striking out on - our CI (homebrewed internally) platform runs in a compose cluster, and we're starting to adjust it to be able to build/run/push images (sort of a DinD situation). I've got the CI's compose declaration set toprivileged: trueand I'm mounting- /var/run/docker.sock:/var/run/docker.sock, and I'm able to actuallybuildimages - the problem is that it doesn't seem to be honouring copy operations fully. If I specify exact filenames or directories, copy works just fine, but in a Dockerfile that has something likeCOPY . /usr/src/app, it copies absolutely nothing over to the created image.
[2016-07-09 00:59:25] <youcandanch> It looks like it's just passing nothing through by context back to the Daemon - running a build on my host for one of our images passes ~61mb to context, within the CI container it's passing ~8
[2016-07-09 01:00:02] <youcandanch> (Ubuntu host, builddeps:jessie base images across the board.)
[2016-07-09 01:02:03] <youcandanch> A previous copy step totally works, too - I'm doing [<-CODE->]  [<-CODE->] 
[2016-07-09 01:03:54] <youcandanch> ...okay, take this all back, I just deleted the .dockerignore file in the code the CI is trying to make an image for and it's totally peachy.
[2016-07-09 01:06:04] <youcandanch> Just bizarre, since the same .dockerignore file on the host is totally fine.
[2016-07-09 01:26:43] <youcandanch> Turns out we have two lines: [<-CODE->] And blowing away the second line resolved it. Turns out that directory doesn't exist on the file system, and replicated it on a non-DinD scenario as well. That's gotta be a bug, right?
[2016-07-10 17:57:11] <dignajar> Hi, I want to mount a volumen inside a container and make some modifications inside the volumen (create new files), but I don't want this changes reflected on the host, there is some way to do this ?
[2016-07-10 18:00:49] <dignajar>  [<-CODE->] 
[2016-07-10 18:02:00] <dignajar> the file test.txt is created in the docker container and in the host, but my idea is this file created just inside the container..
[2016-07-10 19:38:53] <tim-klug> the idea behind a volume is, that files from the host system are linked to the container. You need to create your file outside the linked path.
[2016-07-10 21:15:27] <dignajar> Ok, I understand, how can I copy the path /home/guest/app with a Dockerfile ?
[2016-07-10 21:15:54] <dignajar> because I need the files in the same root as the Dockerfile, and in this case I don't have it
[2016-07-10 21:16:11] <dignajar> My Dockerfile is in, /home/guest/docker/Dockerfile
[2016-07-10 21:20:07] <dignajar> and my files are in /home/guest/app
[2016-07-10 21:21:04] <dignajar> I'm thinking to mount the volume, and then copy the files in different path inside the container.. but is very ugly
[2016-07-10 21:31:28] <tim-klug> can you go with thedocker cp …Here you can copy all files you need into your container.
[2016-07-10 21:36:14] <tim-klug> If you want to work on files inside the docker container, without using a volume, I think you need some 3rd party tooling. Some time a go I used a Samba server on the container to have access to the files inside. I’m not sure if that is the way you need to go today.
[2016-07-11 04:07:41] <baozilala> docker run -it -d -p 80:80 -v /Users/xxx/Docker/lamp/data/mysql:/var/lib/mysql -v /Users/xxx/Docker/lamp/www:/var/www/html 293ef2f50d98if i run command without " -v /Users/xxx/Docker/lamp/www:/var/www/html ", mysql could run normally [<-CODE->] i tried mysql -uroot -p i got error:ERROR 2002 (HY000): Can\'t connect to local MySQL server through socket \'/var/run/mysqld/mysqld.sock\' (2)also i checked  /var/lib/mysq permissions:drwxrwxrwx  6 root root  204 Jul 11 03:11 mysqlwhen i use command: service mysql start, /var/lib/mysql folder will generate 3 log files.ib_logfile0    -  5.2mbib_logfile1    -  5.2mbibdata1    -  18.9mband I searched many many websites but can\'t find a solution. anyone know what\'s going on here?
[2016-07-11 05:53:26] <Daniyal8876_twitter> any one cassandra user here?
[2016-07-11 05:53:30] <Daniyal8876_twitter> i need little help
[2016-07-11 05:54:09] <Daniyal8876_twitter> how to import .csv files through dockerfile or docker-compose
[2016-07-11 08:21:54] <marcelmfs> Daniyal8876_twitter: you'll have to edit thedocker-entrypoint.shand the Dockefile to look for your CSV in a volume and load the table into cassandra using CQL'sCOPY table FROM 'table.csv'from the entrypoint script. Or, you can have an external container to load the initial seeding of tables.
[2016-07-11 08:33:14] <dvirf> Hello everybody,How can I specify in mydocker-cloudfile that one servicedepands_onanother service ( [<-LINK->] )?
[2016-07-11 18:37:50] <tim-klug> baozilala: how are you running docker? I had some problems with docker on mac, when I put my MySql DB into the Macs filesystem. The problem was, related to the user and the usergroup. Inside the virtual box the user was not recognized. Maybe this is fixed with the beta now, when you don’t need virtual box anymore.
[2016-07-11 21:15:16] <GuillaumeLeclerc> hello
[2016-07-11 21:15:31] <GuillaumeLeclerc> the docker-hub api seems down. Am I the only one ?
[2016-07-11 21:15:49] <GuillaumeLeclerc> I'm stuck here : docker.api.build._set_auth_headers: Sending auth config (' [<-LINK->] ')
[2016-07-11 21:15:52] <GuillaumeLeclerc> never ends
[2016-07-11 21:15:57] <GuillaumeLeclerc> or is it a DDOS ?
[2016-07-12 01:48:54] <pablohenrique6> Hi guys, my container  docker  for work when I install java
[2016-07-12 08:35:28] <vtajzich> Hi guys, having problem with latest docker for mac beta18, downloading of images takes ages, docker uses all cpus available, has anyome same issue? I tried to search for older beta to download but didn’t succeded …
[2016-07-12 22:22:54] <NickStefan> mac beta docker. npm install is not installing all of the items in package.json
[2016-07-12 22:23:20] <NickStefan> its installing all BUT say a random 5 out of 100. if I ssh in after, and run npm install again, then everything worls
[2016-07-12 22:23:27] <NickStefan> anyone having similar?
[2016-07-14 08:56:05] <fane89> Hi, did anyone use the docker native on beta? Did You have any issues with memory limit for containers?
[2016-07-14 08:56:10] <fane89> on mac
[2016-07-14 09:36:21] <zerocoolback> fane89: I am using and didn’t find any issue. What issue you getting?
[2016-07-14 09:39:39] <fane89> zerocoolback: Im setting in docker-compose file the mem_limit to 4G, but in docker stats i see only 1.954 GiB...
[2016-07-14 10:31:30] <fane89> zerocoolback: any idead?
[2016-07-14 11:37:22] <zerocoolback> fane89: What version of docker-compose you are using? Can you checkdocker inspect <docker container > | grep -i memory
[2016-07-14 11:38:13] <zerocoolback> fane89: docker stats <docker container >
[2016-07-14 11:39:02] <fane89> zerocoolback: docker-compose version 1.8.0-rc1, build 9bf6bc6
[2016-07-14 11:40:04] <fane89> zerocoolback: "Memory": 4294967296,"KernelMemory": 0,"MemoryReservation": 0,"MemorySwap": 8589934592,"MemorySwappiness": -1,
[2016-07-14 11:41:20] <fane89> zerocoolback: a127528f70fb        3.93%               517.2 MiB / 1.954 GiB   25.85%              132.5 kB / 90.34 kB   51.06 MB / 4.096 kB   93
[2016-07-14 11:44:17] <zerocoolback> fane89: vsmac01:~ zerocoolback$ docker-compose.backup --versiondocker-compose version 1.7.0, build 0d7bf73  looks like i am running older version.. I am not sure if this is an issue.. Let me upgarde and check
[2016-07-14 11:44:45] <fane89> zerocoolback: thank You
[2016-07-14 21:08:11] <brianveltman> What difference does it make to run docker on a VPS? A VPS is most likely running on a vmware architecture, running multiple OS already on the same physical server. Shouldnt we use docker on dedicated servers to get the most benefits out of it?
[2016-07-15 11:32:33] <ChazUK> Does anyone know how to recreate this kind of setup with docker-compose style of [<-LINK->]  [<-CODE->] 
[2016-07-15 11:33:12] <ChazUK> basically I want my themes and plugins folder to be outside of the docker instance for development, and then bundled in for dist
[2016-07-15 12:43:10] <tim-klug> maybe you can add these local resources by linking them in as volumens. When you swith to producion you can copy them to the container.
[2016-07-15 13:10:15] <napisani> Hi All, quick question about red hat's new nulecule spec. Does docker-compose implement that spec/plan to implement that spec. or is it something that only red hat is likely to implement (using atom)
[2016-07-15 13:10:39] <napisani> atomic*
[2016-07-15 13:11:03] <ChazUK> columan: can you do that in docker-compose?
[2016-07-15 13:44:35] <ChazUK> For anyone interested [<-CODE->] 
[2016-07-15 13:55:04] <tim-klug> yes :-)
[2016-07-15 14:02:04] <ChazUK> Second question, Can I get npm, gulp, composer installed on the container using docker-compose? Or do I need to role my own dockerfile and put it on the hub? I want it to work with [<-LINK->] but run gulp in the container
[2016-07-15 14:38:53] <svilenkov> Can you access via localhost, for example a rails server on port 3000, when using net: 'host' in a docker compose yaml file for the rails app?
[2016-07-15 14:39:40] <diegoaguilar> Hello, I start a mongo and a redis containers like this:docker rm mongo redis; docker run -d --name mongo -p 27017:27017 mongo; docker run -d --name redis -p 6379:6379 redis... so I can use them both like mongo and redis servers just exist in my host (I enjoy using redis-cli and mongo cli ) right from my host .. so next time I start the containers, data won't be remove it
[2016-07-15 14:47:02] <svilenkov> You probably need a volume if those images themselves don't have any volumes defined in their Dockerfile(s) to be able to have persistent data on container recreate
[2016-07-15 14:47:19] <diegoaguilar> I'm like super new to docker (2 days using it)
[2016-07-15 14:47:43] <diegoaguilar> how can I check those (the docker files) I downloaded them by the generic image name
[2016-07-15 14:47:53] <diegoaguilar> didnt get my own Dockerfile so I don't know how to check
[2016-07-15 14:48:21] <svilenkov> I assume mongo is at [<-LINK->] 
[2016-07-15 14:48:58] <svilenkov> and redis [<-LINK->] 
[2016-07-15 14:49:03] <svilenkov> But not 100% sure
[2016-07-15 14:50:36] <svilenkov> You can see at [<-LINK->] 
[2016-07-15 14:50:45] <svilenkov> VOLUME /data/db /data/configdb
[2016-07-15 15:00:05] <diegoaguilar> keeperhood: I'm not sure how to keep a change on that volume existance
[2016-07-15 15:07:33] <zimbora69> diegoaguilar: Just started few days ago with docker installation on ubuntu (I recommend that OS). I did a tiny manual with the commands I learned, hope it helps you [<-LINK->] 
[2016-07-15 15:07:51] <diegoaguilar> thanks@zimbora69you rock!
[2016-07-15 15:07:54] <diegoaguilar> btw italian?
[2016-07-15 15:08:20] <zimbora69> diegoaguilar: I'm portuguese
[2016-07-15 15:08:26] <zimbora69> :)
[2016-07-15 15:08:30] <diegoaguilar> yah, lol :)
[2016-07-15 16:49:56] <hhimanshu> Hello there, any help with [<-LINK->] 
[2016-07-15 18:37:59] <brianveltman> Someone available to have a quick discussion on the benefits of Docker?
[2016-07-16 07:07:14] <hieu-n> Here i am
[2016-07-16 08:47:44] <brianveltman> hieu-n: what is the benefit of running docker on a vps architecture? The vps still has its own os and runs with a dozen of other vps instances on the same physical server.
[2016-07-16 08:51:03] <hieu-n> The main benefit for me is to pack my app into a docker container, send it to my vps to saving time for configuration
[2016-07-16 08:53:07] <hieu-n> maybe, it's not the best practice, but i use the same container to run on my laptop, then use IDE like PyCharm to connect to the container and edit code.
[2016-07-16 08:55:30] <hieu-n> docker engine (the service that runs docker containers) may add some overhead, but for me it's worth it
[2016-07-16 08:57:40] <tim-klug> One big advantage of containers is, that you have a predictable environment. It is everytime the same, in dev, test, live ...
[2016-07-16 08:57:41] <MakanTaghizadeh> Besides, segregating some services in different network, process and filesystem stacks makes system more secure and easy to maintain.
[2016-07-16 09:11:15] <brianveltman> Ah I see
[2016-07-16 09:11:57] <brianveltman> these benefits are not being mentioned on the videos I’ve watched.
[2016-07-16 09:12:24] <brianveltman> But sounds as a solid idea. I’ll dive deeper into it
[2016-07-16 09:12:32] <brianveltman> thanks for the responses!
[2016-07-16 09:13:44] <MakanTaghizadeh> brianveltman: 
[2016-07-16 10:05:01] <leitzler> do mounting a host dir to a container work in "Docker for Windows" ?
[2016-07-16 10:05:22] <leitzler> keep getting "Invalid volume destination path" when trying different alternatives in git bash
[2016-07-16 10:05:58] <leitzler> and if I try from powershell the container start without complaining regardless of what I use as source folder :/
[2016-07-16 10:06:30] <leitzler> when I look for more info about it, most answers is about boot2docker and not the new version
[2016-07-16 13:49:09] <jim3mar> Is some one using docker with raspberry pi? when building docker 1.12.0-rc4 deb packages using rpi, the rpi was down. I didn't have any choice without force restart rpi only. And then when run any containers, rpi will be down.
[2016-07-16 14:22:26] <tim-klug> ChazUK: you can add exec commands in your dockerfile, when you pull the image. Or you customize your own image and upload this one. I used to get a image that has as much on board as I need and then do some apt-get … -y to add some missing software in my dockerfile.
[2016-07-17 09:55:00] <svilenkov> Looks like port forwarding is not working in Docker for Mac when you use docker-compose in network_mode: 'host' or v1 net: 'host'
[2016-07-17 09:55:44] <svilenkov> screen ~/Library/Containers/com.docker.docker/Data/com.docker.driver.amd64-linux/ttyDoes anybody know how to manually add a port forwarding rule to a container in the vm
[2016-07-17 09:56:05] <svilenkov> I guess this happens because it's not a true 'host' network mode, but there's this vm wrapper :/
[2016-07-17 10:00:38] <svilenkov>  [<-CODE->] 
[2016-07-17 10:06:22] <svilenkov> I run the the file withdocker-compose -f local.yml up
[2016-07-17 10:07:52] <svilenkov>  [<-CODE->] Ports is empty
[2016-07-17 10:09:47] <svilenkov>  [<-CODE->] iptables  inside the vm shows all other services which don't have thenet: 'host'configuration :/
[2016-07-17 10:10:58] <svilenkov> Via bridge0 is running normally, but with host simply the services are not accesible
[2016-07-17 10:12:27] <svilenkov> Inside the core-server container theip addrcontains this entry [<-CODE->] 
[2016-07-17 10:12:45] <svilenkov> andcurl 192.168.65.2:3000works from inside that container
[2016-07-17 10:14:15] <svilenkov> And from within the vm (Moby) the server port is accessible
[2016-07-17 10:14:17] <svilenkov> wget 192.168.65.2:3000 -O -
[2016-07-17 10:15:05] <svilenkov> But not form the outside (localhost mac computer whatever you call your normal environment)
[2016-07-17 10:18:33] <svilenkov> I guess adding an iptables rule might solve this in the vm, but I don't know how
[2016-07-17 10:18:59] <svilenkov> But then that would be the same as bridge0 ?
[2016-07-17 19:29:37] <brianveltman> When creating  a new container, do you always have to start with a OS base layer?
[2016-07-17 21:28:56] <prateekgogia> brianveltman: No you don't have to always, you container image can be just a static binary
[2016-07-17 21:29:04] <prateekgogia> your*
[2016-07-17 23:28:09] <Orlandop43> How can l commit all the changes just in one time?
[2016-07-18 03:11:59] <keatontaylor> Hello all.
[2016-07-18 08:06:45] <vtajzich> having issues with docker for mac beta19, it starts up but freezes when pulling image and utilize all cpus available, any suggestions?
[2016-07-18 08:59:50] <orbatschow> Does anyone know how i can run a docker container and give it an argument, so I can access it from the host by name ?At the moment im accessing the container like this: 172.16.0.10:3000, I want to access it by name: my-node-app:3000
[2016-07-18 09:13:34] <vtajzich> docker run —name my-node-app -p 3000:3000 <image-name>
[2016-07-18 09:20:30] <orbatschow> this doesn't work, i also don't want to publish the port, i just want to access by ip
[2016-07-18 09:20:41] <orbatschow> and then resolve the ip by using a domain
[2016-07-18 09:21:19] <orbatschow>  [<-LINK->] 
[2016-07-18 09:31:55] <tim-klug> you need to add your docker ip and port to your hosts on your mac. this resolves than local the ip. search for edit hosts on mac or windows
[2016-07-18 09:39:29] <orbatschow> do you suggest to manually edit the /etc/hosts file on my mac everytime i (re)start a container ?
[2016-07-18 09:41:48] <tim-klug> you only need to do this once or for every domain you want.
[2016-07-18 09:43:44] <orbatschow> don't containers restart with a different ip everytime ?
[2016-07-18 09:46:30] <tim-klug> no. my start always with 192.168.99.100 or so. i think you can configure the ip.
[2016-07-18 09:47:02] <orbatschow> okay, i got another question, when i dont wan't to publish the port to the localhost, how can i then access the container by ip ?
[2016-07-18 09:56:55] <orbatschow> okay, sounds like this describes the issue: [<-LINK->] 
[2016-07-18 09:57:10] <asperling> gitoverflow: If you do not specify the ip explicitly only luck will set your containers IP to the same value every time you start it. But yes you seem to be able to configure IP, see [<-LINK->] 
[2016-07-18 09:58:24] <tim-klug> you are right. with docker-machine the ip used to be the same. with the beta you need to specify the ip. see the docs how to do this. [<-LINK->] 
[2016-07-18 09:58:54] <orbatschow> asperling: thank you, thats the experience i made with the newest docker for mac version
[2016-07-18 09:59:24] <asperling> As a follow ap, try docker's built in help:```
[2016-07-18 09:59:50] <asperling>  [<-CODE->] 
[2016-07-18 10:00:44] <orbatschow> according to my knowledge it's unfortunately still not possible to route the container ip from the osx host
[2016-07-18 13:17:11] <RunsFor> I am developing a service (basically http server) on my local osx host. Also I'm running boot2docker vm with a gitlab container inside. I need to let gitlab to send webhooks to my local web server through the docker host. It seems it doesn't have straightforward solution. Can anyone help with it?
[2016-07-18 13:22:35] <brianveltman> prateekgogia: thanx!
[2016-07-18 15:24:14] <jdguzman> hey everyone, has anyone had any weirdness using xvfb-run in a docker-compose run command
[2016-07-18 15:25:20] <jdguzman> if I rundocker-compose run web xvfb-run rspecit doesn’t work, it just hangs. But if I dodocker-compose run web /bin/bashand then doxvfb-run rspeconce I’m at the prompt it works just fine
[2016-07-19 03:47:04] <keatontaylor> Alright so lets say I want to modify a docker image from online and add CMD's that will  start a docker run, is there anyway to do that without rebuilding the entire docker image?
[2016-07-19 05:46:19] <sayanh> jdguzman: : is your container running in --privileged mode? I think for xvfb you would need that.
[2016-07-19 05:48:38] <sayanh> keatontaylor: : There is no need to build the image completely. You can add layers from the existing image.FROM image  CMD echo "test"
[2016-07-19 06:48:18] <keatontaylor> sayanh: , thank you!
[2016-07-19 06:58:36] <hholst80> How does that work? Overlays? FS changes are not stored?
[2016-07-19 11:36:55] <otbe> HI anyone knows something about this error?
[2016-07-19 11:37:10] <otbe>  [<-LINK->] 
[2016-07-19 14:23:03] <izhilenkov> Hi guys! Does anybody can tell me how to make dump of postgres db from docker compose? (using heroku and postgres containers)
[2016-07-19 15:14:03] <jdguzman> sayanh: I will give that a try thanks for the tip!
[2016-07-19 20:48:02] <sayanh> izhilenkov: What do you mean by "docker compose"? docker exec -it <container name> <postsql dump command> should work.
[2016-07-19 21:01:03] <izhilenkov> sayanh: thanks for reply, but no, this doesn’t work ( the error is something like “psql doesn’t starter” and I can’t start it inside container
[2016-07-19 21:07:46] <sayanh> ok - how did you start the container?
[2016-07-19 21:08:22] <sayanh> didn\'t you give cmd as "psqld(something like that)"
[2016-07-19 21:08:52] <sayanh> there is no process in the container hence it exits. Right?
[2016-07-19 21:08:58] <izhilenkov> amm, when I trying to start web app e.g. I start it like this - docker-compose run web rails s
[2016-07-19 21:09:26] <sayanh> can you show me the docker-compose.yml?
[2016-07-19 21:09:36] <izhilenkov> np, give me minute
[2016-07-19 21:12:07] <izhilenkov>  [<-CODE->] 
[2016-07-19 21:14:02] <sayanh> So progres exits right after docker-compose -d up. Right?
[2016-07-19 21:14:20] <izhilenkov> yeap, correct
[2016-07-19 21:14:47] <izhilenkov> on;y via docker-compose I can handle DB
[2016-07-19 21:15:15] <izhilenkov> and, when I trying to run pg_dump via docker compose I got a error(
[2016-07-19 21:15:26] <sayanh> herokuPostgresql:image: postgres:9.4
[2016-07-19 21:16:13] <sayanh> add this :command: postgres
[2016-07-19 21:16:26] <sayanh> right after image...
[2016-07-19 21:17:14] <sayanh> and you gotta expose the ports as well
[2016-07-19 21:17:29] <sayanh> else your app wont be able to connect to it
[2016-07-19 21:17:55] <izhilenkov> and, after a I added it, I could usepg_dumpas often?
[2016-07-19 21:18:17] <sayanh> no ...dont add pg_dump
[2016-07-19 21:18:30] <sayanh> let the DB container run first
[2016-07-19 21:18:55] <sayanh> later you could do :  docker exec -it ..... - see above
[2016-07-19 21:19:09] <izhilenkov> ohhhh, yeap, understood
[2016-07-19 21:19:37] <sayanh> for ports you may add:
[2016-07-19 21:20:03] <sayanh> ```ports: \\n"5432:5432"```
[2016-07-19 21:21:15] <sayanh> damn! cant add new line here...
[2016-07-19 21:21:34] <izhilenkov> something else, maybe? Unfornutally, I can’t try right now, but every additional info will be helpful
[2016-07-19 21:21:43] <izhilenkov> forget about it, I understood you
[2016-07-19 21:21:52] <sayanh>  [<-LINK->] 
[2016-07-19 21:22:18] <izhilenkov> ooooh, it’s looks so useful
[2016-07-19 21:23:33] <izhilenkov> thank you again, I will try it tomorrow, but anyway, you got new star in your karma :)@sayanh
[2016-07-19 21:23:49] <sayanh> Thanks!
[2016-07-20 23:20:25] <anguy95> Has anyone set up wordpress and use nginx as a reverse proxy through docker?
[2016-07-20 23:21:06] <anguy95> I seem to have issues when I attempt to use the nginx port, it doesn't give me a wordpress site
[2016-07-21 06:42:04] <MakanTaghizadeh> anguy95: Yep, how are you connecting these two? Is nginx on a separate container? Are you using php-fpm?
[2016-07-21 07:46:55] <anguy95> MakanTaghizadeh: Im attempting to have nginx on a container, then have wordpress in another one
[2016-07-21 07:52:39] <MakanTaghizadeh> anguy95: I see, so in this case you've got to use php-fpm in your wordpress container and have it bind on all network addresses (i.e. 0.0.0.0 or [::]). Then you can add it in nginx as an upstream.
[2016-07-21 07:53:44] <MakanTaghizadeh> However in this case static files should be passed through php_fpm which results in performance deduction.
[2016-07-21 07:54:46] <anguy95> MakanTaghizadeh: Sorry, I don't know if this is the correct chat to be in. However, why is it necessary to have the php:fpm
[2016-07-21 07:55:02] <anguy95> I am very new to docker and nginx php
[2016-07-21 07:55:51] <MakanTaghizadeh> You can have them both in one container for better performance or simply share the static files (or the whole wordpress) between the two containers (nginx and php-fpm)
[2016-07-21 07:59:27] <MakanTaghizadeh> anguy95: Well, 1st because wordpress is written in PHP so it needs PHP parser, 2nd nginx can only be configured with php-fpm through the fastcgi module, 3rd php-fpm can bind on network interface which helps you segregate it from nginx and they can communicate over the network, 4th it has the ability of multi-core utilizing.
[2016-07-21 08:09:29] <anguy95> MakanTaghizadeh: so If I want a docker stack to be SQL, PHP, WP, and Nginx
[2016-07-21 08:09:44] <anguy95> the best route is to have PHP&WP in container 1
[2016-07-21 08:09:50] <anguy95> SQL in conaitner 2
[2016-07-21 08:09:57] <anguy95> and Nginx in container 3?
[2016-07-21 08:10:06] <anguy95> and use php to talk to NGinx?
[2016-07-21 08:12:45] <MakanTaghizadeh> That's right. And for better performance you can share WP between NGINX and PHP containers to server static files directly from NGINX.
[2016-07-21 08:15:11] <anguy95> Alright thank you@MakanTaghizadehill try and figure out how to do all this. This is my first time exposing myself to this technology
[2016-07-21 08:18:03] <MakanTaghizadeh> Good luck@anguy95, also for sharing data between containers this document makes it as easy as eating a piece of cake :-D [<-LINK->] 
[2016-07-21 08:23:02] <anguy95> MakanTaghizadeh: Thanks :] Ill give it my best shot ahaha
[2016-07-21 08:26:07] <MakanTaghizadeh> np mate  
[2016-07-21 15:23:00] <garrardkitchen> does anybody know how when on docker cloud how to use the -it switches when launching your container?
[2016-07-21 17:11:35] <brentarias> I'm new to Docker.  I'm looking at the [<-LINK->] image on dockerhub.  I know .Net Core itself supports several Linux distros,but how can I tell which distro the Docker image supports?  Or am I supposed to believe that a single Docker image will support all Linux distros that .Net Core supports?
[2016-07-21 17:26:05] <brentarias>  [<-CODE->] FROM microsoft/dotnet:0.0.1-alphaI was expecting instead that it would say "from <some Linux distro>".
[2016-07-21 17:30:31] <MakanTaghizadeh> Then checkmicrosoft/dotnet:0.0.1-alphaDockerfile in here [<-LINK->] 
[2016-07-21 17:32:19] <MakanTaghizadeh> It's usingbuildpack-deps:trusty-scm
[2016-07-21 17:32:19] <MakanTaghizadeh> It's usingbuildpack-deps:trusty-scm
[2016-07-21 17:33:56] <MakanTaghizadeh> So it's based onubuntu:trusty
[2016-07-21 17:39:53] <brentarias> MakanTaghizadeh: Thank you!  You've given me the answer, and you have also (at least partly) taught me how to fish. :)
[2016-07-21 17:58:23] <MakanTaghizadeh> np mate  good luck 
[2016-07-21 22:01:31] <bad5anta> hi. has anyone encountered this issue [<-ISSUE->] ?
[2016-07-21 22:01:57] <bad5anta> is there any workaround?
[2016-07-22 07:06:32] <tim-klug> Does someone know where docker volumes are stored when they are attached without a local path in a Mac? Inspect says it is in /var/lib/docker/... but i don't have even a docker folder there. I'm running the beta on a Mac. thx
[2016-07-22 16:29:29] <prastut> Hi guys,  I am working on my GSoC project and it involves a use of docker machine. Now I need to integrate with a server. Can a docker machine be called using  a HTTP request?  Right now, if I run the docker machine it gives an output on the command line. I want that output requestable from the server.
[2016-07-23 18:21:16] <keatontaylor> Quick question, I am creating a docker image from a Dockerfile and the image that I am importing from, in this case Ruby, still sticks around after the docker image is created.
[2016-07-23 18:22:02] <keatontaylor> Is there any way to safely delete the FROM "image" or include it within the docker created image to keep my docker images from being cluttered?
[2016-07-23 18:22:34] <keatontaylor> If I download a docker from the hub it doesn't add more images than just the one I pull so I am  looking to get a similar effect.
[2016-07-23 18:25:05] <edmondo1984> Hello, how does one initialize a database as a part of a image inheriting from the database itself? I.e. I would like to create an image that inherits from database1 (mongodb) and creates indexes on mongoDB. Running RUN mongo < myfile.js in the children image fails miserably
[2016-07-23 18:50:44] <MakanTaghizadeh> keatontaylor: first of all, the most useful feature of docker platform is that it has layered structure so this helps preventing dups, faster downloads, less disk space and so forth.
[2016-07-23 18:52:21] <keatontaylor> Indeed, but once I've created and image and pushed it, I can pull it again and the FROM ruby image will not show in the docker images command anymore.
[2016-07-23 18:52:37] <MakanTaghizadeh> but anyway, removing the Ruby image doesn't really hurt the system. In fact images are defined using SHA256 checksums, so Ruby is just a tag.
[2016-07-23 18:52:42] <keatontaylor> The disk space is still being used, just cleaner when managing the docker images/containers
[2016-07-23 18:55:05] <MakanTaghizadeh> Sorry it seems I didn't quiet catch the issue, would please elaborate it.
[2016-07-23 18:57:14] <keatontaylor> Mostly just complaining that when building a docker image using a docker file the base image pulled from the FROM command in the dockerfile remains viewable in the docker images command until you push the created image delete all the containers and associated images from the build and pull the created image again.
[2016-07-23 18:59:28] <MakanTaghizadeh> Oh, I see. That's right. I'm afraid there is no possible solution for that yet. But I guess you can use Automation Tools like puppet, ansible and so forth to automate your desired procedure. Imho tho.
[2016-07-23 19:07:52] <MakanTaghizadeh> edmondo1984: Oops... I deleted the message by mistake, gonna right it again.
[2016-07-23 19:08:45] <MakanTaghizadeh> edmondo1984: That's because,mongod(MongoDB Daemon) is not running at the point of building the image. I mean in theDockerfile.
[2016-07-23 19:11:08] <MakanTaghizadeh> keatontaylor: You're totally right, building images pulls some other images. Over the time, really makes it painful to manage images through the CLI.
[2016-07-23 19:13:26] <MakanTaghizadeh> keatontaylor: Have you tried out [<-LINK->] . It really makes it easy to manage docker hosts, images, containers and deployment of the containers.
[2016-07-23 19:14:55] <MakanTaghizadeh> (OMG, I'm literally unable to right messages using Gitter iPad App)
[2016-07-23 23:02:21] <edmondo1984> MakanTaghizadeh: I understand that , is there a simple way? I am not a chef/puppet/ansible/salt expert
[2016-07-23 23:49:23] <Shimster10_twitter> hi everyone! I need some help
[2016-07-23 23:49:37] <Shimster10_twitter> I just found out of the restart flag
[2016-07-23 23:49:48] <Shimster10_twitter> I was wondering if there is a way i could test it
[2016-07-24 03:22:17] <MakanTaghizadeh> edmondo1984: No no, I guess there is a misunderstanding here, I wrote that answer for@keatontaylor.
[2016-07-24 03:23:57] <MakanTaghizadeh> edmondo1984: your problem is that, at the moment you're trying to insert some data in mongo, the daemon (mongod) is not running, so obviously would fail.
[2016-07-24 06:53:14] <edmondo1984> MakanTaghizadeh: this is a classical problem I suppose when testing with docker and compose. Is there an idiomatic approach to solve it? I saw images of mysql or mongo that starts the daemon, initialize, stop it, and then let the parent start it again
[2016-07-24 07:01:06] <MakanTaghizadeh> edmondo1984: That's completely right. They're doing so. However, I assume you're not starting themongod, thus results in failure. May I take a look at your Dockerfile?
[2016-07-24 07:10:29] <Shimster10_twitter> hi guys i wondering what is a good way to test the restart flag for the docker container
[2016-07-24 07:10:40] <Shimster10_twitter> and does this apply for the entire life of the container?
[2016-07-24 07:19:58] <MakanTaghizadeh> edmondo1984: You can create an init script like the following: [<-CODE->] 
[2016-07-24 07:21:50] <MakanTaghizadeh> Then in your Dockerfile copy the script somewhere, execute it and delete it. [<-CODE->] 
[2016-07-24 08:39:52] <Shimster10_twitter> hi guys i was wondering if the restart policy applies to the lifetime of the container
[2016-07-24 09:02:36] <MakanTaghizadeh> Shimster10_twitter: Yep, It does.
[2016-07-24 09:31:11] <prastut> Everybody
[2016-07-24 09:31:54] <prastut> Please help:
[2016-07-24 09:31:59] <prastut> Hi guys, I am working on my GSoC project and it involves a use of docker machine. Now I need to integrate with a server. Can a docker machine be called using a HTTP request? Right now, if I run the docker machine it gives an output on the command line. I want that output requestable from the server.
[2016-07-24 10:06:50] <Shimster10_twitter> MakanTaghizadeh: thank you so much. I wanted to test it out but I can\'t even do "poweroff" in it any idea how i can test the restart policy?
[2016-07-24 10:07:11] <Shimster10_twitter> I keep on looking at the restartcounter but it doesn't seem to increment
[2016-07-24 10:14:48] <MakanTaghizadeh> Shimster10_twitter: poweroffdoes not make sense in a docker container. You can simply kill the root process. Then you see the container with stop and restart again. Root process in a container usually has PID of 1.
[2016-07-24 10:17:03] <MakanTaghizadeh> prastut: If I could catch your issue, You'd like to connect todocker-machineremotely using an HTTP Interface. Am I right?
[2016-07-24 10:29:49] <prastut> Yes@MakanTaghizadeh
[2016-07-24 10:33:54] <MakanTaghizadeh> prastut: I'm afraiddocker-machineis just a CLI tool and doesn't have any API engine. Thus, the thing which you want is not possible directly. But you might achieve it, with the help of some other tools which would have difficulties.
[2016-07-24 10:58:00] <prastut> Okay cool.
[2016-07-24 10:58:29] <prastut> MakanTaghizadeh: How do then people connect to a MongoDB machine? On a port they export from the machine?
[2016-07-24 11:16:38] <MakanTaghizadeh>  [<-CODE->]  [<-CODE->] 
[2016-07-24 11:17:42] <prastut> MakanTaghizadeh: Thank you for the help. Much appreciated. :)
[2016-07-24 11:18:44] <MakanTaghizadeh> My pleasure@prastutGood luck 
[2016-07-24 12:26:13] <staffanselander> Hey guys!
[2016-07-24 12:26:29] <staffanselander> I would like some inputs if you have the time
[2016-07-24 12:27:02] <MakanTaghizadeh> Yeah, sure.
[2016-07-24 12:28:03] <staffanselander> If i have for instance a 3 projects. One API, One CMS, One front-end framework.Everyone would use nginx. Would i have 1 container each or would i place them all inside one container?
[2016-07-24 12:28:27] <staffanselander> I feel it’s more modular to have 3 containers, but wouldnt it be 3 instances of Nginx running?
[2016-07-24 12:29:51] <aios> LadyVipEx: you can use nginx-proxy for generate template for 3 containers or much more.
[2016-07-24 12:30:41] <aios> LadyVipEx: or make volume to manage nginx config manually
[2016-07-24 12:31:36] <staffanselander> So only 1 container for nginx, but would i have the projects inside there own containers aswell?
[2016-07-24 12:32:16] <MakanTaghizadeh> I guess it is the best to have a container for each project and 1 for nginx.
[2016-07-24 12:32:32] <MakanTaghizadeh> What are your projects written with?
[2016-07-24 12:33:12] <MakanTaghizadeh> You can find tiny lightweight, native http servers for that platform, and have the nginx proxy the connections.
[2016-07-24 12:33:19] <staffanselander> CMS would be PHP, API would be PHP and front-end a Angular application
[2016-07-24 12:33:29] <MakanTaghizadeh> Right
[2016-07-24 12:33:48] <MakanTaghizadeh> Without a doubt, front-end should be moved to a CDN.
[2016-07-24 12:34:06] <MakanTaghizadeh> I mean for the best performance
[2016-07-24 12:34:18] <aios> MakanTaghizadeh: if that not spa?
[2016-07-24 12:34:59] <MakanTaghizadeh> No difference, generally in front-end project you're dealling with static files.
[2016-07-24 12:35:21] <aios> MakanTaghizadeh: what about ssr?
[2016-07-24 12:35:50] <aios> MakanTaghizadeh: cdn as solution should use in other tasks
[2016-07-24 12:35:56] <MakanTaghizadeh> Oh, I see, my bad
[2016-07-24 12:36:01] <MakanTaghizadeh> Yep, you're right
[2016-07-24 12:36:07] <MakanTaghizadeh> this just applies for SPAs
[2016-07-24 12:36:20] <MakanTaghizadeh> Sorry for that
[2016-07-24 12:36:28] <aios> MakanTaghizadeh: np
[2016-07-24 12:36:44] <MakanTaghizadeh> But anyway, I guess on all of them it would be better to have
[2016-07-24 12:36:47] <MakanTaghizadeh> php-fpm
[2016-07-24 12:36:50] <aios> LadyVipEx: use container each project
[2016-07-24 12:36:56] <MakanTaghizadeh> yep right
[2016-07-24 12:36:59] <aios> MakanTaghizadeh: yep that right
[2016-07-24 12:37:16] <MakanTaghizadeh> Using php-fpm u can bind on a network interface
[2016-07-24 12:37:17] <aios> LadyVipEx: so imagine will see something
[2016-07-24 12:37:19] <staffanselander> So i would have 3 containers with only “code” ? :)
[2016-07-24 12:37:38] <MakanTaghizadeh> No, no, you say@aios
[2016-07-24 12:37:58] <aios> LadyVipEx: yep - you can make volumes, named volumes - or copy files into container with build Dockerfile
[2016-07-24 12:38:13] <aios> that case make your production solution
[2016-07-24 12:38:30] <aios> for devel tree - you can use volumes in docker-compose
[2016-07-24 12:38:37] <aios> so look at here
[2016-07-24 12:39:10] <aios> you have container with api - with cms - with php-fpm - with nginx  - and with front-end angular
[2016-07-24 12:39:42] <aios> LadyVipEx: or you can make one container with difference folders for you projects and name it to "CodeContainer"
[2016-07-24 12:40:03] <aios> LadyVipEx: something like that....
[2016-07-24 12:40:14] <staffanselander> That makes alot of sense!
[2016-07-24 12:40:32] <MakanTaghizadeh> That's absolutely right.
[2016-07-24 12:40:34] <aios> LadyVipEx: dont forget for depends_on when build a docker-compose.yml
[2016-07-24 12:41:09] <MakanTaghizadeh> But I, personally, prefer to copy the code into the container.
[2016-07-24 12:41:44] <MakanTaghizadeh> It makes more sensible and more closer to Docker philosophy.
[2016-07-24 12:41:45] <aios> MakanTaghizadeh: that is good when you want to deploy complete application
[2016-07-24 12:42:00] <staffanselander> MakanTaghizadeh: Yhea, i usually copy it in when building the application, but in development i have a docker-compose.override.yml using volumes
[2016-07-24 12:42:11] <aios> MakanTaghizadeh: so when you want some debug or make changes to app - more sense use volumes
[2016-07-24 12:42:36] <MakanTaghizadeh> Yeah, true. For dev purposes it would be really painfull and time consuming.
[2016-07-24 12:42:41] <MakanTaghizadeh> True, you're right.
[2016-07-24 12:43:27] <aios> MakanTaghizadeh: @LadyVipExyour welcome. and sorry for bad english
[2016-07-24 12:44:01] <staffanselander> Would you build the containers inside docker-composer.yml using build command or outside using docker build -t … ?Haha didnt notice any bad english 
[2016-07-24 12:44:05] <MakanTaghizadeh> np mate, I ain't good at that, too. :D
[2016-07-24 12:44:41] <aios> LadyVipEx: so build containers in docker-compose are really slowly when you want to start app
[2016-07-24 12:44:56] <aios> LadyVipEx: and that is time-to-live containers
[2016-07-24 12:45:04] <staffanselander> Ooh
[2016-07-24 12:45:30] <aios> LadyVipEx: you cant manage them with docker-compose rm or docker-compose stop
[2016-07-24 12:45:51] <aios> LadyVipEx: it make sense for make some infrastructure time-based
[2016-07-24 12:45:55] <staffanselander> So i would have to build the images themself
[2016-07-24 12:46:07] <aios> LadyVipEx: docker build -t
[2016-07-24 12:46:15] <aios> and show must go on)
[2016-07-24 12:46:20] <staffanselander> Haha :)
[2016-07-24 12:46:22] <MakanTaghizadeh> :D
[2016-07-24 12:46:30] <MakanTaghizadeh> yep
[2016-07-24 12:47:05] <MakanTaghizadeh> I'm usingdocker build, but I've written a script on top of that, to make it simple.
[2016-07-24 12:47:17] <aios> MakanTaghizadeh: look at CI
[2016-07-24 12:47:23] <aios> MakanTaghizadeh: like jenkins
[2016-07-24 12:47:50] <MakanTaghizadeh> No, no I see. I'm using jenkins already.
[2016-07-24 12:47:51] <aios> thats you make one time pipeline for deploy and hook will catch every image builds
[2016-07-24 12:47:54] <staffanselander> But then i have to build them on the server with Jenkins right?
[2016-07-24 12:48:07] <MakanTaghizadeh> But for building in terminal
[2016-07-24 12:48:09] <aios> LadyVipEx: awesome
[2016-07-24 12:48:23] <staffanselander> Is that the correct way?
[2016-07-24 12:48:28] <MakanTaghizadeh> when I started early using docker I used that script.
[2016-07-24 12:48:30] <MakanTaghizadeh> :D
[2016-07-24 12:48:51] <MakanTaghizadeh> LadyVipEx: Right
[2016-07-24 12:49:10] <aios> LadyVipEx: just try it - and you will have more free time for watchpornanime))
[2016-07-24 12:49:37] <staffanselander> Haha, that’s a big plus
[2016-07-24 12:49:56] <MakanTaghizadeh> LadyVipEx: IMO, you can have specific Dockerfile for each project in its repo, so that Jenkins would clone, build, test and Docker Build....
[2016-07-24 12:50:08] <MakanTaghizadeh> Haha :D@aios
[2016-07-24 12:50:55] <aios> LadyVipEx: all changes you make One-time - and all changes apply to production or some other branch automatically)
[2016-07-24 12:51:03] <aios> every build
[2016-07-24 12:51:07] <aios> or builds
[2016-07-24 12:51:09] <aios> or push
[2016-07-24 12:52:36] <MakanTaghizadeh> True 
[2016-07-24 12:54:00] <staffanselander> Can i do it with jenkins, while still having Jenkins running as a docker Container?
[2016-07-24 12:55:05] <MakanTaghizadeh> Sure you can
[2016-07-24 12:55:13] <MakanTaghizadeh> I'm doing this, too.
[2016-07-24 12:57:57] <staffanselander> Wouldnt i have to build the images inside the Jenkins container then?
[2016-07-24 12:58:08] <MakanTaghizadeh> You can pulljenkinsci/jenkinsand mount host's/var/run/docker.sockin the right place as a volume
[2016-07-24 12:58:51] <staffanselander> Aaaah, cool!
[2016-07-24 12:59:09] <MakanTaghizadeh> then jenkins has a plugin which can communicate with docker through rest API
[2016-07-24 12:59:44] <MakanTaghizadeh> Here it is: [<-LINK->] 
[2016-07-24 12:59:55] <MakanTaghizadeh> Or
[2016-07-24 13:00:58] <MakanTaghizadeh> Alternatively you can have host'sdocker-engineto listen on network interface, so that jenkins will be able to communicate with it through the TCP Socket, instead of Unix Socket.
[2016-07-24 13:06:39] <aios> MakanTaghizadeh: that is interesting - i use jenkins without docker
[2016-07-24 13:07:15] <aios> MakanTaghizadeh: for that usually i can start jenkinsci container in docker?
[2016-07-24 13:08:45] <MakanTaghizadeh> aios: Yeah, you can. There an official docker image for jenkins. Here: [<-LINK->] 
[2016-07-24 13:09:22] <MakanTaghizadeh> But You've got to do some trick so that jenkins would be able to build docker images.
[2016-07-24 13:09:22] <aios> looking fun) ty)
[2016-07-24 13:09:49] <aios> MakanTaghizadeh: that trick inside volume with docker sock?
[2016-07-24 13:10:28] <MakanTaghizadeh> There is 2 possible solutions, imo
[2016-07-24 13:10:57] <MakanTaghizadeh> 1) docker sock as a volume + docker binary + shell steps in jenkins pipeline
[2016-07-24 13:11:50] <MakanTaghizadeh> 2) change host'sdocker-engineconfiguration to listen on network interface + using docker plugin for jenkins
[2016-07-24 13:12:29] <MakanTaghizadeh> first one, I guess is really dirty
[2016-07-24 13:12:38] <MakanTaghizadeh> I prefer second one myself
[2016-07-24 13:12:47] <MakanTaghizadeh> but be sure about the security
[2016-07-24 13:13:43] <aios> MakanTaghizadeh: so change hosts that you are about hyper-v machine?
[2016-07-24 13:14:49] <MakanTaghizadeh> (Sorry I deleted the message, it was totally wrong :D)
[2016-07-24 13:15:25] <aios> MakanTaghizadeh: np
[2016-07-24 13:15:46] <staffanselander> It sounds nice, im gonna try it out
[2016-07-24 13:16:17] <aios> MakanTaghizadeh: can you are take info in docs or newspaper in some blog for read about change docker-engine hosts.
[2016-07-24 13:16:28] <MakanTaghizadeh> @MakanTaghizadeh so change hosts that you are about hyper-v machine?Sorry I could quiet understand you...
[2016-07-24 13:16:45] <aios> MakanTaghizadeh: i use docker on windows
[2016-07-24 13:16:58] <MakanTaghizadeh> aios: Oh I see
[2016-07-24 13:17:00] <aios> MakanTaghizadeh: that for main it use hyper-v
[2016-07-24 13:17:57] <MakanTaghizadeh> aios: Right, right. In Windows and Mac docker env is set up using boot2docker in a virtual machine.
[2016-07-24 13:18:20] <MakanTaghizadeh> aios: Haven't you tried the new native betadocker-enginefor windows?
[2016-07-24 13:19:03] <aios> MakanTaghizadeh: yep
[2016-07-24 13:19:26] <MakanTaghizadeh> Anyway, I've got to take a look. But at the moment, unfortunately I don't know any blog or document talking about that.
[2016-07-24 13:20:35] <staffanselander> Are you guys hosting youre images up on Docker Hub?
[2016-07-24 13:20:42] <aios> LadyVipEx: no
[2016-07-24 13:20:44] <MakanTaghizadeh> I just can refer you to the official document ofdocker daemon
[2016-07-24 13:20:55] <aios> MakanTaghizadeh: so if you can)
[2016-07-24 13:21:02] <aios> LadyVipEx: look at private registry
[2016-07-24 13:21:09] <MakanTaghizadeh> Yep, right away.
[2016-07-24 13:21:17] <aios> LadyVipEx:  [<-LINK->] 
[2016-07-24 13:21:57] <staffanselander> Haha thanks!
[2016-07-24 13:22:20] <MakanTaghizadeh> aios: here it is: [<-LINK->] 
[2016-07-24 13:22:48] <MakanTaghizadeh> you can use--hostto provide a listening ip:port for daemon
[2016-07-24 13:23:29] <aios> MakanTaghizadeh: yep i have it on docker beta)
[2016-07-24 13:24:00] <aios>  [<-LINK->] 
[2016-07-24 13:24:24] <MakanTaghizadeh> aios: Great, I couldn't manage to work with docker beta yet.
[2016-07-24 13:24:42] <aios> MakanTaghizadeh: that is fine - simple and smart)
[2016-07-24 13:25:30] <aios> MakanTaghizadeh: can you take your config for that
[2016-07-24 13:25:37] <aios> i will look for example
[2016-07-24 13:26:56] <MakanTaghizadeh> Well, in fact docker for linux doesn't have any configuration file, there is a default file in/etc/default/dockerwhich gives you the ability to change parameters and its like the following:
[2016-07-24 13:27:24] <MakanTaghizadeh>  [<-CODE->] 
[2016-07-24 13:28:00] <aios> MakanTaghizadeh: ok i understand you) thanks)))
[2016-07-24 13:28:24] <MakanTaghizadeh> I have no idea about the configurations in Windows. Unfortunately.
[2016-07-24 13:28:31] <staffanselander> This is super nice btw
[2016-07-24 13:29:04] <aios> MakanTaghizadeh: no i understand where i can find it)
[2016-07-24 13:29:21] <aios> MakanTaghizadeh: have a nice day - and very thank you)
[2016-07-24 13:30:20] <MakanTaghizadeh> aios: @LadyVipExAnd you too, Mates. Thank you all for great knowledge sharing. Have fun 
[2016-07-24 13:30:53] <staffanselander> aios: @MakanTaghizadehThank you both! Excatly the answers i need! :D
[2016-07-24 13:30:59] <aios> MakanTaghizadeh: you too) if have a questions - welcome to conversation
[2016-07-24 13:31:22] <MakanTaghizadeh> LadyVipEx: 
[2016-07-24 13:32:12] <MakanTaghizadeh> aios: Sure, definetly. Thanks Staffan
[2016-07-24 17:28:55] <edmondo1984> Hello, is it known that the bridge network doesn't really work on MacOsx Beta? [<-CODE->] 
[2016-07-24 18:34:33] <MakanTaghizadeh> You're not linkingmysql-camundawith the second container. So pingingmysql-camundawould not definitely work.
[2016-07-24 18:37:15] <MakanTaghizadeh> I don't see any problem with that! Are you sure there're any?
[2016-07-24 18:42:32] <edmondo1984> Aren't container already connected on the bridge network and therefore pingable by name@MakanTaghizadeh?
[2016-07-24 18:47:51] <MakanTaghizadeh> They're connected to the same bridge, but the local DNS server which is built in docker is not running for the default bridge. You've got to create your own network bridge. In this case docker engine will run a tiny local DNS Server in the isolated network you've created, so that containers would find each other by name.
[2016-07-24 18:48:33] <MakanTaghizadeh> For more info on creating networks in docker  refer to this document
[2016-07-24 18:49:27] <MakanTaghizadeh>  [<-LINK->] 
[2016-07-24 18:49:43] <edmondo1984> I imagine there is a good reason for the default dns not running for the default bridge@MakanTaghizadeh
[2016-07-24 18:52:20] <MakanTaghizadeh> You're right, I don't have any idea about that.
[2016-07-24 18:53:18] <MakanTaghizadeh> If you found the reason, I would really appreciate it if you let me know.
[2016-07-24 20:21:38] <Otienoh> docker: /docker  has anyone ever though of creating a docker container with a cron job to run git pull origin after every 15 minutes in order to update the codebase inside the container...  Can me crazy but will appreaciate your feedback
[2016-07-24 20:30:41] <Otienoh> @/allsee above
[2016-07-24 20:56:43] <jpapejr> Why use a container for that? Seems to not grasp the point of point-in-time images.
[2016-07-24 21:22:59] <thaJeztah> edmondo1984: @MakanTaghizadehits for backward compatibility; the default network never had "discovery", only for linked containers, so to preserve that behavior its deliberately disabled. To use the embedded DNS, connect the containers to a custom network (a network created with "docker network create")
[2016-07-24 22:00:31] <aios> thaJeztah: someone has problem with union networks?
[2016-07-24 23:57:07] <thaJeztah> aios: not a "problem", but it would break many exisiting setups, therefore the "default" network keeps the old behavior, and you can opt in for the DNS based resolution by creating a network
[2016-07-25 05:45:53] <MakanTaghizadeh> thaJeztah: I see. I guessed it but I wasn't sure about that. Thanks mate 
[2016-07-25 10:19:15] <aios> Hi all
[2016-07-25 10:19:18] <aios> MakanTaghizadeh: hi
[2016-07-25 10:21:11] <MakanTaghizadeh> Hi@aiosWhat's up? Everything's fine? 
[2016-07-25 10:21:24] <aios> MakanTaghizadeh: Yep!
[2016-07-25 10:21:44] <aios> i try install jenkins in docker - everithing fine)
[2016-07-25 10:21:53] <MakanTaghizadeh> Great 
[2016-07-25 10:33:49] <MakanTaghizadeh> aios: Have you ever tried any of the Clustering Solutions for Docker?  Like Kupernetes, Docker Swarm or something?
[2016-07-25 10:34:21] <MakanTaghizadeh> (oops I mentioned wrong person :-p)
[2016-07-25 10:47:57] <aios> MakanTaghizadeh: no
[2016-07-25 10:48:06] <aios> MakanTaghizadeh: but may be in future.
[2016-07-25 10:54:38] <MakanTaghizadeh> I see. I've got stuck with Kupernetes and have to finish it by the friday night 
[2016-07-25 10:55:03] <MakanTaghizadeh> I think it\'s my "last friday night" :-p
[2016-07-25 11:34:46] <aios> MakanTaghizadeh: so what sense and phylosophy of kubernetes?
[2016-07-25 11:34:50] <aios> MakanTaghizadeh: can you tell?
[2016-07-25 13:06:41] <tsvetann> anybody knows how to maintain multiple projects with Docker for OSX
[2016-07-25 13:07:02] <tsvetann> it seems like the idea behind it was to run a single project unlike docker-machine
[2016-07-25 13:10:24] <Furdarius> Hello all. Was somebody use [<-LINK->] ?
[2016-07-25 13:11:39] <Furdarius> If anyone using it, could you describe  what is the best architecture for organize some machine with nomad?
[2016-07-25 13:12:10] <Furdarius> I can't understand, can nomad-server handle jobs? Or only agent can?
[2016-07-25 13:12:32] <Furdarius> If nomad-server can't handle jobs, then must i have nomad-server and nomad-agent on same machine? Or nomad-agent and nomad-server must be on different machine?
[2016-07-25 19:21:00] <MakanTaghizadeh> So sorry@aiosI was so busy today. Well, nothing describes it  better then it's official description.
[2016-07-25 19:22:10] <MakanTaghizadeh> Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.
[2016-07-25 19:23:27] <MakanTaghizadeh> It's a centric designed ecosystem that gives you the power of scaling  your services horizontally and vertically so easily.
[2016-07-25 19:36:25] <MakanTaghizadeh> We're redesigning our services and infrastructure to be more robust, scalable and reliable, so  i'm reading more about these kinds of solutions to find which one would be the most suitable for us.  Solutions like Kubernetes, Mesos Marathon, OpenStack Heat and so forth.
[2016-07-26 09:53:20] <mgangelov> Hello, this might be a very basic (and potentially stupid) question, but is there a way to define resources constraints (CPU cores, memory, etc) in theDockerfileof an image? It doesn't seem that logical to be possible, since an image should be host-independent, but still I want to know if there's a way. Thanks!
[2016-07-26 12:34:24] <scheiblr> Hey guys, how to use docker behind a corporate proxy (linux). I'm currently struggling...
[2016-07-26 12:34:47] <scheiblr> oh, nevermind, found out, that docker has also gitter. I'm asking there..
[2016-07-26 12:37:47] <MakanTaghizadeh> mangelov95: Resource capping and limiting only applies for containers not images. Thus, not possible to have those constraints inDockerfile. However, you can have them indocker-compose.yaml.
[2016-07-26 12:38:38] <MakanTaghizadeh> schmittr: Here's the gitter room forDockermate. :-)
[2016-07-26 12:41:00] <MakanTaghizadeh> schmittr: proxychainsmight be helpful. I've never tested it myself, tho.
[2016-07-26 13:03:37] <mgangelov> Thanks!@MakanTaghizadeh
[2016-07-26 13:04:47] <MakanTaghizadeh> np@mangelov95
[2016-07-26 13:44:41] <scheiblr> ups@MakanTaghizadeh
[2016-07-26 13:46:01] <scheiblr> MakanTaghizadeh: proxychains??
[2016-07-26 13:46:40] <scheiblr> Do u mean this: [<-LINK->] ?
[2016-07-26 14:14:05] <scheiblr> MakanTaghizadeh: solved it. but like in the docs. a reboot finally did it :D
[2016-07-26 16:15:04] <MakanTaghizadeh> schmittr: Great!! 
[2016-07-26 17:13:14] <dissipate> MakanTaghizadeh: it makes sense for resource constraints to be applied to a container, not an image, however, I wish there was a way to set global resource constraints in a docker-compose file, just like how you can define a default network.
[2016-07-26 18:02:06] <MakanTaghizadeh> dissipate: I see. You're right. It's not possible to have global constraints in compose file yet. It would be nice, tho.
[2016-07-26 18:03:01] <dissipate> MakanTaghizadeh: yes, it would be nice because right now i have to tell developers to put the constraints in for every single one of their containers in their docker-compose file for production. it's a PITA.
[2016-07-26 20:09:45] <groundnuty> hey, we have a need to have the same docker image under two different organizations on docker hub
[2016-07-26 20:10:06] <groundnuty> is there an easy way to configure something so the immage is autoamticly mirrored on the second organizaton?
[2016-07-26 21:13:08] <DerekTBrown> groundnuty: that could easily be done on the repository level.  Use a travis build pipeline to clone it to your second repo
[2016-07-26 21:22:42] <DerekTBrown> Does anyone know if you can do docker discovery with basic auth for etcd?
[2016-07-26 22:31:44] <groundnuty> DerekTBrown: so just, do docker pull , tag, push in travis?
[2016-07-27 09:23:58] <Cmdv> Hello has anyone successfully gotten Docker working with react-hot-loader, just started on a new project and they are currently using docker with react but the reload speed is beyond slow about a minute!! :)
[2016-07-27 09:25:09] <Cmdv> or if anyone could point me to a repo?
[2016-07-27 17:20:03] <mgangelov>  [<-CODE->] The image is jupyterhub, so it's based on Debian.
[2016-07-27 17:30:29] <aios> Look for upstart
[2016-07-27 17:41:47] <mgangelov> With what isupstartbetter thanupdate-rc.d
[2016-07-27 19:56:43] <MakanTaghizadeh> @mangelov95 It's not recomended to have more than one process in a container. As you can see in 10 things to avoid in docker containers, auther says in item 7:7) Don’t run more than one process in a single container – Containers are perfect to run a single process (http daemon, application server, database), but if you have more than a single process, you may have more trouble managing, retrieving logs, and updating the processes individually.
[2016-07-27 20:00:39] <MakanTaghizadeh> There used to be an officialubuntu-upstartimage, but it's now deprecated, latest version of this image isubuntu-upstart:trusty.
[2016-07-27 20:04:28] <MakanTaghizadeh> However, if you insist on doing such a thing for development porpuses, I'd recommend you to go forsystemd,supervisord,pm2and so forth.
[2016-07-27 20:14:58] <MakanTaghizadeh> My bad, latest version ofubuntu-upstartisutopicor14.10nottrusty.
[2016-07-27 20:22:08] <NiggyWizzyWoz_twitter> hey guys
[2016-07-27 20:24:24] <NiggyWizzyWoz_twitter> I was just wondering that is the best way to do development with docker when it comes to managing db volumes. I have a golang/mongodb application that I'm developing on the localhost. I have a docker-compose.yml file to link up the external db volumes into the mongodb image. The problem is I can't think of any good way to transfer these db volumes from the localhost to the dev server and vice versa. How do you usually solve this sort of a problem?
[2016-07-27 20:42:23] <dissipate> NiggyWizzyWoz_twitter: i'm not sure what the 'state-of-the-art' is for managing volumes, but you can use these commands: [<-LINK->] with a good object store such as Amazon S3 buckets
[2016-07-27 21:19:40] <dragon788> mangelov95: you should check out 'tini' it is a great Docker init replacement
[2016-07-27 21:33:07] <NiggyWizzyWoz_twitter> dissipate: thank you, I will try to automate it in such a way that the volumes will be kept in something like amazon (scale way's solution) and ov
[2016-07-28 08:54:24] <mgangelov> MakanTaghizadeh: Thanks a lot! Using Supervisor helped. For anybody interested, this is a great usage guide: [<-LINK->] 
[2016-07-28 10:20:38] <zenvisuals> Hi guys, I have a situation, I have created bash scripts inside my Dockerfile [<-CODE->] put VOLUME at the end and set up volumes in docker-compose ( this step is needed ) [<-CODE->] However when i docker-compose up, the file is gone, does anyone know why?
[2016-07-28 10:29:48] <Shimster10_twitter> hi guys! i have been doing some tests with the --restart policy where it will restart on-failure. I just wanted to make sure. So anyways I ran my container which is great and I killed the process that I found in \'ps aux\' and i find that the docker container does get restarted but whenever i dodocker inspect -f "{{ .RestartCount }}" <containername> i still get \'0\' why isn\'t it incrementing?
[2016-07-28 15:20:35] <MakanTaghizadeh> mangelov95: np mate  Great it worked 
[2016-07-28 16:00:41] <harshadyeola> zenvisuals: can you add one more step after creating gone.sh to check if its created?
[2016-07-28 20:16:29] <nicosuave> Hi all. Regarding Docker Compose: I added an environment file todocker-compose/.envbut am not seeing any environment variables that I've set, as perdocker-compose run --rm web env
[2016-07-29 01:07:40] <jpapejr> Snippet of the compose yml?
[2016-07-29 01:07:59] <nicosuave> Sorted it out. Thank you anyways@jpapejr
[2016-07-29 01:08:20] <nicosuave> ended up simply moving those things over todocker-compose.ymlfor now
[2016-07-29 12:12:16] <oleksdovz> Hi, I want to run docker ct with memory size = 512M, but inside ct   commands  free  and top  show memory  size  what is equal to docker host ~ 12 GB RAM
[2016-07-29 12:12:34] <oleksdovz> can you me  help with this ?
[2016-07-29 12:14:15] <Orlandop43> You have to add the limit on docker file
[2016-07-29 12:14:46] <Orlandop43> Anyone know how auto commit changes on container?
[2016-07-29 12:15:43] <Orlandop43> I would like not lose my changes anytime my container shutdown
[2016-07-29 12:15:53] <Orlandop43> Is it possible?
[2016-07-29 12:16:39] <oleksdovz>  [<-CODE->] 
[2016-07-29 12:18:54] <oleksdovz> Orlandop43: create from CT docker imagelike [<-CODE->] 
[2016-07-29 12:20:39] <Orlandop43> Thanks a lot I will try soon I get hands on my computer
[2016-07-29 12:29:04] <oleksdovz> Please, help me with this or give way  how to resolve
[2016-07-29 12:31:06] <Orlandop43> Mate you have 1.5 on limit you need to have 512 and thee memory results info get u is the first layer not the container you want
[2016-07-29 12:31:18] <Orlandop43> I duno ho check memory just per image sorry
[2016-07-29 15:02:48] <GoNode5> Hello, with Docker now available for Windows, If using an official Docker (like Redis), its the same for linux/mac/windows?
[2016-07-29 15:09:08] <mgangelov> GoNode5: Yes, this is the point of having images and containerisation, every image you deploy into a container will behave the same, indifferent to the host OS.
[2016-07-29 17:35:32] <dissipate> let me get this straight, someone correct me if I'm wrong. Docker version 1.12 has gone GA, but DABs and Stacks are still experimental? [<-LINK->] 
[2016-07-29 20:09:52] <prastut> @MakanTaghizadeh [<-CODE->] I am trying to provide more context:The situation: I have a server which would send a HTTP request to python script which sends something back.In reality: The python script  and server are both in docker machines.Could you comment on the schematics of having  a webserver in python like Flask -> dockerising the python script with the webserver -> and then listening for the HTTP request on the port exposed by the this docker machine? So docker-server when sends HTTP request it connects to the docker-python-webserver_plus_script. Can this scenario be possible.Also I figured out how to get inside a docker container. Is there any way that I can use a editor like Sublime and not Vim for the files inside docker container?
[2016-07-29 20:49:27] <mgangelov> Also I figured out how to get inside a docker container. Is there any way that I can use a editor like Sublime and not Vim for the files inside docker container?Probably not, as most images don't have a graphical environment within them. I guess only possibility is if there's a suitable Sublime plugin - maybe if you have an ssh service running, there is a plugin for Sublime which allowed you to access and edit files (similar to winscp). However, I don't know if it's a good idea to run more than one process on a container (it's considered bad practise). I guess I recommend to stick with vim, although I also personally don't like it very much and prefer Sublime.
[2016-07-29 20:50:35] <prastut> Sorry@mangelov95I am very new to docker, so might be posting some noob doubts. Sorry if this feels very basic.
[2016-07-29 20:52:53] <mgangelov> No, I just hitEnterby mistake before finishing my answer. I'm also new to Docker, so my answer might not be the most correct one, but that's my solution.
[2016-07-29 20:53:57] <prastut> mangelov95: so the good practice is generally doing the edits on your system and build the docker machine again?
[2016-07-29 20:54:10] <prastut> Oh no issues. :)
[2016-07-29 20:55:29] <mgangelov> prastut: No idea what the best practise is (also relatively new to Docker), but I read online that usually people edit their files locally and then transfer them to the running container - so not necessary to rebuild the whole image. I'm not sure how exactly this is done though, sorry.
[2016-07-29 20:56:03] <prastut> No problem, thanks for helping me out 
[2016-07-29 20:59:13] <mgangelov> prastut: No problem, hope I'm mostly correct. 
[2016-07-29 23:22:59] <jondubois> I released v5 of my open source project on Hacker News "SocketCluster v5 – The kubernetization". Upvotes welcome [<-LINK->] 
[2016-07-30 05:22:28] <mayliupeng> hi
[2016-07-30 05:26:30] <mayliupeng> I have a question.I am reading an article named  "Docker for PHP Developers”.I am pulled 4 images.
[2016-07-30 05:26:39] <mayliupeng> tutorial/nginx      latest              7ebd59cdd410        About an hour ago   344.5 MB
[2016-07-30 05:28:14] <mayliupeng> sameersbn/mysql,phusion/baseimage,nmcteam/php56
[2016-07-30 05:28:59] <mayliupeng> how can i find my docker host IP address.I am using docker 1.12 with mac.
[2016-07-30 05:30:26] <mayliupeng> May someone help me?The article says “Our application will be accessible at the docker.dev domain. You should map this domain to your Docker host IP address. If you run Docker natively on your Linux operating system, use the IP address of your own computer. If you rely on Boot2Docker, find your Docker host IP address with the boot2docker ip bash command. Let\'s assume your Docker host IP address is 192.168.59.103. You can map the docker.dev domain name to the 192.168.59.103 IP address by appending this line to your local computer\'s /etc/hosts file:"
[2016-07-30 05:42:20] <aios> Hi all. So any body can tell me how i can deploy data container with exists data. As example mysql container with complete  imported database.
[2016-07-30 05:48:19] <mayliupeng> I know.I used the 127.0.0.1.
[2016-07-30 20:36:19] <neoreeps> docker-machine ip default
[2016-07-30 20:39:48] <neoreeps> mangelov95: actually, i will commonly map my source directory to the install directory and then edit outside the container using standard tools ... changes are instantly reflected within the container ... for instance, my web_app is installed in /opt/web_app so I mount my source using "-v source/web_app:/opt/web_app"
[2016-07-30 20:44:37] <mgangelov> Yeah, that's a good idea. Does this create a new Docker volume or just mounts a host directory in the container?@neoreeps
[2016-07-30 20:45:43] <neoreeps> effectively just mounts the directory over the existing directory in the container.  Does not create docker volume in aufs blah blah ...
[2016-07-30 21:09:56] <mgangelov> Sounds clean!
[2016-07-31 09:55:09] <dextrum74> Hey everyone. Can anyone help me with my dockerfile? I need to start service when container starts, so i wrote my dockerfile and all worked fine until i added USER directive. Here my simplified dockerfile: [<-CODE->] 
[2016-07-31 09:57:15] <dextrum74> I just want change user, but when i did it service start command no longer works
[2016-07-31 10:08:09] <dextrum74> I think i figured out, since CMD executing when container starts it means i have no longer root privilegies, even if this directive above in the code than USER directive. So ... Should i use sudo to start nginx service???
[2016-07-31 10:13:00] <dextrum74> But as written in documentation sudo is not recomend to use in Dockerfile, so what do i do, any ideas?
[2016-07-31 14:03:49] <nakedcity> hey guys anybody knows where a particion is mount with docker compose when using volumes_from from another service
[2016-07-31 14:04:31] <agibsonccc> Anyone use docker in docker to host a complex docker-compose environment?
[2016-07-31 14:05:02] <mattjude> Any devs working on spark 2.0 container?
[2016-07-31 14:06:03] <mattjude>  [<-LINK->] 
[2016-07-31 17:02:17] <chrisguest75> Anyone experiencing problems with the time handling differences between Docker for Windows and Docker for Mac?  On the Mac my time is correct inside the containers whereas on Windows it it 11 hours behind where it should be.    I can't seem to find much discussion on it anywhere.
[2016-07-31 17:17:46] <funkytaco> Do your windows containers have ntp clients?
[2016-07-31 17:17:56] <chrisguest75> Found it - [<-LINK->] yes- disabling and reenabling time sync on hyper-v fixes it instantly.
[2016-07-31 17:18:26] <funkytaco> From that thread: "Same problem here. Ntpd service was not running. Started it manually and now the time is in sync."
[2016-07-31 17:19:15] <chrisguest75> funkytaco: is it recommended to configure  ntpd on the boot2docker image or inside the container?
[2016-07-31 17:19:28] <funkytaco> I'm not sure
[2016-07-31 17:19:51] <funkytaco> I would think both
[2016-07-31 17:20:13] <chrisguest75> All I did was to go into hyper-v settings and click on - click off.  instantly fixed it..  I'm using hyper-v on a laptop so I think sleep is messing with it.
[2016-07-31 17:20:26] <funkytaco> i'm guessing people who create lightweight containers would say only the host
[2016-08-01 01:32:22] <beenanner> Anyone tested out the 1.12 docker swarm stuff yet? I can’t seem to get a single service to be reachable from all nodes. It seems it’s only ever reachable from the node which has the container running.
[2016-08-01 17:17:15] <tclarke> question about log drivers (specifically gelf2). I'm using the plugin to log to logstash/elasticsearch. How do I disambiguate the container's stdout from stderr? It looks like it might use thelevelfield with 6 or 3 (syslog error vs. info) but I'm not sure if other levels are possibl
[2016-08-01 17:46:52] <rollymaduk> Hi please does anyone know how to setup a mongo replica set using a stack file? or docker compose?
[2016-08-01 19:09:52] <beenanner> tclarke: yea I had a similar situation so I’m interested as well what the best practice is
[2016-08-01 19:09:58] <beenanner> I was parsing syslogs with
[2016-08-01 19:10:05] <beenanner> if [message] =~ /\\<30\\>/ {
[2016-08-01 19:10:31] <beenanner> which seems terrible :-p
[2016-08-02 03:30:27] <deanrather> Hey everyone!
[2016-08-02 05:10:04] <MakanTaghizadeh> deanrather: Hey! 
[2016-08-02 05:21:08] <deanrather> Been playing with Docker a lot lately. Just thought I'd say hi instead of being a creeper :p
[2016-08-02 05:30:58] <jizhilong> Hello, everyone!
[2016-08-02 05:33:07] <jizhilong> excuse me for cutting in an ad: [<-LINK->] is a cli tool for building,tagging,and pushing a bunch of related images.
[2016-08-02 05:34:36] <MakanTaghizadeh> jizhilong: nice job! I like it 
[2016-08-02 06:09:27] <jizhilong> MakanTaghizadeh:  thanks!
[2016-08-02 08:20:30] <rkgade> can Visual Studio be packaged as simple docker image?
[2016-08-02 09:56:29] <mgangelov> Since no one in the Swarm room seems to be active, I'll ask this also here:I'm trying to create a network on a swarm but I seem to get this error: [<-CODE->] Do you have any idea what this means? I looked up online but so far found nothing.
[2016-08-02 13:34:05] <rkgade> Can you give the create command ?
[2016-08-02 13:39:36] <mgangelov> rkgade: I've located the problem, turns out I needed to update to1.12to make swarm work with networks without a key-value store
[2016-08-02 14:59:42] <dmitrovskiy> Asking this question because of inactivity in #machine room. [<-CODE->] 
[2016-08-02 17:19:35] <rkgade> mangelov95: yeah. now that 1.12 is GA, you can get it. This is one of the best releases of docker so far. Now docker is very much at a stable state without much dependencies on other tools for either networking or high available key value stores like etcd or consul.
[2016-08-02 17:20:48] <rkgade> Docker 1.12 also has mesh inbuilt so that when request is routed to a host for a container it doesn't host, the machine can itself re-route the request to the machine which runs the required container.
[2016-08-03 08:25:34] <mgangelov> rkgade: I don't like the new version of  Docker so far, too many new things and not enough documentation. Also can we only createdocker-composebundles with images with digests, i.e. ones that have been pushed to the hub? This is very inefficient and hinders the experience.
[2016-08-03 08:48:26] <tony199555> docker for windows is not as awesome as I thought it would be....just saying
[2016-08-03 08:50:03] <tony199555> But i guess microsoft is holding a lot of stuff that docker team cannot touch...so it is not really docker team's fault
[2016-08-03 08:53:51] <mgangelov> tony199555: Isn't what's provided enough for image development and configuration? Just curious, haven't used Docker on Windows and probably won't (because of Windows).
[2016-08-03 08:58:46] <tony199555> hummm, let me just say the features that are dedicated to windows are not really there....so if you have a software with a gui... it is not really working (without purchasing a very expensive server license). For home users/developers that want a quick containment of a gui software, this makes it not good enough.
[2016-08-03 09:00:57] <tony199555> For the part that I said it will (probably) work with a license is because ms has two different images, full and lite version, as I read through the news, the full version will have a desktop (although ms say it will die sooner or later)
[2016-08-03 09:48:33] <rkgade> mangelov95: agreed on those lines. Documentation has to be improved to help people explore the several new things.
[2016-08-03 09:51:38] <mgangelov> Well granted, a lot of  these functionalities are still experimental and very new, so things surely will improve in terms of documentation coverage. I'm trying to use the new docker swarm mode to deploy a docker-compose application, so maybe that's why I feel the lack now.@rkgade
[2016-08-03 09:54:19] <rkgade> tony199555: docker for Windows, at lease images that Microsoft is releasing on docker hub are providing only the runtime. Development tools cannot be put into container for the reason of X11. For example, eclipse or visual studio or stuff like that.
[2016-08-03 11:49:45] <mgangelov> Speaking of the experimentalbundlefeature ofdocker-compose, is there way to add the unsupported top level keys such asnetworksandvolumesin the .dab file, so that they would also be created automatically?
[2016-08-03 14:55:20] <intellix> how can I easily change the project prefix of my docker-compose?
[2016-08-03 14:56:05] <intellix> at the moment it uses the folder name as the prefix, but that's causing conflicts
[2016-08-03 15:01:54] <SachinKSingh28> intellix: : From the docker compose docs, it seems you can pass argument with -p switch to change the project prefix.
[2016-08-03 15:02:11] <intellix> ah, can't persist it to docker-compose file yet though :s
[2016-08-03 15:05:41] <SachinKSingh28> alternatively, you can COMPOSE_PROJECT_NAME environment variable but that won't persist it to docker-compose either.
[2016-08-03 15:06:22] <intellix> really old issue about it here: [<-ISSUE->] 
[2016-08-03 15:06:54] <intellix> ah, you can have a .env in the same folder
[2016-08-03 17:32:36] <izhilenkov> Hi guys! I have problem with creating host via rancher on digitalocean and got stuck on ‘waiting for agent’ stage, does anyone know how to solve it, or, maybe, where can I ask about it?
[2016-08-04 01:45:29] <deanrather> Hey-yo everyone. Just trying to get my head around the whole docker for both dev and deployment workflow... Say in my repo I've got aDockerfilewhich hasfrom:ubuntuand defines how to build an image for my application... Developers usedocker-compose up --buildto get a dev env and start hacking away... When they commit a new version, our CI auto-rebuilds a new image for that version, and we can deploy it... so far so good. But my question is, now that I've got an image in our registry for v1, when a dev comes along what's the workflow so that instead of rebuilding a dev image fromubuntu, they can start fromapplication:v1? Is there an example of this workflow in a blog or repo somewhere? Or is everyone using a different solution?
[2016-08-04 02:45:59] <tony199555> rkgade: I have done a little bit search on x11... not quite sure what is it doing on windows side
[2016-08-04 08:43:55] <linsheng9731> hi, everyone . I just try to login my private registry:2.0 but failed with docker mac , is anyone know how to solve it?
[2016-08-04 08:44:37] <nicosuave> posting your stack traces would be helpful@linsheng9731
[2016-08-04 08:53:29] <linsheng9731> '''
[2016-08-04 08:55:02] <linsheng9731> when i try to login registry, the log:'''Aug  4 16:51:33 damondeMacBook-Pro Docker[28552] <Notice>: VM: 2016-08-04 08:51:33 +0000 UTC daemon.info vsudd: Connection 5 to: 2376 from: 00000000Aug  4 16:51:33 damondeMacBook-Pro Docker[28552] <Notice>: VM: 2016-08-04 08:51:33 +0000 UTC daemon.info vsudd: 5 Done. read: 96 written: 141Aug  4 16:51:33 damondeMacBook-Pro Docker[28550] <Error>: failed to establish 9P connection: Caught EOF on underlying FLOWAug  4 16:51:33 damondeMacBook-Pro Docker[28683] <Notice>: EOF reading packet from Unix domain socket: closingAug  4 16:51:33 damondeMacBook-Pro Docker[28683] <Critical>: Failed to read hello from clientAug  4 16:51:35 damondeMacBook-Pro Docker[28552] <Notice>: VM: 2016-08-04 08:51:35 +0000 UTC daemon.info diagnostics: Running /bin/cat--- last message repeated 27 times ---Aug  4 16:51:35 damondeMacBook-Pro Docker[28552] <Notice>: VM: 2016-08-04 08:51:35 +0000 UTC daemon.info diagnostics: Running /usr/bin/tail--- last message repeated 2 times ---Aug  4 16:52:11 damondeMacBook-Pro Docker[28552] <Notice>: VM: 2016-08-04 08:52:11 +0000 UTC daemon.info vsudd: Connection 6 to: 2376 from: 00000000Aug  4 16:52:12 damondeMacBook-Pro Docker[28552] <Notice>: VM: 2016-08-04 08:52:12 +0000 UTC daemon.info vsudd: 6 Done. read: 221 written: 2249'''The registry:2.0 is running behind a nginx proxy !
[2016-08-04 10:12:01] <linsheng9731> the nginx log :```
[2016-08-04 10:12:05] <linsheng9731> 10.0.1.170 - user [04/Aug/2016:09:51:26 +0000] "GET /v1/users/ HTTP/1.1" 404 19 "-" "docker/1.12.0 go/go1.6.3 git-commit/8eab29e kernel/4.4.15-moby os/linux arch/amd64 UpstreamClient(Docker-Client/1.12.0 \\x5C(darwin\\x5C))" "-"
[2016-08-04 10:12:17] <linsheng9731>  [<-CODE->] 
[2016-08-04 10:12:35] <linsheng9731> why the docker for mac request the v1 api ?
[2016-08-04 15:15:18] <intellix> getting errors that 3306 (mysql) port is already allocated... but I don't have a container running on that port
[2016-08-04 15:15:27] <intellix> it seems like Docker has ahold of it but it's locked or something
[2016-08-04 15:28:57] <mgangelov> Hello, how can I access a container from the public IP of a Swarm note? Scenario is this:I have a web application, let's say Ghost blog. \nI'm deploying it to a node, but I cannot access the private IP as I'm not on the same network as that node is\nI have a public IP assigned to the node and I can use that one to connect. However I can't connect using the same port to which my web application is running (I've binded the host port and the container port together)\nHow exactly to make this work - access the web application from the node's public IP?I know that when I deploy the web app locally everything works fine.
[2016-08-05 01:13:05] <Spittal> Hey guys, I’m having a performance problem with the new Docker for Mac.I’m running a container locally for development that’s just the standard node image from dockerhub. I run webpack from within the container and had no problems with performance before upgrading to official Docker for Mac from Dinghy. I’m talking some big time performance hits. My webpack builds went from about 2 seconds to over 60 seconds.Is this something that is known in the community? Is the performance of Docker for Mac not up to the same standard as a VM like Dinghy?
[2016-08-05 08:22:25] <intellix> I believe it's to do with I/O. There's an open issue in their forum or something with a lot of people talking about it: [<-LINK->] 
[2016-08-05 08:23:21] <intellix> reply from David Sheets about it: [<-LINK->] 
[2016-08-05 10:33:19] <edmondo1984> MakanTaghizadeh: With relation to my question of the 24 july 09:01. The mongodb docker script has a number of customization at startup, so I do not know if launching a plain mongod and running the script would work
[2016-08-05 15:50:14] <kauhat> Anyone here moved from a traditional WHM hosting setup to a container environment? I work at a small web dev where we manage ~100 bog-standard apache/php/mysql sites split between a couple dedicated servers.Would creating a pod for each server be a performance disaster. Is it worth it?
[2016-08-05 16:06:38] <Spittal> intellix: That’s great information
[2016-08-05 16:06:39] <Spittal> thanks a lot!
[2016-08-06 19:01:39] <thecb4> Question -- I am trying to use docker 1.12 on Ubuntu 14.04 behind a proxy and I am getting the following error "x509: certificate signed by unknown authority".  The proxy is not HTTPS.  All of the documentation points to using the signing certificate from the proxy but what do you do when you don\'t have a signing certificate from the proxy?
[2016-08-07 05:26:52] <MakanTaghizadeh> Sorry for this delay@edmondo1984. I've been away for a while. Well, Unfortunately I cannot recall the context. let's recap the story, if you'd like. You want to create a mongo image which includes some documents. And these documents/collections/databases are provisioned and inserted into the DB while building the image. Right so far?
[2016-08-07 15:18:37] <edmondo1984> Correct@MakanTaghizadeh. Yhoug
[2016-08-07 15:18:40] <edmondo1984> The default
[2016-08-07 15:18:58] <edmondo1984> The default image for mongo does much more than starting mongidb
[2016-08-07 20:01:48] <LotosikRa> Hi, everyone.
[2016-08-07 20:02:43] <LotosikRa> Is it a chanel for most of the problems with docker, like using simple containers?
[2016-08-07 20:05:51] <rgodishela> Yup
[2016-08-07 20:09:54] <LotosikRa> I have some problem: I can't reach webapp which is running inside container. I tried to connect to 192.168.99.100 ip and use ˋ-p 5000:5000ˋ, but every time I got ˋconnection refusedˋ error.
[2016-08-07 20:12:00] <LotosikRa> All answers that I have found is about specific ip or port's mapping.
[2016-08-07 20:13:52] <LotosikRa> what info I need to publish to bost resolving?
[2016-08-07 20:15:06] <rgodishela> Were u exposing the port inside the container
[2016-08-07 20:16:58] <LotosikRa> by default app is deploying on 127.0.0.1:5000
[2016-08-07 20:23:43] <LotosikRa> and as I saw in log of container it realy is 5000
[2016-08-07 20:27:16] <rgodishela> docker run -it -P 5000:5000 <imagename:tag>
[2016-08-08 09:46:27] <danielpalmquist> Hi everyone hope you're all having a wonderful great time.
[2016-08-08 09:47:27] <danielpalmquist> I've been getting back into programmer after many years and I'm super excited for my start up in the future that is going to be revolutionary1
[2016-08-08 09:58:58] <mgangelov> danielpalmquist: good luck!
[2016-08-08 10:33:35] <LotosikRa> iamrameshjonathan: I tried to use your command and have error: unable to find image 5000(because-Pdoesn't need any values).If I turn it to-p, launch app on 5000 port, then, whent trying to connect to192.168.99.100:5000I can't reach them again with the same error.
[2016-08-08 10:50:31] <rgodishela> -P publishes all the ports. You may try with -p. I see that u tried with -p.
[2016-08-08 10:50:48] <rgodishela> check docker logs <container name>
[2016-08-08 10:51:18] <rgodishela> check docker inspect <container name> may give you some hints.
[2016-08-08 12:13:39] <auspenskii> Hello! Do i need remove container volumes with docker rm -v <container id> after builds done?
[2016-08-08 12:15:21] <rgodishela> Absolutely
[2016-08-08 12:24:42] <rgodishela> Just wanted to mention that You can remove all volumes with the above command.
[2016-08-08 12:25:34] <rgodishela> if they are inhereited using --volumes-from then you cannot remove and if you have assigned them using with name then u cannot remove.
[2016-08-08 12:25:55] <LotosikRa>  [<-CODE->]  [<-CODE->] 
[2016-08-08 12:30:10] <rgodishela> docker run -it -p 5000:5000 <user/repo:tag> --entrypoint <path/yo/python> <python-file>
[2016-08-08 12:30:17] <rgodishela> try above command.
[2016-08-08 12:31:43] <LotosikRa> nothing change
[2016-08-08 12:33:29] <LotosikRa> and I have another question: can I (and how) quit from container's input without usingexitcommand (that will stop container)?
[2016-08-08 12:35:51] <rgodishela> docker run -d enables u run the container in detachable mode.
[2016-08-08 12:37:33] <auspenskii> iamrameshjonathan: Thank you. But i'm a bit confused with my builds via docker executor. I use gitlab ci and private docker registry to test my php website. My .gitlab-ci.yml ( [<-LINK->] ) when new build triggered docker executor use image from private registry and then runner execute commands in container. I want to do parallel builds in containers so i use docker and set concurrency for runners.  So the question is how can I delete the volume automatically after completion of the build?
[2016-08-08 12:41:40] <LotosikRa> iamrameshjonathan: I'm sorry, I have useddocker run -it -p 5000:5000 --entrypoint <path/to/python> <user/repo:tag> <python-file> <command_for_starting>command, but your command didn't execute and returned usage-help. I think that it is because options for docker must be defined before<user/repo:tag>
[2016-08-08 12:42:28] <LotosikRa> docker run -d enables u run the container in detachable mode. [<-CODE->] 
[2016-08-08 12:47:47] <rgodishela> LotosikRa: You may trydocker run -it -p 5000:5000  --entrypoint <path/yo/python> <python-file> <user/repo:tag>
[2016-08-08 12:50:26] <rgodishela> auspenskii: I would store container id in a variable  when docker run completes
[2016-08-08 12:50:46] <rgodishela> then i can call docker rm -v <containerid>
[2016-08-08 12:51:16] <LotosikRa>  [<-CODE->] This command make error - docker want to find <python-file> like image
[2016-08-08 12:52:33] <rgodishela> auspenskii: or i would do docker run then it will have container id , i immediately grab container id usingdocker ps -l -q, I can call docker rm -v using that container id,
[2016-08-08 12:52:54] <rgodishela> auspenskii: ; u may wanna write a small shell script
[2016-08-08 12:53:01] <LotosikRa> I think this is because <python-file> is an argument for python program and may be defined after image name
[2016-08-08 12:53:22] <rgodishela> LotosikRa: : Yeah, try to run without passing --entrypoint
[2016-08-08 12:53:53] <rgodishela> LotosikRa: docker run -it -p 5000:5000 <user/repo:tag> /bin/bash
[2016-08-08 12:53:58] <auspenskii> iamrameshjonathan: thanks, but where i can configure this variables?
[2016-08-08 12:55:08] <auspenskii> iamrameshjonathan: i need delete volumes from host machine, i think runner cant execute docker commands inside container
[2016-08-08 12:55:32] <LotosikRa>  [<-CODE->] ok, executed, what's next ? in this form python's webapp didn't launch
[2016-08-08 12:56:21] <rgodishela> auspenskii: all these commands have to be run within the host not in container.
[2016-08-08 12:57:19] <rgodishela> LotosikRa: once you are in conatiner, try to launch pythoon webapp, check whether you are able access it from web
[2016-08-08 12:59:10] <rgodishela> auspenskii: : we can only guide you ! Thats how i would do it and you know your environment better so implement that above mentioned solutions to rectify the blocker.
[2016-08-08 13:02:05] <auspenskii> iamrameshjonathan: Yes, I understand, thanks for help.
[2016-08-08 13:03:11] <rgodishela> LotosikRa: if everything works then try --entrypoint="</path/to/python> <python file"
[2016-08-08 13:03:20] <rgodishela> auspenskii: Happy to help!!
[2016-08-08 13:07:16] <LotosikRa> iamrameshjonathan: I have two more questions:How can I know that everything works (port's binding)
[2016-08-08 13:12:18] <LotosikRa> if use entrypoint in this form\n@LotosikRa if everything works then try --entrypoint="</path/to/python> <python file" [<-CODE->] 
[2016-08-09 01:32:54] <necrose99> i'm curious if i can hold onto the docker shell longer
[2016-08-09 09:20:52] <grofit> hello I am trying to get docker running on windows
[2016-08-09 09:21:08] <grofit> and I have a machine running using virtualbox (I have vmware for other stuff so couldnt enable hyper-v)
[2016-08-09 09:21:33] <grofit> but whenever I try to compose an example (the wordpress one) it just blows up saying it cannot find the docker daemon
[2016-08-09 09:21:45] <grofit> all the issues around this seem to be in linux or mac but not on windows
[2016-08-09 09:22:02] <grofit> I have tried adding a DOCKER_HOST user var and setting it to the url of the machine thats running
[2016-08-09 10:02:41] <grofit> The verbose error incase anyone can help is: [<-CODE->] 
[2016-08-09 10:03:39] <grofit> and the DOCKER_HOST user variable is set totcp://192.168.99.100:2376I have tried setting it also to just the IP, IP + PORT still no luck
[2016-08-09 10:13:13] <grofit> (just to confirm thats what docker-machine reports back as the running ip/port)
[2016-08-09 10:45:40] <grofit> oh I realised I had to rundocker-machine env defaultin my other window where I want to compose, all works then
[2016-08-09 12:40:59] <dg-ratiodata> The following commands runs a container with seccomp disabled [<-CODE->]  [<-CODE->] Thanks a lot.
[2016-08-09 15:17:21] <alebianco> anyone knows what's the release cycle of docker for windows? like when the next beta is scheduled etc
[2016-08-09 16:34:23] <prastut> Hi guys! I am having a problem linking containers. Can any kind soul help me out?I have 2 containers:a java server\na flask serverI have linked the flask server to the java server i.e env variables and hosts of flask server are updated in the java server container. The flask server runs on localhost inside the flask server. Now I need to make a POST request to the flask server from the java server. The steps of achieving  the POST request is done. The IP config is something I am running into trouble.
[2016-08-09 16:35:57] <brunoban> Have you exposed any ports?
[2016-08-09 16:36:07] <brunoban> Actually nevermind, I’m not sure you need that
[2016-08-09 16:36:31] <prastut> Yup@brunobanfrom the flask server I have exposed port 5000
[2016-08-09 16:36:36] <brunoban> But what you might need is to bind the java ip to the container
[2016-08-09 18:48:59] <grofit> I have a weird error where I cannot build containers, I am using windows, docker toolbox, virtualbox 5.1.2
[2016-08-09 18:49:37] <grofit> if I run from creating a machine to setting up environment and trying to build a container I get: [<-CODE->] 
[2016-08-09 18:51:09] <prastut> grofit: does the node-test folder contain a Dockerfile?
[2016-08-09 18:51:23] <grofit> yes which contains
[2016-08-09 18:51:33] <grofit>  [<-CODE->] 
[2016-08-09 18:52:09] <grofit> (I am very new so if I have made a mistake anywhere please point it out)
[2016-08-09 18:53:30] <prastut> grofit: I am not familiar with how docker works on windows. Sorry. :/
[2016-08-09 18:54:06] <grofit> np, I am not familiar with it either but google doesnt really help here :(
[2016-08-09 18:54:30] <grofit> do I need to do anything special to get docker engine running? or is that justdocker-machine?
[2016-08-09 18:55:41] <prastut> Umm I think you have to use these env variables to connect to the virtual machine. When you are inside the virtual machine, then docker commands would probably work I guess.
[2016-08-09 18:55:59] <grofit> oh one mo, I need to do these commands inside the VM?
[2016-08-09 18:56:09] <grofit> I thought docker dealt with all that for me
[2016-08-09 18:56:24] <prastut> Yup see this: [<-LINK->] 
[2016-08-09 18:56:57] <grofit> oh yes that bit
[2016-08-09 18:57:03] <grofit> I did that bit in the above code snippet
[2016-08-09 18:57:10] <grofit> where I diddocker-machine env default
[2016-08-09 18:57:18] <prastut> That just gives you the ENV variables.
[2016-08-09 18:57:20] <grofit> isnt that what is required to inject the vars into the current cmd window
[2016-08-09 18:57:21] <prastut> For you to set
[2016-08-09 18:57:40] <grofit> lol
[2016-08-09 18:57:51] <grofit> right ok if I copy and paste the last@FORline
[2016-08-09 18:57:53] <grofit> it works
[2016-08-09 18:58:05] <grofit> is there any tooling which can simplify this sort of thing?
[2016-08-09 18:58:28] <grofit> as its painful having to do the env setup every time I want to do something with docker
[2016-08-09 18:58:40] <prastut> eval "$(docker-machine env default)"Run this command once?
[2016-08-09 18:58:51] <grofit> that is a linux command right?
[2016-08-09 18:58:55] <grofit> on windows its@FOR /f "tokens=*" %i IN (\'docker-machine env default\') DO @%i
[2016-08-09 18:59:19] <prastut> What does it say?
[2016-08-09 18:59:28] <grofit> nothing, but like I say when I did that the build worked
[2016-08-09 18:59:45] <grofit> I thought the output from thedocker-machine env defaultwas setting it
[2016-08-09 18:59:56] <grofit> I didnt know you needed to do the extra bit at the end
[2016-08-09 18:59:58] <prastut> Nono it's just printing out the env variables.
[2016-08-09 19:00:04] <grofit> yeah thats a pain :(
[2016-08-09 19:00:06] <grofit> anyway
[2016-08-09 19:00:18] <grofit> while thats happening whats the difference betweendocker runanddocker-compose up
[2016-08-09 19:00:59] <prastut> Docker run is used to start a container based on an image. Docker-compose is a little tricky and mostly used when you are diving into multi-containers application.
[2016-08-09 19:01:26] <grofit> ah ok, as different tutorials used different commands, some using compose which seemed to bypass the container building step
[2016-08-09 19:02:01] <prastut> Yup because you would have a .yml file on which docker compose runs.
[2016-08-09 19:02:36] <prastut> So inside the yml file, steps are written to build/pull images or run containers based on these images.
[2016-08-09 19:03:03] <prastut>  [<-LINK->] 
[2016-08-09 19:04:14] <grofit> ah ok, so is that more for infrastructure setup
[2016-08-09 19:04:47] <prastut> Yes.
[2016-08-09 19:05:47] <grofit> ok thanks
[2016-08-09 19:07:54] <grofit> I have set my docker container running withdocker run -p 3456:3456 -d grofit/exampleand I can connect up to it which is great
[2016-08-09 19:07:58] <grofit> but how do I stop it now?
[2016-08-09 19:08:04] <grofit> docker stop seems to stop the whole of docker
[2016-08-09 19:08:14] <grofit> its listed indocker ps
[2016-08-09 19:08:18] <prastut> Nope there is nothing like stopping the whole docker
[2016-08-09 19:08:30] <grofit> oh right sodocker stopis the right one?
[2016-08-09 19:08:41] <prastut> docker stop <container name>/<container ID>
[2016-08-09 19:08:51] <grofit> ah right ok I tried that but maybe I did a typo
[2016-08-09 19:09:13] <grofit>  [<-CODE->] 
[2016-08-09 19:09:30] <prastut> That's the image name
[2016-08-09 19:09:32] <andersonkyle> Its not the image name its the container ID
[2016-08-09 19:09:34] <grofit> OH is container ID the crazy hash I got out
[2016-08-09 19:09:42] <grofit> so whats the container name here?
[2016-08-09 19:09:49] <prastut> Indocker psthere's a name column
[2016-08-09 19:09:58] <andersonkyle> Its the hash.
[2016-08-09 19:10:08] <andersonkyle> You'll see it in docker ps
[2016-08-09 19:10:10] <prastut> You can use the hash also like@kanderson450said.
[2016-08-09 19:10:24] <grofit> ah right ok
[2016-08-09 19:10:39] <grofit> it was actuallyfe3622e1ca769a0188e8ec26b7ada404e004dbf0abd49a1fab6e32566a122f28
[2016-08-09 19:10:42] <prastut> Try using names whenever you build your images.docker run --name grofit -p 3456:3456 -d grofit/example
[2016-08-09 19:10:45] <grofit> if I did docker stop with that it stopped it
[2016-08-09 19:10:52] <prastut> Awesome!
[2016-08-09 19:10:52] <grofit> AH right I need to specify a name
[2016-08-09 19:11:03] <grofit> ok so going back to a question before
[2016-08-09 19:11:08] <andersonkyle> Keep in mind, you can only have one container with that name.
[2016-08-09 19:11:09] <grofit> are there any tools recommended to manage this stuff?
[2016-08-09 19:11:18] <andersonkyle> docker-compose is nice.
[2016-08-09 19:11:25] <grofit> so you can see in a GUI tool or something what is running etc
[2016-08-09 19:11:40] <andersonkyle> Kitematic
[2016-08-09 19:11:49] <grofit> well I saw some tuts that used docker-compose but I didnt see its use case vs run
[2016-08-09 19:11:49] <prastut>  [<-LINK->] 
[2016-08-09 19:11:52] <grofit> I have that installed
[2016-08-09 19:11:56] <grofit> as part of toolbox one mo
[2016-08-09 19:13:14] <andersonkyle> grofit: Is your issue resolved?
[2016-08-09 19:13:36] <grofit> yeah
[2016-08-09 19:13:40] <grofit> I got it running and stopped
[2016-08-09 19:13:45] <grofit> I mean I have LOTS of questions
[2016-08-09 19:13:50] <grofit> but I will spread them out as I learn
[2016-08-09 19:14:11] <grofit> as I currently deploy a lot of API/Front end systems at work and home and have wanted to delve into docker
[2016-08-09 19:14:18] <grofit> but its only recently been usable on windows
[2016-08-09 19:14:41] <grofit> kitematic seems to blow up :(
[2016-08-09 19:14:47] <grofit> let me try deleting the VM and retrying
[2016-08-09 19:15:25] <prastut> grofit: you can try watching this playlist. This helped me a lot. [<-LINK->] 
[2016-08-09 19:18:29] <grofit> I get the "why" just not the "how"
[2016-08-09 19:19:10] <grofit> but I think most of it is just using the tooling and getting used to it
[2016-08-09 19:19:43] <grofit> as I like the idea of being able to provision my API with db and various other stuff as a container
[2016-08-09 19:19:44] <andersonkyle> grofit: What are you trying to do that you don't know how to yet?
[2016-08-09 19:19:57] <andersonkyle> Ok, that would be multiple containers
[2016-08-09 19:19:58] <grofit> well we have ticked the first box of make a container and run it
[2016-08-09 19:20:01] <grofit> yeah
[2016-08-09 19:20:06] <grofit> but then I have to link them right
[2016-08-09 19:20:20] <andersonkyle> You would typically use docker-compose which helps orchestrate mutliple containers
[2016-08-09 19:20:22] <grofit> locally I use a mongodb instance but in live I use mongolab
[2016-08-09 19:20:25] <andersonkyle> Yes exactly.
[2016-08-09 19:20:38] <prastut> kanderson450: is there any provision to provide bi-directional linking in docker?
[2016-08-09 19:20:40] <grofit> yeah thats one of the confusing thigns as the docs were quite sporadic on that
[2016-08-09 19:20:45] <prastut> 2 containers talking to and fro?
[2016-08-09 19:20:47] <grofit> but thats a task for me to just google more
[2016-08-09 19:20:55] <andersonkyle> grofit: Absolutely
[2016-08-09 19:21:14] <grofit> although tooling was one thing I was looking at, so I could try to automate a lot of this
[2016-08-09 19:21:18] <andersonkyle> grofit: You will link A -> B and B -> A
[2016-08-09 19:21:24] <grofit> so with our projects we clone, npm install, gulp and off it goes
[2016-08-09 19:21:31] <grofit> so the less I make people do on top the better
[2016-08-09 19:21:42] <grofit> then there is the actual live orchestration aspect, I looked at kubuntes or whatever its called
[2016-08-09 19:22:00] <grofit> but again without knowing the innards of how docker works it didnt all fit yet
[2016-08-09 19:22:29] <andersonkyle> grofit: I would suggest doing your building outside of Docker, with your CI server
[2016-08-09 19:22:54] <grofit> that would build the containers right (TeamCity)
[2016-08-09 19:23:04] <andersonkyle> grofit: Then create a Docker image via a Dockerfile that includes your runtime, application artifact, any other dependencies, and that's it.
[2016-08-09 19:23:10] <grofit> although it would probably be orchestrated via a gulp script, I am sure there is somegulp-docker
[2016-08-09 19:23:50] <grofit> yeah so an artifact is output which is the api, but it will need some "hooks" or something to know that it requires external containers right?
[2016-08-09 19:24:08] <grofit> i.e it may need a locally provisioned mongodb instance on test env as well
[2016-08-09 19:24:08] <andersonkyle> grofit: Possibly, but if not you just run your normal build commands then at the end run docker build foo/bar ./dist/
[2016-08-09 19:24:41] <grofit> then there is the whole issue of templating the dockerfile based upon environmental target
[2016-08-09 19:24:51] <grofit> again I am thinking like 10 steps down the road here without having walked more than 2 :)
[2016-08-09 19:25:02] <grofit> but those are the sort of things that I am trying to solve with docker
[2016-08-09 19:25:12] <andersonkyle> grofit: Right.  Keep the Dockerfile generic and use Environment Variables.
[2016-08-09 19:25:15] <grofit> then eventually just deploy to some cloud host with load balancing etc
[2016-08-09 19:25:44] <grofit> but in the scenario of needing mongodb locally for dev, CI, test but not in live
[2016-08-09 19:25:56] <andersonkyle> grofit: Create a Dockerfile that includes your application artifcat (whatever that is for you, .jar, .exe, etc.)
[2016-08-09 19:26:09] <grofit> can I set aUseLocalDBenv var or something to toggle it?
[2016-08-09 19:26:15] <grofit> yep yep
[2016-08-09 19:26:19] <andersonkyle> grofit: Then create a docker-compose file that starts your custom image, and then also starts mongodb and links the two together.
[2016-08-09 19:26:20] <grofit> a nodejs app in this case
[2016-08-09 19:26:45] <grofit> ah ok so then it is no longer adocker run ...its adocker-compose my-compose-file
[2016-08-09 19:26:50] <grofit> which will tie them all together
[2016-08-09 19:27:05] <andersonkyle> grofit: Perfect, your custom Dockerfile can extend the official node file [<-LINK->] 
[2016-08-09 19:27:09] <grofit> and the docker-compose is done at the environment setup level not the app level
[2016-08-09 19:27:14] <grofit> kk
[2016-08-09 19:27:17] <andersonkyle> grofit: Yup.
[2016-08-09 19:27:28] <grofit> well leave it with me, you guys have been super helpful and over the next few weeks I am sure I will be back with more questions
[2016-08-09 19:27:44] <andersonkyle> grofit: docker-compose just allows your to start multiple container with a single command
[2016-08-09 19:27:58] <grofit> and that is probably one of the most important bits going forward
[2016-08-09 19:28:03] <andersonkyle> grofit: You can obviously still use docker run*but that would be painful with a lot of related containers
[2016-08-09 19:28:13] <grofit> yeah and that was one thing that was not clear
[2016-08-09 19:28:56] <andersonkyle> grofit: Go try your node app + mongodb using Dockerfile and docker-compose and you'll be well on your way
[2016-08-09 19:29:09] <prastut> kanderson450: yes linking A -> B then B -> A. How to achieve that?
[2016-08-09 19:29:16] <grofit> will do that tomorrow, need to nip afk for a bit now, but will ping you later if I get stuck
[2016-08-09 19:29:23] <grofit> OH sorry one quick/last question
[2016-08-09 19:29:27] <grofit> you know when I make a container
[2016-08-09 19:29:31] <grofit> i.edocker build ...
[2016-08-09 19:29:40] <grofit> I assumed it got stored locally
[2016-08-09 19:29:50] <andersonkyle> prastut: using --link with docker run or the link: section in docker-compose
[2016-08-09 19:29:51] <grofit> but I also know there is docker hub which stores stuff, so it doesnt go there by default right
[2016-08-09 19:30:09] <prastut> Umm it's not possible without docker-compose?
[2016-08-09 19:30:17] <andersonkyle> grofit: Exactly.  You can create a Docker Hub account and then do docker push
[2016-08-09 19:30:30] <grofit> but assuming I dont want to do that as its all private (well I could pay for it)
[2016-08-09 19:30:47] <prastut> kanderson450: I was reading this article: [<-LINK->] 
[2016-08-09 19:30:59] <grofit> but anyway assume I am not wanting to use that, does it just store them locally on my FS somewhere?
[2016-08-09 19:31:02] <andersonkyle> prastut: Both ways.  docker run --link db:db foo/barOr put a link: attribute in your docker-compose file
[2016-08-09 19:31:37] <andersonkyle> grofit: Inside the Virtual Machine which is either VirtualBox or Hyper-V depending on which Docker version you are using.
[2016-08-09 19:31:57] <andersonkyle> grofit: You can see all your local images with docker images
[2016-08-09 19:31:59] <grofit> ah, yes I am using VB, I use VMWare lots for work so HyperV conflicts
[2016-08-09 19:32:21] <grofit> I hoped there would be an official driver for VMWare Workstation but there wasnt
[2016-08-09 19:32:32] <grofit> an unofficial one though but its install seemed daunting
[2016-08-09 19:32:34] <grofit> anyway bbl
[2016-08-09 19:34:49] <andersonkyle> prastut: That article is talking about more advanced networking topologies with Docker.  I'm simply saying that with links you can allow apps to communicate with each other easily.
[2016-08-09 19:36:05] <prastut> Okay I have 2 docker containers:A\nB
[2016-08-09 19:36:29] <prastut> I am able to link B to A and therefore A has the required params to communicate to B. How can B communicate back to A?
[2016-08-09 19:36:59] <andersonkyle> docker run --link b:b a (That will allow a to talk to b)docker run --link a:a b (That will allow b to talk to a)
[2016-08-09 19:38:19] <prastut> See that's the issue, the run creates a new container. It's like building on top of each other. When you run the first command you expect that container B is running. But as soon as you execute the second command, it spins of another container for B.
[2016-08-09 19:38:51] <andersonkyle> prastut: I see what you're saying.  Chicken or the Egg scenario.
[2016-08-09 19:38:53] <blandes> You could always do an docker exec -it container_name bash
[2016-08-09 19:39:00] <blandes> It would run in that container alone.
[2016-08-09 19:39:06] <blandes> Not spawn another run off command
[2016-08-09 19:39:23] <prastut> blandes: didn't get you?
[2016-08-09 19:40:31] <andersonkyle> prastut: You're correct in that if you start A it needs B to be already running, but if you start B it needs A to already be running.
[2016-08-09 19:40:44] <blandes> Well, you're using something likedocker run blah blahwill build another container that either stay running or die, right? You could also rundocker exec -it container_name /bin/sh -cThat would make it run in that container alone rather spawn the extra container with runner
[2016-08-09 19:41:37] <prastut> blandes: as far as I knowexecandlinkare seperate
[2016-08-09 19:41:53] <andersonkyle> prastut: This is a good article [<-LINK->] 
[2016-08-09 19:41:54] <blandes> Ohhh I see what you're trying to do, my bad.
[2016-08-09 19:41:57] <blandes> What about docker-compose?
[2016-08-09 19:42:18] <blandes> You should probably use that instead of having individual containers running by themselves. You have better control of your stack.
[2016-08-09 19:42:27] <blandes> I kinda jumped in and didn't read everything, my bad./
[2016-08-09 19:42:38] <andersonkyle> prastut: It offers a few different options, each of which varies in complexity.
[2016-08-09 19:43:07] <blandes> For instance, I have a container that turns on, migrates a db, then dies. So A is still going but B did all the work.
[2016-08-09 19:43:17] <prastut> blandes: no problem!
[2016-08-09 19:43:27] <prastut> kanderson450: thanks for the article! This seems elaborative.
[2016-08-09 19:43:34] <andersonkyle> prastut: I would typically solve this by using a Service Discovery / Configuration server.
[2016-08-09 19:43:55] <andersonkyle> prastut: No problem.  Pick the best solution for your domain.
[2016-08-09 19:44:00] <prastut> kanderson450: can you explain a little in detail (n00b aleart)
[2016-08-09 19:44:40] <prastut> Right now I have exposed both A and B docker containers to the host machine and then they are able to communicate with each other.
[2016-08-09 19:44:54] <prastut> Using the--net=hostflag
[2016-08-09 19:45:02] <prastut> Looking for a better solution, that is.
[2016-08-09 19:45:48] <andersonkyle> prastut: I'm in the Java space so I use Spring heavily.  They have wonderful dependencies such as Eurka that allow your apps to look a common point for finding other services & configuration. [<-LINK->] 
[2016-08-09 19:45:50] <blandes> So, there's a lot of different ways you could solve that. At least to make things a little bit more easier for you. This will be kinda lengthy, but I'm messing with about 20 containers locally as I type this.
[2016-08-09 19:46:07] <andersonkyle> prastut: G2G now.  Hope that helps.
[2016-08-09 19:46:27] <blandes> So basically, what you could do is this.docker create network test-network-discovery. Create a network so that you can control different stacks in the same network w/ network discovery.
[2016-08-09 19:47:12] <prastut> kanderson450: thanks for the help! I am too working with a Java based real-time server called SwellRT. [<-LINK->] (Like the open source version for Firebase or Parse)
[2016-08-09 19:47:32] <prastut> I was connecting it with a Python container for ML/NLP strength.
[2016-08-09 19:47:47] <blandes> Next you woulddocker run -d -p 80:80 -v /var/run/docker.sock:/tmp/docker.sock:ro   --name my-nginx-proxy --net test-network-discovery jwilder/nginx-proxywhich makes use of an automatic nginx proxy that looks for certain environment variables on that network you just made.
[2016-08-09 19:47:52] <prastut> So I needed back and forth containers.
[2016-08-09 19:48:35] <prastut> blandes: this seems nice. I was going to look into docker networks, thanks for the headsup
[2016-08-09 19:49:32] <blandes> next you could run those containers likedocker run - p 80:80 --network test-network-discovery -e VIRTUAL_HOST=workstation.dev container_nameanddocker run - p 80:80 --network test-network-discovery -e VIRTUAL_HOST=workstation2.dev --link db:mysql --name= db container_name
[2016-08-09 19:49:42] <blandes> Here's the repo for the reverse proxy
[2016-08-09 19:49:49] <blandes> Hope this helps. I'll be quiet now :)
[2016-08-09 19:49:53] <blandes>  [<-LINK->] 
[2016-08-09 19:50:30] <prastut> OH oh! 
[2016-08-09 19:50:55] <prastut> Thank you@blandes! This clears a lot of the conceptual part. Will get back to implementing .
[2016-08-09 20:53:49] <remram44> Is there a way to force the daemon to look for volumes under a certain path?
[2016-08-09 20:54:21] <remram44> ie when using-v /some/dir:/datafrom the client, it would actually mount the host's/srv/docker/some/dir?
[2016-08-09 20:54:54] <remram44> I know I could probably run Docker in a fs namespace but that's starting to get weird
[2016-08-10 06:52:57] <grofit> Hello
[2016-08-10 06:53:18] <grofit> so continuing on from our discussions last night aboutdocker runanddocker-composefor larger apps
[2016-08-10 06:54:04] <grofit> now from the "developer" level, i.e you are creating an api, be it nodejs/.net/java etc and you want to run it locally but have infrastructure provisioned for it without installing it all on your pc
[2016-08-10 06:54:24] <grofit> do you basically containerize it from the start and run/debug it within a deployed container
[2016-08-10 06:54:53] <grofit> or do you just get docker to setup the infrastructure requirements and hook into them so you debug and run locally?
[2016-08-10 06:55:08] <grofit> I am just trying to gauge the workflow when trying to make best use of the tech
[2016-08-10 08:21:30] <bruceauyeung> hi everyone. i'm using docker 1.12 swarm mode
[2016-08-10 08:21:36] <bruceauyeung> what's the difference between advertise-addr and listen-addr for docker swarm init?
[2016-08-10 14:45:13] <grofit> kanderson450: As you were pretty knowledgeable on workflows etc do you have any comments on my question 3 lines above?
[2016-08-10 15:25:00] <andersonkyle> grofit: You can do either or.  I have two docker-compose files.  One that starts the databases, message brokers, etc and then I'll run my applications locally.  I have another docker-compose file where I start everything.  You can still debug your apps within the container, as long as you expose the proper ports.  This is runtime specific so you'll have to check Node.js and Express.js or whatever you happen to be using for the details.
[2016-08-10 15:30:28] <andersonkyle> grofit: It is generally more convenient to do most of your development & debugging locally, outside of the container.  Its easier to configure HotReloading, TimeTravel, etc. for a super productive development experience.  You can create as many variations of your apps + infrastructure by creating another docker-compose file.
[2016-08-10 15:56:49] <grofit> OK thanks, so it's not uncommon to have multiple co
[2016-08-10 15:57:47] <grofit> Composition  files in a single project? I am on my phone don't know why it sent half way through
[2016-08-10 15:59:59] <diegossilveira> hello! I'm using docker-compose v1.8.0 and docker v1.12.0 on OS X and I'm facing an issue related to container network. If all services declared in a docker-compose.yml file are on the same network, should service containers be able to ping each other using the service name?
[2016-08-10 16:01:19] <diegossilveira> Because I'm able to ping just from containers that declaratively links to another container, but not the reverse way. Example: container A is linked to container B, I can ping B from A, but not A from B.
[2016-08-10 21:06:31] <grofit> So the info from earlier was great, but one other query I now have, so lets say I go with local app but containerised infrastructure (DB, Message Queues etc)
[2016-08-10 21:07:01] <grofit> now currently I have a single machine "default" on docker machine, however would each composed thing go to their own machine? or does each machine have many containers?
[2016-08-10 21:07:41] <grofit> as basically my question is do I have to provision machines ahead of time, or is there some way to automate this part and if so how do you know what the IP addresses will be for your machines in use?
[2016-08-10 21:11:22] <grofit> as realistically in most scenarios you would want your DB on a different box to your other stuff etc
[2016-08-11 07:16:39] <grofit> I get that most people dont use windows  with docker and even if they do they use hyper-v but for those of you who do use windows and virtual box do you ever have issues where every time you restart you have to manually remove all machines from the.dockerfolder in your user dir? as if I dont I cannot start the default machine and Kitematic is unable to begin, so every reboot requires me basically creating all machines
[2016-08-11 07:17:00] <sofiaguyang> Hi there, I have a quick question about Dockerfile's entrypoint. How will an image's ENTRYPOINT behave if it is based on another image that has ENTRYPOINT already defined?
[2016-08-11 07:19:28] <grofit> I dont have a clue, I can barely get containers going :)
[2016-08-11 08:10:47] <grofit> also when using docker-compose during your development processes do you automate it in any way via gulp scripts or anything or is it a manual step to run it?
[2016-08-11 10:43:26] <gertjvr> we have a start-everything script execute docker-compose
[2016-08-11 10:43:48] <gertjvr> not using gulp atm
[2016-08-11 10:48:19] <grofit> well gulp is not super important as long as there is some way to orchestrate the loading of stuff on command line simply
[2016-08-11 10:49:07] <grofit> like ideally the process would be:Devs clone repo with app and compose files for container dependencies\nSetup containers for app (mongo, redis etc)\nRun app locally but depend upon containers
[2016-08-11 10:49:17] <grofit> and currently we clone, npm install, gulp and job done
[2016-08-11 10:49:40] <grofit> so I was hoping I could do same thing, but have the gulp step provision the machine/containers etc so no extra work is needed
[2016-08-11 10:50:06] <gertjvr> add a single script called reset-the-world which is the first thing after cloning to setup local environment
[2016-08-11 10:50:24] <gertjvr> and then start-the-world to start any external things
[2016-08-11 10:51:02] <grofit> ok so focusing on that bit
[2016-08-11 10:51:23] <grofit> is it best practice to create a machine at that point for hosting the containers then doing the docker compose stuff?
[2016-08-11 10:51:50] <grofit> or do you generally just have adocker-machineprovisioned machine (Again I am on windows) which you just use (docker-machine env defaultetc)?
[2016-08-11 10:52:05] <gertjvr> atm local dev machine setup require then to rundocker-for-windowsordocker-for-mac
[2016-08-11 10:52:46] <grofit> I currently havedocker toolbox
[2016-08-11 10:52:58] <grofit> as I cannot use HyperV due to needing VMWare for other stuff
[2016-08-11 10:53:28] <gertjvr> but can't see why you couldn't include thedocker-machine createin the start reset-the-world script
[2016-08-11 10:54:01] <grofit> but I found that if I diddocker-machine create --driver=virtualbox defaultif I tried to use kitematic it would blow up and need to remove it, and most of the time when I re start my PC I would generally have issues communicating and need to kill/destroy the VM and restart it anyway
[2016-08-11 10:54:04] <gertjvr> only thing is port forwarding to the host
[2016-08-11 10:54:10] <grofit> that was my query if I should have that there
[2016-08-11 10:54:24] <grofit> if it was "best practice" generally when working with docker to have a machine per "project"
[2016-08-11 10:54:49] <grofit> unless you need loadbalancing and other gubbins which would need multiple machines, but again the point of "creating what you need" as part of the project setup
[2016-08-11 10:54:57] <gertjvr> depends... we have multiple solutions that need a common environment
[2016-08-11 10:54:58] <grofit> rather than expecting a machine to exist for you
[2016-08-11 10:55:47] <gertjvr> I see docker as a thing the developer needs to have setup, ie like visual studio ide
[2016-08-11 10:56:20] <gertjvr> but running the containers withdocker-composeis then easy
[2016-08-11 10:56:37] <grofit> yeah but I think the distinction here is that I am talking about machines for docker not the docker setup itself
[2016-08-11 10:56:52] <grofit> its assumed a dev has docker-toolbox or docker-for-windows or whatever installed
[2016-08-11 10:57:32] <grofit> its just how the machines are provisioned and the containers loaded, and those 2 things there I wanted to focus on if an "app" should provision both machines and containers, or just expect all devs to have adefaultmachine pre-setup and just manage container setup
[2016-08-11 10:57:36] <gertjvr> its an assumption, but I am assuming the developer also knows how to setup there local laptop / pc
[2016-08-11 10:57:36] <grofit> if that makes sense?
[2016-08-11 10:58:04] <gertjvr> makes sense
[2016-08-11 10:58:20] <gertjvr> I totally agree want you want to do
[2016-08-11 10:58:39] <gertjvr> but will all your devs be using docker-toolbox
[2016-08-11 10:58:55] <gertjvr> do you care if the have a custom docker setup
[2016-08-11 10:59:25] <gertjvr> just depends on what your common setup is
[2016-08-11 11:00:07] <grofit> well for my current approach I just need to setup mongodb in a container locally for them and have the API app (nodejs) use the db instance there
[2016-08-11 11:00:35] <grofit> then there are a couple of front end apps which would need to depend upon the API (previous app) in a container, which in turn would need mongodb etc
[2016-08-11 11:00:50] <gertjvr> how do you store the config ie connection strings?
[2016-08-11 11:00:53] <grofit> so thats my current "test" for docker to get it all running that way and see if it all works
[2016-08-11 11:01:07] <grofit> the app has a config file which is currently templated as part of build
[2016-08-11 11:01:31] <grofit> when its closer to production it would probably use Octodeploy or something to manage the release aspect
[2016-08-11 11:01:31] <gertjvr> so it would be an ip address to the docker host?
[2016-08-11 11:01:49] <gertjvr> love octopus
[2016-08-11 11:01:49] <grofit> and this ties into part of the question, if you provision the machine you can set the IP of it right?
[2016-08-11 11:01:55] <gertjvr> great product
[2016-08-11 11:02:03] <grofit> our .net apps do build on TC and release management on Octo
[2016-08-11 11:02:10] <gertjvr> same
[2016-08-11 11:02:11] <grofit> so we would probably use the same sort of approach for node
[2016-08-11 11:02:26] <grofit> but its just getting docker plugged in and working with it all
[2016-08-11 11:03:06] <gertjvr> what version are you guys on?
[2016-08-11 11:03:10] <grofit> anyway so like you say the api and front end app need IP addresses, api needs ip/port of mongo (port configured through evn vars for container) and the front end needs IP and port of API (again port via env vars) but the IPs seem to be at the machine level
[2016-08-11 11:03:15] <grofit> version of what?
[2016-08-11 11:03:25] <gertjvr> Octo
[2016-08-11 11:03:31] <grofit> one mo
[2016-08-11 11:03:58] <grofit> 3.2.13
[2016-08-11 11:04:08] <gertjvr> because we are using docker-for-windows + port forwarding to the host
[2016-08-11 11:04:25] <grofit> but docker-for-windows requires HyperV right?
[2016-08-11 11:04:26] <gertjvr> we are able to usemongodb.localtest.me:8000
[2016-08-11 11:04:34] <grofit> thats handy though
[2016-08-11 11:05:04] <gertjvr> which for some reason is faster than going docker.local:8000
[2016-08-11 11:05:13] <gertjvr> or direct with the ip-address
[2016-08-11 11:05:27] <grofit> I assume those dns entry things and all setup by docker-for-windows client?
[2016-08-11 11:05:35] <grofit> as docker toolbox doesnt seem to have any of that stuff
[2016-08-11 11:05:41] <gertjvr> yes docker-for-windows does require hyperv
[2016-08-11 11:05:53] <gertjvr> uses a proxy service
[2016-08-11 11:06:11] <gertjvr> there is no host entries etc
[2016-08-11 11:07:08] <grofit> so just to rewind
[2016-08-11 11:07:21] <gertjvr> yes
[2016-08-11 11:07:33] <grofit> so your team all have docker for windows, and all have the same proxy settings etc
[2016-08-11 11:07:48] <grofit> so your apps only setup containers in the batch/powershell file?
[2016-08-11 11:07:50] <gertjvr> yip, etc 2 developer are using macs
[2016-08-11 11:08:40] <grofit> so is the only scenario where you need multiple machines (given that you have multiple containers on same machine) to do load balancing setups etc
[2016-08-11 11:08:54] <grofit> or would you even do that within the same machine (as at the docker level its all isolated as its own machine on the kernel right?)
[2016-08-11 11:09:00] <gertjvr>  [<-CODE->] 
[2016-08-11 11:09:00] <grofit> (I am still fairly new to all this)
[2016-08-11 11:09:17] <grofit> ah right ok
[2016-08-11 11:09:20] <gertjvr> we have a common docker-compose repo
[2016-08-11 11:09:27] <grofit> so in your project root you just have compose folders for each container required
[2016-08-11 11:09:27] <gertjvr> out side of the application
[2016-08-11 11:09:33] <grofit> ah right
[2016-08-11 11:09:49] <grofit> could you not just have one docker compose file per app and have multipleFROM:entries?
[2016-08-11 11:10:08] <gertjvr> issue is one app requires rabbit + moto
[2016-08-11 11:10:15] <gertjvr> another redis + dynamo
[2016-08-11 11:10:22] <gertjvr> the combination are endless
[2016-08-11 11:10:32] <grofit> yeah I personally (again not knowing docker too well) would just have a single compose file per app
[2016-08-11 11:10:36] <grofit> so it only includes what it needs
[2016-08-11 11:10:44] <grofit> is there some problem doing it that way?
[2016-08-11 11:10:49] <gertjvr> nope
[2016-08-11 11:11:02] <gertjvr> if everything is isolated for the single app / repo
[2016-08-11 11:11:08] <grofit> yeah, ok thanks
[2016-08-11 11:11:20] <grofit> I think you have answered some of my questions and now I have some more
[2016-08-11 11:11:35] <gertjvr> ping me if you need some help
[2016-08-11 11:11:38] <grofit> thanks buddy
[2016-08-11 11:12:31] <gertjvr> are you in oz?
[2016-08-11 11:12:43] <grofit> so for anyone else here who does not have docker for windows or proxy setup ahead of time, do you guys provision a machine with a specific IP or common settings ahead of time, or do you provision the machine at build time?
[2016-08-11 11:12:45] <grofit> I am in UK
[2016-08-11 16:00:04] <GehaniNeil_twitter> chaos engineering w/network emulation for #docker containers - https://goo.gl/aXHxqQ
[2016-08-11 17:19:05] <iosven> Hi, just now I had a case with a Dockerfile containing the non-best-practice setting ENV DEBIAN_FRONTEND=noninteractive (for background see [<-ISSUE->] ). Now, the Dockerfile contained an apt-get upgrade.
[2016-08-11 17:20:03] <iosven> Having some queued updates the apt-get upgrade promted interactively whether to continue or not, which broke the automated DockerHub build which should run non-interactively and only break on relevant issues.
[2016-08-11 17:20:48] <iosven> What is the best thing to do here?Is is maybe wrong to do apt-get upgrade in a Dockerfile?\nShould apt-get upgrade -y be used instead?\nSome other solutions...?
[2016-08-11 17:34:20] <kellyp> is there any documentation for how to turn on the http api for the native mac install?
[2016-08-11 17:39:44] <kellyp> or is it running and I am dumb?
[2016-08-11 19:48:34] <iosven> Why does [<-LINK->] deliver an empty JSON array? I think I did nothing wrong, and it has worked with other images before.
[2016-08-11 19:49:49] <iosven> Kitematic tells me the server is misbehaving ^^ Is that so, why?
[2016-08-11 19:53:41] <epifanio> Hi, I’m building a series of docker images .. but i’m encountering the error: [<-CODE->] 
[2016-08-11 19:54:41] <epifanio> in myDockerfilei’ve interactions like: [<-CODE->] 
[2016-08-11 19:55:15] <epifanio> is the usage of&&generating more instances ofRUN?
[2016-08-11 19:56:02] <epifanio> my automated build failed with this log: [<-LINK->] 
[2016-08-11 20:59:07] <alexellis> Hiall
[2016-08-11 21:22:08] <prastut> Hi guys! Is there any good tutorials for networks and docker compose? Kind souls can post the links too ;)
[2016-08-11 21:25:51] <BretFisher_twitter> hey all... the Captain invasion...
[2016-08-11 21:30:11] <BretFisher> ok that's better, silly twitter
[2016-08-11 21:33:48] <BretFisher> epifanio: if you take that run line out does it still error? (the build log requires me to login, meh)
[2016-08-11 21:38:22] <epifanio> BretFisher: thatRUNcommand is just an example of the several run istance I have in my Dockerfile. the log ends with this log: [<-LINK->] 
[2016-08-11 21:38:44] <epifanio> A build step failed: Cannot create container with more than 127 parents
[2016-08-11 21:39:06] <epifanio> so I’m now figuring out how to reduce the number ofRUN
[2016-08-11 21:40:37] <epifanio> I’m not sure if myRUNexample (using sequence of commandscommand1 ; command2; ...orcommand1 && command2 && ...), counts for 1 singleRUN
[2016-08-11 21:41:24] <BretFisher> right i would add line by line and build each time just for process of elimination.
[2016-08-11 21:41:57] <BretFisher> using&& \\is common to string shell commands together, counts as one RUN
[2016-08-11 21:44:49] <epifanio> the problem is the total amount ofRUNfor the last build, this is my [<-LINK->] the error arise at the build of my [<-LINK->] 
[2016-08-11 21:45:39] <epifanio> i guessdocker buildis taking into account the full amount ofRUNfor all the images
[2016-08-11 21:46:50] <epifanio> to build, I’m using this [<-LINK->] withmake build-all
[2016-08-11 21:46:52] <BretFisher> how many FROM: are you chaining?@epifanio
[2016-08-11 21:47:20] <epifanio> BretFisher: 9 images in total
[2016-08-11 21:47:47] <BretFisher> OK so 127 layers is the current docker limit I think
[2016-08-11 21:48:19] <BretFisher> so you can chain run commands with the&& \\
[2016-08-11 21:48:52] <BretFisher> basically put multiple shell commands in with that to seperate and they'll all count as one layer in image
[2016-08-11 21:50:47] <epifanio> yes, I’m attempting a new build where i merged together severalRUNinstances
[2016-08-11 21:51:27] <epifanio> and I wasn’t sure the&& \\syntax was actually reducing the number of total runs
[2016-08-11 21:51:37] <epifanio> thanks for confirming it
[2016-08-11 21:51:59] <BretFisher> yea this kinda chaining is common in Dockerfile [<-LINK->] 
[2016-08-11 22:03:56] <epifanio> the weird is that it builds fine locally on my server,  and
[2016-08-11 22:04:09] <epifanio> I’m also be able to push it to docker hub
[2016-08-11 22:05:10] <epifanio> but then if I try to pull it from kinematic on windows, it fail giving the log:  Cannot create container with more than 127 parents
[2016-08-11 22:05:52] <epifanio> while for the same repository, but using kinematic beta on my OS X, i can pull the image and work with it just fine
[2016-08-11 22:58:44] <prastut> Hi guys, my docker-compose file is the following: [<-CODE->] 
[2016-08-11 22:58:53] <prastut> Docker ps command:
[2016-08-11 22:59:40] <prastut>  [<-CODE->] 
[2016-08-11 23:00:01] <prastut> Still I am swellrt service isn't able to connect to teem-swellrt-mongo.
[2016-08-11 23:00:50] <prastut> Any clue?
[2016-08-11 23:32:44] <BretFisher> epifanio: maybe it's a version issue in the one that's failing is an older version before limits were raised (a guess)?
[2016-08-11 23:37:13] <BretFisher> prastut: will need to see your mongo compose or run config
[2016-08-12 08:06:32] <auspenskii> hello, why when i try to build my image with docker build -t my-image . in .gitlab-ci.yml via docker dind this image don't have repository name or tag? [<-CODE->] 
[2016-08-12 08:08:54] <BretFisher> auspenskii: does the build command work in assigning a tag if you run it yourself?
[2016-08-12 08:09:06] <BretFisher> w/o gitlab yaml
[2016-08-12 08:09:51] <auspenskii> BretFisher: i don't know need to check
[2016-08-12 08:13:29] <auspenskii> BretFisher: heh, but how i can make it inside docker dind i need run build and test it in parallel?
[2016-08-12 08:34:21] <auspenskii> BretFisher: maybe i need specify full path to Dockerfile when use docker build -t my-image /full/path/to/Dockerfile ?
[2016-08-12 08:34:53] <BretFisher> that's a gitlab question, not related to Docker really :)
[2016-08-12 08:35:31] <auspenskii> ok)
[2016-08-12 08:37:59] <BretFisher> maybe you need$(pwd)/Dockerfilein there, doesn't hurt to try
[2016-08-12 08:39:08] <auspenskii> BretFisher: ok i will try, thank you.
[2016-08-12 08:54:57] <grofit> If I was to locally have an API which I wanted to wrap up as a container, then I wanted to run that container on another machine for another app, so like a front end application depending upon an api (which in turn depends upon dbs etc), given I am on windows so everything happens via VMs is the only way to get the api container from one machine to the other to use something like docker hub?
[2016-08-12 08:55:07] <grofit> as my understanding is containers are cached per machine
[2016-08-12 09:17:17] <auspenskii> BretFisher: yes this thing work, but need to use only $(pwd) because context must be a directory. Thanks for help! )
[2016-08-12 11:53:51] <stephanlinke> hey everbody :)
[2016-08-12 12:03:12] <auspenskii> hi
[2016-08-12 13:36:37] <intellix> my OSX Docker 1.12a seems to be dead, even after restarts I\'m still getting "Bad response from Docker" errors :(
[2016-08-12 13:45:34] <aios> hi all. have simple question
[2016-08-12 13:45:54] <aios> i getting a wordpress container from hub.docker.com
[2016-08-12 13:46:35] <aios> how i can get wordpress files on host machine - or access to wordpress files in container for develop plugins or themes or something?
[2016-08-12 13:47:44] <aios> if i make volumes:  ".:/wordpress"  directory are clean
[2016-08-12 13:48:21] <aios> sorry for bad english - if answer very simple take a direction in documentation please. ty for advance.
[2016-08-12 14:17:24] <grofit> I got that working the other day
[2016-08-12 14:17:47] <grofit> basically you setup a machine, setup your environment (if using windows)docker-machine env <your-env>
[2016-08-12 14:18:02] <grofit> then once you have done that you setup your docker compose file to get wordpress and myself or whatever
[2016-08-12 14:18:19] <grofit> then docker-compose, you can set a mapped drive in the compose file to a local directory if you want
[2016-08-12 14:18:32] <grofit> but I think with windows there are issues with virtualbox and mapped/shared drives
[2016-08-12 14:56:23] <prastut> BretFisher: I have changed my docker-compose file to this: [<-CODE->] 
[2016-08-12 14:57:16] <prastut> The swellrt service has 2 linksdbandtagger. They should both be visible iniside etc/hosts and as env variables but they aren't for some reason
[2016-08-12 16:31:33] <prastut> Please can anybody help me out?
[2016-08-12 18:41:40] <BretFisher> prastut: ok a few things. 1. your env should be- MONGODB_HOST = db
[2016-08-12 18:43:19] <BretFisher>  [<-CODE->] 
[2016-08-12 18:46:34] <BretFisher> Starting around docker 1.10, you will not see entries inside container for /etc/hosts. Now Docker has a DNS server built in, so you should be able to do lookups within a container for other service namesdbandtaggerfrom insideswellrt
[2016-08-12 18:47:09] <BretFisher> Yourtaggeralso needs to expose a port
[2016-08-12 18:51:19] <BretFisher> aios: You're almost there. When you add a bind-mount like.:/wordpressit will overwite what's in container with what's in the host directory. Is the host dir empty?
[2016-08-12 19:09:13] <prastut> @BretFisher thank you for the help, though the solution didn't work. I am detailing out the process:I have 3 containers:db - mongoDB\nbackend - swellRT\nML+flask - taggerI need to create a link from db to backend, and a bidirectional link between backend and tagger system (to get the data which needs to be processed to tagger and updating back the data to swellrt from tagger). Plus want to improve the current architecture, since docker-compose is the way to go for multi-container relationships.Before the docker-compose setup, the link between backend and db was done by this command: [<-CODE->] So if the person doesn't pass the env_variables related to MongoDB, the backend is coded this way to take some default values.Now I need to do the same in terms of docker-compose setup. Following is my new file: [<-CODE->] 
[2016-08-12 19:10:01] <prastut> The backend fails to connect to MongoDB as it can't reach the MONGODB_HOST. If I hardcode the value to something like172.16.0.1it works.
[2016-08-12 19:11:12] <prastut>  [<-CODE->]  [<-CODE->] Clearly the MONGODB_HOST = db is not being defined for the server to properly access it.
[2016-08-12 19:12:17] <prastut> How can I pass the IP of the container/service as a variable to the env_variables for the backend?
[2016-08-12 19:37:16] <BretFisher> ok if sitting on that shell of teem-swellrt-c what do you see when youping db?@prastut
[2016-08-12 19:40:10] <prastut> BretFisher: ping: unknown host
[2016-08-12 19:42:02] <BretFisher> ok trying to replicate your issue, brb
[2016-08-12 19:42:32] <prastut> Thank you@BretFisher, much appreciated. 
[2016-08-12 20:20:41] <BretFisher> hmph this works for me @prastut [<-CODE->] then I ping from inside nginx and it sees db [<-CODE->] then i try to curl endpoint [<-CODE->] everything works for me, so wonder what's diff for you?
[2016-08-12 20:29:22] <prastut> Absolutely clueless as to why it doesn't work for me.
[2016-08-12 20:30:59] <prastut> BretFisher: is it possible to get the IP of the container? or say the value what db holds?
[2016-08-12 22:03:12] <dpayne9000>  [<-LINK->] 
[2016-08-12 22:03:20] <dpayne9000> Docker related maymay
[2016-08-12 22:23:20] <BretFisher> prastut: dns is only supported way.
[2016-08-12 22:25:20] <BretFisher> What's your versions of compose and docker?
[2016-08-13 05:27:03] <prastut> BretFisher:  [<-CODE->] 
[2016-08-13 06:43:23] <aios> BretFisher: VERY VERY VERY THANKS!!!
[2016-08-13 10:58:15] <prastut> BretFisher: I was able to work with this config, the problem was how the environment variables were being defined. Following is my revamped docker-compose file: [<-CODE->] 
[2016-08-13 10:59:02] <prastut> I feel such examples should be mentioned in the docker-compose documentation.
[2016-08-13 17:13:56] <DenisIzmaylov> Друзья, кто говорит на русском языке, наша группа в Telegram по DevOps давно переросла 1000 человек. Мы долго спорили - делать или нет, так или по другому, в итоге мы решили и сделали выделенную группу по Docker. Многим стало проблематично получить ответ на свой вопрос в основной группе devops_ru из-за потока сообщений, за которым, по-честному, становится всё сложнее уследить. В то время как Docker становится mainstream, стандартом упаковки и поставки серверных приложений.Да! Теперь вопросы и новости на тему Docker, Docker Swarm, Docker Cloud и всей его экосистеме, без флуда и профессионально можно получить в отдельной группе. Присоединяйтесь:https://telegram.me/docker_ru
[2016-08-13 22:23:04] <Orlandop43> I have installed doker on my pi but I can't run any image , and I am running pi images
[2016-08-13 22:23:47] <Orlandop43> Any one have done it successfully?
[2016-08-14 05:10:50] <aios> DenisIzmaylov: если че то тут это не интересно.
[2016-08-14 16:09:02] <BretFisher> Orlandop43: latest builds of docker 1.12.1 are working with Pi: [<-LINK->] 
[2016-08-14 16:45:03] <byoukstetter> Is it possible to run a windows docker image on a linux host?
[2016-08-14 17:09:50] <BretFisher> byoukstetter: if you're talking about Windows Containers, no
[2016-08-14 17:10:00] <BretFisher> reverse is also no
[2016-08-14 17:11:14] <BretFisher> Remember that containers aren't VM's, so what you store in them is executed on the kernal of the host OS, so even if you loaded mssql.exe in a container and put it on a linux host, it wouldn't run.
[2016-08-14 18:19:28] <BretFisher> prastut: so looking at your compose changes, I can't explain why those two changes would matter. [<-CODE->] 
[2016-08-14 18:20:28] <prastut> BretFisher: Haha loved the last line. Exactly what I felt like.
[2016-08-14 18:20:59] <BretFisher> Oh just noticed you're using ports not expose.
[2016-08-14 18:21:12] <prastut> BretFisher: I tried with expose, didn't work too.
[2016-08-14 18:21:15] <BretFisher> so that's not ideal for front-end-> db comms, as it exposes db port on your host
[2016-08-14 18:21:31] <BretFisher> so as long as you know the risks there
[2016-08-14 18:21:41] <prastut> Ports are dangerous or expose is?
[2016-08-14 18:22:07] <prastut> You are saying that the frontend may be able to access the DB if it's on the docker network?
[2016-08-14 18:22:31] <BretFisher> well ports will expose those ports to anything that can connect to server, expose only allows other containers in that compose file/network to connect
[2016-08-14 18:22:41] <prastut> Okay cool.
[2016-08-14 18:22:49] <prastut> Thanks for the headsup.
[2016-08-14 18:23:13] <BretFisher> yea ideally you'd want db to be expose, so other containers to talk to it, but only the public-facing site would use ports
[2016-08-14 18:23:34] <BretFisher> are your images public? i never tried pulling
[2016-08-14 18:23:46] <prastut> Also is there any place where I can document such things like you can try this also for linking? Somebody else might run this trouble and he/she could save that time.
[2016-08-14 18:23:51] <prastut> Yes they are public!
[2016-08-14 18:24:07] <prastut> I am working under Google Summer of Code program so everything that I code is open source. :D
[2016-08-14 18:24:26] <BretFisher> Nice, +1 for SoC!
[2016-08-14 18:24:49] <prastut> :D
[2016-08-14 18:25:13] <BretFisher> Well your issues are specifc to you, so let me see if i can recrate from your origional compose yaml
[2016-08-14 18:25:47] <prastut> Okay thanks, highly appreciate the personal help.
[2016-08-16 09:44:02] <groundnuty> hey, I would like to create my one docker cloud node, the thing is that I can't expose the exact pots required. I can expose different ports that will map to those ports on my machine. Is ther anyway to tell docker cloud to expect the secrive on different nodes?
[2016-08-16 09:44:09] <groundnuty> *different ports
[2016-08-16 10:38:43] <groundnuty> why does docker cloud disallow relative paths on host?
[2016-08-16 10:38:53] <groundnuty>  [<-LINK->] 
[2016-08-16 10:39:02] <groundnuty> I get error for that
[2016-08-16 15:11:40] <BretFisher> groundnuty: Cloud likely doesn't want relative paths because you 1. can't predict exactly where that folder will always be 2. can't assume all hosts in your cluster have that path.
[2016-08-16 15:27:58] <BretFisher> @groundnuty cloud saysWe recommend you open incoming port 2375 in your firewall for Docker Cloud to communicate with the Docker daemon running in the node. For the overlay network to work, you must open port 6783/tcp and 6783/udp.
[2016-08-16 15:29:14] <BretFisher> you could change the 2375 with this: [<-LINK->] 
[2016-08-16 16:41:40] <groundnuty> BretFisher: as far as ports are concerned, in some clouds I say I want to expose port 80 and the give me <public ip>:<some random port>
[2016-08-16 16:42:54] <groundnuty> so I have no control over, what port will it be exposed publicly
[2016-08-16 16:43:02] <BretFisher> groundnuty: are you talking about for your container apps or cluster management?
[2016-08-16 16:44:02] <groundnuty> BretFisher: I'm referring to 'setting my own node' for docker cloud
[2016-08-16 16:44:29] <groundnuty> so more cluster management I guess, as it will be used by some docker cloud agent
[2016-08-16 16:45:05] <groundnuty> only way it would work for me, would be if I could say to docker cloud 'hey, on this node,  seek the docker services on ports XYZ'
[2016-08-16 16:47:08] <BretFisher> So the 6783 tcp/udp have to be open between all hosts in a cluster, so containers can talk to each other inside their virtual overlay network
[2016-08-16 16:47:48] <groundnuty> yea and I cant find a way to say "on this node its not 6783 but some other port\'
[2016-08-16 16:55:43] <BretFisher> So I think the overlay network that Docker Cloud uses is Weave, and thoe ports are fixed inside a single cluster afaik
[2016-08-16 16:56:59] <BretFisher> So you're trying to build a single cluster between datacenters that have NAT between them I guess@groundnuty?
[2016-08-16 16:57:13] <groundnuty> BretFisher: much more simple :)
[2016-08-16 16:57:25] <groundnuty> we have a cloud that have just single public ip
[2016-08-16 16:57:33] <groundnuty> and machines who want to expose some ports
[2016-08-16 16:57:57] <groundnuty> can do it, but then they are reacable as
[2016-08-16 16:58:14] <BretFisher> also more on Docker Cloud limits for Bring Your Own Node: [<-LINK->] 
[2016-08-16 16:58:17] <groundnuty> <single public ip>:<random port> and that random port is directed to particualr VM and particualr port
[2016-08-16 16:58:39] <BretFisher> Oh, so, don't worry about any of the ports then if it's not cross-cloud.
[2016-08-16 16:58:56] <BretFisher> Inside your network the hosts have to have 6783 open
[2016-08-16 16:59:04] <BretFisher> and 2375 inbound from Cloud is optional
[2016-08-16 16:59:09] <groundnuty> yea, but the idea was to connect that VM
[2016-08-16 16:59:16] <groundnuty> to public docker cloud setvice :)
[2016-08-16 16:59:18] <groundnuty> as a node
[2016-08-16 16:59:29] <BretFisher> "2375/tcp: This allows Docker Cloud to communicate with the Docker daemon running in the node. If port 2375 is not accessible, Docker Cloud attempts to connect with the node through a secure reverse tunnel."
[2016-08-16 16:59:39] <groundnuty> !
[2016-08-16 16:59:40] <groundnuty> ok
[2016-08-16 16:59:46] <groundnuty> you saved me here i think :)
[2016-08-16 17:00:16] <BretFisher> it'll still works if  you install the cloud agent yourself via that link for BYOH
[2016-08-16 17:00:28] <groundnuty> yea, I will try thx :)
[2016-08-16 17:00:35] <groundnuty> I will get back and tell you if it worked
[2016-08-16 17:00:40] <groundnuty> I missed that part abotu the tunel
[2016-08-17 14:23:40] <anextro> Hello world :) :) :) :)
[2016-08-17 15:09:33] <ehernandez-xk> Hi
[2016-08-17 17:33:27] <akash1233> hi ... has anybody tried runing protractor tests through docker container ?
[2016-08-18 02:13:11] <b-rays> So I have one nginx container serving my static and another container serving my app. How do you connect?
[2016-08-18 02:14:15] <b-rays> Hmm how would you replicate the browserync node proxy with nginx in docker?
[2016-08-18 02:18:24] <b-rays> API: Hey static assets nice to meet you. Static: Oh Hey API, I've been looking for you. Dat convo doh.
[2016-08-18 02:19:08] <b-rays> How does one have this conversation in docker land?
[2016-08-18 07:39:19] <vito-c> anyone know how to increase the disk space usage of docker for mac
[2016-08-18 07:39:25] <vito-c> ~/Library/Containers/com.docker.docker/Data/com.docker.driver.amd64-linux/Docker.qcow2 this file is maxing out at 18GB
[2016-08-18 07:39:34] <vito-c> so i can't even create a new container
[2016-08-18 07:39:45] <vito-c> there was talk about it in the forum
[2016-08-18 07:39:47] <vito-c> as well
[2016-08-18 09:21:43] <avinash2888> hii... is it possible to store my container logs in aws s3 ?
[2016-08-18 09:22:24] <malinich> yes =)
[2016-08-18 09:22:48] <avinash2888> can you give me a brief idea how to do it
[2016-08-18 09:24:39] <malinich> store your container log into host folder-v /data/logs:/logsafter it save you file log where you wanna
[2016-08-18 13:50:11] <alethenorio> Good afternoon everybody. I am trying to figure out how the docker registry schema works. More specifically how do I go about knowing that there has been an update to a specific tag, do I simply count the number of fsLayers and compare?
[2016-08-18 15:36:19] <graingert> anyone know hot to get docker-compose ports working?
[2016-08-18 15:36:29] <graingert> I set them and it's not doing any port forwarding
[2016-08-18 17:05:22] <vito-c> graingert: paste it and give us a little more info
[2016-08-18 17:05:38] <vito-c> anyone know how to increase the disk usage of docker for mac??
[2016-08-18 17:44:01] <graingert> vito-c: it increases on its own, just download a boatload of images
[2016-08-18 17:44:47] <vito-c> graingert: ... that was my problem it wouldn't increase past 18GB
[2016-08-18 18:49:38] <justinhj_twitter> graingert: what do you see when running "docker-compose ps"? Is the ports column empty?
[2016-08-18 18:49:51] <graingert> found the issues
[2016-08-18 18:49:54] <graingert> issue*
[2016-08-18 18:50:04] <graingert> run doesn't open ports (anymore?)
[2016-08-18 18:50:33] <graingert> avinash2888: you probably want to send your logs to CWL then get CWL to dump to S3
[2016-08-18 18:50:56] <graingert> FluentD works nicely
[2016-08-18 20:17:05] <rkgade> Hi Team, any idea on how to search for docker images in DTR through command line ?
[2016-08-19 00:57:05] <ptdave20> Can i define a network interface in a Dockerfile?
[2016-08-19 05:35:39] <gertjvr> only docker-compose file from memory
[2016-08-19 08:46:22] <marcelmfs> akash1233: yes!
[2016-08-19 14:36:32] <brylor> HI. I have a docker-compose file which does command: gunicorn -w 4 -b 0.0.0.0:8000 -t 300 ralph.wsgi  ... Although I really need this exec in src/   what can I do?
[2016-08-19 14:38:23] <andersonkyle> brylor: use the attribute working_dir to set the directory
[2016-08-19 14:55:03] <brylor> @kanderson450 tried this is what I get: [<-CODE->] I'm assuming no such file or directory is from this ...
[2016-08-19 17:54:08] <LucasHelal> Hey guys, I'm beginner with docker and would like to create a complete dockerfile using django and python 3 .. Could anyone give me directions on how to do this?
[2016-08-19 18:02:05] <ptdave20> LucasHelal:  [<-LINK->] 
[2016-08-19 18:02:16] <ptdave20> They have some examples and instructions
[2016-08-19 18:02:51] <LucasHelal> Thanks i ll read then
[2016-08-19 19:41:22] <LongLiveCHIEF> when I usedocker-composeto pull/run an image as a service across a swarm, what nodes would the image actually be pushed to... just the leaders? or all nodes that task is running on?
[2016-08-19 19:41:35] <LongLiveCHIEF> ...or would it be stored on a swarm volume?
[2016-08-20 04:40:35] <buts101> hrllo
[2016-08-20 07:48:26] <EugenMayer> Hello. I am heaving difficulties to get notifications work since i upgraded from 2.3.1 to 2.5, portus is no longer accepting the notifications. Is there any kind of debug option i can use to see  a bit more? The issue is
[2016-08-20 07:48:32] <EugenMayer> httpSink{https://portus.domain.com/v2/webhooks/events} encountered too many errors, backing off 8/20/2016 9:47:08 AM\x1b[31mERRO\x1b[0m[35242] retryingsink: error writing events: httpSink{https://portus.domain.com/v2/webhooks/events}: error posting: Post https://portus.domain.com/v2/webhooks/events: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers), retrying
[2016-08-20 07:50:27] <EugenMayer> Thats my notification endpoint- name: portus\n  url: https://portus.domain.com/v2/webhooks/events\n  timeout: 5000\n  threshold: 2\n  backoff: 10s
[2016-08-20 08:14:27] <EugenMayer> --
[2016-08-20 08:14:41] <EugenMayer> i created a brief gist example to show of the issue: [<-LINK->] 
[2016-08-20 08:36:11] <EugenMayer> also created [<-ISSUE->] .. probably somebody is able to help out
[2016-08-20 08:41:06] <sundararn_twitter> Dear all when I try to run docker-compose through gir bash I notice that the containers are listed as timeout.
[2016-08-20 08:41:26] <sundararn_twitter> Is this a known issue and do we have a fix?
[2016-08-20 13:09:04] <MaherJendoubi> Hi,  I opened the github repository of docker using Visual Studio Code then I set GOPATH and GOROOT but I still having issues to compile all the project docker!
[2016-08-20 14:43:36] <alexellis> I have a quick query on docker-compose. Is it possible to keep a set of services up but rebuild and redeploy only one of them? I tried stop/build and start but the old image was run again.
[2016-08-20 15:06:09] <EugenMayer> alexellis: use up, not start
[2016-08-20 15:06:16] <EugenMayer> actually never use start :)(
[2016-08-20 19:34:38] <rcmalli> hello everyone, I have got windows10 host and using linux docker. Is there any way to connect my webcam and pass it to the docker?
[2016-08-20 19:35:29] <rcmalli> There are some examples of linux host - linux client
[2016-08-20 19:36:13] <rcmalli> but ofcourse windows drivers dont work like linux so that solutions are useless.
[2016-08-21 01:15:10] <groundnuty> I've setup two nodes in docker-cloud. I did not open any ports on them - just ssh. it all seemed to work well. Now I'm deploying a stack that has 2 services that need to talk to each other. In particular to resolved each other hostanmes. Unfortunately for some reason containers does not understand each other container-names :(
[2016-08-21 01:16:18] <groundnuty> I'ts fedora 23 base image
[2016-08-21 01:41:52] <groundnuty> I have comfirmed that it does work on amazon AWS. on private nodes it does not.
[2016-08-21 01:42:06] <groundnuty> are there any requirments to make it work on private nodes?
[2016-08-21 09:12:13] <EugenMayer> i think that is a questions only channel :)
[2016-08-21 09:12:38] <groundnuty> EugenMayer: well I solved it
[2016-08-21 09:13:37] <EugenMayer> well done
[2016-08-21 09:13:41] <groundnuty> :)
[2016-08-21 09:20:10] <EugenMayer> Hello. I am heaving difficulties to get notifications work since i upgraded from 2.3.1 to 2.5, portus is no longer accepting the notifications. Did the notification payload change for 2.3.1 to 2.4/2.5? [<-LINK->] 
[2016-08-22 07:19:45] <avinash2888> hii all, how can i mount s3 bucket  permanently in docker
[2016-08-22 08:17:40] <alexellis> EugenMayer: 
[2016-08-22 10:30:13] <mgangelov> What commands doesdocker-machineactually execute whendocker-machine create --swarmis called, where can I find such info? I've been looking at the source code, but it isn't really clear to me.
[2016-08-22 18:27:47] <sbromberger> Hi all - anyone care to help a newbie with some Docker guidance? I need to stand up a redis instance. I downloaded the image, but now I need to have a datastore as a docker data volume, and I’m lost. Do I create a Dockerfile for this, or is there some other way to do this?
[2016-08-22 18:28:23] <sbromberger> (or are Dockerfiles just used to create / build custom images?)
[2016-08-22 21:03:07] <RALifeCoach> I am trying to copy files from my local machine to a docker image in the cloud. The copy completes, but the files are older version that what I am expecting.
[2016-08-22 22:59:27] <RALifeCoach> I managed to get the correct files copied, but now it won’t run my application.
[2016-08-23 05:35:17] <nicovicz> maybe docker stop $(docker ps -aq) && docker rm $(docker ps -aq)
[2016-08-23 05:35:29] <nicovicz> then run your image
[2016-08-23 06:18:13] <kschlesselmann> Currently I'm trying to set up my own application container. It's based on the officialphp-fpmwhich runsphp-fpmon startup. Now my application needs to run some setup stuff as well. Can I somehow call the parent's startup command after my stuff or am I now forced to callphp-fpmby myself?
[2016-08-23 08:08:50] <intellix> OSX Docker keeps getting into a state where it's impossible to start up again, if I have too many services
[2016-08-23 08:09:16] <intellix> I'm using docker-compose and have specified restarts. Some services don't work yet, so they keep trying to restart and I think when I restart Docker after it fails, it dies again
[2016-08-23 08:09:39] <intellix> only way around it is to reset to factory settings
[2016-08-23 09:42:34] <marcelmfs> kschlesselmann: elaborateofficial php-fpm'cause I can't seem to find that particular Dockerfile.
[2016-08-23 10:21:32] <kschlesselmann> marcelmfs:  [<-LINK->] 
[2016-08-23 11:53:39] <bazted> Hello guys.
[2016-08-23 11:58:56] <marcelmfs> kschlesselmann: the block starting at [<-LINK->] takes care of the configuration ofphp-fpm, and in order for you to drop your configuration, justADD my-custom.conf  php-fpm.din that Dockerfile, and you should be set.
[2016-08-23 11:59:56] <bazted> I have an issue with startingdocker-compose upon TeamCity. To be exact. I have created compose configuration of TC, TC Agent, MySQL. To TC Agent I am sideloading host docker for DinD. Everything works perfectly. Agent can run successfullydocker run hello-worldpulling images and so force. But issue remains with usingdocker-compose up. It says thatdocker-compose.ymlcant be found those it is in the same folder as PWD and LS -LA shows yml file. What can be wrong. I am trying to fight this whole day and no results.  Logs: [<-LINK->] 
[2016-08-23 12:06:33] <moritzschaefer> What's the point in declaring a volume-mountpoint in a Dockerfile?I can mount volumes to any directory when running the container (docker run -v), wether it's declared as mountpoint or not.
[2016-08-23 12:06:45] <marcelmfs> bazted: I'm using docker-compose from TC but in a docker outside of docker setup (dind is overkill for this), just mount /var/run/docker.sock from host to TC agent and the agent will have access to hosts' docker context.
[2016-08-23 12:07:37] <marcelmfs> moritzschaefer: the point is to have docker volumes persisted on hosts' disk at /var/lib/docker/volumes/<id> path.
[2016-08-23 12:08:19] <marcelmfs> otherwise it will be only available in docker container context, and if you everdocker rmcontainer, you'll loose everything that was there.
[2016-08-23 12:09:45] <bazted> marcelmfs: I am doing it the same. Just mounting docker.sock but still docker-compose is not working
[2016-08-23 12:15:31] <moritzschaefer> marcelmfs: I see. Using VOLUME, docker will automatically create a volume and mount it to the specified path?
[2016-08-23 12:16:23] <moritzschaefer> (except I specify a path or volume using "docker run -v")
[2016-08-23 12:22:30] <marcelmfs> bazted: if you're mounting the named pipe, then you don't need dind, then you'd be already doing docker-outside-of-docker, maybe you'll have to run something likedocker-compose  -H /path/to/socket
[2016-08-23 12:24:11] <marcelmfs> moritzschaefer: if your volume definition ondocker-compose.ymlfile is- /path/to/folder/on/host:/path/to/folder/in/containerthen yes, the volume will be mapped and mounted on the specifiedhost-dirlocation (left hand side of the colon). Otherwise docker engine will create an "anonymous" folder in/var/lib/docker/volumes/<id>.
[2016-08-23 12:24:47] <marcelmfs> docker-compose.ymlor using docker client's-v /host/path:/container/path= they're the same.
[2016-08-23 12:26:35] <marcelmfs> bazted: sorry, I misunderstood your problem. compose isn't finding the yaml file. that's weird.
[2016-08-23 12:27:41] <bazted> The most weird that I can find nothing on net
[2016-08-23 12:30:28] <marcelmfs> that's the problem when using too edgy software, you're one of the first having the problems!
[2016-08-23 12:30:45] <moritzschaefer> thanks for your help@marcelmfs
[2016-08-23 12:31:33] <marcelmfs> so, narrowing the scope of the problem, you're in a dockerized TC agent, running docker-compose from there, checking out a repository that contains a docker-compose.yml file, right?
[2016-08-23 12:32:34] <bazted> yes
[2016-08-23 12:34:44] <marcelmfs> maybe if you explicitly passes the file path as argument to docker-compose?docker-compose -f $(pwd)/docker-compose.yml?
[2016-08-23 12:35:03] <bazted> I will try
[2016-08-23 12:54:06] <bazted> there is another error.IOError: [Errno 2] No such file or directory: '/opt/buildagent/work/7569b02ce56564f3/docker/docker-compose.yml'\n[12:41:54]    Process exited with code 1
[2016-08-23 12:56:29] <kschlesselmann> marcelmfs: I'm not sure if we understand each other. I think my problem is that I useENTRYPOINTmyself and so I disable the original call tophp-fpm. I don't reconfigure php-fpm itself but only want to execute it again.
[2016-08-23 12:56:33] <marcelmfs> That's really weird, are you usingserver-side checkouton VCS' setup oragent-side checkout?
[2016-08-23 12:57:37] <marcelmfs> kschlesselmann: if you're overridingENTRYPOINT, you're swapping the one in theDockerfileby anentrypoint.sh, right?
[2016-08-23 12:58:30] <bazted> As it is default for TC 10: checkout files on agent
[2016-08-23 12:59:17] <marcelmfs> hm, I haven't played with latest TC yet...
[2016-08-23 13:10:51] <marcelmfs> Is there anyone here that can enlighten me about the difference between mount-bind data volume and named-volume data volume? I need to weight in the differences between using a named data volume or a mount-bind data volume if someone needs anamed volume mounted in a specific location. Either using [<-LINK->] plugin or just using a mount-bind volume.
[2016-08-23 13:43:59] <kschlesselmann> marcelmfs: Correct
[2016-08-23 13:46:13] <kschlesselmann> Another question: I created my application container with the base imagephp:7-fpm. Now it contains static frontend sources as well which I'd like to server with nginx. I have a runningdocker-composesetup with all those containers here. Right now my frontend is inserted as a volume pointing to my local workspace. Can I somehow create adocker-composeon my server that mounts the frontend in the nginx from my application's image?
[2016-08-23 13:53:09] <marcelmfs> kschlesselmann: so you just need to add as the last line of your entrypoint scriptexec php-fpm
[2016-08-23 13:54:02] <kschlesselmann> marcelmfs: I did that. I just thought it would be nice to "inherit" the original command since it can change sometime …
[2016-08-23 13:54:09] <yuklia> hi) could you tell me how do you usually solve the permission question inside data container?i think an ordinary case is to get into container and run script for setting permissions.BUT what about set  sticky bit chmod g+s .in image and then after docker run (or docker-compose up my_container) attached files from data container will get right permissions. What do you think about this?
[2016-08-23 13:55:16] <yuklia> Did someone try it?
[2016-08-23 13:56:40] <marcelmfs> kschlesselmann: container images are immutable, if you need to change the entrypoint your only choice is to do it using a script that accepts arguments, then you'll be starting your containers withdocker-compose up my_service argument1 argument2and docker will pass the arguments to your entrypoint script.
[2016-08-23 14:02:22] <kschlesselmann> marcelmfs: OK. Do you have a suggestion for my docker-compose volume setup in my live environment? Basically I'd like to mount/var/wwwfrom my container in the official nginx container. This would be sufficient as a quick fix … I think in the long run the nginx should be a custom image as well hosting only the frontend
[2016-08-23 14:23:15] <marcelmfs> my suggestion would be to package your static files as a data container and ship it anywhere together with nginx's container, then in your compose file you use- volumes_fromdirective to link both containers together and have static files being served by nginx.
[2016-08-23 14:32:49] <kschlesselmann> marcelmfs: Yeah … looks like my nginx needs the php file nevertheless and does not simply forward php requests to the other container … so I'ts proably true that I need an app-data container with php/html und use this in nginx as well as in my app-api container
[2016-08-23 14:39:39] <marcelmfs> yeah, that's how nginx works, it receives the request and forwards the php file to be processed by the php-fpm (localhost:9000), then it answers the request it receives as answer from php-fpm.
[2016-08-23 14:56:25] <kschlesselmann> Yep, going to tweak my compose Setup tomorrow so that I get 3 Images for data, api and Frontend. The Last two have to use your volume_from magic then (dont't know that yet)
[2016-08-23 14:57:36] <kschlesselmann> marcelmfs: This way I can use the data Image on my prod Server and just use a local volume in my IDE compose, or?
[2016-08-23 16:01:26] <marcelmfs> yes, that's correct
[2016-08-23 17:54:17] <vito-c> how can you run a docker container that starts a repl
[2016-08-23 17:54:35] <vito-c> also how do you set the workdir in docker-compose
[2016-08-23 18:15:51] <kschlesselmann> marcelmfs: Hm, I think I got it working so far. Now all files in my php container belong to root though and php-fpm runs as www-data. Could you point in the right direction to solve those permission problem when a normal user wants write access on a data containers volume?
[2016-08-23 22:47:37] <rinetd> when i run a mysql docker container,  in  container env the  '/var/lib/mysql' mysql:mysql ,but in the host '/var/lib/mysql' 999:docker .so i must chomd xx7 other user can access it. how to find a way to chown mysql:mysql also use it in the host?
[2016-08-24 00:43:32] <jeff-h> i’ve changed a volume mount in mydocker-compose.yml— can someone tell me how to make that happen in the running container?
[2016-08-24 07:26:44] <dangxunb> Hello. I run my docker container with Rancher. What is the easiest way to get full application's log? Rancher's view log screen only show the most recent log lines
[2016-08-24 08:06:20] <marcelmfs> kschlesselmann: uid's can be synchronized between hosts' and container, or you can add users from Dockerfile's USER directive [<-LINK->] 
[2016-08-24 08:20:14] <yuklia> jeff-h: look at this article [<-LINK->] here was discribed an approach how to do it with nacked docker not docker-compose
[2016-08-24 09:03:35] <marcelmfs> vito-c: docker run -it --rm ubuntuthis is the most simple repl you can have
[2016-08-24 09:07:36] <marcelmfs> vito-c: you can't set workdir on compose, it's a Dockerfile directive [<-LINK->] 
[2016-08-24 12:28:09] <vasily-kirichenko> hi, guys. Are services supposed to be discoverable in a Swarm?
[2016-08-24 12:29:49] <vasily-kirichenko> I created a network, then two services in it. Single instances of the services are running on different nodes. Now I enter one of the containers and try toping <another service name>, which fails.
[2016-08-24 12:32:49] <vasily-kirichenko> I scaled the one of the services so that it runs on all the nodes. Now ping works (where containers of the both services are on the same node).
[2016-08-24 12:51:39] <marcelmfs> how did you created the services in the swarm? are they attached to the network?
[2016-08-24 12:56:52] <vasily-kirichenko> marcelmfs: see [<-ISSUE->] 
[2016-08-24 12:57:22] <vasily-kirichenko> yes, they are both attached to sameoverlaynetwork
[2016-08-24 13:23:50] <marcelmfs> what happens if you try to ping with the FQDN? likeservice-name.net2?
[2016-08-24 13:30:19] <vasily-kirichenko> from service-1 to service-2 to: [<-CODE->] the other way around: [<-CODE->] 
[2016-08-24 13:40:20] <marcelmfs> ok, are those two nodes in the same network? Is it a VPC?
[2016-08-24 13:41:43] <vasily-kirichenko> yes, they both in same network, they are bare metal servers.
[2016-08-24 13:42:06] <marcelmfs> it's weird that your report on swarmkit [<-ISSUE->] does not show the nodes as in:
[2016-08-24 13:42:37] <marcelmfs>  [<-LINK->] 
[2016-08-24 13:44:20] <vasily-kirichenko> wow. yes, it's very strange
[2016-08-24 13:44:33] <vasily-kirichenko> it outputs the same (no nodes) being launched on all nodes
[2016-08-24 13:45:03] <marcelmfs> it looks like something is not correctly configured in your setup
[2016-08-24 13:46:01] <vasily-kirichenko> but what exactly? I justdocker swarm initand then join other nodes to the swarm.
[2016-08-24 13:49:31] <marcelmfs> I'm not actively playing with swarm yet... or overlay network for that matter, I'm mostly using containers for continuous build/test/deployment and they don't actually need to be managed by swarm (yet), they're just a bunch of microservices that binds to the loopback interface and that are served by a reverse-proxy... I still want to have some control over how my network is managed, and I don't even know if I'd ever use swarm.
[2016-08-24 13:51:33] <vasily-kirichenko> without Swarm you need etcd/consul + registrator + nginx + consul template to achieve the same result that Swarm offers for free.
[2016-08-24 13:53:55] <marcelmfs> Or not, or my containers just encapsulates any app from any dev and I'm binding them to loopback like old reversed proxied services always do.
[2016-08-24 13:54:59] <marcelmfs> Like I've said, containers are good because it eases the hassle of having an homogeneous way of building/testing/integrating/deploying. But swarm? meh
[2016-08-24 13:55:31] <marcelmfs> if the load becomes a problem, I can easily scale with docker-compose.
[2016-08-24 13:56:39] <marcelmfs> well, YMMV, my context is very narrow.
[2016-08-24 13:58:20] <vasily-kirichenko> so you run your containers yourself or with docker-compose, exposing fixed ports to hosts. How do they talk to each other then? Via well known ports? How do you load balance if number of containers > 1?
[2016-08-24 14:04:59] <marcelmfs> well, I'm using Mashape's Kong as API router, every service registers itself and creates a dynamic API upstream. All comms are going through kong's nginx.
[2016-08-24 14:06:05] <marcelmfs>  [<-LINK->] 
[2016-08-24 14:41:58] <jpapejr> Greetings, docker denizens: I am trying to stand up an insecure registry in my swarm but I’m having a problem accessing the registrion on the published port 5000 on 3 of the 4 swarm nodes. The only node I’m able to successfully curl against is the one running the registry container. Ideas?
[2016-08-24 15:38:18] <marcelmfs> the only that comes to my mind is that your swarm is not running correctly the registry container in the other nodes
[2016-08-24 16:11:40] <vasily-kirichenko> jpapejr: add --insecure-registry xxxx:5000 to docker args on all your nodes.
[2016-08-24 16:12:18] <jpapejr> vasily-kirichenko: how would that affect my ability to curl port 500 on each machine?
[2016-08-24 16:12:26] <jpapejr> It wasn’t set on the node that worked.
[2016-08-24 16:13:45] <jpapejr> Nevertheless, I’ll give it a try
[2016-08-24 16:16:12] <vasily-kirichenko> what is the error?
[2016-08-24 16:16:25] <vasily-kirichenko> "CLI: Control your Kong cluster from the command line just like Neo in The Matrix." :)
[2016-08-24 16:32:05] <marcelmfs> oh, I haven't saw this error yet? which version? latest?
[2016-08-24 16:35:10] <marcelmfs> Ah, it's only on their readme
[2016-08-24 18:00:38] <vasily-kirichenko> marcelmfs: How Kong is in compare to Kubernates? The latter seems to be the most mature, feature rich and still free orchestration solution.
[2016-08-24 18:02:22] <vasily-kirichenko> (I've never even seen Kubernates in action, planning to try it)
[2016-08-24 18:34:00] <roby2001>  [<-LINK->] 
[2016-08-24 18:34:01] <roby2001> I'm trying to make a docker image following the tutorial. I made a docker file but then how do I build it ? Above is what I tried.
[2016-08-24 18:45:31] <roby2001> nevermind, figured out I have to run the build on the folder not on the file :)
[2016-08-24 22:32:57] <karneaud> Hey guys
[2016-08-24 22:33:16] <karneaud> I'm new to docker and just tried to install the toolbox for OSX Yosemite
[2016-08-24 22:34:36] <karneaud> When I tried to run the docker-machine everything worked good but installing images took up a lot of disk space and in  most cases I could not install and run them. I'm trying to use a network mounted folder as the default docker installation location
[2016-08-24 22:35:11] <karneaud> has anyone ever successfully installed docker in a directory OTHER than the default ~/.docker directory?
[2016-08-24 22:35:24] <karneaud> can one install and run docker on a network folder?
[2016-08-25 02:35:30] <nlhkh> is it possible to ssh into a container in swarm without having to connect to the Docker server in a specific host?
[2016-08-25 07:46:38] <marcelmfs> vasily-kirichenko: They're not comparable, Kong's just a web server with dynamic upstream aka dynamic API router/gateway. Kubernetes/Swarm are container orchestrators, where Kubernetes... enough of me trying to explain the differences, there you have it [<-LINK->] 
[2016-08-25 07:48:24] <marcelmfs> nlhkh: if your container have sshd running and your Dockerfile exposes that sshd's network port outside docker network, then you justssh -p <exposed port> $(docker-machine ip)and you'll be directly connected to the container's sshd.
[2016-08-25 08:04:11] <nlhkh> marcelmfs: I think that will ssh me into the Docker host
[2016-08-25 08:05:23] <marcelmfs> you're free to think whatever you wish! ;)
[2016-08-25 08:05:32] <nlhkh> I am thinking aboutexec -itinto a running container
[2016-08-25 08:06:17] <marcelmfs> you asked if it is possible to ssh into a container
[2016-08-25 08:06:25] <nlhkh> without having toeval $(docker-machine env name)
[2016-08-25 08:06:31] <marcelmfs> it is, given the assumptions I've pointed out
[2016-08-25 08:07:26] <marcelmfs> here I've googled for you: [<-LINK->] 
[2016-08-25 08:11:16] <marcelmfs> now, if you meantdocker exec -it container_name bashwithout using docker-machine to set env vars to $DOCKER_HOST, then, no, it's not possible.
[2016-08-25 08:15:16] <nlhkh> ah thanks for confirming :)
[2016-08-25 08:15:43] <nlhkh> I was exploring the capability of the new docker swarm
[2016-08-25 08:22:52] <vasily-kirichenko> The sad thing is that Rancher just works
[2016-08-25 08:23:01] <vasily-kirichenko> really really works
[2016-08-25 08:24:00] <vasily-kirichenko> but it has two points of failure: a rancher server and, separetly, a mysql server
[2016-08-25 08:24:33] <vasily-kirichenko> so to achieve HA, one have to deploy a mysql cluster + rancher server cluster
[2016-08-25 08:24:45] <vasily-kirichenko> it's annoying
[2016-08-25 08:25:45] <marcelmfs> the good thing is that once you've build docker containers to achieve HA for those resources, they're easily scalable with docker.
[2016-08-25 08:26:24] <marcelmfs> but that is also true with AMI and ELB
[2016-08-25 08:26:45] <vasily-kirichenko> rancher and mysql (1 + 1 on same host) is already running in docker, so...
[2016-08-25 08:27:29] <vasily-kirichenko> AMI and ELB? sorry, I'm a newbie
[2016-08-25 08:27:57] <marcelmfs> those are AWS lingo...
[2016-08-25 08:28:11] <vasily-kirichenko> ah. I'm on bare metal
[2016-08-25 08:29:01] <marcelmfs> well, I wish I'd still be working on real servers.
[2016-08-25 08:31:09] <vasily-kirichenko> yeah, the scenario when Swarm failed (services don't see each other being running on separate nodes) works OK on Rancher. Plus a beautiful UI :)
[2016-08-25 13:40:43] <kschlesselmann> How are you supposed to use a HTTP proxy that requires authentication during docker build? https://docs.docker.com/engine/reference/builder/#/arg statesWarning: It is not recommended to use build-time variables for passing secrets like github keys, user credentials etc. Build-time variable values are visible to any user of the image with the docker history command.So my prxoxy credentials would visible to everyone if I push the image to our registry …
[2016-08-25 13:49:15] <karneaud> HELLO ALL
[2016-08-25 13:49:23] <karneaud> can one install docker on a network drive?
[2016-08-25 13:51:47] <karneaud> I'shaving this kind of problem [<-LINK->] 
[2016-08-25 13:51:51] <karneaud> *I'm
[2016-08-25 13:53:44] <kschlesselmann>  [<-CODE->] 
[2016-08-25 14:03:00] <karneaud> I also get that@kschlesselmann
[2016-08-25 14:03:05] <karneaud> what did you do?
[2016-08-25 14:21:50] <marcelmfs>  [<-LINK->] 
[2016-08-25 14:21:57] <marcelmfs> take a look at HTTP_PROXY
[2016-08-25 14:24:13] <marcelmfs> I'm not sure about authentication though
[2016-08-25 14:25:04] <vasily-kirichenko> current status: managed to make NTLM auth get working on Apache on centos \\m/
[2016-08-25 14:25:11] <vasily-kirichenko> it took a whole day
[2016-08-25 14:25:32] <b3h3rkz> Hi@everyone
[2016-08-25 14:25:38] <b3h3rkz> New to docker
[2016-08-25 14:26:07] <b3h3rkz> So I have docker-machine setup and a django app already running in the machine
[2016-08-25 14:26:44] <marcelmfs> kschlesselmann:  [<-LINK->] 
[2016-08-25 14:26:44] <b3h3rkz> I got the ip of the machine as 192.168.99.100
[2016-08-25 14:27:15] <b3h3rkz> I am not able to connect when I visit the ip on the browser
[2016-08-25 14:27:20] <marcelmfs> vasily-kirichenko: thanks for sharing... YAY?
[2016-08-25 14:28:11] <b3h3rkz> marcelmfs: please can you help?
[2016-08-25 14:28:24] <vasily-kirichenko> I'm a linux newbie, so I'm very happy it finally works :) will write an ansible playbook for it tomorrow. I suspect it will take another day :)
[2016-08-25 14:28:54] <kschlesselmann> marcelmfs: This proxy isn't availableinthe Image duringdocker buildthough, is it?
[2016-08-25 14:29:36] <marcelmfs> it's docker engine (daemon-wide) setup
[2016-08-25 14:30:09] <malinich> b3h3rkz: to see your django app you need expose this portsdjango by default use 8000 port
[2016-08-25 14:30:37] <b3h3rkz> so like 192.168.99.100:8000?
[2016-08-25 14:30:39] <malinich> i mean docker run -p 80:8000 django-app
[2016-08-25 14:30:45] <b3h3rkz> ok
[2016-08-25 14:30:50] <b3h3rkz> let me try
[2016-08-25 14:30:54] <malinich> ok
[2016-08-25 14:32:47] <malinich> or inside your dockerfileconfigure nginx to see 8000 portdjango runserver 8000
[2016-08-25 14:33:26] <malinich> your nginx will listen 80 port and upstream your request to 8000
[2016-08-25 14:33:47] <b3h3rkz> I am not using nginx at the moment
[2016-08-25 14:33:58] <b3h3rkz> it's just a simple setup for practice
[2016-08-25 14:34:15] <b3h3rkz> the name of the project in this case is trial
[2016-08-25 14:34:25] <marcelmfs>  [<-LINK->] 
[2016-08-25 14:35:15] <marcelmfs> when people have chatter/gitter they stop using google to solve their problems or what?
[2016-08-25 14:35:37] <malinich> @marcelmfsexellent, not be angry =)
[2016-08-25 14:36:24] <malinich> excellent for the article
[2016-08-25 14:36:41] <marcelmfs> I understand some newbie questions, but others are just lazyness IMO
[2016-08-25 14:36:46] <marcelmfs> :D happy to help, though
[2016-08-25 14:37:38] <b3h3rkz> lol@marcelmfsno  trouble
[2016-08-25 14:37:55] <b3h3rkz> I have been on the docs and running that  particular example
[2016-08-25 14:38:23] <b3h3rkz> I am just giving it a try to see what it's like
[2016-08-25 14:38:27] <b3h3rkz> been using vagrant
[2016-08-25 14:39:49] <b3h3rkz> At this point, your Django app should be running at port 8000 on your Docker host. If you are using a Docker Machine VM, you can use the docker-machine ip MACHINE_NAME to get the IP address.
[2016-08-25 14:40:13] <b3h3rkz> so I checked the ip of the machine
[2016-08-25 14:40:41] <malinich>  [<-CODE->] 
[2016-08-25 14:41:03] <b3h3rkz> 192.168.99.100
[2016-08-25 14:41:19] <b3h3rkz> Yea I did that already@malinich
[2016-08-25 14:41:32] <malinich> how result?
[2016-08-25 14:42:02] <b3h3rkz> 192.168.99.100
[2016-08-25 14:42:27] <malinich> ) bad
[2016-08-25 14:42:57] <b3h3rkz> I meant I got that when I randocker-machine ls
[2016-08-25 14:43:40] <b3h3rkz> tcp://192.168.99.100:2376
[2016-08-25 14:47:31] <malinich>  [<-CODE->] after you  use your terminal to build and run container onto you remote mashinebut, all command dependent of your dockerfilesee may be it help [<-LINK->] 
[2016-08-25 14:47:46] <b3h3rkz> 192.168.99.100is the ip I got
[2016-08-25 14:48:00] <b3h3rkz> ok@malinich
[2016-08-25 14:50:22] <malinich> and for docker-machinei use this article for config my remote server [<-LINK->] 
[2016-08-25 14:51:27] <b3h3rkz> Nice one thanks!
[2016-08-25 14:51:32] <b3h3rkz> Bookmarked it
[2016-08-25 14:55:23] <hholst80> Generic is that "on metal" docker engine without virtualization?
[2016-08-25 14:57:19] <malinich> generic it common name for use ssh driver instead aws or digital ocean
[2016-08-25 14:57:49] <malinich> using docker-machine Generic SSH Driver
[2016-08-25 14:59:40] <hholst80> OK then I think I understand what it is. Thanks
[2016-08-25 15:00:15] <kschlesselmann> marcelmfs: I know. But this does mean I don't have this proxy inside my Dockerfiles, do I?
[2016-08-25 15:00:44] <kschlesselmann> I need to RUN curl/apt behind a proxy
[2016-08-25 16:04:46] <marcelmfs> you'll have to sort things out in Dockerfile the same way you'd do in a linux environment...
[2016-08-25 19:24:07] <karneaud> hey guys trying to understand the ways of docker and I'm having a problem installing and interacting with the docker default server [<-LINK->] 
[2016-08-25 19:24:40] <karneaud> I am trying to install docker images in a folder OTHER than the default ~/.docker directory
[2016-08-25 19:24:50] <karneaud> I keep running into SSH permission errors
[2016-08-25 19:25:09] <karneaud> any hints as to accomplishing docker on network drives?
[2016-08-25 20:35:44] <karneaud> when kinematic errors out because ofssh permissions being too open....what does that mean? Is this something on the docker side or my local machine side?
[2016-08-25 21:09:01] <karneaud> ugh man i can't get this right man
[2016-08-25 21:09:48] <karneaud> why does it give me [<-LINK->] 
[2016-08-25 21:09:54] <karneaud> is it my permissions?
[2016-08-25 21:10:00] <karneaud> my network permissions?
[2016-08-26 05:58:30] <kschlesselmann> marcelmfs: I know. But I cannot "bake" my credentials to the image which will happen if I use them in ARG/ENV/RUN, wouldn\'t it? I just have to need them during build time but after that they have to be completely removed.
[2016-08-26 07:59:55] <marcelmfs> kschlesselmann: no, you can use--build-arg FOO=BARand inside DockerfileARG FOOand you can also make sure that is set byRUN : ${FOO?"FOO must be set"}
[2016-08-26 08:14:26] <marcelmfs> karneaud: the problem is Virtualbox
[2016-08-26 08:14:48] <marcelmfs> you should try with a real linux docker
[2016-08-26 08:15:27] <marcelmfs> virtualbox introduces it's own set of problems, that problem isn't related to docker.
[2016-08-26 08:16:27] <marcelmfs> Or, if you want to use virtualbox's docker toolbox, don't do anything too fancy like NFS or SAMBA shares to hold docker container images
[2016-08-26 08:17:41] <marcelmfs> Even with docker beta, there are some problems with sharing folders between workstation and the instance running docker. Be it xhyve, virtualbox, I've ran into so many problems and the solution is to do it as native as possible.
[2016-08-26 08:37:34] <marcelmfs> FYI I have docker running on a vm and the graph folder is being persisted to a NAS drive. The drive is mounted as a samba share. It works.
[2016-08-26 09:04:13] <marcelmfs> Any compose experts around?@channel?
[2016-08-26 09:52:55] <kschlesselmann> marcelmfs: But according do the doc I shouldnotuseARGfor credentials!
[2016-08-26 10:28:09] <hholst80> interesting problem how to pass credentials without exposing them in one way or another
[2016-08-26 11:05:40] <vasily-kirichenko> hey, guys. Any ideas how to sniff ntlm auth? I tried Fiddler on windows and it broke ntlm, the browser started show auth dialog.
[2016-08-26 11:06:29] <vasily-kirichenko> What I want to get from sniffing is where user name is in http headers after successful ntlm.
[2016-08-26 11:25:30] <marcelmfs> I don't think NTLM is HTTP, or is it?
[2016-08-26 11:25:48] <marcelmfs> are you proxying NTLM requests via HTTP proxy?
[2016-08-26 11:25:54] <marcelmfs> maybe what you need is a socks proxy
[2016-08-26 11:26:24] <vasily-kirichenko> no. I use Apache for ntlm auth.
[2016-08-26 11:26:31] <vasily-kirichenko> and reverse proxy
[2016-08-26 11:26:37] <vasily-kirichenko> it works
[2016-08-26 11:27:04] <vasily-kirichenko> now I need to extract the user name in my service
[2016-08-26 11:27:18] <vasily-kirichenko> to make authorization
[2016-08-26 11:27:29] <vasily-kirichenko> (that's how I see the process)
[2016-08-26 11:43:21] <kschlesselmann> hholst80: Yeah … actually I cannot find any official resource with a solution for this problem … how are you expected to use credentials duringdocker build…
[2016-08-26 11:53:54] <marcelmfs> just don't use credentials inside Dockerfile, create a script that downloads your artifacts before building the container, and instead of downloading them, you just ADD them to the context.
[2016-08-26 11:54:14] <marcelmfs> *instead of downloading them from within Dockerfile
[2016-08-26 11:55:17] <kschlesselmann> This doesn't fit that nice in mydocker-composesetup though :-(
[2016-08-26 11:56:05] <hholst80> marcelmfs: thats how I am doing with my nginx ssl certs right now. good enough for my needs I thought.
[2016-08-26 12:00:55] <marcelmfs> well, I have some layers of wrappers around docker build and around docker compose. So that everything I cannot do from the native tools I've done with shell scripting.
[2016-08-26 12:01:48] <marcelmfs> but the things are getting so convoluted that I'm thinking about refactoring everything using the official docker-py
[2016-08-26 12:03:49] <kschlesselmann> marcelmfs: Well I certainly cannot do that withapt…
[2016-08-26 12:05:24] <marcelmfs> are you sure you can't apt-get download from and external script and then add the deb packages inside the container and then just dpkg -i?
[2016-08-26 12:06:15] <marcelmfs> almost nothing is impossible nowadays
[2016-08-26 12:29:22] <rexromae_twitter> any of you used graphite in docker?
[2016-08-26 12:29:42] <rexromae_twitter> I cannot make it work.. I’m using this image [<-LINK->] Anyone has some experience with it?
[2016-08-26 12:30:00] <vasily-kirichenko> rexromae_twitter: I run it with no problems
[2016-08-26 12:55:31] <kschlesselmann> marcelmfs: I don't haveapton my system.
[2016-08-26 13:07:05] <marcelmfs> well,docker run -it --rm -v /tmp:/var/cache/apt/archives ubuntu apt-get download package
[2016-08-26 13:08:30] <malinich> interesting trick
[2016-08-26 13:08:50] <marcelmfs>  [<-CODE->] 
[2016-08-26 13:12:09] <marcelmfs> kschlesselmann: not having a resource in ANY system compatible with docker isn't an excuse anymore. ;)
[2016-08-26 13:18:03] <kschlesselmann> marcelmfs: Yeah … and what about the deps of package X? The only solution would be to use another container with the same base image to download the deps, extract them and use them in the final container viaCOPY… but to be honest … that's no real solution. Docker should have some build time credential support in the end.
[2016-08-26 13:19:03] <rexromae_twitter> vasily-kirichenko: it was the way I was running it, the port forwarding was not working, now I managed to make it work..
[2016-08-26 13:19:05] <rexromae_twitter> thanks
[2016-08-26 14:01:14] <rexromae_twitter> Hi@vasily-kirichenkocan you tell me please how to check graphite logs from the docker image?
[2016-08-26 14:01:36] <rexromae_twitter> I m trying to access the log file of the app running inside the docker container. What’s the best way to do this guys?
[2016-08-26 14:03:46] <malinich> may be it fit? [<-CODE->] 
[2016-08-26 14:04:01] <rexromae_twitter> let me try :)
[2016-08-26 14:05:05] <rexromae_twitter> what is-dit? I cannot find it in thedocker run —help
[2016-08-26 14:06:45] <malinich>  [<-LINK->] 
[2016-08-26 14:07:18] <malinich> i typo,. instead -h use -v
[2016-08-26 14:08:16] <rexromae_twitter> do I need to mount or do something on my mac as well?
[2016-08-26 14:08:33] <rexromae_twitter> or it will be done by docker? I tried with-vwith no luck. I will try again.
[2016-08-26 14:08:50] <malinich> wait
[2016-08-26 14:12:01] <malinich> it excerpt from bookHandling Applications that Log to FileIf you have an application that logs to file rather than STDOUT/STDERR, you still have a couple of options available. If you are already using the Docker API to do your logging (e.g., with the Logspout container), the simplest solution is to run a process (normally tail -F ) that just prints the file to STDOUT. An elegant way to do this that maintains the single process to a container philosophy is to use a second container that mounts the log files with --volumes-from . For example, if we have a container called “tolog” that declares a volume at /var/log , we can use the following: [<-CODE->] If you don’t want to take this approach, you can also mount the logs to a known directory on the host and run a collector such as fluentd on them.
[2016-08-26 14:13:34] <rexromae_twitter> thanks@malinich
[2016-08-26 14:13:52] <malinich> Docker Logging with syslogAssuming your Docker host has syslog support, you can use the syslog driver, which will send the container logs to syslog on the host. This is perhaps best explained with an example: [<-CODE->] 
[2016-08-26 14:14:22] <malinich>  [<-CODE->] 
[2016-08-26 14:14:37] <aios> malinich: че ты гонишь на самом то деле.
[2016-08-26 14:15:01] <malinich> =) да я выдержку из книги скинул проше и понятнее =)
[2016-08-26 14:15:19] <malinich> я честно даже не вникал =)
[2016-08-26 14:15:31] <aios> ясно. русским не спамим.
[2016-08-26 14:15:40] <malinich> =)
[2016-08-26 14:16:54] <rexromae_twitter> spasiba :P
[2016-08-26 14:17:54] <malinich> =) good =)see more into "Using Docker Adrian Mouat"
[2016-08-26 14:19:19] <rexromae_twitter> great
[2016-08-27 08:35:43] <mateothegreat> Looking to bring on some docker guys for our SOA deployments (put a bullet in the monolith!) .. full-time, remote, flexible.. pm me if you got the bandwidth to hit the ground running.
[2016-08-27 12:29:13] <ismarkunc> hi :D  It’s possible setup docker with 4 subdomains and how ?
[2016-08-27 12:38:43] <ismarkunc> im’ running 2 container with apache (wordpress backend + laravel frontend), another two with nginx (static + api).It looks like:cms.mydomain.com  - wordpress cms /login => apache for dinamic contentmydomain.com  main frontend site => laravel  + nginxapi.mydomain.com  for API  =>  apachestatic.mydomain for static files(images) => nginx
[2016-08-27 17:06:27] <kmarilleau> N'y o.rx.r
[2016-08-27 17:06:38] <kmarilleau> Je w t o
[2016-08-27 17:07:26] <kmarilleau> U NY
[2016-08-27 17:07:39] <kmarilleau> Merci de CB r
[2016-08-27 18:50:23] <AjeetK> Can anyone help me to find a resource for deploying java application with ant and resin using docker?
[2016-08-28 06:48:02] <vito-c> is there a way to have a container in docker-compose file inherit another container's env?
[2016-08-28 06:49:41] <yuklia> it seems that you can't inherit containers's env BUT you can link containers and all env from first wi'll be shown in second
[2016-08-28 06:50:56] <vito-c>  [<-CODE->] 
[2016-08-28 06:51:25] <vito-c> I would like to do that to keep my config dry
[2016-08-28 06:51:45] <vito-c> cont.two has all of the same envs as cont.one except it is a different image
[2016-08-28 06:51:50] <vito-c> etc
[2016-08-28 06:52:47] <yuklia> i got it. did conteiners linked to each other ?
[2016-08-28 06:53:40] <yuklia>  [<-CODE->] 
[2016-08-28 06:54:17] <vito-c> i can add links
[2016-08-28 06:54:38] <vito-c> but will that make cont.one have the same environment? i thought links was more for networking
[2016-08-28 06:54:58] <yuklia> and for env as well
[2016-08-28 06:55:02] <yuklia> check it)
[2016-08-28 06:56:28] <vito-c> but then it will run the linked container
[2016-08-28 06:56:33] <vito-c> which is not what I want
[2016-08-28 06:56:56] <vito-c> i don't want it to run cont.one when I dodocker-compose run cont.two
[2016-08-28 06:56:59] <vito-c> or up
[2016-08-28 06:57:19] <vito-c> essentially the only thing to change is the image
[2016-08-28 06:57:27] <vito-c> and the run commands
[2016-08-28 06:57:37] <vito-c> but they both use the same port
[2016-08-28 06:57:45] <vito-c> one is for development the other is a compiled version
[2016-08-28 06:59:06] <vito-c> i guess i can use an env file
[2016-08-28 06:59:54] <yuklia> create some bash script that adds common envs and add to both images. in the second image create additional envs (as you need)
[2016-08-28 07:00:28] <yuklia> through command RUN
[2016-08-28 07:00:31] <vito-c> yah was hoping for something oob (out of the box)
[2016-08-28 07:01:29] <yuklia> sorry i don't get it
[2016-08-28 21:13:49] <slushnys> Hello people, I need help as a beginner. Couple questions:
[2016-08-28 21:13:55] <slushnys> wd
[2016-08-28 21:16:03] <slushnys> when i build an image, it already runs on linux and other systems because docker uses linux kernel right? Anyone from here has been using django python with docker?
[2016-08-29 00:36:41] <b-rays> zslusnys: , I  have not used django python. You can use Docker with the linux kernal. What's the issue you're having?
[2016-08-29 00:40:05] <b-rays> Quick question ---docker-compose upworks in thedefaultdocker-machine, but I cannot get it to work with EC2.Docker-compose psin the EC2 machine shows the same output as in the default machine. Is there something I need to tweak in mycomposefile to make this happen, or does anyone have any other suggestions?
[2016-08-29 00:43:24] <b-rays> I suppose the one difference would beKitematicmapsdocker-composeto a random port on my localhost. I would not be able to find that random port on theaws-machine, but it's the client image is mapped to 80. I would imagine it should still show up.
[2016-08-29 00:58:38] <b-rays> Anyone have any ideas or suggestions???
[2016-08-29 01:36:16] <b-rays> The question has a $20 bounty sent via paypal
[2016-08-29 06:56:31] <_skmax_twitter> Hello. I've got 2 website on port 80 inside separate docker containers. Could I make them work on addresses like site-a.dev and site-b.dev without  proxy?
[2016-08-29 06:57:50] <malinich> nginx?
[2016-08-29 06:58:10] <malinich> not help to you?
[2016-08-29 06:58:25] <_skmax_twitter> apache, but I could install nginx
[2016-08-29 06:59:23] <yuklia> _skmax_twitter: why don't you expose sites on different ports ?  (i mean on host machine)
[2016-08-29 07:01:38] <malinich> configure nginx as resolver for you,server {listen       80;server_name  site-a.dev;location / {proxy_pass [<-LINK->] ;}}server {listen       80;server_name  site-b.dev;location / {proxy_pass [<-LINK->] ;}}
[2016-08-29 07:01:46] <_skmax_twitter> yuklia: because I want to run site by addresses like site-a.dev and site-b.dev instead of localhost:5555 and something like this. And in future I want use the same images in production machine. There will be the same two sites in production server.
[2016-08-29 07:02:25] <malinich> i hope is help,
[2016-08-29 07:03:47] <_skmax_twitter> malinich: thanks. But I knew about this solution. I want solution without proxy. I think proxy could decrease performance
[2016-08-29 07:04:24] <_skmax_twitter> Could Docker Embedded DNS server help for me?
[2016-08-29 07:07:49] <malinich> may be if your container will be named  as site-a.dev and exposed 80 port - it could help
[2016-08-29 07:08:47] <malinich> but  i don't know how dns of your host will resolve
[2016-08-29 07:09:31] <malinich> interesting
[2016-08-29 07:13:42] <_skmax_twitter> malinich: yeap, I can't find solution. But what do you think, is it very decrease performance if use nginx proxy ? If I would use proxy, there was 2 webservers work. First webserver works in host machine and second inside container
[2016-08-29 07:17:38] <malinich> i think performance of your proxy it is not worth to see as problem ,  because backend response have more time
[2016-08-29 07:20:02] <malinich> it my opinion and I could be wrong
[2016-08-29 07:23:35] <_skmax_twitter> malinich: thank you
[2016-08-29 07:29:00] <stephanlinke> hey everyone :) probably not the first one to ask, but is there a bug in kitematic for windows that doesn't let you add ports to a docker container? the (+) sign is there, but it doesn't work :/
[2016-08-29 07:31:12] <yuklia> why don't you report an issue?)
[2016-08-29 07:31:28] <stephanlinke> cause I'm not sure if it's just me being stupid :D
[2016-08-29 07:33:13] <stephanlinke> oh okay - didn't know that there's a dedicated room :)
[2016-08-29 07:34:43] <slushnys> Ive built a django app having docker-compose which consists out of a web app. When I do docker-compose up it sets up the webserver, however when I try executing docker run username/repo the container i get no files neither I get my server running. Anyone could tell me whys that?
[2016-08-29 08:23:31] <yuklia> hello @vito-c  after googling finally i found solution for  this case [<-CODE->]  [<-CODE->] 
[2016-08-29 08:27:12] <marcelmfs> yuklia: @vito-cit's possible to have 'templates' of common environment and anything by using theextendsdirective of compose.
[2016-08-29 08:28:21] <marcelmfs> by using extends you can define, for instance, templates forservice-bd-psql,service-bd-mongo,service-rabbitmq-4g, and all sorts of templates for your services.
[2016-08-29 08:28:57] <yuklia> it is great! thanks@marcelmfs
[2016-08-29 11:18:30] <etolbakov> Hi@/all, requesting your help !!!I\'d like to use docker-compose push feature, but I\'ve failed to find any useful info.My scenario is pretty simple: there is docker-compose.yml file which is used for building 2 images(app and db).Then I\'d like to push them to my insecure registry which is configured on another machine.The next step will be the "pull" and then "docker-compose up".Could you please give me a hint of pushing to registry with docker-compose ?Thank you!
[2016-08-29 11:46:23] <sebglon> I search help to Peer Review and help me on PR [<-ISSUE->] to add Apapche Flume Avro Logging driver
[2016-08-29 11:49:31] <sebglon> I have an error on CheckwindowsRS1but i don't understand why
[2016-08-29 11:51:07] <stephanlinke> sebglon: I'm not sure if this is the right channel for apache flume related stuff, as it is the docker channel, not apache ... :)
[2016-08-29 11:52:26] <kschlesselmann> Doesdocker buildtake the.gitignoreinto account? I have a rule like!var/bootstrap.php.cachein my.dockerignorebut the file is just not in the image. It's ignored by the.gitignorethough …
[2016-08-29 11:52:59] <sebglon> yes i have create à Pull request to add Loggind driver on Docker engine to push log to Flume
[2016-08-29 12:03:30] <kschlesselmann> nervermind … forgot to delete the volume :-S
[2016-08-29 12:09:41] <b-rays> I have nodeJS and socketio running on two separate ports in the same container. With mynginx config, I'm able to connect to both the socket connection and my nodejs api + auth endpoints. I would imagine I would be able to send and receive messages in the chat room, but it does not work. Any suggestions?
[2016-08-29 13:40:45] <slushnys> Im using docker-compose to create a web service, it runs locally with docker-compose. What do I need to do so it would run on "docker run" command on local and other machines because now nothing happens when executed..
[2016-08-29 13:42:26] <yuklia> show medocker-compose ps
[2016-08-29 13:44:56] <slushnys> Its running there
[2016-08-29 13:49:39] <slushnys> dg01   python manage.py runserver ...   Up      0.0.0.0:8002->8002/tcp
[2016-08-29 13:50:20] <slushnys> 2567eaf0114a        src_web             "python manage.py run"   2 minutes ago       Up 2 minutes        0.0.0.0:8002->8002/tcp   dg01
[2016-08-29 13:50:27] <slushnys> this is the docker ps
[2016-08-29 13:51:06] <yuklia> so what do you expect ?
[2016-08-29 13:52:11] <yuklia> could you describe the problem more properly?
[2016-08-29 13:54:24] <slushnys> this is when I run docker-compose up within the project. I try running the container that I build withdocker build -tand push to its repository, pulling it on other server and doingdocker run 'username/reponame'it just runs the python2 and does not run any web server. I'm probably not getting something..
[2016-08-29 13:56:05] <yuklia> why don't you use docker-compose.  i think it's more convenient way for container managenent
[2016-08-29 13:56:45] <marcelmfs> what do you have as entrypoint or command in your docker-compose.yml? you'll have to pointdocker runclient to use--entrypoint
[2016-08-29 13:58:18] <slushnys> thats my whole compose.yml ```version: '2'services:  web:    build: .    container_name: dg01    command: python manage.py runserver 0.0.0.0:8002    volumes: [<-CODE->] ```im planning to add nginx soon as I figure out how to run it on other machines.
[2016-08-29 14:00:32] <slushnys> I'm getting the feeling that I should somehow run the docker-compose up from Dockerfile, but not sure it's a good idea.
[2016-08-29 14:01:25] <yuklia> you can usebuildfor this purpose
[2016-08-29 14:02:36] <flajann2> Anyone using both Docker Compose and Ansible together?
[2016-08-29 14:03:59] <marcelmfs> docker run username/container python manage.py runserver 0.0.0.0:8002
[2016-08-29 14:04:02] <marcelmfs> there you go
[2016-08-29 14:07:43] <slushnys> yuklia: I build using thedocker-compose buildbut then when it builds the file I was expecting for docker-compose run automatically.
[2016-08-29 14:08:32] <slushnys> marcelmfs: well... thank you so much kind sir - that worked. However, docker-compose.yml file isn
[2016-08-29 14:10:46] <slushnys> isn't used then, how to use that automatically then with everything I set up? Is there any good tutorial on it? I went through most tutorials about setting up django, all of them use docker-compose but they don't show how to run it. Or is it the commanddocker run username/container docker-compose up?
[2016-08-29 14:12:09] <kschlesselmann> Hm … could someone point me in the right direction how I should handle permissions with data containers? Currently I'm building 3 containers. 1 that contains my PHP source (justCOPYof my built resources topath/) and one that runs php-fpm. The php container uses www-data though to execute my source and the original data container packages it as root. My compose uses then
[2016-08-29 14:12:46] <kschlesselmann>  [<-CODE->] in the php container
[2016-08-29 14:13:24] <kschlesselmann> In the end I don't have permission to create new file there … what's the way to go to handle things like that?
[2016-08-29 14:17:05] <yuklia> set right permissions throughexec. create user the same as local and add it to www-data group
[2016-08-29 14:17:41] <marcelmfs> either you change the user of the app container to run as root, or you'll have to synch UID's between host and container they must match.
[2016-08-29 14:18:05] <marcelmfs> or there is something about named data volumes, I'm not sure...
[2016-08-29 14:18:29] <marcelmfs> zslusnys: you cannot rundocker run foo/bar docker-compose up
[2016-08-29 14:23:55] <slushnys> marcelmfs: how does docker-compose run from the docker-compose.yml file with all those services then?
[2016-08-29 14:24:36] <andersonkyle> zslusnys: docker-compose up
[2016-08-29 14:29:06] <kschlesselmann> yuklia: I cannot change the permissions since in my Dev Setup i Mount my local workspace in the container
[2016-08-29 14:30:26] <yuklia> permissions on source code?
[2016-08-29 14:30:52] <slushnys>  [<-CODE->] What I imagine then is that I would need to have a command of running docker-compose within Dockerfile, however docker is not installed within docker container itself.. it all confuses me :D
[2016-08-29 14:31:22] <yuklia> kschlesselmann: so do you want to have different permissions for shared data ??
[2016-08-29 14:33:01] <andersonkyle> zslusnys: Dockerfile's need to be self-contained and indepdently runnable.  You don't put orchestration logic within the Dockerfile.  A docker-compose file is simply a faster way of starting a bunch of related containers.  If your team needs this docker-compose file, then you'll have to share it with them, ideally within version control.  Make sense?
[2016-08-29 14:34:22] <kschlesselmann> I'm trying to achieve: 3 Containers, ine with php/ja stuff, One with nginx obe with php. Both Mount the data If the First in Produktion. Nginx ro and php rw. N I tried to do sonething like RUN chmod -R o=rwX /my/source in the data Container because I thought I don't care which User finally writes to it. But it seems that that does nit work ...
[2016-08-29 14:34:49] <kschlesselmann> In my Dev Setup there is no data Container but a direct volume to my workspace
[2016-08-29 14:39:06] <kschlesselmann> Sorry for the Bad spelling ... Dann Mobile here
[2016-08-29 21:16:55] <etsuo> hi all… is it not possible to point a shared volume to a symbolic link on the host operating system? I’m trying to use let’s encrypt for my certs while setting up registry, but it’s not recognizing the host files… whene I do andocker exec -it <container> cat /certs/cert.pemit actually says that no such file exists even though I can see the file when I rundocker exec -it <container> ls /certs
[2016-08-29 21:24:15] <etsuo> oooo it’s not resolving the symlink… when Ils -lait shows the actual symlink for the file in the host, not the contiainer… weird.
[2016-08-29 22:01:25] <qballer> does anybody know how to load an in memory volume ?
[2016-08-29 23:52:18] <CNSKnight> Image > Container > What's Installed <- is there a command for that?
[2016-08-30 01:19:22] <aios> qballer: just use tmpfs
[2016-08-30 02:07:29] <deanrather> Hey all! Any way to know which file(s) caused a Dockerfile COPY statement to invalidate the cache?
[2016-08-30 02:18:03] <deanrather> Also Stackoverflow'd for your sweet sweet rep [<-LINK->] 
[2016-08-30 02:30:20] <aios> deanrather: so what a problem with that?
[2016-08-30 02:30:33] <aios> you can use any software to look file timestamps
[2016-08-30 02:30:50] <aios> If file timestamps changed - docker will see it and invalidate cache
[2016-08-30 02:31:26] <deanrather> The problem is that I'm getting rebuilds and not knowing why :(
[2016-08-30 02:32:06] <aios> look for docker ignore file
[2016-08-30 02:32:27] <aios> in here you can set folders or files what are not changed many times
[2016-08-30 02:32:57] <deanrather> Yeah, I've got a.dockerignorefile. And I've added.gitto it.
[2016-08-30 02:32:59] <aios> just like logs, caches, uploads, settings or something
[2016-08-30 03:03:23] <timfallmk> deanrather: that sounds like an edge case between copy and add
[2016-08-30 03:03:53] <timfallmk> You can get the engine to dump the hash, but that's not really helpful in your case
[2016-08-30 03:04:38] <timfallmk> What's your copy line?
[2016-08-30 03:14:14] <aios> timfallmk: suggest i think he just get a problem with named volumes.
[2016-08-30 03:15:13] <timfallmk> During a build?
[2016-08-30 03:15:20] <timfallmk> Um ok
[2016-08-30 03:16:46] <aios> timfallmk: not - during deploying
[2016-08-30 03:38:42] <deanrather> COPY . /app/
[2016-08-30 03:43:34] <deanrather> You know what... I think I'm just confused about Volumes :(
[2016-08-30 03:46:17] <deanrather>  [<-CODE->]  [<-CODE->] 
[2016-08-30 03:46:40] <deanrather> Why on earth is docker-compose's volume assuming I want to mount a host dir?? my head...
[2016-08-30 03:46:51] <deanrather> (this is a docker-compose v1 file)
[2016-08-30 03:48:37] <deanrather> ah. I forgot that I was mounting my host's./:/app/.. so I guess that's why.
[2016-08-30 03:48:54] <deanrather> so the lesson here is that.dockerignoredoesn't prevent the container from creating new dirs on the host
[2016-08-30 05:37:17] <aios> deanrather: booring
[2016-08-30 05:37:32] <aios> deanrather: just simplify your working process
[2016-08-30 05:37:56] <aios> deanrather: you need to install node_modules one more time on develop machine
[2016-08-30 05:38:07] <aios> and result copy to image
[2016-08-30 05:39:03] <aios> deanrather: npm install && npm update && docker build -t someregistry/someimage:latest .
[2016-08-30 05:39:30] <aios> Just dont share volumes by dockerfile when you deploying on the prod
[2016-08-30 05:39:41] <aios> and with docker-compose
[2016-08-30 05:39:52] <aios> it makes sense on dev-machine
[2016-08-30 05:46:51] <deanrather> I don't think that makes sense at all... the developer's machine might have a different architecture to the container..
[2016-08-30 05:47:28] <deanrather> and it results in a case where developer X makes an image and it works because they had node vX installed. and then developer Y makes an image and it doesn't work because they had node vY installed...
[2016-08-30 05:50:16] <deanrather> (I'm new to Docker so please somebody tell me if I've got it all wrong!)
[2016-08-30 05:50:18] <aios> deanrather: why doesnt work? in container you have node vX and all used you container has vX. I dont say about all working process on host machine - i telling you about install/build/test project inside container
[2016-08-30 05:54:10] <aios> deanrather: Read the documentation and learn to understand the technology in simple things. And when you will have more knowledge of what to ask a question to which you can answer "Yes" or "No" - return to this room. (sorry for bad english)
[2016-08-30 05:58:58] <deanrather> Haha, that's ok. Sorry - I understand my question wasn't very simple.
[2016-08-30 05:59:09] <deanrather> Above, where you said:npm install && npm update && docker build -t someregistry/someimage:latest .Did you mean inside the container?
[2016-08-30 11:47:33] <kschlesselmann> Is it possible te map users in docker-compose? I have a container that runs aswww-dataand I'd like to map this user to my local user so the container can edit files in my workspace as 'me'
[2016-08-30 11:50:04] <EugenMayer> kschlesselmann: no, its not. You can use [<-LINK->] and define your mapping - thus not using native shares, but sync-like shares. If you are under OSX, that will be a massive performance boost anyway
[2016-08-30 11:50:07] <EugenMayer> (in addition)
[2016-08-30 11:53:11] <kschlesselmann> I'm not on OSX and I'd lile to use simple volumes here. Looks like I have to use plain permissions then …
[2016-08-30 13:24:41] <renothing> anybody  know how to change default registry when docker pull ?I set mirror in /etc/docker/daemon.json and it doesn't work at all, it always pull from [<-LINK->] 
[2016-08-30 13:25:01] <renothing> this is my docker info: [<-CODE->] 
[2016-08-30 16:08:27] <avinash2888> hii  all, can i change my username in docker, if yes how can i do it...thanks
[2016-08-31 06:31:22] <_skmax_twitter> Hello. How could I connect to mysql in my host machine inside container?
[2016-08-31 10:20:53] <kailashyogeshwar85> Hi i am downloading the node binary from node site and then moving that archive to separate folder and then i want to extract file using  tar xvf but i gives no such file found errorBelow is my Dockerfile [<-CODE->]  [<-CODE->] 
[2016-08-31 10:24:02] <kailashyogeshwar85> what can be the solution for it ?
[2016-08-31 10:27:03] <kschlesselmann> avinash2888: USER?
[2016-08-31 10:27:40] <kschlesselmann> _skmax_twitter: Just connect to the IP of your host in the docker bridge network
[2016-08-31 10:29:10] <kschlesselmann> kailashyogeshwar85: The error could be that you forgot to install thexz-utilsor whatever it's called
[2016-08-31 10:33:12] <kailashyogeshwar85> i have tar already in place for extracting
[2016-08-31 10:35:37] <kschlesselmann> Yeah … but tar needs to handle xz
[2016-08-31 10:38:26] <kailashyogeshwar85>  [<-CODE->] It works when i create a archive inside the container and then extract it using tar
[2016-08-31 10:42:22] <kailashyogeshwar85> kschlesselmann: thanks that did work to extract the files (xz-utils) but i have no idea why it worked in above case
[2016-08-31 12:49:03] <_skmax_twitter> @kschlesselmann@_skmax_twitter Just connect to the IP of your host in the docker bridge networkHow? It could be changed. And docker doesn't provide alias like dockerhost
[2016-08-31 13:02:54] <kschlesselmann> You could use --net=Host
[2016-08-31 13:04:09] <_skmax_twitter> Yes, but I don't want this. Because in this case all will be able from outside
[2016-08-31 13:06:34] <marcelmfs> usedocker run -p 3306:3306 -v /var/lib/mysql:/var/lib/mysql mysql
[2016-08-31 13:06:47] <marcelmfs> then mysql -h localhost -p 3306 mydb
[2016-08-31 13:23:04] <_skmax_twitter> marcelmfs: it's not very good way. Because mysql data folder can be in other path. Or user could run app in windows
[2016-08-31 13:24:35] <marcelmfs> so just omit-v /local_host/folder:/docker_container/folder
[2016-08-31 13:25:29] <marcelmfs> in any case, you're looking for-p 3306:3306<- this is how you expose a port in the container onto your localhost network environment.
[2016-08-31 13:25:57] <marcelmfs> you can use-p 33066:3306and thenmysql -h localhost -p 33066from you localhost.
[2016-08-31 13:27:50] <_skmax_twitter> No, I need connect from container to host machine. Is it the same?
[2016-08-31 13:28:38] <_skmax_twitter> Could I run inside container mysql -p 33066 and connect to host machine mysql?
[2016-08-31 15:01:23] <marcelmfs> you have mysqld running on your host machine and need the application from the container to connect to it?
[2016-08-31 15:01:29] <marcelmfs> hm
[2016-08-31 15:02:27] <marcelmfs> can you check if mysqld is listening on0.0.0.0:3306? Then you might be able to connect from the container.
[2016-08-31 19:28:15] <RedDevilHat> Hello guys
[2016-08-31 19:28:23] <RedDevilHat> can you help me?
[2016-08-31 19:36:51] <RedDevilHat> i have this config [<-CODE->] with this he seeC:\\Users\\admin\\Documents\\GitHubbut mustC:\\Users\\admin\\Documents\\GitHub\\test
[2016-09-01 02:44:05] <timfallmk> RedDevilHat: you can specify a direct path for a volume if you like
[2016-09-01 09:41:01] <MOZGIII> Hi, when I use docker swarm mode (1.12+), how do I connect two containers together?
[2016-09-01 10:08:02] <RedDevilHat> timfallmk: hello, i think i stuped
[2016-09-01 10:08:16] <RedDevilHat> this config must work with docker-machine
[2016-09-01 10:08:29] <RedDevilHat> and he work on linux host
[2016-09-01 10:08:53] <RedDevilHat> but if i start docker machine on windows 10 with Hyper-V
[2016-09-01 10:09:02] <RedDevilHat> my PC shutdown
[2016-09-01 10:09:27] <RedDevilHat> if i disable Hyper-V pc work, but docker no
[2016-09-01 10:09:47] <RedDevilHat> if i start virtualbox
[2016-09-01 10:10:30] <RedDevilHat> and try start ANY virtual system
[2016-09-01 10:10:37] <RedDevilHat> with Hyper-V
[2016-09-01 10:10:47] <RedDevilHat> my pc shutdown and restart
[2016-09-01 10:11:15] <RedDevilHat> but if i disable Hyper-V virtual system start
[2016-09-01 10:11:22] <RedDevilHat> but docker no
[2016-09-01 10:11:42] <RedDevilHat> how i can fix this problem with Virtual box?
[2016-09-01 14:51:16] <avinash2888> getting the folloeing error when trying to load awslog driverdocker: Error response from daemon: Failedto initialize logging driver: Invalid signatureException: Signature expired: 20160901T120741Z is now earlier than 20160901T141126Z (20160901T141626Z - 5 min.)    status code: 400, request id: ab7a55ef-704e-11e6-acab-2d1346dfe018.
[2016-09-01 14:51:41] <avinash2888> how can i resolve that ?
[2016-09-01 15:32:27] <InfoSec812> I'm having issues trying to work with a non-root user inside of my containers... [<-CODE->] Anyone have suggestions on how to resolve this?
[2016-09-01 15:33:15] <InfoSec812> Additional details: Docker host is CentOS7 with SELinux not enforcing... Docker version is 1.12.1
[2016-09-01 18:18:56] <InfoSec812> Found the problem... In our Dockerfile for several of our containers we doADD docker /, and the ADD command changes the permissions of the directories. Adding aRUN chmod 755 / /usr /usr/bin /etcafter the ADD resolved the problem...
[2016-09-01 19:18:09] <vin67> Hi I’m new to Docker & Compose. I’ve created a Docker.yml file with nginx, fpm & mysql. I can execute php commands but I can’t execute mysqlicommands. phpinfo.php shows '--enable-mysqlnd’  and it appears to be installed. Configuration File (php.ini) Path /usr/local/etc/php is doesn’t have any php.ini… i’m not sure what to do to get this mysqlcommands to work. Appreciate some help!
[2016-09-01 23:52:27] <deanrather> you either want aDockerfileor adocker-compose.yml. Not aDocker.yml...
[2016-09-02 01:48:37] <buts101> is docker swarm 'distributed computing'?
[2016-09-02 05:28:14] <saikrishna321> Hi Folks, i’m new to docker.. i’m really liking it .. wanted to findout is there a way were we can stop all the dependent containers
[2016-09-02 05:28:14] <saikrishna321> ?
[2016-09-02 10:14:16] <MOZGIII> Hi, does docker store--build-argsused atdocker buildcall somewhere in the image? Is it safe to put private keys in build args?
[2016-09-02 11:07:45] <mkumatag> MOZGIII: man pages says - this is not meant for passing secret values.
[2016-09-02 11:24:02] <MOZGIII> mkumatag: Oh, thanks
[2016-09-03 08:45:28] <buts101> heello?
[2016-09-03 12:24:58] <lwojciechowski> Is it possible with docker swarm to bundle two containers together? For example nginx + django app because they connect through socket. Or should I put them into one container?
[2016-09-04 03:16:31] <buts101> is docker swarm can be used as 'cloud computing'?
[2016-09-04 08:43:26] <vasily-kirichenko> lwojciechowski: have you seen this [<-LINK->] 
[2016-09-04 08:44:54] <vasily-kirichenko> I'm not sure it's possible to enforce swarm to place each container of one service alongside with a container of another service tho.
[2016-09-04 08:46:13] <vasily-kirichenko> however, why do you want it? Services can talk to each other by name, if they are in the same swarm network, so I would not worry about physical location of each container in a swarm
[2016-09-05 00:53:59] <vin67> deanrather: Hi Dean - Thanks for replying… that was a early morning typo in my request. I have a Dockerfile and  a docker-compose.yml. So question stands…. Anyone with an running example template that I can look at. The step thats stumping me is adding I think the mysql extension… I think I have to create a Dockerfile to handle it but want to check if thats the case but maybe that can be handled in the docker-compose.yml?
[2016-09-05 08:01:20] <anextro> So I am running docker on windows :) Hello-world
[2016-09-05 08:39:41] <akessner> anextro: Windows10 pro?
[2016-09-05 08:39:54] <anextro> yes
[2016-09-05 08:39:56] <anextro> hyper-v
[2016-09-05 08:40:06] <akessner> Does anyone know what I'd need locally to properly test docker swarm?
[2016-09-05 08:40:15] <akessner> Does it work well?
[2016-09-05 08:40:28] <anextro> well so far, everything looks nice.
[2016-09-05 08:40:42] <akessner> How much Harddrive space is it taking up?
[2016-09-05 08:41:05] <anextro> 2GB
[2016-09-05 08:41:12] <anextro> 2 cpus
[2016-09-05 08:41:16] <akessner> I happen to be looking to get a new computer and using docker in windows10 so I'm asking silly questions :)
[2016-09-05 08:41:45] <anextro> No they seem like perfectly legitimate questions to me
[2016-09-05 08:42:33] <akessner> 2gb of ram or hd?
[2016-09-05 08:43:09] <anextro> 2gb ram, I made my C: drive available to docker.
[2016-09-05 08:43:19] <anextro> so i think it uses memory from my C: drive
[2016-09-05 08:43:36] <akessner> how big is your c:\\?
[2016-09-05 08:43:55] <anextro> 400gb
[2016-09-05 08:44:27] <akessner> Are you running anything like Intellij while the docker is running?
[2016-09-05 08:44:54] <anextro> yes  like my eclipse is up and running
[2016-09-05 08:46:06] <akessner> It's running at its usual performance?
[2016-09-05 08:46:20] <anextro> for now, yes.
[2016-09-05 08:46:35] <anextro> but will be watching it incase of degraded performance
[2016-09-05 08:46:47] <akessner> do something crazy like refactor the logging function :P
[2016-09-05 08:46:59] <anextro> hahahaha
[2016-09-05 08:47:32] <anextro> it seems like we can work together on this. I want to know more about Docker internals, my team will be using it in production
[2016-09-05 08:51:29] <akessner> happy to help however I can, but I'm new to docker as well.
[2016-09-05 08:53:06] <anextro> I have installed ubuntu image. I want to install a docker image on the ubuntu image and then use that as my play ground
[2016-09-05 09:02:17] <akessner> You did it as a VM or a dual boot?
[2016-09-05 09:02:38] <akessner> installing docker from within ubuntu is really easy
[2016-09-05 09:02:44] <akessner> just use apt-get
[2016-09-05 09:02:57] <anextro> when the ubuntu is also an image?
[2016-09-05 09:03:46] <akessner> if you can ssh/bash into it yeah
[2016-09-05 09:04:35] <anextro> I want to install centos and work with that instead since that is what we use for our linux server
[2016-09-05 09:05:17] <akessner> Same difference, except I don't know centos :)  you can put it into virtualbox and use it like normal.
[2016-09-05 09:05:37] <anextro> I guess it will work out fine then :)
[2016-09-05 09:07:12] <akessner> Can you let me know your your computer's performance is after you install the centos virtual box?
[2016-09-05 09:07:47] <anextro> you mean after i have run it?
[2016-09-05 09:07:54] <akessner> yeah
[2016-09-05 09:08:02] <anextro> okay, just running it now.
[2016-09-05 09:08:07] <anextro> will monitor and let you know
[2016-09-05 09:12:47] <akessner> Also, what computer are you using? :P
[2016-09-05 09:42:12] <anextro> I am using Thinkpad T460p
[2016-09-05 11:24:24] <akessner> All is going well?
[2016-09-05 16:33:42] <anextro> yes
[2016-09-05 16:33:49] <anextro> achieved something today
[2016-09-06 02:34:04] <kfrz> Hello, I'm using docker-compose to run a simple pair of machines for postgres and rails -- I can build the images fine but when they start up I get permissions errors - rails can't access logs or tmp it seems. I can login via docker run -i -t appimagename_web
[2016-09-06 02:34:21] <kfrz> and then run ls -al and see the permissions - they all belong to the app user
[2016-09-06 02:36:05] <kfrz> but no dice. Really bumping my head on this one, I have read through the dockerbook, I'm on v1.12
[2016-09-06 02:41:13] <BretFisher> kfrz: can you post your dockerfiles and compose file?
[2016-09-06 02:43:03] <kfrz>  [<-LINK->] 
[2016-09-06 02:43:36] <kfrz> BretFisher: Thanks -- any glaringly obvious advice accepted with much thanks
[2016-09-06 04:17:19] <kfrz> Removing the user-addition stuff makes it work like a charm but I am thinking about how I should deploy
[2016-09-06 08:20:34] <mjbright> I want to run multiple docker engines on one host, with version 12.1.   I intend to do this using the static binaries available on the release page.  (I've no idea how to launch the multiple daemons which exist now).   Any pointers to how to do this?
[2016-09-06 11:01:10] <gallexme> the question is why
[2016-09-06 11:15:17] <anextro> Yeah that was the first question that came to mind, but it seems interesting to give the answer and then ask why later :)
[2016-09-06 12:32:45] <gallexme> how about putting docker inside docker?
[2016-09-06 12:32:58] <gallexme> 1 docker container for each docker engine
[2016-09-06 12:33:28] <gallexme> but i really dont think u get any benefits from it
[2016-09-06 16:04:37] <BretFisher> mjbright: I don\'t think multiple docker engines running on one host is a workable scenerio, but "docker in docker" is a thing: [<-LINK->] 
[2016-09-06 16:12:26] <BretFisher> kfrz: I bet it works when you take out the compose volumes line in yaml
[2016-09-06 16:13:58] <BretFisher> Problem is, you're doing all these permissions and file stuff on $REPO_DIR in image, then in compose you've bind-mounted a host dir over top of that location at runtime, which will supersede any changes you made to $REPO_DIR
[2016-09-06 16:14:37] <BretFisher> a bind-mount replaces that location and all sub files/dirs
[2016-09-06 16:19:04] <BretFisher> I know it's what you want to do local dev, but by running your Dockerfile stuff as non-root, you're making it harder for bind-mounts to work... because... security is hard. Struggle is real: [<-ISSUE->] 
[2016-09-06 23:12:22] <nicosuave> Anyone seeno space left on deviceissues with Docker for mac? Shouldn't the image auto expand?
[2016-09-06 23:12:45] <timothyjlaurent> if only, lol
[2016-09-06 23:13:30] <timothyjlaurent> Some use cases over here necessitate very large containers -- impossible on docker for osx
[2016-09-06 23:14:45] <nicosuave> bah
[2016-09-06 23:15:43] <timothyjlaurent> There is a way to manually make your disk bigger with some qemu command if you have time to troll the forums to find it.
[2016-09-06 23:17:53] <nicosuave> Rad, hunting that down now. Thanks@timothyjlaurent
[2016-09-07 08:40:39] <mac2000> Hi guys, wondering if somebody can answer dummy question, I have windows cmd file that starts container with -it and --rm flags but after closing cmd by pressing on X on upper right corner - container stays running
[2016-09-07 10:15:42] <timfallmk> mac2000: the -i and -t flags make the container run interactively and allocate a tty, respectively. The --rm flag removes the containerafterit stops.
[2016-09-07 10:16:16] <timfallmk> If you're simply closing the window without terminating the command, it's still running.
[2016-09-07 10:17:55] <timfallmk> If you want the container to stop and then be removed, you'll need to terminate your command, in this case your session. Ctrl+C would do it on Linux. I believe it's the same for Windows.
[2016-09-07 10:21:52] <mac2000> timfallmk: thank you for clarifying things, I do understand what and why is happening, just curios if there is workaround, this is happening with docker but not with other executables so should be possible somehow
[2016-09-07 10:22:56] <timfallmk> I'm not sure what you mean by workaround. That's the expected behavior
[2016-09-07 10:25:39] <timfallmk> I think your confusion may come from the fact that you're not running a binary in the window
[2016-09-07 10:26:30] <timfallmk> The docker client communicates with the docker daemon, which manages the container. By closing the window, you're just closing your connection to it
[2016-09-07 10:29:19] <mac2000> Its is a good pointHere is sample:native.cmd [<-CODE->] docker.cmd [<-CODE->] after closing first window I do kill both cmd and redis-cli in second case I do close cmd and docker.exe that is just a connection to container (closest thing I think about is tmux/screen)
[2016-09-07 10:36:26] <timfallmk> Yeah. That's a way to think about it
[2016-09-07 15:40:00] <mjbright> gallexme: @anextro@BretFisherThanks for your replies ... in fact I consider D-in-D not a usable scenario (too many warning in JPetazzoni's blog post on the subject) so I was wondering about the possibilities of having multiple docker engines appearing as multiples machines (phys/virtual ...) for a lab.  I hacked something together yesterday evening based on this post [<-LINK->] and using the static docker binaries [<-LINK->] .  I was able to start several docker engines, run containers in those engines.  Of course this means that each engine keeps it's own copy of image layers but this is still better than VMs (well cowardly as I am I'm running all that in 1 VM - better than 4 VMs).  I still need to see how usable this is for a lab ... don't want to confuse people, just hide the fact that these aren't real machines.   Will update  ...
[2016-09-07 17:58:30] <BretFisher> That sounds so much harder then 4 vm's but cool. Looking forward to you positing on how to do that for labs :)
[2016-09-07 19:04:47] <mjbright> BretFisher: for sure ... as it happens part of the motivation was avoid having a cpu going to 100 degrees C (ok, since then I see how to cap VMs with Vagrant/VBox but it's by VM which is really naff).  Anyway, it'll be fun trying ... and the answer to the problem just has to be docker ;-) wish me luck ;-)
[2016-09-08 02:49:52] <InfoSec812> Does anyone know if there are any plans to implement the ability to search (docker search) based on image labels in the future?
[2016-09-08 02:52:38] <InfoSec812> For example, if I build a containerdocker build -t tag --label "version=1.2.3"and publish it to my private repo, I would love to be able to search/pull based on those labels likedocker search tag --filter \'label=version=1.2.3\'
[2016-09-08 08:55:29] <doublebyte1> Hi everyone
[2016-09-08 08:56:12] <doublebyte1> I've submitted a PR for an official docker image, and it is failing the integration tests :-(
[2016-09-08 08:56:21] <doublebyte1> could somebody help me to understand why?
[2016-09-08 08:56:22] <doublebyte1>  [<-LINK->] 
[2016-09-08 21:00:58] <kalicki> Hey... Does anyone know this style of PaaS (netlify.com) but supported the docker???!!!I want to focus on the code and automate cloud =)
[2016-09-09 08:31:51] <sdikby> Hi all, [<-CODE->] i even tried to build an SSH connection with my host but without success.It would be very nice if someone put me on the right way:1- if trying to build an SSH connection is the right solution for the main problem and how ?2- how can i build it with airflow in a container and knowing that i tried to do it it with SSHExecuteOperator
[2016-09-09 09:10:31] <anextro> Hi guys
[2016-09-09 09:10:53] <anextro> So I have a docker instance on a linux box
[2016-09-09 09:11:19] <anextro> I want to be able to set the host ip as an environment variable from my docker file
[2016-09-09 09:11:44] <anextro> Note that its not the ip of the docker container i want, rather the ip of the host machine
[2016-09-09 09:16:14] <poliveira89>  [<-CODE->] I'm on OSX with docker-mac 1.12.x
[2016-09-09 10:57:40] <code-ph0y> Hi, Can I ask is docker free to use?
[2016-09-09 10:57:52] <code-ph0y> open-source?
[2016-09-09 10:59:44] <code-ph0y> I have heard it's open source but when I go to the docker site its saying you have to pay for a licence?
[2016-09-09 11:00:04] <landsman> code-ph0y: if you have it on own server, yes it is.
[2016-09-09 11:00:44] <landsman> code-ph0y: docker site offer "hosting" with docker
[2016-09-09 11:02:10] <code-ph0y> ahhh! so it would be free if I installed it on a server in an educational institution?
[2016-09-09 11:02:39] <landsman> code-ph0y: for example, sure ..
[2016-09-09 11:03:20] <code-ph0y> perfect! thanks michal!
[2016-09-09 11:03:44] <code-ph0y> now I just have to figure out how lol
[2016-09-09 14:56:39] <code-ph0y> Hi Guys,
[2016-09-09 14:59:04] <code-ph0y> Am I right in saying that you can run operating systems vm ware on docker containers?
[2016-09-09 15:22:04] <anextro> I want to be able to set the host ip as an environment variable from my docker fileNote that its not the ip of the docker container i want, rather the ip of the host machine
[2016-09-11 16:05:27] <ugurcanlacin> Hi everybody,I have a question which annoys me a lot. I am senior student and want to create a microservice based web application, and use Docker for it.1-  For production, I plan to use Docker Swarm. Should I seperate production and development Docker tool ? (in production Swarm, in development compose)2- If I work with Docker Compose in a single server, there is no problem about microservice communication. I can send requests to local ports , and get response. However, if my application runs on more than one server,  how can I send request from one microservice to another while there are multiple servers which have different ips.PS:  Thanks for any keyword, link, advice, etc.
[2016-09-11 17:44:26] <galvesribeiro> Hello guys!
[2016-09-11 17:45:08] <galvesribeiro> I'm seeing tons of nuget packages that claim to talk with docker APIs like this one [<-LINK->] and I wonder which one of those is the official or at least the recomended way to do that
[2016-09-11 17:46:06] <galvesribeiro> our idea at project Orleans is to initially make our unit tests to spin up some docker containers and then tear it down when the tests are done hence why we need to interact with the APIs.
[2016-09-11 17:46:19] <galvesribeiro> appreciate  anyone's input on that
[2016-09-11 17:46:22] <galvesribeiro> Thanks
[2016-09-11 20:45:39] <galvesribeiro> ok, looks like this is the Microsoft official nuget
[2016-09-11 20:46:08] <galvesribeiro> but I'm unable todocker pull microsoft/windowsservercore
[2016-09-11 20:46:22] <galvesribeiro>  [<-CODE->] 
[2016-09-12 08:27:15] <intellix> docker psnever seems to work in OSX for 1.12.0-a, I have no idea what's going on. Diagnosis always says the same. Restart does nothing and only fix is to Restore Factory Defaults
[2016-09-12 08:28:11] <intellix> not using it too frequently, but it seems every time I come to use it, it's dead
[2016-09-12 08:28:58] <marcelmfs> update to latest 1.12.1-beta25
[2016-09-12 08:30:54] <intellix> will give it a try, thanks :) any idea what caused it? (out of curiosity)
[2016-09-12 08:33:02] <intellix> same story there in 1.12.1-beta25 :) Guess I have to restore to factory as the VM must be dead
[2016-09-12 08:39:43] <marcelmfs> which osx version?
[2016-09-12 08:43:08] <intellix> El Capitino
[2016-09-12 08:43:29] <intellix> think I've resorted to factory defaults at least 5 times now :) My guess is that a particular container causes the VM to eat up all resources and then it loses contact. Not sure if Docker protects against such a thing, despite containing
[2016-09-12 08:45:54] <marcelmfs> probably
[2016-09-12 08:46:22] <marcelmfs> which containers are you using? you have to be careful with [<-LINK->] 
[2016-09-12 08:47:04] <marcelmfs>  [<-LINK->] 
[2016-09-12 08:47:27] <marcelmfs>  [<-LINK->] 
[2016-09-12 08:48:14] <marcelmfs>  [<-LINK->] 
[2016-09-12 08:48:48] <marcelmfs> I personally use [<-LINK->] as tiny init process handler
[2016-09-12 08:50:07] <marcelmfs> 1)screen -AmdS docker ~/Library/Containers/com.docker.docker/Data/com.docker.driver.amd64-linux/tty ; screen -S docker -p 0 -X stuff
[2016-09-12 08:50:14] <marcelmfs> 2)screen -r docker
[2016-09-12 08:50:24] <marcelmfs> 3)screen -S docker -X quit
[2016-09-12 08:50:43] <marcelmfs> 1 - create a screen session to xhyve's docker vm
[2016-09-12 08:50:49] <marcelmfs> 2 - attach to it
[2016-09-12 08:50:55] <marcelmfs> 3 - kill it
[2016-09-12 08:51:47] <marcelmfs> this gives you the ability to troubleshoot you misbehaving containers in the alpine VM that docker for mac uses.
[2016-09-12 10:37:08] <groundnuty> hey, how do I use docker docker-cloud clis as an organization, not y private self
[2016-09-12 12:04:53] <atrauzzi> Does docker compose allow for a way to define all my infrastructure in one file, and then plug into those containers from other, unrelated compose files?
[2016-09-12 12:05:22] <marcelmfs> yes, if you use the same-p flag
[2016-09-12 12:05:53] <marcelmfs> which in turn defines the name of the network, iirc
[2016-09-12 12:10:54] <atrauzzi> Network?
[2016-09-12 12:11:22] <marcelmfs> if you have 2 docker-compose files, one with:
[2016-09-12 12:13:17] <marcelmfs>  [<-CODE->] and another with: [<-CODE->]  [<-CODE->] 
[2016-09-12 12:13:42] <marcelmfs> without -p flag, you can't
[2016-09-12 12:13:48] <atrauzzi> Hmm, looks like I can define networks in the compose files too!
[2016-09-12 12:13:54] <marcelmfs> or that!
[2016-09-12 12:14:23] <atrauzzi> Awesome
[2016-09-12 12:20:32] <hholst80> mm you can always use "external" networks if the -p flags does not fit your use case
[2016-09-12 12:21:02] <hholst80> but I like the -p switch. I always use it nowdays
[2016-09-12 12:38:05] <atrauzzi> I'm looking to set up a nice local development environment, so the fewer commands, the better.
[2016-09-12 14:31:06] <hholst80> is this merged into docker-compose? and if so, in what version?
[2016-09-12 14:31:07] <hholst80>  [<-LINK->] 
[2016-09-12 17:00:04] <galvesribeiro> guys, anyone has an idea on what could be this error?
[2016-09-12 17:00:26] <galvesribeiro>  [<-CODE->] I'm on windows 10 anniversary edition with latest Pro insider preview build
[2016-09-12 17:55:40] <kalicki> Does anyone have experience in [<-LINK->] 
[2016-09-13 10:24:21] <BrunoMVPCosta> hi
[2016-09-13 10:25:21] <BrunoMVPCosta> I'm trying to configure nginx with docker compose, but nginx can't resolve my container :S
[2016-09-13 11:34:31] <dizorg> what do you mean by "resolve"?
[2016-09-13 12:48:49] <scheung38> Hi a complete newbie here... If i use docker to make an image for client, and it is not pushed to hub.docker, then how to allow client to access code within their company firewall, but still remaining private so that no one from outside the company can access it for security reasons.
[2016-09-13 12:51:15] <scheung38> I am using MUP from kadirahq/mup for MeteorJS deployment
[2016-09-13 12:51:30] <scheung38> Meteor v1.4.1.1
[2016-09-13 14:47:41] <marcelmfs> scheung38: you want to export your container to a file and give to someone else?
[2016-09-13 14:47:49] <marcelmfs> or you want someone to access your app?
[2016-09-13 14:49:58] <scheung38> You know when you have a docker container that is accessible from anywhere. I would like to deploy docker to company provided VM, and they also have private IP address to port forward for  security I guess
[2016-09-13 14:50:36] <scheung38> marcelmfs: I would like to deploy docker VM that is only available intranet wide
[2016-09-13 14:51:43] <scheung38> not sure how to share it with only clients and colleagues, but not for the rest of the world
[2016-09-13 14:51:50] <scheung38> this docker VM
[2016-09-13 14:52:28] <scheung38> so really it is two questions. Sharing and port forwarding
[2016-09-13 14:54:18] <marcelmfs> have you ever deployed any service before?
[2016-09-13 14:54:26] <marcelmfs> docker or not dockerised?
[2016-09-13 14:54:59] <scheung38> deployed to heroku and Digital Ocean
[2016-09-13 14:55:12] <marcelmfs> your question has no place in here, ask your Network Admin how to open ports to specific IP/port
[2016-09-13 14:55:23] <scheung38> with the kadirahq/mup tools for MeteorJS
[2016-09-13 14:55:31] <marcelmfs> I can't help you with your question.
[2016-09-13 14:56:01] <marcelmfs> it doesn't matter what software you're building, you need someone to add a firewall rule so that a specific IP can access your intranet
[2016-09-13 14:56:19] <scheung38> He has given the port number, but he is no docker expert
[2016-09-13 14:56:22] <marcelmfs> and that I (neither anyone in this chatroom) can't answer.
[2016-09-13 14:56:35] <marcelmfs> he doesn't have to be an expert
[2016-09-13 14:57:22] <marcelmfs> if you'd developing an app that listens to requests at 0.0.0.0:5000, how would you do to make it available outside your intranet?
[2016-09-13 14:57:36] <marcelmfs> it's not a docker specific procedure
[2016-09-13 14:59:49] <scheung38> But it is not 0.0.0.0:5000 and then making it available outside of it
[2016-09-13 15:00:18] <marcelmfs> well, sorry again, but I can't help you.
[2016-09-13 15:00:36] <scheung38> It has public IP address and private IP address and I am asking how to port forward which is a docker procedure, but you are saying this is not the right place.
[2016-09-13 15:01:09] <marcelmfs> ah, if you already have all your intranet accessing your app, so you already know how to expose a network port from the container to the host.
[2016-09-13 15:01:40] <scheung38> That is my question
[2016-09-13 15:02:18] <marcelmfs> docker run -d -p <local_network_port>:<container_network_port> yourcontainer
[2016-09-13 15:02:24] <marcelmfs> use-pflag
[2016-09-13 15:03:32] <scheung38> Cheers that might do it Marcel
[2016-09-13 15:08:47] <marcelmfs> you're welcome
[2016-09-13 15:11:55] <scheung38> But this is a command line, possible to have it baked into image as part of the build?
[2016-09-13 15:22:15] <marcelmfs> nope, you'll need docker-compose for that
[2016-09-13 15:22:29] <marcelmfs>  [<-LINK->] 
[2016-09-13 16:18:52] <BrunoMVPCosta> dizorg: I've the 'container_name' in my nginx configuration but it cannot find the container
[2016-09-13 16:19:02] <BrunoMVPCosta> I'm using dnsmasq now
[2016-09-13 16:33:04] <dizorg> and did you add the dnsmasq interface as the resolver ip in nginx? is it solved by now?
[2016-09-13 16:36:46] <BrunoMVPCosta> yes, it's fixed thanks :)
[2016-09-13 16:37:09] <BrunoMVPCosta> I'm having another issue, trying to connect to a mysql instance on aws from a container on my machine
[2016-09-13 16:37:15] <BrunoMVPCosta> ^^
[2016-09-13 22:06:25] <scheung38> created a docker image but sshroot@172.17.0.5ssh: connect to host 172.17.0.5 port 22: Operation timed out?
[2016-09-14 08:05:01] <marcelmfs> This is how you do it:docker exec -it --rm your-image:latest /bin/bash
[2016-09-14 09:59:05] <grofit> Hello, quick query around docker compose files with dockerfile
[2016-09-14 09:59:29] <grofit> so I am still new to all this, but I notice a few docker compose files reference a dockerfile in the build section (version 2 schema for compose files)
[2016-09-14 09:59:50] <grofit> now am I right in thinking that for something like
[2016-09-14 10:00:13] <grofit>  [<-CODE->] 
[2016-09-14 10:00:48] <grofit> I am basically going to get the Dockerfile to specify what the base image and dependencies etc are, then it will output an image withmynamecalledmyapiwith the ports exposed etc
[2016-09-14 10:01:45] <grofit> the thing that confuses me here is that in the real world this image will depend upon a mongodb instance
[2016-09-14 10:02:13] <grofit> but a dockerfile seems to just inherit a singular image and then set some setup script when its started, likeFROM nodejs/nodejsor something
[2016-09-14 10:02:51] <grofit> so should I have another service listed in the compose which depends upon a db (and link it)
[2016-09-14 10:03:26] <grofit> as it seems the Dockerfile should only really care about the setup of my API not the infrastructure, and that seems to be where the compose step comes in, but I just wanted to confirm my understanding
[2016-09-14 11:10:40] <marcelmfs> grofit: you're correct. The Dockerfile is suppose to build your app and contain it. The docker-compose.yml file is the definition of how separate containers interact with each other, composing your final service.
[2016-09-14 11:43:19] <grofit> kk thx
[2016-09-14 11:54:18] <bwnyasse> Hi guys , feedbacks are welcome for this simple tool for exploring containers logs [<-LINK->] . As we are starting a new project , 'docker logs -f' doesn't seem  to fit our need during dev process.
[2016-09-14 13:00:34] <marcelmfs> but docker already have a fluentd log driver [<-LINK->] 
[2016-09-14 13:01:11] <marcelmfs> I know, I know, why simplify if you can try to reinvent the wheel?
[2016-09-14 13:03:57] <bwnyasse> marcelmfs: It is just a tool that used this drive. The idea is not to reinvent the wheel exactly :) .  It is just an explorer that provides the way to avoid typing  constantly 'docker logs -f' .  So you start your container and natively with docker fluentd log driver , your logs will be available in this tool . Maybe I need to remove the 'fluentd' mention in the tool name
[2016-09-14 13:06:22] <bwnyasse> marcelmfs: So the README precise that the tool uses the native docker fluentd log driver [<-LINK->] 
[2016-09-14 14:03:05] <marcelmfs> I see, from the project name I mistakenly assumed something else, you're right.
[2016-09-14 14:04:00] <bwnyasse> marcelmfs: Thank you for the feedback :)
[2016-09-14 19:56:02] <rmcdaniel> If I dodocker rmi $(docker images -q)to delete all my images and then dodocker pullfollowed bydocker buildwhy does it always have to rebuild all the layers? It always says "Downloaded newer image for ubuntu:latest" and then rebuilds. Why doesn\'t it just download that image and see that nothing has changed?
[2016-09-14 20:12:25] <rmcdaniel> Hmm, it looks like that's just the way it works. It has to already have something in the cache to check against it.
[2016-09-14 21:21:16] <BrunoMVPCosta> I'm having troubles trying to connect to mysql on AWS from a container on my machine
[2016-09-14 21:28:50] <BrunoMVPCosta> Now it's working, no idea how :S
[2016-09-15 07:16:12] <grofit> In docker files I am trying to work out how they all seem to build off each other
[2016-09-15 07:17:21] <grofit> so for example the node container recommends that you use theirnode:<version>-onbuildas that does a lot of stuff for you, however if you use the basenode:4for example you are recommended to do some more work yourself in the docker file based upon what the on-build does, so are docker files like constructor inheritance?
[2016-09-15 07:17:52] <grofit> i.e when you do aFROM node:4it runs the node dockerfile, which runs any docker file it depends upon etc then finally runs my dockerfile tasks?
[2016-09-15 08:17:30] <hanovruslan> Hi! I\'ve got lame question - can i mount some volume with modified perms ?on the host - dir "dir_name" with perms nobody:nobody 0755 => mount to=> dir "dir_name" with perms user:user 0777According to docker volume reference - there is not such feature ... can i emulate it somehow?
[2016-09-15 08:26:13] <marcelmfs> no way of having two different sets of permissions of mount volumes
[2016-09-15 08:51:43] <hanovruslan> Emulation is possible?
[2016-09-15 08:56:30] <marcelmfs> not that I know of
[2016-09-15 10:01:23] <grofit> I have a strange issue where I am trying to get a node app deployed to a container, but it seems to use a stale npm module even though a new one exists
[2016-09-15 10:01:39] <grofit> I have tried removing the container,docker-compose downetc
[2016-09-15 10:01:58] <grofit> rebuilding then finally pushing it back updocker-compose up
[2016-09-15 10:02:44] <grofit> but locally if I do an npm install, it gives me the right module, but the one in the container is reporting an older version, so is there any way a container can have stale data in there? I have not set any volumes or anything
[2016-09-15 10:03:26] <grofit> I am using the default instance provided by kitematic not sure if that matters
[2016-09-15 10:04:24] <grofit> even after closing kitematic and re-opening it same issue
[2016-09-15 10:05:06] <grofit> Here is my compose file: [<-CODE->] 
[2016-09-15 10:05:11] <grofit> here is my dockerfile
[2016-09-15 10:05:27] <grofit>  [<-CODE->] 
[2016-09-15 10:05:46] <grofit> anyone see anything crazy?
[2016-09-15 14:14:52] <marcelmfs> you're not rebuilding bydocker-compose up<- this only re-instantiate your already built container
[2016-09-15 14:15:22] <marcelmfs> you have todocker buildto have your build process to pick the newer module after updating package.json.
[2016-09-15 16:09:24] <timothyjlaurent> How come docker cleans out my configurations (insecure registries) when I update it. Super annoying!
[2016-09-15 16:22:04] <akanieski> Good Morning, I'm having trouble containerizing a simple django app using this tutorial ( [<-LINK->] )
[2016-09-15 19:41:25] <thiagopecanha> Hey Guys, Does anybody knows how could I access Mysql command line in my docker machine? I am running it linked to a Rails docker machine...  through docker-compose
[2016-09-15 19:54:12] <grofit> marcelmfs: just to confirm then as I was doingdocker-compose buildthendocker-compose upand I thought the build there actually refreshed the container contents, so should I be usingdocker build -f docker-compose.ymlor something instead?
[2016-09-15 20:00:44] <Earl-Brown> I think docker hub search is broken ... if I google "docker mariadb", I get [<-LINK->] - but if I go to hub.docker.com and search "mariadb" it says "no results".  I actually can\'t getanyresults from searching hub.docker.com.  Anybody else have issues?
[2016-09-15 20:03:24] <thiagopecanha> Earl-Brown: Same results over here...
[2016-09-15 20:04:43] <Earl-Brown> Good to know I'm not alone!
[2016-09-15 20:11:33] <mlvnd> You're right, it's down: [<-LINK->] 
[2016-09-15 20:25:55] <Earl-Brown> I hope I can remember that link in the future! :)
[2016-09-15 20:33:25] <mlvnd> If Google isn't down also, you can always Google it.
[2016-09-16 08:17:27] <grofit> Also@marcelmfsit seemsdocker buildis more for buildingDockerfilenotdocker-composefiles
[2016-09-16 08:20:27] <roby2001>  [<-LINK->] 
[2016-09-16 08:20:29] <roby2001> Any clue what could be causing this?
[2016-09-16 08:21:23] <marcelmfs> grofit: I misunderstood you, when you saidrebuilding then finally pushing them up with docker-compose up
[2016-09-16 08:35:39] <grofit> no problem
[2016-09-16 08:35:49] <grofit> I am new to this so my terminology etc may not be 100% correct
[2016-09-16 08:35:55] <grofit> but basically I am using the above scripts
[2016-09-16 08:36:11] <grofit> and its almost like it never runs the npm install
[2016-09-16 08:36:21] <grofit> it has thenode_modulesas it runs modules
[2016-09-16 08:36:26] <grofit> but it never seems to get newer ones
[2016-09-16 08:37:12] <grofit> as the endapp.jsthrows an error with something in one of the modules, but in the latest version that file no longer exists in the module, but I dont know why its not getting the right modules
[2016-09-16 08:37:41] <grofit> my understanding was that every time I deployed that container it would be a "fresh" and isolated environment for it so it would always need to get those node modules (fromnpm installstep)
[2016-09-16 08:37:58] <marcelmfs>  [<-CODE->] 
[2016-09-16 08:38:43] <grofit> yeah I have rundocker-compose buildmany times hoping it would rebuild it
[2016-09-16 08:38:55] <marcelmfs> maybe you need to use--no-cache
[2016-09-16 08:39:02] <grofit> but when I go to dodocker-compose upafterwards (so it actually runs it) it seems to have stale files
[2016-09-16 08:39:07] <grofit> oh ok let me try that
[2016-09-16 08:54:11] <grofit> hmm I can see it installing all the npm modules now, but it still gives same error, let me verify all the containers and images have been removed and are explicitly re-created
[2016-09-16 08:55:10] <grofit> also a slightly related question for some reason when I dodocker-compose buildit seems to create the container with a random name (I see it via Kitematic) then remove it afterwards, I assume this is normal for it to do its setup stuff?
[2016-09-16 08:56:40] <grofit> right great after explicitly removing stuff it seems to be picking up right stuff now although I needed to manually close the docker-compose process as although I could see the container was finished the command line was still processing for some reason
[2016-09-16 09:06:21] <marcelmfs> yeah,docker rmi -f $(docker images -q)anddocker rm -f $(docker ps -qa)is always handy (but you also might want a localhost:5000 registry to cache some images locally and save bandwidth.
[2016-09-16 09:30:35] <grofit> ok another query while I have you here
[2016-09-16 09:30:46] <grofit> so when you link things or put them in a network on the docker-compose file
[2016-09-16 09:30:55] <grofit> so in this scenario I am linking mongodb to an api instance
[2016-09-16 09:31:09] <grofit> would I access it as "localhost:<port-specified>"
[2016-09-16 09:31:33] <grofit> as I would expect it has a different IP (the mongo container)
[2016-09-16 09:31:48] <marcelmfs> not if you don\'t expose the port withports: "27017:27017"in your docker-compose.yml
[2016-09-16 09:31:50] <grofit> but how do you know the IP of it within your code
[2016-09-16 09:32:11] <grofit> in the above config like 20 lines up I do expose those ports
[2016-09-16 09:32:13] <marcelmfs> from your code you can usecontainer_name, orhostname
[2016-09-16 09:32:35] <grofit> where can I use them? are they env vars?
[2016-09-16 09:32:46] <marcelmfs> I'm not sure if you can reach the service/api or mongo by service name...
[2016-09-16 09:32:58] <marcelmfs> container_name and hostname are docker-compose directives
[2016-09-16 09:33:08] <grofit> hmm ok
[2016-09-16 09:33:19] <grofit> well let me ask this a different way, and I apologise for it being not 100% docker related
[2016-09-16 09:33:51] <grofit> so in the API I have a config.js file which contains a section like so: [<-CODE->] 
[2016-09-16 09:34:09] <grofit> now historically that was being hosted by a mongodb container in kitematic, as the api was not containerised
[2016-09-16 09:34:15] <marcelmfs> I'm sure I can reach my services via container_name, but I always name the services the same name...
[2016-09-16 09:34:47] <grofit> but now I am in a position to do that, so in the nodejs app it uses these vars to populate the DB, connection string so how do I get from the docker layer, the information about where the mongodb container lives to populate those vars?
[2016-09-16 09:34:58] <marcelmfs> you'll probably want to usemongoand test if your app can reach your datastore via service name definition
[2016-09-16 09:35:53] <marcelmfs> well, you usedlinks: mongoso probably you'll be able to reachmongohostname fromapicontainer.
[2016-09-16 09:35:59] <marcelmfs> just usemongoas the host.
[2016-09-16 09:36:09] <grofit> AH right ok so this is the crux of what I am asking I think
[2016-09-16 09:36:16] <grofit> so does docker do some host.etc trickery
[2016-09-16 09:36:25] <grofit> to map MONGO as a hostname or something?
[2016-09-16 09:36:36] <marcelmfs> yep
[2016-09-16 09:36:37] <grofit> well "mongo" as it was lowercase
[2016-09-16 09:36:38] <grofit> AH right ok
[2016-09-16 09:36:50] <grofit> this makes 100% sense, I just didnt get what the link or network stuff actually did
[2016-09-16 09:36:52] <grofit> ok brilliant
[2016-09-16 09:37:33] <grofit> things are fitting into place mentally now
[2016-09-16 09:37:41] <grofit> so what does network do? as the linking bit makes sense
[2016-09-16 09:37:44] <marcelmfs> you don't need links if you're docker 1.10 or newer, but then I don't know if service name is enough to reach containers...
[2016-09-16 09:38:41] <grofit> hmm usingmongoas the host name didnt work there, I am using docker on windows but via docker tools (as I need HyperV disabled)
[2016-09-16 09:38:44] <marcelmfs> linking was pre-1.10 iirc, until 1.9 or 1.8 network was something experimental and you had to explicitly declare it--net=bridge|host|none, but now it's natively supported by the engine.
[2016-09-16 09:39:00] <grofit> I am using 1.12.0
[2016-09-16 09:39:06] <grofit> so should be fine
[2016-09-16 09:40:08] <marcelmfs> try to declarecontainer_name: mongoin you dockerfile and retry
[2016-09-16 09:40:17] <marcelmfs> *docker-compose
[2016-09-16 09:40:40] <grofit> as textual "mongo"?
[2016-09-16 09:40:58] <grofit> I am assuming so will try that now
[2016-09-16 09:41:54] <grofit>  [<-CODE->] 
[2016-09-16 09:41:55] <grofit> same
[2016-09-16 09:42:39] <grofit> as I am setting a network as well is that effecting it?
[2016-09-16 09:42:48] <marcelmfs> ah, maybe, yes
[2016-09-16 09:43:41] <grofit> let me remove the network then, can you give me a high level quick overview of what thenetworksproperty does?
[2016-09-16 09:43:49] <grofit> I have tried reading the docker docs but they are very confusing
[2016-09-16 09:44:02] <grofit> and quite verbose on bits which seem rather unimportant
[2016-09-16 09:45:55] <grofit> oh hmm maybe it is another problem
[2016-09-16 09:46:11] <grofit> as I just noticed the mongo instance dies instantly saying it doesnt have any storage space
[2016-09-16 09:52:06] <grofit> anyway thanks for your help, much appreciated I will sort out the mongo issue and then come back if there are still problems
[2016-09-16 09:54:26] <ATLSAPI> Hello
[2016-09-16 09:55:50] <ATLSAPI> I was just reading about windows containers for docker in WIN 10 Anniversary Edition, and it sayd just have to install a diffrenet verison of docker.
[2016-09-16 09:57:23] <ATLSAPI> Is there a way to install both windows docker engine and linux docker engine. And manage them withn the same docker clinet? Thanks for your help@marcelmfs
[2016-09-16 09:58:04] <marcelmfs> I can't help with windows questions
[2016-09-16 09:58:14] <marcelmfs> I only use linux in production
[2016-09-16 09:58:28] <marcelmfs> no proprietary software thanks
[2016-09-16 09:59:24] <ATLSAPI> Ha ha. Ok. Tried googling with no luck. Anywhere you think i'll find this information?@marcelmfs
[2016-09-16 10:26:58] <grofit> I use windows
[2016-09-16 10:27:03] <grofit> although I also use VMWare
[2016-09-16 10:27:07] <grofit> so I do not use Docker for windows
[2016-09-16 10:27:11] <grofit> I use Docker Tools for windows
[2016-09-16 10:27:22] <grofit> as that way I can use Virtual Box for thedocker-machinedriver
[2016-09-16 10:27:51] <grofit> but I am on windows 10 pro latest version
[2016-09-16 10:27:54] <grofit> and it all works fine
[2016-09-16 10:28:01] <grofit> apart from my general incompetence with docker
[2016-09-16 10:28:23] <ATLSAPI> Can you spin up a windows container?
[2016-09-16 10:28:56] <grofit> you mean a container which is using windows as a host instead of linux?
[2016-09-16 10:29:30] <grofit> as to my knowledge you cannot run windows within any containers
[2016-09-16 10:29:41] <grofit> as it wouldnt support the OS isolation thing that docker does
[2016-09-16 10:30:55] <ATLSAPI> Docker has partnered with Microsoft for windows conatiner but they'll only work on windows. See here [<-LINK->] 
[2016-09-16 10:31:44] <ATLSAPI> It was announced here [<-LINK->] 
[2016-09-16 10:32:56] <grofit> oh right
[2016-09-16 10:32:59] <grofit> not tried it
[2016-09-16 11:42:06] <marcelmfs> They're fundamentally different. Linux containers relies on cgroups and process namespacing, on windows, who knows which witchery they'll come up for windows containers in windows server 2016??
[2016-09-16 14:03:57] <grofit> hmm ok so I got the nodejs app running
[2016-09-16 14:04:41] <grofit> however for some reason it wont connect, just get ERR_CONNECTION_REFUSED
[2016-09-16 14:04:59] <grofit> but the port binding is right (kitematic also shows the port in the access link)
[2016-09-16 14:06:11] <grofit> do I need to do anything other than set the PORTS in the compose and Dockerfile? (and make sure the app is using those exposed/bound ports)
[2016-09-16 14:18:40] <grofit> could it be because I have the ports exposed in both docker-compose and Dockerfile? (one via ports, one via EXPOSE)
[2016-09-16 14:25:07] <grofit> works, ok its because I was using "localhost" in the container not "0.0.0.0"
[2016-09-16 15:40:08] <bkbonner> upgraded to docker 1.12.1   and now I'm SOL
[2016-09-16 15:40:26] <bkbonner> anybody know where I can find the docker for mac 1.12.0 dmg?
[2016-09-16 15:41:04] <andersonkyle> bkbonner:  [<-LINK->] 
[2016-09-16 15:42:03] <bkbonner> that isn't 1.12.1?
[2016-09-16 15:42:46] <andersonkyle> My bad, you want the previous patch version.  But what's wrong with it?
[2016-09-16 15:43:23] <bkbonner> 1.12.1 gives me this behavior: [<-ISSUE->] 
[2016-09-16 15:43:27] <bkbonner> :(
[2016-09-16 15:43:40] <bkbonner> been out of commission for the morning.
[2016-09-16 15:45:38] <bkbonner> to be fair...Xcode also got updated to 8.0 around the same time...
[2016-09-16 15:46:01] <bkbonner> and I installed Adobe Illustrator
[2016-09-16 15:46:14] <bkbonner> it was working fine yesterday
[2016-09-16 15:46:16] <andersonkyle> bkbonner:  [<-LINK->] 
[2016-09-16 15:46:19] <bkbonner> after Illustrator
[2016-09-16 15:47:14] <andersonkyle> bkbonner: Give that a spin.
[2016-09-16 17:48:09] <jaksky> Hello, I am new to docker (running on Windows 10 currently) and I am facing weird issues - when running docker container it is complaining that it cannot write to its own (internal) directories, any way how to debug or trace this issue?
[2016-09-16 17:48:46] <jaksky> No volumes added etc
[2016-09-16 17:49:37] <jaksky> using docker toolbox
[2016-09-16 18:51:30] <Earl-Brown> jaksky: - you're on windows 10?  Is your docker using Hyper-V?
[2016-09-16 19:36:12] <aios> jaksky: just share your drives where you executing docker-compose
[2016-09-16 19:36:46] <aios> jaksky: if no share drives docker dont have access to files (host machine) for volumes.
[2016-09-16 21:50:11] <ATLSAPI> Found the answer to my question earlier about switching between windows and linux containers on windows 10 here [<-LINK->] 
[2016-09-16 21:50:32] <ATLSAPI> Found the answer to my question earlier about switching between windows and linux containers on windows 10 here [<-LINK->] @lp@marcelmfs
[2016-09-17 19:20:41] <enavarrocu> Hello
[2016-09-17 19:20:53] <enavarrocu> I'm getting failed to register layer: rename /var/lib/docker/image/overlay/layerdb/tmp/layer-442365506 /var/lib/docker/image/overlay/layerdb/sha256/572abd49c8d725039f250316175eb56d53434c07ba325641aa8f4b42053086f1: directory not empty
[2016-09-17 20:41:18] <nite> Hi all - I\'m able to run the hypriot/rpi-node (ARM) image in docker on windows (64bit), but in all linux x86/64 machines I\'ve tried (debian, coreOS, alpine etc) I get the following error, which makes sense to me but I dont get why it\'d run in docker on windows then, and I wonder whether I\'m missing some opportunity to use an x86 machine as a build server (ie. the default in google/aws cloud). Any ideas?docker run -ti hypriot/rpi-node lsstandard_init_linux.go:175: exec user process caused "exec format error"
[2016-09-17 21:10:31] <enavarrocu> nite: you have the same error than me
[2016-09-17 21:11:14] <enavarrocu> you are using a different architecture image
[2016-09-17 21:30:38] <nite> enavarrocu: that's the weird thing - docker for win runs a single alpine linux (mobylinuxvm) to host docker - it must be x64 as it's on x64 windows, but it can run both x64 and arm/rpi images - no other x64 linux I've seen can do both
[2016-09-17 21:31:44] <enavarrocu> I had the problem running hypriot in the Raspberry Pi 2
[2016-09-17 21:49:25] <nite> hmm, no that should work@enavarrocu- although I'm running pi3 so can't check
[2016-09-17 21:49:57] <enavarrocu> I have it running now with a image made for armhf
[2016-09-17 22:18:11] <vyscond> Hello everyone! Guys is it possible to use shared folder-vwhen running your container on a remote docker machine e.g.: one docker machine on the digital ocean create through thedocker-machine?
[2016-09-18 03:51:14] <SalahAdDin> Hi guys, i have a problem with docker in local developer computer.
[2016-09-18 03:51:37] <SalahAdDin> I'm working with django, and create a image for my django project.
[2016-09-18 03:52:11] <SalahAdDin> These are my files [<-LINK->] 
[2016-09-18 03:52:36] <SalahAdDin> I build the image, and i dodocker-compose up.
[2016-09-18 03:52:47] <SalahAdDin> But the custom images doesn't works
[2016-09-18 03:54:52] <SalahAdDin>  [<-CODE->] This.
[2016-09-18 03:59:46] <SalahAdDin> Can anyone explain me what is my error?
[2016-09-18 03:59:48] <SalahAdDin> Please.
[2016-09-18 07:40:50] <Krokop> SalahAdDin: try [<-CODE->] 
[2016-09-18 07:44:54] <SalahAdDin> No
[2016-09-18 07:44:57] <SalahAdDin> Doesn't works
[2016-09-18 07:47:25] <Krokop> you can run [<-CODE->] and then find where manage.py is located
[2016-09-18 07:50:14] <SalahAdDin>  [<-CODE->] 
[2016-09-18 07:50:29] <SalahAdDin> only existnode_nodules
[2016-09-18 07:54:31] <SalahAdDin> i don't understand why happen this.
[2016-09-18 07:57:00] <SalahAdDin> when i build the image, uzman, i haven't problems, install requirements with pip and install node packages as global
[2016-09-18 07:57:08] <SalahAdDin> without problems
[2016-09-18 08:09:00] <Krokop> thats because your [<-CODE->] rewrite folder code
[2016-09-18 08:23:39] <SalahAdDin> i want install nodemodules in the same folder that my django project
[2016-09-18 08:26:54] <Krokop> ok, then removenpmblock, then run [<-CODE->] 
[2016-09-18 08:43:19] <SalahAdDin> yes
[2016-09-18 08:43:31] <SalahAdDin> you are right
[2016-09-18 08:43:42] <SalahAdDin> without npm block
[2016-09-18 08:43:45] <SalahAdDin> i can see all
[2016-09-18 08:44:39] <SalahAdDin>  [<-CODE->] 
[2016-09-18 08:45:10] <Krokop> npm install
[2016-09-18 08:46:59] <SalahAdDin> Wait a minute, i haven't a json package, i have to build it, but, here works fine :D
[2016-09-18 08:47:28] <Krokop> :)
[2016-09-18 09:01:21] <SalahAdDin> Sorry, i have a problem with elasticsearch image
[2016-09-18 09:03:41] <SalahAdDin>  [<-CODE->] 
[2016-09-18 09:05:19] <Krokop>  [<-CODE->] 
[2016-09-18 09:05:21] <SalahAdDin> But, nothing place using these address
[2016-09-18 09:06:16] <SalahAdDin> These coman doesn't solve the bug.
[2016-09-18 09:08:45] <Krokop> sudo fuser -k 9300/tcp
[2016-09-18 09:09:06] <SalahAdDin>  [<-CODE->] 
[2016-09-18 09:09:28] <SalahAdDin> I don't understand, why hava have 9300 occuped?
[2016-09-18 09:09:46] <SalahAdDin> i have elasticsearch in my computer, but it take 9200.
[2016-09-18 09:12:13] <SalahAdDin> Oh my GOD!
[2016-09-18 09:12:16] <SalahAdDin> It's works!!!
[2016-09-18 09:12:31] <SalahAdDin> Well, i stop local elasticsearch service
[2016-09-18 09:12:39] <SalahAdDin> and add the package json
[2016-09-18 09:12:43] <SalahAdDin> and finally it works :D
[2016-09-18 09:12:46] <SalahAdDin> Thanks!
[2016-09-18 09:13:19] <Krokop> U welcome :)
[2016-09-18 09:14:56] <SalahAdDin> I have a question,
[2016-09-18 09:15:02] <SalahAdDin> this module:
[2016-09-18 09:15:26] <SalahAdDin>  [<-CODE->] 
[2016-09-18 09:15:35] <SalahAdDin> give me this error:
[2016-09-18 09:16:12] <SalahAdDin>  [<-CODE->] It's necessery give a volume to elasticsearch?
[2016-09-18 09:18:03] <Krokop> elasticsearch_1 - this is folder or file ?
[2016-09-18 09:22:19] <SalahAdDin> I don't know, i'll use elasticsearch as searching backend for django, using django-haystack, so, i don't know if needed for create indexes and more.
[2016-09-19 06:39:57] <SalahAdDin> Guys!
[2016-09-19 08:11:21] <grofit> So quick query around testing in dockers
[2016-09-19 08:11:51] <grofit> So currently I have an API which depends upon mongodb, and that is deployed in a container and works fine
[2016-09-19 08:11:59] <grofit> with its own docker-compose and dockerfile
[2016-09-19 08:12:20] <grofit> now the problem is I have tests which I want to be able to run in a container
[2016-09-19 08:12:48] <grofit> but this container will depend upon the API container which in turn depends upon Mongo
[2016-09-19 08:13:46] <grofit> so based upon articles I have seen online I would need another dockercompose and dockerfile specifically for the tests, but my query is do I need to setup all the dependencies for the api, or can I somehow have my test one just reference the existing api image and it will "just work"
[2016-09-19 08:15:04] <marcelmfs> SalahAdDin: you need a named data container definition in your compose file. [<-LINK->] 
[2016-09-19 08:15:57] <marcelmfs> grofit: usually if you don't want to test integration of your app with the rest of your architecture you would mock stuff...
[2016-09-19 08:16:39] <grofit> I already have unit/integration tests as part of the API
[2016-09-19 08:16:45] <grofit> this is more acceptance level testing
[2016-09-19 08:16:48] <marcelmfs> so that every call for any external resources would be mocked not to integrate, but only to test if given a procedure call, and with the expected response from the external resource, your app works as expected.
[2016-09-19 08:16:50] <grofit> so it would be end to end
[2016-09-19 08:17:52] <marcelmfs> so yes, you're doing end to end integration tests, and I'd suggest you to have the docker compose file that describes the service also defining the datastore.
[2016-09-19 08:17:55] <grofit> but forgetting what you should/shouldnt be testing, I am interested in how I should best represent this dependency with docker, you could easily change the problem to being an API which depends upon another API like in microservices or whatever
[2016-09-19 08:18:19] <grofit> so I will need to setup the db dependency for the API container in this docker compose file then?
[2016-09-19 08:18:39] <grofit> I was hoping I could just depend upon the API and let it sort itself out :(
[2016-09-19 08:19:11] <marcelmfs> what I do is, every service is self contained, and in the dockerfile for this service I'd declare all dependent components, so that the service isdocker-compose -f docker-compose.yml up -dby itself
[2016-09-19 08:19:43] <grofit> oh right ok, so you just make sure the API is online before you run your tests
[2016-09-19 08:19:45] <marcelmfs> you don't have to setup dependency, if your service is resilient enough to start only after detecting that the db is up
[2016-09-19 08:19:59] <grofit> much like you would with local development (you could automate the http server I guess)
[2016-09-19 08:22:42] <marcelmfs> ahn, well that depends.
[2016-09-19 08:23:57] <grofit> part of the reason I am interested in managing dependencies on other containers is at some point I may have like 3 APIs (all self contained in their own containers) being required for another one etc so I didnt want to have to manage all dependencies for all dependent containers
[2016-09-19 08:24:16] <marcelmfs> the thing here is that if you want to test end to end and you have, say, 5 services you wish to test your service against, then you'd have to have continuos deployment of the service that'sin developmentso that you can end-to-end test it against the rest of your environment.
[2016-09-19 08:24:41] <grofit> I dont want to have to wait until the CI server to test this stuff
[2016-09-19 08:25:06] <grofit> I want to be able to quickly create the infrastructure locally and test it there before it is comitted
[2016-09-19 08:25:33] <marcelmfs> ah, this is not for continuous flows?
[2016-09-19 08:25:40] <marcelmfs> it's for local testing
[2016-09-19 08:25:43] <grofit> yes
[2016-09-19 08:25:46] <grofit> it will be used in CI
[2016-09-19 08:26:09] <grofit> but Ci would just do the same sort of thing the local dev does when building, and the CI environment deployment wouldnt even take the tests
[2016-09-19 08:26:47] <grofit> so the flow would be (and was before docker):Dev checks out code\nDev changes code\nDev tests code\nDev pushes changes\nCI tests code\nCI deploys to env
[2016-09-19 08:27:02] <marcelmfs> you'd have to have two sets of compose files - one for dev, and another for ci.
[2016-09-19 08:27:10] <grofit> so I am in the process of docker-ifying an existing project as a proof of concept
[2016-09-19 08:27:14] <grofit> and am at stage 3
[2016-09-19 08:27:28] <grofit> why would I need 2 sets?
[2016-09-19 08:27:58] <marcelmfs> it will depend on the strategy you'd choose for the deployment.
[2016-09-19 08:28:58] <marcelmfs> because, if you have a mongodb that's queried (requirement) for several services, then you don't want it to be restarted/redeployed after every change on any of it's dependant services.
[2016-09-19 08:29:21] <marcelmfs> but you'd have to have a compose file that defines that datastore for local testing.
[2016-09-19 08:29:48] <grofit> hmm good point
[2016-09-19 08:29:59] <grofit> I was planning on just templating certain files for this sort of thing
[2016-09-19 08:30:18] <marcelmfs> what do you mean by templating?
[2016-09-19 08:30:23] <grofit> so its still one entry point, just depending upon environment the config may be changed on the server, but maybe its simpler to have multiple files
[2016-09-19 08:30:26] <grofit> token replace style
[2016-09-19 08:30:32] <grofit> much like octo deploy with config files
[2016-09-19 08:31:11] <marcelmfs> I see, I don't know how that would work with compose files though.
[2016-09-19 08:32:29] <francescopersico> a little question: if i do docker service inspect etcd
[2016-09-19 08:32:48] <francescopersico> my VirtualIP part is like
[2016-09-19 08:32:57] <francescopersico>  [<-CODE->] 
[2016-09-19 08:34:00] <francescopersico> etc service is in "clusternet" network
[2016-09-19 08:34:21] <francescopersico> but if i type docker network inspect clusternet
[2016-09-19 08:34:37] <francescopersico> my container part is like
[2016-09-19 08:34:43] <francescopersico>  [<-CODE->] 
[2016-09-19 08:34:55] <francescopersico> 10.3 instead of 10.2
[2016-09-19 08:35:36] <francescopersico> i am missing something i think
[2016-09-19 08:36:45] <francescopersico> if in another container i have to specify etcd ip
[2016-09-19 08:36:51] <francescopersico> wich one i need to use
[2016-09-19 08:38:27] <marcelmfs> I don't know how etcd works with virtualips, but in docker you just refer to your container by it's hostname or container_name or(!?) service name definitions.
[2016-09-19 08:42:48] <francescopersico> don't know if it changes something but i miss to say i am using swarm mode
[2016-09-19 08:43:00] <francescopersico> and i am using 3 nodes
[2016-09-20 06:39:28] <Speechkey_twitter> Hi folks
[2016-09-20 06:40:12] <Speechkey_twitter> I’m looking for an approach to mount a NFS or GlusterFS share in container
[2016-09-20 06:40:38] <Speechkey_twitter> And I cann’t find any acceptable solution
[2016-09-20 06:41:33] <Speechkey_twitter> Is there really no possiblity to mount a network file system in the container?
[2016-09-20 06:43:43] <Speechkey_twitter> How can I handle the situation in the cluster, where two or more containers have to access the same data?
[2016-09-20 08:08:34] <marcelmfs> Speechkey_twitter: , according to [<-LINK->] - you need to issue the mount command from within the container, instead of-v /nf/share:/container/path.
[2016-09-20 08:10:02] <marcelmfs> and, according to [<-LINK->] , it seems there is a volume-driver plugin that also achieve the same results with more compatibility options.
[2016-09-20 08:10:54] <marcelmfs> Have you stumbled upon those articles? Aren't those acceptable solutions? Why?
[2016-09-20 08:26:25] <roby2001> I know this might not be entirely docker-related but when I try to connect to aws ecr using  the return ofaws ecr get-login --region eu-west-1I'm getting :An error occurred trying to connect: Post http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.24/auth: open //./pipe/docker_engine: The system cannot find the file specified.. Any clues what might be causing this?
[2016-09-20 09:43:03] <sunilgupta01> What are the various deployment architecture approaches to setup a microservice for MySQL DB esp. in microservices environment?
[2016-09-20 09:45:24] <izhilenkov> Hi guys! I’m trying to use docker on remote machine viadocker -H=tcp://***.***.**.***:2375, but I’ve got a problem like thisCannot connect to the Docker daemon. Is the docker daemon running on this host?
[2016-09-20 10:16:18] <BrunoMVPCosta> are you using docker on mac?
[2016-09-20 11:00:33] <izhilenkov> yeap
[2016-09-20 11:00:53] <izhilenkov> but remote machine on digital ocean (ubuntu 14 04)
[2016-09-20 16:21:57] <vivace-io> Woops, never mind... works now
[2016-09-20 18:18:13] <verto> Hi guys, is it common creates docker for development tools? ex. grunt, sbt, maven?! I was trying to make it but i'm always need to know how the code works to define volumes and env vars. maybe it doesn't works well.
[2016-09-20 20:32:01] <Chuwiey> hi all, i’m having an issue with installing docker on mac os x… everytime i install it, i see it complaining about a crash (v1.12.1) — i saw a bunch of complaints about this on google but for 1.12.0-rc2, anyone know what i can do about this?
[2016-09-21 00:15:32] <zozo123> Hi, I would like to cross compile docker daemon for arm. What's the best approach of doing that? Docker 1.12.1
[2016-09-21 04:56:49] <avinash2888> hi, how can i store my container logs in aws s3
[2016-09-21 05:33:24] <SalahAdDin> marcelmfs: For what?
[2016-09-21 05:34:20] <SalahAdDin> i have a problem with elasticsearch container: [<-LINK->] 
[2016-09-21 06:53:33] <Speechkey_twitter> marcelmfs: Thank your for response. I would like to run a docker cluster, e.g. with Swarm. So the solution to mount a nfs share on the host and then to mount it within the docker would be not acceptable.
[2016-09-21 08:37:46] <rchodava> Hi there, I am having an issue where the docker container just hangs .. maybe deadlocks? .. I'm running a FUSE file system (written in Go) which I don't think is doing anything out of the ordinary .. after it locks, I can't interrupt gdb either .. anyone have any experience dealing with this type of thing?
[2016-09-21 11:22:50] <Speechkey_twitter> marcelmfs: I will check the netshare plugin, thanks
[2016-09-21 12:48:07] <eirikb> I'm probably doing this wrong, but I'm trying to set up a docker-based build server for my team, just for testing. So I have a container for Jenkins, Nexus and Upsource. In addition I have a container with a long-running script for a specific integration test.Question is, how can I start this integration test from Jenkins, which itself is a container? Or should I do that at all? Jenkins runs  forever, the test exists only while it runs.
[2016-09-21 12:55:02] <eirikb> Looks like I'm not alone with this problem: [<-LINK->] 
[2016-09-21 13:06:32] <eirikb> How do I install Docker CLI? I'm trying the socker-solution mentioned above inside a phusion/baseimage-container. I canapt-get install docker, which will probably give me the CLI, but I imagine I will get a lot more which I don't want
[2016-09-21 13:20:14] <eirikb> I was able to run it in Alpine with the socket-approach after doingapk --update add docker. I'm sure I can make my own version ofjenkinsimage with docker cli installed
[2016-09-21 17:56:07] <luiscostalmeida> Hello, question anyone using GELF logging driver on docker?
[2016-09-21 17:59:35] <tiffanyfay> luiscostalmeida: Only thing I know about with GELF is Jérme Petazzoni's workshop: [<-LINK->] 
[2016-09-22 05:23:35] <SalahAdDin> Hello
[2016-09-22 08:28:46] <marcelmfs> eirikb: usually in Continuous Build/Integration workflows you don't have to use docker inside docker, what you need, is docker outside docker, which is, your docker container can also execute docker client commands to the underlying docker host socket. That way, jenkins or whatever CB/I will spawn sibling containers which can be targeted by containers running tests.
[2016-09-22 08:57:45] <milindchawre> Hi I want to start contributing to docker, I already build the docker codebase and was able to make some changes and test it out. But I want to understand the code in much depth, so how do I start referring the docker code. Want to know from which file or package should I start.
[2016-09-22 15:22:06] <chernals> Is it possible to change the subnet of the ingress network ? By default it seem to be 10.x but my host network is also on 10.x
[2016-09-23 09:14:14] <tomVeloso> I have a containear running differnet bash with different pid ... can I directrly connect to one of this bash .. if yes how?
[2016-09-23 09:54:58] <hholst80> how can I bake in thescale worker=16for a worker service but don't start any services yet?
[2016-09-24 06:58:42] <nerdyglasses> hey there
[2016-09-24 06:59:03] <nerdyglasses> I'm trying to deploy a simple node app using docker-machine and docker-compose
[2016-09-24 06:59:19] <nerdyglasses> I've tried for hours now but I cannot get solve the problem
[2016-09-24 06:59:48] <nerdyglasses> locally everything works fine but on digitalocean this happens:
[2016-09-24 06:59:51] <nerdyglasses>  [<-CODE->] 
[2016-09-24 07:00:47] <nerdyglasses> does anyone know what I'm doing wrong?
[2016-09-24 07:01:57] <nishant-jain-94> seems its not able to find package.json
[2016-09-24 07:02:51] <nishant-jain-94> would be great if you could share your dockerfile
[2016-09-24 08:23:17] <nerdyglasses> I\'ve "fixed" it differently now
[2016-09-24 08:23:53] <nerdyglasses> this was the dockerfile before
[2016-09-24 08:23:56] <nerdyglasses>  [<-CODE->] 
[2016-09-24 08:24:07] <nerdyglasses> this is it now:
[2016-09-24 08:24:10] <nerdyglasses>  [<-CODE->] 
[2016-09-24 08:54:21] <webus> hmm.main changes you change default /usr/src/app to /code ? why ?
[2016-09-24 08:55:05] <webus> it's just container. no matter where is the code...
[2016-09-24 09:01:02] <nerdyglasses> oh I've also tried /usr/src/app
[2016-09-24 09:01:15] <nerdyglasses> I'm new to docker. I just took something from the internet
[2016-09-24 09:01:29] <nerdyglasses> but I've found out that it should have been /usr/src/app
[2016-09-24 15:36:13] <FredLackeyOfficial> any vim fans here?
[2016-09-25 01:48:06] <chan_seeker_twitter> guys i am new to  docker..can u guys plz assist me in where to start and gve some brief usage of docker as i cant understand..I would like to takeoff with a small push from you guys
[2016-09-25 07:25:01] <chernals> docker run -it --rm ubuntu bash
[2016-09-25 07:25:07] <chernals> should get you going...
[2016-09-25 11:59:14] <chan_seeker_twitter> chernals: i am not using ubuntu..i am arch user :D
[2016-09-25 11:59:40] <chernals> then you should really read something about docker ;)
[2016-09-25 12:01:20] <chan_seeker_twitter> chernals: suggest me some sites or links where i could get on quickly with doccker instead of official docker docs link
[2016-09-25 12:02:13] <chernals> what's wrong with the official doc(k haha) ?
[2016-09-25 12:03:15] <chan_seeker_twitter> chernals: i find it some what lengthy and not able to get it dude
[2016-09-25 12:06:26] <chernals> what are you trying to do ?
[2016-09-25 18:44:21] <tiffanyfay> chan_seeker_twitter:  [<-LINK->] , [<-LINK->] 
[2016-09-25 18:47:59] <chan_seeker_twitter> tiffanyfj: the content in  tat link is static one
[2016-09-25 18:48:39] <tiffanyfay> chan_seeker_twitter: What?
[2016-09-25 18:49:28] <chan_seeker_twitter> tiffanyfj: Yup..Only 1 slide is poping up thats it...others are not coming
[2016-09-25 18:49:40] <tiffanyfay> chan_seeker_twitter: Use your arrow keys.
[2016-09-25 18:50:28] <tiffanyfay> chan_seeker_twitter: Or if you want a pdf: [<-LINK->] 
[2016-09-25 18:51:11] <chan_seeker_twitter> tiffanyfj: Thanks bud...with tat i should take off i reckon
[2016-09-25 20:43:50] <pinguinjkeke> Hello everyone!
[2016-09-25 20:44:05] <pinguinjkeke> I have a big problem with file reading speed on OS X using native docker
[2016-09-25 20:44:31] <pinguinjkeke> How can I solve slow file reading problem?
[2016-09-25 22:40:52] <SalahAdDin> chan_seeker_twitter: Me too.
[2016-09-26 06:47:07] <DaeBang-Olufsen> Hi everyone! I am right now trying to setup a docker.yml file, for other to use, but when it comes to making my MySQL server from the YML file, it just stops at "Version: \'5.6.33\'  socket: \'/var/run/mysqld/mysqld.sock\'  port: 3306  MySQL Community Server (GPL)" and i dont knwo why, can anyone help?
[2016-09-26 15:52:36] <sideffect0> quit
[2016-09-26 17:08:23] <armandojose009> hi how are you?? how can change the bridge network for docker-compose ??
[2016-09-26 17:28:43] <FredLackeyOfficial> am i missing something?
[2016-09-26 17:29:04] <FredLackeyOfficial> i really like the way docker-toolbox runs on the mac ... isolating machines ... different IPs, etc
[2016-09-26 17:29:26] <FredLackeyOfficial> i understand the benefit, in a hosting environment, of using docker on a single box / ip
[2016-09-26 17:30:22] <FredLackeyOfficial> is there an official way of still getting the docker-toolbox scenario (using different vms possibly) on a single box
[2016-09-26 17:30:30] <FredLackeyOfficial> feels more natural for dev purposes
[2016-09-26 17:30:34] <FredLackeyOfficial> ??
[2016-09-26 17:31:47] <FredLackeyOfficial> or, is it somehow just a matter of installing / using docker-machine ??
[2016-09-26 17:33:23] <FredLackeyOfficial> (on ubuntu, btw)
[2016-09-26 18:47:18] <jensaronsson> Hello! On my host ( not the linux host vm ) i am connected to vpn and i need all container traffic go through that vpn network. Is that possible ? Thx
[2016-09-27 02:29:28] <pauljlucas> is anyone using docker for mac on a hackintosh? i cant connect to my containers once they are running (and show working just fine with docker ps) and im not sure why
[2016-09-27 03:15:22] <zerocoolback> Looks like official docker support for windows is launching today. This is definitely a game change [<-LINK->] 
[2016-09-27 08:52:41] <intellix> I've got some services in a docker-compose file withrestart: always. If I do docker stop for those services and restart docker, they're back again. Shouldn't a stop disable them coming back up automatically?
[2016-09-27 08:53:00] <kschlesselmann> Nope
[2016-09-27 08:53:20] <kschlesselmann> intellix: Check the doc …unless-stoppedis your friend
[2016-09-27 08:53:28] <marcelmfs> butdocker-compose stopmaybe
[2016-09-27 08:53:43] <intellix> will test docker-compose
[2016-09-27 08:54:25] <kschlesselmann> Nope …alwaysretsartalways.
[2016-09-27 08:54:43] <intellix> aah, makes sense
[2016-09-27 15:45:52] <louisburton> Hi. Is it possible to publish a container's port  if the container was created via a docker service? i.e. I would like to use a docker service to scale and manage my service cluster, but I would like each container to still be directly externally accessible without use of the routing mesh. (useful in examples that use smart routing to a cluster - like data grid services)
[2016-09-27 20:53:23] <desprit> Hi everyone!In my app I'm using database so I created network in docker-compose file: [<-CODE->] Now when I'm checking database from inside container, I'm able to connect with host 'rethinkdb'. But outside of container I'm using localhost to make connection to the same database. What is the way to have 1 same host name inside container and on host machine?
[2016-09-28 07:24:11] <vedam> Hey all,this is driving me mad.I'm trying to pass an ARG in my docker-compose-file. [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] any help appreciatedthx in advance
[2016-09-28 07:28:08] <bwnyasse> vedam: What about [<-CODE->] 
[2016-09-28 07:32:09] <vedam> @bwnyasse [<-CODE->]  [<-CODE->] 
[2016-09-28 07:39:28] <bwnyasse> @vedam as it is not an environment variable , I think the solution is to rebuild the image.I would create a dockerfile like this [<-CODE->] Copy it next to the docker-compose file with the following content [<-CODE->] Lemme know what you think ( and if it's working )
[2016-09-28 07:47:42] <vedam> bwnyasse: thx a lot. I think this is going in the right direction.still throws an error, but it rebuilds: [<-CODE->] 
[2016-09-28 08:06:31] <vedam> bwnyasse: hmm. just found, there's an [<-ISSUE->] /discussion on that
[2016-09-28 08:15:39] <vedam> @bwnyassefyiI passed the args in the Dockerfile: [<-CODE->] and made a simple: [<-CODE->] That worked.So. It was the right directionthx again
[2016-09-28 09:27:40] <bwnyasse> vedam: You're welcomed :)
[2016-09-28 09:48:13] <hholst80> I am not sure thatdocker-compose -f path/to/docker-compose.ymlshould assume that Dockerfile is inpath/toinstead of.where . is the directory I launchdocker-compose. Comments?
[2016-09-28 09:52:05] <marcelmfs> usually I rundocker-compose upcommand with several multiple-f path/to/compose.ymlarguments, so that I can have isolated docker-compose files for each of my micro-services that can run independently.
[2016-09-28 09:53:08] <hholst80> yes that is a fair workflow
[2016-09-28 09:53:20] <hholst80> but you have a static set of docker-compose.yml files then
[2016-09-28 09:53:43] <hholst80> We're generating them and throwing them away. its more convenient to have them in a separate directory instead of filling up the root git directory with temps
[2016-09-28 09:55:19] <hholst80> also, we want to build "." directory not,/path/to/compose. TheDockerfileis identical between all docker-compose.yml files as well. only the container instantiation is different
[2016-09-28 10:42:10] <DaeBang-Olufsen> Hi! Does anyone know how to make a "Reverse-proxy" able to have a line to subdirectories inside a docker conatiner? :)
[2016-09-28 12:04:57] <hholst80> what is a line to a subdirectory?
[2016-09-28 12:05:33] <hholst80> do you want to share contents from within a container to antother container?volumes-frommight be something you can use
[2016-09-28 12:06:29] <DaeBang-Olufsen> You know, if you have an index site and you want to move to a subfolder via a link, and it jumps out of the container...
[2016-09-28 12:07:34] <marcelmfs> That question is completely unrelated to docker containers, it's a webserver question. Go figure in w3schools or something better...
[2016-09-28 12:08:26] <DaeBang-Olufsen> Okay, i will do that, thanks.
[2016-09-28 16:32:32] <yuriyf> hi all
[2016-09-28 17:05:13] <WellingtonBraga> Hi guys.
[2016-09-28 17:05:39] <WellingtonBraga> Is there a way to save file in IDE, and automatically publish it in the container instead of use docker cp?
[2016-09-28 23:40:32] <b-rays> WellingtonBraga: What's wrong with Docker cp?
[2016-09-29 05:06:21] <nischay30> what is the network mode in docker.compose.yml file
[2016-09-29 05:06:37] <nischay30> *docker-compose.yml
[2016-09-29 08:37:06] <marcelmfs> b-rays: @WellingtonBragafor development cycle, if you want to already develop something directly inside a container, it's a pain to always cp to test.
[2016-09-29 08:38:00] <marcelmfs> what's commonly done around there, is to mount bind map your app folder into the container and run your app from there with some kind of notifier that catches file changes and reload your app...
[2016-09-29 09:49:05] <hholst80> Anyone made a patch fordocker statsthat gives me an option to show container image names instead of hashes?
[2016-09-30 11:55:52] <Speechkey_twitter> Hi folks, does anyone know something likewait-fot-it.shwhich is able to work in alpine and sh?
[2016-09-30 13:52:26] <marcelmfs> likeuntil $(curl --fail http://web/is_alive); do sleep 1; echo 'waiting for webserver'; done?
[2016-09-30 13:52:42] <WellingtonBraga> marcelmfs: Thanks for your answer. So I need to bind my local folder and thus, the container will retrieve the app in this folder? When you says "some kind of notifier" you are refering to something that will be listening any changes in my app ?@b-raysas Marcel sad, it is a painful task always use docker cp to publish app updates in container.
[2016-09-30 13:55:26] <marcelmfs> yes, like gulp livereload dev mode
[2016-09-30 13:56:41] <WellingtonBraga> Awesome@marcelmfsIs it possible to find some tutorial on the web which explains how to do it?
[2016-09-30 13:57:56] <marcelmfs> nothing is impossible nowadays
[2016-09-30 13:58:14] <WellingtonBraga> For sure
[2016-09-30 13:58:27] <marcelmfs>  [<-LINK->] 
[2016-09-30 14:02:12] <WellingtonBraga> marcelmfs: Thank you Marcel. I'll try to do it.
[2016-09-30 14:06:29] <InfoSec812> I'm trying to resolve a problem with our docker partitions growing beyond bounds... I have looked at [<-ISSUE->] , but the solution was supposedly applied in 1.9 but I am still having issues with 1.12.1
[2016-09-30 14:09:31] <InfoSec812> We're running docker on CentOS7 and have updated our kernels to 4.7.5 in an effort to help resolve problems, but we are still having issues.
[2016-09-30 14:17:57] <wklm> Hi all :) Any one know how to escape spaces in windows paths in dockerfile?
[2016-09-30 14:29:48] <InfoSec812> wklm: Since docker on Windows is actually using a Linux VM, I would think that you would use *NIX style paths/escapes...
[2016-09-30 14:37:17] <wklm> InfoSec812: well i'm using newly released docker for windows (based on nt kernel)
[2016-09-30 15:03:24] <marcelmfs> InfoSec812: are you using devicemapper? the solution is to use--storage-driver=overlay2
[2016-09-30 15:05:01] <marcelmfs> wklm: I think "C:\\\\Path to your\\folder with spaces\\should do\\the\\job"
[2016-09-30 18:42:05] <pupssman> Hello there!Dunno it it's the right place to ask the question -- but could anyone share their experience with multiple docker-compose files share insights into this problem: [<-LINK->] 
[2016-10-01 04:03:44] <SalahAdDin> Hi guys, i have a big question about docker containers:
[2016-10-01 04:04:31] <SalahAdDin> i had being trying install jenkins in docker container and i had got many problems.
[2016-10-01 04:05:53] <SalahAdDin> Two days ago, finally i run a docker image with jenkins: [<-LINK->] 
[2016-10-01 04:06:08] <SalahAdDin> But in this case i haven't container log.
[2016-10-01 04:07:32] <SalahAdDin> I'm using this compose: [<-LINK->] 
[2016-10-01 04:07:46] <SalahAdDin> which official jenkins docker image i have a full compose log in real time
[2016-10-01 04:07:52] <SalahAdDin> but with this custom image, i have this:
[2016-10-01 04:08:31] <SalahAdDin>  [<-CODE->] But, this is only the first question.
[2016-10-01 04:09:22] <SalahAdDin> The second problem, i have to shut down my pc,
[2016-10-01 04:09:38] <SalahAdDin> and after, when i up the same image, well, ia haven't access to jenkins
[2016-10-01 04:09:44] <SalahAdDin> or at least nginx
[2016-10-01 04:09:55] <SalahAdDin> localhost get me connection error, and this by twoo days.
[2016-10-01 04:10:15] <SalahAdDin> Until today that i up the container again and i have all well again, why?
[2016-10-01 04:14:23] <SalahAdDin> Can anyone explain me this extrange performance?
[2016-10-01 18:19:16] <enavarrocu> anybody knows a gitter room for debian or linux in general?
[2016-10-02 11:03:44] <intellix> Docker  for Mac seems to never work for me :/ Everytime I come to use it, I get:Error response from daemon: Bad response from Docker engineand see it's restarting. Now it seems to be indefinitely restarting and I've gotta resort to Resetting it again
[2016-10-02 12:06:45] <chernals> Hey guys. Allow me to raise your attention to this question on SE I'd really like to know more about: [<-LINK->] 
[2016-10-02 16:44:36] <PriyankaUppu_twitter> Hello all, am new to Docker. I try to build using the command "docker build -tfilename" but i get an error "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?" and I\'m running it on Mac. Can someone help me pleasE?
[2016-10-02 18:14:06] <jaksky> Hello, running docker native on windows and when starting environment via docker-compose it is complaining that port for various containers is already bind. The only process bind to that port is docker process - butdocker ps -adoesn't show any other running container. Even restart of docker doesn't help. Any hints?
[2016-10-02 18:58:17] <jaksky> Found it, missing share options for directories
[2016-10-03 06:17:59] <SalahAdDin> I have a big question: is useless instal docker and docker-machine in a server? or local, whatever... Because i see that docker-machine install inside his own docker image.
[2016-10-03 06:18:18] <SalahAdDin> But, i don't understand very well it.
[2016-10-03 08:01:55] <hholst80> What is the added benefit of usingtiniin our containers? When should we consider using it?
[2016-10-03 08:02:02] <hholst80>  [<-LINK->] 
[2016-10-03 09:29:42] <marcelmfs> hholst80: I use it everywhere.
[2016-10-03 09:30:42] <marcelmfs> otherwise you'd have to do signal handling inside the entrypoint script to forward SIGTERM/KILL/INT/STOP
[2016-10-03 10:59:38] <InfoSec812> marcelmfs: Finally catching up to your comment from a few days ago... We are using BTRFS after having problems with using AUFS and then DeviceMapper. In the earlier cases we kept hitting inode exhaustion. BTRFS, on the other hand, has been very stable for operation but slowly uses more and more space until the partition reaches 100%.
[2016-10-03 11:00:45] <InfoSec812> The only solution we have been able to come up with is to: Stop Docker, Unmount partition, reformat partition, remount, start docker, and finally reload containers.
[2016-10-03 11:00:57] <InfoSec812> Not a very good workflow.
[2016-10-03 11:24:23] <marcelmfs> hey@InfoSec812, is the kernel version 3.13? what's the context?
[2016-10-03 11:28:55] <InfoSec812> marcelmfs: Kernel is 4.7.5, btrfs-progs 3.19, Docker 1.12.1
[2016-10-03 11:29:06] <InfoSec812> Running on CentOS 7
[2016-10-03 11:29:36] <InfoSec812> But it looks like the btrfs-progs needs to be updated. I will see what I can do about that.
[2016-10-03 11:33:30] <InfoSec812> marcelmfs: The general situation is that when we first deploy our containers they use ~3.5GB of space on our/var/lib/dockerBTRFS partition. After about 72 hours we are at ~200GB with the same containers deployed (no restarts of container, no new containers deployed)
[2016-10-03 11:36:51] <marcelmfs> But are you sure your containers aren't using that space because of legitimate reasons? if you have a database container or an app that heavily downloads things or caches repositories or something?
[2016-10-03 11:39:42] <InfoSec812> marcelmfs: We mount external volumes for all "output" (e.g. /var/log).
[2016-10-03 11:41:29] <InfoSec812> CRAP! I think I just figured it out!!find /var/lib/docker/btrfs/subvolumes/ -mmin -$((60*40))found a HUGE number of core dumps from one of our applications!
[2016-10-03 11:42:54] <marcelmfs> :)
[2016-10-03 11:43:33] <marcelmfs> combined with docker\'s "always restart" policy
[2016-10-03 11:43:39] <marcelmfs> or, always coredump!
[2016-10-03 11:44:10] <InfoSec812> marcelmfs: Actually, we use supervisord inside of the container to restart applications and then let the container die if the restarts are too frequent.
[2016-10-03 11:45:07] <InfoSec812> But it looks like the application dies about once/hour, which is not frequent enough for the whole container to die.
[2016-10-03 11:45:21] <InfoSec812> Each core dump is >1.5gb
[2016-10-03 11:45:35] <InfoSec812> That explains SO MUCH!
[2016-10-03 11:46:47] <InfoSec812> Yep! Deleting the core files gets us back down to ~3.5GB.
[2016-10-03 11:46:59] <marcelmfs> Nice you've figured it out... as per your kernel version and docker context it didn't ring any bells for btrfs, as btrfs only works well for kernels newer than 3.13.
[2016-10-03 11:55:29] <InfoSec812> marcelmfs: Yeah, we had upgraded our kernel about 9 days ago in our efforts to resolve.
[2016-10-03 12:02:44] <marcelmfs> I'd recommend version 4.4 fromkernel-ltinstead ofkernel-mlbut it's fine if you already have latest mainline version.
[2016-10-03 12:06:49] <InfoSec812> marcelmfs: Thanks for the advice... 4.7.5 has been stable so far..
[2016-10-03 12:06:59] <InfoSec812> But I will keep that in mind..
[2016-10-03 13:31:01] <pyemkey> Hello. I've tried to find answer for my question on SO, docker forum but all answer doesn't work for me. Or maybe I don't understand something. I've created volumes for mysql docker image and what I read is problem with permissions. My docker-compose file looks [<-LINK->] and error what I am getting is[ERROR] Could not use /Users/cubi/data/mysql/log/cubi_tv.log for logging (error 2). Turning logging off for the whole duration of the MySQL server process. To turn it on again: fix the cause, shutdown the MySQL server and restart it.Any idea how to solve it?
[2016-10-03 13:37:07] <aseoparson> Are you sure you have access to/var/log? Might be a permissions issue
[2016-10-03 13:38:33] <aseoparson> Try storing the logs to the mysql data folder/var/lib/mysql/and see if it works. If it does, you don’t have permission to access/var/log
[2016-10-03 13:52:37] <pyemkey> asaparson: Please correct me if I'm wrong.$PWD/data/mysql/log:/var/log/mysql. When we map this value we can say thatHOST:CONTAINER. I don't have idea how to setup/Users/cubi/data/mysql/log/cubi_tv.logto be writable for container.
[2016-10-03 14:03:48] <pyemkey> btw I've changed as you said before and still the same
[2016-10-03 18:59:56] <WellingtonBraga> marcelmfs: Hi Marcel. A few days ago we were talking about use gulp live reload to automatically rebuild application in docker container without the use of docker cp. I am working to get this done, but I have a doubt about it. If I use gulp live reloading, everytime that I make a change in my application, will gulp reload the entire container? I mean, I have a container running, then I save the file, after that gulp will identify this change, kill the running container and re-start it again? If the answer is yes, what kind of problems I can have assuming this approach (if there are problems with this approach)?
[2016-10-03 20:38:20] <SalahAdDin> Anyone can explain me?
[2016-10-04 00:38:21] <rbuckland> SalahAdDin: you need to install docker using the following suggestions - [<-LINK->] 
[2016-10-04 00:40:28] <rbuckland> docker/for-mac the new beta was released over the weekend, 1.12.2-rc1-beta27 which resolves an issue for self-signed SSL Certs [<-CODE->]  [<-CODE->] 
[2016-10-04 00:41:45] <rbuckland> and is that [<-ISSUE->] an internal number that we cannot see info on ? or is it elsewhere
[2016-10-04 07:19:46] <miha-> Hi, I am quite new with docker . I have pulled some container from hub. Now I do not know how to set more space for this container as it is out of space. tnx for help ( [<-LINK->] )
[2016-10-04 08:20:13] <marcelmfs> WellingtonBraga: no, not to restart the whole container. Gulp would run inside the container and monitor changes on files on a folder mapped from the host to the container, and then reloading your app when you save changes.
[2016-10-04 09:12:31] <pinguinjkeke> Hi! Is anyone using docker for mac? I have file sync problem. osxfs is too slow :(
[2016-10-04 09:12:57] <anextro> Hi, can someone suggest or point me to a link to setting up docker for a group of developers?
[2016-10-04 10:28:21] <anextro> Does it make sense to include ARG <value> in a docker file?
[2016-10-04 11:02:31] <yuriyf> hi all
[2016-10-04 11:08:11] <anextro> hi@yuriyf
[2016-10-04 11:32:38] <WellingtonBraga> marcelmfs: Ok. Thanks a lot for your answer. I'll keep trying and I'll let you know when I get this done.
[2016-10-04 11:46:04] <marcelmfs>  [<-LINK->] 
[2016-10-04 12:58:02] <damaarten> miha-: how do you see that the container is out of space? As far as I know, containers use the host's disk space (host = the computer that your Docker is running on). So if the container is out of space, that would mean your host is out of space.
[2016-10-04 12:58:58] <anextro> damaarten: You can specify the space your docker container will run on.
[2016-10-04 12:59:04] <anextro> using the -m option
[2016-10-04 12:59:34] <anextro> Also you can usedocker statsto see the memory statistics of the running containers in your host machine
[2016-10-04 13:00:26] <damaarten> anextro: I was answering@miha-. Thanks for your suggestions. Please direct them also to@miha-
[2016-10-04 13:40:22] <rtacconi> miha-: they have just added a new feature in Docker regarding the space used by containers [<-ISSUE->] 
[2016-10-04 14:14:55] <jackmahoney> hello. on linux is there support for connecting to a webserver running on thelocalhost(not a container)from within a container?
[2016-10-04 14:15:19] <jackmahoney> i tried binding ports but the ports are already in use by the webserver
[2016-10-04 14:15:42] <anextro> by connect what do you mean?
[2016-10-04 14:15:50] <jackmahoney> i mean send an http request
[2016-10-04 14:16:02] <jackmahoney> from inside a container to outside the container to my localhost webserver
[2016-10-04 14:16:49] <rtacconi> if you are inside a container localhost will point to the container's loopback interface, so I do not make sense to me. You could use the host's IP
[2016-10-04 14:16:59] <anextro> I think its possible to make any http call to any IP addr from within the container
[2016-10-04 14:17:21] <jackmahoney> sure, i can use ifconfig and get my ip but that value is usually dynamic
[2016-10-04 14:17:26] <jackmahoney> was wondering if there was a simpler way
[2016-10-04 14:18:04] <jackmahoney> (a way that is easily reproducable for a team too - not having them parse their ifconfig output, for instance)
[2016-10-04 14:18:06] <rtacconi> start the container with an environment variable with the IP the you want to use
[2016-10-04 14:19:05] <jackmahoney> yeah that could work
[2016-10-04 14:19:29] <jackmahoney> although knowing that ip with certainty within a shell script seems difficult
[2016-10-04 14:20:17] <jackmahoney> alternatively i tried just running my local webserver within a container but ran into issues because the server is a local development server and has filewatchers that reload the server etc
[2016-10-04 14:20:28] <jackmahoney> and unfortunately, for unknown reasons this didn't pan out
[2016-10-04 14:20:34] <jackmahoney> thanks for the help anyway
[2016-10-04 14:20:39] <rtacconi> ifconfig eth0 | grep "inet addr" | cut -d \':\' -f 2 | cut -d \' \' -f 1try this
[2016-10-04 14:20:59] <anextro> rtacconi: what does this do?
[2016-10-04 14:21:09] <jackmahoney> ha, i appreciate that script, it feel quite hacky tho
[2016-10-04 14:21:20] <rtacconi> gets the IP address of eth0
[2016-10-04 14:21:28] <rtacconi> see the beginning
[2016-10-04 14:21:44] <jackmahoney> i think eth0 is not reliable tho
[2016-10-04 14:21:55] <jackmahoney> it could be tun0 for instance
[2016-10-04 14:22:20] <jackmahoney> but i think im shaving a yak as it is
[2016-10-04 14:22:35] <rtacconi> well that depends on how your system is configured. Usually for service discovery Consul or similar are used
[2016-10-04 14:32:19] <jackmahoney> ok, thanks anyway
[2016-10-04 14:33:09] <marcelmfs> you can always fetch the ip of the default gateway of the internal docker network (it will always point to an interface at your docker host)
[2016-10-04 14:33:13] <marcelmfs> or, docker0
[2016-10-04 14:33:55] <rtacconi> ah docker0 I did not think about it!
[2016-10-04 14:34:42] <anextro> Does docker0 give the correct ip addr of the host machine ?
[2016-10-04 14:34:48] <marcelmfs> from within the container:$ ip r | grep default | awk '{print $3}'
[2016-10-04 14:35:27] <marcelmfs> if your nginx on the docker host is set to bind to all interfaces,0.0.0.0then it will also listen to requests on docker0
[2016-10-04 14:36:38] <marcelmfs> here's the thing [<-LINK->] ;)
[2016-10-04 16:18:43] <memasdeligeorgakis> Hi, a quick question to confirm that i have understood correctly:after the below, I was expecting to see the content of /var/www/htdocs on my local Osx /Users/pathOnMyOsx [<-CODE->] 
[2016-10-04 16:19:09] <memasdeligeorgakis> Did i understand the functionality wrong?
[2016-10-04 16:19:52] <memasdeligeorgakis> so my goal was to mount to an existing container
[2016-10-04 16:21:18] <memasdeligeorgakis> after this when i inspect my new runnign container i can see the paths correctly, but on my local Osx i cannot see any content in the folder, even though in the container /var/www/htdocs has content
[2016-10-04 17:39:17] <yuriyf> hi all
[2016-10-04 17:39:33] <yuriyf> How I can change default docker network ?
[2016-10-04 17:39:46] <yuriyf> 172.0.0.0/24
[2016-10-04 17:40:40] <yuriyf> I use vpn tunnel where my subnet  is 172.x.x.x networks )
[2016-10-04 17:56:49] <ciminuv> Hi everyone, I am developing a Rails application running onDockerwith all dependence services listed in docker-compose. And I am going to deploy the app to production server using docker cloud, question is do I need to move all the dependence services (e.g Postgree, Redis) from docker-compose.yml toStackfile?
[2016-10-04 17:57:28] <yuriyf> hi
[2016-10-04 17:58:24] <yuriyf> you can use  docker-compose.yml.j2 for templete
[2016-10-04 17:58:39] <yuriyf> docker+ansible ) is very good
[2016-10-04 18:01:42] <ciminuv> Not sure I am understand you correctly. could you send me a link?
[2016-10-04 18:02:44] <yuriyf> What do you need ? Do you  have create deploy for project ?
[2016-10-04 18:06:25] <ciminuv> Yes. everything work great in my local machine right now, I am going to deploy the app to production server which required multiple servers, load balancing…
[2016-10-04 18:07:13] <ciminuv> And I found Docker Clould is something that I am looking for.
[2016-10-04 18:09:05] <yuriyf> xmm   I use [<-LINK->] only  for  source code and config filesmy docker containers is olways on serversif you have remove containrs you can use tower
[2016-10-04 18:10:00] <yuriyf>  [<-LINK->] 
[2016-10-04 18:11:21] <yuriyf>  [<-LINK->] 
[2016-10-04 18:22:50] <ciminuv> Thanks for your recommendation but I still prefer Docker Cloud better.
[2016-10-04 18:22:54] <ciminuv>  [<-LINK->] 
[2016-10-04 18:25:44] <yuriyf> ok
[2016-10-04 18:26:33] <ciminuv> So, the question is remain, to use Docker Cloud do I need to move services listed in docker-compose.yml to docker-cloud.yml? if yes, what is the best practice for the job to save other developers time on install dependence services (eg: Postgree, Redis, etc) on development?
[2016-10-04 18:27:06] <yuriyf> sorry but I use only frre open source code
[2016-10-04 18:29:55] <yuriyf> What you need move all conteiners ?
[2016-10-04 18:31:30] <yuriyf> redis - use onlny for session and cachenginx -  don't  need movephp -  also
[2016-10-04 18:31:45] <yuriyf> you need  move only DBs - postgres or mysql
[2016-10-04 18:32:18] <yuriyf> but you cant use backup db
[2016-10-04 18:59:50] <SalahAdDin> docker is needed for install docker-machine
[2016-10-04 19:01:16] <yuriyf> SalahAdDin: he uses  docker services )
[2016-10-05 05:51:36] <nischay30> my question is how to use docker-compose with docker swarm.
[2016-10-05 05:52:55] <nischay30> my scenario is that  i want to deploy ten instances of same service in different docker-machines which are in a swarm and i want to deploy them in specific machine by giving specific IP..so help me please how to do it
[2016-10-05 06:08:22] <kschlesselmann> nischay30: But isn't the whole point of a docker swarm that you don't care about specific nodes in the end?
[2016-10-05 06:13:28] <nischay30> kschlesselmann: actually i want to deploy 3 instances or more at different nodes but i want to control on which nodes it will be deployed
[2016-10-05 06:15:32] <kschlesselmann> nischay30: I'm not experienced with docker swarm but normally you define some kind of policy in the swarm and then just deploy your service. The swarm should take care that it deploys everything according to your policy … your deployment should never worry about specific nodes …
[2016-10-05 06:16:21] <nischay30> how to write the swarm policy with docker compose up
[2016-10-05 06:21:43] <nischay30> kschlesselmann: how to write the swarm policy with docker compose up
[2016-10-05 06:31:24] <kschlesselmann> nischay30: No idea. As I said: I've got no experience with docker swarm. But that's the way I'd expect it to go … because I don't want to know about nodes and such if I use some kind of cluster/cloud
[2016-10-05 06:32:23] <nischay30> kschlesselmann: ok..Actually i am trying to build deployment platform on which anyone can deploy his/her project
[2016-10-05 06:33:39] <kschlesselmann> Yeah … so just create some cloud and use some load balancing mechanism …
[2016-10-05 14:02:13] <intellix> had to Reset Docker OSX to factory settings again today -.-
[2016-10-06 02:34:38] <chan_seeker_twitter> guys i am arch user and i wanna try out docker swarm so i found docker toolkit on net but the thing is there is no docker toolkit package for linux
[2016-10-06 02:34:44] <chan_seeker_twitter> how can i do it?
[2016-10-06 08:41:40] <marcelmfs> use ubuntu
[2016-10-06 11:34:10] <chan_seeker_twitter> marcelmfs: dude i am arch user and i love it
[2016-10-06 11:42:04] <kschlesselmann> chan_seeker_twitter: Then just install docker and go? Why would you need docker toolkit?
[2016-10-06 12:34:16] <chan_seeker_twitter> kschlesselmann: With only docker i can't  docker swarm which requires VM,machine which we can get in the docker toolkit
[2016-10-06 14:25:06] <kschlesselmann> Can't you just run multiple swarms on your Host?
[2016-10-06 15:49:26] <chan_seeker_twitter> nope
[2016-10-06 15:52:47] <andersonkyle> I\'m trying to figure out how to build a Dockerfile that start a Java Application AND the Filebeat service for logging.  It seems that CMD and Entrypoint only want to accept a single executable.  Any ideas on how to accomplish this?This is my current Entrypoint:ENTRYPOINT ["java","-Djava.security.egd=file:/dev/./urandom","-jar","/app.jar"]
[2016-10-06 15:53:48] <andersonkyle> How would I add:service filebeat start
[2016-10-06 16:03:44] <matszym> I'm trying to understand what happens in docker-compose.yml, in volumes section: [<-CODE->] The first one mounts my project into docker container - but what exactly second line does?In docker file I copied package.json in order to run npm install, with generates node_modules directory - so does it works like ignore node_modules folder and use the one that was created in container?
[2016-10-06 17:38:10] <tuxity> Hello guys! A question, how I can do to optimize the push of a large image (~1.5Gb) to a private registry ? At the beginning it was quick, but now pushing all layers take a lot of time
[2016-10-06 17:38:32] <tuxity> I saw an blog post [<-LINK->] but dunno if  it's the better way
[2016-10-06 17:45:14] <tuxity> Maybe I have to clean my images on the registry too
[2016-10-06 18:31:40] <xialvjun> how to mount a windows directory
[2016-10-06 18:33:13] <xialvjun> I userdocker run -it -v "D:\\\\workspace:/root/workspace" python bashis not ok
[2016-10-06 19:13:50] <xialvjun> Oh, it is the shared drive's problem...I found it.
[2016-10-06 20:16:42] <damaarten>  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2016-10-06 23:41:20] <jo-sm> Hey guys, I'm a bit confused how to access a private registry via a SOCKS proxy. I've set the registry as insecure and I try to runALL_PROXY=socks5://localhost:1080 docker push <image>and it doesn't work (and no logs on the other end), but when I do CURL the registry with the same proxy,ALL_PROXY=socks5://localhost:1080 curl http://<my_registry>/v2/it returns the expected{}. How can I push an image via a SOCKS proxy?
[2016-10-07 00:14:50] <jo-sm> Is this even possible? There doesn't seem to be much/any documentation on this, and the only thing I have found that would seem to work is tunneling a specific port over SSH, rather than tunneling the whole connection and using it as a SOCKS proxy
[2016-10-07 01:29:38] <jo-sm> Yeah, when I change the proxy settings in the Mac app to use the SOCKS proxy, it says connection refused:http: error connecting to proxy http://localhost:1080: dial tcp [::1]:1080: getsockopt: connection refused
[2016-10-07 13:20:45] <Ekt0s> Hi!
[2016-10-07 13:22:13] <Ekt0s> Can somebody help me, I'm having trouble connecting my docker server to my jenkins server It appear that Jenkins cannot contact the docker server 
[2016-10-07 13:28:53] <marcelmfs> paste your compose file, otherwise it's black magic trying to advice you.
[2016-10-07 13:29:57] <marcelmfs> but you probably needports: 8080:80
[2016-10-07 13:30:06] <marcelmfs> or-p 8080:80
[2016-10-07 22:05:01] <andersonkyle> damaarten: Yeah I understand that generally containers should be single-purpose but there are ancellary functions such as logging agents or discovery server agents that also commonly need to run alongside your application.  I'll take a look at using  a shell script.  Thanks!
[2016-10-08 00:31:32] <enavarrocu> Guys I want to map a host directory to a running container, how I can do that?
[2016-10-08 01:42:33] <pauljlucas> hey im working with nodejs and ive tried a few different base images but keep having the same problem, when i do a docker run i always get back that localhost unexpectantly closed the connection. Also if i try a curl i get Server aborted the SSL handshake. I am using https on node (and only want to use https). Any tips around this?
[2016-10-08 08:18:30] <Serkan-devel>  [<-LINK->] 
[2016-10-08 09:38:13] <enavarrocu> anybody here?
[2016-10-08 09:41:23] <MadLittleMods> enavarrocu: What have you tried?
[2016-10-08 09:47:47] <damaarten> enavarrocu: ...
[2016-10-08 09:49:10] <damaarten> enavarrocu: As far as I know this is not possible. You have to create another container with
[2016-10-08 09:50:04] <MadLittleMods> damaarten: If you are using the Gitter UI, you can edit your last message with the up arrow or clicking edit from the...dropdown in the top-right of every message.
[2016-10-08 09:50:11] <MadLittleMods> enavarrocu: related todocker/docker#10975\nhttps://jpetazzo.github.io/2015/01/13/docker-mount-dynamic-volumes/
[2016-10-08 09:52:02] <damaarten> MadLittleMods: Thanks but 'edit message' is not available on iPhone web interface
[2016-10-08 09:52:33] <MadLittleMods> damaarten: Double/triple tap the message (Android user but kinda familar with the iOS app)
[2016-10-10 07:35:19] <enavarrocu> damaarten: @MadLittleModsThank you guys
[2016-10-10 07:35:39] <enavarrocu> I just create the container again.
[2016-10-10 07:35:47] <enavarrocu> But now I have another issue
[2016-10-10 07:37:21] <enavarrocu> In a Dockerfile I have this
[2016-10-10 07:39:09] <enavarrocu>  [<-LINK->] 
[2016-10-10 07:39:38] <enavarrocu> the file is copied as root so I can't write on it from inside of the container
[2016-10-10 08:05:42] <matszym> enavarrocu: So, coping going fine, but you dont have acces to file, when using other user than root in the container? If thats the case, change ownership of the file, to other user, that one you are using
[2016-10-10 08:07:04] <enavarrocu> matszym: yes but I can't change the ownership
[2016-10-10 08:07:36] <enavarrocu> I tried with the Dockerfile, don't work
[2016-10-10 08:08:06] <enavarrocu> also inside of the container getting Illegal Operation if I don't remember wrong
[2016-10-10 08:08:28] <enavarrocu> I can't test right now, but later I can try again and give better feedback
[2016-10-10 08:08:39] <matszym> enavarrocu: Are you changing the ownership while logged in as user thats owner of the file?
[2016-10-10 08:09:22] <matszym> @enavarrocu hers part of my docker file [<-CODE->] notice i change ownership before switching to the nodejs user
[2016-10-10 08:10:45] <enavarrocu> yes I tried that already but didn't work, I can't remember right now why, I will try again later when I have access to the machine and give you the exact details
[2016-10-10 08:11:04] <enavarrocu> thanks for your time
[2016-10-10 09:29:44] <enavarrocu> matszym: I'm able to test now. This is the image I'm using [<-LINK->] 
[2016-10-10 09:30:07] <enavarrocu>  [<-CODE->] 
[2016-10-10 09:30:12] <enavarrocu> this is my docker  file
[2016-10-10 09:30:41] <enavarrocu> as you can see here the chown didn't work
[2016-10-10 09:30:46] <enavarrocu>  [<-CODE->] 
[2016-10-10 16:55:14] <tiivik> Hey! A general question about Docker. Does the docker image and host OS share input-output devices? What I have in mind is that I want to send a message to COM port with Python to manipulate an external device (ardunio) but would like to run the code inside Docker image?
[2016-10-10 21:20:09] <sbbowers__twitter> I'm dockerizing my development environment, which consists of multiple web services running on different domains.  I have it working in bridged mode and docker sets up DNS resolution for the services to talk to each other, which is great.  the problem I'm having is that there doesn't seem to be a good way to set DNS locally that can point to the containers in the bridged network. I can enumerate the IPs bydocker inspectand manually configure hosts file entries, but the IPs change and shift around as services are started/stack is rebooted.  Are there any tools to handle this?
[2016-10-11 07:33:30] <marcelmfs> tiivik:  [<-LINK->] 
[2016-10-11 07:34:03] <marcelmfs> check for CAP_SYS_ADMIN and see if you can assign the capabilities to a container to talk serial.
[2016-10-11 07:34:45] <marcelmfs> Allow access to the nvram device    Allow administration of apm_bios, serial and bttv (TV) device\nAllow manufacturer commands in isdn CAPI support driver    Allow reading non-standardized portions of pci configuration space\nAllow DDI debug ioctl on sbpcd driver    Allow setting up serial ports
[2016-10-11 07:56:54] <marcelmfs> sbbowers__twitter: you should be able to start different services in different networks using thenetworkdirective of compose files, the name of the network could be your different domains and then docker will create the right DNS for you.
[2016-10-11 07:57:32] <marcelmfs> tiivik: disclaimer - I never used serial capabilities in docker
[2016-10-11 08:44:40] <tiivik> marcelmfs: Cheers
[2016-10-11 11:14:18] <mluis> Hi! Is it possible to share the iSight camera with docker?
[2016-10-11 12:09:38] <marcelmfs> it's a/dev/somethingright?
[2016-10-11 12:10:07] <mluis> it’s the macbook camera
[2016-10-11 12:33:07] <Erovia> hi guys, the arm experimental repo gives me "Hash sum mismatch" error, does anybody else experiences this?W: Failed to fetch https://apt.dockerproject.org/repo/dists/debian-jessie/experimental/binary-armhf/Packages  Hash Sum mismatch
[2016-10-11 12:35:35] <marcelmfs> mluis: that will be tricky as you'll have to export your device to the xhyve vm where docker machine runs
[2016-10-11 12:35:43] <marcelmfs> I don't know how to proceed with that
[2016-10-11 12:36:45] <mluis> yep, I’m also with that in mind..
[2016-10-11 12:54:40] <sbbowers__twitter> marcelmfs: You mentioned defining networks using the network directive. I created and configured "networks.default.external.name = my-stack". How does docker expose the containers to the host machine? I need something like a DNS record "container1.my-stack" (or something I can associate with my services)
[2016-10-11 12:55:21] <sbbowers__twitter> I will add that internally, everything in the stack has DNS records for "container1", etc.
[2016-10-11 12:57:20] <sbbowers__twitter> So my stack works, I'm just having trouble configuring my host environment to be able to talk to it sanely.
[2016-10-11 13:15:25] <marcelmfs> ah, you want docker to add/alter entries on your local network DNS?
[2016-10-11 13:18:29] <marcelmfs> I think you'll have to use something like consul's forwarding to achieve what you want: [<-LINK->] 
[2016-10-11 15:53:50] <sbbowers__twitter> Yes, I just want a sane way to configure hostnames in my local environment to point to the docker hostnames on the bridged network.  I'll take a look at consul
[2016-10-11 20:32:20] <desprit> Hi guys! What is a "true" way to switch between using service as docker container and using service standalone? For example I have a python-flask api container which is connected to redis container likeredis:6379. But when I want to do some tests on api, I run it without docker and Im no longer able to connect to redis withredis:6379, instead, I uselocalhost:6379. I feed like doing something wrong :)
[2016-10-11 20:33:49] <desprit> using host network on all containers could be a workaround but i wanted to do it some other way
[2016-10-12 09:24:37] <marcelmfs> if youdocker run -p 6379 redisit\'s the "same" as running redis onlocalhost:6379, you don\'t need--net=hostfor that to work.
[2016-10-12 10:19:49] <MathiasRenner> Docker docs do not offer a command that restores containers to a node that had crashed and is now back up and running (in Docker Swarm Mode).service updateandscaledoes not work. Anyone?
[2016-10-12 15:30:35] <desprit> marcelmfs: "if youdocker run -p 6379 redisit\'s the "same" as running redis onlocalhost:6379"no, if I\'d do-p 6379it wouldn\'t work. I will be able to connect to redis container bylocalhostfrom host machine only if I run it with-p 6379:6379
[2016-10-12 16:12:58] <tuxity> Hey guys, I'm wondering, what's the best OS option to run docker ? I mean debian have an old kernel and some storage driver are not in the kernel
[2016-10-12 16:13:22] <tuxity> ubuntu maybe if I want to stay on a debian based os
[2016-10-12 16:13:40] <tuxity> but it's stable in prod environement ?
[2016-10-12 17:21:29] <jdevillard> Hello, I\'m starting using Docker! I used Docker For Windows and would like to test Monitoring Container that allow me to monitor Docker like cAdvisor, but I\'ve got the following error in the container : "nable to connect to Docker: Cannot connect to the Docker daemon. Is the docker daemon running on this host?" I can access to the Rest API of the Docker Daemon on [<-LINK->] using Fiddler on my host but I don\'t succeed to configure any container to call this daemon. So my question is, is it possible to do this with docker on windows ? (or only on linux) and If so, does anyone already done this? Thanks a lot
[2016-10-13 09:59:14] <nimrodshn> Hey everyone I am attempting to create a docker container for development purposes. I have a directory on my machine and am trying to mount it to the relevant directory inside the docker container using: docker run -v local/path/here:container/path/here container_image
[2016-10-13 09:59:28] <nimrodshn> But unfortunately this Isn't working. I suspect this is because the Docker dir I'm attempting to mount is symbolically linked to two other directories inside the container - does this mean my local dir should also be linked to those directories?
[2016-10-13 10:40:42] <pinguinjkeke> Hey, is somene using docker for mac? Any news with file io speed?
[2016-10-13 10:49:01] <V3ckt0r> Hey@jdevillard,
[2016-10-13 10:49:35] <V3ckt0r> which port are you using to monitor your container
[2016-10-13 10:49:50] <V3ckt0r> you might not have the port exposed on the container
[2016-10-13 10:52:46] <V3ckt0r> nimrodshn: - sounds like you might be better off mounting the volume in your docker file. check out resource here [<-LINK->] 
[2016-10-13 10:56:13] <V3ckt0r> tuxity: - are you trying to start a war with that question? ^_^ . OS fanboys might go flaming about which os is best lol. Personally I use ubuntu and CentOS/RHEL 7 in production.
[2016-10-13 10:59:42] <nimrodshn> V3ckt0r: it seems to be equivilent according to the docker documentation:
[2016-10-13 10:59:54] <nimrodshn> Note: You can also use the VOLUME instruction in a Dockerfile to add one or more new volumes to any container created from that image.
[2016-10-13 11:20:50] <V3ckt0r> nimrodshn: -  yes that is correct. I do most the mounting through this mechanism as oppose to the way you are doing it.
[2016-10-13 11:28:14] <nimrodshn> V3ckt0r: and then you use 'docker build ... '?
[2016-10-13 11:37:11] <V3ckt0r> nimrodshn: yes either rebuild your container and add the volume mount. or just use the ADD directive to add just the files you want.
[2016-10-13 12:04:30] <jdevillard> V3ckt0r: , I'm not sure about your question. cAdvisor is deployed using the image google/cadvisor:latest. What I understand is that the App cAdvisor communicate with the Docker Dameon (located outside the container, in the host) and allow cAdvisor to get info about all the container of the platform (name, image, metrics, etc). So for me the container doesn't need to open any port for this, but maybe I'm wrong.
[2016-10-13 12:44:13] <marcelmfs> jdevillard: no, cAdvisor uses a trick which is to mount the docker named pipe socket file from the host so that whenever it writes http requests to the named pipe docker on will answer with all containers information
[2016-10-13 13:19:05] <jdevillard> marcelmfs: hum, ok, So I've to found how to mount the docker named pipe socket file when my environment is Docker For Windows ?
[2016-10-13 20:11:59] <jdevillard> ok, so nevermind!, It's seems that I misconfigured the container ... :( everything is ok and I succeed to configure the container. Thanks
[2016-10-14 10:01:25] <swelham> Just after some opinions here. When deploying a web app wrapped in a container, do you deploy nginx in the container or on the host machine?
[2016-10-14 10:01:38] <swelham> Any pros/cons either way?
[2016-10-14 10:01:56] <glend> I would run another nginx container.
[2016-10-14 10:03:37] <swelham> That would make much better sense!
[2016-10-14 10:03:46] <Jamlee> swelham: if you just used as a load balance ,maybe can try haproxy
[2016-10-14 10:06:02] <Erovia> If you want load-balancing and reverse-proxying, I can vouch for Traefik
[2016-10-14 10:06:22] <swelham> Jamlee: yeah I am considering haproxy as I haven't used it before
[2016-10-14 10:06:36] <swelham> Erovia: I will definitely check that out
[2016-10-14 11:30:12] <Onyx74> hello guys,  what did we do about this problem?During operation of Docker Cloud there was detected vulnerability which caused fail of Nodes and stak.Fail was caused by disconnection of server and Nodes docker cloud (server side).For setting the certificates it is required to open 443 port on server. There were set up iptables, added a rule, but systemctl restart of iptables leads to break of all the connections.After that STAK on Docker Cloud has failed. Redeploy had no results. We recreated all stak. After while the main Nodes has fell off.Solution.We managed to recover operability of DockerCloud only by restarting of dockercloud-agent.service on server.Nodes HealthWe are re-assembling the new stak (as old one doesn’t run containers).The most interesting is that break of connection between server and Dockercloud leads to 100% stak’s fail (which shall be assembled again, redeploy has no results, containers don’t run).PS: Testing shown, that at any breakage of connection between docker agent and docker cloud it is required to manually assemble all stak from the beginning.There is a problem, after stak’s fail containers don’t link and detect each other by name (only by IP).
[2016-10-14 12:57:33] <marcelmfs> That's why I won't jump to a new service provider before some years of hardening and troubleshooting. I'd stick with what I know works for me, like Co-location/(AWS|GCC)/Linode/DigitalOcean (in order of reliability, maturity, proven record).
[2016-10-14 12:58:49] <marcelmfs> never used Rackspace/OVH/cloudscale, although I've heard are good providers.
[2016-10-14 16:58:58] <WellingtonBraga> Hi guys, my team is facing a trouble with  docker-toolbox
[2016-10-14 17:00:12] <WellingtonBraga> The quickstart is not finding IP during the initialization process. The exit status is 255 and the message is: "Error getting ip address: Something went wrong running the SSH command!"
[2016-10-14 17:00:52] <WellingtonBraga> Has anyone faced the same problem? How we can solve this ? Thanks in advance.
[2016-10-14 22:23:38] <NickStefan> How does one pipe into a docker command? for example something likedocker exec 106338bf484c pg_restore -U myname < STREAM FROM HOST
[2016-10-14 22:24:08] <NickStefan> the docker container just hangs waiting for empty stdin
[2016-10-17 08:14:21] <mgangelov> hello, I'm trying to build an image from Dockerfile, which includes copying some files using the COPY statement. The files I'm trying to copy are there , however I am getting: [<-CODE->] 
[2016-10-17 08:15:39] <mgangelov> I am using Docker 1.12.1 and I was able to previously copy files (probably on version 1.12)
[2016-10-17 08:45:06] <Erovia> mangelov95: are the files are in the same directory as the Dockerfile?
[2016-10-17 08:46:19] <mgangelov> Erovia: No, they are in the /etc directory, however previously I was able to copy files from there. I also tried copying a file from the same directory as the Dockerfile and I still get the same error.
[2016-10-17 11:57:59] <daavidkllr> Hei @all,does anyone know why i am not able to enter the docker bash?command: docker exec -i -t <container name> /bin/basherror: rpc error: code = 2 desc = oci runtime error: exec failed: exec: "/bin/bash": stat /bin/bash: no such file or directory
[2016-10-17 12:07:29] <radriaanse> daavidkllr: Try another shell (like /bin/sh), looks like the conatiner doesn't have bash in place
[2016-10-17 13:01:36] <marcelmfs> NickStefan: usecat SQL | docker exec -i pg_restore -U myname(-i opens the stdin filehandle)
[2016-10-17 14:52:26] <ankibalyan> Hi Folks
[2016-10-17 14:55:28] <ankibalyan> can I create a replica set from docker-compose.yml file?
[2016-10-17 14:55:39] <ankibalyan> how?
[2016-10-18 09:15:05] <kilient> i pull the mysql image from docker.io, and run it with -v parameter to store the data external the container,
[2016-10-18 09:15:21] <kilient> but got the error, Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock'
[2016-10-18 09:15:34] <kilient> how could i fix it, thanks
[2016-10-18 09:20:54] <renuka25165> i am looking for golang developer
[2016-10-18 14:33:08] <bhicks> is there a good way to use the output from a command run on the local host, or local host environment variable, on a container?
[2016-10-18 14:33:44] <bhicks> my goal is to copy the host’s git configuration file into the container
[2016-10-18 17:10:50] <ksylvan> Can't you just -v mount the git config files to the container on docker run?@bhicks
[2016-10-18 18:19:22] <bhicks> yeah i guess i can. thanks for the suggestion, still a little new to this :)
[2016-10-19 13:20:28] <jackrabb1t> Friends, I am trying to find the location of the docker images on a mac, and the locations as suggested in searches on StackOverflow such as /var/lib/docker do not exist on my machine. [<-CODE->] Is there a way to find the physical location? TIA!!
[2016-10-19 14:22:09] <radriaanse> Don't own a Mac, but does the second answer here help? [<-LINK->] 
[2016-10-19 14:22:19] <radriaanse> jackrabb1t: 
[2016-10-19 15:10:57] <jackrabb1t> @radriaanse  : thank you for replying. [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2016-10-19 15:30:05] <radriaanse> jackrabb1t: Now that I look at the docs, it's seems that there are 2 ways to install under Mac. Did you use [<-LINK->] or [<-LINK->] ? The latter one uses xhyve instead of virtualbox
[2016-10-19 15:44:28] <jackrabb1t> @radriaanse  : I used the former ( docker-toolbox )It asked to update virtualbox, which I did.
[2016-10-19 21:14:00] <remram44> I'm wondering if there is a way to hide the Docker socket behind some other client that is safe for users to use, i.e. would disallow --privileged, use the user's user namespace, and only allow volumes to be mounted under the user's home directoryit doesn't seem very hard (just a proxy?) but I can't find anything like thatIt seems that work is being done towards authorization plugins but is not quite done yet (I found [<-LINK->] but seems to need more work)
[2016-10-20 07:51:57] <marcelmfs> jackrabb1t: docker-machine sshand thencd /var/lib/docker
[2016-10-20 10:10:35] <LanderU> Hi, how I can create my own Docker private hub?
[2016-10-20 10:15:19] <gwmoura> LanderU: you can use docker registry image
[2016-10-20 10:17:02] <LanderU> gwmoura: thanks
[2016-10-20 12:48:08] <jackrabb1t> @marcelmfs  thank you for your reply.the following steps allowed me to get there: [<-CODE->] however, it was not clear to me how I would be able to copy a file ( say a data.sql file ) to this image.( the standard postgres docker container in this case )I was expecting to be able to scp this files to the image as an update, and then run psql passing in the script.Am I missing a few steps?
[2016-10-20 14:16:18] <SlimxaQ> Hey,Someone can help me on Private Chat?
[2016-10-20 14:47:10] <marcelmfs> jackrabb1t: you can alsossh $(docker-machine ip), and do anything ssh is able to with the information of what's the docker-machine ip
[2016-10-20 14:47:59] <marcelmfs> docker-machine scp file.sql default:/tmp
[2016-10-20 14:50:46] <marcelmfs> and finallydocker-machine help
[2016-10-20 15:08:14] <marcelmfs> jackrabb1t: you don't have to ssh or scp anything to docker-machine. you can do it all using the docker client itself.
[2016-10-20 15:08:28] <marcelmfs> if you want to copy a file from host to container, justdocker cp file.sql container:/tmp
[2016-10-20 15:09:14] <marcelmfs> or evencat file.sql | docker run -it my_postgresql psql -U postgres database
[2016-10-20 16:18:08] <rsvp> I locally retagged an official debian image as rsvp/jessie andpushed it to docker.io as my public repo, however, that failed in "Retrying in ..."as it  tried to actually upload the bulk. All the necessary layers should already be pre-existing at Docker\'s hub, hence expected behavior would be no uploading necessary. What is going on with latest  Docker version 1.12.2, build bb80604? Is there a permission problem?
[2016-10-20 16:28:15] <marcelmfs> restart your docker-machine
[2016-10-20 19:21:02] <jackrabb1t> @marcelmfs  : thank you. [<-CODE->] 
[2016-10-21 07:56:03] <Shane0531> hello i have  a one question
[2016-10-21 07:56:39] <dearfrankg> how do you delete an image on dockerhub from the CLI
[2016-10-21 07:57:32] <Shane0531> i use docker hub and bitbucket automated build
[2016-10-21 07:58:02] <Shane0531> why push and build 3 images??
[2016-10-21 08:00:53] <Shane0531>  [<-LINK->] 
[2016-10-21 08:01:39] <Shane0531> like this
[2016-10-21 08:09:24] <marcelmfs> jackrabb1t: maybe you could trycat file.sql | docker run -i my/postgresql psql -U postgres database
[2016-10-21 09:17:03] <hamedb89> Hey guys, I have a problem mounting my local folder with docker-compose. Anybody having the same problem on OSX?
[2016-10-21 09:29:17] <marcelmfs> hamedb89: what's the error? Have you added the folder to the File Sharing docker preferences?
[2016-10-21 10:37:57] <hamedb89> When i try to set the folder in which my docker-composer.yml and my Dockerfile are as a volume which is supposed to be stored in /var/www/html for instance, It wont work.Even if I check manually via shell while the container is up and running.
[2016-10-21 10:39:58] <hamedb89> marcelmfs: I dont wont to use an ADD“ from wihtin the dockerfile because I need to be able to change the files live, while the container is running, since its going to be a dev environment.
[2016-10-21 11:10:12] <hamedb89> marcelmfs: I think I have figured it out :)
[2016-10-21 14:00:04] <xialvjun> I have a container server listening 2424 and 2480 and binded to the host machine.   And then I want an other container client to connect the server, how should I do ?
[2016-10-21 20:50:50] <vyscond> HEy guys, is it possible to assign random ip address with arbitrary ports at a docker-compose file? I want to launch to service using the 80 port but i dont mind using another IP. Right now i'm using'80:80'which makes the container use the0.0.0.0:/ so the second container is failing  because the address is already in user ;-;
[2016-10-22 12:14:25] <gwmoura> vyscond: you need to use a proxy server on port 80 and map yours services on docker-compose as subdomains.
[2016-10-22 12:15:37] <gwmoura> Ex: you can use a ngix running on 80 and configure he to access api and web using a subdomain web.local.dev api.local.dev
[2016-10-22 12:18:36] <gwmoura> xialvjun: you can explain more your doubt?
[2016-10-22 14:31:48] <hamedb89> Hey guys, I am not sure if it is correct to seperate webserver an app into seperate containers . Especially in regards of the docker volumes.
[2016-10-22 14:32:06] <hamedb89> What is the best practice in that case?
[2016-10-22 17:25:42] <xialvjun> @gwmoura thank you, and I have found the solution.  My problem was : [<-CODE->] 
[2016-10-22 18:22:34] <Speechkey_twitter> Hi folks, is it possible to install convoy on macOS?
[2016-10-22 18:44:52] <Jamlee> artem: Macos can not install native docker like linux. it must use hypervivor.
[2016-10-22 18:49:39] <Jamlee> the convoy is the front-end adapter to docker for variant back-end storage such as glusterfs.
[2016-10-22 20:15:29] <rsvp> I locally retagged an official debian image as rsvp/jessie and pushed it to docker.io as my public repo, however, that failed in "Retrying in ..." as it  tried to actually upload the bulk. All the necessary layers should already be pre-existing at Docker\'s hub, hence expected behavior would be no uploading necessary.Created issue  #27659
[2016-10-23 14:01:07] <zombiQWERTY> Hello everyone [<-CODE->] Here is a part of my service config in docker-compose:https://gist.github.com/zombiQWERTY/1c1d2da813e9401ac55c448a43876f50
[2016-10-23 14:02:28] <ameukam> zombiQWERTY: what is the result of 'ls -l ./Docker/dev/Dockerfile' ?
[2016-10-23 14:03:29] <zombiQWERTY> ameukam: -rw-r--r--  1 zombiQWERTY  staff  522 Oct 23 02:30 ./Docker/dev/Dockerfile
[2016-10-23 14:04:08] <ameukam> hum. curious.
[2016-10-23 14:04:40] <Erovia> zombiQWERTY: you can just do:build: ./path/to/dir
[2016-10-23 14:04:54] <Erovia> it will find the Dockerfile automatically
[2016-10-23 14:05:35] <zombiQWERTY> Erovia: my sources are above Dockerfile
[2016-10-23 14:05:58] <ameukam> dev:\n  build:./Docker/dev/
[2016-10-23 14:06:36] <zombiQWERTY> Ok, I am trying
[2016-10-23 14:06:51] <zombiQWERTY> ERROR: Cannot locate specified Dockerfile: Dockerfile
[2016-10-23 14:07:01] <zombiQWERTY>  [<-CODE->] 
[2016-10-23 14:08:27] <zombiQWERTY> $ docker --versionDocker version 1.12.1, build 6f9534c
[2016-10-23 14:08:52] <zombiQWERTY> $ docker-compose --versiondocker-compose version 1.8.1, build 878cff1
[2016-10-23 14:10:59] <zombiQWERTY> I have been trying to deside this issue for three days
[2016-10-23 14:16:45] <zombiQWERTY> Any thoughts?
[2016-10-23 14:16:53] <ameukam> do you have specified the version of your docker-compose file ?version: '2'
[2016-10-23 14:17:01] <zombiQWERTY> Yep
[2016-10-23 14:17:06] <zombiQWERTY> I have
[2016-10-23 14:17:13] <Erovia> im sure it must be something trivial
[2016-10-23 14:17:18] <Erovia> that makes it hard to spot
[2016-10-23 14:17:22] <Erovia> could you please do anls -R
[2016-10-23 14:19:24] <zombiQWERTY>  [<-LINK->] 
[2016-10-23 14:19:52] <zombiQWERTY> If need I can provide docker-compose.yml and Dockerfile
[2016-10-23 14:20:39] <rbuckland> zombiQWERTY: yes - paste it up somwhere so we can see it "in context"
[2016-10-23 14:21:21] <zombiQWERTY>  [<-LINK->] 
[2016-10-23 14:21:47] <zombiQWERTY> There is docker-compose and Dockerfile
[2016-10-23 14:25:52] <Erovia> i'm not seeing anything obvious :/
[2016-10-23 14:26:54] <zombiQWERTY> Me too. And this is very weird
[2016-10-23 14:27:32] <Erovia> anyway, can you build the images bydocker build -f ./Docker/dev/Dockerfile?
[2016-10-23 14:27:56] <zombiQWERTY> Let me try
[2016-10-23 14:31:01] <rbuckland> @zombiQWERTY no issue with my test - I stripped your sample back.https://gist.github.com/rbuckland/80da3b31dd26c6a2088b91b87428e66a
[2016-10-23 14:31:28] <zombiQWERTY> Erovia:  [<-CODE->] 
[2016-10-23 14:31:53] <rbuckland> add a "." at the end
[2016-10-23 14:32:11] <Erovia> sorry i forgot that
[2016-10-23 14:32:58] <zombiQWERTY> Thanks. It's building
[2016-10-23 14:34:45] <ameukam> can you try to downgrade your version of docker-compose ? to 1.8.0 ?
[2016-10-23 14:35:59] <zombiQWERTY> Give me several minutes
[2016-10-23 14:41:55] <zombiQWERTY> How to install specific version of docker-compose on mac?
[2016-10-23 14:41:58] <zombiQWERTY> ameukam: 
[2016-10-23 14:43:54] <Erovia> you can grab it from github: [<-LINK->] 
[2016-10-23 14:45:00] <ameukam> don't forget to uninstall your current version before. :-)
[2016-10-23 14:51:25] <zombiQWERTY> With version 1.8.0 similar issue
[2016-10-23 14:56:47] <Erovia> okay, time for a mindless trial&error test, what happens when you put the Dockerfile in the same dir as the docker-compose and modify the compose file accordingly?
[2016-10-23 15:00:04] <zombiQWERTY> It works when Dockerfile is in the same dir
[2016-10-23 15:03:13] <Erovia> interesting, what happens if the Dockerfile is right inside the Docker dir?
[2016-10-23 15:05:06] <zombiQWERTY> Second
[2016-10-23 15:05:43] <zombiQWERTY> The same issue
[2016-10-23 15:07:21] <zombiQWERTY> What's wroooong
[2016-10-23 15:07:28] <zombiQWERTY> I am being crazy
[2016-10-23 15:07:38] <Erovia> ill be AFK for a while, will try to help you if you cannot solve it in the meantime
[2016-10-23 15:07:51] <zombiQWERTY> Okay, thank you
[2016-10-23 20:17:12] <zombiQWERTY> Any more thoughts?@Eroviaare you here?
[2016-10-23 20:34:53] <zombiQWERTY> There is full info [<-ISSUE->] 
[2016-10-23 20:49:47] <zombiQWERTY>  [<-ISSUE->] 
[2016-10-23 22:13:52] <rbuckland> zombiQWERTY: did you find the answer ? I noticed you closed [<-ISSUE->] 
[2016-10-24 12:15:04] <agustinvinao> quick question about docker+rails: I have my container working with a rails app, when I update a file in my rails app I see the file changed in the container but my rails app doesnt update if I do a new request. The rails server is running in development env, it should update any code change, anyone has an idea whats it should be the issue?
[2016-10-24 12:16:02] <glend> i dont know rails, but if the file inside the container is changed, then it's not a docker issue
[2016-10-24 12:17:57] <agustinvinao> yeap, I eas assuming is not a docker issue, but i cant find the problem, rails is running in development mode, and is working as production environment
[2016-10-24 12:18:54] <glend> maybe this rails app is caching something regardless of what environment you set
[2016-10-24 14:22:51] <JnMik> Hey guys quick question regarding docker for windows, i\'ve been using docker for a year now on linux and it is marvelous. Now I\'m trying to use it as well on my gaming pc, on windows. Docker for windows is pretty much straight forward and works way better than it used to, but I still have issue with SSH key. (Mounting my windows ssh key into the container via volume makes the permissions over chmod 600 and using composer install resolve in an ssh error "SSH keys are too open".Probaly some kind of NTFS / linux problem or something..My collegue is having the same issue and fixing this could be major plus for us and the company where we work.We tried with the SSH_AGENT_SOCKS as well without success.Anyone can help me out on this ?
[2016-10-24 14:26:55] <JnMik> I've even tried using cygwin to changes permissions but it did not work, and it's clearly not an acceptable solution for me even if it would have worked. Way too much overhead.
[2016-10-24 15:10:24] <Erovia> zombiQWERTY: sorry, i had to run some errands yesterday, work today, so still haven't had the chance to test things
[2016-10-24 15:10:39] <Erovia> did you managed to solve the issue in the meantime?
[2016-10-24 21:21:42] <justinhj_twitter> JnMik: are you able to work around having to copy ssh keys to your container? Depending on your use case you could probably just use the exec command to execute a shell, run processes etc
[2016-10-25 08:36:08] <felixheck>  [<-CODE->] Node-Backend: hapi\nJS-Frontend: angular\nMongoDB database [<-CODE->] 
[2016-10-25 08:56:36] <felixheck> Here are further information and file contents: [<-LINK->] 
[2016-10-25 12:12:24] <daCodez> Hello, I have just setup a VM with RH Linux Enterprise to use as a testing environment for publishing docker containers.  I've installed docker and I can  create containers but how can I get it to assign IP addresses to my containers so that I can test connections to the containers?
[2016-10-25 13:07:34] <JnMik> justinhj_twitter: If I copy SSH keys into the container, they'll stick there or I'll have to code some kind of shell to remove them. Feels like useless work. I don't have this issue on my ubuntu host.
[2016-10-25 13:41:10] <marcelmfs> don't ssh into your container, it's not necessary to have sshd running. justdocker exec -it my_container bash
[2016-10-25 14:03:40] <JnMik> marcelmfs: The SSH keys I copy into the container is not for remote ssh connexion, I need it to install dependencies (composer install)
[2016-10-25 14:04:46] <JnMik> They are only there during the build time (On the bamboo server), then the image is released in production without the ssh volume
[2016-10-25 17:28:28] <daCodez> Has anyone installed docker-machine on Redhad Linux Enterprise before?
[2016-10-25 17:30:09] <daCodez> I'm trying to use the following command : curl -L [<-LINK->] -s-uname -m` >/usr/local/bin/docker-machine && \\ chmod +x /usr/local/bin/docker-machine but I keep getting permission denied
[2016-10-25 18:30:42] <kalahari> daCodez: do you have write permissions on /usr/local/bin/docker-machine?
[2016-10-25 18:44:39] <daCodez> kalahari: how would I find out?  I'm really new to linux
[2016-10-25 18:49:51] <daCodez> I've even tried using sudo -i and still get the same permissions error
[2016-10-25 19:12:48] <kalahari> sudo won't work with an output redirect
[2016-10-25 19:13:31] <kalahari> I suggest you download the file to your home directory, set the execute bits on it, and then use sudo to move it to /usr/local/bin
[2016-10-25 20:07:09] <daCodez> can't seem to get it to work
[2016-10-25 21:41:00] <brendonsteg_twitter> hey
[2016-10-25 21:41:10] <brendonsteg_twitter> I have a question and I need help with it
[2016-10-26 07:49:56] <deviantony> Hi guys, we recently released Portainer : a simple management UI for Docker. You can have more information here: [<-LINK->] (we also have a demo if you want to try it). We'd love your feedback ! You can ask me any questions ;)
[2016-10-26 07:52:28] <kraulain> sweeeeet  
[2016-10-26 12:59:18] <kschlesselmann> Currently I'm trying to set up a CI workflow here. I'd like to use Jenkins from a docker container but my builds should be able to use docker as well. Should I try to get a dind oder dood approach working nowadays?
[2016-10-26 13:06:55] <marcelmfs> dood is what I'm currently using from CI agents to launch builds, tests and deployment/integration/end-to-end tests
[2016-10-26 13:07:12] <marcelmfs> which is basically just being able to write to the host's docker socket
[2016-10-26 13:43:15] <kschlesselmann> marcelmfs: Exactly. I read that you now have to install all docker tools in the container though … in order to to so I'd have to create a custom container based on jenkins:latest which installs docker and then mount my hosts docker.sock as a volume in the container, or?
[2016-10-26 13:48:43] <marcelmfs> no no, I don't do any of that, I just-v /path/to/docker.socket:/var/run/docker.socketwhen instantiating the CI agent image
[2016-10-26 13:49:13] <marcelmfs> you gotta have the docker binary also, so I also have-v /path/to/bin/docker:/usr/bin/docker
[2016-10-26 13:59:59] <damilare> docker-compose port not working for me
[2016-10-26 14:00:51] <damilare> docker port service01 returns 8000/tcp -> 0.0.0.0:9000 but visisting localhost:9000 gives me connection refused
[2016-10-26 14:00:56] <damilare> anything else I need to do ?
[2016-10-26 14:24:57] <marcelmfs> are you using docker for osx?
[2016-10-26 14:25:16] <damilare> yeah i am, thanks i figure i’d to go via boot2docker’s ip
[2016-10-26 14:25:30] <marcelmfs> yes $(docker-machine ip)
[2016-10-26 16:09:50] <adewes> Hi! I have a question regarding the internal DNS server: Is it possible to connect to it from the host operating system? I want to build a CI setup with docker containers, and I'd like to be able to connect to a given host in a Docker network using its internal name (as given by  Docker), but I can't figure out how to resolve the hostname. Connecting via IP address works fine btw.
[2016-10-26 16:11:45] <adewes> It seems that the DNS server only listens on the local interface: [<-LINK->] 
[2016-10-26 20:04:39] <MadMub> Hey everyone, total docker/ops noob. I have to run a docker container with the following flags--cap-add SYS_ADMIN --cap-add MKNOD --device=/dev/fuse --security-opt apparmor:unconfinedThis is to be able to mount an amazon s3 bucket vias3fs. What are the security implications of what I just did. Any tips is greatly appreciated.
[2016-10-26 21:20:14] <dearfrankg> on osx: I can run nginx on my home laptop and get to it using my domain_name (configured in the router)when I run my docker nginx I can get to it with curl localhost but not using my domain nameif I shut off my macbook's firewall I can get to it.How can i configure my macbook's firewall to work with docker?
[2016-10-27 02:57:44] <mozinrat> hi everyone, can some one point to me how to use dynamic cpu setting, i have docker-compose setup of spark and i want to allocate 1 dedicated cpu per container, one thing i can think of is i can copy paste executer image part n number of times and the provide cpuset as 0,1,2 for each different. I want to figure out if there is technique with docker -compose.
[2016-10-27 07:18:49] <kschlesselmann> marcelmfs: Hm … I read something like docker isn't statically linked any more so you have to install the tools in your container as well. Can I even suppose that the docker of my host (Ubuntu 16.04) will work as expected in my jenkins container (which is itself openjdk8 which boils down to debian jessie I think)?
[2016-10-27 08:22:56] <jinseokoh> Hello room. A total docker noob here.  I want to specify a command-line parameter todocker runinside of docker-compose.yaml. more specifically, I addeddocker-oracle-xe-11gto docker-compose.yaml file. when Idocker-compose up -d oracle. it runs without the parameter ( -e ORACLE_ALLOW_REMOTE=true ) I want. how to specify that parameter in the yaml file?
[2016-10-27 08:23:29] <glend> that's an environment variable
[2016-10-27 08:24:22] <glend> see [<-LINK->] how to add these
[2016-10-27 08:24:53] <jinseokoh> glend: Oh, is that it? alright. thanks!
[2016-10-27 10:06:07] <jinseokoh>  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] But it's not working. What do I miss?
[2016-10-27 10:06:41] <kschlesselmann> ORACLE_ALLOW_REMOTE: true
[2016-10-27 10:06:44] <kschlesselmann> Try it like thi
[2016-10-27 10:07:42] <glend> it should work both ways
[2016-10-27 10:08:45] <jinseokoh> kschlesselmann: I tried that way too. but, did not work for me.
[2016-10-27 10:20:39] <gwmoura> jinseokoh: what's the message error?
[2016-10-27 10:22:26] <jinseokoh> gwmoura: No error there. it just doesn't allow me to access the Oracle DB.
[2016-10-27 10:24:52] <gwmoura> You can paste the log messages when you rundocker-compose up?
[2016-10-27 10:28:17] <jinseokoh> gwmoura: I will try...
[2016-10-27 10:33:05] <gwmoura> Ok@jinseokoh. Looking your docker-compose.yaml, the config is correct and should run. Probaly can be a problem on docker network or another service is using the port.
[2016-10-27 10:45:05] <kschlesselmann> jinseokoh: Well do you even need this? What are you trying to do?
[2016-10-27 10:46:24] <kschlesselmann> It looks like it only flips:
[2016-10-27 10:46:35] <kschlesselmann>  [<-CODE->] 
[2016-10-27 10:46:46] <jinseokoh> kschlesselmann: Im just trying to figure out how docker-compose.yaml works as a noob
[2016-10-27 10:47:10] <kschlesselmann> jinseokoh: OK, and why do you think it doesn't work as expected?
[2016-10-27 10:48:48] <jinseokoh> kschlesselmann: with the docker run command I can access to oracle, but the 2nd one didn't allow me to do so. so thats where my question comes from
[2016-10-27 10:50:03] <kschlesselmann> @jinseokoh Well that sounds more like a wrong port mappingI use [<-CODE->] here
[2016-10-27 10:50:20] <kschlesselmann> (That binds the port to localhost as well
[2016-10-27 10:50:51] <jinseokoh> i'm going to stick with the docker run command at least for now until I learn more about docker. thank you all anyway.
[2016-10-27 10:53:29] <gwmoura> jinseokoh: follow this steps:
[2016-10-27 10:54:24] <gwmoura> 1 -docker ps- check If exists containers running in background using the Oracle port
[2016-10-27 10:54:59] <gwmoura> 2 - If yes, stop the container and rundocker-compose up
[2016-10-27 10:55:25] <gwmoura> If you do this before, reject my messages 
[2016-10-27 11:16:16] <V3ckt0r> Hey guys
[2016-10-27 11:16:30] <V3ckt0r> Looking for some help with the docker registry api v2.0
[2016-10-27 11:17:03] <V3ckt0r> how would you go about finding out what images you have stored in your private registry?
[2016-10-27 11:17:43] <V3ckt0r> I don’t believe GET /v2/_catalog endpoint is supported in 2.0. Think this comes along in v2.1
[2016-10-27 11:19:13] <V3ckt0r> would the only way be to ssh to the server and look under the docker/registry/v2/repositories location manually?
[2016-10-27 12:53:26] <StielEiche> Hello World!
[2016-10-27 13:01:43] <RanjithThavamaniraj> Hello team. Just started learning Docker and new to the group
[2016-10-27 13:28:48] <StielEiche> Welcome Ranjith
[2016-10-27 14:28:12] <landsman> Hello guys!I have problem with container run. Can you help me please? [<-CODE->] 
[2016-10-27 14:43:18] <pea> I saw you could in theory use Wordpress with Docker. But how would that work, given that you can’t really version control a whole Wordpress site with git?
[2016-10-27 14:44:04] <glend> You could, there are examples of running Wordpress in a scaling environment.
[2016-10-27 14:50:08] <pea> I’ll have a read
[2016-10-27 16:39:43] <PaulReiber> landsman: your kernel needs to be newer probably
[2016-10-27 19:00:57] <smuthali> Is is the correct chat room to post questions for Docker on Mac?
[2016-10-27 23:29:33] <galvesribeiro> guys, anyone is having this issue [<-ISSUE->] ? I'm unable to connect to Docker for Windows  using the remote APIs... any workaround?
[2016-10-28 09:05:20] <mark-norgate> Hi there. Where can I find service status messages for Docker? I'm getting a timeout trying to login from my client.
[2016-10-28 09:24:25] <marcelmfs>  [<-LINK->] 
[2016-10-28 09:25:20] <mark-norgate> Thanks@marcelmfs
[2016-10-28 09:25:26] <mark-norgate> So I wonder why I can't login
[2016-10-28 09:25:39] <marcelmfs> docker hub web is having issues
[2016-10-28 09:25:48] <mark-norgate> Oh.
[2016-10-28 09:26:07] <mark-norgate> I found the URL it was hitting and that wasn't the hub.
[2016-10-28 09:26:15] <mark-norgate> Don't know enough about the setup.
[2016-10-28 10:32:41] <mark-norgate> Is it possible to configuredocker downloadto use a single chunk, rather than the ten or so it currently uses? My upload speed is pretty poor and it keeps timing out.
[2016-10-28 12:31:09] <marcelmfs> you meandocker pull, and sometimes (at least in versions prior to 1.12), I had to restart the docker machine for the download to not suck timeouts
[2016-10-28 20:26:25] <matrixbot> dsthi, hello there, do we can: docker run gnome - on small distros like coreos, ...?
[2016-10-28 20:26:34] <matrixbot> dstor kde w.e.
[2016-10-29 05:01:40] <nischay30> hey anybody tell me how to call the docker api through postman or through my express server?
[2016-10-29 10:33:11] <syscools> nischay30 send an http request to /var/run/docker.sock
[2016-10-30 12:49:27] <thanosme> Hello. I try to link wordpress to mysql in a user defined network and it doesn' t seem to work. It works in the default network. Any ideas?
[2016-10-30 15:42:14] <keatontaylor> Oh docker how I love you.
[2016-10-30 15:42:38] <keatontaylor> I am in the process of dockerizing my NAS server.
[2016-10-30 15:42:56] <keatontaylor> All services within containers for higher security, easier updating, etc.
[2016-10-30 15:43:31] <keatontaylor> Debian base OS, with zfs and docker installed and made into a live CD.
[2016-10-30 15:44:36] <keatontaylor> so the debian host that the docker engine is installed on essentially remains as small as possible.
[2016-10-30 15:44:44] <keatontaylor> and clean
[2016-10-31 09:13:02] <MaximZavitaev> Hi. Someone uses Docker on Windows?
[2016-10-31 10:29:38] <dearfrankg> public ports working for docker-for-mac hosts but not with docker-machine hosts  -- help
[2016-10-31 10:30:34] <marcelmfs> Sometimesdocker-machine restartit's the only way to restore virtualbox's networking
[2016-10-31 10:31:03] <marcelmfs> Other times when that isn't enough, you'll have to recreate docker-machine
[2016-10-31 10:32:28] <dearfrankg> marcelmfs: thanksI forgot to mention my docker-machine hosts where made with docker-machine-driver-xhyve so no virtual-box here
[2016-10-31 10:35:53] <marcelmfs> restart docker then
[2016-10-31 10:36:30] <dearfrankg> yeah, I've tried that reinstalled from scratch a few times
[2016-10-31 10:41:03] <marcelmfs> So it might be another problem, maybe your macbook is already using the network socket that docker is trying to bind to?
[2016-10-31 10:41:49] <marcelmfs> the weird thing is that docker-for-mac also uses xhyve
[2016-10-31 10:42:14] <marcelmfs> so if you're using docker-machine with xhyve driver, that shouldn't be any different (but I might be wrong)
[2016-10-31 11:03:25] <dearfrankg> marcelmfs: I think I found the answer here: [<-LINK->] 
[2016-10-31 11:06:46] <dearfrankg> it seem the container port gets mapped to the docker-machine port as opposed to the laptop's portso in my case: 192.168.64.21:5000 instead of 127.0.0.1:5000so I can use nginx to map the laptop's port to the docker-machine portgiving it a try
[2016-10-31 11:14:14] <JackTiger> docker run -p 9000:9000 --name minio1 \\-v /mnt/export/minio1:/export \\-v /mnt/config/minio1:/root/.minio \\minio/minio server /export
[2016-10-31 11:15:00] <JackTiger> /export or /root/.minio is created in minio images？
[2016-10-31 11:15:49] <JackTiger> Then where does the command "server /export" defined, in minio images?
[2016-10-31 12:00:56] <dearfrankg> marcelmfs: FYI, that process I mentioned earlier worked for me.
[2016-10-31 12:06:20] <aios> MaximZavitaev: what are you asking for?
[2016-10-31 12:11:21] <fchevitarese> Morning peps!
[2016-10-31 12:12:08] <fchevitarese> Does anyone have an example of docker-compose file that persist data in postgres container? Thanks in advance!
[2016-10-31 12:12:40] <aios> fchevitarese: docker-commit
[2016-10-31 14:41:07] <MaximZavitaev> aios: Install Docker. After starting writesDocker is starting...more not what happens. In the logsbuild Local 7135 is as good as the 7135 on remote channel and Stablehanging
[2016-10-31 14:48:40] <aios> MaximZavitaev: look on hyper-v service is it on?
[2016-10-31 14:58:40] <MaximZavitaev> aios: Yes
[2016-11-01 08:43:17] <edmondo1984> I met the famigerated "failed to register layer: devicemapper: Error running deviceResume dm_task_run failed" on ec2. what\'s the correct workaround?
[2016-11-01 10:39:00] <damilare> V3ckt0r: Yo how do I put docker in docker?
[2016-11-01 10:39:38] <damilare> Does anyone have any success running docker-compose in jenkins in docker?
[2016-11-01 11:51:52] <singuerinc> damilare:  [<-LINK->] ?
[2016-11-01 11:52:37] <damilare> singuerinc: its says "This work is now obsolete"
[2016-11-01 12:28:18] <RedDevilHat> hi guys, have one question.i try work with docker on Windows 10.i do nowDockerfile [<-CODE->] docker-compose [<-CODE->] evrything start, but lokalhost send me 403 Forbidden
[2016-11-01 12:33:11] <brud> RedDevilHat:  [<-CODE->] 
[2016-11-01 12:34:09] <RedDevilHat> а в fpm volumes надо какие-то,
[2016-11-01 12:34:11] <RedDevilHat> ?
[2016-11-01 12:34:16] <RedDevilHat> brud: 
[2016-11-01 12:34:16] <brud> and infpmyou need add your app in volumes
[2016-11-01 12:34:21] <brud> да)
[2016-11-01 12:34:24] <RedDevilHat> )
[2016-11-01 12:34:36] <RedDevilHat> т.е. сделать секцию app?
[2016-11-01 12:34:49] <RedDevilHat> сча попробую
[2016-11-01 12:49:37] <RedDevilHat> @brud [<-CODE->] и тут же вылетает
[2016-11-01 12:49:47] <RedDevilHat> т.е. контейнер стартует
[2016-11-01 12:49:53] <RedDevilHat> и выдает exit code 0
[2016-11-01 12:49:58] <RedDevilHat> без ошибок и логов
[2016-11-01 12:51:17] <RedDevilHat> compose сейчас такой
[2016-11-01 12:51:26] <RedDevilHat>  [<-CODE->] 
[2016-11-01 13:09:33] <RedDevilHat> Guys, sombady save my brain. [<-LINK->] 
[2016-11-01 13:10:06] <brud> RedDevilHat: virtualbox?
[2016-11-01 13:10:20] <RedDevilHat> стоит
[2016-11-01 13:10:44] <brud> RedDevilHat:  [<-LINK->] 
[2016-11-01 13:10:49] <RedDevilHat> однако на винде же он не работает с docker'ом
[2016-11-01 13:11:00] <brud> без этой статьи я бы не разобрался
[2016-11-01 13:11:39] <brud> сначала надо пробросить папки в вритуалбокс (в настройках), а потом из виртуалбокса выполнить команду
[2016-11-01 13:11:52] <brud> и только потом пробрасывать из виртуалбокса в докер
[2016-11-01 13:12:16] <RedDevilHat> brud: z ctqxfc cnhfiye. dtom crf;e
[2016-11-01 13:12:25] <RedDevilHat> я сейчас страшнуюю вещь скажу
[2016-11-01 13:12:28] <RedDevilHat> даж жве
[2016-11-01 13:12:40] <RedDevilHat> я не создавал докер машину
[2016-11-01 13:12:46] <brud>  [<-CODE->] 
[2016-11-01 13:12:47] <RedDevilHat> и в виртуалбоксе пусто
[2016-11-01 13:12:51] <brud> лоооол
[2016-11-01 14:24:34] <gurghet> hello
[2016-11-01 14:25:40] <gurghet> how do I launch a sibling docker within the same network?
[2016-11-01 14:28:23] <gurghet> алло?
[2016-11-01 14:57:58] <hlogeon> Граждане, а кто сталкивался с тем, что у контейнеров нет доступа к интернету?uname -a [<-CODE->] 
[2016-11-01 14:58:11] <hlogeon> docker info [<-CODE->] 
[2016-11-01 14:59:14] <hlogeon> Гугление не помогает. Запуск контейнеров с--network=hostне помогает
[2016-11-01 14:59:55] <gurghet> говорить на англиском помогает
[2016-11-01 15:00:26] <hlogeon> @gurghetNo problem.I have an issue with internet inside containers
[2016-11-01 15:00:42] <hlogeon> There is no access at all
[2016-11-01 15:01:26] <hlogeon> I've already tried to start containers with--network=hostoption
[2016-11-01 15:01:56] <gurghet> do ifconfig
[2016-11-01 15:02:01] <gurghet> ifconfig
[2016-11-01 15:02:04] <gurghet> post results
[2016-11-01 15:02:21] <hlogeon>  [<-CODE->] 
[2016-11-01 15:04:21] <hlogeon> ipv4 forwarding is enabled on both: host and containers
[2016-11-01 15:05:50] <gurghet> what command did you use to run the container?
[2016-11-01 15:06:00] <gurghet> did you used some flags?
[2016-11-01 15:07:07] <hlogeon> I've been trying different ways.Even simpledocker run -i -t ubuntudoesn't have internet access
[2016-11-01 15:09:25] <hlogeon> But my final target is to run my containers using docker-compose.compose.ymland Docker files are too big to post it here.
[2016-11-01 15:41:23] <hlogeon>  [<-CODE->]  [<-CODE->] Same file on host machine [<-CODE->] I had local DNS server(DNS masque) before and may be that is the reason. I found recipe on stackoverflow which saying to comment out [<-CODE->]  [<-CODE->] 
[2016-11-01 16:58:52] <aios> hlogeon: look at pm.
[2016-11-01 16:59:16] <aios> hlogeon: i know solve for you problem)
[2016-11-02 07:10:07] <Onyx74> Andrey, you should restart docker agent
[2016-11-02 08:12:12] <hlogeon> Onyx74: I did it couple times and no effect. After I come back home from my office everything started to work well. So I think the problem is in my office network(possibly there are some kind of proxy or something like that)
[2016-11-02 08:21:44] <danielwii> guys, is it possible to run ‘docker run exec -it <<id>> bash’ via docker remote api?
[2016-11-02 16:45:21] <krzysztof-magosa>  [<-LINK->] 
[2016-11-02 16:45:32] <krzysztof-magosa> i believe it's what you are looking for
[2016-11-02 20:03:30] <MaximZavitaev> Hi! How I can runphp-fpmservice?
[2016-11-02 20:04:42] <MaximZavitaev> RUN service php7.0-fpm startDon't work
[2016-11-02 20:37:35] <toughIQ_twitter> Run during build process can execute single commands and not start daemons like service. If you want a Container to run PHP-fpm at runtime, you have to use CMD PHP-fpm.
[2016-11-02 20:41:46] <MaximZavitaev> toughIQ_twitter: CMD ["php-fpm"]also tried. Says that php-fpm is not found in PATH
[2016-11-02 20:43:54] <toughIQ_twitter> How does your Dockerfile look like? How do you install PHP-fpm?
[2016-11-02 20:45:38] <MaximZavitaev> toughIQ_twitter:  [<-CODE->] 
[2016-11-03 05:46:03] <danielwii> krzysztof-magosa: I have tried that. but the stream not accept input...
[2016-11-03 10:50:56] <toughIQ_twitter> MaximZavitaev: if I run your build instructions, I get an gpg key error and the build fails. I assume you need this special build? because it would be way easier to go with the default php:fpm image from dockerhub. [<-LINK->] 
[2016-11-03 12:46:22] <olsynt> Can anyone help me to understand about volume drivers please
[2016-11-03 15:02:08] <colshacol> Allo, everybody. I am working on a project that is just giving me hell to clone the repo and get it set up. I was wondering if it is possible to use a Docker container while developing an app. I don't know much about Docker, but I know I'm over this other crap I've been doing all morning!
[2016-11-03 15:21:04] <toughIQ_twitter> colshacol: it depends on the project. ;-) but yeah, sure you could use a docker container.
[2016-11-03 15:21:54] <colshacol> toughIQ_twitter: Thank you, friend. It shouldn't be a problem to have the app running in a Docker container and be altering it simultaneously?
[2016-11-03 15:25:28] <toughIQ_twitter> depends on the app. if its an interpreted language, like php, you could do it on the fly, by just mounting your local working directory into the  container. if its something which has to be compiled in some way, you would have to rebuild the container to reflect changes. but since building is done via aDockerfile, you just have to write all the steps down one time and all setup steps will be done properly at build time.
[2016-11-03 15:27:23] <colshacol> The project my employer requests is a modification of https://github.com/grafana/grafana. It offers a Docker image, just didn't know if it was plausible to develop on top of it.I appreciate you. Last thing: Do you know where Docker, by default, stores the images it downloads?
[2016-11-03 15:32:40] <toughIQ_twitter> /var/lib/docker/image/*but its not really a human readable format ;-)
[2016-11-03 15:37:16] <colshacol> Then how am I supposed to develop within Docker! =P
[2016-11-03 15:40:18] <marcelmfs> if you\'re using virtualbox, you might face several drawbacks as sometimes the \'Shared folder\' between your workstation and virtualbox and the VM gets out of sync. If you\'re using xhyve or "native" virtualization you might be better off but still, there are some drawbacks on developing in osx or windows.
[2016-11-03 15:41:03] <marcelmfs> And, if you're having problems setting up your own dev environment locally, I wouldn't say it would be easier with docker anyhow...
[2016-11-03 15:41:17] <toughIQ_twitter> by a quick look I found a build script, which seems to create a container from your current, local source. But I am not sure how elaborate this is and how usable during development: [<-LINK->] 
[2016-11-03 15:41:46] <marcelmfs> you might want to take a look at [<-LINK->] 
[2016-11-03 16:52:58] <colshacol> So here is what I am currently thinking:I can take the Grafana Docker image, load it up on a container and mount local directories to it.
[2016-11-03 16:53:14] <colshacol> I can then edit my local code and have it persist in the running container.
[2016-11-03 16:54:57] <colshacol> Question: If I mount a volume-v local-dir:alias-on-container, can I override the container's directories? For example, if I want to work on the ./app directory in the container, could I mount my local ./app directory as ./app in the container and it'd run code from my local rather than the image?
[2016-11-03 16:57:02] <jnbnyc> yes-v ./app:/app
[2016-11-03 16:58:38] <colshacol> jnbnyc: thank you, sir.
[2016-11-03 17:00:36] <jnbnyc> a docker-compose.yml file really helps with local development, and I suggest settingWORKDIRin Dockerfile orworking_dirin docker-compose.yml; it will put you directly in that directory when youdocker exec it ...
[2016-11-03 18:05:10] <sauga84> hi
[2016-11-03 18:05:37] <sauga84> got a quick questn on entrypoint  -- my dockerfile has entrypoint defined with arguments..
[2016-11-03 18:05:50] <sauga84> how can i reference it in docker-compose.yml file
[2016-11-03 18:06:21] <sauga84> ENTRYPOINT  <command> --spring.profiles.active=$PROFILE
[2016-11-03 18:07:00] <sauga84> now chow can i pass $Prorfile argument in docker-compose yml or while running docker-compose up
[2016-11-03 18:17:59] <colshacol> Wtf. -_- Docker works fine, but out of nowhere my computer thinks Go is not installed, and when I try to install it it tells me it already is installed....
[2016-11-03 18:37:40] <toughIQ_twitter> @sauga84 try this way in docker-compose.yml: [<-CODE->]  [<-CODE->] 
[2016-11-03 19:08:30] <sauga84> ok. thanks Christian
[2016-11-03 19:09:04] <sauga84> toughIQ_twitter: but i dont need to specify my command..
[2016-11-03 19:09:13] <sauga84> correct..
[2016-11-03 19:09:44] <sauga84> under entrypoint i can directly specufy by argument shud work , rite as command is already placed in dokerFile
[2016-11-03 19:11:44] <sauga84> also i dont need to specify again in the docker-compose.yml as i already have that entrypoint defined in dockerFile..
[2016-11-03 19:12:07] <sauga84> i just need ti subtitute the value of "PROFILE" when i run docker-compose up
[2016-11-03 20:14:15] <sauga84> how do i scale my service with docker compose
[2016-11-03 20:14:35] <sauga84> it fails when i specify ports in compose-yml file. stating port is already used
[2016-11-03 21:02:55] <toughIQ_twitter> You cannot scale with ports specified. Need something like a loadbalancer or docker swarm.
[2016-11-03 21:07:15] <sauga84> docker-compose doesnt allow ?
[2016-11-03 21:07:58] <sauga84> there is option where we provide docker-compose scale "servicename=number"
[2016-11-03 21:08:07] <sauga84> doesnt this option work
[2016-11-03 21:09:53] <toughIQ_twitter> Yes. This works. But exposed ports forbid it. You can't bind more than one process to a port on the host. And since compose alone does not provide a loadbalancer or routing mesh, scaling will fail.
[2016-11-04 00:18:22] <oOthkOo> Hello Developers ! I am pleased to announce that you can now sign up to SlugBay beta - The biggest open platform of resources for developers ;-) Build your personal library !Register now !!https://www.slugbay.com
[2016-11-04 00:44:46] <frank-dspeed> Nice but google and other solve that also thx for the offer
[2016-11-04 08:49:43] <oOthkOo> frank-dspeed: How Google and other solve that ?
[2016-11-04 13:03:17] <frank-dspeed> oOthkOo: Same as you Query for the right Words
[2016-11-04 13:03:39] <frank-dspeed> or look coderwall or github.com
[2016-11-04 13:03:48] <frank-dspeed> dont matter its not related to here
[2016-11-04 13:13:27] <oOthkOo> frank-dspeed: On google, the developpers search and sort through thousands of results to find a dozen tools, frameworks etc ... on Slugbay the developers are no longer alone to Find a Good tools, framework, book, video etc .. To choose between 2 libraries that do the same thing, to keep notified of new tools, frameworks and co. I think it is important for a developer to constantly learn and for that he must be able to organize his knowledge
[2016-11-04 14:15:57] <marcelmfs> there should be a way of kicking people out of rooms if they don't comply with the rules, missing old #IRC sometimes...
[2016-11-04 14:16:11] <marcelmfs> get your advertise out of here dude
[2016-11-04 14:16:16] <marcelmfs> it just don't belong here
[2016-11-04 14:50:04] <marcelmfs>  [<-LINK->] <- GET OUT
[2016-11-04 18:37:14] <AdamScislowicz> Hi folks, I\'m having an issue w/ docker on an embedded platform. The error message is as follows (related to cpuset):docker: Error response from daemon: invalid header field value "oci runtime error: container_linux.go:247: starting container process caused \\"process_linux.go:258: applying cgroup configuration for process caused \\\\"failed to write 0-1\\\\n to cpuset.cpus: write /sys/fs/cgroup/cpuset/docker/cpuset.cpus: invalid argument\\\\"\\"\\n".uname -aLinux 38Z-rohvai 3.10.17-yocto-standard #1 SMP PREEMPT Wed Nov 2 21:32:33 PDT 2016 i686 GNU/LinuxI\'m using docker 1.12.0.
[2016-11-05 12:30:15] <netw0rm> hi
[2016-11-05 12:34:21] <netw0rm> how to use docker-plugin command
[2016-11-05 12:35:29] <netw0rm> how to install a plugin
[2016-11-07 08:40:54] <leon> Hi!I’m trying out docker cloud and I’ve got stuck with how to handle static file updatesI’ve got abackend - spring bootangular2 app packaged into a busy boxnginx using volumes_from angular2 appthis works but when I push a new version of the angular2 app it redeploys but nginx doesn’t update to the new version.I don’t want to have to redeploy the nginx service just to link in the new /var/www/html files.Any suggestions on how to get a good setup with data volumes and nginx?
[2016-11-07 10:02:33] <V3ckt0r> Hey@damilare,
[2016-11-07 10:02:40] <V3ckt0r> Check out [<-LINK->] ^_^
[2016-11-07 10:03:14] <V3ckt0r> sry about the late reply. Been up in Manchester
[2016-11-07 13:56:43] <am0nshi> hi gyus! can anyone help with next problem in swarm - making cluster from 2 physical machines, 1st one run swarm, manager and client, as key-value used consul. how can i setup second one, to organize all of containers from both physical servers into 1 network? currently we have 192.168.99.xx subnetwork on both servers, but both networks is local
[2016-11-07 14:54:05] <MadMub> Hey everyone, I am trying to setup a tcp proxy stack. Basically I will have one container that tcp proxies to an indefinite number of other containers
[2016-11-07 14:54:12] <MadMub> I get how linking works (i think)
[2016-11-07 14:54:48] <MadMub> but the problem is the second container type gets created and destroyed on the fly
[2016-11-07 14:55:34] <MadMub> is there a way to open up container to container communication, could one docker container list all the IPs of the other containers on the same network
[2016-11-07 14:55:34] <JnMik> Your main process in container should not run as daemon, docker container needs a process that stays up
[2016-11-07 15:23:14] <toughIQ_twitter> am0nshi: are you using the stand alone swarm? Since swarm mode in docker 1.12 solves all questions you asked.
[2016-11-07 16:47:17] <ysangkok> why is 1.12.2 linked from [<-LINK->] instead of 1.12.3?
[2016-11-07 16:47:42] <V3ckt0r> vec
[2016-11-07 20:24:22] <fabiofumarola> does node promotion in docker swarm work?
[2016-11-07 20:24:47] <fabiofumarola> I tried to promote a worker to manager and when in the promoted node I run docker node ls
[2016-11-07 20:24:59] <fabiofumarola> it returnsError response from daemon: This node is not a swarm manager. Worker nodes can't be used to view or modify cluster state. Please run this command on a manager node or promote the current node to a manager.
[2016-11-07 21:50:12] <toughIQ_twitter> fabiofumarola: but the first manager told you with node ls, that the node was successfully promoted?
[2016-11-08 08:45:44] <fabiofumarola> yes, but when I check to the nodes I can’t see the change [<-CODE->] 
[2016-11-08 09:33:39] <o3o3o> Hi,  does anyone use docker service create with command  likedocker run  image command? e.g:docker service create --name test  redis bash.  I want to start an temp container in swarm mode with the same network for debuging on production.
[2016-11-08 11:44:08] <ely029> Hey guys I am new here by the way I am ely. I have a server it is Ubuntu then I have my application that are installed in the  windows 7. I had download docker for windows 7 then I dont know how to deploy the application from my desktop to the server. I search for this kind of situation but the result is deploying the project in the digitalocean and other web hosting site. this project is intranet.can you help me out with this?thanks you so much
[2016-11-08 11:53:23] <ely029> docker: 
[2016-11-08 11:53:59] <ely029> joshmoore: @jeremyjs
[2016-11-08 13:31:47] <toughIQ_twitter> o3o3o: yes...I do sometimes. I built myself a simple debian container, where I put some debug tools into it.docker service create --name toolbox --network <aNetworkYouWantToAttachTo> --mode global toughiq/toolboxSo I have this toolbox container running on each node...connected to a network (if needed) to inspect stuff there.Sources here: [<-LINK->] 
[2016-11-08 13:38:30] <o3o3o> toughIQ_twitter: Thank your very much.   This may be   the only solution that build a debug tool container.
[2016-11-08 14:16:30] <toughIQ_twitter> @fabiofumarola I just tried promoting a worker to manager and it worked fine. I used this on the first manager to promote my second node to manager:Status before promotion: [<-CODE->] Promote command: [<-CODE->] Status after promotion: [<-CODE->] 
[2016-11-08 15:35:17] <colshacol> How can I boot up an.iso(Antergos Linux)` via Docker? -- Or, is that not within the capabilities of Docker?
[2016-11-08 15:57:35] <toughIQ_twitter> colshacol: Thats not within the scope of Docker. Docker doesnt boot or run operating systems. Docker just provides everything needed to run a specific process.
[2016-11-08 16:48:40] <fjcero> Hi, I'm trying to find some reference/doc/cookbook on how to Build images with ARG/ENV fetched from a config file or a command like sed
[2016-11-08 16:49:25] <fjcero> I didn't tried yet to mount a volume during Build time, but I'm looking for options
[2016-11-08 18:09:15] <sauga84> has anyone use fluentd to log the docker container o/p?
[2016-11-08 18:10:12] <sauga84> i have used key_name as log_message in the filter tag.. but when start the docker container , i get messages stating log_message does not exis
[2016-11-08 18:10:14] <sauga84> exist
[2016-11-08 18:17:13] <fabiofumarola> toughIQ_twitter: I tried but I can’t see the status Reachable
[2016-11-08 19:41:41] <toughIQ_twitter> fjcero: afaik this is not supported. the idea of docker is, that a Dockerfile or build process should work anywhere, so relying on some local environment is against this idea.Why do you want/need to mount a volume during build time? this does not make sense, since this volume wont be available at the time and place a container is run from this image.
[2016-11-08 20:46:41] <mshareghi> I'm trying to mount a /certs directory containing keystores and certs into a docker container using docker-compose, but when I do so the pfx keystore files end up empty (0 byte size). Any idea what's going on?
[2016-11-08 20:47:02] <mshareghi> The other certs appear to be unchanged
[2016-11-08 20:49:25] <mshareghi> I\'m using the volumes: "./certs/:/opt/wildfly/certs/:ro" where ./certs is correctly mapped to a my host folder. I\'m using windows 7 w/ virtualbox
[2016-11-08 20:50:07] <fjcero> toughIQ_twitter: I agree on what you say, I moved my idea to use --build-arg so I can read a file and setup ARG that will be used to manage the rest of the build process
[2016-11-08 21:03:16] <mshareghi> nevermind.. apparently my pfx keystores got zeroed out somehow
[2016-11-09 02:49:59] <o3o3o> Hi, all guys. I want to useiptablesto limit the expose port  of outside. Now I limit the expose port onINPUT chain, but the docker swarm mode useFORWARD chainto redirect the packet from outside or from container to container, from node to node.  We use docker swarm mode in our internal network with mutiple network interface, I want to know how  I limit theFORWARD chainwith specific exposed port ( whitelist of exposed port) ?
[2016-11-09 07:18:21] <o3o3o> I  inserted an limit chain into the head of FORWARD , now I can limit the connection from outside to docker by iptables. But, I found DOCKER_INGRESS is been inserted  into the head of FORWARD after restart docker service. :(
[2016-11-09 07:27:28] <o3o3o>  [<-LINK->] 
[2016-11-09 09:12:12] <ely029> what is the job of busybox??
[2016-11-09 09:12:32] <ely029> I am trying to make a images of mysql and wordpress
[2016-11-09 09:12:54] <ely029> is the busybox useful for the communicating of the two containers?
[2016-11-09 09:14:11] <detached> ely029: busybox is one tiny binary that bundles the functionality of many unix tools
[2016-11-09 09:14:50] <ely029> so it is required@detached??
[2016-11-09 09:15:23] <detached> required for what? It is just a tool that can help you
[2016-11-09 09:16:06] <ely029> awww okay my bad. I just a beginner.
[2016-11-09 09:16:12] <ely029> thanks@detached
[2016-11-09 09:17:38] <detached> Maybe have a look at this page [<-LINK->] 
[2016-11-09 10:32:00] <ely029> what is the use of swarm? I read the docs and I dont Understand
[2016-11-09 10:35:47] <ely029> and how can I deploy a project on an image? from my development env
[2016-11-09 11:10:26] <toughIQ_twitter> ely029: There are some basic videos by Docker in this playlist: [<-LINK->] 
[2016-11-09 11:19:53] <tony199555> 1.2? that is little bit outdated
[2016-11-09 16:12:42] <sauga84> am using fluentd driver for logging .. by default it formats it as json.. i want to keep the logs as is generated by the application without any formatting just redirect to a log file
[2016-11-09 16:13:22] <sauga84> how would the fluent.conf file look like in order to achieve it
[2016-11-09 16:13:32] <sauga84> any thoughts on it
[2016-11-10 01:15:16] <nafg> Where can I find information about docker-compose / docker run "domainname" option?
[2016-11-10 01:44:25] <bwoodlt> Hi Guys. I'm trying to use nginx with my node js app. I have a docker file in my project home which build a node container. Now I'm not sure how to go about building the nginx container? Do I need to have two docker containers in the same project => 1 for node and the other for nginx? or how do I go about ensuring application running express on port 3000 get routed to 80.
[2016-11-10 03:41:45] <ely029> hey guys. what are the repository of ubuntu server  to build in docker without gui? beginner here thanks
[2016-11-10 05:42:30] <nafg> ely029: what do you mean?
[2016-11-10 05:56:45] <ely029> I want to build an image for ubuntu without a gui in docker
[2016-11-10 05:56:51] <ely029> nafg: 
[2016-11-10 06:26:39] <nafg> ely029: you want to build in image for ubuntu, without a gui in docker?
[2016-11-10 06:26:49] <nafg> I still don't know what you mean
[2016-11-10 07:43:04] <detached> bwoodlt: There is no need to use nginx if you only want to bind your node.js container port 3000 to port 80 of your host. There is the-p $hostPort:$containerPortfor that. But if you plan to use the nginx for other things like https offloading or authentication, than you should start two containers. [<-LINK->] is a handy tool for this.
[2016-11-10 07:44:44] <sauga84> hi, i have my microservice which o/ps to logs stdout, so when the docker container starts i want the logs which are displayed using "docker logs <containerId>" to mount to volume on the host server
[2016-11-10 07:45:03] <sauga84> can this be done?
[2016-11-10 07:48:25] <detached> sauga84: Do I get this right? You want to write the docker container logs to a file on your docker host?
[2016-11-10 07:48:34] <sauga84> yes
[2016-11-10 07:49:05] <detached> k, you can configure the log driver of your docker deamon [<-LINK->] 
[2016-11-10 07:49:29] <detached> May use journald or syslog, depending on your OS
[2016-11-10 07:50:03] <sauga84> i tired fluentd, syslog option but the log which gets generated are not formatted properly
[2016-11-10 07:50:37] <sauga84> as all multiline app logs when sent to fluentd or syslog gets broken into multiple lines
[2016-11-10 07:51:11] <sauga84> but if i dont use any driver.. and just view using docker logs <coontainer Id>, then logs appear in correct format..
[2016-11-10 07:51:30] <sauga84> so was thinking if if is there any way i can just mout to a host volume for logs
[2016-11-10 07:51:37] <sauga84> instead of the drivers
[2016-11-10 07:52:44] <detached> hm, maybe gelf is an option
[2016-11-10 07:54:09] <sauga84> but what wud gelf provide
[2016-11-10 07:54:10] <sauga84> ?
[2016-11-10 07:54:22] <sauga84> would the formatting issue be resolved
[2016-11-10 07:55:17] <detached> I think I read about multiline support...
[2016-11-10 07:56:08] <sauga84> yes. i saw that but problem happens is when the logs from application are transmitted to fluentd as is.. there itself the problem arise
[2016-11-10 07:56:43] <sauga84> so even if after that we apply filter/format/parsing it wont resolve the issue
[2016-11-10 07:58:09] <sauga84> volumes wont work for logs?
[2016-11-10 07:58:28] <detached> I would consider it kind of hacky
[2016-11-10 07:58:57] <sauga84> yes , the reason why i wanted to try is to see how logs appear
[2016-11-10 07:59:02] <sauga84> how can we do that.
[2016-11-10 07:59:31] <sauga84> even if its hacky shud be ok.. coz with all logging drivers.. m getting some trouble with how logs appear in log files
[2016-11-10 07:59:54] <detached> Maybe s.o. around here has knowledge of fluentd?
[2016-11-10 08:00:27] <sauga84> are you aware of the volume mounting.. how to do that?
[2016-11-10 08:00:35] <sauga84> i want to try and see how it works
[2016-11-10 08:07:52] <detached> You could export an nfs share of your loghost and mount it on your docker host. (But as I said, I wouldn't recommend this). You have read the fluentd docker guide for sure, didn't the chapter about multiline work four you? [<-LINK->] 
[2016-11-10 08:29:05] <Speechkey_twitter> Hi folks! Is it possible somehow to build docker image on the remove host with docker engine installed without keeping docker client connnected to the remote host along the whole building process? For exeample, if I would executedocker -H tcp://host:2375 build -t “test” .I have to be connected until the image is built.
[2016-11-10 08:29:49] <rbuckland> Speechkey_twitter: you could just usetmuxon the client that kicks off the build.
[2016-11-10 08:30:51] <rbuckland>  [<-LINK->] 
[2016-11-10 08:33:31] <Speechkey_twitter> rbuckland: Will it work if I will start the session and than close my laptop and go home, without have to wait until the buiild is done?
[2016-11-10 08:34:13] <rbuckland> :-) no .. if you have a remote session on a server - it will - not your laptop.
[2016-11-10 08:34:54] <rbuckland> you could use "docker in docker"
[2016-11-10 08:34:58] <rbuckland> :-)
[2016-11-10 08:41:43] <detached> Speechkey_twitter: May use a jenkins or any other task runner for that
[2016-11-10 08:45:00] <Speechkey_twitter> So, docker don’t support something like send the whole build context the the engine, and let it build the image? Right?
[2016-11-10 08:46:25] <Speechkey_twitter> detached: Thanks I’m aware of that option, and use it for production, but in that case, It is an unstable image, which I’m currently testing before commit it
[2016-11-10 08:47:47] <rbuckland> Speechkey_twitter: do you have remote ssh access on the "docker" host ?
[2016-11-10 08:49:22] <detached> Speechkey_twitter: actually the docker cli does exactly that: sending the whole context to the daemon. But I am not sure if the task will be canceled if you kill the "session".
[2016-11-10 08:50:25] <rbuckland> [local] git check in code\n[remote] tmux\n[remote] git clone (fetch pull)\n[remote] docker build -t test .\ndisconnect tmux session / exit host and close laptop
[2016-11-10 08:57:27] <detached> From the docker api spec:The build is canceled if the client drops the connection by quitting or being killed.
[2016-11-10 09:12:48] <hholst80> I would like to kill a container if itsHEALTHCHECKis failing. What is the preferred way of doing that?
[2016-11-10 09:13:57] <hholst80> I was thinking of running akill 1inside theHEALTHCHECK CMDitself.
[2016-11-10 09:17:57] <Speechkey_twitter> detached: @rbucklandThanks guys :-) That is exactly what I’ve suspected
[2016-11-10 11:13:38] <Ravencrow> Hi there!
[2016-11-10 11:13:44] <Ravencrow> I have a newbie question:
[2016-11-10 11:14:19] <Ravencrow> if a docker image can't change... is it posible to work on a frontend project inside a container?
[2016-11-10 11:14:32] <Ravencrow> I have seen angular2 and ionic images, but I don't get the idea of this
[2016-11-10 15:28:28] <rbuckland> Hi@Ravencrowyes you can work on the front end of a web app running in a docker container. You need to read up on volume mounts
[2016-11-10 22:46:29] <sauga84> have a questn on application customized logs with docker --
[2016-11-10 22:47:09] <sauga84> application has logback xml where in the path is configured for application customized logs say /logs/<filename>when i dockerize the image and run the containerhow can i view that /logs to check my customzied logs
[2016-11-11 10:34:44] <pea> Docker containers are immutable aren’t they? Meaning that generated files will be lost if an application is redeployed.
[2016-11-11 11:21:54] <pea> Got it - volumes*
[2016-11-11 11:33:18] <skubi> hello guys, I am currently having one issue with mounted drives and permissions when mounted folder is created with docker-compose (so gets root ownership), but inside the container (elasticsearch) there is another non-root user used. so as a result I am getting permissions error on attempt to write to mounted drive (obviously). the thing is that i am thinking on fixing the permissions and I was really wondering what is the best way (best practice) to do this at the moment? i have found a lot of different approaches starting from finding user uid from within container and then assigning the ownership for the same uid on host machine to running extra script as entry point for fixing the permissions. I am a bit lost which path to take. sorry if the question is quite obvious as I am not really experienced with Docker so far
[2016-11-11 13:47:58] <megalooser1_twitter> I have the same question  
[2016-11-11 13:49:48] <pea> I wish Docker had more descriptive error messages
[2016-11-11 15:19:28] <dangxunb> pea: me too
[2016-11-11 15:19:59] <dangxunb> Always get confused with docker's error message
[2016-11-11 16:14:42] <bwoodlt> Hi all. I have a docker file and inside the file, I want to RUN this command:docker run --rm -ti -v $PWD/:/app node /app/npm-install.sh
[2016-11-11 16:15:19] <bwoodlt> How do I present this in my Dockerfile? ThisRUN --rm -ti -v $PWD/:/app node /app/npm-install.shdoesnt work
[2016-11-11 16:56:38] <christhomas> I am working with docker for mac, inside a container, I try to use guzzle in a php website to access a php api in another container, I use the hostname and it resolves to 127.0.0.1, which is not letting me access the service running on the other container, anybody know why?
[2016-11-11 17:00:17] <christhomas> perhaps inside a container, using 127.0.0.1 to access the containers is wrong, should I use the container ip's  ?
[2016-11-11 17:00:48] <christhomas> but then I am wondering how to automatically setup those ips, cause I cannot keep changing stuff each time I restart containers
[2016-11-11 18:11:49] <toughIQ_twitter> christhomas: link containers and use this to access
[2016-11-11 18:52:33] <mshareghi> Is there any timeline on a fix for the case-sensitive DNS on docker networks? [<-ISSUE->] This is a big issue with multi-platform support off of windows software that configures upper case hostnames. There's a workaround whereby you create a network alias for the container in uppercase and lowercase, but this doesn't work for auto-generated host names
[2016-11-11 18:53:21] <mshareghi> I've been considering working on fix myself but I'm still learning Go and haven't looked into the docker code at all
[2016-11-11 21:08:17] <sauga84> hi, i have question -- in dockr-compose i have three services defined.. but we want specific service to wait on anotheer service before it builds and run..
[2016-11-11 21:08:23] <sauga84> how can that be done
[2016-11-11 21:08:24] <sauga84> ?
[2016-11-11 21:10:47] <am0nshi> guys, have any1 run docker-compose with weave network? we have situation, where we need to run some linked containers, some of them should be attached to weave network coz we use UDP and in the same time should be linked to their's DB containers. any ideas how it can be realized?
[2016-11-11 21:11:59] <etolbakov> sauga84: you can use   "depends_on" . If it doesn\'t match your scenario have a look at this approach [<-LINK->] 
[2016-11-11 21:12:49] <sauga84> i used depends_on but it didnt work .. basically i have three services in compose file
[2016-11-11 21:13:37] <sauga84> and used something like below -
[2016-11-11 21:13:47] <sauga84> depends_on:<service1>
[2016-11-11 21:14:00] <sauga84> but it didnt work
[2016-11-11 21:16:22] <etolbakov> The following configuration works for me fineserver:...depends_on: [<-CODE->] 
[2016-11-11 21:17:41] <sauga84> even if they are custom servies.. rite..
[2016-11-11 21:17:54] <sauga84> like service1, service2 and service3
[2016-11-11 21:19:22] <etolbakov> If you mean docker image  under the 'service' - yes
[2016-11-11 21:21:04] <sauga84> i have smethng like below
[2016-11-11 21:21:05] <sauga84> version: '2'services: service1:  build:   context: ./service1   dockerfile: DockerfileFor Gatewayservice2:  build:   context: ./service2   dockerfile: Dockerfile  depends_on:'service1'
[2016-11-11 21:21:39] <sauga84> so basically build uses dockerfile to build and run
[2016-11-11 21:21:52] <sauga84> depends on service doesnt have image.. directly
[2016-11-11 21:26:26] <sauga84> does it always need to be image or even for other builds it woud wait if i use deoends_on
[2016-11-11 21:26:35] <sauga84> depends_on
[2016-11-11 21:27:34] <etolbakov> in my case all images which are described in docker-compose.yml are built before
[2016-11-11 21:27:56] <sauga84> ok let me try that.. as well
[2016-11-12 08:33:11] <smahi> Hi, I am using docker to deploy my nodejs app, i am using also Nginx as proxy server in front of the docker container.My issue is that logging file of the app is not showing the real ip address of the client.How can i fix this issue.
[2016-11-12 09:51:45] <toughIQ_twitter> smahi:  [<-LINK->] 
[2016-11-12 10:56:18] <bwoodlt> I'm looking for an hour docker-support. This is paid for via PayPal. Have been trying to build 4 different containers using docker-compose.yml. My setup's a little different and want to run it through someone more experienced to ensure I'm doing the right thing. Please assist!
[2016-11-12 11:43:38] <BharatKalluri> Hello ! when i try to run docker run hello-world i get [<-CODE->] 
[2016-11-12 11:43:49] <BharatKalluri> what does the error mean?
[2016-11-12 11:57:18] <BharatKalluri> anyone here..
[2016-11-12 12:45:19] <christhomas> toughIQ_twitter: but I dont want
[2016-11-12 12:45:26] <christhomas> Ohmygod
[2016-11-12 12:46:44] <christhomas> toughIQ_twitter: sorry, typing on phone, kept pressing enter, I dont want to access the service by an alias, I want to access it by a hostname, because the software is reading the request URL
[2016-11-12 17:33:16] <smahi> toughIQ_twitter: thx
[2016-11-12 18:59:01] <dkontorovsky>  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2016-11-12 20:04:05] <hholst80> A question related todocker-compose; If I extend a service (usingdocker-compose  -f docker-compose.yml -f docker-compose.extend.yml); how are services extended? for instance, the volume and environment options are they appended or replaced?
[2016-11-12 20:12:18] <hholst80> volumeseems to be appended;environmentseems to be appended and with override in the case of variables with the same name.
[2016-11-13 04:12:25] <suren343> E: Command line option 'g' [from -get] is not known.The command '/bin/sh -c apt-get -y update && apt -get install -y fortunes' returned a non-zero code: 100
[2016-11-13 04:12:42] <suren343> what does the above error says
[2016-11-13 17:53:26] <ilgooz> hi, i'm experimenting docker service. i followed this tutorial [<-LINK->] can you suggest me a tutorial about how to do blue-green deployments with docker service to accomplish zero downtime and rollbacks?
[2016-11-13 20:23:19] <rsvp> So how are you creatingaliases? Are there plans to support something like:.dockerrc\nwriting shell script like docker-foo which is then executed by $ docker foo (patterned after git subcommands)
[2016-11-14 06:41:34] <ely029> hey guys I install a ubuntu:14.04 container then I install vim then I press ctrl+p+q then I run it again when I run vim the ubuntu said it is not installed. what is wrong with this?
[2016-11-14 07:12:37] <kschlesselmann> Du run the same container or a new one?
[2016-11-14 09:52:13] <ely029> I ran the same container
[2016-11-14 09:52:26] <ely029> kschlesselmann: 
[2016-11-14 09:56:40] <ely029> I just forget to commit the image hehe sorry guys my bad
[2016-11-14 10:30:54] <marcelmfs> ilgooz: : [<-LINK->] 
[2016-11-14 12:23:21] <kschlesselmann> rsvp: Aliasesfor what?
[2016-11-14 14:58:55] <marcelmfs> yeah, bash questions on how ppl like their bashrc filled withaliases
[2016-11-14 20:20:14] <pea> I had an error in my dockerfile and now build fails every time - even when the error definitely isn’t there. I’ve tried —no-cache, is ther some other cache I need to clear?
[2016-11-14 20:26:20] <ptab> hi everyone. I'm having an issue trying to run any image (even the hello world) on my Linux desktop. everytime I have this: [<-CODE->] I tried my best on google but I couldn't find anything that helped.
[2016-11-14 20:47:00] <bwoodlt> ptab: is this a custom hello-world container you're trying to start or the one from docker registry?
[2016-11-14 20:48:51] <ptab> it's the one from the default registry. in the meanwhile I installed docker-1.13-rc1 (out of desperation) and at least I get a proper error message now: [<-CODE->] 
[2016-11-14 20:50:28] <ptab> I believe this is a systemd issue, not a docker one.
[2016-11-14 21:14:02] <monksy> I'm currently stuck with Docker 1.11 ... is there anyway that I can install Docker swarm on the machine?
[2016-11-14 21:14:36] <monksy> A forced upgrade to 1.12 has conflicts with selinux and a ton of other stuff that my version of Centos/Amazon AMI won't allow
[2016-11-15 00:53:49] <poojavade> Hi all, a quick question though it seems silly, I have to execute a command something like this:  sambamba sort -m 50G -t 20 --tmpdir=/tmp/tmpHElee8 ... Since my inputs are large in size and /tmp has very small space, how can I make tmpdir (--tmpdir) point to a scratch space inside my container instead of /tmp (this is set by default from my container)? Is there a way to change the tmpdir location from /tmp to /scratch? I need to do the same in dockstore once I fingure out this. Thanks!
[2016-11-15 05:27:47] <mitzkia> Hi, I have a small Dockerfile and a script.sh file. I found an "interesting" issue when I build the Dockerfile. Briefly: inside  Dockerfile the script.sh creates a socket file, and after it I check the type of the file, if it is a socket or not. First I check it from the script.sh file (from where it created), it shows it is a socket. After that I check it again with the same command, but from the Dockerfile and it shows it is a regular file. Can it be a bug, or I miss something. Thanks a lot.
[2016-11-15 05:32:53] <mitzkia>  [<-CODE->] 
[2016-11-15 10:52:03] <ely029> hi guys I have 2 imagesmicrosoft/mssql-server-2014-express-windowsubuntu:latestubuntu is my application server and the other image is my database serverI want to connect them using an ip how to connect them? I see some tutorials but I cannot understand is
[2016-11-15 11:38:05] <kschlesselmann> ely029: I'd suggest you use something like docker-compose. This will create a private subnet for your containers where you can just access your containers with their name as hostname
[2016-11-15 17:08:41] <phumberdroz> Hello people,I am currently trying to run a VPN thru docker but the public IP is always bound to the main interface so I have:eth0 <- host ip adresseth0:1 <- VPN 1eth0:2 <- VPN 2so i can connect to the VPN with the IP Address specified (the correct one) but the facing public ip address is always the eth0 IP adress so how can I specify a certain interface to use? e.g. eth0:1? I think I have to use docker network thing but I am not sure.
[2016-11-15 17:10:43] <phumberdroz> ups just that this is not a help chat.
[2016-11-15 17:10:44] <phumberdroz> sorry
[2016-11-15 18:07:20] <JnMik> Is there a way with the latest Swarm version to auto-scale containers without manual intervention (if we Cap a Memory usage limit or some other healthcheck) ?Considering our cluster would have plenty of ressources available to handle more containers for the project in need..All videos / docs / tutorials I find seems to be people scalling containers manually  when they discover something's wrong.Bugsnag seemed to have the same question has me (see AutoScaling Policies sub-title) [<-LINK->] 
[2016-11-15 20:53:09] <sbbowers__twitter> is there a way to expose the ip of the host machine to a container using docker-compose's extra_hosts option (or some other means)?
[2016-11-15 20:59:08] <sbbowers__twitter> or something opposite of the "ports" option?
[2016-11-16 00:19:42] <elewis787> Has anyone used the golang docker client to pull images from a private repo hosted with docker hub ? Im trying to figure out how to include the auth tokens needed to pull/push images.https://godoc.org/github.com/docker/docker/api/types#ImagePullOptionstrying to create the RegistryAuth string
[2016-11-16 00:46:26] <elewis787> AuthenticationAuthentication configuration is handled client side, so the client has to send the authConfig as a POST in /images/(name)/push. The authConfig, set as the X-Registry-Auth header, is currently a Base64 encoded (JSON) string with the following structure:{"username": "string", "password": "string", "email": "string",  "serveraddress" : "string", "auth": ""}api docs helped 
[2016-11-16 04:48:32] <ely029> I have a ubuntu image then I want to view to the other network using LAN. how can I set it up?
[2016-11-16 07:11:18] <manneting> ```rubydef hello_worldputs "hello world"end
[2016-11-16 16:00:38] <killerspaz> Hi all, I can't find proper documentation on  how to upgrade Docker host on Windows... I seedocker-machine lssaying the docker version in my VM is 1.12.3, but the host still shows 1.11....Any tips?
[2016-11-16 16:22:32] <killerspaz> Also, when idocker pull node:7-alpineI get 2 images...
[2016-11-16 16:22:44] <killerspaz>  [<-CODE->] 
[2016-11-16 16:23:07] <killerspaz> Why is that? I've scoured the entire manual and cannot find these answers.
[2016-11-16 16:55:18] <killerspaz> Ok, I re-installed Docker Toolbox, it shows v1.12 on cli, and there's now only 1 image indocker imagesoutput.... that was ridiculously confusing. Also, when I did adocker-machine upgrade defaulton another computer running docker 1.9, it for some reason pulled 1.13-rc1.... seems a bit silly to pull an RC on a stable install.
[2016-11-16 16:56:16] <killerspaz> However, now I get [<-CODE->] 
[2016-11-16 19:12:23] <killerspaz> Completely removed VBOX and Docker, reinstalled, and now all good... talk about a headache!
[2016-11-17 05:59:55] <milindchawre> Docker uses runc as container runtime. I was trying to make some code changes in runc, and use that changes in docker. But I don't know how to point docker to my runc commit.Any ideas!
[2016-11-17 09:09:43] <Ullidtz> Hey, I am having an issue that may be very basic, but have not been able to find a solution anywhere online. I have never used Docker before and I'm trying to run Docker on windows, so I hope you will bear with me. I have tried following this guide [<-LINK->] 
[2016-11-17 09:10:35] <Ullidtz> I got to a certain point,  but when I try to assign a port number when running a container I always get the same error
[2016-11-17 09:11:30] <Ullidtz> Error starting userland proxy: mkdir /port/tcp:0.0.0.0:32837:tcp:172.17.0.6:443: input/output error.
[2016-11-17 09:12:31] <Ullidtz> The command I ran was:docker run -P prakhar1989/static-site
[2016-11-17 09:13:07] <Ullidtz> If I don't use the-Pargument it seems to run, but I don't know how to access the site then.
[2016-11-17 09:13:46] <Ullidtz> I should also mention that if I rundocker-machine lsthe list is empty. I'm not entirely sure if this is an issue.
[2016-11-17 09:14:16] <Ullidtz> It may also be worth mentioning that I am simply running Docker, and not using Boot2docker. I got the impression it was no longer needed?
[2016-11-17 09:15:20] <Ullidtz> I know I'm asking for help with something that should be really simple here, but I'm really lost on this issue and not sure what to do next. any help would be greatly appreciated.
[2016-11-17 13:14:04] <kmohanar> Hi All,Cannot find the module 'adm-zip'..,
[2016-11-17 13:14:37] <kmohanar> While executing the gulp command getting this error
[2016-11-17 13:15:20] <kmohanar> Can anyone please help to resole this
[2016-11-17 13:42:57] <intellix> I'm having issues with a php/xdebug container. Usually if it was running locally you'd create a xdebug server on 9001 and PHP with xDebug connects to that
[2016-11-17 13:44:01] <intellix> but, I have a php container with php+xdebug inside. I specified "9001:9001" inside my compose file, but when I try to start the XDebug server from my IDE, it says that port 9001 is in use (obviously)
[2016-11-17 13:44:55] <intellix> I\'m a bit of a network noob, but it seems like I need the "php" container to be able to connect to the host\'s 9001 on the host, rather than the host listening on port 9001
[2016-11-17 15:49:49] <marinpurgar> You don't have to expose the port, just specify connect back in the xdebug ini.
[2016-11-18 03:34:59] <Ullidtz> It's me again, still stuck on the same issue. I tried writing a detailed question on Stackoverflow here: [<-LINK->] 
[2016-11-18 03:35:11] <Ullidtz> Much appretiated if anyone could find the time to have a look.
[2016-11-18 09:38:11] <marcelmfs> Ullidtz: Microsoft just joined the Linux Foundation, do like they did, use a real Operating System.
[2016-11-18 09:50:22] <chan_seeker_twitter> marcelmfs: Microsoft is just encouring linux,not joined..How will a propietary company can join a open community?
[2016-11-18 10:55:25] <Ullidtz> Someone helped me get through the issue on stack overflow. And no I'm not going to tell my boss we need to switch to another OS because someone had a cheeky comment on Gitter ;P
[2016-11-18 16:25:51] <dragon788> chan_seeker_twitter: they did actually join, and they have been doing more and more open source every month, the new CEO is definitely changing the company direction, [<-LINK->] 
[2016-11-18 16:30:50] <killerspaz> Ullidtz: what's your host's docker version, and your vm's docker version?docker -v && docker-machine ls
[2016-11-18 23:43:37] <Skhoshhal> Hey guys when I make start docker show me this message/usr/local/bin/docker-compose -p dockerlocal up -d\nERROR: Couldn't connect to Docker daemon. You might need to start Docker for Mac.\nmake: *** [up] Error 1
[2016-11-19 00:29:17] <scippio> Hi all .. I successfully built docker image: [<-CODE->]  [<-CODE->] 
[2016-11-19 02:30:07] <colshacol> I am trying to run my virtual environment docker container and then access its api from a external UI folder that I am hosting locally with live-server, but I getERR CONNECTION CLOSED. Anybody know how I can make this work? Maybe something I can add to my docker-compose.yml?
[2016-11-19 02:33:53] <colshacol> --Resolved. -_- Dumb mistake. Was trying to connect tohttps://localhost/.... Switched tohttpand it is fine.
[2016-11-19 19:26:45] <toughIQ_twitter> scippio: completely empty? Or just your image not there?
[2016-11-20 11:18:12] <scippio> toughIQ_twitter: not there ... but I found that it only happens in another instance terminal. In same terminal where I build it I found my image ...
[2016-11-20 16:06:31] <nischay30> $@scippiohey try eval command to set up the enivronment of the terminal with the docker machine...like eval $(docker-machine env nameOfMachine)
[2016-11-21 06:20:03] <Benjman> Is there a way to include directories in the java maven docker plugin?? Something like [<-CODE->] 
[2016-11-21 11:22:33] <vamsiporala> Has anyone tried to create 300 docker bridges on a single docker host?
[2016-11-21 13:06:23] <sirroland> Hello. Help solve the problem please.Dockerfile: [<-CODE->] When I run a container returns an error: [<-CODE->] (but /root/run.sh File exists)
[2016-11-21 13:08:11] <krzysztof-magosa> 1st thing, remove space between+andxin chmod invocation
[2016-11-21 13:08:27] <krzysztof-magosa> 2nd thing, try "/bin/bash /root/run.sh"
[2016-11-21 13:09:37] <sirroland> in Dockerfile all right, I'm wrong here\nNow I will try, thank you
[2016-11-21 13:10:30] <sirroland>  [<-CODE->] 
[2016-11-21 13:11:23] <krzysztof-magosa> you can try also with /bin/sh
[2016-11-21 13:11:34] <toughIQ_twitter> scippio: is it possible, that the two windows are connecting to different daemons? Due to different environment settings?
[2016-11-21 13:12:26] <sirroland> krzysztof-magosa:  [<-CODE->] 
[2016-11-21 13:12:52] <sirroland> Docker version 1.12.3, build 6b644ec
[2016-11-21 13:14:05] <krzysztof-magosa> try
[2016-11-21 13:14:15] <krzysztof-magosa> CMD [ "/bin/sh", "/root/run.sh"]
[2016-11-21 13:15:51] <sirroland> CMD [ "/bin/sh", "/root/run.sh"] it\'s work. thanks
[2016-11-21 13:16:10] <krzysztof-magosa> ;-)
[2016-11-21 14:49:22] <sirroland> How I can start nginx and php on starting container?
[2016-11-21 14:49:44] <sirroland>  [<-CODE->] not working ((
[2016-11-21 14:58:00] <gudron> Hi guys.
[2016-11-21 14:59:21] <gudron> i have stupd question;i have two physical server with docker engine on board.1 - with mysql container2 - with apps containers
[2016-11-21 15:00:52] <gudron> I need to create a network between the two docker-host
[2016-11-21 15:01:27] <gudron> what should I do? what tool to use?
[2016-11-21 15:02:54] <vkrot> gudron: , have you checked this [<-LINK->] ?
[2016-11-21 15:05:33] <gudron> hm...
[2016-11-21 15:05:58] <gudron> i must do it on every host?
[2016-11-21 18:34:59] <killerspaz> krzysztof-magosa: @sirrolandif you want/bin/shto be your interpreter just supply CMD as a quoted array as you have; see: [<-LINK->] 
[2016-11-21 18:38:18] <dragon788> sirroland: you'll probably need to put those two commands in a single  .sh file and execute it via cmd
[2016-11-21 18:46:13] <marcfielding1> Lol I was just coming to ask about networking between containes@vkrotSo basically you create a "network" on the host and then assign that as the interface for any container that needs to interact with others - I have a node API, a MySQL container and a Sphinx container that need to communicate ideally by name, this provides that functionality?
[2016-11-21 18:47:42] <marcfielding1> Ahh so it does, thats nifty!
[2016-11-21 18:56:59] <marcfielding1> @sirroland I think you simply need && after the first start so [<-CODE->] CMD executes a single command so by using && you get it to do both - at least thats my understanding
[2016-11-21 18:57:13] <marcfielding1> although ideally as has already been mentioned a shell script would be a good idea
[2016-11-21 21:12:13] <killerspaz> Also, docker compose does all that for you out of the box
[2016-11-21 21:14:40] <killerspaz> Skhoshhal: you need to start the Docker VM.... it should have told you also to rundocker-machine start default... then follow outputs from there.
[2016-11-21 21:20:45] <matrixbot> Yan Minarione of my docker-compose services won't show it's name before the log it outputs
[2016-11-21 21:22:35] <matrixbot> Yan Minariposted an image:
[2016-11-21 21:22:38] <matrixbot> Yan Minarilike this
[2016-11-21 22:03:18] <scippio> toughIQ_twitter: maybe different environments... but it's seems ok, now. so I do not care... thanks.
[2016-11-22 07:14:12] <gudron> hi guys.
[2016-11-22 07:15:15] <gudron> Anyone know what to do with this problem?
[2016-11-22 07:15:53] <gudron> blockquoteWARNING: The Docker Engine you're using is running in swarm mode.Compose does not use swarm mode to deploy services to multiple nodes in a swarm. All containers will be scheduled on the current node.To deploy your application across the swarm, use the bundle feature of the Docker experimental build.
[2016-11-22 07:16:54] <krishnaghatti_twitter> gudron: i think docker-compose is not yet compatible with the new swarm-mode
[2016-11-22 07:17:14] <krishnaghatti_twitter> Swarm mode is not supported by compose yet. Compose basically does a run on the containers in your compose file. In swarm mode run only schedules containers on the daemon to which your client is connected.
[2016-11-22 07:18:09] <krishnaghatti_twitter> the doc [<-LINK->] says it will work but there are a lot of issues posted on github for issues around it
[2016-11-22 07:18:23] <gudron> oh...
[2016-11-22 07:20:06] <gudron> so .. how do I run a container? from the command line?
[2016-11-22 07:20:36] <gudron> big list of ENV variables...
[2016-11-22 07:20:46] <krishnaghatti_twitter> gudron: just one container or do you have a compose file?
[2016-11-22 07:20:54] <gudron> 6
[2016-11-22 07:21:11] <gudron> 2 on node-1
[2016-11-22 07:21:16] <gudron> 4 on node-2
[2016-11-22 07:21:41] <krishnaghatti_twitter> you can put all the ENV in a ‘.env’ file and pass it with -e
[2016-11-22 07:22:10] <gudron> indocker service create?
[2016-11-22 07:23:32] <krishnaghatti_twitter> sorry not with -e …it is env_file parameter
[2016-11-22 07:23:57] <krishnaghatti_twitter>  [<-LINK->] 
[2016-11-22 07:24:20] <krishnaghatti_twitter> compse will not schedule across nodes…it will bring up all the nodes  in one box
[2016-11-22 07:25:39] <gudron> docker service create [OPTIONS] IMAGE [COMMAND] [ARG...]-e, --env value                      Set environment variables (default [])
[2016-11-22 07:26:01] <gudron> ok..without docker-compose.
[2016-11-22 07:26:46] <gudron> how to manage the containers on the hosts?
[2016-11-22 07:26:46] <krishnaghatti_twitter> looks like docker service does not hava a env_file param...
[2016-11-22 07:27:26] <gudron> facepalm ?)))
[2016-11-22 07:28:35] <krishnaghatti_twitter> :)
[2016-11-22 07:29:03] <krishnaghatti_twitter> not sure why the env_file is not supported…more than half of mesos deployments use the env_file parameter..
[2016-11-22 07:31:41] <gudron>  [<-LINK->] 
[2016-11-22 07:32:20] <gudron> It recommends the use of bundles.
[2016-11-22 07:33:05] <gudron> but there is no support - volume mounts
[2016-11-22 07:33:12] <gudron> facepalm ?))
[2016-11-22 07:33:37] <gadget_mnky_twitter> Bundles are a 1.13
[2016-11-22 07:33:47] <gadget_mnky_twitter> And too experimental right now iirc
[2016-11-22 07:35:11] <gudron> ok ... how can I run the containers in multiple hosts on the same network. And use ENV_FILE and mount volumes?
[2016-11-22 08:24:31] <Skhoshhal> killerspaz: Thanks man every day I have a new problem with Docker 
[2016-11-22 11:32:58] <krishnaghatti_twitter> Skhoshhal: lol
[2016-11-22 12:12:58] <Skhoshhal> krishnaghatti_twitter: 
[2016-11-22 12:13:16] <RedDevilHat> Hi guys
[2016-11-22 12:13:27] <RedDevilHat> i have no docker question
[2016-11-22 12:13:37] <RedDevilHat> anyone work with dredd?
[2016-11-22 12:34:09] <krishnaghatti_twitter> RedDevilHat: i only know about the Dredd movie.. :)
[2016-11-22 12:34:17] <krishnaghatti_twitter> what is it anyway.
[2016-11-22 12:34:40] <RedDevilHat> krishnaghatti_twitter: me to..
[2016-11-22 12:34:41] <RedDevilHat>  [<-LINK->] 
[2016-11-22 13:20:39] <LuizTibo> Hi guys, I need a docker compose to  use with php 7, postgresql, mongo e nodejs. Do you have some example?
[2016-11-22 13:40:58] <marcelmfs> LuizTibo: : [<-LINK->] 
[2016-11-22 15:52:08] <colshacol> If my boss says to take these 3 files and add them to mydocker-machinemachinedev local, what the heck am I supposed to do? -_-
[2016-11-22 17:07:53] <marcelmfs> docker-machine scp file container:path?
[2016-11-22 17:23:19] <colshacol> He has given me a docker-environment.zip now and saysexport it to $HOME/.docker. I moved the zip file there. Idk if that is what I was supposed to do. When I unzipped it after I downloaded it it has a User folder, and inside of that a folder with his name, but nothing else. -- And the download was 38mb.
[2016-11-22 17:25:54] <Speechkey_twitter> Hi folks, [<-CODE->]  [<-CODE->] On that way the logs should be written: [<-CODE->] 
[2016-11-22 18:28:31] <aaronmcadam> hey everyone, are there any good patterns for copying production credential files to an image? We were thinking of putting our credential files on S3 and downloading them
[2016-11-22 19:10:00] <Speechkey_twitter> aaronmcadam:  [<-LINK->] 
[2016-11-22 19:20:15] <aaronmcadam> Thanks@Speechkey_twitter, does that support using files?
[2016-11-23 00:17:33] <dragon788> files are not a great pattern unless they are encrypted in transit and at rest
[2016-11-23 00:17:52] <dragon788> Vault is pretty awesome, another@Hashicorpwin
[2016-11-23 08:44:20] <ShurikAg> hi all
[2016-11-23 08:44:51] <ShurikAg> Is there a way to set folder ownership on mounted volume?
[2016-11-23 08:45:30] <ShurikAg> Somehow, when I change permissions once, it’s kept on my local docker but not on AWS.
[2016-11-23 18:08:05] <lucasjahn> ShurikAg: I have a really similar file permission issue. So upvote for any helpful tipp on this :)
[2016-11-23 18:17:45] <dragon788> I'd suggest checking this out, since running as root is definitely an anti-pattern that should be avoided, [<-LINK->] 
[2016-11-23 19:15:11] <thebuccaneersden> dragon788: 
[2016-11-23 23:24:22] <zapcode> can i use docker in a virtualbox ?
[2016-11-23 23:24:35] <MadMub> yes
[2016-11-23 23:24:43] <MadMub> just be careful with docker and vagrant
[2016-11-23 23:24:57] <MadMub> docker inside a vm through vagrant gets effed
[2016-11-23 23:25:11] <zapcode> some link about this ?
[2016-11-23 23:25:25] <MadMub> about vagrant?
[2016-11-23 23:25:29] <MadMub> Or docker in a vm?
[2016-11-23 23:25:46] <zapcode> about docker run in vbox
[2016-11-23 23:25:55] <MadMub> just install and use normally
[2016-11-23 23:26:06] <MadMub> docker can basically inside anything with a linux kernel
[2016-11-23 23:26:27] <MadMub> docker on windows used to be docker through a linux vm
[2016-11-23 23:26:48] <MadMub> docker on amazon ecs is docker running on a vm
[2016-11-23 23:27:12] <zapcode> yes, i install in my windows but the problem is activate hyper and break the virtualbox
[2016-11-23 23:27:17] <MadMub> haha
[2016-11-23 23:27:18] <MadMub> yes
[2016-11-23 23:27:27] <MadMub> a host operating system can only have 1 hypervisor
[2016-11-23 23:27:36] <zapcode> i write a command that i can select in the booting if activate/desactivate hyper
[2016-11-23 23:27:47] <zapcode> but the docker not run if i need vbox
[2016-11-23 23:27:56] <zapcode> and vbox no run if i select hyper and no like this
[2016-11-23 23:28:14] <zapcode> i need can use the two without reboot
[2016-11-23 23:28:16] <MadMub> on windows, you cannot run both hyper and vbox
[2016-11-23 23:28:22] <MadMub> on any os
[2016-11-23 23:28:30] <MadMub> you cant run competing hypervisors
[2016-11-23 23:28:36] <MadMub> to me knowledge at least
[2016-11-23 23:29:13] <MadMub> if you have hyperv just use that it can do everything vbox does
[2016-11-25 12:30:52] <scippio> hi all I\'m trying start nginx via:docker run --network "host" -e NGINX_PORT=8080 2f3c6710d8f2but I get only:2016/11/25 12:29:06 [emerg] 1#1: bind() to 0.0.0.0:80 failed (98: Address in use)\nnginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address in use)
[2016-11-25 12:31:14] <scippio> How I can change the port in [<-LINK->] image ...? :/
[2016-11-25 12:49:56] <lucasjahn> you should use the --expose option for this
[2016-11-25 12:50:33] <lucasjahn>  [<-CODE->] 
[2016-11-25 12:51:38] <lucasjahn> have a look at the commandline  reference here [<-LINK->] or directly in the nginx image docs [<-LINK->] in the section exposing ports, there you have a direct example
[2016-11-25 12:52:04] <lucasjahn>  [<-CODE->] this would map your local port 8080 to the port 80 in the container
[2016-11-25 13:25:10] <scippio> lucasjahn: still have same problem
[2016-11-25 13:25:23] <scippio> withdocker run --network "host" -p 8080:80 -e NGINX_PORT=8080 2f3c6710d8f2
[2016-11-25 13:47:14] <lucasjahn> you set NGINX_PORT=8080
[2016-11-25 13:47:18] <lucasjahn> so you should adjust
[2016-11-25 13:47:25] <lucasjahn> -p 8080:8080
[2016-11-25 13:47:28] <lucasjahn> to this
[2016-11-25 13:47:50] <lucasjahn> can you just paste in your error again in here?
[2016-11-25 14:01:19] <scippio> docker run --network "host" -p 8080:8080 -e NGINX_PORT=8080 2f3c6710d8f2
[2016-11-25 14:01:22] <scippio> still same error
[2016-11-25 14:01:34] <scippio>  [<-CODE->] 
[2016-11-25 14:02:01] <scippio> it's ignore my 8080 settings :/
[2016-11-25 14:11:41] <matrixbot> uhoregAre you sure the image you\'re using supports NGINX_PORT?  Don\'t use \'--network "host"\'.  Just do "docker run -p 8080:80 nginx"
[2016-11-25 14:16:31] <scippio> but I want --network "host"
[2016-11-25 14:17:11] <scippio> I'm using this image: [<-LINK->] 
[2016-11-25 14:17:47] <scippio> hmm...
[2016-11-25 14:17:47] <scippio> "Out-of-the-box, Nginx doesn\'t support using environment variables inside most configuration blocks. But envsubst..."
[2016-11-25 15:02:10] <lucasjahn> and what happens if you just run it like@matrixbotsaid?
[2016-11-25 15:02:16] <lucasjahn> still the error?
[2016-11-25 15:35:01] <scippio> lucasjahn: no.. it\'s ok. but I need --network "host" option ... so I must build my own image from nginx:alpine ...
[2016-11-25 17:14:52] <Benjman> Sorry if this is the wrong channel, but can anyone tell me where I might see the log output for an AWS ECS container I'm trying to start a docker container on? I think it's failing, but I have no idea where to see if it is.
[2016-11-25 17:21:02] <Forecaster> Might be a better place, but I'm having issues getting php-fpm and nginx working (in separate containers), I'm getting a bad gateway and I think it might be because nginx can't communicate with php properly, but I'm not sure why
[2016-11-25 18:15:15] <DylanNWatt> Hey guys, realtively new to docker, helping my company (who doesn't currently use docker) move on to it. I have a best practices question. Should starting a process be part of the Dockerfile, or the responsibility of the container manager. EG, given an node app, shouldnpm startbe called in the dockerfile, or in docker-compose?
[2016-11-25 18:16:44] <MadMub> dockerfile
[2016-11-25 18:16:50] <MadMub> set it as CMD
[2016-11-25 18:17:05] <MadMub> 1 process per container
[2016-11-25 18:17:41] <MadMub> I myself am no docker expert only containerized basic applications though, others jump in and correct me
[2016-11-25 18:18:57] <Forecaster> dockerfile
[2016-11-25 18:19:50] <MadMub> official nodejs docs have a basic tut
[2016-11-25 18:19:51] <MadMub>  [<-LINK->] 
[2016-11-25 18:20:43] <DylanNWatt> As an extension of that, how does that work with local development? For example, I currently build the dockerfile by linking in some relatively pathed code. But then in docker compose, I want to link in code as a volume, so that changes are live.
[2016-11-25 18:21:05] <DylanNWatt> Linking in that colume sort of messes up the runtime, though, IE I need to rerunnpm installbeforenpm startworks.
[2016-11-25 18:21:16] <DylanNWatt> Would it just be a separate dockerfile for development?
[2016-11-25 18:21:35] <MadMub> I cant speak to any of that, I’ve never really found success for docker in dev, not a docker pro yet
[2016-11-25 18:22:38] <DylanNWatt> Thanks for the link though. It definitely makes sense that the process should be started from the Dockerfile, I'm jusyt trying to figure out how to make local development seemless in a docker world.
[2016-11-26 11:55:53] <ilgooz> is it possible to auto pull volumes from registry while doing docker service create? do i have to manually ssh into all swarm nodes and do a pull of my volume(container) each time a new version is ready?
[2016-11-26 14:19:15] <nischay30> Jst try docker service update
[2016-11-26 14:26:27] <gadget_mnky_twitter> Looking to scale a bunch of compose files across hosts but swarm minus bundle seems like a pain
[2016-11-26 14:27:07] <gadget_mnky_twitter> Kubernetes/mesos the only option?
[2016-11-27 11:48:30] <lucasjahn> Hey there, can anyone help me with an cron issue. I have a PHP container in which I need to run cron (for wordpress, because the wordpress cron is not running)
[2016-11-27 11:48:54] <lucasjahn> I created a cron with supervisord and the service is running in the container
[2016-11-27 11:49:10] <lucasjahn> but the crontab (which is also available in the container) is never starting or running
[2016-11-27 11:50:35] <lucasjahn> in the dockerfile: [<-CODE->] cron tab file [<-CODE->] in the container: [<-CODE->] and the supervisor d: [<-CODE->] 
[2016-11-27 11:50:52] <lucasjahn> and the /tmp/test is never created its weird
[2016-11-27 15:44:51] <ImFlog> Hello, I have an issue with swarm. I have a simple java application which tries to call another application. I use swarm for my deployment through a network overlay. The problem is that when I scale an app, I can validate that the hosts behind the VIP are updated but my client keeps calling the same addresses.I tried a lot of things like changing java DNS cache ttlAnyone ever had something like that ?
[2016-11-28 02:43:03] <gadget_mnky_twitter> Hi, looking to scale my existing compose file across multiple hosts using swarm. Any examples I could follow?
[2016-11-28 10:10:44] <ninabreznik> heyho, one stupid question, but i really don't know how to solve this
[2016-11-28 10:11:15] <ninabreznik> so, i dockerized the app and pushed it to docker hub and my computer crashed so i would need to get the source code back from the docker image
[2016-11-28 10:11:44] <ninabreznik> i pulled it now from the docker hub, but i have the image...how do i get to the code?
[2016-11-28 10:11:51] <ninabreznik> thanks a lot for help :)
[2016-11-28 10:14:08] <Forecaster> ninabreznik: you mean the files for your app?
[2016-11-28 10:14:16] <ninabreznik> yes
[2016-11-28 10:14:29] <ninabreznik> i have a rails app and want to get to it :)
[2016-11-28 10:14:46] <Forecaster> you can run it as a container and use 'docker cp' to copy files out of it
[2016-11-28 10:15:34] <Forecaster> likedocker cp imageid:/path/on/image /path/on/host
[2016-11-28 10:15:54] <ninabreznik> huh, i forgot a bit how to do it. will try to refresh my memory and see how to run it and then how to do that, but ok, it's doable. yay
[2016-11-28 10:16:45] <Forecaster> you can copy entire directories at once by just pointing it at a dir
[2016-11-28 10:17:10] <ninabreznik> how do i run it again? docker run imageID... ?
[2016-11-28 10:17:42] <Forecaster> you probably want to dodocker run -d image
[2016-11-28 10:18:07] <Forecaster> that will not attach to it, it will just run it in the background
[2016-11-28 10:18:23] <ninabreznik> ok, did that
[2016-11-28 10:18:28] <ninabreznik> and now i do the cp thing?
[2016-11-28 10:18:35] <Forecaster> yep
[2016-11-28 10:18:54] <ninabreznik> what do i use as path/on/image?
[2016-11-28 10:19:14] <Forecaster> "image" should be "container"
[2016-11-28 10:19:21] <Forecaster> but the path to where your files are stored
[2016-11-28 10:20:26] <ninabreznik> ok, lemme check my cheatsheets :D
[2016-11-28 10:20:31] <ninabreznik> muchas gracias for this
[2016-11-28 10:20:40] <Forecaster> no problem
[2016-11-28 10:27:16] <ninabreznik> Forecaster: If i run docker inspect containerID, I get this [<-CODE->] 
[2016-11-28 10:27:49] <Forecaster> okay?
[2016-11-28 10:27:55] <ninabreznik> do i find path here?
[2016-11-28 10:28:15] <ninabreznik> i don't know how to find image path and host path that you mentioned?
[2016-11-28 10:28:34] <Forecaster> you misunderstood me then
[2016-11-28 10:28:39] <ninabreznik> i did this like a year ago and since that didn't touch docker, so I forgot everything :D
[2016-11-28 10:29:31] <Forecaster> docker cp containerId:/path/to/source/in/container /output/path/on/host
[2016-11-28 10:30:05] <Forecaster> ninabreznik: hopefully that is more clear
[2016-11-28 10:31:56] <ninabreznik> So, I bash into my container and find a path to my app and then path/on/host means where on my comp i want to save it?
[2016-11-28 10:32:05] <Forecaster> yes
[2016-11-28 10:32:11] <ninabreznik> oh yeah, let's see
[2016-11-28 10:43:35] <ninabreznik> ole
[2016-11-28 10:43:46] <ninabreznik> have it! owe you a beer or carrot juice :)
[2016-11-28 10:43:55] <ninabreznik> thanks again
[2016-11-28 10:43:56] <Forecaster> nice :)
[2016-11-28 10:44:14] <ninabreznik> now off to play ;)
[2016-11-28 12:48:20] <jacobcamm> hey guys, running a docker exec cmd to a remote host and the output just stops showing? The process still seems to be running in the container on the remote host but there's no more stdout displayed on my machine? Is there a timeout or anything of the sort for that, or any reason it would stop?
[2016-11-28 16:06:12] <mikewrighton> hi! does anyone happen to know about inspecting execution state in a container? when youexeca command you can see the exec id in the container state, and the docker API allows you to query that state (e.g. to see whether it’s running) but I don’t see any docs for command line support
[2016-11-28 16:06:45] <mikewrighton> in other words, my question is can you do this in the CLI tool: [<-LINK->] 
[2016-11-28 17:15:04] <Forecaster> mikewrighton: you mean this? [<-LINK->] 
[2016-11-28 17:16:32] <mikewrighton> so I can rundocker inspectto get the list of current exec ids for a container, but I can’t seem to actually inspect the execution state for those exec ids
[2016-11-28 17:18:18] <mikewrighton> I tried runningdocker inspect<exec id> but gotError: No such image, container or task:<exec id>
[2016-11-28 17:19:03] <mikewrighton> unless I’m missing something, it seems like this is not implemented for the CLI tool?
[2016-11-28 17:20:37] <Forecaster> maybe if you request the data as json from the container?
[2016-11-28 17:23:20] <mikewrighton> oh, how can I try that?
[2016-11-28 17:29:04] <Forecaster> oh, the default format is json it appears
[2016-11-28 17:29:44] <Forecaster> if that doesn't contain it then you may be stuck with the api
[2016-11-28 17:35:40] <mikewrighton> yeah it looks like it, thanks anyway.
[2016-11-28 21:13:43] <killerspaz> mikewrighton: which OS? If on linux, you needsudo... otherwise, ensure the container exists withdocker ps -a
[2016-11-28 21:14:34] <mikewrighton> the docker docs don’t even claim to support this
[2016-11-28 21:14:48] <mikewrighton> but I can get what I need from the remote API viacurl
[2016-11-28 21:15:07] <mikewrighton> like this:curl -XGET --unix-socket /var/run/docker.sock http://localhost:3475/exec/$id/json
[2016-11-28 21:18:03] <mikewrighton> (on osx)
[2016-11-28 21:24:18] <killerspaz> Use inspect as suggested by@Forecaster....docker inspect <id>
[2016-11-28 21:25:01] <mikewrighton> I getError: No such image, container or task: a9952be2c74f2c6f3a7ae9faf12dc1576367bba5197fe74c243b637289fb653b
[2016-11-28 21:25:16] <mikewrighton> but an exec id is not an image, container or task
[2016-11-28 21:26:05] <mikewrighton> so docker inspect, as far as I can tell, does not support quering exec ids
[2016-11-28 22:51:21] <killerspaz> ah, i misunderstood your use-case... i didn't realize you were looking at stats for an exec... i do not know about that one
[2016-11-28 22:53:10] <dragon788> mikewrighton: I think you are correct, inspect is mostly for containers and images
[2016-11-29 06:47:30] <lakshmantgld> newbie question!! Understood about docker. Would like to know the docker orchestration tools and would be great if you show me a tutorial for getting started
[2016-11-29 08:18:10] <vkrot> Hi, can't find information in docs - what is docker iptables chainDOCKER-ISOLATIONfor?
[2016-11-29 16:13:10] <killerspaz> my guess would be to isolate docker traffic routes to only work on the bridged network
[2016-11-29 18:50:43] <rperezs> Lakshman-LD: hope this link works
[2016-11-29 18:50:58] <rperezs>  [<-LINK->] 
[2016-11-29 20:32:40] <dearfrankg> has anyone had problems with nginx-proxy?
[2016-11-29 20:59:13] <Nezteb> Does anyone have an officially supported solution to this problem? [<-ISSUE->] 
[2016-11-29 20:59:58] <Nezteb> And: I need to use Toolbox. I cannot put HyperV on my machine for "Docker for Windows"
[2016-11-29 21:20:22] <Nezteb> I click "Use Virtualbox" and it works fine, but then every time I launch Kitematic it asks again. There\'s no way to set a default.
[2016-11-30 00:34:43] <rightisleft> If im running the latest docker for mac - do i still need docker machine?
[2016-11-30 00:37:30] <rightisleft> should i uninstall docker-machine if  i have no legacy VMs?
[2016-11-30 12:06:26] <toughIQ_twitter> Lakshman-LD: Orchestration:Since Version 1.12 there is Swarm Mode: https://docs.docker.com/engine/swarm/\nIf you are looking for a GUI to orchestrate, take a look at Portainer: http://portainer.io/There is also a Gitter channel for Portainer: https://gitter.im/portainer/Lobby\nFor more complex scenarios take a look at Rancher: http://rancher.com/rancher/
[2016-11-30 15:11:51] <jdevillard> Hello, I'm new on docker, I would like to know if there is some UI and/or orchestrator that allow me to manage multiple cluster in one place. I understand that there is many Docker UI available but it seems that it allows to manage only one cluster (or maybe I miss something). Indeed my cluster will be hosted on Azure, in different Vnet and I would like a single interface to manage them all. Do you have any idea?
[2016-11-30 15:24:18] <marcelmfs> check rancher.com
[2016-11-30 15:25:30] <jdevillard> interesting thanks@marcelmfs!
[2016-11-30 19:30:09] <rightisleft> Is there a version of kitematic that doesn't use Virtualbox for OS X ?
[2016-11-30 20:07:03] <dragon788> rightisleft: I believe the new version is Docker Toolbox which may use the native hypervisor in OSX, but not sure if that\'s fully released, otherwise docker-machine should natively use the "best" option per platform
[2016-12-01 07:28:22] <raghavtan> hey,
[2016-12-01 07:28:39] <raghavtan> i have been trying to use docker-ansible modules
[2016-12-01 07:28:53] <raghavtan> which were running successfully up till now
[2016-12-01 07:29:03] <raghavtan> but have been failing
[2016-12-01 07:29:27] <raghavtan>  [<-CODE->] 
[2016-12-01 07:29:36] <raghavtan> error message
[2016-12-01 07:30:16] <raghavtan>  [<-CODE->] 
[2016-12-01 07:30:42] <raghavtan> the same task was running fine a couple of days back
[2016-12-01 07:30:52] <raghavtan> can anyone help please
[2016-12-01 14:27:25] <dragon788> raghavtan: it sounds like it isn't contacting Docker Hub, hence the http:// host not specified error
[2016-12-01 18:59:41] <rightisleft> Im trying to replace my brew docker instance with a dockerized version - i can start the container - and see my data from within the container - but when i try and access it on the exposed port on os x - i get connection refused
[2016-12-01 18:59:46] <rightisleft> docker run -d --net po-net -p 5432:5432 -e POSTGRES_USER='rightisleft' -e POSTGRES_DB='mydb' --env 'PG_TRUST_LOCALNET=true' -v /usr/local/var/postgres:/var/lib/postgresql/data --name po-postgres postgres:9.5
[2016-12-01 19:00:38] <rightisleft> database psql -U rightisleft -d mydbpsql: could not connect to server: Connection refusedIs the server running locally and acceptingconnections on Unix domain socket "/tmp/.s.PGSQL.5432"?
[2016-12-01 19:01:13] <rightisleft> docker ps -a show it active with the following ports - 0.0.0.0:5432->5432/tcp
[2016-12-01 19:04:09] <picturejess> im trying to attach a dynamic env variable to my docker container and I am a bit stuck. any ideas on how I can do something similar to this:docker run  -e TEMP_VAR=$(cat /etc/resolv.conf | grep "nameserver" | awk \'{print $2}\' | tr \'\\n\' \' \')
[2016-12-01 22:24:59] <LuizTibo> Good evening guys, i made a docker-compose with de php7-fpm, nginx and postgres. But the postgres does't works. the driver could not find, what should i do? how should my dockerfile-php?
[2016-12-01 23:55:31] <danieldram> Is there a way to get the original IP from the request client inside a node express app? It is always 10.0.0.22 for me
[2016-12-02 00:03:30] <danieldram> the node app runs in a container this is why I can't get the remote address
[2016-12-02 00:37:56] <dragon788> danieldram: you probably want to have a proxy pass the original IP as an additional X-header
[2016-12-02 02:59:21] <danieldram> dragon788: thanks for the reply! Are there docs available for this? I've been looking everywhere online for a solution :S
[2016-12-02 04:22:09] <dragon788> Do you have nginx or some other proxy in front? Typically you just set up your original page to pass that header when a request comes through it
[2016-12-02 14:01:23] <picturejess> any ideas on my issue above?
[2016-12-02 14:09:41] <dragon788> picturejess: you could try usinginstead of $( as in my experience from using it in scripts, theevaluates every time while $( stores the value immediately and doesn't re-evaluate when called again
[2016-12-02 14:10:19] <dragon788> what is the end goal of your script/variable? there might be a better way using etcd or something
[2016-12-02 14:11:20] <picturejess> I want to get the value of nameserver in /etc/resolv.conf at the time the container is spun up. the value may be different on different systemsm
[2016-12-02 14:18:30] <dragon788> you could map the /etc/resolv.conf from the host into the container as a specific file (probably not /etc/resolv.conf) and then run your eval inside the container as part of the CMD
[2016-12-02 14:19:15] <dragon788> or follow the Docker docs and do map it in, [<-LINK->] 
[2016-12-02 14:20:02] <dragon788> per that doc, mapping the file should be last resort, "The exact details of how Docker maintains these files inside the container can change from one Docker version to the next, so you should leave the files themselves alone and use the following Docker options instead."
[2016-12-02 14:29:38] <picturejess> ill try that out, thanks!
[2016-12-02 14:55:34] <dearfrankg> I'm using docker-machine plus docker-machine-driver-xhyve on my mac.  I was able to run my containers as a non-root user but when I try to use a host volume, in the container the volume is owned by root so my non-root user cannot read/write to it.  Is there a fix for this?
[2016-12-02 14:56:33] <dragon788> dearfrankg: I think if you search back in this channel I posted a link about how to run containers by default as a non-root local user, otherwise if I can find time I'll see if I can pull it up again
[2016-12-02 14:57:14] <dragon788> I think there is either a umask or uid that you can pass to the volume command to mount/present it as a different user inside, but the link addressed most of that
[2016-12-02 14:57:20] <dearfrankg> dragon788: I can run as non-root now.  my problem is accessing the volume.  Do you address that issue?
[2016-12-02 14:58:03] <dearfrankg> dragon788: I'm curious about your post -- I will hunt for it
[2016-12-02 14:58:25] <dragon788> this one I think, [<-LINK->] 
[2016-12-02 14:58:45] <dragon788> Gitter search wasn't helpful, but Google knew I'd been there before
[2016-12-02 14:59:12] <dearfrankg> dragon788: funny.  I just read that blog post.  That's how I learned to run as a non-root user.  But I cannot access the host volume.
[2016-12-02 15:02:17] <dearfrankg> dragon788: I see your umask point - still digging
[2016-12-02 15:12:20] <dearfrankg> dragon788: are you able to use host volumes with a non-root user running the container?
[2016-12-02 15:15:25] <dearfrankg> here is recent answer: [<-LINK->] 
[2016-12-02 15:16:04] <dragon788> sadly I'm doing most of my work on Windows these days, so haven't been able to play with the more recent Docker releases
[2016-12-02 15:17:35] <dragon788> I do recall seeing that workaround in some of our Dockerfiles when I was messing with them a year or so ago
[2016-12-02 19:24:21] <jmif> hey all, I'm looking at the documentation regarding backing up a swarm state here: [<-LINK->] .  Does anyone have experience with this?  It is really as simple ascp -r /var/lib/docker/swarm/raft /tmp/backup && REST_OF_BACKUP_PROCESS?  Do we not have to worry about online vs online backups and maintaining a consistent state of the backup files?
[2016-12-02 19:40:09] <killerspaz> Anyone notice howdocker-compose restartisn't honoringdepends_onreferences? Seems to restart in random order
[2016-12-02 19:44:58] <killerspaz> Start seems to work in the order i expect based on mydepends_onstatements, but stop/restart are always the same order, which i don't see any rhyme or reason to
[2016-12-03 21:08:25] <renegoretzka> heyo =) does anyone use docker with caddy (as webserver)?
[2016-12-04 09:28:27] <FuzzOli87> Anybody familiar with running a cql file on a Cassandra container?
[2016-12-05 04:54:57] <ely029> hey guys can I pull or push docker private registry without an internet?
[2016-12-05 04:55:16] <ely029> I am new here hehe.
[2016-12-05 04:58:19] <aios> ely029: if your private registry on your own local machine
[2016-12-05 04:59:30] <ely029> okaayyy then. thanks for answering :) I just keep studying docker env. Is kinda cool :)
[2016-12-05 07:05:13] <ely029> how can I run the 3 images at one time? using a Dockerfile? should I create a private registry for running this images?
[2016-12-05 07:07:33] <aios> ely029: docker-compose
[2016-12-05 07:08:52] <ely029> okay. Is it required in the server to create a private registry?
[2016-12-05 10:18:10] <christhomas> hey guys, so I am wondering how you all manage your docker compose definitions, say I have an api, built in a microservice architecture, it results in something like 50+ docker compose services and I am wondering, if there is a better way to setup all these services using tools instead of hardcoded yml files on disk
[2016-12-05 10:19:56] <christhomas> I guess a nicer way would be through some interface, where I can build the configurations and house them in a tool which I could run, store them in a backend database, then I could manage them easier, any tools which you guys run that would help? or do you run everything using docker run? I guess not, cause multi service architectures would be a bit tricky to manage
[2016-12-05 11:37:57] <Forecaster> I use Rancher
[2016-12-05 11:46:24] <christhomas> ok, thats a good answer, thanks
[2016-12-05 11:48:25] <christhomas> ok, I have another question, I am trying to do some port forwarding and for some reason it doesnt work.in my docker-compose service, I have ports: - "10001:9001" and inside my container, I run a simple php script to listen on port 9001 and output when a connection is made.if I shell into the container and do a curl 127.0.0.1:9001 it says connection successfulif I try to do that curl command outside the container like: curl 127.0.0.1:10001, it doesnt get any reply, even though I assumed it would forward the port 10001->9001any ideas?
[2016-12-05 11:50:04] <christhomas> if I use my host computers ip address, or the containers ip address, both dont work, I just get an empty response, it only works from inside the container, so its like I have forwarded the port, but I need to expose it as well?
[2016-12-05 11:57:53] <christhomas> ok, I just tried something random, seems that binding to ip address 0.0.0.0 makes it available externally, but 127.0.0.1 does not
[2016-12-05 13:13:30] <LuizTibo> Hello guys, I have problems with my docker.... I have a docker-compose with nginx, php-fpm and postgres. It's works, but my page don't loading completly. A think it could be something like 'CORS'. I think that the AJAX requests don't work. Anybody Know how can i resolve this problem?
[2016-12-05 14:15:45] <christhomas> CORS is not a docker problem, its a PHP/Javascript/Cross Origin Resource Sharing problem, you should go to ask in one of the other related channels
[2016-12-05 14:16:13] <christhomas> if you can execute php and it works and your problem is something in that code, then this isnt really the place to ask that, try a PHP / JS channel
[2016-12-05 14:17:27] <LuizTibo> Thanks@christhomas
[2016-12-05 14:22:23] <christhomas> yw
[2016-12-05 14:38:25] <skvoz> Hello , anybody know how install and work with supervisor in docker container ?
[2016-12-05 15:10:04] <LuizTibo> christhomas: I can to make it work with php5, the problem was the php version. But I could not find the php error log in my container, I did a test with php5 and it worked
[2016-12-05 18:04:00] <Forecaster> skvoz:  [<-LINK->] 
[2016-12-05 18:42:50] <renegoretzka> Hello.. anyone using caddy with docker?
[2016-12-05 18:50:17] <renegoretzka> is it usually to install like mysql and wordpress in the same docker? so i have separated every database and wordpress for each website? i shall i use one database docker for more as one website?
[2016-12-05 18:54:59] <dragon788> renegoretzka: typically Docker is designed to be used as a microservices style infrastructure, basically one service/responsibility per container
[2016-12-05 18:55:29] <renegoretzka> okay.. but should i separated the db container for multiple sites?
[2016-12-05 18:55:29] <dragon788> you can use something like Docker-Compose to link between them, which allows you to upgrade MySQL without reconfiguring and reinstalling your Wordpress
[2016-12-05 18:55:58] <dragon788> ahh, you may want to have separate databases, but you could probably do one DB container for a few sites depending on the performance requirements
[2016-12-05 18:56:10] <renegoretzka> ahh
[2016-12-05 18:56:15] <renegoretzka> so thats no really big prob
[2016-12-05 18:56:34] <renegoretzka> thanks bro
[2016-12-05 18:56:43] <renegoretzka> i think you helped me already :)
[2016-12-05 18:56:53] <renegoretzka> docker++
[2016-12-05 18:56:56] <dragon788> yeah, depends if you want each developer/site owner to be able to run it locally or just have one database instance for a hosting site
[2016-12-05 18:57:12] <renegoretzka> i host all the websites
[2016-12-05 18:58:45] <renegoretzka>  [<-CODE->] 
[2016-12-05 18:58:54] <renegoretzka> i think this will just run very good
[2016-12-05 18:59:56] <renegoretzka> i can add a volume to my wordpress to load my wordpress files from my host volume where i save all my stuff.. how to do the volume to it?
[2016-12-05 19:05:15] <renegoretzka> dragon788: you know what i mean?
[2016-12-05 19:14:25] <dragon788>  [<-CODE->]  [<-CODE->] iirc
[2016-12-05 19:15:03] <skvoz> Forecaster: tnx  i read this doc but, i have some problem with it , error with copy supervisor.config, system can't see config file, ok i copy this instruction in docker-compose.yml, but , when i started supervisor inside container i get error port look like this [<-LINK->] when i fixed it and start supervisor , process not worked and error log is clear :(
[2016-12-05 19:15:08] <renegoretzka> okay, but does it overwrite the wordpress php-files in the container with my files from my host?
[2016-12-05 19:15:36] <dragon788> if you specify a path that "conflicts" I believe the mapped ones will always overwrite/win
[2016-12-05 19:15:50] <renegoretzka> okay great i will try that :)
[2016-12-05 19:16:02] <renegoretzka> thank you very much@dragon788
[2016-12-05 20:12:24] <renegoretzka> how do i set a specific name to a service instead of dockerfiles_service_1?
[2016-12-05 20:13:49] <renegoretzka> ahhh is i container_name?
[2016-12-05 20:13:51] <renegoretzka> *it
[2016-12-05 21:01:35] <dragon788> yeah, it's your foldername as the prefix and then the containername
[2016-12-06 06:23:18] <ketchupmonkey> hi i was wondering if you all could help me I am working at a apache environment and I am planning on moving all the web applications(and they are a lot) to docker but I was wondering how will I be able to let all containers run at the same time since most of them will be using port 80 and 443. So far the only idea i have is should i just assign each container a random port number(e.g 81 for one and the next one will be 82 and etc.) which translates it to 80 & 443 and run a reverse proxy to point to those random port numbers for each or is there a better solution?
[2016-12-06 07:02:36] <ketchupmonkey> any help plz?
[2016-12-06 07:09:34] <skvoz> ketchupmonkey: very long question , you want started some container with different application ?
[2016-12-06 07:31:27] <ketchupmonkey> skvoz: : Thanks for replying. sorry for the long question. basically i have a bunch of web apps and i want to dockerize them but i am just concerned coz all of them will be using port 80 and 443 which may cause some port conflicts any way I could approach this?
[2016-12-06 07:59:30] <skvoz> ketchupmonkey: look at docker-compose you can use many options for comunicate between container and user
[2016-12-06 08:08:43] <ketchupmonkey> but if i deploy several containers exposing ports 80 & 443 wouldn't there be a conflict?
[2016-12-06 08:11:19] <Forecaster> yes
[2016-12-06 08:11:59] <ketchupmonkey> how can I deploy several dockerized web applications that each use port 80 & 443 in one host?
[2016-12-06 08:12:25] <Forecaster> you can't
[2016-12-06 08:12:34] <Forecaster> you have to use different ports
[2016-12-06 08:13:43] <duaneleem> I use different ports, and use nginx to proxy pass to each of the docker web apps (each have their own port)
[2016-12-06 08:14:00] <ketchupmonkey> oh cool
[2016-12-06 08:14:15] <ketchupmonkey> so you just need to take note of what port you assigned to which container then
[2016-12-06 08:14:33] <duaneleem> yea, you can see which ports are taken when you "docker ps" under ports
[2016-12-06 08:15:04] <ketchupmonkey> can apache do to redirects too? I know that sounds like a silly question but I am more familiar doing redirects with nginx than with apache. I'm just not sure about the performance
[2016-12-06 08:15:09] <duaneleem> u can run each docker web application "docker run -p 8080:80"
[2016-12-06 08:15:32] <ketchupmonkey> sweet thanks@duaneleem@Forecaster@skvoz
[2016-12-06 08:15:46] <duaneleem> oh haven't tried it with apache for proxy pass
[2016-12-06 08:16:11] <Forecaster> doing proxy passes is awful in apache
[2016-12-06 08:16:17] <Forecaster> such a config nightmare
[2016-12-06 08:16:23] <duaneleem> screw that haha
[2016-12-06 08:16:39] <Forecaster> I've tried and never gotten it to work correctly
[2016-12-06 08:16:45] <ketchupmonkey> oh really? damn. the environment I'm managing is mainly using apache.
[2016-12-06 08:17:02] <Forecaster> it should be possible, but finding out how is hard
[2016-12-06 08:17:30] <ketchupmonkey> cool. Oh well i guess back to googling then
[2016-12-06 08:18:16] <ketchupmonkey> Thank you so much guys
[2016-12-06 08:18:41] <duaneleem> hope that was helpful, np
[2016-12-06 09:15:40] <ely029> I created a docker-compose.yml filehere is the code `frontend:  image: ubuntu:14.04web:  build: .  command: apt-get update  command: apt-get install php7.0  command: apt-get install apache2  command: apt-get install subversion  volumes: [<-CODE->] ports: [<-CODE->] links: [<-CODE->]  [<-CODE->] Is there something wrong in my yml file?
[2016-12-06 09:17:17] <sebmoule> ketchupmonkey: you can give a look at Traefik proxy which allows you to configure dynamically your proxy just specifying some docker labels.
[2016-12-06 09:38:32] <ketchupmonkey> sebmoule: : wow i didn't know there was something that could do that. Thanks :)
[2016-12-06 11:35:21] <reticool> hello. I have a problem with docker. I deploy with docker-compose django app. I do small change in one file (delete one line), build, up, and if I do exec cat /path_to_file.py I see this deleted line. It exist still. I don't want stop containers and delete all images, but I can't force it.I try:docker-compose build --force-rm --no-cachedocker-compose up -d --force-recreate --remove-orphans
[2016-12-06 12:34:03] <reticool> hello. I have a problem with docker. I deploy with docker-compose django app. I do small change in one file (delete one line), build, up, and if I do exec cat /path_to_file.py I see this deleted line. It exist still. I don't want stop containers and delete all images, but I can't force it.I try:docker-compose build --force-rm --no-cachedocker-compose up -d --force-recreate --remove-orphansproblem solved, I do:docker-compose builddocker-compose downdocker-compose up -d
[2016-12-06 20:09:10] <RahulConqueror> Please guide me how to start on learning basics of Docker DevOps
[2016-12-07 04:43:17] <siassaj> ave
[2016-12-07 04:44:31] <siassaj> I am curious, when I want to deploy an image that I've built locally is it possible (or even plausible) to upload only that top application layer that's changed, and let my machines fetch the lower layers from cache?
[2016-12-07 05:05:01] <lakshmantgld> siassaj: I think trhe layers are introduced for reducing the payload during the uploads. So, the layers are automatically recognized and only those layers that are changed, will be sent as payload.
[2016-12-07 05:21:33] <javafun> Hi Guys, does anyone successfully manage the volume on windows?
[2016-12-07 05:24:59] <javafun> Here is my docker commanddocker run -d -p 5984:5984 --privileged=true -v d:/data:/usr/local/var/lib/couchdb --name couchdb klaemo/couchdb
[2016-12-07 05:26:15] <javafun> the container running status is up running, and I successfully put the data in the couchdb
[2016-12-07 05:26:35] <javafun> however, I can't find the couchdb file from my mount volume
[2016-12-07 05:42:57] <javafun> ignore above, my bad. The latest couchdb expose data volume changed to/opt/couchdb/data
[2016-12-07 07:00:24] <siassaj> Lakshman-LD: ok, that makes sense. So i think maybe I need a server on the same network/data centre as my app servers that will pull from github, build the image then deploy (meaning only the shared layers get sent to the app servers)
[2016-12-07 07:00:38] <siassaj> so probably time to go figure out how to do that, thank you :)
[2016-12-07 07:09:50] <lakshmantgld> :)
[2016-12-07 13:24:32] <dragon788> siassaj: there is a docker container for the registry that is free to use
[2016-12-07 14:41:58] <huangyanxiong01>  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2016-12-07 14:47:51] <marcelmfs> huangyanxiong01: you probably hit a bug, what docker version?
[2016-12-07 14:48:28] <marcelmfs> one possible workaround:docker rm -f $(docker ps -qa)
[2016-12-07 14:55:42] <huangyanxiong01> marcelmfs: ```
[2016-12-07 14:55:46] <huangyanxiong01> ~ docker --versionDocker version 1.12.3, build 6b644ec
[2016-12-07 15:01:32] <huangyanxiong01> marcelmfs: thank you,this error reloved
[2016-12-07 15:07:16] <huangyanxiong01> marcelmfs: why docker use id:7af7a7fe75de name:node-app image?But,my docker-compose.yml web service use node image
[2016-12-07 15:38:21] <desprit> I have docker-compose file with about 7 services in it. How should I organize tests? Make a separate service for testing  to test all my containers or do tests inside each container?
[2016-12-07 15:50:36] <aios> desprit: make one service with volumes_from: all services - make inside your test logic and environment and set depends_on all services from test-service - profit
[2016-12-07 15:50:57] <aios> desprit: круто я придумал да?)
[2016-12-07 15:54:54] <desprit> aios: xD PM
[2016-12-07 16:16:33] <scippio> Hi all ... I starting my container via docker-compose with this command:/bin/bash -c "envsubst \'$$NGINX_UPSTREAM\' < /etc/nginx/nginx.conf.template > /etc/nginx/nginx.conf && nginx -g \'daemon off;\'"
[2016-12-07 16:17:05] <scippio> all is fine... but docker kill -s HUP <containerID> does not work :(
[2016-12-07 16:49:20] <scippio> docker exec <containerID> nginx -s reloadworks fine ... 
[2016-12-07 17:10:33] <marcelmfs> scippio: most probably because you're not using a signal forwarding process manager likehttps://github.com/krallin/tini
[2016-12-07 17:11:27] <marcelmfs> huangyanxiong01: you needcontainer_name: nodeandhostname: nodein order for docker to correctly associate to the container name and hostname.
[2016-12-07 17:24:20] <agustinvinao> OSX question: Im using native docker and when i go to the console my docker-machine is not active, is that a normal thing? I need to do eval $(docker-machine env default) to make it available
[2016-12-07 17:33:10] <scippio> marcelmfs: ok... thanks.. I'll try tini..
[2016-12-07 17:40:41] <renegoretzka> heyo, can someone help me please? i want to move my websites (wordpress) to my new host with docker. i have a container with mysql and i am wondering how i will move my database to the new server.. do you know how i can restore my databases?
[2016-12-07 17:44:41] <dragon788> you can either try to export the container and layers with tar, or you could use the built in MySQL command line to create a backup, or you could add something like PHPMyAdmin to administer the MySQL from a web server container, been a while since I've done any of that though
[2016-12-07 17:45:42] <renegoretzka> and how do i restore the databases?
[2016-12-07 17:45:57] <renegoretzka> i have 1 mysql container for several websites
[2016-12-07 17:47:00] <dragon788> there should be a mysql restore command that you can use to import the export
[2016-12-07 17:47:17] <renegoretzka> hmm
[2016-12-07 17:47:20] <dragon788> I'd check [<-LINK->] , I'd wager it's a common query
[2016-12-07 17:47:32] <renegoretzka> okay thanks bro
[2016-12-07 17:47:35] <renegoretzka> i will check dat =)
[2016-12-07 18:47:39] <scippio> marcelmfs: is this right? [<-CODE->] 
[2016-12-07 19:20:33] <Trezamere> If I've got a docker container running docker (teamcity agent running builds) what is the best way to mount a volume in the 'parent' container into the 'child' container?
[2016-12-07 19:22:25] <Trezamere> The 'parent' container has the host docker socket bound (-v /var/run/docker.sock:) so when the agent (parent container) tries to run a new container and pass some -v flags; the -v flags don't get mounted correctly as far as I can tell
[2016-12-07 19:27:55] <Trezamere> presumably because it's not actually a child; but a sibling; and the directory trying to be mounted doesn't actually exist outside the 'parent'
[2016-12-07 20:01:18] <renegoretzka> is it possible to access my containers on my server with kitematic?
[2016-12-07 20:01:23] <renegoretzka> (dedicated)
[2016-12-07 20:36:48] <dragon788> Trezamere: I haven\'t actually messed with volumes in that manner, but have you tried using "volumes_from" by creating a sibling of the parent container that maps in the volumes from the host you want to use and then having the spun up agents using  volumes_from?
[2016-12-07 20:54:49] <sbbowers__twitter> Hello, is it possible to mount the mysql socket file directly into a docker container?
[2016-12-07 20:58:09] <sbbowers__twitter> Or basically any method that would allow me to connect to a vanilla mysql server running on the host.
[2016-12-07 21:09:28] <dragon788> hmmm, you could probably mount the socket, though you might need to run the container with--privilegedto do so, any particular reason?
[2016-12-07 21:11:41] <renegoretzka> whats the hell
[2016-12-07 21:11:50] <renegoretzka> ```MySQL Connection Error: (2002) Connection refusedWarning: mysqli::__construct(): (HY000/2002): Connection refused in - on line 19Warning: mysqli::__construct(): (HY000/2002): Connection refused in - on line 19MySQL Connection Error: (2002) Connection refusedWarning: mysqli::__construct(): (HY000/2002): Connection refused in - on line 19MySQL Connection Error: (2002) Connection refused[07-Dec-2016 19:59:18] NOTICE: fpm is running, pid 1[07-Dec-2016 19:59:18] NOTICE: ready to handle connections
[2016-12-07 21:11:54] <renegoretzka> oops sorry
[2016-12-07 21:11:57] <renegoretzka> ```
[2016-12-07 21:12:11] <renegoretzka>  [<-CODE->] 
[2016-12-07 21:12:24] <renegoretzka> whats that?
[2016-12-07 21:12:31] <renegoretzka> i cant connect to my mysql
[2016-12-07 21:13:05] <renegoretzka> ```
[2016-12-07 21:13:12] <renegoretzka>  [<-CODE->] 
[2016-12-07 21:13:52] <dragon788> is it a user/network restriction that hasn\'t been "GRANT"ed access in the database?@renegoretzka
[2016-12-07 21:14:16] <renegoretzka> thats the config
[2016-12-07 21:14:30] <renegoretzka> i can access my sql by phpmyadmin
[2016-12-07 21:14:35] <renegoretzka> but not with my wordpress
[2016-12-07 21:15:05] <renegoretzka> i get the error in the terminal of the wordpress container
[2016-12-07 21:18:36] <dragon788> hmmm, and you provided a grant towordpresswith the password you specified?
[2016-12-07 21:18:56] <dragon788> I'd check the tables and make sure the permissions are present
[2016-12-07 21:19:40] <renegoretzka> but wouldnt phpmyadmin not run?
[2016-12-07 21:21:43] <dragon788> the way it is set up I think phpmyadmin isn't using a username and password to login, so it may be accessing via root permissions
[2016-12-07 21:22:33] <renegoretzka> hmm
[2016-12-07 21:26:40] <renegoretzka> its because of php7.0-fpm@dragon788
[2016-12-07 21:26:58] <renegoretzka> i think that version has error.. when i use latest php5.6 and apache it works
[2016-12-07 21:28:03] <renegoretzka> but i really want php7 lol
[2016-12-07 21:35:58] <renegoretzka> dragon788: you have an idea?
[2016-12-07 21:36:07] <renegoretzka> its because of fpm i guess
[2016-12-07 22:43:27] <dragon788> I don't, I haven't messed with PHP in ages, I'd file an issue against their repository and see if you can replicate it outside of Docker
[2016-12-07 22:44:41] <renegoretzka> dragon788: i really have big probs
[2016-12-07 22:44:46] <renegoretzka> i cant start my shit
[2016-12-07 22:44:57] <renegoretzka> i just wanted to move my domain to my new server with docker
[2016-12-07 22:45:05] <renegoretzka> but now nothing works
[2016-12-07 22:45:08] <renegoretzka> i get to many error
[2016-12-07 22:45:31] <renegoretzka> WARNING: proxy_header is deprecated and will be removed soon; use header_upstream instead. [<-LINK->] Activating privacy features... done.
[2016-12-07 22:45:35] <renegoretzka> what the fuck is that
[2016-12-07 22:47:31] <dragon788> hmmm, no idea on that one, you should make sure you have your new Docker hosting secured with a secure SSH key and avoid using passwords as much as possible
[2016-12-07 22:48:15] <renegoretzka> i dont have any passwords
[2016-12-07 22:50:00] <renegoretzka> why does my container have an unique id when i run the container in front of the name??
[2016-12-07 22:51:50] <dragon788> every "instance" of a container is a unique run, this allows you to scale up to 3x web containers in front of 1x DB container without doing too much extra work
[2016-12-07 22:52:17] <renegoretzka> but the container name is unique!
[2016-12-07 22:53:11] <dragon788> when you rundocker psit is different than the one you ran it with? or running it withdocker-compose ps?
[2016-12-07 22:54:20] <renegoretzka> yes its different
[2016-12-07 22:54:30] <renegoretzka> docker-compose is correct
[2016-12-07 22:54:49] <renegoretzka> but cant kill the container
[2016-12-07 22:56:24] <renegoretzka> dragon788: any idea??
[2016-12-07 23:00:59] <dragon788> you probably need todocker-compose stopthendocker-compose killin the directory where yourdocker-compose.ymlis located
[2016-12-07 23:01:52] <dragon788> you can also usedocker killto kill the container if you get its ID viadocker ps, a handy shortcut is you only need enough characters to have it be unique, I've found 4-6 usually does it
[2016-12-08 02:46:22] <huangyanxiong01> marcelmfs: thank you
[2016-12-08 05:50:43] <ely029> I am trying to make a docker-compose.yml file for creating 3 services ( I dont know if this is the right term for it) the services are follows:1.frontend2.backend3.databasehere is my codedocker-composer.yml`frontend:    image: eboraas/apache-php    build: ./dockerfile-frontend    links: [<-CODE->] database:    image: rsmoorthy/mssql    environment: [<-CODE->] `I dont know how can I connect the
[2016-12-08 09:37:19] <ely029> guys I always get this error when I running this:  sudo docker-compose up [<-CODE->] this is my docker-compose.yml [<-CODE->] 
[2016-12-08 09:38:44] <ely029> silentnull: 
[2016-12-08 09:38:48] <ely029> jeremyjs: 
[2016-12-08 09:38:57] <ely029> bfirsh: 
[2016-12-08 09:41:11] <marcelmfs> scippio: I'm not sure. In order for tini to work as expected, it needs to be your entrypoint, and be assigned PID 1.
[2016-12-08 09:41:49] <marcelmfs> only then tini will forward signals to it's child processes
[2016-12-08 10:33:52] <scippio> marcelmfs: I had resolved the issue ... I created a bash scrip with all my commands + nginx exec at the end and tini as entrypoint ... and all is fine now :)
[2016-12-08 14:15:12] <ssharpjr> New to resin.io.  I have a series of RPI devices running in a production environment.  Each has the same code but they each have a unique identifier that is used in an API call to get data specific to what that device is connected to.  I need to deploy new devices with their unique identifier preset.  Is this possible?  Also, can I preset a device name instead of getting a random name generated?  Thanks in advance.
[2016-12-08 14:15:36] <ssharpjr> Err, wrong chat, sorry
[2016-12-08 19:16:39] <sbbowers__twitter> hello, I'm trying to define static IP addresses in my IPAM config using the aux_addresses key. My hosts don't get the IP addresses in this dictionary. Is there a trick to it? I'm just specifying host: ipaddress in the aux_addresses dictionary
[2016-12-08 19:18:03] <sbbowers__twitter> matching the host keys in the aux_addresses dictionary to the keys in my services dictionary.
[2016-12-08 19:23:14] <sbbowers__twitter> looks like I have docker-compose version 1.8.1 Thats what pip pulls. do I need to upgrade or something?
[2016-12-08 19:27:55] <sbbowers__twitter> upgraded to 1.9.0. still not getting the IPs from aux_addresses
[2016-12-08 19:28:48] <dragon788> sbbowers__twitter: is that a function of a certain version of the docker-engine as well?
[2016-12-08 19:30:12] <sbbowers__twitter> I assume so. my docker is 1.12.3
[2016-12-08 19:31:09] <sbbowers__twitter> basically I'm doing this: [<-LINK->] 
[2016-12-08 19:32:54] <sbbowers__twitter> which appears to be the latest stable. its had static IP support for quite awhile
[2016-12-08 19:41:46] <dragon788> so you have the ip_range and gateway and subnet settings defined as well in the same range as your aux_ips?
[2016-12-08 19:46:51] <dragon788> that example is rather confusing because it defines multiple non-overlapping networks in one go
[2016-12-08 19:47:39] <dragon788> but I think the gist of it is that you need the range for all containers to pull from, a dhcp pool defined for dynamic hosts, and then you can set up static mappings outside of the DHCP pool
[2016-12-08 19:49:42] <sbbowers__twitter> I'm missing the range.  found that it works if I specify anetworks.<network>.ipv4_addresskey on the service itself.
[2016-12-08 19:49:49] <sbbowers__twitter> I'll see if I can get the range to work.
[2016-12-08 19:50:19] <dragon788> yeah, it also sounds like you need to define the "top level" networks and then the "service level" networks, [<-LINK->] 
[2016-12-08 19:51:00] <dragon788> weird, they have some funky documentation, [<-LINK->] 
[2016-12-08 19:54:43] <sbbowers__twitter> thanks for some ideas. gotta run
[2016-12-08 19:55:16] <renegoretzka> heyo.. i get error 502 bad gateway using fpm and caddyserver
[2016-12-08 19:55:34] <renegoretzka> but i dont get why
[2016-12-08 20:06:44] <renegoretzka> Can anybody help me with this issue?
[2016-12-08 23:24:47] <sbbowers__twitter> that message means that caddyserver can't talk to your fpm server.
[2016-12-09 00:47:03] <CarlosAmaral> hey
[2016-12-09 00:47:57] <CarlosAmaral> im trying to rundocker -H <IP address> -d &but I get aflag provided but not defined: -d
[2016-12-09 00:48:03] <CarlosAmaral> any clue?
[2016-12-09 00:48:29] <CarlosAmaral> my version is 1.12.3 and im running docker on ubuntu server 16.04
[2016-12-09 09:37:37] <mmisztal1980> when running a container in swarm, can I obtain the host's IP somehow?
[2016-12-09 10:58:01] <tsm91> hi
[2016-12-09 11:01:02] <tsm91> i would like to dockerize a project that consist of:a frontend codebase (angular 2, after npm run build all the STATIC files i need is in the dist directory)\na backend codebase (a nodejs app w/o any transpilation build process)the production nginx.conf file looks like this: [<-CODE->] the backend api got a dependency for mongodb, so i will need a node, mongo, nginx Dockerfile
[2016-12-09 11:01:39] <tsm91> what i am not sure is,  to which image's filesystem should i put the frontend static files? It should be in the nginx image. Am i correct?
[2016-12-09 11:02:50] <am0nshi> if it 100% static its better to put them into ngixn, but you can mount physical directory into both images, its depends on how you will build your containers
[2016-12-09 11:46:29] <kschlesselmann> If they're only needed in the frontend I'd put them there, yes. After you all you don't ship a nginx but your frontend.
[2016-12-09 11:47:56] <CarlosAmaral> any clue on my problem?
[2016-12-09 12:05:07] <am0nshi> CarlosAmaral: what do you try to do with this command?
[2016-12-09 13:56:51] <CarlosAmaral> add my ip address to docker@am0nshi
[2016-12-09 13:58:04] <am0nshi> CarlosAmaral: for which purposes? it's not local docker?
[2016-12-09 13:59:11] <am0nshi> CarlosAmaral: thisdocker -H <IP address>similar for justdockerbut on remote host. what you suppose to be when you just rundocker -d?
[2016-12-09 14:03:26] <CarlosAmaral> yeah it's a docker on a vm, i dunno i was following the deep dive tut on pluralsight
[2016-12-09 14:05:21] <am0nshi> CarlosAmaral: -d it's demonize container, its not main, its secondary directive, which often used withdocker runcommand. in puredockerthere is no -d, only indocker run
[2016-12-09 14:40:31] <CarlosAmaral> oh ok got it ty
[2016-12-09 15:53:14] <sbbowers__twitter> so docker-compose validates the yaml file and fails if there are extra keys. Is there a place to put non-validated config data that I can use as templates for other things?
[2016-12-09 15:53:57] <sbbowers__twitter> for instance, I have an app with many services, which are mostly the same, minus a few environment variables.
[2016-12-09 15:54:33] <JnMik>  [<-LINK->] 
[2016-12-09 15:54:36] <sbbowers__twitter> i'd like to make a configuration template with all of the configuration for my apps, and then overlay the environment vars related for each service.  YAML supports this.
[2016-12-09 15:55:50] <sbbowers__twitter> I'm aware of environement variables. I can't put the service template inside of an environement variable inside of a service definition.
[2016-12-09 16:01:56] <sbbowers__twitter> This is exactly what I'm talking about. I guess its not possible. [<-ISSUE->] 
[2016-12-09 18:10:53] <JnMik> Ok so you want some common variables shared accross all the services, and then you want to specify some environment variables for each specifics ?
[2016-12-09 18:32:36] <dragon788> you might be better served writing a simple script that outputs the correct yaml for your current environment. there are so many libraries for Ruby/Python/etc to parse and output YAML, and a simple text replace wouldn't be many lines at all.
[2016-12-09 18:45:00] <drew-r> god damn it is there a single CI platform that does docker properly
[2016-12-09 18:45:34] <dragon788> drew-r: docker properly in what way?
[2016-12-09 21:39:04] <killerspaz> I want something to read my docker compose file and set up the UI for me, then allow me to add health monitoring for evented orch
[2016-12-09 22:38:31] <dragon788> killerspaz: have you looked at RancherOS?
[2016-12-09 22:50:40] <drew-r> dragon788: docker 1.10 at least and supports compose and doesn't do weird shit like codefresh
[2016-12-09 22:51:44] <dragon788> tried AWS or looked at Linode and managing your own version of Docker?
[2016-12-09 23:26:12] <FuzzOli87> Hello all! Maybe you guys can help me out, been beating this up all day.
[2016-12-09 23:26:55] <FuzzOli87> I'm trying to create a base docker image that would allow me to use volumes and have them be created with the same permission as the host. This is the base image for our containers:
[2016-12-09 23:27:02] <FuzzOli87>  [<-LINK->] 
[2016-12-09 23:27:55] <FuzzOli87> This is the Dockerfile for using it in an application:
[2016-12-09 23:27:56] <FuzzOli87>  [<-LINK->] 
[2016-12-09 23:28:46] <dragon788> FuzzOli87: you can see if this gives you any more clarity [<-LINK->] 
[2016-12-09 23:35:58] <FuzzOli87> If I mount a dist Volume in the Dockerfile dist and run a build step it creates all the files on my host, with the correct permissions. I run it like so [<-CODE->] 
[2016-12-09 23:36:14] <FuzzOli87> dragon788: That is where I got this whole base image idea from :D
[2016-12-09 23:37:04] <FuzzOli87> However, I don't want to add aVOLUME ./dist:$HOME/distto this Dockerfile bc I'm going to use it to build my final production  build
[2016-12-09 23:37:34] <FuzzOli87> I created a set of docker-compose.yamls that extend each other and pass in variables etc
[2016-12-09 23:37:35] <FuzzOli87>  [<-LINK->] 
[2016-12-09 23:39:20] <FuzzOli87> the docker.compose.yml used the Dockerfile I used in the previous example. Yet if I try doing this: [<-CODE->] 
[2016-12-09 23:39:33] <FuzzOli87> It generates the dist directory on my host as root. I don't understand why when I ran a similar command against the image this compose file is based from it created the dist directory with proper permission but running it like this does not.
[2016-12-10 08:50:04] <lucperkins> Hey y’all, I have a pretty basic question (I’m a bit of a newcomer) but I can’t seem to wrap my head around it. Let’s say that I have an HTTP server running inside of a Docker container on my laptop. I want to test it in conjunction with, say, MySQL running on my laptop. How do I enable the process running inside the container to talk to the DB? I’ve tried some approaches I saw online, like using a—add-hostflag, but to no avail.
[2016-12-10 08:50:55] <lucperkins> (this would be a non-containered DB)
[2016-12-10 18:10:30] <GastroGeek> @lucperkins rather than me re-hashing... read this:https://stackoverflow.com/questions/24319662/from-inside-of-a-docker-container-how-do-i-connect-to-the-localhost-of-the-machHope it helps
[2016-12-10 18:31:00] <lucperkins> GastroGeek: Thatdoeshelp, although it turns out my problem was a stupid syntax error at the application level. Derp. Learned a bunch from that SO question, though, so thanks :)
[2016-12-10 20:44:14] <GastroGeek> lucperkins: heh, glad it helped! :)
[2016-12-10 21:28:56] <Forecaster> Hm, I'm having an odd issue
[2016-12-10 21:29:09] <Forecaster> I'm trying to set up a php <-> nginx environment
[2016-12-10 21:29:29] <Forecaster> I have them in separate containers, with a link from the nginx container to the php one called "php"
[2016-12-10 21:30:10] <Forecaster> in the nginx config I have a fastcgi_pass to "php:9000", which fails with a bad gateway "connection refused"
[2016-12-10 21:30:40] <Forecaster> if I ping "php" from inside the nginx container it tells me it\'s pinging the ip 103.224.182.212
[2016-12-10 21:30:52] <Forecaster> but the ip of the php container is 10.42.187.89
[2016-12-10 21:31:09] <Forecaster> if I replace "php" with 10.42.187.89 in the nginx config for the cgi_pass it works
[2016-12-10 21:31:20] <Forecaster> why is the link pointing to the wrong ip? D:
[2016-12-10 21:37:31] <Forecaster> it's not the host ip
[2016-12-10 23:11:28] <GastroGeek> @Forecaster - are you doing the linking at runtime via docker run --link ? might be worth posting your full command and any Dockerfile/docker-composer.yml etc.I just ran docker-composer up on this: [<-CODE->] and it links through OK (assuming you set up the nginx/php confs OK) - but the php:9000 part appears to be working. [<-CODE->] 
[2016-12-10 23:12:23] <GastroGeek> @Forecaster - also, I think --link is deprecated?https://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/
[2016-12-10 23:43:38] <Forecaster> Hm
[2016-12-10 23:43:44] <Forecaster> well, the link is created by Rancher
[2016-12-10 23:43:51] <Forecaster> I believe it uses -links
[2016-12-10 23:44:51] <Forecaster>  [<-CODE->] 
[2016-12-10 23:45:16] <Forecaster> that's the docker-compose it generates
[2016-12-10 23:48:21] <Forecaster> is that the same as run --link?
[2016-12-10 23:51:42] <Forecaster> GastroGeek: 
[2016-12-10 23:52:52] <Forecaster> Rancher uses version 1 of docker-compose though
[2016-12-10 23:52:56] <Forecaster> it can't use version 2
[2016-12-11 00:02:55] <Forecaster> hm, maybe it can, there's been a few new versions...
[2016-12-11 00:03:05] <Forecaster> but how to upgrade it without loosing my settings
[2016-12-11 00:03:13] <Forecaster> I don't know if they're kept inside the container or not
[2016-12-11 00:04:05] <Forecaster> ah there's a process for it in their docs, good
[2016-12-11 00:35:42] <Forecaster> Hm, well, I updated rancher which now supports version 2, which allows networks, and I specified a network in my setup instead of the link
[2016-12-11 00:35:54] <Forecaster> but now when I try to go to the site it says it can't be reached...
[2016-12-11 00:39:36] <Forecaster> does the container need to be on some network to be accessible from the outside even when a port is open?
[2016-12-11 01:04:14] <Forecaster> I can get it working using a link and the container ip
[2016-12-11 01:04:23] <Forecaster> other combinations will not work
[2016-12-11 01:04:35] <Forecaster> : |
[2016-12-11 01:05:08] <Forecaster> time for bed. Continue tinkering tomorrow
[2016-12-11 01:05:16] <Forecaster> I'd really like this to work properly
[2016-12-11 01:06:49] <Forecaster>  [<-CODE->] This works, but if I remove the link it stops working, or if I try to use the link name instead of the ip
[2016-12-11 10:54:45] <renegoretzka> Hello :)
[2016-12-11 10:58:53] <renegoretzka> I have a problem with a container, it says that it is restarting.. what can be the reason?
[2016-12-11 11:33:53] <Forecaster> what do you mean it says it's restarting?
[2016-12-11 11:33:54] <Forecaster> where?
[2016-12-11 12:10:39] <renegoretzka> Forecaster: it is image caddy and i wanted to exec -it to look at an error, where i have seen that docker keeps restarting it
[2016-12-11 12:11:32] <Forecaster> I don't know what that is
[2016-12-11 12:11:52] <renegoretzka> Error response from daemon: Container 82369cb8f8ccb21a8b0292b6d52dcc66b9651a8da3f2d2465af51be9174bf367 is restarting, wait until the container is running
[2016-12-11 12:11:56] <renegoretzka> thats the error
[2016-12-11 12:12:06] <Forecaster> but if the container was started with-restart alwaysor-restart unless_stopped
[2016-12-11 12:12:16] <Forecaster> it's going to keep restarting if it fails
[2016-12-11 12:12:19] <renegoretzka> its restart always
[2016-12-11 12:12:42] <Forecaster> then the container is probably failing somehow and docker restarts it
[2016-12-11 12:12:50] <renegoretzka> where do i see the docker log?
[2016-12-11 12:13:24] <Forecaster> dunno
[2016-12-11 12:13:31] <Forecaster> I use Rancher to manage my containers
[2016-12-11 12:13:37] <renegoretzka> rancher?
[2016-12-11 12:13:42] <renegoretzka> gonna look at that
[2016-12-11 12:13:47] <Forecaster> it's an orchestration system
[2016-12-11 13:36:54] <vadviktor> renegoretzka: docker logscan hrelp you look into the docker container for stdout and stderr output. That is the first you should look at.
[2016-12-11 15:39:16] <GastroGeek> @renegoretzka - you could also try running with: [<-CODE->] And see if it outputs anything to the console/screen during boot. If you have volumes, its likely a permissions issue. If it has requirements (like MySQL) then possibly misconfig/missing requirement etc.
[2016-12-11 23:12:24] <jjohnson1994> Hello, I'm trying to install mysql-server in my Dockerfile but the script breaks when the MySQL installer asks to set the root password. Is there a way I can supply a password in the Dockerfile somewhere? I'll put my Dockerfile bellow... [<-CODE->] 
[2016-12-11 23:15:07] <Forecaster> why are you making a mysql image instead of using the official one?
[2016-12-11 23:15:35] <jjohnson1994> I'm not making a MySQL images, plus I just want to learn Docker
[2016-12-11 23:16:05] <Forecaster> you're making an image with mysql in it
[2016-12-11 23:16:11] <Forecaster> :P
[2016-12-11 23:16:30] <rollymaduk> jjohnson1994: have you tried installing quietly using the -q -y switch
[2016-12-11 23:16:56] <rollymaduk> FROM ubuntu:16.04RUN apt-get update && apt-get install -q -y \\git \\nginx \\mysql-server \\php7.0-fpm php-mysql \\php7.0-mysql
[2016-12-11 23:17:02] <Forecaster> the official mysql image gets the root password from an environment variable you supply when you run it in a container
[2016-12-11 23:17:16] <jjohnson1994> rollymaduk: I'll try that now, thanks :)
[2016-12-11 23:17:17] <Forecaster> I don't know how they implement that though
[2016-12-11 23:19:34] <rollymaduk> FYI I agree with@Forecaster.. you really should use the official image and its best practice to have a single container manage a single app/service, you can alway connect them by linking
[2016-12-11 23:20:02] <jjohnson1994> Forecaster: &@rollymadukso would you leave mysql-server out of the Dockerfile and include the image later on in the docker-compose.yml?
[2016-12-11 23:20:45] <jjohnson1994> I'm trying to set up a LEMP environment if it helps
[2016-12-11 23:24:40] <rollymaduk> I really don't know much about LEMP but a major advantage of containerization is to have you services independent and atomic, which enables easy scaling, microservices and better  failover, its simply easier to reason about, you can then interconnect these by linking them or orchestrate with docker-compose
[2016-12-11 23:35:26] <rollymaduk> So I guess LEMP is a stack like MEAN and setting that up with docker could be having mongo on a separate container  and my express node.js  on a different container , I then orchestrate and connect using docker compose
[2016-12-12 04:09:06] <quickeee> hi any documentation to setup java developer environment using docker( i want to have a docker machine with maven/jdk/tomcat server) and developer will use eclipse to develop application.. any guidelines?
[2016-12-12 08:22:06] <Forecaster> jjohnson1994: I have Nginx, PHP and MySQL all in separate containers
[2016-12-12 08:22:28] <Forecaster> I use pre-made images for each of them
[2016-12-12 08:24:21] <Forecaster> mysql:latestphp:7-fpmnginx:latest
[2016-12-12 09:13:40] <Forecaster> There is also a pre-made but unoffical nginx+fpm image, but that uses php5
[2016-12-12 10:23:16] <jjohnson1994> Thanks@Forecaster, would you mind sharing your docker-compose.yml?
[2016-12-12 10:24:08] <Forecaster>  [<-CODE->] 
[2016-12-12 10:24:41] <Forecaster> There
[2016-12-12 10:28:55] <jjohnson1994> Thanks a lot@Forecaster, I'm missing a lot of that in mine
[2016-12-12 10:48:13] <Forecaster> No problem
[2016-12-12 11:59:58] <satterly> Is docker compose yaml format version 2.1 supported in the downloadable docker app for mac, yet?
[2016-12-12 12:49:49] <GastroGeek> @satterlyAccording to the notes, version 1.12+ supports it and I appear to have 1.12.3 via latest update? [<-CODE->] 
[2016-12-12 12:49:56] <GastroGeek>  [<-LINK->] 
[2016-12-12 14:08:52] <satterly> GastroGeek: Looks like I have the same version of Docker for Mac but it was only running docker-compose 1.8.1. To get version 1.9.0 which supports version 2.1 compose files  I had to download the latest version using curl . see [<-LINK->] 
[2016-12-12 14:50:13] <GastroGeek> satterly: - good spot - wonder why they didn't bother bundling it Docker for Mac... meh.
[2016-12-12 17:10:05] <WillSkates> Hi everyone is there a way to read the logs for a non-entrypoint process running inside a container? Whenever I try to read from /proc/<pid>/fd/1 I get "permission denied"
[2016-12-12 17:26:48] <WillSkates> ^^ no worries I didnt realise I could read them from the host.
[2016-12-13 17:26:45] <PetrusKiendys> it's not possible to have conditionals or templating in docker-compose.yaml files right?
[2016-12-13 17:27:50] <PetrusKiendys> I've ended up with something like this for a service I'm composing:
[2016-12-13 17:28:33] <PetrusKiendys>  [<-CODE->] 
[2016-12-13 17:29:45] <PetrusKiendys> and then I :upload one of these files manually:elasticsearch-master.yml  elasticsearch-slave1.yml  elasticsearch-slave2.yml
[2016-12-13 17:31:05] <PetrusKiendys> and comment out the volumes mounts that are unused, surely there must be an easier way
[2016-12-13 17:31:49] <PetrusKiendys> I think I'll make a bash script if docker-compose doesn't support conditionals out of the box
[2016-12-13 17:32:10] <PetrusKiendys> feel free to send me a PM if you have any tips :)
[2016-12-13 18:14:56] <dragon788> PetrusKiendys: I think with newer Docker-Compose you can use a base config and extend it for different environments
[2016-12-13 18:15:07] <dragon788> not sure it supports YAML inheritance and overrides
[2016-12-13 20:40:06] <renegoretzka> hello, anyone using rancher here?
[2016-12-13 20:48:19] <rightisleft> Whats best practice to restart a node container on file change? (Seems like a bad idea to install nodemon inside the container )
[2016-12-13 20:49:27] <renegoretzka> why would you restart the container?
[2016-12-13 20:50:41] <rightisleft> well i need to restart the process to pick up file changes
[2016-12-13 20:51:13] <renegoretzka> rightisleft: for app.js or so files?
[2016-12-13 20:51:43] <renegoretzka> why dont you pull the repo with git
[2016-12-13 20:51:57] <rightisleft> developing locally
[2016-12-13 20:52:32] <rightisleft> specifically a typescript project where a large number of .js files change  on transpliation
[2016-12-13 20:53:04] <rightisleft> If this is the wrong approach - please let me know.
[2016-12-13 20:53:27] <rightisleft> but it seemed counter to dockers ethos of 1 pid per container to shove nodemon into it
[2016-12-13 20:55:20] <rightisleft> I've also got my production services working already - im just trying to figure out the best way to get them working as a primary developer environment
[2016-12-13 21:53:53] <PetrusKiendys> thanks for the tip@dragon788
[2016-12-13 22:36:50] <dragon788> rightisleft: you might want to implement something liketiniinside your containers so you can restart services without resetting the entire container
[2016-12-14 01:00:29] <VRspace4> I have a few dozen images I'd like to pull from [<-LINK->] and pushed into a private registry. Anyone know the fastest way to do this and not have to pull and then push each image individually?
[2016-12-14 01:24:27] <Risto-Stevcev> does anyone know how ownership works with volumes?
[2016-12-14 01:25:16] <Risto-Stevcev> for example, if I run something like:docker run --rm -itv $(pwd):/some/dir docker/image:tag bash
[2016-12-14 01:25:38] <Risto-Stevcev> and there is afoouser, it will create the directory withfooas the owner
[2016-12-14 01:26:07] <Risto-Stevcev> however, if I base my docker image off of another image that has afoouser, and my image has abaruser, then it will create the volume as iffooowns the volume
[2016-12-14 01:26:21] <Risto-Stevcev> any way I can get docker to correctly makebarthe owner?
[2016-12-14 04:48:47] <dragon788> you need to chown
[2016-12-14 04:49:27] <dragon788> VRspace4: versions of 1 container or many containers?
[2016-12-14 04:49:58] <dragon788> you will have to pull and push but you could easily script it
[2016-12-14 04:49:59] <VRspace4> 1 version of many images
[2016-12-14 04:50:18] <VRspace4> oh there's no built in docker command?
[2016-12-14 04:51:05] <VRspace4> it's actually pull, tag, and then push for each image
[2016-12-14 04:53:23] <dragon788> yeah, Docker follows the Unix philosophy of do one thing and do it well, and not making special tools for a single use, just combining multiple tools to accomplish those special needs
[2016-12-14 04:54:26] <dragon788> you could either loop through all the pulls/tags/pushes separately in a shell script or you could do a pull/tag/push per image in a loop
[2016-12-14 04:54:44] <VRspace4> k, scripting it is. thanks for your help!
[2016-12-14 04:55:07] <dragon788> the trick is to remember to tag them with your private repository's hostname
[2016-12-14 04:55:26] <dragon788> so that a push gets them to the right place
[2016-12-14 04:55:52] <VRspace4> yep
[2016-12-14 04:56:08] <VRspace4> I've been using this to stop all containers:docker stop $(docker ps -a -q)
[2016-12-14 04:56:21] <VRspace4> maybe I could tweak it a bit to do what I need
[2016-12-14 04:56:31] <dragon788> oh yeah, that one is pretty awesome
[2016-12-14 04:56:56] <dragon788> there is a similar one for cleaning up unused or stopped containers as well
[2016-12-14 10:26:44] <Forecaster> renegoretzka: I use rancher
[2016-12-14 14:39:28] <Risto-Stevcev>  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2016-12-14 14:39:45] <Risto-Stevcev> btwbardoesn't (and cannot) have superuser privileges
[2016-12-14 16:17:34] <gdelazzer> Hello, I have duplicated a stack that I had on my personal account to my organisation account but I am not able to access this new stack url (I am using nginx). I guess it is far stretched, but any idea where I could look into to fix this issue?
[2016-12-14 16:18:33] <gdelazzer> (I a using Docker Cloud)
[2016-12-14 16:18:59] <Forecaster> what is the stack?
[2016-12-14 16:20:03] <MadMub> docker gurus, I wanna do something crazy, I would like to “freeze” a container, export it and restart it later, exactly where it was
[2016-12-14 16:20:06] <MadMub> is this possible?
[2016-12-14 16:20:14] <gdelazzer> my own stack: nginx-proxy, letsencrypt, django, postgres
[2016-12-14 16:21:03] <Forecaster> what do you mean you can\'t "access the new url"?
[2016-12-14 16:22:31] <gdelazzer> well, I get an url for nginx-proxy created automatically right? I cannot access this url, I do not see any log on nginx side, and on the browser side it just "fail to open the page"
[2016-12-14 16:37:22] <gdelazzer> Forecaster: : here is the trace route if it helps: [<-LINK->] 
[2016-12-14 16:37:45] <gdelazzer> on the left it is the stack on my personal account that resolves correctly
[2016-12-14 16:37:50] <gdelazzer> on the right the new stack
[2016-12-14 16:57:08] <Forecaster> I don't know nginx-proxy
[2016-12-14 17:00:03] <killerspaz> dragon788: ironically doing a deep dive right now
[2016-12-14 17:01:11] <killerspaz> rightisleft: use volumes to mount your source to your app space, assuming you're running docker daemon natively. Won't work with docker-machine init'd devices through VirtualBox, as it doesn't support inotify events from hosts.
[2016-12-14 17:03:02] <killerspaz> rightisleft: personally I use docker-compose which i'm able to overlay configs to enable these volumes only for dev
[2016-12-14 17:09:16] <killerspaz> GRRRR, no rancheros gitter :/
[2016-12-14 18:00:40] <dragon788> Risto-Stevcev: you actually need to do those chowns inside of your ENTRYPOINT script iirc
[2016-12-14 18:01:51] <dragon788> tried this? [<-LINK->] 
[2016-12-14 18:16:51] <killerspaz> Ok I realize this is #docker and not #rancheros, but i'm trying to install rancheros into a VirtualBox machine, and not sure how in the world i would get my cloud-config.yml on the device as I can't ssh in or paste my sshkey into the VM (no guest addition support)
[2016-12-14 18:16:57] <killerspaz> anyone have any ideas?
[2016-12-14 20:45:33] <MadMub> found some experimental CRIU stuff that should work
[2016-12-14 23:17:42] <Risto-Stevcev> dragon788: I figured out what the issue was. The volume owner gets mapped to the uid:gid of the currently logged in user on the host machine. The actual owner in the container is based on whoever has that uid:gid combination, which in my scenario is the first user.
[2016-12-14 23:22:39] <dragon788> killerspaz: you should be able to SSH in without the guest additions, the machine will still have an IP address it just won't have the shared folder functionality, you can probably either scp a file to it or copy and paste in your SSH session with a redirect to a file
[2016-12-15 06:07:18] <mingsterism> hey guys
[2016-12-15 06:07:44] <mingsterism> why does my containers always automatically exit when i rundocker-compose up -d
[2016-12-15 06:07:49] <mingsterism> this is my docker-compose.yml file
[2016-12-15 06:08:02] <mingsterism>  [<-CODE->] 
[2016-12-15 06:08:42] <mingsterism> even when i rundocker start test1, the container automatically exits
[2016-12-15 06:08:55] <mingsterism>  [<-CODE->] 
[2016-12-15 06:09:24] <mingsterism>  [<-CODE->] 
[2016-12-15 06:09:41] <mingsterism>  [<-CODE->] 
[2016-12-15 06:26:56] <mingsterism> i managed to get the container running. but i ended up with this problem. any ideas?
[2016-12-15 06:26:58] <mingsterism>  [<-CODE->] 
[2016-12-15 06:27:14] <mingsterism> this is my docker-compose filedockerC1
[2016-12-15 06:27:24] <mingsterism>  [<-CODE->] 
[2016-12-15 06:39:17] <mingsterism> im using digitalocean $  20 /mo$0.030 /hour2 GB / 2 CPUs40 GB SSD disk3 TB transfer
[2016-12-15 13:12:22] <dragon788> Sounds like it has a corrupt or broken version of the package, try a previous tag version?
[2016-12-15 13:35:48] <smahi> Hi,I am new to docker and i am building lemp stack using docker every thing work as expected beside some permission issues, how to fix permissions so that php can create files/folders ( the right way).Knowing that i am using nginx:alpine, php:fpm-alpine and a custom container volume
[2016-12-15 15:17:47] <galvesribeiro> hey guys
[2016-12-15 15:18:22] <galvesribeiro> I have this docker file  [<-CODE->] 
[2016-12-15 15:18:49] <galvesribeiro> when I docker build: [<-CODE->] 
[2016-12-15 15:19:14] <galvesribeiro> it stuck there like forever
[2016-12-15 15:19:26] <galvesribeiro> is there any way to see what is going on and why it is stucking there?
[2016-12-15 15:20:28] <galvesribeiro> (btw, docker for windows using a nanoserver image)
[2016-12-15 15:20:58] <galvesribeiro> the next command in the dockerfile is suppose to beWORKDIR /app
[2016-12-15 15:33:24] <dragon788> you probably don't want to use theCOPY . .line, you should try using actual paths for inside the container, like/or/app
[2016-12-15 15:34:23] <galvesribeiro> dragon788: I'm trying to copy my app build output to the C:/app
[2016-12-15 15:34:34] <galvesribeiro> what would be the proper way?
[2016-12-15 15:38:42] <dragon788> I think justCOPY . /appwould work, though in a windows nano container not sure if it will prefer/apporC:\\app, you can try it both ways
[2016-12-15 15:39:04] <galvesribeiro> just tried C:/app
[2016-12-15 15:39:07] <galvesribeiro> however
[2016-12-15 15:39:13] <galvesribeiro> it hang on the  COPY action
[2016-12-15 15:39:16] <dragon788> if you do adocker psyou can see if the container that is being built is running, and then you could trydocker inspect <containerID>
[2016-12-15 15:39:26] <dragon788> was it working with the copy before, just hanging on the step after?
[2016-12-15 15:39:36] <galvesribeiro> basically it always hang on the 2nd step
[2016-12-15 15:39:37] <galvesribeiro> :(
[2016-12-15 15:39:55] <galvesribeiro> I removed everything and left just FROM, COPY and ENTRYPOINT
[2016-12-15 15:40:02] <galvesribeiro> it always freeze on the 2nd command
[2016-12-15 15:40:25] <dragon788> try removing the MAINTAINER line? I think it is optional but just recommended?
[2016-12-15 15:40:25] <galvesribeiro>  [<-CODE->] 
[2016-12-15 15:40:32] <galvesribeiro> yeah I removed
[2016-12-15 15:40:45] <galvesribeiro> the 2nd now is copy and still hang there
[2016-12-15 15:41:03] <dragon788> smahi: read back a little bit, I pasted a link regarding a good practice for changing permissions for an app
[2016-12-15 15:41:27] <dragon788> can you justdocker pullthe image that you are building from to see if it is locally?
[2016-12-15 15:42:19] <galvesribeiro>  [<-CODE->] 
[2016-12-15 15:42:28] <galvesribeiro> :(
[2016-12-15 15:43:29] <galvesribeiro> I'm already rebooted my machine to make sure there is no crap with the docker daemon but, it just don't work
[2016-12-15 15:43:32] <dragon788> you might want to see if there is an example Windows Nano Dockerfile that is using copy, or provide a full path to the input directory and output directory, does your system have Hyper-V enabled to run the Nano container? VT-x for virtualization enabled?
[2016-12-15 15:43:43] <dragon788> can you run the base image itself?
[2016-12-15 15:44:13] <galvesribeiro> the container serices are runing just fine, I can run other containers
[2016-12-15 15:44:18] <galvesribeiro> I did built other images
[2016-12-15 15:44:52] <galvesribeiro> and pushed them to my registry
[2016-12-15 15:47:51] <galvesribeiro> this is the dockerfile for the image I'm building from:
[2016-12-15 15:47:54] <galvesribeiro>  [<-CODE->] 
[2016-12-15 15:48:10] <galvesribeiro> basically it gets the nanoserver image and add .Net Core SDK in it
[2016-12-15 15:48:24] <galvesribeiro> it works fine, I can spin a container from it
[2016-12-15 16:03:37] <killerspaz> dragon788: I couldn't find the defaultrancher-user password and empty password didn't work like it does on install/boot. I ended up mounting host->guest usb stick which for some reason only mounted asmsdos... either way, got 'er done!
[2016-12-15 16:16:30] <galvesribeiro> freaking annoying :( just hangs...
[2016-12-15 16:41:14] <smahi> dragon788: thank you for the link.I did not understand your last question :can you justdocker pullthe image that you are building from to see if it is locally?sorry about that.
[2016-12-15 16:49:47] <galvesribeiro> I think I got the problem
[2016-12-15 16:50:02] <galvesribeiro> the freaking CRL / LF on the docker file
[2016-12-15 16:50:05] <galvesribeiro> dammit
[2016-12-15 16:56:44] <dragon788> rofl, yup line endings are a PITA
[2016-12-15 16:57:26] <dragon788> smahi: sorry, was mixing up my conversations, that one was for another convo
[2016-12-15 16:58:05] <dragon788> kind of sad Gitter doesn't have threading like FlowDock, but that's probably the only thing I really miss, as everything else is very GitHub oriented with the pulls/commits/issues
[2016-12-15 16:58:31] <galvesribeiro> btw
[2016-12-15 16:58:47] <galvesribeiro> dragon788: when I'm doing adocker rmi imagenameit removes the images locally, or it removes from my registry?
[2016-12-15 16:58:48] <dragon788> galvesribeiro: there are some tools for converting, I think maybe Notepad++ can do it as well as Vim
[2016-12-15 16:58:56] <galvesribeiro> yup
[2016-12-15 16:58:59] <dragon788> rmi is just removing from local
[2016-12-15 16:59:01] <galvesribeiro> VSCode does it for me
[2016-12-15 16:59:11] <galvesribeiro> right
[2016-12-15 16:59:13] <galvesribeiro> how to remove from the registry?
[2016-12-15 16:59:43] <dragon788> to remove from the registry I think you tend to have to browse it's filesystem and manually remove, depending on which registry you are using, I know Artifactory Pro allows you to delete from the web UI or their API
[2016-12-15 16:59:56] <galvesribeiro> ouch
[2016-12-15 17:00:03] <dragon788> not sure if there is acurlcommand you can use to delete on the Docker official registry
[2016-12-15 17:00:07] <galvesribeiro> I'm using Azure Container Registry
[2016-12-15 17:00:24] <galvesribeiro> will open a support ticket to check on that
[2016-12-15 17:00:29] <galvesribeiro> thanks! :)
[2016-12-15 17:01:15] <dragon788> cool, if they are using the standard registry API this might work, [<-LINK->] 
[2016-12-15 17:02:14] <galvesribeiro> yep, it is the standard API 2.0+they just back it with a blob storage
[2016-12-15 17:08:42] <galvesribeiro> lol such a work to get a image deleted hehehe
[2016-12-15 17:08:54] <galvesribeiro> it should be a parameter of rmi or something...
[2016-12-15 17:25:38] <smahi> dragon788: Thank you again for your kindness and help 
[2016-12-15 17:47:36] <galvesribeiro> weird situation
[2016-12-15 17:47:47] <galvesribeiro> I can ping the container using the IP that appear on docker inspect
[2016-12-15 17:47:57] <galvesribeiro> however, I cant connect the Port
[2016-12-15 17:48:22] <galvesribeiro> I'm callingEXPOSE 5000at the Dockerfile
[2016-12-15 17:48:36] <galvesribeiro> and-p 9999:5000in docker run
[2016-12-15 17:49:11] <galvesribeiro> so from the host,telnet localhost 9999don't work :(
[2016-12-15 17:59:25] <cjus> I’m trying to install docker on Ubuntu 16.04 using these official [<-LINK->] . My question is whether it’s common for the keyserver to timeout? [<-CODE->] 
[2016-12-15 18:15:16] <galvesribeiro> do I need to enything besides useEXPOSE 5000on Dockerfile and-p 9999:5000/tcpindocker runto get access to my container?
[2016-12-15 18:35:49] <erkanerol> Hi. Could you help me? [<-LINK->] 
[2016-12-15 18:42:01] <galvesribeiro> dragon788: any clues?
[2016-12-15 19:20:46] <killerspaz> galvesribeiro: if your host is Win/OSX, then access it via the ip given fromdocker-machine ip; otherwise on linux you can uselocalhost
[2016-12-15 19:39:01] <galvesribeiro> killerspaz: it is windows
[2016-12-15 19:39:08] <galvesribeiro> but, no, it isn't working using the IP
[2016-12-15 19:41:36] <galvesribeiro> docker run -it -p 9999:5000/tcp --rm myimage
[2016-12-15 19:42:12] <galvesribeiro> and in another cmd, Itelnet myIP 9999
[2016-12-15 19:42:23] <galvesribeiro> and myIP I tried all IPs assigned to my machine
[2016-12-15 19:42:44] <galvesribeiro> the regular one from my wired network and all others that are added by docker
[2016-12-15 19:46:44] <dragon788> galvesribeiro: in my experience that should be all you need to do. Are you certain the application is running on port 5000 inside the container?
[2016-12-15 19:48:20] <galvesribeiro> yup
[2016-12-15 19:48:32] <dragon788> galvesribeiro: you should check and see whatipconfig /allreports for interfaces and IP addresses, you should be able to hit your container directly via it's Docker interface IP, and if you have exposed the port it should be available at your host's Docker interface IP, also try127.0.0.1instead oflocalhost, as Windows doesn't typically aliaslocalhostlike Linux does
[2016-12-15 19:48:43] <galvesribeiro> I did adocker exec...in another terminal to access powershell
[2016-12-15 19:48:54] <galvesribeiro> and I did telnet 5000 and it connect
[2016-12-15 19:49:19] <dragon788> yeah, that means that they are able to communicate via the Docker-only network
[2016-12-15 19:49:29] <galvesribeiro> tried 127.0.0.1 no success
[2016-12-15 19:49:49] <dragon788> so it could be a firewall on Windows preventing you from accessing the Docker network if you don't have a route for Windows to get there
[2016-12-15 19:50:14] <galvesribeiro> the funny thing is, I can ping the container IP
[2016-12-15 19:50:27] <galvesribeiro> and my host windows firewall is fully turned off just to be sure
[2016-12-15 19:51:05] <galvesribeiro> docker psreport the container running and PORTS as0.0.0.0:9999->5000/tcp
[2016-12-15 19:51:47] <galvesribeiro>  [<-CODE->] 
[2016-12-15 19:51:54] <galvesribeiro> docker inspect on the container
[2016-12-15 19:56:36] <galvesribeiro> that is really frustrating... something that is supposed to be simple just don't work :(
[2016-12-15 19:56:36] <dragon788> try hitting 0.0.0.0:9999 on your host?
[2016-12-15 19:57:05] <galvesribeiro> that will never connect
[2016-12-15 19:57:12] <galvesribeiro> it i sjust a wildcard for any IP
[2016-12-15 19:57:42] <dragon788> I tend to cheat and use Docker-Compose where possible because it handles some of the networking magic for the expose and mappings, but I haven't used it with nano yet
[2016-12-15 19:57:59] <galvesribeiro> it must be the same thing
[2016-12-15 19:58:05] <galvesribeiro> the API level is the same
[2016-12-15 19:58:06] <dragon788> so what if you hit the gateway IP or gateway.2 and that port?
[2016-12-15 19:58:06] <galvesribeiro> and
[2016-12-15 19:58:19] <galvesribeiro> cant connect
[2016-12-15 19:58:30] <galvesribeiro> the gateway IP is my machine IP on docker network
[2016-12-15 19:59:28] <dragon788> yeah, if you can hit the Docker container through that then it might be a routing issue that prevents your Windows "side" from accessing the container directly, but I\'d think it should map to localhost or127.0.0.1or127.0.1.1
[2016-12-15 20:00:14] <galvesribeiro> the problem is, if there is a route issue, how can I ping the container IP?
[2016-12-15 20:00:41] <dragon788> this is true :)
[2016-12-15 20:00:47] <galvesribeiro> :P
[2016-12-15 20:01:09] <dragon788> so it sounds like maybe it's the expose syntax, what if you don't expose and just do the mapping of-p 9999:5000?
[2016-12-15 20:01:36] <galvesribeiro> you mean remove EXPOSE from the dockerfile and just pass the parameter?
[2016-12-15 20:01:42] <dragon788> yeah
[2016-12-15 20:01:46] <galvesribeiro> ok let me try
[2016-12-15 20:02:58] <galvesribeiro> wait
[2016-12-15 20:03:04] <galvesribeiro> 9999:5000?
[2016-12-15 20:03:24] <galvesribeiro> it shouldn't becontainerInternalPort:HostPublicPort?
[2016-12-15 20:04:00] <galvesribeiro> -p 5000:9999this is how I'm doing it
[2016-12-15 20:04:04] <dragon788> that I'm not sure, didn't look up the proper syntax :p
[2016-12-15 20:04:10] <galvesribeiro> kkkkkkkkkkkk ok
[2016-12-15 20:04:29] <dragon788> well earlier you pasteddocker run -it -p 9999:5000/tcp --rm myimage
[2016-12-15 20:04:42] <dragon788> so maybe it was getting confused?
[2016-12-15 20:04:44] <galvesribeiro> ok well, that was another attempt
[2016-12-15 20:04:45] <galvesribeiro> :D
[2016-12-15 20:04:52] <galvesribeiro> let me confirm here
[2016-12-15 20:11:09] <galvesribeiro> nothing
[2016-12-15 20:11:10] <galvesribeiro> :(
[2016-12-15 20:12:28] <galvesribeiro>  [<-LINK->] 
[2016-12-15 20:12:30] <galvesribeiro> I'm doing that way
[2016-12-15 20:19:27] <dragon788> try usingEXPOSE 5000and then just use-Pto "expose all" on the host interfaces without the-p 5000:9999?
[2016-12-15 20:20:43] <dragon788> are you testing this locally on a Hyper-V host or in a boot2docker?
[2016-12-15 20:22:07] <galvesribeiro> localy
[2016-12-15 20:22:09] <galvesribeiro> windows 10
[2016-12-15 20:22:13] <galvesribeiro> and -P dont work
[2016-12-15 20:22:18] <galvesribeiro> it add a random port
[2016-12-15 20:22:24] <galvesribeiro> tried access with that as well no lucky
[2016-12-15 20:22:49] <dragon788> hmmm
[2016-12-15 20:23:42] <dragon788> you might have to find some Docker on Windows pros, not sure if they have a channel on IRC or maybe check StackOverflow/ServerFault?
[2016-12-15 20:24:14] <galvesribeiro> Someone guys from Microsoft hang here
[2016-12-15 20:24:25] <galvesribeiro> but besides you, I'm see this channel a deadland :(
[2016-12-15 20:24:38] <galvesribeiro> issues on GH takes like months open without a reply, even on linux
[2016-12-15 20:24:39] <galvesribeiro> :(
[2016-12-15 20:24:58] <galvesribeiro> but in all cases I really appreciate your help
[2016-12-15 20:25:00] <galvesribeiro> thanks
[2016-12-15 20:25:04] <galvesribeiro> will see what I can find
[2016-12-15 20:27:58] <killerspaz> galvesribeiro: lots of text scrolled by, and honestly too busy/lazy to read it all, but usetelnet $(docker-machine ip) 9999
[2016-12-15 20:28:34] <galvesribeiro> there is no docker machine here@killerspazbut thanks
[2016-12-15 20:28:43] <killerspaz> also,host:portis an invalid format for telnet
[2016-12-15 20:28:50] <killerspaz> if your host is windows it's required
[2016-12-15 20:29:11] <galvesribeiro> :) I know
[2016-12-15 20:29:12] <killerspaz> if you dont' have it, you did something weird
[2016-12-15 20:29:21] <galvesribeiro>  [<-LINK->] 
[2016-12-15 20:29:23] <galvesribeiro> why do I need docker machine on windows?
[2016-12-15 20:30:08] <killerspaz> that's how docker works on windows, the docker daemon lives in a virtual machine (likely virtualbox), not on your local host; so exposed ports will be on THAT host
[2016-12-15 20:30:09] <galvesribeiro> on Windows 10 it is just enable hyper-V, Container Services, install docker for windows from Beta channel and it should be ready
[2016-12-15 20:30:15] <galvesribeiro> no
[2016-12-15 20:30:18] <galvesribeiro> the VM is gone
[2016-12-15 20:30:21] <galvesribeiro> way back
[2016-12-15 20:30:22] <galvesribeiro> :)
[2016-12-15 20:30:30] <killerspaz> Don't believe that's possible
[2016-12-15 20:30:42] <killerspaz> you ahve no way to natively run docker daemon on windows
[2016-12-15 20:30:44] <galvesribeiro> the only VM on windows is IF you want run Linux VMs
[2016-12-15 20:30:48] <galvesribeiro> ofc we have
[2016-12-15 20:30:48] <galvesribeiro> :D
[2016-12-15 20:31:19] <galvesribeiro>  [<-LINK->] 
[2016-12-15 20:31:34] <killerspaz>  [<-LINK->] 
[2016-12-15 20:31:37] <galvesribeiro> I think you didn't read the news on docker in about 6 months :D
[2016-12-15 20:32:38] <galvesribeiro> that is old
[2016-12-15 20:32:41] <galvesribeiro> and like I said
[2016-12-15 20:32:46] <galvesribeiro> only for docker linux containers
[2016-12-15 20:32:51] <galvesribeiro> I'm using WIndows Containers
[2016-12-15 20:32:52] <galvesribeiro> :)
[2016-12-15 20:33:04] <galvesribeiro> it is native
[2016-12-15 20:34:32] <killerspaz> do you have a source?
[2016-12-15 20:34:40] <galvesribeiro> which source?
[2016-12-15 20:34:45] <killerspaz> I'm not seeing anything indicating what you're saying to be how it works
[2016-12-15 20:34:51] <galvesribeiro> ok 1m
[2016-12-15 20:35:32] <killerspaz> but last thing i wanted to say was the ip's your utilizing is a subnet your docker engine is routing through; you won't be able to access that subnet directly without NAT transfers, which typically docker-machine does for you
[2016-12-15 20:35:32] <galvesribeiro>  [<-LINK->] 
[2016-12-15 20:36:10] <killerspaz> reading
[2016-12-15 20:36:11] <galvesribeiro> there are tons of videos on internet in DockerConn and other stuff for windows
[2016-12-15 20:36:23] <galvesribeiro> trust me, there is docker on windows :)
[2016-12-15 20:36:29] <galvesribeiro> without VMs
[2016-12-15 20:36:35] <dragon788> yeah, it was a big deal at DockerCon 2016 iirc about it
[2016-12-15 20:36:43] <galvesribeiro> yup
[2016-12-15 20:36:43] <dragon788> and then at the Microsoft Ignite? conference
[2016-12-15 20:37:06] <dragon788> works on Win10 and should be "native" in 2016 iirc? or at least the first SP
[2016-12-15 20:37:56] <galvesribeiro> yup for both statements
[2016-12-15 20:38:15] <galvesribeiro> even more, on Windows you have 2 isolation levels... Hyper-V and Windows Server Containers... you decide
[2016-12-15 20:38:21] <galvesribeiro> linux is just linux containers
[2016-12-15 20:38:29] <killerspaz> So i've only  lightly skimmed it, but it still sounds ilke it's using Hyper-V for the daemon host
[2016-12-15 20:38:36] <galvesribeiro> no
[2016-12-15 20:38:38] <galvesribeiro> it doesn't
[2016-12-15 20:39:11] <galvesribeiro> in Hyper-V mode it does use a "pseudo-hypervisor", but in Windows Server Container mode, there is no hyper-V at all
[2016-12-15 20:39:20] <galvesribeiro> but in both cases
[2016-12-15 20:39:21] <killerspaz> i see
[2016-12-15 20:39:23] <galvesribeiro> docker behave the same way
[2016-12-15 20:39:29] <galvesribeiro> same APIs
[2016-12-15 20:39:33] <galvesribeiro> same client
[2016-12-15 20:40:31] <galvesribeiro> anyway, still, the fraking container isnt working here :(
[2016-12-15 20:41:32] <killerspaz> hmm... so... in LINUX anyway, you have a bridge to allow your local subnet to route to the docker subnet; essentially VLans
[2016-12-15 20:41:52] <galvesribeiro> killerspaz: I think you skipped that part in the chat history
[2016-12-15 20:41:58] <galvesribeiro> I'm able to ping the container IP from my machine
[2016-12-15 20:42:00] <galvesribeiro> just fine
[2016-12-15 20:42:03] <killerspaz> yeah like i said too much scrolled by :P
[2016-12-15 20:42:10] <galvesribeiro> hehehe
[2016-12-15 20:42:11] <galvesribeiro> :D
[2016-12-15 20:42:17] <galvesribeiro> so there is no routing or vnet problem here
[2016-12-15 20:42:22] <killerspaz> hmmmmmmm
[2016-12-15 20:42:26] <killerspaz> strange indeed
[2016-12-15 20:42:29] <galvesribeiro> the problem is the freaking port not being mapped as it is suppose to be
[2016-12-15 20:42:36] <killerspaz> can you attach to the container and connect locally?
[2016-12-15 20:43:07] <galvesribeiro> I candocker exec containerID -it powershelland it open a PS session
[2016-12-15 20:43:12] <galvesribeiro> so I can do a ifconfig
[2016-12-15 20:43:16] <galvesribeiro> ipconfig
[2016-12-15 20:43:25] <galvesribeiro> the ip is the same as expect bydocker inspect
[2016-12-15 20:43:35] <galvesribeiro> the application inside it is running
[2016-12-15 20:43:36] <killerspaz> but inside can youtelnet localhost 5000
[2016-12-15 20:43:40] <galvesribeiro> yes
[2016-12-15 20:43:42] <galvesribeiro> it works
[2016-12-15 20:43:53] <killerspaz> is the server bound to 0.0.0.0? or just localhost?
[2016-12-15 20:44:07] <galvesribeiro> good question...
[2016-12-15 20:44:13] <galvesribeiro> it an asp.net core app
[2016-12-15 20:44:16] <galvesribeiro> let me confirm that
[2016-12-15 20:44:18] <killerspaz> just shootin things out :P
[2016-12-15 20:44:21] <galvesribeiro> yup
[2016-12-15 20:44:30] <galvesribeiro> let me check on that 1m
[2016-12-15 20:44:39] <dragon788> very weird that you can ping the IP but can't hit the port
[2016-12-15 20:44:47] <dragon788> maybe it is a NAT/networking issue with Hyper-V
[2016-12-15 20:44:55] <galvesribeiro> don't think so
[2016-12-15 20:44:58] <dragon788> can you open the Hyper-V management console and see the Docker "VM" running in there?
[2016-12-15 20:45:05] <killerspaz> if it's pinging, NAT is working
[2016-12-15 20:45:17] <killerspaz> but the server may only accept local connections
[2016-12-15 20:45:18] <galvesribeiro> docker VM only run if I switch to linux mode
[2016-12-15 20:45:34] <galvesribeiro> so I can create linux containers "on windows"
[2016-12-15 20:45:38] <galvesribeiro> if I don't, there is no VM there
[2016-12-15 20:46:04] <galvesribeiro> let me check that bound
[2016-12-15 21:04:14] <galvesribeiro>  [<-CODE->] 
[2016-12-15 21:04:25] <galvesribeiro> yeah, I'm listening to all IPs in the appliaction
[2016-12-15 21:11:28] <galvesribeiro> ok... I got something
[2016-12-15 21:11:50] <galvesribeiro> if I telnet 172.26.134.35 5000 on my machine
[2016-12-15 21:11:51] <galvesribeiro> it connect
[2016-12-15 21:12:20] <galvesribeiro> 5000 is the port of the application, and the one defined onEXPOSEstatement...
[2016-12-15 21:12:37] <galvesribeiro> it is really weird... this is supposed to be the internal port, not the one open
[2016-12-15 21:17:49] <killerspaz> might be something they're still wokring through? definitely sounds weird
[2016-12-15 21:18:54] <galvesribeiro> yeah, will open an issue on GH and hope someone will get back later
[2016-12-15 21:19:06] <galvesribeiro> at least now my developers can use the container
[2016-12-15 21:19:28] <galvesribeiro> now I need to find a way to connect this container with one running SQL server
[2016-12-15 21:19:39] <galvesribeiro> just for development
[2016-12-15 21:19:56] <galvesribeiro> anyway, again, thank you@killerspazand@dragon788for try to help
[2016-12-15 21:20:45] <dragon788> I think that is the IP I was trying to stumble across when I said try the gateway :P
[2016-12-15 21:21:07] <dragon788> whatever the "Docker interface" of your host machine is, or is that the docker interface of your container?
[2016-12-15 21:21:22] <galvesribeiro> the gateway is the .1 on that 172.26.134.0 network
[2016-12-15 21:21:32] <galvesribeiro> that is the container IP
[2016-12-15 21:21:34] <galvesribeiro> the .35
[2016-12-15 21:21:46] <galvesribeiro> the .1 is the gateway on the container
[2016-12-15 21:21:53] <galvesribeiro> which is the IP of my machine in that network
[2016-12-15 21:22:10] <galvesribeiro> docker creates 2 networks here
[2016-12-15 21:22:14] <galvesribeiro> (dont ask me why)
[2016-12-15 21:22:17] <galvesribeiro>  [<-CODE->] 
[2016-12-15 21:22:25] <killerspaz> galvesribeiro: linkis what you want to cross-talk between containers... docker-compose does that all sexy-like for you
[2016-12-15 21:22:48] <galvesribeiro> killerspaz: cool, will have a look on that
[2016-12-15 21:23:16] <killerspaz> you can also manage docker networks pretty easily and limit communication to subnets as seen fit
[2016-12-15 21:23:39] <galvesribeiro> yeah, that would be another step on our docker learning curve
[2016-12-15 21:23:53] <galvesribeiro> for now its ok that all containers talk to each other
[2016-12-15 21:24:05] <galvesribeiro> because the hosts for a group of container types, will be isolated
[2016-12-15 21:25:32] <galvesribeiro> anyway, time to drive home, will continue from there
[2016-12-15 21:25:42] <galvesribeiro> thank you folks, will be back later
[2016-12-15 21:26:52] <killerspaz> also every docker-compose config creates it's own network unless specified, so typically you don't have to worry about it
[2016-12-15 21:27:06] <killerspaz> so you can cluster associative services to a single config and not concern yourself about it
[2016-12-15 21:27:15] <galvesribeiro> humm
[2016-12-15 21:27:18] <galvesribeiro> that is good
[2016-12-15 21:27:19] <galvesribeiro> :)
[2016-12-15 21:27:33] <galvesribeiro> our scenario is a bit complex in terms of networking
[2016-12-15 21:27:42] <galvesribeiro> due to PCI compliance
[2016-12-15 21:27:45] <killerspaz> sounds cool
[2016-12-15 21:27:49] <killerspaz> ahhh, vlans out the wazoo
[2016-12-15 21:27:50] <galvesribeiro> I'll have a look on that
[2016-12-15 21:27:54] <galvesribeiro> yeah
[2016-12-15 21:27:58] <galvesribeiro> TONS of vLans
[2016-12-15 21:28:07] <killerspaz> good ol SAS 70
[2016-12-15 21:28:07] <galvesribeiro> and Network Security Groups
[2016-12-15 21:28:11] <galvesribeiro> hehehehe
[2016-12-15 21:31:12] <killerspaz> can get even more fun with docker swarm, and docker stacks with docker-cloud
[2016-12-16 02:44:42] <Avasz> I am trying to run as a different user in entrypoint (docker alpine), but I am getting:su: must be suid to work properly. Any help please?`
[2016-12-16 02:45:20] <Avasz>  [<-CODE->] 
[2016-12-16 02:45:33] <Avasz> that is my entrypoint to run start.sh as user dev.
[2016-12-16 02:48:15] <Avasz> My solution for now is to specifyUSER devbefore ENTRYPOINT.
[2016-12-16 02:57:37] <dragon788> Does the Alpine container come with sudo?
[2016-12-16 02:57:46] <Avasz> I don't think so
[2016-12-16 02:58:46] <Avasz> usingUSER devis helping me for now.
[2016-12-16 09:59:54] <marcelmfs> Is there any Makefile-fu master around here? I'm trying to come up with a Makefile that will build docker images from one repo where each folder have a Dockerfile and it's build context, where make will dynamically list all folders and generate the dependency tree so that whenever an upstream image is rebuilt make will also rebuild all dependent containers. In short, I need to come up with a dynamic way of generating a dependency likenginx: alpine,html5_app: nginxonly by parsing Dockerfiles on multiple folders.
[2016-12-16 10:01:28] <marcelmfs> so far I have a bash one liner that looks likefind . -name Dockerfile -exec dirname {} \\; -exec egrep FROM {} \\; | sed -e 's/\\.\\/\\(.*\\)/$(BUILD_DIR)\\/\\1:/;s/FROM .*\\/\\(.*\\):.*/$(BUILD_DIR)\\/\\1/' | sed '$!N;s/\\n/ /'and outputs something like:
[2016-12-16 10:02:00] <marcelmfs>  [<-CODE->] 
[2016-12-16 10:46:10] <PavelPenkov> How would you guys go about using Docker to develop an application that has some kind of "development" mode which is wildly different from "production"? Say something with Webpack/Gulp/Rails asset pipeline?
[2016-12-16 13:16:10] <EugenMayer> Pavel there are like a gazzilion tutorials, howtos an examples in the web for this. there is no simple one line answer
[2016-12-16 13:16:28] <dragon788> marcelmfs: try docker-compose, it will pretty much do that for you
[2016-12-16 13:16:48] <EugenMayer> dragon788: an if not, just install it :)
[2016-12-16 13:17:38] <EugenMayer> does anybody has a good replacement for docker-compose cp ? This is the only missing part holding me back stopping using named containers
[2016-12-16 13:18:06] <EugenMayer> does anybody knows if docker-compose exec <servicename> does run the specified command on all containers of this service ( scaled )?
[2016-12-16 13:21:08] <dragon788> I don't know offhand, otherwise you could maybe list and loop containers matching the servicename
[2016-12-16 13:46:17] <marcelmfs> dragon788: thanks but my compose files are not being used to build anything, just to start my services (they're split across several different repositories), while all Dockerfiles are within one single repo structure.
[2016-12-16 13:46:29] <marcelmfs> And I've figured it out ;)
[2016-12-16 14:40:09] <siassaj> So I'm trying to figure out a way to build images that arecompletedbuilds for my rails app deployments. I've basically read a bunch of stuff and come to the conclusion that I should create an image that has all my base dependencies like ruby version, nodejs, etc. Then i should create a dockerfile using that image as base, then copying over my 'tmp' directory that contains build cache, my 'node_modules' dir that contains previously downloaded javascript dependencies, and similarly so for my gems, and my javascript and image/css precompiled assets. After copying them into the image i can run my ruby 'build' tasks, then save all the new tmp, node_modules etc contents back to the host computer filesystem, and finish off the dockerfile.
[2016-12-16 14:40:41] <siassaj> If i'm not mistake this can give me very fast build times with minimal downloading etc and leads to a single image that I can spin up on any number of machines very quickly
[2016-12-16 14:40:47] <siassaj> does this approach make any sense?
[2016-12-16 14:42:05] <siassaj> apologies for the lack of sensible terminology.
[2016-12-16 14:45:54] <marcelmfs> if you want to leverage caching of build tasks, yes, that's the best solution. But to release a container for production, I usually remove build tools and ship the container with the minimum to run the service.
[2016-12-16 14:47:06] <siassaj> I dont understand shipping containers
[2016-12-16 14:47:19] <siassaj> i thought you ship images, and when you run them you end up with a container on the host system
[2016-12-16 14:47:54] <siassaj> are you saying i should build everything first, then copy what i need into a docker image?
[2016-12-16 14:47:58] <siassaj> that could work too
[2016-12-16 14:48:51] <siassaj> to be honest docker has me questioning my intelligence or ability
[2016-12-16 14:48:58] <siassaj> it's not easy to understand the workflows
[2016-12-16 15:51:12] <dragon788> image/container are used synonymously most of the time, the difference comes from how they are referenced locally, an image is the collection of layers, a "container" is a running instance of an image
[2016-12-16 15:51:48] <dragon788> but your container will have the same contents regardless of the system you run on assuming you built the image as a standalone that doesn't use volume mapping
[2016-12-16 15:53:14] <dragon788> one workflow I\'ve seen is having a "build" container that assembles all your dependencies and your package, and then outputting that to a local volume share, then having a second container that only has the application dependencies (not the build ones) and copying the build container\'s output into the runtime container
[2016-12-16 15:54:26] <dragon788> this may end up being more than two builds because you might have a base layer with just the application dependencies as those would also probably be required for the build, then you make a "build" image and use the output of that to build the "prod" image on top of the base
[2016-12-16 16:03:39] <galvesribeiro> one workflow I\'ve seen is having a "build" container that assembles all your dependencies and your package, and then outputting that to a local volume share, then having a second container that only has the application dependencies (not the build ones) and copying the build container\'s output into the runtime containerThis is quite same process .Net Core team is using... One container with the SDK and the other only with the runtime
[2016-12-16 16:14:26] <siassaj> dragon788: that's quite complex. very interesting
[2016-12-16 16:14:40] <siassaj> it pays to be creative with this it seems
[2016-12-16 16:15:07] <siassaj> not much in google results to teach us how to do these complex, efficient/fast to build and then deploy flows
[2016-12-16 16:15:08] <dragon788> yeah, there are ways to use and abuse the layers and caching depending on where you want to focus your energy
[2016-12-16 16:15:49] <dragon788> another trick you'll see is when somebody does a [<-CODE->] 
[2016-12-16 16:16:22] <dragon788> because every RUN/COPY/etc creates a new layer
[2016-12-16 16:16:53] <siassaj> yeah I understandthat. In fact the dockerfile albeit simple seems... too simple
[2016-12-16 16:17:06] <dragon788> and most Linux containers that aren't build on Alpine also take pains to clear out their package manager cache before packing the first time
[2016-12-16 16:17:36] <siassaj> to keep the size minimal e
[2016-12-16 16:17:37] <siassaj> eh
[2016-12-16 16:17:38] <dragon788> well as they've added docker-compose and other higher level orchestration mechanisms the simplicity of the Dockerfile has been helpful
[2016-12-16 16:18:16] <dragon788> yeah, though the "smallest" Windows container is still like 300Mb :P maybe somebody has gotten that down, but the busybox binary and the Alpine base image are both <10Mb iirc
[2016-12-16 16:18:18] <siassaj> the forced caching on each layer is scary
[2016-12-16 16:18:43] <dragon788> why is it scary? they get cached by md5sum/sha1 so you know the contents are immutable
[2016-12-16 16:19:16] <siassaj> also I don't understand how distributing images works. Ithinkwhat happens is that you 'push' an image to a repo, which is actually sending meta data + a bunch of layersafterchecking the repo to see if it already has those layers or not. As in it only sends up what it needs to
[2016-12-16 16:19:19] <siassaj> is that correct?
[2016-12-16 16:19:41] <siassaj> well the scary part was the hacks I saw to get specific layers not to cache
[2016-12-16 16:19:56] <siassaj> which I undrestand busts everything after
[2016-12-16 16:36:02] <galvesribeiro> hey guys
[2016-12-16 16:36:09] <galvesribeiro> curiousity...
[2016-12-16 16:36:14] <galvesribeiro> if I spin up 2 containers
[2016-12-16 16:36:26] <galvesribeiro> no docker-compose or link enabled
[2016-12-16 16:36:32] <galvesribeiro> and I need to make them talk...
[2016-12-16 16:36:35] <galvesribeiro> is that possible?
[2016-12-16 16:36:55] <galvesribeiro> I mean, I spin up a SQL Server in one container, exposed the port 1433
[2016-12-16 16:37:04] <galvesribeiro> and from another container I'm trying to connect to it
[2016-12-16 16:37:13] <galvesribeiro> will it work?
[2016-12-16 16:37:19] <mihasK> you can open ports on host machine, and use DOCKER_HOST host for connection
[2016-12-16 16:37:45] <galvesribeiro> hum? sorry I'm not following...
[2016-12-16 16:37:59] <galvesribeiro> DOCKER_HOST is a env variable for docker engine, right?
[2016-12-16 16:38:31] <mihasK> I mean ip of host machine inside docker container
[2016-12-16 16:38:48] <galvesribeiro> ok
[2016-12-16 16:38:52] <galvesribeiro> let me try
[2016-12-16 16:39:13] <galvesribeiro> you mean the HOST IP on docker network, right?
[2016-12-16 16:39:39] <mihasK> there's no such variable, but you can find the ip . it depends on docker network used
[2016-12-16 16:40:50] <siassaj> and a docker image isn't 1 file is it, it's a bunch of slices and some meta data describing which slice in which order, eh?
[2016-12-16 16:41:27] <galvesribeiro> mihasK: no lucky
[2016-12-16 16:41:35] <mihasK> galvesribeiro: I will send you how to get host ip soon
[2016-12-16 16:42:00] <galvesribeiro> don't work
[2016-12-16 16:42:24] <galvesribeiro> the hostIP is simple... just do a ipconfig
[2016-12-16 16:42:26] <galvesribeiro> or
[2016-12-16 16:42:38] <mihasK> /sbin/ip route|awk '/default/ { print $3 }'
[2016-12-16 16:42:41] <galvesribeiro> just get the gateway IP on the docker inspect of the container
[2016-12-16 16:42:53] <galvesribeiro> sorry, I'm on Windows Containers :)
[2016-12-16 16:42:58] <mihasK> hah)
[2016-12-16 16:43:22] <galvesribeiro> but anyway, it doesn't work, the container is not talking to the SQL Server :(
[2016-12-16 16:43:25] <mihasK> I'm not sure then. But do you forward ports?
[2016-12-16 16:43:54] <galvesribeiro> yep, they areEXPOSEd and I started it with-p 1433:1433
[2016-12-16 16:44:46] <mihasK> then it should work. If the port 1433 is accessible on host ip, it should be accessible from container too
[2016-12-16 16:44:59] <galvesribeiro> yeah but it doesn't
[2016-12-16 16:49:29] <mihasK> I'm not sure how it is on Windows, but on linux sometimes default settings for databases don't allow to connections from outside: it's configured for 127.0.0.1:1433 instead of 0.0.0.0:1433
[2016-12-16 16:49:50] <galvesribeiro> that wasn't the problem
[2016-12-16 16:50:02] <galvesribeiro> I'm able to connect to SQL from my machine
[2016-12-16 16:50:32] <galvesribeiro> the problem was the Password not meet the minumal complexity when starting the container
[2016-12-16 16:50:33] <galvesribeiro> hehehe
[2016-12-16 16:50:34] <mihasK> it would be a problem on linux: you could connect from localhost (127.0.0.1), but not from other networks
[2016-12-16 16:50:36] <galvesribeiro> looks like it work
[2016-12-16 16:50:38] <galvesribeiro> let me check here
[2016-12-16 16:51:21] <mihasK> 127.0.0.1 doesn't allow connections from other networks, only from localhost
[2016-12-16 16:51:35] <siassaj> bind to 0.0.0.0
[2016-12-16 16:51:38] <siassaj> usually works
[2016-12-16 16:51:44] <galvesribeiro> yup, that is why I'm trying the connection to the database IP address
[2016-12-16 16:51:53] <galvesribeiro>  [<-CODE->] 
[2016-12-16 16:51:56] <galvesribeiro> it was able to connect
[2016-12-16 16:52:01] <galvesribeiro> now the error is diff
[2016-12-16 16:52:07] <galvesribeiro> but thanks, I got the message :)
[2016-12-16 16:52:37] <mihasK> this is a progress btw)
[2016-12-16 16:52:43] <galvesribeiro> :D
[2016-12-16 17:16:28] <dragon788> siassaj: you are correct, if you are building on top of the same base layer for a specific image "repository" then it will already have that base layer if you have previous pushed an image to it, then it only has to transfer the newer/different layers
[2016-12-16 17:16:52] <dragon788> what tricks for cache busting are you referring to?
[2016-12-16 22:37:10] <hillct> I wonder if someone more knowledgeable than I might be able to speak to this issue: [<-ISSUE->] 
[2016-12-17 06:39:20] <siassaj> dragon788: i saw a few, i don't remember exactly off the top of my head.
[2016-12-17 06:43:28] <siassaj> so i need to create an image to serve as my 'base' image for my application images
[2016-12-17 06:44:25] <siassaj> so instead of FROM ruby:2.3.1 I'd rather do FROM my-company-app-env
[2016-12-17 06:45:09] <siassaj> and I suspect that I'll have a bunch of other utility apps with their own docker images, possibly basing off other app enviroments, such as my slackbot etc
[2016-12-17 06:45:20] <siassaj> these 'base' images that I want to use, should each have a director and a Dockefile
[2016-12-17 06:46:15] <siassaj> or should I just create a dir like 'company-dockerfiles',  and put 'app-env.dockerfile', 'slackbot-env.dockerfile', etc
[2016-12-17 06:46:16] <siassaj> ?
[2016-12-17 14:15:28] <xiaopeng163> I am writing a docker k8s lab handbook [<-LINK->] 
[2016-12-18 11:47:43] <fr4ngus> Hi guys, I want to access to one of my container from another device connect to the same netowk
[2016-12-18 11:48:02] <fr4ngus> So I want to know how could I expose my nginx container to the network ?
[2016-12-18 11:49:31] <fr4ngus> I'm using docker compose, so I can launch multiple services, and I need to share a specific service (nginx)
[2016-12-18 14:30:53] <EugenMayer> fr4ngus: when you start services ( that is what is called a unit in docker-compose ) you can access every other service of this "docker-compose.yml" file by using the service name
[2016-12-18 14:31:23] <EugenMayer> ping <servicename> will work, but also telnet <servicename> 80 for your nginx-container
[2016-12-18 14:31:44] <EugenMayer> you do not need to expose any ports in the internal network of services in a docker-compose network
[2016-12-18 16:12:00] <fr4ngus> It's not my question, I try to access from my smartphone that is connect on the same network, and I can't
[2016-12-18 16:32:34] <fr4ngus> I launch my container on my mac and after try to access with my smartphone to the nginx container but doesn't work.
[2016-12-18 18:39:27] <fr4ngus> I solved my problem by adding a new rul in my nginx conf, the problem doesn't come from my docker conf but my nginx conf.
[2016-12-18 21:53:26] <krishnaghatti_twitter> i am checking out the " --read-only” option ..was wondering how to set that as default in the docker DOCKER_OPTS. Did any one try it out?
[2016-12-18 21:54:35] <krishnaghatti_twitter> i want to start all my docker images RO by default and want to set RO as default option.
[2016-12-18 21:54:57] <krishnaghatti_twitter> some thing like this worksdocker run -t -i -d --read-only --tmpfs /run --tmpfs /tmp python:3 /bin/bash
[2016-12-18 21:55:13] <krishnaghatti_twitter> want to set it as default with DOCKER_OPTS
[2016-12-19 02:45:50] <siassaj> are there any strategies to speed up docker COPY commands. I have to copy several cache directories from host into my image so that my asset compilation and app build is fast. But these directories are full of files.
[2016-12-19 02:46:00] <siassaj> Is it faster to tar them first, transfer the tar and untar it (or use ADD)
[2016-12-19 02:46:20] <siassaj> even ENV commands take several seconds to complete
[2016-12-19 02:48:14] <siassaj> perhaps I'll load host volumes instead of copying
[2016-12-19 02:49:34] <siassaj> ah i see I'd have to mount it, run my commands then commit the container to a new image
[2016-12-19 08:05:47] <ely029> hey guys how can I deploy the database in mssql image?
[2016-12-19 08:13:51] <marcelmfs> siassaj: use volumes bind mounts. I have adeveloperuser, which has in it's$HOMEall cached folders from npm, bower, ivy2, and so on. Then I only have-v $HOME:/home/docker_userindocker run
[2016-12-19 14:00:45] <alexisvincent> Hi guys, I have an interesting problem that I’m trying to solve, and I wondered if anybody here has any input. I’m building an distributed incremental job runner (want to be able to run locally, on kubernetes and others). Each job generates files. Some jobs need to see and add to previous jobs files. Multiple jobs might need to rely on the output of a single other job. Job outputs should be immutable. Delay between starting jobs should be as little as possible. Jobs probably will run on different machines. The layer I use for file storage should be able to run anywhere docker can run, and I have limited ‘control' over the underlying machine. As in I can’t install kernel extensions or partition drives. So the storage layer should be as thin as possible.My current thinking is to use something like UFS… And distribute layers manually…Alternatively, if I could use the underlying docker storage layer that would be awesome. Any ideas?
[2016-12-19 14:01:59] <alexisvincent> Also jobs should be able to run in parrallel where possible (shouldnt be limited by single write master)
[2016-12-19 15:37:37] <marcelmfs> don't create files if you need to distribute output, use a database in the cloud.
[2016-12-19 15:40:57] <alexisvincent> marcelmfs: The output is files. Basically build artifacts
[2016-12-19 16:03:55] <marcelmfs> so use s3 to sync artifacts, or something like artifactory or sonatype's nexus
[2016-12-19 16:05:59] <alexisvincent> Need something faster then that and more lightweight. These would be intermediary steps, not a final artifact.
[2016-12-19 17:59:16] <mamartins> hello!
[2016-12-19 17:59:38] <mamartins> anyone can help me? new to docker
[2016-12-19 17:59:58] <alexisvincent> Hi :) How can I help
[2016-12-19 18:00:20] <mamartins> cannot run an instance of strapi says module not found :o
[2016-12-19 18:00:34] <alexisvincent> command?
[2016-12-19 18:01:19] <mamartins> docker file?
[2016-12-19 18:01:24] <alexisvincent> or that
[2016-12-19 18:01:38] <mamartins> FROM node:5.11.1RUN curl -o- -L https://yarnpkg.com/install.sh | bashENV PATH /root/.yarn/bin:$PATHRUN yarn global add strapi --ignore-enginesavoid reinstalling everything if no changes were madeADD package.json yarn.lock /tmp/RUN cd /tmp && yarn --ignore-enginesRUN mkdir -p /app && cp -a /tmp/node_modules /app/WORKDIR /appADD . /appEXPOSE 3000CMD npm start
[2016-12-19 18:01:39] <alexisvincent> Give me a way to see what you are doing
[2016-12-19 18:02:20] <alexisvincent> ok, so in the container, doing a yarn install fails
[2016-12-19 18:02:49] <mamartins> it doen't fail
[2016-12-19 18:02:52] <mamartins> *Doesnt
[2016-12-19 18:03:28] <alexisvincent> Oh, trying to run the strapi bin fails?
[2016-12-19 18:06:34] <alexisvincent> can you share your npm start script
[2016-12-19 18:06:38] <mamartins> when trying to run the container
[2016-12-19 18:06:46] <mamartins> says strapi module not found
[2016-12-19 18:06:56] <mamartins> Error: Cannot find module \'strapi\'"
[2016-12-19 18:08:27] <alexisvincent> my guess is that yarn is putting the package somewhere weird. tryCMD yarn start
[2016-12-19 18:09:30] <mamartins> let me try
[2016-12-19 18:14:13] <mamartins> same
[2016-12-19 18:14:14] <mamartins> yarn start v0.18.1$ node --harmony server.jsmodule.js:341    throw err;    ^Error: Cannot find module 'strapi'
[2016-12-19 18:15:32] <alexisvincent> if yourm -rf node_modulesin your project andyarn installdoes it work if you plain runnpm start
[2016-12-19 18:16:49] <mamartins> trying
[2016-12-19 18:19:12] <mamartins> woek
[2016-12-19 18:19:15] <mamartins> *works
[2016-12-19 18:21:55] <alexisvincent> hmm… Runyarn global binfrom inside the container. As indocker run container_name yarn global bin
[2016-12-19 18:22:25] <alexisvincent> The output of that is what should be put in your path
[2016-12-19 18:26:04] <mamartins> will try
[2016-12-19 18:30:53] <mamartins> returns /usr/local/bin
[2016-12-19 18:41:52] <mamartins> this is the path of the bin
[2016-12-19 19:49:11] <msitruk> Hello i try to build this Dockerfile : [<-LINK->] with this command : "docker build ." and i get this error on this step "Step 8 : RUN npm install" :  "invalid header field value "oci runtime error: container_linux.go:247: starting container process caused \\"open /proc/self/fd: no such file or directory\\"\\n""
[2016-12-19 20:50:57] <msitruk> nobody can help me ?
[2016-12-19 21:05:20] <dragon788> sounds like the container you are inheriting from may have issues
[2016-12-19 21:05:47] <dragon788> are you doing this on OSX or Linux?
[2016-12-19 21:06:11] <JackChr> Hi@msitruk. What version of Docker have you got?
[2016-12-19 21:06:45] <msitruk> hey Docker version 1.12.3, build 6b644ec
[2016-12-19 21:07:11] <msitruk> and kernel : Darwin MacBook-Pro.local 15.6.0 Darwin Kernel Version 15.6.0: Thu Jun 23 18:25:34 PDT 2016; root:xnu-3248.60.10~1/RELEASE_X86_64 x86_64
[2016-12-19 21:07:18] <msitruk> JackChr: 
[2016-12-19 21:10:12] <msitruk> dragon788: 
[2016-12-19 21:10:41] <JackChr> Im runnig you Dockerfile on version 1.12.4, and Kubuntu 4.4.0-53-generic [<-ISSUE->] -Ubuntu SMP Fri Dec 2 15:59:10 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux and I have same problem. The new version of Docker is 1.12.5.
[2016-12-19 21:10:57] <dragon788> can you pull and run just the container that you are trying to inherit from?
[2016-12-19 21:11:01] <dragon788> msitruk: 
[2016-12-19 21:11:16] <msitruk> so i should update docker ?
[2016-12-19 21:11:50] <msitruk> Docker 1.12.3 is currently the newest version available.
[2016-12-19 21:12:13] <msitruk> dragon788: yes i can try 1 second
[2016-12-19 21:12:26] <dragon788> does your docker run within a Virtualbox VM or is it using the native darwin hypervisor?
[2016-12-19 21:12:27] <JackChr>  [<-LINK->] 
[2016-12-19 21:13:17] <msitruk> dragon788 native i think I have the whale icon on top bar
[2016-12-19 21:21:01] <msitruk> dragon788: I can pull and run node:6-slim witheout error
[2016-12-19 21:22:44] <dragon788> can you find another Dockerfile that uses it to see if it is just this particular file? I'm not sure I've seen two WORKDIRs defined in a single file before
[2016-12-19 21:23:42] <msitruk> yes was orking on other project
[2016-12-19 21:44:36] <mamartins> hello
[2016-12-19 21:44:56] <mamartins> trying to run a container but I get that node modules are missing
[2016-12-19 22:01:27] <dragon788> mamartins: the container may assume you already rannpm installin the directory where the Dockerfile and packages.json is loacated?
[2016-12-19 22:04:12] <mamartins> I run CMD ls node_modules and modules are there!
[2016-12-19 22:04:18] <mamartins> now it is working but I did nothing
[2016-12-19 22:04:50] <mamartins> strange ...
[2016-12-19 22:06:20] <mamartins> found what I add to make it work
[2016-12-19 22:06:21] <mamartins> CMD ls node_modulesCMD npm start
[2016-12-19 22:06:26] <mamartins> the first CMD
[2016-12-19 22:06:36] <mamartins> i'll remove to check it problem returns
[2016-12-19 22:17:41] <mamartins> ok error again
[2016-12-19 22:17:43] <mamartins> error:  TypeError: Cannot read property 'find' of undefinedat Object.module.exports.adapter.find (/app/node_modules/sails-mongo/lib/adapter.js:353:17)at module.exports.find (/app/node_modules/waterline/lib/waterline/adapter/dql.js:120:13)at _runOperation (/app/node_modules/waterline/lib/waterline/query/finders/operations.js:408:29)at run (/app/node_modules/waterline/lib/waterline/query/finders/operations.js:69:8)at module.exports.find (/app/node_modules/waterline/lib/waterline/query/finders/basic.js:264:16)at Deferred.exec (/app/node_modules/waterline/lib/waterline/query/deferred.js:477:16)at module.exports.findOrCreate (/app/node_modules/waterline/lib/waterline/query/composite.js:56:2
[2016-12-19 22:37:09] <dragon788> that sounds like a failure of node inside the container, you might ask in the nodejs/node channel about that
[2016-12-19 22:37:48] <mamartins> indeed
[2016-12-20 07:47:02] <arjunurs> Hi, I am noticing that the container files don’t update after the host files change in a mounted volume. I would appreciate any suggestions
[2016-12-20 08:46:34] <marcelmfs> alexisvincent: Ok, if you need something better than I'd say your requirements of synchronizing artifacts between multiple locations is pretty much a blocking point. Or you can use something like Jenkins to actively push artifacts around as soon as they're built to synch every location, but still, you'll be no better than using S3 as the bottleneck would still be on the network LAN transfers.
[2016-12-20 08:49:33] <alexisvincent> marcelmfs: I'm kind of thinking of using overlay fs, and creating a unified fs, then pushing tars of the diff around the cluster via some distributed file sharing system.
[2016-12-20 08:49:45] <alexisvincent> Much like docker does internally
[2016-12-20 13:51:46] <marcelmfs> docker does not distribute any volume afaik
[2016-12-20 15:30:26] <Iamgowtham29_twitter> Gulp watch is not working on docker with volume sharing ,could anyone share some suggestion to make it working
[2016-12-20 16:06:43] <galvesribeiro> Iamgowtham29_twitter: webpack works with it: [<-LINK->] 
[2016-12-20 18:20:17] <darkSasori> hello,docker run -it --rm --network bridge alpine shand when I execute ping get this error:ping: bad address 'google.com'
[2016-12-20 18:27:45] <darkSasori> any idea?
[2016-12-20 21:31:57] <arjunurs> Hi, I have a volume mapped from host to container in docker-compose.yml but the container files don’t seem to update when I change the host file. Any suggestions?
[2016-12-21 00:02:18] <darkSasori> arjunurs: the volume is mapped in Dockerfile?
[2016-12-21 00:37:13] <dragon788> sometimes depending on the kernel module your docker is using you can get some weird file caching behaviors, iirc aufs depending on the system can be one, there are a few different options
[2016-12-21 07:27:21] <Iamgowtham29_twitter> @galvesribeirothanks for the suggestion I ll look on to that
[2016-12-21 16:28:26] <marcelmfs> darkSasori: :
[2016-12-21 16:29:05] <marcelmfs>  [<-CODE->] 
[2016-12-21 16:29:42] <marcelmfs> can you even resolve names from the docker host?
[2016-12-21 16:32:16] <darkSasori> marcelmfs: yes, and if i addnameserver 8.8.8.8in /etc/resolv.conf in docker, this works
[2016-12-21 16:34:12] <darkSasori> but this only happens in some connections, in office works but in home dont
[2016-12-21 17:04:13] <dragon788> darkSasori: is dnsmasq enabled on your host? sometimes this doesn't update if you change networks
[2016-12-21 17:06:25] <darkSasori> dragon788: i will verify this, ty
[2016-12-21 17:31:58] <sbbowers__twitter> So when I run a docker instance, my entrypoint runs some bootstrapping commands to sync dependancies (specifically php'scomposer install).  These dependencies are written to disk owned by root:root. Is there a way to tell docker (specifically docker-compose) to write files as the user I'm running docker as?
[2016-12-21 17:49:55] <sbbowers__twitter> Looks like docker-composer supports auserkey in the yaml file. I'll try it out, but it would be nice if there was an agnostic way to let all developers run the same config.
[2016-12-21 18:05:59] <renegoretzka> hello. i use rancher and using caddyserver as container and cant forward to my wordpress container, i tried to ping the wordpress container and i gives answer, but still cant proxy to my wordpress.. you could help me figure out my problem?
[2016-12-21 18:09:21] <dragon788> sbbowers__twitter: typically this is construct you create inside your container that picks up the user running the container's ID and chown all the files inside the container to that user during the build
[2016-12-21 18:09:53] <dragon788>  [<-LINK->] 
[2016-12-21 18:38:37] <sbbowers__twitter> dragon788: So the "standard approach" is to bake in "gosu" into all of your docker images by curling a binary off the net and then require your entrypoint to run the command through that, which gives you the option of passing an environment variable with the ID of your current user, all of which won\'t work with docker-compose. Do I understand that right?
[2016-12-21 18:40:30] <dragon788> I thinkgosuis one way to do it, but really since it isn't recommended to run as root anyways, a lot of containers will chmod everything to a known user and run everything as that, the trick is whether that UID exists on your system or not
[2016-12-21 18:47:38] <sbbowers__twitter> So the easy way would to do auseradd -u {some arbitrary ID I pick} docker-useron the host and then pass that user ID to docker's -u?
[2016-12-21 18:48:25] <sbbowers__twitter> If I specify "docker-user" to docker, will it resolve the ID from the host, or does it do a useradd and create a new user?
[2016-12-21 18:52:19] <dragon788>  [<-LINK->] 
[2016-12-21 18:54:27] <dragon788> this appears to have a workaround on an open bug that is somewhat related, [<-ISSUE->] 
[2016-12-21 19:00:54] <renegoretzka> hmm
[2016-12-21 19:00:58] <renegoretzka> no one can help me out?
[2016-12-21 19:01:53] <dragon788> hi@renegoretzkayou might need to ping the Rancher channel as I'm not that familiar with how that platform interacts with containers and forwarding
[2016-12-21 19:02:29] <dragon788> at first blush I\'d check and make sure the containers are on the same network "segment" and then that you exposed the appropriate ports from the wordpress container
[2016-12-21 19:03:35] <renegoretzka> gitter dont have a rancher channel
[2016-12-21 19:04:14] <renegoretzka> i linked both, wordpress and caddy server.. and i even can ping them.. thats the weird path
[2016-12-21 19:05:15] <sbbowers__twitter> Thanks for your help,@dragon788
[2016-12-21 19:05:38] <dragon788> you can rundocker exec <wordpress id> ping <caddyIP>@renegoretzka?
[2016-12-21 19:05:50] <dragon788> np@sbbowers__twitterI just make it up as I go along :D
[2016-12-21 19:06:19] <renegoretzka> yea@dragon788
[2016-12-21 19:49:53] <dragon788> I don't know if the container could have telnet, but you could try runningtelnet <caddyIP> portinstead of  ping, does that work?
[2016-12-21 19:50:34] <renegoretzka> hmm
[2016-12-21 19:51:52] <renegoretzka> telnet does not exist
[2016-12-21 20:07:34] <renegoretzka> dragon788: it seems like caddyserver does not get any request from outside
[2016-12-21 20:07:43] <renegoretzka> since caddyserver didnt write anything to log
[2016-12-21 20:07:49] <renegoretzka> what can be the reason?
[2016-12-21 20:51:30] <dragon788> if it doesn't have a port exposed or if the service isn't running properly inside that could be an issue
[2016-12-21 22:26:48] <rymo90> hi guys i’m new to go programmig language and i having problem with my code… i’m trying to understand why there is blank space when i try to add value into my list /sliece
[2016-12-21 22:26:56] <rymo90> this is how my code looks like
[2016-12-21 22:27:55] <rymo90>  [<-CODE->] 
[2016-12-21 22:28:07] <rymo90> and here is my terminal output
[2016-12-21 22:28:31] <rymo90>  [<-CODE->] 
[2016-12-22 02:21:36] <siassaj> Depending on whether I'm running on staging or on production
[2016-12-22 02:21:43] <siassaj> I need to use a different nginx.config file
[2016-12-22 02:21:56] <siassaj> But i have no idea how to do that. anyone know?
[2016-12-22 06:11:03] <ely029> hey guys I just cloned a dockerized yii. Yes it  is working. How can I create a database? Can anyone here teach me? here is the linkhttps://github.com/codemix/yii2-dockerized
[2016-12-22 06:11:08] <ely029> thanks :)
[2016-12-22 07:42:35] <arjunurs> darkSasori: the volume is mapped in docker-compose.yml file [<-CODE->] 
[2016-12-22 09:56:44] <dmi3zkm> Hi allI have faced an issue regarding docker registry. I have a jenkins which builds new images after each stable commit in VCS. These images promoted to some staging environment. When docker registry runs out of available space jenkins fails to push new images. Is there any thing that would delete old images on scheduled basis from docker registry that are no longer used on my staging environment ?
[2016-12-22 11:18:38] <GastroGeek> @dmi3zkm - dunno about best practice etc but you could mash something together with a script to automagically remove images from storage?https://github.com/burnettk/delete-docker-registry-imageMaybe as part of the build/deploy?
[2016-12-22 11:19:52] <GastroGeek> @dmi3zkm - also check up on 'garbage collection' - newer version may already have support for this?https://github.com/docker/distribution/blob/master/docs/configuration.md#read-only-mode
[2016-12-22 12:35:10] <shyamaspari> HI everyone
[2016-12-22 12:36:00] <dmi3zkm> GastroGeek: thank for your answer, I will research on that
[2016-12-22 13:03:31] <darkSasori> arjunurs: and in your Dockerfile has the declaration of volume```VOLUME /source
[2016-12-22 13:42:46] <richard-ball> Do I have to create host user accounts to allow containers to access persistent storage?
[2016-12-22 20:27:33] <renegoretzka> hey.. i got my caddyserver working.. i get a database error now from wordpress container
[2016-12-22 20:27:44] <renegoretzka> this is the link [<-LINK->] 
[2016-12-22 20:27:54] <renegoretzka> Error establishing a database connection
[2016-12-22 20:55:08] <arjunurs> darkSasori: I have this in the Dockerfile [<-CODE->] 
[2016-12-22 22:12:31] <renegoretzka> i have wordpress running but i dont get any response
[2016-12-22 22:12:37] <renegoretzka> it gets request, but curl is just empty
[2016-12-22 22:12:45] <renegoretzka> wtf?
[2016-12-22 22:55:58] <darkSasori> arjunurs: you need addVOLUME /sourceto work
[2016-12-23 07:09:07] <renegoretzka> Hello,I got Caddyserver running. The Database is working correctly now and moved the domain to point to my new server. Somehow I get just a clear Website, even when I curl the webseite I get zero response.I have made a look into the Caddyserver logs and WordPress logs and I get the request, but no response. I also installed nginx as a container and served the nginx to Caddy to see if Caddy is proxying correctly. I get the welcome screen from nginx. So this is working fine, but when I again bind the WordPress container to Caddy its just nothing.Do you have a clue what can be the reason to get no response on the client but requests on the server?Thank you!
[2016-12-23 10:42:11] <galvesribeiro> hey guys
[2016-12-23 10:42:23] <galvesribeiro> after latest update docker don't start anymore on windows
[2016-12-23 10:42:25] <galvesribeiro>  [<-CODE->] 
[2016-12-23 10:42:48] <galvesribeiro> when my PC restart and if I open the preferences app and click on restart I got this:
[2016-12-23 10:42:55] <galvesribeiro>  [<-CODE->] 
[2016-12-23 10:43:01] <galvesribeiro> any idea on what that means?
[2016-12-23 13:54:02] <dragon788> Are you running from an administrator prompt?
[2016-12-23 14:33:32] <galvesribeiro> Nop
[2016-12-23 14:33:46] <galvesribeiro> I just rebooted my pc
[2016-12-25 10:52:40] <ninabreznik> Hello,I have strange issues on my droplet. A disk drive on my computer died and I had to replace it. Because I don\'t really get this ssh stuff, I of course didn\'t save any keys or anything. And when I nowssh into it and run [<-CODE->] I get this: [<-CODE->] I assumed this means, I can\'t access API, so I ran these 2 commands: [<-CODE->] And got response from API.If I try to start my VM [<-CODE->] I again get thisStarting "default"...POST https://api.digitalocean.com/v2/droplets/34462402/actions: 401 Unable to authenticate you.I am lost, can you please help me figure out what is wrong?Thank you in advance.
[2016-12-25 15:06:41] <dragon788> You will probably need to regenerate your access keys on your droplet
[2016-12-25 15:07:11] <ninabreznik> Thanks@dragon788Any tips how to do that? :D
[2016-12-25 15:11:33] <ninabreznik> Should i go to [<-LINK->] and click add ssh key?
[2016-12-25 15:12:05] <ninabreznik> Do I add the one from my computer or the one from the server (droplet)?
[2016-12-25 18:30:04] <ninabreznik> I have 3 docker VM on my digital droplet.2 are not running, one (new) running perfectly [<-CODE->] My droplet's IPstarts with 45.55.... and new (running) VM starts with same IP, but default and esova have IP starting with 104.131... I created them all on same droplet, haven't check on the server for some months, but now new dev from my client had access to the droplet and restared the password and since then this...Any ideas what is happening?
[2016-12-25 18:30:59] <ninabreznik> If I run [<-CODE->] Everything works perfect.
[2016-12-25 18:31:46] <ninabreznik> But if I do [<-CODE->] I get [<-CODE->] 
[2016-12-25 18:45:23] <shershen08> hello, I am total new to docker, so have couple of questions
[2016-12-25 18:46:08] <shershen08> 1) how to locate where in my fs does this or that container reside? 2) how to remove container by ID - i have couple of containers with the same name.
[2016-12-25 18:46:26] <shershen08>  [<-LINK->] 
[2016-12-25 19:16:31] <ninabreznik>  [<-CODE->] 
[2016-12-25 19:28:26] <shershen08> Thank you!
[2016-12-25 19:30:58] <shershen08> I get back -Error response from daemon: No such container: 01bbb21c400c
[2016-12-25 19:32:19] <shershen08> seems it's this - [<-LINK->] 
[2016-12-25 23:17:53] <mmisztal1980> hi all, I'm working on a container that I intend to run in a swarm env, once it's active - I want it to register with consul, how can I tell what node is it running on? I think I'm going to need it to register with service discovery...
[2016-12-26 11:56:47] <dmi3zkm> does anyone have experience building akka cluster on top of docker swarm?
[2016-12-26 12:00:02] <alexisvincent> Is it possible to store layers as a DAG in the registry? Or does it only support layers that are organised as a tree
[2016-12-26 12:00:10] <alexisvincent> I.e. Standard containers
[2016-12-26 12:40:17] <shyamhd> shershen08: 01bbb21c400c is not cotainer
[2016-12-26 12:40:21] <shyamhd> it is image id
[2016-12-26 12:41:40] <shyamhd> shershen08: write docker ps -a and see what happens
[2016-12-26 12:41:57] <shyamhd> there will be a cointainer id with image name
[2016-12-26 18:19:55] <pfenig> all: trying to find a simple way to tail or access stdout of a linked container running a simple service from another container (running tests) - I'd rather not modify the container running the service i.e. just use stdout - is there a good way to write stdout to a shared volume??
[2016-12-27 01:17:03] <iDVB> I'm new to docker and have been working at getting react-starter-kit up and running for dev and prod using docker-compose. I keep running into issues no matter how I seem to go about it.  Using straight docker I get it running but I can't seem to browse to the server thats running in the container.
[2016-12-27 01:18:45] <iDVB> When I use docker-compose I get an error likesh: babel-node: not foundwhich I think might be happening because for some reason the container is not in the right directory
[2016-12-27 01:19:10] <iDVB> Anyone that might be able to lend a hand would be very appreciated
[2016-12-27 03:17:34] <iDVB> Easier question.... for those looking to use docker for dev workflows that use hot reloading/auto reloading.... is there a best practise for node_modules folder? I mean the node_modules folder needs to be compiled on the container but conversely I need to setup a volume for the src so hot reloading works. Seems odd tonpm iinto a tmp folder in the dockerfile and then get docker-compose to copy that over into the host machine volume. Not to mention that folder being leftover after compose is shut down.
[2016-12-27 20:46:13] <killerspaz> iDVB: simply supplying the volume of the source root folder should do what you want
[2016-12-28 00:58:54] <seroandone> hi
[2016-12-28 13:43:31] <vyscond> hello
[2016-12-28 14:15:38] <olsynt> hi, does containers with c# must run on windows vm ?
[2016-12-28 17:31:46] <dragon788> is it .NET Core C# or legacy .NET Framework C#?
[2016-12-28 18:27:59] <galvesribeiro> olsynt: hey, if you plan to use .Net Full Framework, usemicrosoft/windowsservercoreimage and if you want to run .Net Core, usemicrosoft/nanoserverimage... You can run .Net Core onmicrosoft/windowsservercorehowever it is probably a waste of resources...
[2016-12-28 20:10:14] <killerspaz> Anyone doing any stuff for container dependencies? I havedepends_onin my compose file, but it appears that really doesn't mean much if your command takes a while to initialize.... I see people doing netcat tests to other containers, and this ( [<-LINK->] ), but it feels so dirty... Is there really nothing internal?
[2016-12-28 20:22:17] <killerspaz> also, that doesn't even seem to work, it exits almost immediately and logs show order is NOT kept the way i want
[2016-12-28 21:11:27] <killerspaz> Seriously trying to decouple this crap, and it seems every implementation people have come up with 1000% directly couple containers, which seems to defeat the purpose of a lot of this effort people (including myself) do to abstract ports and hostnames....
[2016-12-28 22:11:04] <multi-io> $ docker-machine create --driver openstack  --openstack-ssh-user ubuntu  --openstack-image-id 8f7f32ee-532f-4e6d-9e96-fb1e95dfdf96  --openstack-flavor-name m1.small  --openstack-floatingip-pool ext-net  --openstack-sec-groups default  docker-devError setting machine configuration from flags provided: Endpoint type must be 'publicURL', 'adminURL' or 'internalURL'
[2016-12-28 22:11:33] <multi-io> ^^^ anything known about incompatibilities of docker-machine's openstack driver with current OpenStack versions?
[2016-12-28 22:12:39] <multi-io> I have a working OpenStack client config, including a tenant ID, in the environment here, all the OpenStack client CLI tools work.
[2016-12-28 22:21:00] <multi-io> hm, added --openstack-auth-url $OS_AUTH_URL --openstack-endpoint-type publicURL , that seems to do it
[2016-12-29 00:57:26] <shawnmclean> What would be the windows volume syntax to point a volume to something like:%USERPROFILE%/.awsusing docker-compose.yml files.?
[2016-12-29 02:18:04] <killerspaz> {$USERPROFILE}/.awsi believe
[2016-12-29 02:18:53] <killerspaz>  [<-LINK->] for reference
[2016-12-29 02:19:19] <killerspaz> looks like i got the braces and $ backwards
[2016-12-29 02:19:31] <killerspaz> ${USERPROFILE}/.aws
[2016-12-29 10:51:59] <munish-dhiman> Is it possible to deploy code on docker swarm using a dockerfile added into the code
[2016-12-29 10:52:00] <munish-dhiman> ?
[2016-12-29 14:24:37] <j6k4m8> munish-dhiman: can you clarify what you’re trying to accomplish?
[2016-12-29 14:25:30] <j6k4m8> (btw there’s a docker/swarm chat too :) )
[2016-12-29 16:11:27] <galvesribeiro> hey guys
[2016-12-29 16:13:32] <galvesribeiro> can an application running inside a container detect which port was used as public in-p xxxx:YYYYY? i.e I want to detect what is the port outside the container so the APP can listen to it even when using random ports generated by docker
[2016-12-29 16:24:14] <killerspaz> docker inspect <container_id>
[2016-12-29 16:24:25] <killerspaz> that'll give you everything docker knows about the container
[2016-12-29 16:43:36] <galvesribeiro> killerspaz: I mean from inside the container
[2016-12-29 16:44:19] <killerspaz> did you see this? [<-ISSUE->] 
[2016-12-29 16:44:20] <galvesribeiro> I mean, after docker spin up the container, my app needs to be aware of its IP and port exposed by docker so it can start listening on that port
[2016-12-29 16:44:42] <j6k4m8> I would pass those as environment variables if you can — should be easier and safer to run on different machines
[2016-12-29 16:44:54] <killerspaz> yeah was going to ask why not supply the port?
[2016-12-29 16:45:57] <galvesribeiro> Because I dont wnat to be supplying ports each I spin a new container
[2016-12-29 16:46:10] <galvesribeiro> I just want to run it and it resolve itself
[2016-12-29 16:46:29] <galvesribeiro> It is pretty common and useful for those mocroservices scenarios
[2016-12-29 16:46:35] <galvesribeiro> Let me see that issue
[2016-12-29 16:49:18] <killerspaz> well the beauty of docker is that ports don't matter in the end, everything is routed through a subnet from different hosts when using docker compose
[2016-12-29 16:49:36] <killerspaz> i have every service running on the same port, and map to different ports to host should I need access
[2016-12-29 16:50:04] <killerspaz> but cross-container's all access byhostname:COMMON_PORT
[2016-12-29 16:58:41] <galvesribeiro> the issue still open, 3 years...
[2016-12-29 16:58:45] <galvesribeiro> anyway
[2016-12-29 16:59:30] <galvesribeiro> killerspaz: the way docker works today as you are stating works pretty well if you are using simple/regular webapps
[2016-12-29 16:59:46] <galvesribeiro> if you have a complex distributed cluster you will end up with this problem
[2016-12-29 17:00:16] <killerspaz> explain more, because I have very complicated distributed clusters
[2016-12-29 17:00:20] <killerspaz> and don't have this problem
[2016-12-29 17:00:29] <galvesribeiro> ok look at this [<-LINK->] 
[2016-12-29 17:01:10] <killerspaz> yeah don't do that
[2016-12-29 17:01:17] <killerspaz> use docker network properly and you won't have this issue
[2016-12-29 17:01:18] <galvesribeiro> the two containers running that has the SiloHost.exe,EXPOSE 2323on its docker file, and they write to a membership table store its port
[2016-12-29 17:01:23] <galvesribeiro> no no
[2016-12-29 17:01:29] <galvesribeiro> listen
[2016-12-29 17:01:36] <galvesribeiro> (read :P )
[2016-12-29 17:02:26] <galvesribeiro> theOrleansClient.exewhich may be a container or not, read from the Membership table storage and know that both silos are running on 2323 so it try to connect to one of them and fail
[2016-12-29 17:02:41] <galvesribeiro> because the port exposed is 3333 and 4444
[2016-12-29 17:02:47] <killerspaz> imo, you shouldn't be spinning up docker containers manually (unless purely testing that single container alone) nor exposing ports manually (again, unless testing)... docker network bridges take care of all that for you.
[2016-12-29 17:03:05] <killerspaz> again, all 50 of my services run on the same port
[2016-12-29 17:03:05] <galvesribeiro> no it doesn't
[2016-12-29 17:03:09] <galvesribeiro> that is the point
[2016-12-29 17:03:20] <galvesribeiro> the client connects to the silos by reading the membership table
[2016-12-29 17:03:24] <killerspaz> in that drawing, you have no context of any network
[2016-12-29 17:03:34] <galvesribeiro> we don't need the context
[2016-12-29 17:03:36] <galvesribeiro> ignore that
[2016-12-29 17:03:41] <killerspaz> no i'm telling you that you DO
[2016-12-29 17:03:54] <killerspaz> in order for the containers to talk to each other without you having to worry about port mapping
[2016-12-29 17:04:24] <killerspaz> unless you're not detailing enough information, this is the basis of docker and microservices, and not out of the norm
[2016-12-29 17:04:42] <galvesribeiro> assume that the containers are reacheable to each other
[2016-12-29 17:05:15] <killerspaz> i have 50 services per cluster, and about 12 clusters across the globe, and don't have any issues with having to track down ports
[2016-12-29 17:05:47] <galvesribeiro> the problem is that the 1. Server app need to know the port and IP it will bind to so it can write it to membership table. 2. the client read this data from that table so it WILL need IP and PORT each silo is running
[2016-12-29 17:05:50] <galvesribeiro> trust me
[2016-12-29 17:05:53] <killerspaz> so when you spin up your deployment, you're manually runningdocker runlines?
[2016-12-29 17:05:55] <galvesribeiro> the application NEED that
[2016-12-29 17:06:02] <killerspaz> no dude, docker has all that built in natively
[2016-12-29 17:06:07] <galvesribeiro> :(
[2016-12-29 17:06:08] <killerspaz> you don't need to know IPs at all
[2016-12-29 17:06:24] <galvesribeiro> you are not understanding :(
[2016-12-29 17:07:04] <killerspaz> so maybe you can elaborate a bit? Because I'm still not seeing the issue other than your understanding of docker/compose
[2016-12-29 17:07:19] <galvesribeiro> ok... let me try again
[2016-12-29 17:07:36] <galvesribeiro> regardless of how docker manage dns resolution and port binding
[2016-12-29 17:08:00] <galvesribeiro> the server application needs to know which IP:PORT it will listen to and write to the membership store tables
[2016-12-29 17:08:02] <galvesribeiro> got it?
[2016-12-29 17:08:04] <galvesribeiro> now
[2016-12-29 17:08:24] <killerspaz> i'm pretty certain I understand what you're trying to do
[2016-12-29 17:08:28] <galvesribeiro> the client which will read from the membership table will need to be able to reach IP:PORT
[2016-12-29 17:08:28] <killerspaz> you're basically building a mesh
[2016-12-29 17:08:34] <killerspaz> an explicit mesh
[2016-12-29 17:08:40] <galvesribeiro> it is a Distributed Hash Table
[2016-12-29 17:08:45] <killerspaz> which i'm telling you is redundant because docker has that native
[2016-12-29 17:08:47] <galvesribeiro> that manages membership of the cluster
[2016-12-29 17:09:02] <galvesribeiro> ok...
[2016-12-29 17:09:03] <galvesribeiro> so
[2016-12-29 17:09:03] <killerspaz> answer this, are you ever runningdocker runoutside of running unit tests?
[2016-12-29 17:09:22] <galvesribeiro> for the local tests I'm using docker run
[2016-12-29 17:09:33] <galvesribeiro> but I plan to learn and use compose to make it production soon
[2016-12-29 17:09:50] <killerspaz> i'd get that going immediately, you'll see it works all that out really quick
[2016-12-29 17:10:05] <galvesribeiro> it wont
[2016-12-29 17:10:45] <galvesribeiro> the cluster althought they are running the same image, when each machin join the cluster it join the DHT which makes it handle specific part of the messages
[2016-12-29 17:11:07] <galvesribeiro> it is not like a web server that you can reach a service or DNS name that will be round robin balanced to any server
[2016-12-29 17:11:23] <killerspaz> you supply services, which docker-compose will institute hostnames as the same name, then ports you can just keep constant, and access viaservice_A:1024,service_B:1024,some_mongo_instance:27017(if using default mongo images with default ports)
[2016-12-29 17:11:32] <galvesribeiro> the client (based on that membership table) will need to connect specifically for a given silo/server to do specific stuff
[2016-12-29 17:11:33] <killerspaz> docker compose IS a dns
[2016-12-29 17:11:41] <killerspaz> ... effectively
[2016-12-29 17:12:22] <galvesribeiro> ok, but institute default port will make 2 conatiners to run in the same host
[2016-12-29 17:12:32] <killerspaz> mm no
[2016-12-29 17:12:37] <killerspaz> that's already bad construction of containers
[2016-12-29 17:12:46] <killerspaz> they should be separate containers
[2016-12-29 17:13:01] <killerspaz> mongo_users, mongo_logs, mongo_whatever
[2016-12-29 17:13:13] <killerspaz> not just "mongo" and all your dbs are in that container
[2016-12-29 17:13:34] <galvesribeiro> :(
[2016-12-29 17:13:39] <galvesribeiro> you still don't undertand  my problem
[2016-12-29 17:13:40] <galvesribeiro>  [<-LINK->] 
[2016-12-29 17:13:51] <galvesribeiro> you deal as it was a regular web app
[2016-12-29 17:13:54] <galvesribeiro> but it is not
[2016-12-29 17:14:00] <galvesribeiro> it is really a distributed cluster
[2016-12-29 17:14:15] <galvesribeiro> and I may have multiples clusters running on the same machine
[2016-12-29 17:14:26] <galvesribeiro> and if I specify a given port they will not be able to run
[2016-12-29 17:14:58] <killerspaz> your clusters should be subnetted
[2016-12-29 17:15:10] <killerspaz> and on different hostnames
[2016-12-29 17:15:16] <galvesribeiro> why?
[2016-12-29 17:15:26] <killerspaz> because best practices
[2016-12-29 17:15:31] <killerspaz> for this reason exactly
[2016-12-29 17:15:41] <killerspaz> you avoid port collission
[2016-12-29 17:15:42] <galvesribeiro> I want have multiple a pool of container host machines
[2016-12-29 17:15:52] <galvesribeiro> and just spin containers in them
[2016-12-29 17:15:56] <galvesribeiro> and ask them to just run
[2016-12-29 17:16:01] <galvesribeiro> that is what I do today with VMs
[2016-12-29 17:16:33] <killerspaz> thus, began docker compose
[2016-12-29 17:16:50] <killerspaz> it does all the subnet and iptable routing for you
[2016-12-29 17:17:00] <galvesribeiro> I already have a notion of what compose does and it don't solve my problem
[2016-12-29 17:17:29] <galvesribeiro> because (again) load balancing is not what I'm looking for...
[2016-12-29 17:17:29] <killerspaz> I think you're trying to over complicate it, honestly.... Not sure what Orleans is for exactly, but it's redundant imo.
[2016-12-29 17:17:37] <killerspaz> i'm not talking about load balancing
[2016-12-29 17:17:51] <killerspaz> i'm talking about host and port resolution
[2016-12-29 17:17:55] <galvesribeiro> ok, so tell me one thing...
[2016-12-29 17:18:09] <galvesribeiro> does docker has service discovery?
[2016-12-29 17:18:14] <killerspaz> yes
[2016-12-29 17:18:18] <galvesribeiro> ok, how?
[2016-12-29 17:18:25] <killerspaz> through hostnames via docker-compose
[2016-12-29 17:18:27] <galvesribeiro> service discovery != DNS resolution
[2016-12-29 17:19:01] <killerspaz> it effectively is though; [<-LINK->] 
[2016-12-29 17:19:11] <killerspaz> docker cloud uses docker compose to create the mesh
[2016-12-29 17:19:49] <killerspaz> compltely via hostname, which is the same as the service name
[2016-12-29 17:19:50] <galvesribeiro> service discovery is not just hostnames or DNSs... it is service name (maybe it can be the hostname in case of single node service) plus port
[2016-12-29 17:20:07] <galvesribeiro> links only add HOSTNAME to the machines
[2016-12-29 17:20:11] <galvesribeiro> not service discovery
[2016-12-29 17:21:19] <galvesribeiro> ok, let me ask something else
[2016-12-29 17:21:50] <killerspaz> in traditional service discovery you'd absolutely need the port like you're doing, but i'm saying with docker/kubernetes/etc you do not. The SWARM clusters figure all the routing between subnets for you, and you simply access viaremote_hostname:whatever_port_you_run_inside_container
[2016-12-29 17:21:57] <galvesribeiro> is there a way for my client containers to query "hey docker, what are the conainters running the Image XXXX and what are their published port" ?
[2016-12-29 17:22:34] <killerspaz> I don't believe that's a valid use-case with docker
[2016-12-29 17:22:41] <killerspaz> except for health monitoring maybe
[2016-12-29 17:22:48] <galvesribeiro> ok, then it doesn't have service discovery :D
[2016-12-29 17:22:50] <killerspaz> but even still, IoC would work better
[2016-12-29 17:23:57] <killerspaz> i would say in my app "nc servicename:port` and connect and be done... I dont\' care which of the 20 cloned containers it is, the swarm handles that for me routing to an existing container
[2016-12-29 17:24:12] <killerspaz> it's service discovery in the sense that you can access services simply, without having to LOOK them up first.
[2016-12-29 17:24:14] <galvesribeiro> the point is, when my server start, it need to say tosomething"hey I\'m listening on port XXXX and my resolvable hostname is YYYY", then the client will query this same "something" for all the available services
[2016-12-29 17:24:42] <galvesribeiro> I dont' care which of the 20 cloned containers it isThat is the problem... We DO care about which container we are connecting to
[2016-12-29 17:24:55] <killerspaz> ok, but why?
[2016-12-29 17:25:02] <galvesribeiro>  [<-LINK->] 
[2016-12-29 17:25:05] <killerspaz> I can accept that, just need to understand why
[2016-12-29 17:25:28] <galvesribeiro> because of the membership protocol and the DHT which distribute what and where some actions will happen in Orleans
[2016-12-29 17:25:28] <killerspaz> ignoring orleans atm, what is the actual business case for this
[2016-12-29 17:25:44] <killerspaz> simply because you WANT to use Orleans?
[2016-12-29 17:26:35] <galvesribeiro> no, because I USE Orleans and that is proven piece of tech created by multiple PhDs in Distributed Computing and host huge distributed services like Halo game, Skype, and multiple others
[2016-12-29 17:26:36] <killerspaz> I'm just trying to understand why out of 20 cloned containers you need any one specific one
[2016-12-29 17:26:41] <galvesribeiro> so trust me, they know what they are doing
[2016-12-29 17:26:57] <dragon788> galvesribeiro: I hope you plan on getting your PhD, because most Microsoft tools require that in order to use them
[2016-12-29 17:27:11] <killerspaz> Not saying they don't, but there's other ways to accomplish the same thing that I think are easier
[2016-12-29 17:27:27] <galvesribeiro> because 1 of the actors (the processing unit in Orleans) that I'm interested in is inside that give specific container
[2016-12-29 17:27:28] <killerspaz> but i'm not fully understanding your need
[2016-12-29 17:27:29] <dragon788> the problem is microsoft always ignores existing implementations like etcd/consul/etc and invents their own way of doing things, typically ignoring the existing work done and the pitfalls that have been encountered and worked around
[2016-12-29 17:27:52] <galvesribeiro> dragon788: Orleans works perfectly with Consul, Zookeeper and other membership providers
[2016-12-29 17:27:57] <killerspaz> so they aren't 20 cloned containers in your example then, right? they'd actually be unique containers?
[2016-12-29 17:28:19] <killerspaz> conatiner 1 does something completely different than container 2?
[2016-12-29 17:28:21] <galvesribeiro> dragon788: if you read the link I pasted it mention that... so MS don't ignore anything
[2016-12-29 17:28:34] <galvesribeiro> killerspaz: the OS, Frameworks, APP, they are the same, cloned
[2016-12-29 17:28:46] <galvesribeiro> they just process part of the workload individually
[2016-12-29 17:28:56] <killerspaz> so why would one act differently than the other?
[2016-12-29 17:28:56] <galvesribeiro> the Actors are balanced between the cluster
[2016-12-29 17:29:08] <galvesribeiro> they don't act diff then another
[2016-12-29 17:29:14] <killerspaz> so each container can POTENTIALLY do n-actions?
[2016-12-29 17:29:26] <killerspaz> all as first-class citizens?
[2016-12-29 17:29:29] <galvesribeiro> its hard to explain...
[2016-12-29 17:29:35] <killerspaz> lol sounds like it :P
[2016-12-29 17:29:35] <galvesribeiro> do you know the Actor model?
[2016-12-29 17:29:38] <killerspaz> yes
[2016-12-29 17:29:40] <galvesribeiro> ok
[2016-12-29 17:29:48] <galvesribeiro> in Orleans a cluster is a pool of machines
[2016-12-29 17:29:53] <galvesribeiro> that have same code running
[2016-12-29 17:30:15] <galvesribeiro> the 1 actor instance can be activated anywhere in the cluster
[2016-12-29 17:30:33] <galvesribeiro> in this case on any of container being part of the cluster
[2016-12-29 17:30:35] <galvesribeiro> so
[2016-12-29 17:30:43] <galvesribeiro> assuming that I have 2 containers in the cluster
[2016-12-29 17:31:02] <killerspaz> so key phrase i\'m reading is "any of container"
[2016-12-29 17:31:11] <galvesribeiro> one request comes and activate ActorA on containerA and another comes and activate ActorB in containerB
[2016-12-29 17:31:20] <killerspaz> which means you do not need to know which one, just A container that can do what you need
[2016-12-29 17:31:42] <killerspaz> ok, that is load balancing
[2016-12-29 17:31:44] <galvesribeiro> so while the actors are in memory,  when the client needs to talk to the ActorB it MUST connect directly to containerB
[2016-12-29 17:32:02] <killerspaz> sure
[2016-12-29 17:32:03] <galvesribeiro> the actor balancing and placement is an internal behavior of Orleans
[2016-12-29 17:32:15] <galvesribeiro> not a regular web/tcp NLB thing
[2016-12-29 17:32:37] <killerspaz> I can't help you with Orleans, at all... But again, it sounds heavily redundant based on docker technology
[2016-12-29 17:32:41] <galvesribeiro> and the client figure out where that specific activation is based on that membership table and an activation catalog
[2016-12-29 17:32:54] <galvesribeiro> Orleans is ortogonal
[2016-12-29 17:32:57] <galvesribeiro> to any of this
[2016-12-29 17:33:00] <galvesribeiro> like I said
[2016-12-29 17:33:04] <killerspaz> that's the point though
[2016-12-29 17:33:16] <galvesribeiro> I can create a Membership provider that uses Docker infrastructure
[2016-12-29 17:33:38] <galvesribeiro> just like we did for SQL, Zookeeper, Paxus, etcd, Consul and many other service discovery mechanisms
[2016-12-29 17:33:56] <killerspaz> except you can't, because you don't know your ip/port?
[2016-12-29 17:34:08] <galvesribeiro> so, in order to create that membership provider in Orleans, I need to know where I can query for my containers
[2016-12-29 17:34:26] <killerspaz> i dunno, i have tons of jobs that distribute across multiple clusters and sync across th eworld... i've never had to concern myself with discovery when using docker
[2016-12-29 17:34:56] <galvesribeiro> because you use regular balancing stuff... like DNS  :)
[2016-12-29 17:35:10] <killerspaz> i hit a load balancer, it directs to a container i need, done.... but i always access via hostname. if a container needs to be spun up, it spins up, shuts down when done.
[2016-12-29 17:35:13] <galvesribeiro> which is perfect for Web and basic request/response stateless services
[2016-12-29 17:35:22] <galvesribeiro> yeah, because they are stateless
[2016-12-29 17:35:25] <killerspaz> i don't care which of the 1000 physical bare metal boxes it starts on
[2016-12-29 17:35:35] <galvesribeiro> yes! because they are stateless :P
[2016-12-29 17:35:48] <killerspaz> lol now we're about to get into more wars :P
[2016-12-29 17:35:54] <galvesribeiro> heheheheheh
[2016-12-29 17:36:29] <killerspaz> I believe in stateless design; containers are meant to be ephemeral
[2016-12-29 17:36:43] <galvesribeiro> that issue you first posted is precisely why we need that and tons of people replied with +1 3years ago
[2016-12-29 17:36:53] <galvesribeiro> and they do in Orleans
[2016-12-29 17:36:59] <galvesribeiro> if one container is destroyed
[2016-12-29 17:37:01] <galvesribeiro> no problem
[2016-12-29 17:37:20] <galvesribeiro> the state is persisted and if someone ask for that actor again, it is activated on another server
[2016-12-29 17:38:17] <killerspaz> could you possibly netstat and get the port by process?
[2016-12-29 17:38:49] <galvesribeiro> you mean the client netstat the container host?
[2016-12-29 17:39:00] <killerspaz> inside the container itself
[2016-12-29 17:39:06] <killerspaz> to register it to the Membership Table
[2016-12-29 17:39:16] <galvesribeiro> it does it today
[2016-12-29 17:39:23] <galvesribeiro> I mean
[2016-12-29 17:40:46] <galvesribeiro> when starting a Orleans silo, and has a membership provider configured, it will get that port and IP and write to the membership table
[2016-12-29 17:40:53] <galvesribeiro> that is regardless of docker or whatever
[2016-12-29 17:41:00] <galvesribeiro> the problem is not the silo
[2016-12-29 17:41:20] <galvesribeiro> the image will do aEXPOSE xxxxso all containers internally expose the same port
[2016-12-29 17:41:27] <galvesribeiro> that is OK so fa
[2016-12-29 17:41:28] <galvesribeiro> far
[2016-12-29 17:41:42] <killerspaz> you don't need EXPOSE though
[2016-12-29 17:41:45] <killerspaz> with compose
[2016-12-29 17:41:47] <galvesribeiro> humm
[2016-12-29 17:41:51] <galvesribeiro> ok
[2016-12-29 17:41:54] <galvesribeiro> so ignoring expose
[2016-12-29 17:42:07] <galvesribeiro> the app start and write down its port to the membership
[2016-12-29 17:42:30] <galvesribeiro> next step is the client read the membership table, get the IP and PORT of all silos alive
[2016-12-29 17:42:39] <galvesribeiro> and connect to each one of them on that port
[2016-12-29 17:42:59] <killerspaz> so is it possible to run all members on the same port if they were different hosts?
[2016-12-29 17:43:04] <killerspaz> or is it mandatory to be arbitrary?
[2016-12-29 17:43:51] <galvesribeiro> you mean make all them with-p sameexposedport:someinternalporton all the containers assuming only 1 is running on that same host?
[2016-12-29 17:46:13] <killerspaz> here's an example of my docker-compose.yml: [<-LINK->] 
[2016-12-29 17:46:34] <killerspaz> inside the container, the app spins up some service.. in the case of mongo, they all start on port 27017
[2016-12-29 17:46:45] <killerspaz> but i don't define that, mongo does... i COULD with an ENV var, but I don't
[2016-12-29 17:46:59] <killerspaz> however, all my other containers can access mongo_user:27017 without issue
[2016-12-29 17:47:11] <killerspaz> and mongo itself can load balance to it's own cluster/shards/etc
[2016-12-29 17:47:51] <killerspaz> as for the bottom oneapi.user, that's a nginx load balancer with knowledge of all the associative services. it's the ONLY container exposed in this example.
[2016-12-29 17:48:01] <killerspaz> so external services can contact this cluster
[2016-12-29 17:49:03] <killerspaz> but i can just access viawget api.userfrom any container
[2016-12-29 17:49:09] <killerspaz> ANY container
[2016-12-29 17:49:21] <killerspaz> or vice versa,mongo_users
[2016-12-29 17:49:35] <galvesribeiro> yeah, pretty clean 3-tier web architecture
[2016-12-29 17:49:44] <killerspaz> that's just a snippet of the 50+ that are in there
[2016-12-29 17:50:02] <killerspaz> and only 1 cluster type
[2016-12-29 17:50:04] <galvesribeiro> which is very different from what we do
[2016-12-29 17:50:42] <killerspaz> afaiac, that's how docker is meant to be used
[2016-12-29 17:51:02] <galvesribeiro> yeah that is what I meant in the first place :)
[2016-12-29 17:51:17] <galvesribeiro> docker is easy and really good for simple web applications which mostly are 3-tier apps
[2016-12-29 17:51:45] <galvesribeiro> when you have something complex like actor frameworks and DHT scenarios you have this problem
[2016-12-29 17:51:53] <galvesribeiro> it is not just Orleans
[2016-12-29 17:51:54] <galvesribeiro> I mean
[2016-12-29 17:52:03] <galvesribeiro> Erlang, Akka, they all would have the same issue
[2016-12-29 17:52:26] <galvesribeiro> because they all agree on some membership protocol mostly based on DHTs
[2016-12-29 17:53:16] <killerspaz> and i would never use those with a container system, personally
[2016-12-29 17:53:35] <galvesribeiro> that is the point, they are really good fit for containers
[2016-12-29 17:53:43] <killerspaz> most modern message systems use SWIM algorithm to avoid this
[2016-12-29 17:53:50] <galvesribeiro> ???
[2016-12-29 17:54:00] <galvesribeiro> modern, you mean web :)
[2016-12-29 17:54:08] <killerspaz> anything within the last 10 years
[2016-12-29 17:54:25] <killerspaz> look at how netflix does their stuff... i can guarantee it's more complex that yours and mine combined :P
[2016-12-29 17:54:58] <galvesribeiro> netflix is a streaming service which is 90% of their work focused on web apps :D
[2016-12-29 17:55:06] <killerspaz> not even close
[2016-12-29 17:55:16] <galvesribeiro> there is nothing about distributed computing for netflix :D
[2016-12-29 17:55:21] <galvesribeiro> they just, stream stuff
[2016-12-29 17:55:21] <killerspaz> LOL ok
[2016-12-29 17:55:31] <galvesribeiro> I did an interview with them here :)
[2016-12-29 17:55:33] <killerspaz> that's not remotely true
[2016-12-29 17:55:43] <galvesribeiro> not saying that they are crap
[2016-12-29 17:55:44] <galvesribeiro> they are amazing
[2016-12-29 17:55:50] <galvesribeiro> but it is something focused on web
[2016-12-29 17:55:57] <galvesribeiro> not even close to distributed computing or actors
[2016-12-29 17:56:24] <galvesribeiro> they dont have concurrency and other problems that distributed computing propose to handle
[2016-12-29 17:56:25] <galvesribeiro> anyway
[2016-12-29 17:56:30] <galvesribeiro> lets not bloat the chat with it
[2016-12-29 17:56:36] <killerspaz> lol they most certainly do
[2016-12-29 17:56:59] <galvesribeiro> I just need to figure out a way to create a membership provider for docker
[2016-12-29 17:57:06] <galvesribeiro> to give an Idea
[2016-12-29 17:57:14] <galvesribeiro> do you know Service Fabric?
[2016-12-29 17:58:18] <galvesribeiro> they have a internal "Naming Service" which is basically a service discovery service... so Orleans run perfectly in it... we created a provider that register the silos in this service, and the client ask about the service there
[2016-12-29 17:58:20] <killerspaz> i'm familiar, but never used it
[2016-12-29 17:58:41] <galvesribeiro> so the "Membership Table" is just a concept, which can be implemented anywhere as long as we follow the protocol
[2016-12-29 17:58:46] <galvesribeiro> so SF just works
[2016-12-29 17:59:03] <killerspaz> and how do you define the internal names
[2016-12-29 17:59:19] <galvesribeiro> the same way as Consul and Zookeeper which are K/V dictionary repo
[2016-12-29 17:59:22] <galvesribeiro> internal names?
[2016-12-29 17:59:38] <killerspaz> they have a internal "Naming Service" which is basically a service discovery service
[2016-12-29 18:00:03] <killerspaz> so when you want to discover, do you have to use some randomly generated names, or do you provide them
[2016-12-29 18:00:53] <killerspaz> SF is to Azure as Docker Swarm is to Docker
[2016-12-29 18:01:28] <galvesribeiro> I ask them for ALL the silos in naming service, connect to 1 of them first time, get a list of the Actors activation and later on, based on which actor I want to connect, I specifically connect to that server
[2016-12-29 18:01:42] <galvesribeiro> not exactly
[2016-12-29 18:02:08] <galvesribeiro> when you use swarm there is a notion of service
[2016-12-29 18:02:34] <galvesribeiro> which you client try to connect to it, and it forward to any of the thousands of containers listen on diff internal ports
[2016-12-29 18:02:42] <galvesribeiro> this is basically DNS with port forwarding
[2016-12-29 18:03:01] <killerspaz> no, you have each docker daemon join the swarm (aka DHT)
[2016-12-29 18:03:08] <killerspaz> there's no routing, it's explicit
[2016-12-29 18:03:28] <galvesribeiro> yes they join and form a swarm cluster I understand that
[2016-12-29 18:03:42] <killerspaz> which is what you're trying to accomplish with Orleans from my understanding
[2016-12-29 18:03:54] <galvesribeiro> Orleans already do that
[2016-12-29 18:03:55] <galvesribeiro> but
[2016-12-29 18:03:59] <galvesribeiro> like I said
[2016-12-29 18:04:01] <galvesribeiro> it is plugable
[2016-12-29 18:04:29] <galvesribeiro> so if I can query Swarm I can create a provider for it :D
[2016-12-29 18:04:47] <killerspaz> and what would this provider do?
[2016-12-29 18:05:42] <killerspaz> i just can't understand a reason i'd ever want to access a single container explicitly. Sounds entirely cumbersome.
[2016-12-29 18:06:21] <galvesribeiro> if you understand actors there is multiple reasons for that
[2016-12-29 18:06:37] <galvesribeiro> but the location of the actor is transparent for the developer
[2016-12-29 18:06:40] <galvesribeiro> it "Just run"
[2016-12-29 18:06:50] <galvesribeiro> the framework internally needs to understand that
[2016-12-29 18:07:16] <galvesribeiro> at the server/silo side the provider, register all servers in swarm... as far as I understood, docker already register the containers on swarm as part of a service, good, so no change at all at server
[2016-12-29 18:07:52] <galvesribeiro> so in the client, when it start, the provider must query something to get a list of silos in that cluster that are alive
[2016-12-29 18:08:40] <galvesribeiro> and then when it needs to send a message to a specific actor in a specific server you will connect to that specific silo
[2016-12-29 18:09:36] <galvesribeiro> the load balancing of an actor in Orleans is extremely efficient and beat by far NLB algorithms and reverse proxies
[2016-12-29 18:14:27] <galvesribeiro> but@killerspazdo you think if there is a chance to find what I want, docker swarm docs is the write guy to look for it, right?
[2016-12-29 18:15:12] <killerspaz> yes, in conjunction with docker compose
[2016-12-29 18:15:15] <killerspaz> imo
[2016-12-29 18:15:21] <killerspaz> unless anyone else has any other input
[2016-12-29 18:15:32] <galvesribeiro> ok thank you, really appreciate the help
[2016-12-29 18:15:36] <killerspaz> i wouldn't call myself an expert, but I've just never needed to do what you're trying
[2016-12-29 18:15:38] <galvesribeiro> will have a look on both deeper
[2016-12-29 18:15:50] <killerspaz> and i have concurrent systems all over the place
[2016-12-29 18:16:02] <killerspaz> let me rephrase... i haven't had the need since using docker
[2016-12-29 18:16:32] <killerspaz> and i'm using SWIM technologies to simplify the DHT issues you're having
[2016-12-29 18:17:14] <killerspaz>  [<-LINK->] 
[2016-12-29 18:17:41] <galvesribeiro> that is my point, if docker handle somehow service discovery, I would be more than happy to use it and plug it on docker by a provider
[2016-12-29 18:17:47] <galvesribeiro> yeah I know SWIM
[2016-12-29 18:18:02] <galvesribeiro> it is another variation of PAXOS
[2016-12-29 18:18:23] <killerspaz> we're currently using pattern matching for identifying the node we need to discover, but that's all behind the scenes
[2016-12-29 18:19:35] <killerspaz> so i can send a message in json format if i want like:{ actor: 'User', action: 'sync'}and every node that supports thath command is told to sync, and they are queued into rabbitMQ in batches, then another job that was also listening for the same pattern processes the queue
[2016-12-29 18:19:41] <killerspaz> ... for example.
[2016-12-29 18:19:58] <galvesribeiro> yeah but that is just a pub/sub mechanism
[2016-12-29 18:20:32] <killerspaz> mmm not exactly, it MUST exist
[2016-12-29 18:20:49] <killerspaz> the SWIM impl uses the pattern to do service discovery
[2016-12-29 18:21:02] <killerspaz> which services support this
[2016-12-29 18:21:05] <killerspaz> THEN it messages them
[2016-12-29 18:21:11] <killerspaz> it's very similar to akka actually
[2016-12-29 18:21:21] <galvesribeiro> ok
[2016-12-29 18:21:31] <killerspaz> only i don't need elasticsearch
[2016-12-29 18:21:32] <galvesribeiro> its hard to wrap around our heads on actors... I had a hard time first some years ago... then I found Orleans after I leave MSFT
[2016-12-29 18:21:44] <galvesribeiro> Akka and Erlang is so limited
[2016-12-29 18:22:31] <galvesribeiro> you as a developer in Erlang or Akka, need to instantiate an actor and put it on a specific place in the cluster
[2016-12-29 18:22:36] <galvesribeiro> in orleans you don't do that
[2016-12-29 18:23:24] <galvesribeiro> you get a reference without knowing where the actor is running and call a regular method... that method call is shipped internally to the right silo in the cluster and you will receive the response
[2016-12-29 18:23:38] <galvesribeiro> exceptions are propagated across all nodes etc
[2016-12-29 18:23:39] <galvesribeiro> anyway
[2016-12-29 18:24:06] <galvesribeiro> a very modern (and easy) way to make distribute cloud apps
[2016-12-29 18:27:46] <killerspaz> I've been out of the microsoft world for a bit, other than OS.
[2016-12-29 18:27:56] <killerspaz> not by choice, just how things worked out
[2016-12-29 18:31:01] <galvesribeiro> Ic
[2016-12-29 18:31:04] <galvesribeiro>  [<-ISSUE->] 
[2016-12-29 18:31:22] <galvesribeiro> This issue proposes an introspection rest api just as AWS does
[2016-12-29 18:31:36] <galvesribeiro> That would give me the information I need
[2016-12-29 19:17:55] <dragon788> in orleans you don't do thatyou get a reference without knowing where the actor is running and call a regular method... that method call is shipped internally to the right silo in the cluster and you will receive the response
[2016-12-29 19:18:11] <dragon788> this is what is confusing me, why do you need to find/call the actor yourself if your framework handles that?
[2016-12-29 19:20:24] <dragon788> in your example if Client B talks to Container B and initiates a session, you just need to ensure that session persists between B and B, not add the ridiculous complexity of pulling out all this information from the containers and discovering the overall topology of the entire cluster, that way lies madness
[2016-12-29 19:20:48] <dragon788> it sounds like you are defeating the purpose of Orleans if you are doing all this extra work
[2016-12-29 19:36:08] <galvesribeiro> dragon788: there are two roles here
[2016-12-29 19:36:26] <galvesribeiro> I as an application developer which use Orleans dont need to care about it
[2016-12-29 19:37:25] <galvesribeiro> But I as an Orleans maintainer which is trying to make Orleans to run on container needs to know and implement it. Because behind the scenes the framework uses it
[2016-12-29 19:42:25] <dragon788> are you running this in house or on a cloud hosting solution? reading the Orleans whitepaper they recommend using Zookeeper if in house, or Azure Tables/SQL if elsewhere
[2016-12-29 19:47:13] <galvesribeiro> dragon788: it doesnt matter actually. It is just a general suggestion. Zookeeper is just one of many membership providers supported
[2016-12-29 19:47:42] <galvesribeiro> But I'm runnin on azure VMs with windows containers in it
[2016-12-29 19:47:56] <dragon788> agreed, but Zookeeper/Consul/etc will all solve this for your containers, so what is preventing you from using those or Azure Tables as your MemberShipPool?
[2016-12-29 19:48:01] <dragon788> or registry or whatever
[2016-12-29 19:48:20] <galvesribeiro> But even if I use zookeeper it will not fix my issue
[2016-12-29 19:48:28] <galvesribeiro> Neither consul or whatever registry
[2016-12-29 19:49:12] <dragon788> I think you are overthinking this
[2016-12-29 19:49:53] <dragon788> I'd just give it a try using Azure Tables or whatever, then if it does not work, you have exhausted the possibility, if you haven't tried it and are just assuming it won't work, then it is hard to suggest alternatives
[2016-12-29 19:50:09] <galvesribeiro> The problem is by the time my orleans silo  app is installing, it need to know which port it is using so it write it to membership table
[2016-12-29 19:50:18] <galvesribeiro> Or zookeeper or consul or whatever
[2016-12-29 19:50:34] <galvesribeiro> I already have orleans on several production apps
[2016-12-29 19:50:42] <galvesribeiro> Just jot in containers
[2016-12-29 19:51:12] <galvesribeiro> Installinng I meant starting (sorry on mobile now)
[2016-12-29 20:09:24] <galvesribeiro> Looks like registrator keeps pooling docker APIs to check the containers there and register them...
[2016-12-29 20:11:45] <galvesribeiro> I may have an idea :)
[2016-12-29 20:16:11] <galvesribeiro> From inside a container can I access the host ip machine (on docker virtual network) so I can make requests to dockerd REST api?
[2016-12-29 22:38:06] <galvesribeiro> dragon788: /@killerspaz?
[2016-12-29 22:39:54] <dragon788> yeah
[2016-12-29 22:40:21] <dragon788> the host may exist on the docker network depending on what options you run a container with
[2016-12-29 22:40:31] <dragon788> a lot of it is designed for isolation, but you can bypass that
[2016-12-29 22:41:41] <dragon788> or you could mount the docker socket into a specific container and present the REST api on the docker network, though security wise that is frowned upon
[2016-12-29 22:42:30] <galvesribeiro> Yeah I see an IP on the host that is on the container network and inside the container this very same IP is its gateway
[2016-12-29 22:42:52] <galvesribeiro> I cant use the socket hack because it is linux specific
[2016-12-29 22:42:58] <galvesribeiro> Windows doesnt have it
[2016-12-29 22:45:15] <dragon788> ahhh yeah, poor Windows :)
[2016-12-29 22:45:26] <galvesribeiro> Hehehe
[2016-12-29 22:45:28] <galvesribeiro> Yeah
[2016-12-29 22:45:44] <galvesribeiro> Anyway
[2016-12-29 22:46:05] <galvesribeiro> Will try this docker api workaround and see what I can found
[2016-12-29 22:46:35] <galvesribeiro> Maybe I can create a Orleans MEmbership provider who talks to docker api and query for the containers running orleans
[2016-12-29 22:46:41] <galvesribeiro> Will see 
[2016-12-29 22:52:19] <dragon788> w00t w00t
[2016-12-30 03:58:54] <josephgardner> I\'m trying to run a docker image on a windows server VM, and the service crashes when trying to pull the image "unexpected EOF" If I try to restart the docker service, I get a 1067 error
[2016-12-30 03:59:06] <josephgardner> Is there an issue related to this, or am I doing something wrong?
[2016-12-30 10:34:22] <obernardovieira> I think, I have something important to say.It's the second time that this happens with me. I install docker on Linux Mint and after some hours the disk is full. Dont know why this happens, but I found out one thing, that also happens these two times. I lost all my system backups (I use timeshift). I dont know if it's some kind of conflit, but I think I have to report this, because it's a shame. The last time I had to reinstall my system, because I couldnt even start the system. This time, when I realise I had just 6GB left, I deleted some stuff here to have at least 20GB free, then disconnect from internet, restart, delete all docker images (Yes, I installed yesterday and I downloaded 4 images) then uninstall docker, and the magic happens. 100GB free right now ... Someone tells me. How this is even possibel that docker uses 100GB ? I was watching the free space decreasing. C'mon. Fix that. Until there, I will be using docker on a virtual machine, because I cant trust this software anymore.
[2016-12-30 12:03:14] <Forecaster> "Fix that."
[2016-12-30 12:03:18] <Forecaster> great feedback
[2016-12-30 13:13:34] <kkarolis> Hey, is it normal behaviour that memory footprint of processes running in docker container are not visible on the host? I.e. when I run 10 containers where each consumes 400MiB of space(reported by docker stats), host machines /proc/meminfo:MemoryAvailable stays mostly the same.
[2016-12-30 21:01:13] <dragon788> are they the same container? the kernel is pretty smart about shared vs isolated memory and if it is the same basic runspace it could be the majority of that is being reused between the containers unless you launched with some special cgroup magic to force isolation
[2016-12-30 21:02:10] <dragon788> obernardovieira: it sounds like you performed adocker pull somehugerepositoryinstead of adocker pull somehugerepository:specifictagand ended up filling your disk
[2016-12-30 21:02:58] <dragon788> josephgardner: Windows Server 2016 VM on Hyper-V or something else?
[2016-12-30 22:14:57] <obernardovieira> dragon788: doenst make any sense, because after I restart my computer, the disk free space keeps decreasing
[2016-12-30 22:16:56] <dragon788> if you look at the disk space being used, what directory is the most full? you can use the Disk Usage Analyzer tool if that is installed
[2016-12-30 22:18:41] <matrixbot> @quaddo:matrix.orgI've got a laptop with Mint installed, I could try to repro this...?
[2016-12-30 22:20:06] <matrixbot> @quaddo:matrix.org fires up the Thermal Beast of Doom
[2016-12-30 22:25:47] <matrixbot> @quaddo:matrix.orgMint 17 fwiw - this laptop doesn't see much action, long overdue for an update
[2016-12-30 22:28:47] <matrixbot> @quaddo:matrix.orgran df -h, installed docker, ran df -h again, not seeing any noticeable change
[2016-12-30 22:29:49] <matrixbot> @quaddo:matrix.orgBernardo Vieira (Gitter): after you installed docker, did you do any docker pulls?
[2016-12-30 22:30:00] <matrixbot> @quaddo:matrix.org(I'm assuming you did; I'm fishing to find out what exactly)
[2016-12-30 22:32:52] <matrixbot> @quaddo:matrix.orghm
[2016-12-30 22:32:56] <matrixbot> @quaddo:matrix.orgI'll use this quiet time to upgrade, then
[2016-12-31 03:44:37] <josephgardner> dragon788: I created issue # [<-ISSUE->] 
[2016-12-31 14:49:14] <dragon788> Did you pass through the CPU VT-x capabilities in parallels?
[2017-01-01 19:12:28] <ixiadev1_twitter> I cannot start liquibase from myApp to migrate with mysql database via Rancher. I have built images for mysql & myApp. The mysql container is already started, after that I start myApp container but it failed at liquibase. Any help?
[2017-01-01 21:34:08] <mmisztal1980> can docker-machine be scripted? I'd like to have a script to setup my env
[2017-01-01 21:34:16] <mmisztal1980> right now I'm having little luck with it
[2017-01-01 21:38:42] <SISheogorath> you can write a shell script which uses docker-machine
[2017-01-01 21:46:10] <mmisztal1980> any examples on how can I start containers in docker engines provisioned by the docker-machine?
[2017-01-01 23:08:41] <mmisztal1980> I've run into problems trying to pull a container image  using a machine created viadocker-machine create -d=hyperv <NAME>.
[2017-01-01 23:09:00] <mmisztal1980> docker run -d -p 8500:8500 progrium/consul:latestUnable to find image 'progrium/consul:latest' locallyPulling repository docker.io/progrium/consuldocker: Error while pulling image: Get https://index.docker.io/v1/repositories/progrium/consul/images: dial tcp: lookup index.docker.io on [::1]:53: read udp [::1]:58176->[::1]:53: read: connection refused.
[2017-01-01 23:09:26] <mmisztal1980> Can anyone advise? getting the same result when trying to execute the same command in the VM's (boot2docker) console window
[2017-01-01 23:11:38] <matrixbot> @quaddo:matrix.orgLooks to be a local DNS lookup failure.
[2017-01-01 23:17:37] <matrixbot> @quaddo:matrix.orgMore precisely, there doesn't seem to be any listener at ::1
[2017-01-02 09:03:49] <msqaddura> hello all, I have a problem with my docker for windows client whenever if i do something like this  volumes: [<-CODE->] i get the following error:ERROR: for platform Conot create container for service platform: Invalid bind mount spec "D:\\myFile\\blabla:/myTarget" Invalid volume specification \'D:\\myFile\\blabla:/myTarget\'
[2017-01-02 09:04:22] <msqaddura> have anyone struggled wit this one?
[2017-01-02 19:02:19] <imaia> Folks, I'm having a problem where my django container exits with status 0 if I provide a entrypoint
[2017-01-02 19:03:51] <imaia> Runs nicely without entrypoint; even if the entrypoint is empty
[2017-01-02 19:05:05] <imaia> suggestions?
[2017-01-02 22:42:41] <mmisztal1980> anyone?
[2017-01-02 22:43:36] <matrixbot> @quaddo:matrix.orgMaciek Misztal (Gitter): you mean, regarding the error you posted yesterday?
[2017-01-02 22:43:58] <mmisztal1980> yes
[2017-01-02 22:44:21] <matrixbot> @quaddo:matrix.orghere's what I wrote yesterday:
[2017-01-02 22:44:23] <matrixbot>  [<-CODE->] More precisely, there doesn't seem to be any listener at ::1
[2017-01-02 22:45:07] <mmisztal1980> ahhhh - I didn't realize you were responding to me :) any hints how can I remedy that? I'm trying to create a docker-machine script to have a infrastructure as code environment
[2017-01-02 22:45:34] <mmisztal1980> is there something I need to add atdocker-machine createstage?
[2017-01-02 22:46:36] <matrixbot> @quaddo:matrix.orgI could be mistaken, but this might be a question regarding where you're running docker-machine from, ie, what does /etc/resolv.conf look like (for starters)?
[2017-01-02 22:48:53] <mmisztal1980> it appears that the file is present at/etc/resolv.confbut it's empty
[2017-01-02 22:49:23] <matrixbot> @quaddo:matrix.organd no local DNS server (eg, BIND) running...?
[2017-01-02 22:49:29] <mmisztal1980> I'm using docker for windows, so basically it starts aboot2dockerinstance in hyper-v
[2017-01-02 22:49:33] <mmisztal1980> nope
[2017-01-02 22:49:46] <matrixbot> @quaddo:matrix.orgless familiar with that, but we should be able to make do
[2017-01-02 22:50:19] <matrixbot> @quaddo:matrix.orgedit /etc/resolv.conf and add the following lines:
[2017-01-02 22:50:24] <matrixbot> @quaddo:matrix.orgnameserver 8.8.8.8
[2017-01-02 22:50:34] <matrixbot> @quaddo:matrix.orgnameserver 8.8.4.4
[2017-01-02 22:50:56] <matrixbot> @quaddo:matrix.orgthen try something as rudimentary as this command after you've saved and exited the editor:
[2017-01-02 22:51:14] <matrixbot> @quaddo:matrix.orgdig +short google.com
[2017-01-02 22:51:27] <matrixbot> @quaddo:matrix.org(this assumes dig is installed, which it may not be)
[2017-01-02 22:52:36] <mmisztal1980> it appears dig is not installed
[2017-01-02 22:52:54] <matrixbot> @quaddo:matrix.orgtry this then:
[2017-01-02 22:53:46] <matrixbot> @quaddo:matrix.orgargh, scratch that - seems like ICMP is being blocked
[2017-01-02 22:54:03] <matrixbot> @quaddo:matrix.orgwas gonna have you try index.docker.io
[2017-01-02 22:54:18] <matrixbot> @quaddo:matrix.orgtry this:
[2017-01-02 22:54:27] <matrixbot> @quaddo:matrix.orgping [<-LINK->] 
[2017-01-02 22:54:46] <mmisztal1980> I got a 'bad address' wth...
[2017-01-02 22:56:25] <matrixbot> @quaddo:matrix.orgwhat about: ping 8.8.8.8
[2017-01-02 22:56:48] <mmisztal1980> network is unreachable
[2017-01-02 22:56:56] <matrixbot> @quaddo:matrix.org...
[2017-01-02 22:57:03] <mmisztal1980> same error message when I tried runningalpine:latest
[2017-01-02 22:58:24] <mmisztal1980> I'm examining the docker for windows settings, apparently there's a proxy section that's used for pulling images. mine is not configured. reading up on it
[2017-01-02 22:58:36] <matrixbot> @quaddo:matrix.orgaha
[2017-01-02 22:59:01] <matrixbot> @quaddo:matrix.orgyeah there's definitely something hinkey going on with your network
[2017-01-02 23:00:06] <mmisztal1980> amazingly it works ok if I only use the default MobyLinuxVM, but when I start using docker-machine it quickly goes to hell
[2017-01-02 23:00:57] <mmisztal1980> (docker-machine creates boot2docker vms)
[2017-01-02 23:01:10] <mmisztal1980> and both VM types appear to be using the same network setup in hyper-v
[2017-01-02 23:01:19] <mmisztal1980> which is the DockerNAT switch
[2017-01-02 23:01:55] <matrixbot> @quaddo:matrix.orghmm
[2017-01-02 23:03:07] <matrixbot> @quaddo:matrix.orglooking at this: [<-LINK->] 
[2017-01-02 23:03:21] <matrixbot> @quaddo:matrix.orgdid you already rundocker-machine create --driver hyperv vm
[2017-01-02 23:03:37] <mmisztal1980> hmmm
[2017-01-02 23:03:53] <mmisztal1980>  [<-LINK->] 
[2017-01-02 23:04:11] <mmisztal1980> it appears that the DockerNAT is only for the MobyLinuxVM
[2017-01-02 23:04:27] <mmisztal1980> yes I did run it with -d=hyperv
[2017-01-02 23:04:39] <mmisztal1980> apparently I need to configure an extra v-switch
[2017-01-02 23:07:16] <mmisztal1980> here goes...
[2017-01-02 23:07:27] <matrixbot> @quaddo:matrix.orgheh
[2017-01-02 23:09:13] <mmisztal1980> network unreachable
[2017-01-02 23:09:35] <matrixbot> @quaddo:matrix.orgfun
[2017-01-02 23:09:49] <mmisztal1980> even better - eth0 doesn't have an ipv4 address
[2017-01-02 23:10:23] <matrixbot> @quaddo:matrix.orgdoesn't entirely surprise me, based on the error you posted yesterday
[2017-01-02 23:10:38] <mmisztal1980> right
[2017-01-02 23:11:21] <mmisztal1980> I'm guessing that the MS and Docker folks, don't want my life to be boring...
[2017-01-02 23:11:30] <matrixbot> @quaddo:matrix.org:)
[2017-01-02 23:11:46] <matrixbot> @quaddo:matrix.orgthis sounds mostly to be a hyper-v issue
[2017-01-02 23:11:57] <matrixbot> @quaddo:matrix.orgit might get sorted if we could get it running ipv4
[2017-01-02 23:12:49] <mmisztal1980> aye
[2017-01-02 23:12:51] <mmisztal1980> seems like it
[2017-01-02 23:13:28] <matrixbot> @quaddo:matrix.org [<-LINK->] 
[2017-01-02 23:13:29] <matrixbot> @quaddo:matrix.orga bit dated, but still
[2017-01-02 23:15:12] <mmisztal1980> not sure if this applies to my case
[2017-01-02 23:15:25] <mmisztal1980> looks like it's related to a physical NIC settings
[2017-01-02 23:15:34] <mmisztal1980> not entirely the same thing in hyper-v
[2017-01-02 23:15:58] <matrixbot> @quaddo:matrix.orgcheck requirements? [<-LINK->] 
[2017-01-02 23:16:30] <mmisztal1980> it's been enabled via Powershell, no worries here
[2017-01-02 23:17:34] <matrixbot> @quaddo:matrix.orgso long as you're not on Windows 10 Home
[2017-01-02 23:17:41] <matrixbot> @quaddo:matrix.orgthat's what caught my eye
[2017-01-02 23:18:04] <mmisztal1980> Windows 10 Enterprise here
[2017-01-02 23:18:12] <matrixbot> @quaddo:matrix.orgk
[2017-01-02 23:18:18] <mmisztal1980> I don't think I'd be able to use hyper-v on home
[2017-01-02 23:19:15] <matrixbot> @quaddo:matrix.organd if you spin up a Linux VM otherwise, it's all good?
[2017-01-02 23:19:33] <mmisztal1980> a different distro?
[2017-01-02 23:19:44] <matrixbot> @quaddo:matrix.orgjust anything, really
[2017-01-02 23:19:49] <mmisztal1980> let me check...
[2017-01-02 23:21:56] <mmisztal1980> downloading an image, will ping back shortly
[2017-01-02 23:22:06] <matrixbot> @quaddo:matrix.orgaight
[2017-01-02 23:26:29] <matrixbot> @quaddo:matrix.orgdon't know if you've already seen this link [<-LINK->] 
[2017-01-02 23:37:59] <mmisztal1980> not yet, reading up while the OS installs
[2017-01-02 23:52:28] <mmisztal1980> I've run into issues with hyperv networking
[2017-01-02 23:52:35] <mmisztal1980> I give up for today, it's 1am over here
[2017-01-02 23:52:36] <mmisztal1980>  [<-LINK->] 
[2017-01-02 23:53:04] <mmisztal1980> external switch seems to fail and switching to an internal one managed to kill the wifi
[2017-01-02 23:53:07] <mmisztal1980> :D
[2017-01-02 23:53:19] <mmisztal1980> I'm off to bed, I'll give it a shot tomorrow
[2017-01-02 23:53:48] <matrixbot> @quaddo:matrix.orgOne of the links I found touched on the wifi issue
[2017-01-03 02:20:59] <siassaj> I want my docker image builds to be faster
[2017-01-03 02:21:07] <siassaj> what are some good strategies?
[2017-01-03 14:25:07] <SISheogorath> @siassaj keep it small, add multithreaded/processed builds (like using make with -j)depending on your usecase add more layers.For dev images check for example the node:*-onbuild images which are really nice with their dep caching.For production images you should keep the number of layers as small as possible.
[2017-01-03 21:48:29] <ankitarya10> I have been searching through the documentation but I haven't been able to figure out how to connect to an existing aws instance. I know docker-machine create -d  can be used to create an instance but that is not the use case I have. Also, is there a way to give identification file with docker-machine ssh cmd ?
[2017-01-03 21:49:07] <ankitarya10> Thanks for your time !
[2017-01-03 22:00:37] <killerspaz> docker-machine lsgive you any info?
[2017-01-03 22:30:49] <ankitarya10> docker-machine lsNAME   ACTIVE   DRIVER   STATE   URL   SWARM   DOCKER   ERRORS
[2017-01-03 22:31:00] <ankitarya10> its not connected to anything yet
[2017-01-04 06:58:19] <vamsiporala> I have a centos 7 minimal server as docker host. I started a ubuntu xrdp enabled xfce desktop docker container in which firefox is installed. Now  I need to start the firefox inside the container through command line from docker host. But it is failing due to below error. Appreciate any help on this issue.
[2017-01-04 06:58:22] <vamsiporala> [root@nitro-hadooprdp-gucamole]# docker exec RDP-TEST bash -c "firefox [<-LINK->] "Error: GDK_BACKEND does not match available displays
[2017-01-04 09:22:18] <kylegordon_twitter> siassaj: docker build should use a cache whereever possible
[2017-01-04 09:22:34] <kylegordon_twitter> where are you hitting a delay?
[2017-01-04 09:22:42] <siassaj> kylegordon_twitter: well it's very odd
[2017-01-04 09:22:46] <siassaj> I'm not sure if it's expected
[2017-01-04 09:23:01] <siassaj> but each instruction takes minimum 4 seconds unless I hit a cache
[2017-01-04 09:23:01] <kylegordon_twitter> that's a phrase I've seen around Docker a lot :-)
[2017-01-04 09:23:09] <kylegordon_twitter> odd
[2017-01-04 09:23:12] <kylegordon_twitter> DNS timeout?
[2017-01-04 09:23:45] <siassaj> ARG RAILS_ENV
[2017-01-04 09:23:49] <siassaj> that instruction takes 4 seconds
[2017-01-04 09:24:25] <kylegordon_twitter> same for other ARGs?
[2017-01-04 09:24:29] <siassaj> yes
[2017-01-04 09:25:10] <kylegordon_twitter> weird
[2017-01-04 09:25:24] <siassaj> I also have 2 instructions, one updates my ruby gems, and one updates my node packages. No matter how i go about this, at some point one of those cache layers will be invalidated for no reason because the other changes
[2017-01-04 09:25:35] <siassaj> kylegordon_twitter: on 2 different machines too
[2017-01-04 09:29:04] <siassaj> the Dockerfile is a naively simple tool
[2017-01-04 09:29:35] <siassaj> would have been much more powerful if they had given us a ruby DSL to build out dockerfile descriptions, that way we could have implemented caching as we pleased
[2017-01-04 09:29:45] <siassaj> bbl
[2017-01-04 09:31:25] <kylegordon_twitter> hmm, wish I could help, but I'm equally as stuck
[2017-01-04 16:01:26] <Husamuddin> hello thereI have a problem to stop/kill containers on dockerit says: [<-CODE->] I'm on ubuntu 16.04here is my kernel version: 4.4.0-57-genericand docker version:Client: Version:      1.12.5 API version:  1.24 Go version:   go1.6.4 Git commit:   7392c3b Built:        Fri Dec 16 02:42:17 2016 OS/Arch:      linux/amd64Server:  Version:      1.12.5  API version:  1.24  Go version:   go1.6.4  Git commit:   7392c3b  Built:        Fri Dec 16 02:42:17 2016  OS/Arch:      linux/amd64and docker info:Containers: 1 Running: 1 Paused: 0 Stopped: 0 Images: 11 Server Version: 1.12.5 Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 16 Dirperm1 Supported: true Logging Driver: json-file Cgroup Driver: cgroupfsPlugins:Volume: local Network: bridge null overlay host Swarm: inactive Runtimes: runc Default Runtime: runc Security Options: apparmor seccomp Kernel Version: 4.4.0-57-generic Operating System: Ubuntu 16.04.1 LTS OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 7.683 GiB Name: husamuddin-Aspire-E1-572G ID: RLPM:FCJP:LJQV:5OZZ:P7QS:NA4M:QET7:LTMX:NWTZ:EUOI:NLOR:FZPK Docker Root Dir: /var/lib/docker Debug Mode (client): false Debug Mode (server): false Username: husamuddin Registry: https://index.docker.io/v1/ WARNING: No swap limit support Insecure Registries:  127.0.0.0/8
[2017-01-04 16:03:27] <Husamuddin> any ideas!
[2017-01-04 16:14:42] <matrixbot> @quaddo:matrix.orgdid you originally start the container from root, and are now trying to stop it as a regular user?
[2017-01-04 17:00:21] <dragon788> siassaj: you simply combine your two commands into one "call" and this would create a single layer with all the changes from both, IIRC you can also while building a container run a couple commands from the command line and then "commit" afterwards in order to control when the layer actually gets saved
[2017-01-04 17:48:25] <galvesribeiro> hey guys
[2017-01-04 17:48:53] <galvesribeiro> does anyone ever used Docker.DotNet to talk to docker daemon? I have a question regarding label filtering and appreciate any help on that
[2017-01-04 18:32:02] <mmisztal1980> matrixbot: I've managed to resolve the network issues we've been investigating 2 days ago. the boot2docker vm now has NW connectivity and is getting an ip v4 address, however the docker service is listening on:::2376and is thus unreachable from the outside ... what the heck?
[2017-01-04 18:33:17] <matrixbot> @quaddo:matrix.orgthat's an ipv6 socket
[2017-01-04 18:33:33] <matrixbot> @quaddo:matrix.orgwould need to get it so that it listens on ipv4
[2017-01-04 18:36:13] <matrixbot> @quaddo:matrix.orgactually, that may not even be an issue, as it should be implicit
[2017-01-04 18:37:21] <matrixbot> @quaddo:matrix.orgassumingtelnetis installed on the VM, can you connect usingtelnet localhost 2376?
[2017-01-04 18:40:17] <mmisztal1980> let me check that
[2017-01-04 18:40:41] <mmisztal1980> let me check that
[2017-01-04 18:41:43] <mmisztal1980> connection was successful
[2017-01-04 18:43:37] <madpipeline> hello world
[2017-01-04 18:44:59] <madpipeline> I know I'm doing something stupid, but I don't know how else to do it. I need advice.
[2017-01-04 18:45:03] <madpipeline> I'm working on making a docker image for production for Pootle here: [<-LINK->] 
[2017-01-04 18:45:18] <madpipeline> And I'm not sure what to do about the development packages, that are needed to build the image, but not needed to run the service
[2017-01-04 18:45:18] <matjazmav> Hey anyone using microsoft/mssql-server-Linux image?
[2017-01-04 18:46:07] <matrixbot> @quaddo:matrix.orgbut no joy connecting to that socket from outside the VM?
[2017-01-04 18:48:28] <mmisztal1980> yep
[2017-01-04 18:48:44] <mmisztal1980> curiously I can ping it though
[2017-01-04 18:48:51] <mmisztal1980> PS D:\\Checkout\\PoC.Docker> test-netconnection 192.168.8.101 -port 2376WARNING: TCP connect to 192.168.8.101:2376 failedComputerName           : 192.168.8.101RemoteAddress          : 192.168.8.101RemotePort             : 2376InterfaceAlias         : vEthernet (DockerExternal)SourceAddress          : 192.168.8.101PingSucceeded          : TruePingReplyDetails (RTT) : 0 msTcpTestSucceeded       : False
[2017-01-04 18:49:17] <mmisztal1980> I can connect from the inside, but not from the outside
[2017-01-04 18:49:17] <mmisztal1980> boot2docker doesn't have a firewall - does it?
[2017-01-04 18:49:39] <matrixbot> @quaddo:matrix.orgit shouldn't, that would aggravate a lot of folks out of the gate :)
[2017-01-04 18:49:43] <mmisztal1980> boot2docker doesn't have a firewall - does it?
[2017-01-04 18:50:08] <matrixbot> @quaddo:matrix.orgbut is there a Windows firewall at play, here?
[2017-01-04 18:50:09] <dragon788> it shouldn't have a firewall, but you are essentially going through 2 layers of networking
[2017-01-04 18:51:36] <dragon788> ovidiub13: typically I\'ve seen places maintain two images, one for building and one for running, they could both inherit from the same base image and your build script could build the "build" and then use that to create the "run"
[2017-01-04 18:52:27] <mmisztal1980> I don't believe so, but I'll double check
[2017-01-04 18:53:07] <madpipeline> dragon788: that is the plan, but I'm not sure if we can do the inheritance thing, sice the devel image will be very much different
[2017-01-04 18:53:11] <mmisztal1980> no change after disabling the windows firewall
[2017-01-04 18:54:02] <dragon788> oh yeah, you would have  base => devel and base => runtime, you wouldn't want to go base => devel => runtime, that would bloat the image too much
[2017-01-04 18:59:36] <madpipeline> And how would I make that base image?
[2017-01-04 19:00:05] <madpipeline> the problem I'm having is with the devel packages that I need to install, and then remove in the runtime image
[2017-01-04 19:00:22] <madpipeline> but those packages come with some dependencies
[2017-01-04 19:00:31] <dragon788> are you building a Windows NanoServer image or something on an ubuntu/CentOS base?
[2017-01-04 19:00:34] <madpipeline> and I'm not sure on what's the best way to keep track of those
[2017-01-04 19:01:01] <madpipeline> I'm basing off the python image.. so eventualy it's debian
[2017-01-04 19:06:58] <dragon788> so the runtime image uses a package that you are compiling in the devel image or it requires an environment similar to the devel image minus a few devel packages?
[2017-01-04 19:25:21] <madpipeline> I need gcc to compile some python modules
[2017-01-04 19:25:43] <madpipeline> and I don't need gcc in the runtime image
[2017-01-04 19:25:46] <madpipeline> for example
[2017-01-04 19:25:50] <madpipeline> gcc is not the only one
[2017-01-04 20:50:33] <galvesribeiro> guys, the container id by default is always be set as hostname, right?
[2017-01-04 21:22:52] <matrixbot> @quaddo:matrix.orgfrom what I'm seeing, the container id is always a uniquely generated hexadecimal number
[2017-01-04 23:24:24] <dragon788> the container ID is a random GUID, you can pass the--name somenameto adocker runcommand to give it a name you can reference, but it needs to be unique
[2017-01-04 23:24:41] <dragon788> galvesribeiro: ^^
[2017-01-04 23:25:16] <galvesribeiro> hey
[2017-01-04 23:25:20] <galvesribeiro> hum...
[2017-01-04 23:25:29] <galvesribeiro> the point is not the container name actually
[2017-01-04 23:25:40] <galvesribeiro> I'm trying to get the hostname itself
[2017-01-04 23:25:57] <matrixbot> @quaddo:matrix.orgah
[2017-01-04 23:26:18] <matrixbot> @quaddo:matrix.orghostname is the same as the container id
[2017-01-04 23:26:32] <galvesribeiro> unless you specify the --name
[2017-01-04 23:26:33] <matrixbot> @quaddo:matrix.orgwhy would you need to change that?
[2017-01-04 23:26:38] <dragon788> the hostname from outside of the container or inside?
[2017-01-04 23:26:40] <galvesribeiro> I don't need to change
[2017-01-04 23:26:44] <danieldram> when I use docker cp it copies to local machine not my aws  EC2 is this normal?
[2017-01-04 23:29:45] <matrixbot> @quaddo:matrix.orgGutemberg Ribeiro (Gitter): sorry, must have misunderstood where you were going with that.
[2017-01-04 23:30:33] <matrixbot> @quaddo:matrix.orgDaniel Ram (Gitter): seems normal to me. What do you see when you rundocker cp --help?
[2017-01-04 23:34:50] <danieldram> somebody messed up my docker-compose file and now I need to copy the db exports from the container to the host to preserve them :(
[2017-01-04 23:35:45] <matrixbot> @quaddo:matrix.orgcan you login to the instance and rundocker cpthere?
[2017-01-04 23:36:04] <danieldram> hmm good idea!
[2017-01-04 23:36:05] <galvesribeiro> matrixbot: no problem
[2017-01-04 23:38:34] <danieldram> hmm once I ssh into the docker-machine it won't have reference to the docker containers?
[2017-01-04 23:39:11] <matrixbot> @quaddo:matrix.orgcan't say I've tried it
[2017-01-04 23:39:15] <matrixbot> @quaddo:matrix.orgso, try it :)
[2017-01-04 23:39:25] <matrixbot> @quaddo:matrix.orgyou might need to become root
[2017-01-04 23:41:56] <danieldram> I can ssh into the docker-machine but when I set the env it doesn't exist
[2017-01-04 23:43:04] <matrixbot> @quaddo:matrix.orggetting in over my head on this one
[2017-01-04 23:43:24] <matrixbot> @quaddo:matrix.orgat a fundamental level, why are you not fond of copying to your local filesystem?
[2017-01-04 23:43:38] <danieldram> files are large.
[2017-01-04 23:43:57] <danieldram> I would have to upload them to the EC2 afterwards and mongo upsert them
[2017-01-04 23:44:05] <matrixbot> @quaddo:matrix.orgthought that might be the reason
[2017-01-04 23:44:19] <matrixbot> @quaddo:matrix.orglet me ponder this a sec
[2017-01-04 23:44:32] <danieldram> when I do docker exec -it on the contianer, I can see the files
[2017-01-04 23:44:42] <danieldram> but I can't move them from there
[2017-01-04 23:45:02] <danieldram> when I do docker-machine ssh EC2, I can't locate the container to pull the files
[2017-01-04 23:48:49] <danieldram> Like there should be a way to move the files from a container on the computer that hosts the container right?
[2017-01-05 00:06:09] <danieldram> I guess there's no way arund it
[2017-01-05 00:06:35] <danieldram> I'll just cp the big ass files and reupload them to the same instance, so odd we can't do this.
[2017-01-05 00:11:49] <matrixbot> @quaddo:matrix.orgwait, you said you can rundocker exec -iton the container, and you can indeed see the files you want?
[2017-01-05 02:30:39] <galvesribeiro> hey guys
[2017-01-05 02:31:06] <galvesribeiro>  [<-CODE->] 
[2017-01-05 02:31:33] <galvesribeiro> that happen when I'm trying to set a label in a running container... it is not possible? :(
[2017-01-05 02:35:51] <galvesribeiro>  [<-ISSUE->] 
[2017-01-05 02:36:08] <galvesribeiro> that was merged, so I wonder if it reached the beta channels
[2017-01-05 03:42:32] <galvesribeiro> ok, passed that...
[2017-01-05 03:46:25] <galvesribeiro> so... is there a way to make a label or a env to have its value generated (i.e. a random number) while the container is starting?
[2017-01-05 05:16:51] <danieldram> matrixbot: yea I can get the files there, but if I try to mv them to a root folder, it won't do it.
[2017-01-05 05:17:05] <danieldram> matrixbot: even as super user
[2017-01-05 11:30:42] <ioan-cristea> Hi. I want to know if I can run multiple websites on a server, served by multiple containers.
[2017-01-05 11:31:47] <Bajix> KRIOFT: Yes; use something like ELB to do the port mappings then run containers on separate ports
[2017-01-05 11:32:41] <ioan-cristea> I understand, I will try. Thanks!
[2017-01-05 13:43:15] <galvesribeiro> hey guys, how can my container access the host machine? I mean, which of the IPs the containers should hit to get to the host?
[2017-01-05 14:05:10] <SISheogorath> galvesribeiro: Use the hostname of your machine. That's the easiest way
[2017-01-05 14:30:07] <galvesribeiro> SISheogorath: it doesn't work :(
[2017-01-05 14:31:49] <am0nshi> galvesribeiro: for what purposes you nedd host machine?
[2017-01-05 14:32:27] <galvesribeiro> the container need to query the Docker Remote API of the host to check some stuff
[2017-01-05 14:32:54] <am0nshi> galvesribeiro: you can mount host docker.sock into your machine
[2017-01-05 14:33:03] <am0nshi> and write http requests into it
[2017-01-05 14:33:10] <galvesribeiro> there is no docker.sock in windows :(
[2017-01-05 14:46:34] <am0nshi> use unix 8)
[2017-01-05 14:57:02] <galvesribeiro> I cant hehehe
[2017-01-05 15:14:31] <damilare> Question, anyone has a strategy to make Docker Builds faster, I don’t have to re-install my libraries and dependencies all the time I make tiny changes to my source code
[2017-01-05 15:15:03] <am0nshi> damilare: MOUNT?
[2017-01-05 15:15:37] <am0nshi> and then will be no need to use builds at all, build is environment only for dev
[2017-01-05 15:23:37] <damilare> MOUNT?
[2017-01-05 15:23:58] <damilare> how do you mean, and dev env is actaullly my main concerned
[2017-01-05 15:24:44] <am0nshi> damilare: $ docker run -d -P \\--volume-driver=flocker \\-v my-named-volume:/webapp \\ <- this line--name web training/webapp python app.py
[2017-01-05 15:24:50] <am0nshi>  [<-LINK->] 
[2017-01-05 15:26:01] <damilare> hmmm
[2017-01-05 15:26:02] <damilare> thanks
[2017-01-05 15:27:31] <galvesribeiro> there must be a way to a container to talk to a docker host :(
[2017-01-05 15:27:45] <damilare> this way, I dont have to build images when I make changes to my source code then
[2017-01-05 15:27:48] <damilare> makes sense thanks
[2017-01-05 15:28:26] <am0nshi> galvesribeiro:  [<-LINK->] and dont use windows ^^
[2017-01-05 15:28:35] <am0nshi> damilare: +
[2017-01-05 15:28:53] <galvesribeiro> am0nshi: that is what I'm using
[2017-01-05 15:29:08] <galvesribeiro> don't use windows is not an option
[2017-01-05 15:29:58] <am0nshi> galvesribeiro: its called lxc containers (linux containers), in windows you loose all features they provide :) and u make from docker vagrant :)
[2017-01-05 15:30:21] <galvesribeiro> not anymore
[2017-01-05 15:30:31] <galvesribeiro> its is not lxc cotnainers-only anymore
[2017-01-05 16:29:24] <SISheogorath> @damilare Check some onbuild images. Like https://github.com/nodejs/docker-node/blob/master/7.4/onbuild/DockerfileThey are made to preinstall dependencies.
[2017-01-05 16:32:50] <damilare> thanks@SISheogorath
[2017-01-05 16:34:19] <SISheogorath> but it's not recommended to use the onbuildimages for production
[2017-01-05 17:04:52] <chaitanyapochampally> all: has anyone tried using docker build and publish plugin in Jenknis? Is that working fine.
[2017-01-05 17:31:52] <SISheogorath> chaitanyapochampally: I know there are people using Jenkins with plugins. They are mostly hanging around in #ci-cd inside the Slack community. So may consider to join community.docker.com
[2017-01-05 18:40:52] <chaitanyapochampally> SISheogorath: thanks
[2017-01-06 02:50:37] <galvesribeiro> now docker is trying to piss me off
[2017-01-06 02:50:39] <galvesribeiro>  [<-CODE->] 
[2017-01-06 02:50:51] <galvesribeiro> this throw when calling anydocker run
[2017-01-06 03:05:49] <galvesribeiro>  [<-LINK->] 
[2017-01-06 06:17:09] <nischay30> can anybody tell me what is the difference between docker stack deploy and docker deploy?
[2017-01-06 08:52:59] <milanvdmria> I assume the docker host has a volume to which I have to write the outcomes of a python script inside a docker container. This host volume has to be mounted on the docker container which runs the python script. But how can I get this path of this mounted host volume and put it as a ENV in the docker container? (so that the python script knows where to write its data to)
[2017-01-06 10:59:11] <nischay30> Define Your Volume likevolumes:$Home/data:/dataand in environment Variables:ENIVRONMENT_VARIABLE_NAME: '/data'
[2017-01-06 16:24:16] <iDVB> Anyone know of a good example code/repo for Docker(dev+prod)+Node App(requiring build) ?
[2017-01-06 16:25:26] <killerspaz> Unfortunately I had not seen a complete/good sample, and I'm not capable of open-sourcing mine atm, but if you need help feel free to ask... I will say this, check outdocker-composethe second you understand how to make a Dockerfile, and deep dive into networking and volumes, and you should get up to speed pretty quick
[2017-01-06 16:26:17] <killerspaz> at least nothing that suited my needs and/or standards.... I took a TDD approach for development locally, and integration tests for containerized development
[2017-01-06 16:28:34] <iDVB> Thanks@killerspazI have a working compose and docker files for my stack.(Node+ReactJS+HotReload+Postgres+Nginx) but its local dev only. Just really struggling to make the leap to TINY docker images, ready for prod.  Would you even be able to share your compose/dockerfile? usually not too much propriety in there, no?
[2017-01-06 16:29:47] <iDVB> The next big question is what to go with for private/hosted CI/CD and cloud host (noOps). So far, the best looks like Codeship+Cloud66
[2017-01-06 16:31:12] <iDVB> Our infra is small, we def want AWS cloud (political reasons) but don't really want to manage the infra for security updates, patches, for OS and docker, hence Cloud66.
[2017-01-06 16:32:46] <killerspaz> iDVB: for small images, check outalpine linux... super small base image of like 50mb
[2017-01-06 16:33:16] <killerspaz> as for repos, we private host internal to our network as our deployments are by the thousands internally deployed to individual machines
[2017-01-06 16:34:33] <iDVB> but what are people using for dev vs prod workflows?   Eg. compose for prod seems non-existant. Codeship ignores compose and uses  its own services/steps.yml ..... same for Cloud66 which uses services/manifest.yml
[2017-01-06 16:34:34] <killerspaz> but depending on your existing SAAS options (i.e., if you use github or bitbucket, etc etc) there are various approaches like pipelines, or even jenkins if you're so inclined
[2017-01-06 16:34:46] <killerspaz> yeah that's typical
[2017-01-06 16:35:30] <iDVB> I've spend a few days google around to see what people are using for the full workflow. We'd ideally like to use docker in DEV and Prod
[2017-01-06 16:36:17] <killerspaz> so you havedocker-compose.yml, which should be the bare minimum to get an image to at least build... thendocker-compose.override.ymlthat docker-compose will automatically read, so adocker-compose upwill merge those two files natively.... in this file you can expose ports to your host for testing, set ENV vars liekNODE_ENV=developmentthen you'll typically have a separate compose file for prod, which I namedocker-compose.prod.yml, and execute asdocker-compose -f docker-compose.yml -f docker-compose.prod.yml
[2017-01-06 16:36:49] <iDVB> I've also heard quite a few opinions that docker+DBs are not ready for prod .... hence Cloud66 is using native boxes and not containers for DB and loadbalancer. For me... that looks like a very fragmented workflow.
[2017-01-06 16:38:15] <iDVB> killerspaz: Yup, completely understand your last..... but who actually uses that IN prod? what do the commands before and afterdocker-compose -f docker-compose.yml -f docker-compose.prod.ymllook like?
[2017-01-06 16:39:04] <iDVB> maybe the answer is so simple I'm missing it?
[2017-01-06 16:40:14] <iDVB> how do I get the output of that command into a production enviroment.... and if my DEV compose uses a container for DB.... then what  should PROD use. (considering alot of people seem to think docker+db+prod === bad)
[2017-01-06 16:40:49] <killerspaz> iDVB: i PM'd you
[2017-01-06 16:42:32] <andersonkyle> Is there anyway to force docker to store credentials in plaintext in the config file?  It is keeps using wincred and I don't want to use that...
[2017-01-06 16:43:10] <andersonkyle> I've logged out and logged back in to no avail.
[2017-01-06 16:43:42] <andersonkyle> I definitely remember my local machine storing them in the config file, but for some reason it now is only using wincred.   Any ideas?
[2017-01-06 16:45:40] <killerspaz> creds for a registry?
[2017-01-06 16:45:56] <killerspaz>  [<-LINK->] 
[2017-01-06 16:48:25] <andersonkyle> Yes
[2017-01-06 16:49:35] <andersonkyle> How can I force docker to use the config file to store the credentials instead of wincred on Windows?
[2017-01-06 16:51:19] <sc6l6d3v> Hi, am trying to debug a container that blows up starting my app and am down to looking at linux startup files that process various config files. Why would I be getting a permission denied when trying to copy the entire image from the root as follows:montreux:mlt-viz hkatz$ docker cp   d340eba864a1:/ ~/tmp/dockroot\nmkdir /Users/hkatz/tmp/dockroot/consul-template/config.d: permission denied?
[2017-01-06 16:51:47] <killerspaz> it says on that page how to define the credStore, please read the page I sent.
[2017-01-06 16:52:15] <andersonkyle> killerspaz: No it doesn't.
[2017-01-06 16:52:52] <killerspaz> so you don\'t see the 42pt font text that says "Credentials store" ???
[2017-01-06 16:53:03] <killerspaz> and the subheader entitled "Usage" ?
[2017-01-06 16:53:36] <andersonkyle> killerspaz: I guess you didn't read it cause it doesn't explain how to set the config to use plain text.
[2017-01-06 16:53:42] <andersonkyle> killerspaz: It only gives a single example of setting it to Mac OSX's credential manager.
[2017-01-06 16:54:32] <andersonkyle> killerspaz: If you see it there, what exactly is the setting for plain text?
[2017-01-06 16:55:18] <killerspaz> dude, if you can't read, that's on you... there's literally 3 bullet points in that section indicating your options
[2017-01-06 16:55:35] <killerspaz> This is the list of currently available credentials helpers and where you can download them from:
[2017-01-06 16:55:52] <andersonkyle> D-BUS, MacOS, Windows...
[2017-01-06 16:56:02] <killerspaz> READ THE WHOLE PAGE, I'm done talking to people that don't RTFM
[2017-01-06 16:56:22] <andersonkyle> killerspaz: Again, if it were there, you'd answer the question.  It aint', so you can't.
[2017-01-06 16:57:16] <killerspaz> dude, you either choose one of the 3, or use a config, just like it says on the page
[2017-01-06 16:57:26] <killerspaz> the end, done.... there's no more conversation happening between us at this point.
[2017-01-06 16:58:01] <SISheogorath> iDVB: may check hackmd, we build an awesome docker container there
[2017-01-06 16:58:52] <andersonkyle> Again, the question is docker is defaulting to wincred every time I perform docker login.  How, where and what setting is required to force it to save the credentials in plain text in the config file?  That is not explained on this page.  I've read it many times.
[2017-01-06 16:59:25] <killerspaz> You should find a new job
[2017-01-06 17:00:10] <andersonkyle> killerspaz: You obviously don't know the answer so why bother helping?
[2017-01-06 17:01:07] <andersonkyle> killerspaz: Is it really that hard to explicitly provide the information I'm requesting?  If you knew the answer you would I'm sure.  But it's clear you do not...
[2017-01-06 17:02:45] <killerspaz> i wish i could block you
[2017-01-06 17:02:48] <killerspaz> you're really dense
[2017-01-06 17:02:54] <killerspaz> right on the fucking page it says: [<-CODE->] 
[2017-01-06 17:03:15] <killerspaz> so put your credentials in there like the format it shows at the bottom of the page
[2017-01-06 17:03:21] <killerspaz> if you read the page fully, you wouldn't continue to ask
[2017-01-06 17:03:39] <killerspaz> don't put your ignorance on me pal
[2017-01-06 17:04:27] <andersonkyle> Again.  docker login is not storing them in config.json.  That's what I'm trying to fix.  I need the docker login command to store them in plain text in config.json....
[2017-01-06 17:04:59] <andersonkyle> Its using wincred for some reason and I'm trying to find out how I can disable that.
[2017-01-06 17:22:47] <aios> killerspaz: be simple and smart.
[2017-01-06 17:23:37] <aios> kanderson450: what kind of that problem - you can't login another PR instead hub.docker?
[2017-01-06 17:25:13] <andersonkyle> aios: I'm able to login to a private registry using :docker login private.registry.comBut the credentials aren't being saved in%USERPROFILE%/.docker/config.jsonInstead it is using an external credential store, in my case: wincred.
[2017-01-06 17:26:02] <aios> kanderson450: so you are logged in private registry?
[2017-01-06 17:26:06] <andersonkyle> aios: I'm trying to force docker to save the credentials in%USERPROFILE%/.docker/config.jsoninstead of the external credential store but I can't seem to find any information on how to do that.
[2017-01-06 17:26:38] <andersonkyle> aios: Yes.  Logging in and Logging out results in the same behavior.wincredis the credential store docker keeps using.
[2017-01-06 17:28:06] <aios> kanderson450:  [<-LINK->] 
[2017-01-06 17:28:37] <aios> look at here - you can try use [<-LINK->] - and look all you stored credentials
[2017-01-06 17:29:28] <andersonkyle> aios: Those are the external credential store options.  I don't want to use an external store, but instead want to save everything in plain-text withinconfig.json
[2017-01-06 17:30:11] <andersonkyle> And I know that my docker installation used to behave this way, but recently began usingwincredthe Windows Credential Manager external store.
[2017-01-06 17:30:35] <SISheogorath> that's the point. As docker only calls the credential manager. Store it plain into config.json is not avaiable
[2017-01-06 17:30:38] <andersonkyle> I'm trying to figure out how to disable that.
[2017-01-06 17:31:12] <SISheogorath> you can read it from config.json but not write right now
[2017-01-06 17:33:04] <andersonkyle> The config.json only saves the URL, and credstore: wincred   No matter if I remove that it keeps coming back
[2017-01-06 17:33:48] <andersonkyle> When it is working properly, config.json should save the URL, auth token and email address.
[2017-01-06 17:34:30] <andersonkyle> I can't seem to find any way of forcingdocker loginto use config.json instead of the external credential store.
[2017-01-06 17:37:11] <SISheogorath> O.o it works as designed: [<-LINK->] 
[2017-01-06 17:38:14] <SISheogorath> And as mentioned store it to the config.json is not an option right now
[2017-01-06 17:38:27] <SISheogorath> so no, it's not possible.
[2017-01-06 17:38:42] <SISheogorath> If you disagree with that open an issue
[2017-01-06 17:39:18] <andersonkyle> SISheogorath: Ok, so what you're saying is that they've disabled the plain-text option completely?
[2017-01-06 17:41:37] <SISheogorath> you can't save your credentials to config.json, right. You can read them from there (as far as I know. Didn't test it) but you can not write it there for sure by using the docker login command
[2017-01-06 17:43:12] <andersonkyle> SISheogorath: Ok.  That's disappointing, but thanks for the help!
[2017-01-06 17:45:37] <SISheogorath> it's a bad habit to write credentials unencrypted to a file. So it's more or less secret managment. As mentioned if you disagree with that file an issue
[2017-01-06 18:02:15] <galvesribeiro> hey guys
[2017-01-06 18:02:19] <galvesribeiro> quick question...
[2017-01-06 18:02:40] <galvesribeiro> is there a way to docker monitor if a service inside the container is alive or not?
[2017-01-06 18:03:59] <galvesribeiro> I mean, the main ENTRYPOINT is alive, so from docker perspective, the container is running however, some internal crap happen on the app and I need docker to check with some sort of heartbeat the application (idk, a ping on a specific port or whatever) and if it does'nt reply, just kill the container... is it possible?
[2017-01-06 18:05:55] <killerspaz> need some health monitoring internal and external to the container; something internal to keep checking the status of what you need running/accessible, and something external to poll it once in a while to know to kill/restart it.... there's unfortunately so many ways to accomplish this, it just depends on what level of effort you want to put into it.
[2017-01-06 18:06:33] <killerspaz> you could simplyexecaps | grep APPto see if it's running external from container on the host
[2017-01-06 18:06:34] <galvesribeiro> killerspaz: hey! :)
[2017-01-06 18:06:50] <galvesribeiro> that is the poin
[2017-01-06 18:06:52] <galvesribeiro> point
[2017-01-06 18:07:47] <galvesribeiro> in Orleans we have a health monitoring service which all nodes of the cluster ping each other and after a given number of ping fail from some servers, they declare it dead, and remove from the cluster membership ring
[2017-01-06 18:08:08] <galvesribeiro> it already works pretty fine on VMs and bare metal
[2017-01-06 18:08:24] <galvesribeiro> I did implemented an Docker membership provider
[2017-01-06 18:08:57] <galvesribeiro> the problem now is that for the provider, it only knows if a node is up or down only by checking docker daemon if it is up or down
[2017-01-06 18:08:59] <galvesribeiro> and that is our problem
[2017-01-06 18:09:18] <galvesribeiro> a container can be app, but some internal thread in the application process for whatever reason is blocked
[2017-01-06 18:09:31] <galvesribeiro> so no new requests should go to that node
[2017-01-06 18:09:45] <galvesribeiro> so the idea is to ask docker (or swarm) to kill that node
[2017-01-06 18:10:01] <galvesribeiro> but to be sure of that, I need to detect this stallness correctly
[2017-01-06 18:10:19] <killerspaz> how is the provider checking daemon status?
[2017-01-06 18:10:31] <killerspaz> remember, i know nothing about Orleans, so my apologies for simpleton questions related to that
[2017-01-06 18:11:54] <galvesribeiro> nah no worries :D
[2017-01-06 18:12:40] <galvesribeiro> that is another problem :D
[2017-01-06 18:12:55] <killerspaz> if you are simply doing adocker ps | grep MY_CONTAINER_NAME | grep Runningor something of the nature, it's simple to also do something like:docker exec MY_CONTAINER_NAME ps aux | grep processordocker exec MY_CONTAINER_NAME ping somehost.com
[2017-01-06 18:13:35] <galvesribeiro> in linux, you map docker.socket and you make docker API requests to it
[2017-01-06 18:13:51] <galvesribeiro> but on windows, there is no docker.socket!!! o.o
[2017-01-06 18:16:30] <killerspaz> imo it's best to keep that check external to the container... i like to couple things downstream instead of upstream... but that's preference
[2017-01-06 18:16:45] <galvesribeiro> we have this check external
[2017-01-06 18:17:10] <galvesribeiro> each node of Orleans cluster (which is a container) send health messages to each other
[2017-01-06 18:17:40] <galvesribeiro> the rendevour point of those messages, used to be the membership table
[2017-01-06 18:17:59] <galvesribeiro> if multiple nodes try to reach a node and fail (lets say 3 times), that node is marked as dead
[2017-01-06 18:18:03] <galvesribeiro> even if the machine is running
[2017-01-06 18:18:09] <galvesribeiro> so noone will send a message to it again
[2017-01-06 18:18:16] <galvesribeiro> now, in docker, we don't have that table
[2017-01-06 18:18:25] <galvesribeiro> we were relying on docker labels
[2017-01-06 18:19:09] <galvesribeiro> so each Orleans node should query docker (or swarm) daemon periodically about all the containers with a given Label that are running
[2017-01-06 18:19:22] <galvesribeiro> that would make them know who is on the cluster
[2017-01-06 18:20:31] <galvesribeiro> if a container is killed/exit, next query on docker api will return all containers - that one
[2017-01-06 18:20:56] <galvesribeiro> that is ok for periodic refreshes and consider only the container up or down
[2017-01-06 18:21:01] <galvesribeiro> the problem is internal
[2017-01-06 18:21:15] <galvesribeiro> I need to mark a container as dead even if it is running
[2017-01-06 18:21:18] <killerspaz> could you then iterate over all the containers and exec a "health check" script that is consistently implemented?
[2017-01-06 18:21:32] <killerspaz> even if it does NOTHING?
[2017-01-06 18:22:00] <galvesribeiro> the problem is not the healthcheck mecanism
[2017-01-06 18:22:03] <galvesribeiro> we already have it
[2017-01-06 18:22:09] <galvesribeiro> the problem is how to mark it as dead
[2017-01-06 18:22:30] <killerspaz> errr, other than just killing the container?
[2017-01-06 18:22:40] <killerspaz> or can you modify a label?
[2017-01-06 18:22:50] <galvesribeiro> ok way, let me rephrase
[2017-01-06 18:22:53] <killerspaz> i haven't messed with labels really outside of RancherOs
[2017-01-06 18:23:12] <galvesribeiro> the problem is how to save the counted votes to kill that node
[2017-01-06 18:23:17] <killerspaz> so my knowledge there is low as well, other than you can kinda query against them
[2017-01-06 18:23:31] <galvesribeiro> remember, before docker, we had that table as a central point
[2017-01-06 18:23:35] <galvesribeiro> now I have labels
[2017-01-06 18:23:38] <galvesribeiro> so the ideal would be
[2017-01-06 18:23:41] <killerspaz> ahhh.... yeah, can you store that in a label at all? otherwise you'll probably have to persist that yourself somewhere
[2017-01-06 18:23:51] <galvesribeiro> I can
[2017-01-06 18:24:05] <galvesribeiro> labels are writeable in runtime?
[2017-01-06 18:24:15] <galvesribeiro> I mean, each vote will increment a counter in it
[2017-01-06 18:24:19] <galvesribeiro> does it work?
[2017-01-06 18:24:49] <killerspaz> damn [<-ISSUE->] 
[2017-01-06 18:25:10] <killerspaz> well, could the container persist it internally?
[2017-01-06 18:25:21] <killerspaz> simply have a file with a count in it?
[2017-01-06 18:25:37] <killerspaz> lame, i know.... but it could suffice
[2017-01-06 18:27:02] <killerspaz> wait... now i'm confused: [<-LINK->] 
[2017-01-06 18:27:38] <killerspaz> oh nvm... that's a container creation
[2017-01-06 18:28:10] <galvesribeiro> Yeah creation isnok
[2017-01-06 18:28:16] <galvesribeiro> The problem is update
[2017-01-06 18:28:21] <killerspaz> right....
[2017-01-06 18:28:27] <galvesribeiro> Shame... it is supposed to be metadata
[2017-01-06 18:28:33] <galvesribeiro> So it should be updatable
[2017-01-06 18:28:49] <galvesribeiro> Regarding the file with the count
[2017-01-06 18:28:56] <killerspaz> well without having a central db for that, i'd just shoot the count into a file inside the container, and make that an opinionated implementation
[2017-01-06 18:29:09] <killerspaz> although, it's not the prettiest
[2017-01-06 18:29:18] <galvesribeiro> The problem is that it will cause races
[2017-01-06 18:30:04] <galvesribeiro> Remember, there could be thousands of request to declare a node dead if you have thousands of containers in that cluster
[2017-01-06 18:30:14] <galvesribeiro> So it is very fragile
[2017-01-06 18:31:42] <galvesribeiro> In the regular membership table there is a lock mechanism to avoid the races
[2017-01-06 18:33:21] <galvesribeiro> If the exec where guaranteed to be exclusive execution, then maybe it would work... but I doubt
[2017-01-06 19:32:51] <galvesribeiro> killerspaz: I think I found a solution
[2017-01-06 19:32:58] <galvesribeiro> not beautiful but maybe work
[2017-01-06 19:33:07] <galvesribeiro> let me format here and paste to you, 1m
[2017-01-06 19:39:05] <killerspaz> nice
[2017-01-06 19:51:04] <galvesribeiro>  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2017-01-06 19:51:44] <galvesribeiro> killerspaz: suggestions are welcome :)
[2017-01-06 19:59:07] <killerspaz> yep, basically what I was thinking
[2017-01-06 20:00:24] <galvesribeiro> I'm afraid of having multiple people trying to kill the same silo heheheh
[2017-01-06 20:00:31] <galvesribeiro> because there is no lock whatsoever
[2017-01-06 20:00:32] <galvesribeiro> :P
[2017-01-06 20:04:10] <killerspaz> at some point the race should work itself out, shouldn't it?
[2017-01-06 20:10:40] <galvesribeiro> Only after the silo is dead heheh
[2017-01-06 20:11:40] <galvesribeiro> We could avoid the files if we could increment a counter on labels
[2017-01-06 20:11:52] <galvesribeiro> But that isnt possible unfortunately
[2017-01-06 20:14:39] <galvesribeiro> Ok assuming this problem is "sorted", nothing from this would work if I can\'t make the container to reach the docker API on the host (i.e from inside the container make requests to http|tcp://hostIP:2375)
[2017-01-06 20:18:03] <galvesribeiro> On linux hosts just need to map the docker.socket file and make requests to it... easy... the only way I see is to make it work on windows hosts, is making this request thru network. However, I madetelnet hostIPonDockerNetwork 2375from inside a container and it dont connect from inside the container... the container can ping the host, just dont connect to the port
[2017-01-06 21:07:39] <SISheogorath> galvesribeiro: what version of Docker are you running?
[2017-01-06 21:08:19] <SISheogorath> If case of 1.12.x you can use the HEALTHCHECK option of the Dockerfile which provides healthchecks inside the container
[2017-01-06 21:09:25] <galvesribeiro> hummm
[2017-01-06 21:09:30] <galvesribeiro> let me check the version
[2017-01-06 21:09:48] <galvesribeiro> Docker version 1.13.0-rc4, build 88862e7
[2017-01-06 21:10:04] <galvesribeiro> SISheogorath: What kind of checks this HEALTHCHECK does?
[2017-01-06 21:10:48] <SISheogorath> galvesribeiro: it runs a followed command every 30 seconds if you don't specifiy another period and restarts the container if it fails
[2017-01-06 21:11:29] <SISheogorath>  [<-LINK->] 
[2017-01-06 21:12:31] <SISheogorath> We do a very basic healthcheck here: [<-LINK->] 
[2017-01-06 21:14:17] <galvesribeiro> hummm
[2017-01-06 21:14:19] <galvesribeiro> interesting...
[2017-01-06 21:14:34] <galvesribeiro> but I still need the file stuff
[2017-01-06 21:15:41] <galvesribeiro> I mean, looks like it only abstract the need to check if the files are > threshold
[2017-01-06 21:22:12] <galvesribeiro> SISheogorath: the major problem with this healt check is that it check from docker host process to a local container
[2017-01-06 21:22:15] <galvesribeiro> that is fine
[2017-01-06 21:22:19] <galvesribeiro> it is one type of chec
[2017-01-06 21:22:22] <galvesribeiro> check
[2017-01-06 21:22:27] <galvesribeiro> the problem is remote check
[2017-01-06 21:23:09] <killerspaz> SISheogorath: @galvesribeirooh that's badass
[2017-01-06 21:23:35] <SISheogorath> Oh yes, It's not a monitoring. It only makes sure that the container itself is in a healty state.
[2017-01-06 21:23:37] <galvesribeiro> the problematic container may think "hey I\'m ok" while the host for whatever reason is having a transient network partition problem, so other containers in other docker hosts can\'t talk to it
[2017-01-06 21:23:44] <galvesribeiro> yup
[2017-01-06 21:24:34] <galvesribeiro> I need a way to external containers to say "hey docker, that container is unhealthy" and eventually ask docker to kill it
[2017-01-06 21:24:50] <galvesribeiro> regardless what docker or the container itself think
[2017-01-06 21:25:07] <galvesribeiro> this pattern is common in distributed computing actually...
[2017-01-06 21:25:19] <SISheogorath> K8s, Rancher, Swarm
[2017-01-06 21:25:31] <SISheogorath> Take what you need they all check for that
[2017-01-06 21:26:05] <galvesribeiro> you mean they check themselves, not the containers
[2017-01-06 21:27:41] <SISheogorath> K8s and Rancher has healthchecks for their "services" and swarm simply checks that all containers have a healthy state. And as long as every container has a healty state all containers work as expected and everything from outside is L4 mesh magic :D
[2017-01-06 21:27:46] <killerspaz> i think he's saying they check the container's health status based on the result of that HEALTHCHECK entry as likely listed bydocker inspect, and have an option to auto-kill the container should it be unhealthy
[2017-01-06 21:33:01] <galvesribeiro> There are 2 types of health check. Local, where if unhealthy, just suicide(the HEALTHCHECK is a good candidate for that) and the distributed consensus, which is made by external sources trying to reach that container and failing, so they agree on ask docker to kill it
[2017-01-06 21:33:46] <galvesribeiro> In orleans case the consensus is what I'm having problems to implement in docker due to those limitations
[2017-01-06 21:34:20] <galvesribeiro> The self check can be made with the HEALTHCHECK just fine I guess
[2017-01-06 21:37:18] <iDVB> Docker, Docker Compose, Docker Swarms, Docker Cloud..... docker-compose.yml, docker-cloud.yml, services.yml(Cloud66), build.yml(Cloud66), codeship-services.yml(Codeship), codeship-steps.yml(Codeship)    does anyone else's brain hurt.... or just me?
[2017-01-06 21:38:01] <iDVB> I've pretty well got dev docker workflow working. I'm starting to loose hope for that to translate into a prod docker stack
[2017-01-06 21:39:19] <iDVB> docker-compose.ymlseems like a great implementation/standard file.... why did we feel the need to createdocker-cloud.yml?
[2017-01-06 21:39:20] <galvesribeiro> iDVB: this is called "Docker ecosystem around Docker"
[2017-01-06 21:39:36] <galvesribeiro> Anyway
[2017-01-06 21:40:37] <galvesribeiro> killerspaz: @SISheogorathbut nothing of those health check strategies will work if I'm unable to reach docker daemon api from inside the container 
[2017-01-06 21:41:08] <killerspaz> kill your main process to kill the container?
[2017-01-06 21:41:22] <killerspaz> otherwise, you need an orchestration system like kubernetes or rancher
[2017-01-06 21:42:23] <SISheogorath> galvesribeiro: Why should you need to reach the docker api from inside the container? As mentioned for unreachable nodes you have orchestration solutions like K8s, Rancher or swarm. They take care about that
[2017-01-06 21:42:33] <iDVB> galvesribeiro: Sorry, just burning out trying to ramp up to all things Docker/Containerizing. Still have a ton to learn about related best practises etc. Not wanting to deal with the Ops side of things. Docker Cloud seems to promise as much.... but requires another filedocker-cloud.ymlcreated, so I'm curious why. docker-compose seems to contain much of the same.
[2017-01-06 21:43:04] <iDVB> The same can be said about many other docker hosts or CI tools. Eg. my examples of codeship and cloud66
[2017-01-06 21:43:52] <SISheogorath> iDVB: it\'s really annoying yes :D but everyone have their own "best way to do it" so mhm have to deal with it
[2017-01-06 21:47:43] <galvesribeiro> @killerspazkill your main process to kill the container?That is doable for the local check@SISheogorathThe app running in the container have to read some labels from docker API to know which containers are part of the cluster and then inspect each one to get their IPs to connect to.We don't want to enforce users to use an external orchestration solution because none of them, will get what we need. In fact, we are using Swarm... When I say query Docker API, I mean query it thru Swarm endpoint
[2017-01-06 21:47:53] <iDVB> SISheogorath: thanks. I'm starting to see that now. I guess I'm a perfectionist and struggling with needing to guess at the best foot forward.  Wish someone would feel opinionated enough to just point to a workflow that seems to work well for them.  Docker Cloud looks decent but it is prod ready? Cloud66 looks like ikea for docker (in a good easy way) but I'mn struggling with their build process.
[2017-01-06 21:48:26] <galvesribeiro> btw, just receive a new docker update
[2017-01-06 21:48:27] <galvesribeiro>  [<-CODE->] 
[2017-01-06 21:50:43] <SISheogorath> galvesribeiro: wait. classic swarm or swarm-mode?
[2017-01-06 21:50:58] <iDVB> One of my issues is that I have a minimal prod container to run a nodejs app.  that its expecting to already be built and at the host location/buildhowever I need something to build those files using the same repo first. So do I need to create two containers, one for building and one for prod?  Whats the workflow for that? I guess I could include the built files in the repo.... but that seems dirty to me.
[2017-01-06 21:52:23] <SISheogorath> iDVB: what do you mean? Can you file an example repo?
[2017-01-06 21:52:35] <iDVB> absolutely.... sec
[2017-01-06 21:52:55] <galvesribeiro> SISheogorath: sorry my noobish, what is the difference? I though there is only 1 swarm o.O
[2017-01-06 21:53:16] <SISheogorath> galvesribeiro: how did you init swarm?docker swarm init?
[2017-01-06 21:53:29] <iDVB> SISheogorath:  [<-LINK->] 
[2017-01-06 21:54:36] <iDVB> please disregard the fact that those examples don't have a CLEAN MINIMAL docker.... I do have one... here...
[2017-01-06 21:55:39] <SISheogorath> wow this looks wrong :D you should do this in a Dockerfile or at least in a entrypoint script if you need to do it on startup
[2017-01-06 21:55:47] <galvesribeiro> SISheogorath: I didn't initialized swarm yet... I though it uses the (almost) same APIs as in docker daemon with just a diff endpoint... I'm testing now locally with only the daemon
[2017-01-06 21:56:08] <iDVB> SISheogorath: ...sorry.. I just updated the gist
[2017-01-06 21:56:17] <iDVB> it now includes both dev and prod dockerfiles
[2017-01-06 21:57:05] <iDVB> so the issue is that the APP needs to npm install / yarn install all the deps including the devdeps. then it needs to build then those resulting files are the only thing that needs to go into the prod container
[2017-01-06 22:00:10] <SISheogorath> galvesribeiro: The only nodes who have access to the controler API of docker swarm mode are the managers. They are the only hosts who decide if the whole cluster lives or die. They ensure they can see each other and reschedule things in case a node goes doen. So the only nodes where you can run your service if it needs the docker API are the managers or you have to build some crazy "docker socket socat"-workarounds. :D Works and is fun but not really perfect ;)
[2017-01-06 22:00:15] <killerspaz> iDVB: overrideis ALWAYS read along side ofdocker-compose.yml, unless-fis explicitly used
[2017-01-06 22:00:59] <killerspaz> so it's more suggested to put DEV changes in there, and create a separate compose for prod that can override your base, and execute as:docker-compose -f docker-compose.yml -f docker-compose.prod.yml up
[2017-01-06 22:01:16] <killerspaz>  [<-LINK->] 
[2017-01-06 22:01:18] <SISheogorath> So you never face that problem you descripted. In case a node is dead it's services are rescheduled somewhere else and everything is fine
[2017-01-06 22:02:44] <killerspaz> iDVB: and yeah as@SISheogorathmentioned i'd use a dockerfile to simplify your yml config
[2017-01-06 22:03:19] <iDVB> killerspaz: yup....sorry I think that gist might be older than that discovery. But the real issue is how to build my app and then put those files into the prod container
[2017-01-06 22:03:45] <killerspaz> that's what your Dockerfile would do
[2017-01-06 22:03:59] <iDVB> the prod one or the dev one?
[2017-01-06 22:04:05] <killerspaz> there would only be one
[2017-01-06 22:04:07] <iDVB> cuz the dev one does do it
[2017-01-06 22:04:23] <killerspaz> your ENV vars would imply to your app what mode it should be in
[2017-01-06 22:04:40] <iDVB> but I don't want dev source files or the deps to build them on/in the prod container
[2017-01-06 22:05:38] <galvesribeiro> So you never face that problem you descripted. In case a node is dead it's services are rescheduled somewhere else and everything is fineThis problem exist regardless of the containers or not. And it is not a matter of a Container is up or not, it is a matter of the application running inside of it is healthy or not
[2017-01-06 22:05:49] <killerspaz> so i assume you're going to need the deps no matter what in one form or another; assuming you're concat'ing them together somehow (js project i'm also assuming)
[2017-01-06 22:06:01] <iDVB> exactly
[2017-01-06 22:06:12] <iDVB> there are prod deps and dev deps
[2017-01-06 22:06:20] <killerspaz> right, so I have my output always go to adistfolder; regardless of mode
[2017-01-06 22:06:32] <killerspaz> that's what i copy to my docker container
[2017-01-06 22:06:55] <iDVB> also... the devdeps (node) require native apps in order to build..... none of that should be in prod
[2017-01-06 22:07:40] <killerspaz> mmmm i guess one could make that argument....
[2017-01-06 22:08:02] <killerspaz> personally I don't care about that, my images are no more than 60mb with gcc and such
[2017-01-06 22:08:03] <SISheogorath> iDVB: can you install them into the container, build it and than uninstall it?
[2017-01-06 22:08:13] <iDVB> well put it this way.... this.... should not need to be in prod....RUN apk add --no-cache make gcc g++ python
[2017-01-06 22:08:40] <killerspaz> i mostly agree... but also dont' care :P
[2017-01-06 22:08:46] <iDVB> and this....yarn installwill install and nativle compile with the above... a TON of useless stuff
[2017-01-06 22:08:55] <killerspaz> baremetal machines are likely to have those anyway
[2017-01-06 22:09:01] <killerspaz> so i dont' see it any different
[2017-01-06 22:09:27] <iDVB> as I understand.... this also slows down builds and adds to container size and layers significantly
[2017-01-06 22:09:31] <killerspaz> but keep in mind, that won't ever execute outside of the context of an image build
[2017-01-06 22:10:05] <killerspaz> well there's cached layers, so that becomes a moot point
[2017-01-06 22:10:13] <SISheogorath> iDVB: see [<-LINK->] 
[2017-01-06 22:11:00] <SISheogorath> In this case we build an cpp application but as long as you keep install and uninstall in a singleRUNit doesn't effect the image size
[2017-01-06 22:11:01] <killerspaz> SISheogorath: that will affect your filesystem in your image, but not your image size... those layers will still exist in the image
[2017-01-06 22:12:13] <SISheogorath> killerspaz: It's the only layer which adds real content to the image >.>
[2017-01-06 22:13:19] <killerspaz> true; but i'm just saying overall i think your image is still the max bloat size in that context... you have to squash the layer (which can't be done via Dockerfile) and commit the image for it to rewrite the layer history... much like git and rebasing
[2017-01-06 22:13:46] <killerspaz> it can all be done, but not really worth the effort
[2017-01-06 22:13:53] <killerspaz> i mean disk space is so cheap these days
[2017-01-06 22:13:57] <iDVB> I have no experience, so I can\'t debate.... but everything I\'m reading is slapping hands for this kinda thing. Saying "MINIMAL CONTAINER", Immutable,  nothing in the container not needed. etc
[2017-01-06 22:14:13] <killerspaz> yeah i think there's some invisible lines you have to draw
[2017-01-06 22:14:34] <killerspaz> for example, i read that more as, don't put mongo and your node app in the same container
[2017-01-06 22:14:39] <galvesribeiro> SISheogorath: in all cases... how can I reach the Docker/Swarm API from inside the container?
[2017-01-06 22:14:40] <iDVB> and I\'ve seen examples that show dockerfiles that "assume" the built app and just import it
[2017-01-06 22:14:43] <killerspaz> and not all containers CAN be immutable, simply due to data storage needs
[2017-01-06 22:15:11] <iDVB> are those supposed to use volumes then?
[2017-01-06 22:15:12] <SISheogorath> killerspaz: heh? actuall this whole block is one single layer.
[2017-01-06 22:16:08] <SISheogorath> there is nothing to squash
[2017-01-06 22:16:10] <killerspaz> iDVB: you could have your process build locally and then just copy everything over, that's feasible
[2017-01-06 22:16:28] <killerspaz> SISheogorath: the concept of "add then remove" is prime candidate for squashing
[2017-01-06 22:16:43] <killerspaz> but again, we're probably talking less than 20mb of layer data
[2017-01-06 22:18:08] <killerspaz> iDVB: but you'll still obviously need to do installs of say node, pm2, etc.... in which case you may still need gcc, etc
[2017-01-06 22:44:04] <killerspaz> man i really wish virtualbox would get their inotify game in check... this is some bullshit
[2017-01-06 22:45:19] <killerspaz>  [<-LINK->] 
[2017-01-06 22:47:57] <galvesribeiro> Btw, what is the diff between the two swarms?
[2017-01-06 22:49:32] <killerspaz> k8s and docker swarm?
[2017-01-06 22:49:34] <iDVB> Isnt that a show... "Between two swarms"?     .... sorry.... I had to... fried.
[2017-01-06 22:49:48] <iDVB> Anyway... thanks for the help everyone....need to do more reading
[2017-01-06 22:50:06] <killerspaz> I swarm, you swarm, we all swarm for shawarma
[2017-01-06 22:50:24] <killerspaz> lol also fried :P
[2017-01-06 22:51:19] <galvesribeiro> Classic swarm vs Swarm mode
[2017-01-06 22:51:27] <galvesribeiro> lol
[2017-01-06 22:51:36] <galvesribeiro> Shawarma is good 
[2017-01-06 22:53:09] <killerspaz> I think it's the mere fact it's integrated now? I am not really sure
[2017-01-06 22:55:18] <galvesribeiro> SISheogorath: mentioned that so I though there is any diff
[2017-01-06 22:56:36] <SISheogorath> Swarm is integrated now. (named swarm mode) But there is still the classic swarm tool kit
[2017-01-06 22:56:45] <killerspaz> Yeah i think that's what he was referring to, before hand you used a swarm image to do the management for you
[2017-01-06 22:57:10] <SISheogorath>  [<-LINK->] vs. [<-LINK->] 
[2017-01-06 22:57:16] <galvesribeiro> @SISheogorathThe only nodes who have access to the controler API of docker swarm mode are the managersSo that means I cant have a docker cli connecting to it from outside it?
[2017-01-06 22:57:31] <galvesribeiro> The container will behave just as any docker client
[2017-01-06 22:57:48] <galvesribeiro> I just need them to have connectivity to the master nodes
[2017-01-06 22:57:50] <galvesribeiro> Thats all
[2017-01-06 22:58:20] <SISheogorath> galvesribeiro: you have to access thedocker.sockon the swarm managers in case you want to see/edit things.
[2017-01-06 22:58:45] <galvesribeiro> That is weird
[2017-01-06 22:58:58] <SISheogorath> That's named security :D
[2017-01-06 22:59:07] <galvesribeiro> Imagine that I have my cluster in azure or aws
[2017-01-06 22:59:29] <galvesribeiro> How can I connect to it ao I can issue docker run for instance?
[2017-01-06 23:00:32] <SISheogorath> why should you use docker run?
[2017-01-06 23:00:42] <galvesribeiro> Just an example
[2017-01-06 23:00:49] <galvesribeiro> To run a container in the swarm
[2017-01-06 23:00:57] <SISheogorath> yes
[2017-01-06 23:01:40] <galvesribeiro> You will use the tls cert and point to one of the master hosts IP address, correct?
[2017-01-06 23:02:50] <SISheogorath> what? I don't get your usecase x.x sry
[2017-01-06 23:04:40] <galvesribeiro> I'm trying to say that if you can connect to a docker swarm manager in order to issue commands a d manage it, why in earth cant a container connect to it using its IP as well?
[2017-01-07 01:13:59] <SISheogorath> @galvesribeiro because first of all a container should not manage the docker swarm. With a few exceptions but in this case those containers easily can run on a manager node.On the other hand it is possible to expose the docker socket via tcp. BUT(!) that's very  danagrous and something you should never do. N E V E R.Some containers like traefik as reverse proxy use labels of docker containers to redirect traffic. in this case you use the already mentioned socat containers which expose the docker socket to special networks which are only used by the containers which need the docker socket to work
[2017-01-07 01:14:54] <galvesribeiro> ic
[2017-01-07 01:15:08] <galvesribeiro> the lack of security in docker socket trends to that
[2017-01-07 01:15:23] <galvesribeiro> I mean, there are tons of other ways to secure the managers or the APIs
[2017-01-07 01:15:32] <galvesribeiro> what I'm asking is introspection
[2017-01-07 01:15:34] <galvesribeiro> just it
[2017-01-07 01:15:43] <galvesribeiro> which should be available inside the containers
[2017-01-07 01:16:15] <galvesribeiro> just the way AWS provide a 169.x.x.x IP inside the container/VM so you can use as introspection endpoint from inside the container
[2017-01-07 01:16:21] <galvesribeiro> its a shame docker doesn't offer that
[2017-01-07 01:16:52] <galvesribeiro> and don\'t have it as an excuse of "security issues"... well, that is not a proper answer from them :D
[2017-01-07 01:17:11] <SISheogorath> the problem is that the docker socket controls a appliction running as root. you should avoid to expose something running as root. Exemption for this rule is only sshd
[2017-01-07 01:17:23] <galvesribeiro> yeah, I understand
[2017-01-07 01:17:40] <galvesribeiro> that is why it should be a TCP/HTTP endpoint exposed
[2017-01-07 01:17:49] <galvesribeiro> and not the .socket directly
[2017-01-07 01:18:21] <galvesribeiro> something like a service identity using a diff certificate that the containers can connect to and make whatever they are allowed to
[2017-01-07 01:18:40] <galvesribeiro> this case I'm showing is a totally legit usage of the APIs
[2017-01-07 01:18:57] <galvesribeiro> if there is a security problem with them, it should be addressed :D
[2017-01-07 01:19:27] <galvesribeiro> ask people to deploy extra infrastructure is something insane
[2017-01-07 01:19:39] <galvesribeiro> I mean, deploy an orchestration
[2017-01-07 01:19:58] <galvesribeiro> while docker already has everything most of people need in a very simple and generic way
[2017-01-07 01:20:23] <SISheogorath> O.o I still don't see the real usecase of your request. what do you need what you can't have right now?
[2017-01-07 01:20:32] <galvesribeiro> ok
[2017-01-07 01:21:41] <galvesribeiro> I need a container to go to docker (or swarm) and as "Hey, I need all containers that have a labeldeploymentId=12345" and it return a list of the containers info like Id, name, hostname, IP, Ports, etc
[2017-01-07 01:22:16] <galvesribeiro> docker remote APIs is suppose to be used like that
[2017-01-07 01:22:18] <SISheogorath> in this case you should address services not containers directly
[2017-01-07 01:22:39] <galvesribeiro> and it is secured by the TLS certificate
[2017-01-07 01:23:33] <galvesribeiro> ok so, "Docker, give me all containers from theService Awhich are running and have asomelabel=AAAAA"
[2017-01-07 01:23:52] <galvesribeiro> what I mean is, the remote API should be available
[2017-01-07 01:30:04] <SISheogorath> I'm not sure if you can label different containers of the same service in a different way
[2017-01-07 01:32:21] <galvesribeiro> ignore the label
[2017-01-07 01:32:44] <galvesribeiro> if the Service works as a filter and return me all the containers so I can inspect them, I'm ok with that :D
[2017-01-07 01:33:37] <SISheogorath> That sounds like Monitoring :D In this case run your software on a mananger node and everything is fine :D
[2017-01-07 01:34:05] <galvesribeiro> what if I make all my nodes managers?
[2017-01-07 01:35:58] <galvesribeiro> so you are saying that the only way to issue commands to a swarm is if I'm locally logged (ssh/powershell remote) on a manager node, right?
[2017-01-07 01:36:25] <galvesribeiro> so I can't remote manage a swarm cluster if I'm not logged into a manager node, right?
[2017-01-07 01:38:51] <SISheogorath> If you really want you can do it. But as mentioned it's not recommended.You can also use a container which is forced to run on manager nodes in your swarm like Portainer which allows you remote management but I guess you talk about CLI.So by using swarm-mode and stay as save as possible yes, you can only manage it while you ssh to it.
[2017-01-07 01:41:11] <galvesribeiro> CLI uses docker.socker (linux) or namedpipes (windows) to talk to the server when local logged... What I'm saying is to use Docker Remote API [<-LINK->] which uses the same TLS for client authenticate the requests
[2017-01-07 01:41:35] <galvesribeiro> and, ofc, true tcp:// or http:// endpoints
[2017-01-07 01:41:41] <galvesribeiro> so it can be accessed over network
[2017-01-07 01:41:48] <galvesribeiro> yes, the docker port will be open on the host
[2017-01-07 01:42:07] <galvesribeiro> and it is work of the IT guys to manage traffic to and from those nodes with firewall
[2017-01-07 01:42:22] <galvesribeiro> so, again, I have 2 hosts
[2017-01-07 01:42:33] <galvesribeiro> 1 master, 1 worker
[2017-01-07 01:42:50] <galvesribeiro> I have 1 container which can be hosted on any of those hosts
[2017-01-07 01:43:22] <galvesribeiro> can I access [<-LINK->] (for example) from inside the container?
[2017-01-07 01:43:38] <SISheogorath> if it is exposed, yes
[2017-01-07 01:43:58] <galvesribeiro> by exposed you mean the docker port is open on the master host's firewayy, correct?
[2017-01-07 01:44:07] <SISheogorath> yes
[2017-01-07 01:44:54] <galvesribeiro> ok, assuming it, and it WILL be (otherwise swarm cluster nodes will never connect to it), I don't see why it is not working here
[2017-01-07 01:45:35] <galvesribeiro> the same concept should apply if you have no swarm, just a regular docker host standalone
[2017-01-07 01:47:24] <galvesribeiro> let me try something here
[2017-01-07 01:52:17] <SISheogorath> sure
[2017-01-07 02:39:20] <galvesribeiro> SISheogorath: looks like the security problem can be handled by those plugins :) [<-LINK->] 
[2017-01-07 02:42:12] <SISheogorath> looks nice. I wasn't aware of the--authorization-plugin=[]-option :D
[2017-01-07 02:42:40] <galvesribeiro> yeah, looks like you can implement one yourself to provide fine grained authorization or fine some other around
[2017-01-07 02:43:08] <SISheogorath> I still prefer the old way, but if it works for you perfect :) I'm happy to see that you have found a solution which fits your needs
[2017-01-07 02:43:24] <galvesribeiro> yeah, I still didn't hehehe
[2017-01-07 02:43:28] <galvesribeiro> I still have 2 problems
[2017-01-07 02:44:07] <galvesribeiro> connect the container to docker remote API and find a good way to healthcheck the application inside the container from other containers :D
[2017-01-07 02:46:58] <SISheogorath> first is easy. You define your manager nodes. they are static. so you can add a rr DNS entry which addresses the manager nodes in your environment
[2017-01-07 02:48:31] <galvesribeiro> ok but do I need swarm? I mean, if I'm on a developer machine, can't I use regular docker daemon for that?
[2017-01-07 02:51:34] <SISheogorath> For the second one I'm still not sure what kind of health check you want to do a HTTP call with a predefined result to see that your API is working or a correct html page is the output or run some kind of weird script that does something idk. Maybe you can explain your use case a bit more.And the swarm API is a bit different than the pur docker API. But if you really want you can run Swarm as 1 node setup. So there is not a big problem to access the same API like you would do in production
[2017-01-07 02:51:37] <galvesribeiro>  [<-LINK->] 
[2017-01-07 02:51:54] <galvesribeiro> left side is the container
[2017-01-07 02:51:59] <galvesribeiro> right side my local machine
[2017-01-07 02:52:11] <galvesribeiro> I tried connect to all known ips of my host machine
[2017-01-07 02:52:16] <galvesribeiro> none connect from the container
[2017-01-07 02:52:46] <SISheogorath> netstat -anshows that the port is open?
[2017-01-07 02:54:16] <galvesribeiro>  [<-LINK->] 
[2017-01-07 02:54:21] <galvesribeiro> yeah, windows firewall is also disabled just to be sure
[2017-01-07 02:54:35] <SISheogorath> that IP is localhost
[2017-01-07 02:54:35] <galvesribeiro> on my machine, I can connect just fine
[2017-01-07 02:54:37] <galvesribeiro>  [<-CODE->] 
[2017-01-07 02:55:09] <SISheogorath> for sure you can\'t connect to it using a "remote" container :D you have to expose it on an external IP :D
[2017-01-07 02:55:21] <galvesribeiro> hmm
[2017-01-07 02:55:23] <galvesribeiro> make sense
[2017-01-07 02:55:32] <galvesribeiro> so I need to start the daemon with a diff config?
[2017-01-07 02:55:39] <SISheogorath> yes
[2017-01-07 02:57:12] <galvesribeiro> let me check
[2017-01-07 02:57:46] <SISheogorath> Oh my got I had such a great idea :D :D :D Have to build a test setup :o
[2017-01-07 02:57:55] <galvesribeiro> lol
[2017-01-07 02:58:11] <galvesribeiro> may I ask what is it? :P
[2017-01-07 02:58:16] <galvesribeiro> (curious)
[2017-01-07 03:00:01] <galvesribeiro>  [<-CODE->] 
[2017-01-07 03:00:11] <galvesribeiro> that should do if my docker doesn't explode :P
[2017-01-07 03:02:35] <SISheogorath> you can run a API request on container healthcheck which validates you your external output :D but As I noticed a few seconds ago in this case you can also do a simple internal health check. Because you know docker works (as container). and external validation can hit any other container as there is a traffic rounting mesh between the nodes
[2017-01-07 03:03:37] <SISheogorath> is your host still alive? :D
[2017-01-07 03:03:41] <galvesribeiro> no
[2017-01-07 03:03:43] <galvesribeiro> it doesn't
[2017-01-07 03:03:44] <galvesribeiro> heheheh
[2017-01-07 03:04:00] <galvesribeiro> it is saying that I'm using the hosts as a flag and in the config file
[2017-01-07 03:04:11] <galvesribeiro> I'm not seeing where is this flag
[2017-01-07 03:04:17] <SISheogorath> -H
[2017-01-07 03:04:27] <galvesribeiro> yeah but who did that? o.O
[2017-01-07 03:04:33] <galvesribeiro> it is installed with docker for windows
[2017-01-07 03:04:38] <galvesribeiro> need to check on that
[2017-01-07 03:05:34] <SISheogorath> ew yes :D saw it in your screenshots :D I try to avoid windows and docker :X :D In case of docker for windows you have to do some weird things because it runs inside a HyperV VM :D
[2017-01-07 03:05:47] <galvesribeiro> nop
[2017-01-07 03:05:47] <SISheogorath> (if you use linux containers)
[2017-01-07 03:05:49] <galvesribeiro> it doesn't
[2017-01-07 03:05:52] <galvesribeiro> AH ok
[2017-01-07 03:05:56] <galvesribeiro> linux :P
[2017-01-07 03:06:02] <galvesribeiro> but our case everything is windows
[2017-01-07 03:06:07] <galvesribeiro> containers, hosts, etc
[2017-01-07 03:06:51] <SISheogorath> ew okay I have to say that I know windows "well" but not docker on Windows. it was always too much magic for me :D for serverside things I stay on linux :D
[2017-01-07 03:07:02] <galvesribeiro> heheheeh
[2017-01-07 03:07:19] <galvesribeiro> I used to be on your side many many years ago
[2017-01-07 03:07:24] <galvesribeiro> tired of suffering :P
[2017-01-07 03:09:22] <SISheogorath> I was Windows Domain admin for 3 years it was nice, I had a lot of fun, weird issues and in most case a reboot fixed it but I really have to say doing things like containers on linux is a lot more enjoyable. :DI can only speak for my self :D
[2017-01-07 03:09:58] <galvesribeiro> yeah, it may be a lot easier today... windows is just starting with containers...
[2017-01-07 03:10:11] <galvesribeiro> lets see later on when we have System Center and other tooling for it
[2017-01-07 03:10:18] <galvesribeiro> but no, I'm not a sysadmin :D
[2017-01-07 03:11:01] <galvesribeiro> btw, where in earth should I change to set the-H...
[2017-01-07 03:11:02] <SISheogorath> let's try something new :D
[2017-01-07 03:11:11] <SISheogorath> I have an idea how to solve it :D
[2017-01-07 03:11:18] <galvesribeiro> solve what?
[2017-01-07 03:11:36] <SISheogorath> the listen problem :D
[2017-01-07 03:12:58] <galvesribeiro> ah ok
[2017-01-07 03:13:09] <galvesribeiro> I have so many problems to fix with docker and Orleans :D
[2017-01-07 03:13:36] <SISheogorath> netsh interface portproxy add v4tov4 listenport=2375 listenaddress=<place one of you external ips here> connectport=2375 connectaddress=127.0.0.1run this as administrator in a cmd.exe should forward the port from the external address to the localhost port so you can access it
[2017-01-07 03:13:55] <SISheogorath> but if someone ask I didn't do anything :D
[2017-01-07 03:14:12] <galvesribeiro> lol
[2017-01-07 03:14:44] <galvesribeiro> but that is for my dev machine, what about in a real environment?
[2017-01-07 03:16:16] <SISheogorath> In theory you can use it here too. It's hacky but it should work :D On linux it would be so simple :/ It's like using the sledgehammer
[2017-01-07 03:16:26] <galvesribeiro> lol
[2017-01-07 03:16:52] <galvesribeiro> what about chaning dockerd parameters to accept 0.0.0.0, would that work?
[2017-01-07 03:18:37] <SISheogorath> maybe. On windows server it works different than docker for windows. But that's another story :D
[2017-01-07 03:18:46] <galvesribeiro> hehehe
[2017-01-07 03:23:03] <SISheogorath> The problem I have with docker containers based on windows... even the "nano-windows-server" has >4GB :D I mean What the hell? I can build a gigantic application on a overloaded debian base image and it takes 1.3GB or 1.5GB :D (that\'s the biggest image I had until now)  And I\'m still far away from the BASE IMAGE :D
[2017-01-07 03:23:27] <galvesribeiro> yup
[2017-01-07 03:23:34] <galvesribeiro> windows images are by far bigger than linux
[2017-01-07 03:23:39] <galvesribeiro> the smaller has 400mb
[2017-01-07 03:23:53] <galvesribeiro> but they are working to reduce it
[2017-01-07 03:24:19] <galvesribeiro> nanoserver started at 800mb... few months after its announcement down to 500mb, and now 400mb
[2017-01-07 03:24:23] <galvesribeiro> they will improve it
[2017-01-07 03:24:43] <galvesribeiro> current NT kernel is very big
[2017-01-07 03:24:49] <galvesribeiro> cant compare with linux kernel
[2017-01-07 03:25:38] <galvesribeiro> it does a lot more (than it should) than linux one... Many things could be safely moved today to user-mode... I think they will eventually do it
[2017-01-07 03:36:45] <SISheogorath> oh yes they dropt the size dramatically since my last visit
[2017-01-07 03:37:09] <SISheogorath> but I still prefer my 5MB (unzipped) alpine image :D
[2017-01-07 03:37:23] <galvesribeiro> jisus
[2017-01-07 03:37:29] <galvesribeiro> I though it was 40mb :P
[2017-01-07 03:38:20] <galvesribeiro> I think I screw up my docker install :(
[2017-01-07 03:38:32] <SISheogorath> what did you do?
[2017-01-07 03:38:48] <galvesribeiro> tried to dosc config com.docker.service binpath= "\\"C:\\Program Files\\docker\\docker\\Docker for Windows.exe\\" --run-service -H tcp://0.0.0.0:2375"
[2017-01-07 03:39:10] <galvesribeiro> now I forgot to take a note on what the previews parameters were
[2017-01-07 03:39:11] <SISheogorath> oh okay no idea about it :D
[2017-01-07 03:39:25] <galvesribeiro> it makes the service pass parameters at start time
[2017-01-07 03:39:28] <galvesribeiro> crap
[2017-01-07 03:39:34] <galvesribeiro> let me reinstall it quickly
[2017-01-07 03:39:37] <SISheogorath> (in worst case you can do what every windows user does) reinstall
[2017-01-07 03:39:38] <SISheogorath> :D
[2017-01-07 03:40:01] <SISheogorath> 2 people 1 thought
[2017-01-07 03:40:07] <galvesribeiro> :)
[2017-01-07 03:40:35] <galvesribeiro> I'm seriously think on install it manually now
[2017-01-07 03:40:37] <galvesribeiro> without the installer
[2017-01-07 03:40:42] <galvesribeiro> so I can control dockerd.exe
[2017-01-07 03:41:44] <galvesribeiro> nvm
[2017-01-07 03:41:50] <galvesribeiro> it is only available on windows server 2016 :(
[2017-01-07 03:43:08] <SISheogorath> I see
[2017-01-07 03:43:39] <galvesribeiro> let me grab the installer
[2017-01-07 03:43:40] <galvesribeiro> dammit
[2017-01-07 03:43:46] <galvesribeiro> there must be a way :(
[2017-01-07 03:45:55] <SISheogorath> maybe you can ask in the [<-LINK->] the slack community has a nice #docker-for-windows channel
[2017-01-07 03:54:43] <galvesribeiro> waiting for pending approval
[2017-01-07 03:54:45] <galvesribeiro> :(
[2017-01-07 03:55:36] <SISheogorath> yeah :/ it can take a moment. But once you has been approve it's a lot of fun :)
[2017-01-07 03:55:45] <galvesribeiro> nice
[2017-01-07 04:05:11] <galvesribeiro> ok, my docker is back
[2017-01-07 04:05:14] <galvesribeiro> now lets try not break it
[2017-01-07 04:05:50] <galvesribeiro> Docker daemon failed with message:\nunable to configure the Docker daemon with file C:\\ProgramData\\docker\\config\\daemon.json: the following directives are specified both as a flag and in the configuration file: hosts: (from flag: [npipe:////./pipe/docker_engine_windows], from file: [tcp://0.0.0.0 http://0.0.0.0])
[2017-01-07 04:08:55] <SISheogorath> in this case clear theC:\\ProgramData\\docker\\config\\daemon.json
[2017-01-07 04:09:08] <galvesribeiro> yes, that is when I try to change it
[2017-01-07 04:09:18] <galvesribeiro> if I remove it, it run fine
[2017-01-07 04:09:25] <galvesribeiro> but I want to change the host :D
[2017-01-07 04:10:18] <SISheogorath> check your services. looks like there is a variable passed ^^
[2017-01-07 04:11:12] <galvesribeiro> there isn't :(
[2017-01-07 04:11:15] <galvesribeiro>  [<-LINK->] 
[2017-01-07 04:26:27] <galvesribeiro> I'll try your netsh hack for now
[2017-01-07 04:26:48] <galvesribeiro> pulling images again
[2017-01-07 04:42:10] <galvesribeiro> SISheogorath: dumb question... I'm totally ignorant about kubernetes... is it an orchestration tech that run on top of Docker (like swarm) or is it a different container tech?
[2017-01-07 04:43:08] <SISheogorath> K8s is a ochestration solution using docker as container engine. But can also use others.
[2017-01-07 04:43:22] <galvesribeiro> ok, nice
[2017-01-07 04:43:36] <galvesribeiro> I wonder if they have more "open" APIs and if it uses windows
[2017-01-07 04:43:52] <galvesribeiro> btw, now I know whatK8means! lol :P
[2017-01-07 04:44:05] <SISheogorath> works well for big deployments. But is oversized for setups with less than 10 nodes (personal opinion).
[2017-01-07 04:44:12] <galvesribeiro> humm
[2017-01-07 04:44:13] <galvesribeiro> ic
[2017-01-07 04:44:37] <galvesribeiro> maybe is time for a midsize orchestration tech! hehehe
[2017-01-07 04:45:02] <galvesribeiro> major problem is to create and manage the overlay network
[2017-01-07 04:45:06] <galvesribeiro> its all software based
[2017-01-07 04:45:12] <SISheogorath> They have another (opener) API :D as they don't utilize the docker.socket to communicate with the ochestrator
[2017-01-07 04:45:53] <galvesribeiro> so tons of tcp/upd sockets have to be implemented to make a virtual network across multiple hosts...
[2017-01-07 04:45:54] <SISheogorath> not really you can use "network drivers" in docker which communicate with you infrastructure to setup something like vlans
[2017-01-07 04:46:04] <galvesribeiro> hummm
[2017-01-07 04:46:50] <galvesribeiro> in all cases, the big win of swarm over the other IMHO is that you don't need to install anything else
[2017-01-07 04:46:58] <galvesribeiro> just have to have docker
[2017-01-07 04:47:37] <galvesribeiro> and major docker players like AWS, Azure, Digital Ocean, will not allow you to install a new orchestrator on their hosts for obvious reasons...
[2017-01-07 04:48:28] <galvesribeiro> and everywhere I only hear people talking about swarm...
[2017-01-07 04:49:06] <SISheogorath> not true :D AWS provides K8s as a service :D
[2017-01-07 04:49:25] <galvesribeiro> OH! true
[2017-01-07 04:49:52] <galvesribeiro> but in all cases, Swarm looks like the mostfamousone
[2017-01-07 04:52:44] <SISheogorath> because docker swarm-mode still has some problems (a lot getting fixed in 1.13) means missing some important featues K8s is still more popular than docker swarm-mode in production. But as mentioned for small setups docker swarm is way more attractive and easy to use.
[2017-01-07 04:53:09] <galvesribeiro> humm
[2017-01-07 04:53:12] <galvesribeiro> ic
[2017-01-07 04:53:43] <galvesribeiro> I'm 1.13.0-rc5 :) hope that problems get fixed :P
[2017-01-07 04:55:25] <SISheogorath> right now I still missing good multi datacenter support. Which is nicely provided by K8s and allows you to manage multiple geolocations easily
[2017-01-07 04:55:43] <galvesribeiro> I though Docker Cloud already do that
[2017-01-07 04:57:03] <SISheogorath> Not sure I'm not a Docker Cloud user
[2017-01-07 04:57:16] <galvesribeiro> they claime to do that
[2017-01-07 05:09:10] <SISheogorath> In this case they do :D
[2017-01-07 05:09:29] <galvesribeiro> :P
[2017-01-07 05:11:17] <galvesribeiro> Oh! Azure has Kubernetes as well :)
[2017-01-07 05:11:35] <SISheogorath> I was expecting that :D
[2017-01-07 05:11:58] <galvesribeiro> do you know if it can run on windows machines? I mean, like a dev machine?
[2017-01-07 05:12:18] <SISheogorath> iirc there was a annoncement a few days ago
[2017-01-07 05:12:19] <galvesribeiro> (I'll will read the docs later, just wnat to set my expectations)
[2017-01-07 05:12:25] <galvesribeiro> humm good
[2017-01-07 05:12:27] <galvesribeiro> let me check :D
[2017-01-07 05:15:29] <killerspaz> galvesribeiro: i hope you're gonna blog this stuff :P
[2017-01-07 05:15:56] <galvesribeiro> blog what? my failure getting docker to work with Orleans? :P
[2017-01-07 05:16:14] <killerspaz> lol and your eventual success, of course!
[2017-01-07 05:17:17] <galvesribeiro> I hope so :D
[2017-01-07 05:17:35] <galvesribeiro> btw, not finding anything about kubernetes on windows :(
[2017-01-07 05:18:30] <galvesribeiro>  [<-LINK->] 
[2017-01-07 05:18:32] <galvesribeiro> found that
[2017-01-07 05:25:57] <galvesribeiro> looks like kube is only for windows server 2016 and still require a linux machine for its control plane
[2017-01-07 05:25:58] <galvesribeiro> :(
[2017-01-07 05:55:08] <nischay30> hey whats the difference between docker deploy and docker stack deploy?
[2017-01-07 05:55:36] <galvesribeiro> SISheogorath: the netsh hack worked :P
[2017-01-07 05:55:52] <galvesribeiro> thank you!
[2017-01-07 05:56:11] <galvesribeiro> the problem is that it will not work on any other hosts hehehe
[2017-01-07 05:56:17] <galvesribeiro> I mean, AWS, Azure etc
[2017-01-07 05:56:18] <galvesribeiro> :P
[2017-01-07 05:57:33] <SISheogorath> galvesribeiro: you'll fix that soon :D
[2017-01-07 05:57:39] <galvesribeiro> hahahahahaa
[2017-01-07 05:57:44] <galvesribeiro> I wish I could
[2017-01-07 05:57:59] <SISheogorath> I should blog about it :D
[2017-01-07 05:58:26] <galvesribeiro> in all cases, I opened that [<-LINK->] 
[2017-01-07 05:58:32] <galvesribeiro> maybe someone jump in
[2017-01-07 05:58:59] <galvesribeiro> I changed thelistenaddressto 0.0.0.0
[2017-01-07 05:59:04] <galvesribeiro> instead of use a fixed API
[2017-01-07 05:59:09] <galvesribeiro> (DHCP hell)
[2017-01-07 05:59:36] <SISheogorath> nischay30: check [<-LINK->] 
[2017-01-07 06:00:00] <SISheogorath> hope that's enough ;)
[2017-01-07 06:00:51] <nischay30> thanks@SISheogorath
[2017-01-07 06:02:08] <galvesribeiro> SISheogorath: if I create a swarm cluster with my own machine, can I destroy it later?
[2017-01-07 06:02:32] <SISheogorath> galvesribeiro: yes, usedocker swarm leave -f
[2017-01-07 06:02:38] <nischay30> galvesribeiro: You can't destroy a swarm..You can leave the swarm
[2017-01-07 06:02:39] <galvesribeiro> good
[2017-01-07 06:35:49] <galvesribeiro> hummm docker swarm managers have an implementation of Raft in it
[2017-01-07 06:36:04] <galvesribeiro> I wonder if we can access it thru swarm APIs :P
[2017-01-07 06:36:08] <galvesribeiro> lets keep reading
[2017-01-07 06:49:53] <SISheogorath> why do you want to access it?
[2017-01-07 06:51:08] <galvesribeiro> we have a raft provider in Orleans as well... so we could "maybe" leverage its codebase and make the health consensus to use Docker one... Idk, just a guess... I\'m pretty sure it is exclusive for docker swarm
[2017-01-07 06:52:01] <galvesribeiro> I readed that the classic sward relied on Zookeeper or Consul to maintain its membership
[2017-01-07 06:52:23] <galvesribeiro> so they probably removed that dependency by implementing a private Raft cluster themselves
[2017-01-07 06:56:44] <killerspaz> SISheogorath: i'd read it
[2017-01-07 06:58:14] <SISheogorath> ehhh okay, not sure what you're referring to
[2017-01-07 07:05:30] <galvesribeiro> calleddocker swarm initand it is taking a while and don't finished
[2017-01-07 07:07:48] <SISheogorath> sounds wrong
[2017-01-07 07:08:22] <nischay30> try docker experimental or docker 1.13 version and do docker swarm init..it willwork
[2017-01-07 07:08:41] <galvesribeiro> I'm with experimental and 1.13 rc5
[2017-01-07 07:08:45] <galvesribeiro> the update came today
[2017-01-07 07:08:52] <galvesribeiro> I did a ctr+c to cancel
[2017-01-07 07:08:56] <galvesribeiro> and look at this
[2017-01-07 07:09:16] <galvesribeiro>  [<-LINK->] 
[2017-01-07 07:09:31] <SISheogorath> trydocker node ls
[2017-01-07 07:09:59] <galvesribeiro>  [<-LINK->] 
[2017-01-07 07:10:07] <SISheogorath> if you see something (like your node) it worked
[2017-01-07 07:10:08] <nischay30> galvesribeiro: first do docker swarm leave --force
[2017-01-07 07:10:13] <nischay30> and then show your docker info
[2017-01-07 07:10:17] <SISheogorath> looks fine
[2017-01-07 07:10:28] <galvesribeiro> down?
[2017-01-07 07:10:54] <SISheogorath> oh didn't open it :D
[2017-01-07 07:10:59] <galvesribeiro> hehehe
[2017-01-07 07:11:06] <galvesribeiro> let me try leave first
[2017-01-07 07:11:23] <nischay30> yes leave first with force and show your docker info
[2017-01-07 07:11:26] <galvesribeiro> node left the swarm
[2017-01-07 07:11:59] <galvesribeiro>  [<-LINK->] 
[2017-01-07 07:13:42] <nischay30> ok...
[2017-01-07 07:14:06] <nischay30> now try to run docker swarm init --advertise-addr='IP'
[2017-01-07 07:14:18] <galvesribeiro> I did with 127.0.0.1
[2017-01-07 07:14:30] <SISheogorath> ew that's a bad idea
[2017-01-07 07:14:40] <galvesribeiro> the problem is that I have 5 diff networks that I join
[2017-01-07 07:14:48] <galvesribeiro> all them are DHCP :(
[2017-01-07 07:14:51] <nischay30> ok ok...no issue..
[2017-01-07 07:15:00] <nischay30> now show docker info
[2017-01-07 07:15:11] <galvesribeiro> again?
[2017-01-07 07:15:17] <nischay30> yes
[2017-01-07 07:15:27] <galvesribeiro> you mean after the swarm command?
[2017-01-07 07:16:03] <nischay30> yes
[2017-01-07 07:16:25] <galvesribeiro> running the init
[2017-01-07 07:17:58] <galvesribeiro> ...
[2017-01-07 07:18:06] <nischay30> ?
[2017-01-07 07:18:23] <killerspaz> SISheogorath: saying i'd read the blog post exploring this discussion.. Something succinct with a focus. There's a ton of information here that could be explored in detail
[2017-01-07 07:19:46] <galvesribeiro> still blocked on the swarm init
[2017-01-07 07:20:19] <nischay30> show docker info
[2017-01-07 07:20:25] <galvesribeiro> it is blocked
[2017-01-07 07:20:33] <galvesribeiro> still running the init
[2017-01-07 07:20:46] <nischay30> let me try with the new version
[2017-01-07 07:21:43] <SISheogorath> nischay30: don't forget that he's using docker for Windows
[2017-01-07 07:22:17] <killerspaz> not docker toolbox for windows, literally docker FOR windows
[2017-01-07 07:22:34] <galvesribeiro> the latest and native docker, for windows
[2017-01-07 07:22:35] <galvesribeiro> :)
[2017-01-07 07:22:57] <killerspaz> I'm not a windows server guy, but I'm really fascinated by this exploration
[2017-01-07 07:23:27] <killerspaz> Azure is very appealing, MS is very prominent in Austin and pushes it very hard
[2017-01-07 07:23:58] <galvesribeiro> I'll write a blog about it here [<-LINK->] with my journey :P
[2017-01-07 07:24:27] <killerspaz> wait, are you the Orleans dev?
[2017-01-07 07:24:39] <galvesribeiro> I'm one of the contributors
[2017-01-07 07:24:45] <killerspaz> nice
[2017-01-07 07:24:51] <galvesribeiro> I'm no on Microsoft anymore
[2017-01-07 07:25:01] <galvesribeiro> but still have a good relationship there :)
[2017-01-07 07:25:07] <killerspaz> please post when you do!
[2017-01-07 07:25:13] <galvesribeiro> sure ;)
[2017-01-07 07:25:26] <SISheogorath> :o that explains why you are so focused on Windows :D
[2017-01-07 07:25:33] <killerspaz> hehe shhh
[2017-01-07 07:25:34] <galvesribeiro> hahahahaha
[2017-01-07 07:25:37] <galvesribeiro> :P
[2017-01-07 07:25:52] <galvesribeiro> I worked several years ago on IBM with linux
[2017-01-07 07:26:09] <galvesribeiro> thanks gosh I left this world :P
[2017-01-07 07:26:16] <nischay30> lol
[2017-01-07 07:26:24] <killerspaz> I love both honestly.... Fuck osx
[2017-01-07 07:26:31] <killerspaz> and bsd for that matter
[2017-01-07 07:26:51] <killerspaz> My opinions are that of my own
[2017-01-07 07:26:53] <galvesribeiro> O not even mention that thing :P
[2017-01-07 07:26:56] <killerspaz> lol
[2017-01-07 07:27:33] <galvesribeiro>  [<-ISSUE->] is the issue I'm tracking with Docker for Orleans and here my PR [<-LINK->] 
[2017-01-07 07:28:09] <galvesribeiro> both are part of a huge effort to bring Orleans to Linux and other cloud services provider natively
[2017-01-07 07:29:15] <galvesribeiro> specially now that we almost finished the first part of .net core port [<-ISSUE->] 
[2017-01-07 07:29:16] <SISheogorath> I don't know all those microsoft languages tends to have ultra long names for their methods and objects
[2017-01-07 07:29:26] <galvesribeiro> hehehehehe
[2017-01-07 07:30:17] <SISheogorath> same applies to commandline programs :(dirvsls
[2017-01-07 07:30:28] <killerspaz> c# is one of my favorite standards
[2017-01-07 07:31:06] <killerspaz> i love mono and what they've done for the language; .Net is also pretty great with some of the past few years' advancement
[2017-01-07 07:31:28] <killerspaz> their async/await stuff in 4.5+ is just mindblowing
[2017-01-07 07:31:45] <galvesribeiro> yup
[2017-01-07 07:32:02] <galvesribeiro> Orleans is fully based on async/await and tasks in a distributed fashion
[2017-01-07 07:33:14] <SISheogorath> I have native C++ or NodeJS for that :D
[2017-01-07 07:33:30] <SISheogorath> sometimes in combination \\o/
[2017-01-07 07:33:51] <galvesribeiro>  [<-CODE->] 
[2017-01-07 07:34:23] <galvesribeiro> that simple code in Orleans means that each of those actor tasks will run in a diff silo (a node/server in the cluster) and you get the result back
[2017-01-07 07:34:35] <galvesribeiro> it is wonderful :D
[2017-01-07 07:35:03] <galvesribeiro> my next fun project will be write Orleans fully in TypeScript for node.js :D
[2017-01-07 07:36:22] <galvesribeiro> let give node community some real distributed framework :D
[2017-01-07 07:38:58] <killerspaz> <3 TS. Ready for ES9 by now.... let's get to a real language! :P
[2017-01-07 07:40:32] <SISheogorath> oh yes! but we have to mention that in general nodejs already includes a cluster framework :D so not sure how useful it is :D But I'll give it a try
[2017-01-07 07:42:24] <killerspaz> true, it's pretty useful, too
[2017-01-07 07:43:50] <galvesribeiro> cluster in node is not a real cluster
[2017-01-07 07:44:12] <galvesribeiro> it is just a proxy/main process which spawn other process and forward requests to be processed there
[2017-01-07 07:44:26] <galvesribeiro> node (because of V8 and libUV) has a single thread
[2017-01-07 07:44:37] <galvesribeiro> so each node.exe process is 1 single thread
[2017-01-07 07:45:11] <galvesribeiro> what cluster does is multiplex that thread with diff process at cost of serialization and marshaling between process
[2017-01-07 07:45:36] <galvesribeiro> so you basically have 1+CPUThreadCount node processes per machine
[2017-01-07 07:45:39] <galvesribeiro> this is their cluster
[2017-01-07 08:00:00] <galvesribeiro> and my docker swarm init still running :(
[2017-01-07 08:03:01] <galvesribeiro> ok... its almost 6am here and I'm fighting this thing
[2017-01-07 08:03:04] <galvesribeiro> time to sleep
[2017-01-07 08:03:17] <galvesribeiro> night all bb tomorrow and thanks for all help again
[2017-01-07 08:03:32] <SISheogorath> galvesribeiro: yes, that's how nodes cluster works :D and you can build a abstraction over it to add remote nodes too :D it was very easy and very useful as we simply passed API requests trough it and ended up in nicely scaling setup
[2017-01-07 08:03:38] <SISheogorath> See you
[2017-01-07 08:03:54] <galvesribeiro> yeah
[2017-01-07 08:04:08] <galvesribeiro> but that is just usefull for stateless request/response kind of app
[2017-01-07 08:04:21] <galvesribeiro> like web servers and maybe websocket server
[2017-01-07 08:04:27] <galvesribeiro> but you can't do much with that
[2017-01-07 08:04:56] <galvesribeiro> when I find time will start the project and let you know
[2017-01-07 08:05:10] <galvesribeiro> anyway, ttyl night
[2017-01-07 08:05:49] <SISheogorath>  I'm waiting for it ;)
[2017-01-07 08:44:28] <nischay30> how to define links in docker-compose file if i want to deploy on the warm
[2017-01-07 08:44:30] <nischay30> swarm
[2017-01-07 08:45:20] <SISheogorath> you should not use links in this case. Address the services and may add network aliases
[2017-01-07 08:46:08] <nischay30> means how??i m not getting you..like i m having 3 service ..one is redis ,another one is neo4j and third one my nodejs app which has to run on 8081
[2017-01-07 08:48:52] <nischay30> ?
[2017-01-07 08:56:15] <SISheogorath> oh wait you talk about compose v3?
[2017-01-07 08:56:31] <nischay30> yes i m talking about that
[2017-01-07 08:57:07] <nischay30> i dont know how to write compose version 3.but i have to user version  3 so that i cn deploy a stack in docker 1.13 using compose nt bundle
[2017-01-07 08:57:23] <SISheogorath>  [<-LINK->] 
[2017-01-07 08:57:42] <SISheogorath> should be a nice example
[2017-01-07 08:58:06] <nischay30> ok i will explore...thanx
[2017-01-07 09:12:46] <nischay30> SISheogorath: but tell me i m having one environment vairable in nodejs app i.e.neo4j Url and i have to mention it in that and i have to refer that neo4j.so without links how i mention that?
[2017-01-07 09:14:36] <SISheogorath> set the url to the servicename of your neo4j service. if you name it "foo" use " [<-LINK->] " as url. docker swarm networking will do the rest
[2017-01-07 09:17:18] <nischay30> is it necessary that  i have to define the network also?
[2017-01-07 12:59:05] <SISheogorath> yes
[2017-01-07 15:39:00] <galvesribeiro> Afternoon! 
[2017-01-07 17:09:04] <galvesribeiro> SISheogorath: the swarm init never worked :(
[2017-01-07 17:10:31] <SISheogorath>  I have no real idea why this happens. Are you know part of the docker community?
[2017-01-07 17:11:36] <galvesribeiro> nop... got one email from Victor Coisne saying in other words, wait :(
[2017-01-07 17:17:56] <SISheogorath> Oh okay :o that's new
[2017-01-07 17:20:28] <galvesribeiro> the chat is probably too bloated
[2017-01-07 17:20:41] <galvesribeiro> so they are controlling access now unfortunately :(
[2017-01-07 17:33:29] <galvesribeiro> frustrating
[2017-01-07 17:39:31] <SISheogorath> I aggree with that but I currently have no idea. Maybe you can file an issue on github
[2017-01-07 17:40:31] <galvesribeiro> nah, don't want be an 4ss... let them take their time...
[2017-01-07 17:41:08] <galvesribeiro> regardless of swarm, I still have the Orleans <-> Docker stuff to deal with
[2017-01-07 17:42:39] <galvesribeiro> I read thru whole swarm docs yesterday (or Today? Who knows!) before sleep... it is very simple and has not much for my case actually
[2017-01-07 17:44:10] <galvesribeiro> the Orleans cluster deployment is not actually related to swarm... the only feature of swarm that is actually used but totally unrelated, is the placement strategy of containers on hosts and the desired state... thats it... load balancing etc, those things we will never use
[2017-01-07 17:45:07] <galvesribeiro> so a single standalone docker host or a swarm cluster makes no diff for me... what we care are the labels and find a way to proper health check the service
[2017-01-07 20:22:19] <vyscond> Hey guys! is it possible to point to anotherdocker-compose.ymlfile  withdocker-composecommand just like we withdocker build?
[2017-01-07 20:25:24] <galvesribeiro> vyscond: use-fjust as indocker build
[2017-01-07 20:25:43] <galvesribeiro> docker-compose up -f somefile.yml
[2017-01-07 20:25:57] <vyscond> galvesribeiro: thanks a million sport!
[2017-01-07 20:26:56] <galvesribeiro> vyscond: most of docker commands just havedocker [command] --helpso the majority of parameters are there
[2017-01-07 20:27:51] <vyscond> galvesribeiro: yup. but i forgot to run that underdocker-composealone. Instead i wasdocker-compose up --help. :/
[2017-01-07 20:28:58] <galvesribeiro> you are right
[2017-01-07 20:29:17] <vyscond> omg man, i was starting believing i was blind@_@
[2017-01-07 20:29:21] <galvesribeiro> ahhaahah
[2017-01-07 20:29:22] <galvesribeiro> :D
[2017-01-07 20:29:24] <galvesribeiro> sorry
[2017-01-07 20:29:37] <galvesribeiro> I did run here before I reply you
[2017-01-07 20:29:46] <galvesribeiro> just forgot to check which of commands had it, sorry :P
[2017-01-07 20:30:22] <vyscond> galvesribeiro: cool. thanks a million again mate :3
[2017-01-07 22:11:22] <galvesribeiro> guys
[2017-01-07 22:11:26] <galvesribeiro> according to that: [<-LINK->] 
[2017-01-07 22:11:48] <galvesribeiro> filters – a JSON encoded value of the filters (a map[string][]string) to process on the images list.
[2017-01-07 22:12:09] <galvesribeiro> does anyone have an example of that json?
[2017-01-08 13:14:26] <jjohnson1994> Hello, I want to be able to clone a repo into my docker container at run time. Because I'm using SSH to get read-only access to my repo I need to have the keys within the docker container somewhere. Is it safe to keep the public and private keys within the containers files and then link the volume in the docker-compose file? or should I be doing this another way?
[2017-01-08 13:54:29] <SISheogorath> jjohnson1994: it depends on your "secretness". If it\'s a deployment key and it\'s not a problem if everyone has it. Include it. If it is a problem, you can thing aboutmount the key to container\nadd it as environment variables\nwait vor 1.13 and add it as secret
[2017-01-08 13:57:56] <jjohnson1994> SISheogorath: It's just a deployment key so should be okay, thanks
[2017-01-08 13:58:44] <SISheogorath> You can think about it like about "would I include that into  my github repository" ;)
[2017-01-08 16:04:32] <galvesribeiro> hey guys
[2017-01-08 16:06:00] <galvesribeiro> when I do adocker inspect imageIdOrNamewhat is the difference between the objects insideConfigandContainerConfig?
[2017-01-08 16:06:54] <galvesribeiro> I'm calling this [<-LINK->] and according to their sample, we have dupplicated fields on both cases
[2017-01-08 16:07:59] <galvesribeiro> in fact, it is the same object for both... I just don't understand why it is dupplicated
[2017-01-08 18:31:01] <galvesribeiro> SISheogorath: finally got the invite from docker team to docker community
[2017-01-08 18:31:20] <SISheogorath> \\o/
[2017-01-08 18:36:45] <galvesribeiro> lets see is someone from windows is alive there heheh
[2017-01-08 18:36:50] <galvesribeiro> slack chats usually are dead
[2017-01-08 18:36:51] <galvesribeiro> :)
[2017-01-08 19:59:24] <SISheogorath> I can't agree with that. Neither for the docker community nor for k8s, nor ghost
[2017-01-08 20:17:19] <galvesribeiro> humm
[2017-01-09 04:49:19] <netw0rm> who use 1.13
[2017-01-09 08:48:26] <matrixbot> Baffyis anyone having trouble starting docker on the latest Mint?
[2017-01-09 08:48:30] <matrixbot> Baffyi think it's a systemd issue
[2017-01-09 09:28:19] <nischay30> netw0rm: i am using
[2017-01-09 09:29:00] <nischay30> could anyone tell me how to start one service after 10seconds of particular service in new docker-compose
[2017-01-09 09:32:54] <avinash2888> is it possible to do Port forwarding from container to remote server ...if possible ,how can i do it ?
[2017-01-09 09:33:49] <nischay30> avinash2888: mention the port forwarding in docker-compose file
[2017-01-09 09:36:14] <avinash2888> hii@nischay30...i tried with dockerfile by putting the following commandssh   -f -Nusername@hostname-L [local port]:[database host]:[remote port] StrictHostKeyChecking=no
[2017-01-09 09:45:41] <SISheogorath> avinash2888:  [<-LINK->] 
[2017-01-09 10:00:28] <nischay30> SISheogorath: hi that day  u had give me a link for docker-compose v3 file but in that they are using depends_on but in the release notes depends_on is not available
[2017-01-09 10:08:14] <nischay30> ?
[2017-01-09 10:11:27] <SISheogorath> Oh@nischay30didn't know that. But makes sense. The official docs doesn't say anything new about depends_on. But they always tell you to follow this: [<-LINK->] 
[2017-01-09 10:12:56] <nischay30> SISheogorath:  [<-LINK->] go here and find depends_on
[2017-01-09 10:14:32] <SISheogorath> That's about compose file version 2.1 not 3
[2017-01-09 10:14:58] <SISheogorath> For swarm deployments you need docker compose file version 3
[2017-01-09 10:14:59] <nischay30> just read the note belowe that line
[2017-01-09 10:15:19] <SISheogorath> Yes I did
[2017-01-09 10:56:30] <nischay30> seriously i was not able to find what i should put instead on depends_on
[2017-01-09 11:08:02] <milanvdmria> Im trying to run a python script in a docker container but it is having import troubles. [<-CODE->]  [<-CODE->] 
[2017-01-09 11:12:24] <SISheogorath> milanvdmria: try to check thatpwdis the correct.
[2017-01-09 11:13:28] <milanvdmria> SISheogorath: pwd runs fine, what do you exactly mean with checking if it is correct?
[2017-01-09 11:15:17] <SISheogorath> nischay30: try to not depend on order. If you do as mentioned in the linked document make your container waiting for the database. Because starting a database will take time anyways when you have some data in it anddepends_on, exempt the compose-file version 2.1,
[2017-01-09 11:15:34] <SISheogorath> Doesn't wait to start anyway
[2017-01-09 11:16:01] <SISheogorath> milanvdmria: that you're in the correct directory
[2017-01-09 11:16:23] <nischay30> SISheogorath: the container exits if the dependent container didn't start at time
[2017-01-09 11:17:26] <milanvdmria> SISheogorath: I run it from the root in the docker container. That is also where thefolderis located. So from the root (pwdgives back /), I runpython folder/subfolder1/script1.py
[2017-01-09 11:17:44] <SISheogorath> nischay30: fix it ;)
[2017-01-09 11:18:40] <nischay30> SISheogorath: seriously i was not able to fix it..
[2017-01-09 11:20:07] <SISheogorath> milanvdmria: you may have to check the Python version. (I'm not a Python coder so I'm possibility wrong) but docs talk about version 3.2 in case of your way to build the software: [<-LINK->] 
[2017-01-09 11:20:21] <SISheogorath> nischay30: what's the problem?
[2017-01-09 11:21:24] <SISheogorath> As mentioned in the docs you should use dockerize, wait-for-it.sh or a selfwritten solution
[2017-01-09 11:22:07] <milanvdmria> SISheogorath: Locally I am running 2.7.12 and on the docker 2.7.13.Im gonna upgrade locally and check if the problem persists :)
[2017-01-09 11:24:40] <SISheogorath> milanvdmria: As mentioned it was just a guess based on that I found it the docs ^^ For me Python in its thousands and thousands of versions and different handlings of errors, exceptions and libs is nothing I want to use. So I can't really make good recommendations
[2017-01-09 11:27:26] <milanvdmria> SISheogorath: The same problem persists. Locally it works, in the container it doesnt.
[2017-01-09 11:30:13] <SISheogorath> What does the import error exactly say?
[2017-01-09 11:53:24] <Husamuddin> hello there!
[2017-01-09 11:53:38] <Husamuddin> hello there!
[2017-01-09 11:53:52] <Husamuddin> I have a question on the fly!
[2017-01-09 11:54:10] <Husamuddin> is anybody here?!
[2017-01-09 11:54:20] <nischay30> ?
[2017-01-09 11:57:43] <Husamuddin> if run docker-compose up.. should I see the running containers of docker-compose on docker ps?!
[2017-01-09 11:57:55] <nischay30> yes
[2017-01-09 11:59:15] <Husamuddin> this is odd.. I run docker-compose ps and find a running services.. but can't find them on docker ps or docker-compose exec the running container
[2017-01-09 12:00:25] <nischay30> it wil show
[2017-01-09 12:01:49] <Husamuddin> supposedly yes.. but it doesn't
[2017-01-09 12:02:18] <Husamuddin> I'm searching around to find if there is anybody having the same issue but can't find any till now
[2017-01-09 12:07:09] <SISheogorath> Husamuddin: do you usectrl+cbefore you rundocker ps?
[2017-01-09 12:07:20] <SISheogorath> In this case your containers are stopped
[2017-01-09 12:12:42] <milanvdmria> SISheogorath:  [<-CODE->] 
[2017-01-09 12:17:39] <SISheogorath> Are you on windows or linux?
[2017-01-09 12:18:13] <milanvdmria> SISheogorath: mac, but this error is from the docker container which runs alpine3.5
[2017-01-09 12:19:19] <milanvdmria> Because when I run it on my mac, it runs just fine.
[2017-01-09 12:22:49] <SISheogorath>  [<-LINK->] <-- sounds like a possible solution. I guess/is not part of the$PYTHONPATHfor multiple reasons. So first of all may place your code into a directory instead of blank/and than this directory to$PYTHONPATH
[2017-01-09 12:25:12] <milanvdmria> SISheogorath: Ill try that, it is just weird that it runs locally where my Pythonpath is completely clean. It seems though that  it is more a Python problem than a Docker problem.
[2017-01-09 12:26:06] <SISheogorath> yes. iirc MacOS haspwdin$PATHwhich is also used to find modules
[2017-01-09 13:17:12] <richard-ball> How do I ensure that docker sees my host mounted volumes?
[2017-01-09 13:17:49] <richard-ball> I am getting permission denied I have restarted docker and its still not seeing my host mounted volumes.
[2017-01-09 13:25:54] <milanvdmria> SISheogorath: I added/newfolder/folderto myPYTHONPATHin the dockerfile but it is still not working.(PYTHONPATH="/newfolder/folder:/newfolder/folder/subfolder1:/newfolder/folder/subfolder2")So now Im not convinced anymore it is a Python problem but more a Python problem related to Docker.
[2017-01-09 13:50:42] <SISheogorath> milanvdmria: as mentioned I'm not a python pro so maybe someone else can help you. You should possibly ask on freenode or open an issue on github related to your base image
[2017-01-09 13:51:16] <SISheogorath> richard-ball: what do you mean by "not seeing my host mounted volumes"?
[2017-01-09 14:38:18] <richard-ball> I have mounted an EBS volume to my host, when i run docker it is trying to access the mountpoint and not the mounted volume. As such I get access denided
[2017-01-09 14:43:45] <richard-ball> `mount /dev/sdb /var/jenkins_homedocker run -v /var/jenkins_home:/var/jenkins_home jenkins
[2017-01-09 14:44:17] <richard-ball> It does not write to the mounted volume, it tries to write to the host folder /var/jenkins_home and fails on permissions, why?
[2017-01-09 14:51:02] <SISheogorath> are you sure it's not completely failing on permissions?
[2017-01-09 14:52:13] <SISheogorath> Because the mounted volume is owned by uid 500 and your container is using 123?
[2017-01-09 14:52:57] <j6k4m8> SISheogorath: interesting! Does that mean docker would fail to mount, or just fail to write?
[2017-01-09 14:53:15] <j6k4m8> I would have imagined it failed at write-time, since the mount is legal but the write isn’t
[2017-01-09 14:53:16] <SISheogorath> easiest way to verify:docker run -v /var/jenkins_home:/var/jenkins_home alpine touch /var/jenkins_home/test.txt
[2017-01-09 14:53:42] <SISheogorath> right@j6k4m8that's what I'm thinking
[2017-01-09 14:53:50] <j6k4m8> gotcha
[2017-01-09 14:54:58] <SISheogorath> To make containers more secure theUSERTag is used more often in Dockerfiles. This way you drop root permissions which results in a problem if you mount directories from your real host. Because you have an uid mismatch
[2017-01-09 14:56:15] <j6k4m8> just gave this a test on my machine, failed onwrite, not mount. Learned something new :)
[2017-01-09 14:56:29] <j6k4m8> (Though it was just a regular directory that I mounted, nothing special)
[2017-01-09 14:56:56] <j6k4m8> Is that what you expected?
[2017-01-09 14:58:12] <richard-ball> ive entered the container and i see /var/jenkins_home is filling up
[2017-01-09 14:58:23] <richard-ball> even though i have passed -v /var/jenkins_home
[2017-01-09 14:58:39] <richard-ball> I thought that exposed the path to the host?
[2017-01-09 14:58:57] <richard-ball> if i do -v dir:dir it fails on permissions
[2017-01-09 14:59:12] <richard-ball> i tested with non moutned volumes on the host and it works
[2017-01-09 14:59:17] <richard-ball> its to do with the mounted volumes
[2017-01-09 14:59:41] <richard-ball> I would think this is standard practice since you would use separate ebs volume for peristent data to that of the OS.
[2017-01-09 15:00:43] <SISheogorath> richard-ball: no, that's only add a datavolume. Check: [<-LINK->] 
[2017-01-09 15:01:12] <SISheogorath> you have to define host path and in-container path
[2017-01-09 15:01:27] <SISheogorath> than you mount the host's directory
[2017-01-09 15:03:42] <richard-ball> I did that
[2017-01-09 15:03:47] <richard-ball> drwxr-xr-x 3 jenkins jenkins 4096 Jan  9 10:55 /var/jenkins_home/
[2017-01-09 15:04:00] <richard-ball> docker run -d --name jenkins -v /var/jenkins_home:var/jenkins_home -p 8080:8080 jenkins
[2017-01-09 15:04:12] <richard-ball> Can not write to /var/jenkins_home/copy_reference_file.log. Wrong volume permissions?
[2017-01-09 15:05:01] <richard-ball> docker is not respecting the host mounted volumes
[2017-01-09 15:05:12] <richard-ball> /dev/xvdb       7.8G   18M  7.4G   1% /var/jenkins_home
[2017-01-09 15:05:54] <SISheogorath> can you rundocker exec -it jenkins whoami
[2017-01-09 15:07:08] <richard-ball> It fails to run because of the permission error
[2017-01-09 15:07:31] <SISheogorath> Oh I see
[2017-01-09 15:07:55] <richard-ball> I reran without the volume moutned and it says jenkins
[2017-01-09 15:08:23] <richard-ball> Docker version 1.11.2, build b9f10c9/1.11.2
[2017-01-09 15:08:27] <richard-ball> im using AWS AMI
[2017-01-09 15:08:29] <SISheogorath> than you should check the permissions and UIDs of your volume
[2017-01-09 15:09:06] <SISheogorath> because, as mentioned before, the in-container UID does not match with the UID on your host which has write permissions to the volume and THAT is your problem
[2017-01-09 15:11:09] <richard-ball> what UID?
[2017-01-09 15:11:27] <SISheogorath> you know unix uids?
[2017-01-09 15:11:34] <richard-ball> ahh
[2017-01-09 15:12:22] <SISheogorath> you container doesn't run as root so it has to follow the rules like every other user and respect the file permissions on the volume
[2017-01-09 15:13:29] <richard-ball> I set -u jenkins
[2017-01-09 15:13:38] <richard-ball> -u uid worked
[2017-01-09 15:13:40] <richard-ball> thanks a lot.
[2017-01-09 15:14:14] <SISheogorath> You're welcome
[2017-01-09 15:14:17] <richard-ball> I thought by specifying -u jenkins it would map it
[2017-01-09 15:15:22] <richard-ball> I guess that is inside the container.
[2017-01-09 15:30:53] <SISheogorath> yes it sets the UID inside the container
[2017-01-09 16:17:25] <Husamuddin> hello! do any body knows why command property in the docker-compose.yml file prevents docker to make the container up! [<-CODE->] I mean you won't find it on docker ps
[2017-01-09 16:19:00] <Husamuddin> I just need to run bash script just after the container is up.. without override the default command
[2017-01-09 16:35:27] <killerspaz> Husamuddin: see if this helps: [<-LINK->] 
[2017-01-09 16:35:56] <killerspaz> my guess is you have an entrypoint defined
[2017-01-09 16:48:53] <Husamuddin> I still don't get why it prevents container to be up!
[2017-01-09 16:49:07] <Husamuddin> I can't see it in docker ps
[2017-01-09 16:53:26] <Husamuddin> I don't get that why i feel like it's complicated.. I'm doing volume .:/app and once it's up I need to run specific bash script from that dir
[2017-01-09 17:56:00] <SISheogorath> Husamuddin: as@killerspazmentioned there is maybe an entrypoint script. If there is an entrypoint script your command is passed to the entrypoint script like parameters. So you may want to check that
[2017-01-09 17:57:11] <SISheogorath> (by reading your Dockerfile)
[2017-01-09 19:24:49] <somombo> jeffdm: I see you are listed on the docker/toolbox list of core maintainer.. and I didn't really know how else to reach out. I opened a PR ( [<-ISSUE->] ) for which there's also an open issue several months ago. I was wondering if you or anyone else would be able to review it or discuss changes that need to be made. It doesn't appear that there has been any feedback from the docker/toolbox maintainers.. I really appreciate it!
[2017-01-09 19:26:50] <killerspaz> how is that an issue? You can access docker from anywhere, you just have to actually START boot2linux
[2017-01-09 20:57:42] <somombo> Lol..@killerspaz, of course this is in fact, an issue . Here is a screenshot of  a trying to rundocker infoon a clean Windows 10 install of the latest Docker Toolbox  in three different terminal environments. It fails in all but the "Docker Quickstart terminal" Why?. There is an open discussion going on here ( [<-ISSUE->] ). Feel free to read through the details and ask questions on that thread ... we would love to here your feedback.
[2017-01-09 20:58:03] <somombo> The PR [<-ISSUE->] fixes this but it doesn't seem to have been reviewed yet by the team
[2017-01-09 21:03:30] <killerspaz> I told you, it's failing because you aren't actually starting boot2linux like the Docker Quickstart Terminal does... all it is, is a simple shell script initializing docker.... i don't use it and have never had any issues getting to docker
[2017-01-09 21:04:02] <killerspaz> docker-machine start default && eval $(docker-machine env).... then i'm set
[2017-01-09 21:04:24] <killerspaz> and I can't see your screenshot, it's too small on my screen and no way to expand it?
[2017-01-09 21:05:01] <killerspaz> somombo: try that combo-command and i'm 99.999999% certain you'll be accessing Docker within seconds
[2017-01-09 21:05:48] <killerspaz> the error isn't saying it can't find the docker binary, which that PR seems to focus on.. it's saying it can't connect to a pipe
[2017-01-09 21:06:07] <somombo> here you go@killerspaz [<-LINK->] 
[2017-01-09 21:06:32] <somombo> you will be able to zoom in if you follow the link
[2017-01-09 21:07:15] <killerspaz> yeah that's the error when docker host isn't running
[2017-01-09 21:07:38] <somombo> as you can see on the left dockerwasrunning
[2017-01-09 21:07:52] <erichermansson> Is it possible to have bridged network using docker?
[2017-01-09 21:08:30] <killerspaz> try the command... guarantee it'll start working
[2017-01-09 21:08:47] <killerspaz> reviewC:\\Program Files\\Docker Toolbox\\start.sh; you'll see it does very little with a ton of error checking
[2017-01-09 21:08:57] <killerspaz> that's whatDocker Quickstart Terminalexecutes
[2017-01-09 21:09:27] <killerspaz> in the end, it does exactly what i said to run
[2017-01-09 21:09:44] <somombo> I know exactly what yourdocker-machine ... evalcommand is doing the problem is you have to re-run that commandeverytimeyou close out of your terminal.. that's not how docker was meant to be.. and the PR fixes that
[2017-01-09 21:11:16] <somombo> evalportion sets the environment variables for that session... transiently .. once session is done you have to run that command again
[2017-01-09 21:11:24] <killerspaz> Mmmmm I\'m not sure I agree with the "not how docker was meant to be".... I WANT it to lose my env vars every time I restart my terminal, so I\'m not working on the wrong machine
[2017-01-09 21:12:20] <killerspaz> the whole concept of docker in general is transient/ephemeral run-time.... to me this is right inline with that mentality.
[2017-01-09 21:14:33] <galvesribeiro> never used docker toolbox or machine...
[2017-01-09 21:14:51] <galvesribeiro> dunno if it is required nowadays with official Docker Inc. support of docker on windows
[2017-01-09 21:15:24] <killerspaz> can you run linux guests with your setup@galvesribeiro?
[2017-01-09 21:15:32] <galvesribeiro> yup
[2017-01-09 21:15:43] <galvesribeiro> Docker for Windows create a vm of MobyLinux on HyperV
[2017-01-09 21:15:48] <galvesribeiro> and you can run linux containers there
[2017-01-09 21:16:09] <somombo> official docker for windows requires hyper-V which breaks your ability to use Virtualbox on the same machine for other things e.g. android dev
[2017-01-09 21:16:10] <galvesribeiro> you just need to switch the client to point to the proper ddaemon
[2017-01-09 21:16:33] <galvesribeiro> it is not a requirement actually
[2017-01-09 21:16:39] <galvesribeiro> you can live without it
[2017-01-09 21:16:46] <killerspaz> doesn't hyperv require windows server?
[2017-01-09 21:16:56] <galvesribeiro> you just wont be able to start linux containers
[2017-01-09 21:17:08] <galvesribeiro> killerspaz: you have it on windows "clients" as well
[2017-01-09 21:17:12] <galvesribeiro> and windows containers as well
[2017-01-09 21:17:25] <galvesribeiro> somombo: btw, I use hyperV for Android simulator as well
[2017-01-09 21:17:53] <galvesribeiro> A LOT faster than VMs from google or the 3rd party ones based on virtual box
[2017-01-09 21:18:21] <somombo> cool.. I much rather not be locked in.. use different tools for different jobs
[2017-01-09 21:18:39] <galvesribeiro>  [<-LINK->] 
[2017-01-09 21:18:54] <galvesribeiro> killerspaz: that make the docker client to connect to the VM
[2017-01-09 21:19:01] <galvesribeiro> but you are not obligated to have it
[2017-01-09 21:19:50] <galvesribeiro>  [<-LINK->] 
[2017-01-09 21:19:54] <galvesribeiro> and like I said, containers and hyper-v are 2 diff things
[2017-01-09 21:21:20] <killerspaz> i can't remember what i did, but i've only ever seen that menu on first install... i've completely uninstalled and killed every registry key I could find, but still doesn't come back on re-install for me.... but honestly, it's working exactly like I expect it to and directly compatible with our linux workflow, so I'm ok with how it is atm
[2017-01-09 21:22:28] <killerspaz> yeah i'm running win10 home, those don't exist for me :/
[2017-01-09 21:22:34] <galvesribeiro> oh yeah
[2017-01-09 21:22:37] <galvesribeiro> forgot to mention
[2017-01-09 21:22:40] <killerspaz> server only
[2017-01-09 21:22:43] <galvesribeiro> windows 10 pro or enterprise
[2017-01-09 21:22:45] <galvesribeiro> no
[2017-01-09 21:23:02] <galvesribeiro> windows 10 works, home SKU isn't supposed to run work/professional stuff :P
[2017-01-09 21:24:03] <killerspaz> interesting... they have an article on msdn on 5/6/2016 that saysWindows 10 Enterprise, Professional, or Education, but another on 7/2/2016 saying it will only work on win8 and server 2012+ .... lame...
[2017-01-09 21:24:17] <killerspaz> anyway, i find it funny that Education somehow has more support than Home :P
[2017-01-09 21:24:19] <somombo> anyhow@killerspazi'm not here to debate toolbox, this is not the right place for this.. Just thought I'd shout out to anybody that's helping maintain the toolbox repo to give the Issue and PR a serious and honest look. I am not the only one who thinks there is something wrong docker-toolbox workflow. So if the outcome of giving it an honest look and discussing how to move forward is a decision that that PR is not the best way to do it and a better way is provided.. then that's great! I'm all for that. We invite you to engage on github.
[2017-01-09 21:24:54] <galvesribeiro>  [<-LINK->] 
[2017-01-09 21:24:59] <somombo> jeffdm: 
[2017-01-09 22:51:32] <NickStefan> docker-compose down && docker-compose build && docker-compose up, i used to be able to pair these and it would only rebuild images when things needed to be. my containers are now being rebuilt from scratch every time. any reason one could think?
[2017-01-09 22:53:35] <NickStefan>  [<-CODE->] used to be, that if i hadnt changed requirements.txt, it would reuse that cache. i have not changed requirements.txt and for some reason its bailing and not using the cache
[2017-01-09 22:54:28] <killerspaz> is your source is changing between builds? or are you clearing any dangling containers at any point?
[2017-01-09 22:55:47] <NickStefan> its rebuilding containers that i have definitely not changed. for example, im changing stuff in a django container, but theres a node container i never touch, and its going through all the npm install bs that usually only happens when the package.json is different (invalidates the build)
[2017-01-09 22:56:21] <killerspaz> looks like cache is actually breaking at step 3; which is very strange
[2017-01-09 22:56:36] <killerspaz> is something else changing the contents of/usr/srcfrom a shared volume?
[2017-01-09 22:57:08] <killerspaz> sub-question, are you volume mounting/usr/srcfrom your host?
[2017-01-09 22:57:42] <NickStefan>  [<-CODE->] 
[2017-01-09 22:58:19] <NickStefan> usr/src is being mounted as a volume
[2017-01-09 22:58:39] <killerspaz> I bet something external is changing it and docker isn't liking that one bit
[2017-01-09 22:58:51] <NickStefan> could it be a log file or something being written from inside that docker?
[2017-01-09 22:59:06] <killerspaz> my guess is it's another container or directly from your host
[2017-01-09 22:59:24] <killerspaz> try building that one image alone a few minutes apart, see if it ever does a cache-bust
[2017-01-09 22:59:35] <killerspaz> if so, it's def your host.... if not, then it has to be another image
[2017-01-09 23:00:43] <killerspaz> either way, I think the result is the fact your/usr/srcis being modified before yourWORKDIR /usr/srcis re-executed, and thus invalidates the layer cache
[2017-01-09 23:00:55] <NickStefan> thats helpful, thanks
[2017-01-09 23:02:27] <killerspaz> honestly it's a wild guess :P
[2017-01-09 23:09:17] <NickStefan> so, ive killed everything. and im just doingdocker-compose build django(single container)
[2017-01-09 23:09:39] <NickStefan> it builds. finishes. dont touch ANY CODE, and rundocker-compose build djangoagain, and it once again invalidates and rebuilds all
[2017-01-09 23:09:46] <NickStefan> must be OS ?
[2017-01-09 23:18:58] <NickStefan> even justdocker build .in the directory repeatedly builds the entire thing. i have nothing else running. not changing any code. any ideas where to look?
[2017-01-09 23:22:46] <NickStefan> how can I debug that WORKDIR /usr/src keeps making a different checksum?
[2017-01-10 00:00:05] <NickStefan> so another dev, same code, not having this problem... so my computer i guess
[2017-01-10 00:23:35] <NickStefan> SOMEONE_IMPORTANT: (lol), the problem was that i was on 1.13.0-rc beta. Rolling back to 1.12.5 stable fixed everything!
[2017-01-10 14:53:37] <j6k4m8> super tempted to change my nick to@SOMEONE_IMPORTANT
[2017-01-10 14:55:53] <galvesribeiro> lol
[2017-01-10 14:56:06] <galvesribeiro> galvesribeiro: /nick SOMEONE_IMPORTANT
[2017-01-10 14:56:09] <galvesribeiro> lol
[2017-01-10 14:56:17] <erichermansson> Anyone know how i run docker with bridged network?
[2017-01-10 21:48:59] <holmser> I've got an interesting issue... I'm running docker containers and the application is reporting significant time skew
[2017-01-10 21:49:32] <holmser> but when I check on both the host and the container using date and hwclock they are both identical and correct
[2017-01-11 04:12:39] <quickeee> Hi , is there any documentation or checklist before moving application into production running in docker?
[2017-01-11 07:06:39] <kschlesselmann> quickeee: Well there are recommendations for production docker daemon setups … regarding to your application: propably the same you had before.
[2017-01-11 10:52:19] <decabyte> Hi all, I've got a question about production environments and upgrades of the docker-engine. I've been managing my docker-compose services using Systemd units however upon upgrade of the docker engine the system doesn't restart the containers. Is there any best practice to follow during the upgrade path?
[2017-01-11 14:30:36] <dragon788> How are you typically starting the containers in the first place? Have you added them to a systemd startup script or you just assume your system will never reboot?
[2017-01-11 14:30:49] <dragon788> decabyte: ^
[2017-01-11 15:42:34] <xiaopeng163> welcome to use this lab [<-LINK->]  
[2017-01-11 17:29:37] <SISheogorath> quickeee: A very useful test: Start your application, write things that should persist, than stop the contaienr, remove it. start a new one an check that your stateful data is still there. There is nothing more annoying than to realize that you mounted your volume to the wrong path ;) after 2 days of use (in my case it was  while staging but have this in a production setup is horror)
[2017-01-11 17:36:26] <galvesribeiro> guys
[2017-01-11 17:37:50] <galvesribeiro> does docker swarm detect network partition?
[2017-01-11 17:38:23] <galvesribeiro> I mean, it is based on Raft, so if 1 node fail to ping, the other nodes will tell that it is dead... ok, that work for the managers but, what about the other nodes?
[2017-01-11 20:23:35] <Aetherix> Hi, I've just created my first Docker image. I've pushed it to Docker Hub. I can pull it from another machine, but I can't see it on the Docker Hub web page. Any ideas?
[2017-01-11 20:27:08] <killerspaz> Might be a batched process, could take a bit?
[2017-01-11 20:28:17] <Aetherix> That would explain it. I'll just keep an eye on it then.   
[2017-01-11 20:31:16] <galvesribeiro> killerspaz: any ideas about my previous question?
[2017-01-11 20:33:51] <killerspaz> I didn't quite understand it
[2017-01-11 20:34:31] <killerspaz> Other nodes should be connecting via host/service name, so the managers should work it out (if I'm understanding correctly)
[2017-01-11 20:34:58] <milanvdmria> I made a docker container with Airflow (which runs on localhost:8080) and I exposed that port. But how can I connect to the localhost inside of the docker and get the 'site' on my chrome?
[2017-01-11 20:36:15] <Aetherix> Did you trydocker run -d -p 8080:8080 <your image>
[2017-01-11 20:38:01] <Aetherix> 8080:8080as in<your chrome port:your docker port>
[2017-01-11 20:38:58] <milanvdmria> Oke, thanks, I couldnt directly find it in the docs.Seems I have some permission error though.docker: Error response from daemon: invalid header field value "oci runtime error: container_linux.go:247: starting container process caused \\"exec: \\\\\\"/entrypoint.sh\\\\\\": permission denied\\"\\n".
[2017-01-11 20:40:22] <milanvdmria> Forgot mychown, nvm :)
[2017-01-11 20:40:52] <Aetherix> Nice! Glad that it works! 
[2017-01-11 20:44:46] <killerspaz> milanvdmria: check out: [<-LINK->] 
[2017-01-11 21:02:39] <milanvdmria> When I do the connect to the exposed port in docker, that is the moment where the entrypoint.sh gets executed right?
[2017-01-11 21:02:58] <milanvdmria> Because I added some echo's in the entrypoint.sh but dont see them printed.
[2017-01-11 21:05:22] <milanvdmria> Oke, I see them when I start bash with the run command.
[2017-01-11 21:09:32] <killerspaz> no, entrypoint is executed the instant the container is ran
[2017-01-11 21:11:46] <killerspaz> I have a question: I have a container mounting a volume and writing to the FS, but gives permission denied... My thought it is has to do with UnionFS? Basically a user is created inside the dockerfile and switched to that user, but on my host that user ID (1000) has limited ACL.... What's the proper solution for this? We don't control the Dockerfile, so chown/chmod in there isn't valid, right now I'm resorting to doing a chown on the host through the volume mount, but I don't like seeing on the host that the owner of the volume is a hardened user.
[2017-01-11 21:16:37] <killerspaz> What is the best practice for this type of ping-pong of user IDs?
[2017-01-11 21:18:29] <dragon788> you can mount a volume as a specific user/UID I believe, but if you don't have control of the Dockerfile it becomes a bit more challenging
[2017-01-11 21:21:24] <killerspaz> no no... i'm mounting the volume, it's owned by my host's logged-in user because .. well.. i made it... but when the container wants to write to it, the UID of the user inside the container is a different UID than my own
[2017-01-11 21:23:18] <dragon788> yeah, typically there is a trick you can perform in the Dockerfile to map the runtime user to your host\'s UID so that the permissions don\'t get mucked up, but if you aren\'t doing an "FROM: Someimage" with your own chown/chmod commands that doesn\'t help much
[2017-01-11 21:23:54] <killerspaz> so say my host user is "spaz", uid = 1005... inside the container it creates a user, uid = 1000.... when it wants to write, the volume is owned by 1005 and fails... permission denied.chown 1000.1000 /path/to/volumefixes the issue
[2017-01-11 21:24:28] <killerspaz> ok, i was afriad of that.... I'll just document it for now, but that kinda blows :/
[2017-01-11 22:20:22] <milanvdmria> In an entryfile, what exactly doesif [ "$1" = "webserver" ] || [ "$1" = "worker" ] || [ "$1" = "scheduler" ] ; thenmean?
[2017-01-11 22:20:36] <milanvdmria> I assume it tests if a certain image is there or something?
[2017-01-11 22:22:34] <killerspaz> if the first argument to the script is any of those strings, then do something
[2017-01-11 22:23:18] <killerspaz> so:entrypoint.sh webserverwould trigger the code following that
[2017-01-11 22:23:25] <milanvdmria> Oke
[2017-01-11 22:23:30] <milanvdmria> Thanks!
[2017-01-11 22:23:33] <killerspaz> np
[2017-01-11 22:23:48] <killerspaz> that's standard bash scripting stuff if you need to google more about it
[2017-01-11 22:24:26] <milanvdmria> Yea, its late here, I completely forgot it was bash so I was googling for docker stuff instead
[2017-01-12 00:42:03] <mingsterism> does anyone know what does this code mean?
[2017-01-12 00:42:16] <mingsterism>  [<-CODE->] 
[2017-01-12 00:47:10] <killerspaz> if the user isn't in the docker group add vagrant to the docker group and restart your shell and runlaunch.shin the process
[2017-01-12 00:47:41] <killerspaz> this is so vagrant can run docker commands without root access
[2017-01-12 00:47:45] <killerspaz> (or sudo)
[2017-01-12 00:48:40] <mingsterism> thanks. whatsnewgrp docker
[2017-01-12 00:48:45] <mingsterism> create a new group?
[2017-01-12 00:49:07] <killerspaz>  [<-LINK->] 
[2017-01-12 00:49:15] <killerspaz> no that will reset the shell
[2017-01-12 00:49:22] <killerspaz> man newgrpin your shell
[2017-01-12 00:50:47] <mingsterism> in the code block above, can i change the name to something else apart fromvagrant
[2017-01-12 00:50:55] <mingsterism> because i dont intend to installvagrant.
[2017-01-12 00:51:20] <killerspaz> well, that code would be useful in something like an environment setup script, not something you'd need to execute regularly
[2017-01-12 00:51:24] <mingsterism> this is the original bash script. i dont seevagrantappear anywhere except for that line
[2017-01-12 00:51:27] <mingsterism>  [<-LINK->] 
[2017-01-12 00:51:53] <mingsterism> it looks likevagrantis just a name to me? dont know if right
[2017-01-12 00:52:06] <killerspaz> The readme saysThe network playground is a Vagrant box...
[2017-01-12 00:52:19] <killerspaz> meaning you're expected to operate within the confines given
[2017-01-12 00:52:21] <mingsterism> yes. its a vagrant box just to load up theos
[2017-01-12 00:52:31] <mingsterism> but i think all the work is done in docker right?
[2017-01-12 00:52:34] <killerspaz> yeah so that script is the launching point of the playground
[2017-01-12 00:52:37] <mingsterism> cos i intend to use digitalocean
[2017-01-12 00:53:08] <killerspaz> the dev is likely using vagrant to orchestrate docker composition
[2017-01-12 00:53:09] <mingsterism> i mean to load up the network, he isnt using vagrant. just purely docker right?
[2017-01-12 00:53:18] <killerspaz> i'm not a vagrant user so i'm uncertain of most of it
[2017-01-12 00:53:29] <mingsterism> oh. do you know how to find it. because vagrant is causing me many headaches
[2017-01-12 00:53:40] <mingsterism> if i can just purely use docker ordocker-machinethat would be awesome
[2017-01-12 00:54:24] <killerspaz> it could be that something else is executing vagrant, i'm uncertain.... don't really plan on reading the source of a project i don't use
[2017-01-12 00:55:17] <mingsterism> totally understand. but actually its just a few files there. if u see the code.
[2017-01-12 00:55:17] <mingsterism>  [<-LINK->] 
[2017-01-12 00:55:36] <killerspaz> there's also this: [<-LINK->] 
[2017-01-12 00:55:37] <mingsterism> i went through  them. it didnt seem like it was using vagrant. but just wasnt too sure.
[2017-01-12 00:56:49] <mingsterism> thanks  :)
[2017-01-12 00:56:52] <mingsterism> didnt see that earlier
[2017-01-12 01:08:06] <mingsterism> how can i create this purely in docker
[2017-01-12 01:08:07] <mingsterism>  [<-LINK->] 
[2017-01-12 02:16:24] <dragon788> You may be able to do it with docker-compose but it might require Adobe extra networking commands
[2017-01-12 11:43:02] <milanvdmria> Currently I have build three images: alpine with postgres, pyspark, and airflow.I would like to connect those three (and execute their entrypoints.sh). But honestly, Im quite confused on how to tackle this problem.
[2017-01-12 12:17:06] <SISheogorath> @milanvdmria you run the containers and now you have 2 options: [<-CODE->]  [<-CODE->] 
[2017-01-12 12:18:10] <Onyx74> hi
[2017-01-12 19:24:07] <graingert> shin- do you know when that will be hitting PyPI?
[2017-01-12 21:22:21] <killerspaz> ok, windows insider preview borked my system, so i just wiped and reinstalled... got docker toolbox again and tried to start up my project... i'm getting:Cannot create container for service eqsyslog: Invalid bind mount spec
[2017-01-12 21:23:05] <killerspaz> oddly enough, i google and find thatCOMPOSE_CONVERT_WINDOWS_PATHSexists... i know i never set that before, is this new?
[2017-01-12 21:23:25] <killerspaz> whether i set it to 0 or 1 it seems to work, but wtf .... why do i need this NOW?
[2017-01-13 10:44:08] <jacobus-brogly> you anyone here
[2017-01-13 10:44:15] <jacobus-brogly> there seems to be aconflict
[2017-01-13 10:44:21] <jacobus-brogly> i have centOS 7.2
[2017-01-13 10:44:37] <jacobus-brogly> I am having these errors
[2017-01-13 10:45:03] <jacobus-brogly> Package docker-engine-selinux.noarch 0:1.12.6-1.el7.centos will be installed--> Processing Conflict: docker-engine-1.12.6-1.el7.centos.x86_64 conflicts docker-io--> Processing Conflict: docker-engine-1.12.6-1.el7.centos.x86_64 conflicts docker--> Processing Conflict: docker-engine-selinux-1.12.6-1.el7.centos.noarch conflicts docker-selinux--> Finished Dependency Resolution
[2017-01-13 10:45:20] <jacobus-brogly> also
[2017-01-13 10:45:33] <jacobus-brogly> why does "dockerd" doesnt exist on CentOS distro?
[2017-01-13 10:46:04] <graingert> anyone know what the timeline for docker-py 2 is ?
[2017-01-13 12:06:17] <jacobus-brogly> docker is a piece of crap, it is failing on CENTOS install
[2017-01-13 12:06:26] <jacobus-brogly> curl -fsSL https://get.docker.com/ | shsudo -E sh -c 'sleep 3; yum -y -q install docker-engine'Error: docker-engine-selinux conflicts with 2:container-selinux-1.10.3-59.el7.centos.x86_64You could try using --skip-broken to work around the problem[1:02]what a pile of shit
[2017-01-13 12:06:45] <jacobus-brogly> can they set up a correct working repo for once?
[2017-01-13 12:31:09] <dragon788> That isn't all Docker's fault, if CentOS has that installed from another package or repository it would fail no matter what Docker does
[2017-01-13 13:03:00] <jacobus-brogly> you didnt catch that is came from the same repo?
[2017-01-13 13:03:31] <jacobus-brogly> the repo is trying to install 2 conflicting packages
[2017-01-13 13:03:57] <jacobus-brogly> its a recent issue btw
[2017-01-13 13:06:29] <jacobus-brogly>  [<-LINK->] 
[2017-01-13 13:06:36] <jacobus-brogly> Seems i am not the only one
[2017-01-13 13:06:53] <jacobus-brogly> why is the repo trying to download 2 packages)) lolz
[2017-01-13 13:07:37] <jacobus-brogly> CentOS is a major distro, you can have this error  flying under the radar
[2017-01-13 14:30:47] <jeud> hi after the docker finish running and exit, what's in the left containers?, what are those left containers intended for ? just history ?
[2017-01-13 14:36:06] <SISheogorath> jeud: you can restart them. check out their logs etc. you don't need to usedocker runto start a container.docker runis just a shortcurt fordocker create && docker start
[2017-01-13 14:40:42] <jeud> SISheogorath: , thanks :)
[2017-01-13 14:40:58] <SISheogorath> You're welcome
[2017-01-13 14:44:38] <jeud> is there any cli commands to show default command of the image ? e.g.ubuntu:/bin/bash
[2017-01-13 15:01:38] <SISheogorath> docker historycan show you some Dockerfile commands of an image
[2017-01-13 15:16:34] <jeud> SISheogorath: , :)
[2017-01-13 15:32:48] <sbbowers__twitter> Hello, whats the correct way to manage keys for downloading source from a private repository with docker ADD or RUN?
[2017-01-13 15:37:44] <jeud> what is the equivalentdocker start <container id>todocker run docker/whalesay cowsay boo, i meant i don't get how to pass the argument when usingdocker start
[2017-01-13 15:41:29] <killerspaz> jacobus-brogly: you do realize that error you keep getting is due to your ignorance of how a package manager works, right?
[2017-01-13 15:42:45] <killerspaz> has nothing to do with Docker, has to do with how your system already has a docker daemon installed.
[2017-01-13 15:43:30] <killerspaz> jeud: check this or something similar out: [<-LINK->] 
[2017-01-13 15:43:47] <killerspaz> i haven\'t found one that\'s "perfect," but it should give you most of the important info
[2017-01-13 15:44:56] <killerspaz> Anyone familiar with this change? I swear I never had that env var.... but now i'm curious why ANY value works?  [<-LINK->] 
[2017-01-13 15:46:42] <jeud> killerspaz: , thanks
[2017-01-13 17:15:45] <dragon788> sbbowers__twitter: I\'d use a runtime volume mount or an environment variable passed in with an API key or equivalent, not sure what the "best practice" is
[2017-01-13 17:16:52] <killerspaz> sbbowers__twitter: we opted to use firewalled private registries to avoid having to worry about auth
[2017-01-13 17:19:19] <dragon788> killerspaz: how did you install Compose on Windows that you got that env-var?
[2017-01-13 17:20:57] <killerspaz> it came packaged with Docker Toolbox
[2017-01-13 17:21:18] <killerspaz> Toolbox 1.12.6
[2017-01-13 17:23:42] <killerspaz> damnit, nowdocker-compose downis throwing python errors :/
[2017-01-13 17:24:53] <killerspaz>  [<-ISSUE->] 
[2017-01-13 17:25:04] <killerspaz> strange that I'm seeing this on a stable build....
[2017-01-13 17:25:27] <killerspaz> apparently means docker daemon can't be reached, but it USED to say explicitly it couldn't....
[2017-01-13 17:34:04] <SISheogorath> jeud: You can also use a build-arg or download your keys from some trusted source and remove it in the same run step. The build arg is the pretty way but I'm not sure how it is placed inside the image so maybe it's secret, maybe not.
[2017-01-13 17:40:52] <killerspaz> i mean usually you have to copy a key, or embed the creds, or do some env vars... all of which end up storing some form of credentials (i.e.,git remote/.gitconfigwill show user/pass ifhttpsprotocol)....
[2017-01-13 17:41:18] <killerspaz> you can create read-only deploy users to alleviate any damage, but your IP is still at stake
[2017-01-13 17:41:29] <killerspaz> IP being intellectual property, not internet protocol addy
[2017-01-13 17:43:45] <SISheogorath> mhm passing credentials as build-arg -> bad idea
[2017-01-13 17:45:03] <SISheogorath> all this secret management is still bad in docker :/ it's sad
[2017-01-13 18:44:04] <killerspaz> So, links are deprecated officially..... how would one go about utilizing an image prebuilt by 3rd party that assumes a service name if links are deprecated?
[2017-01-13 18:45:29] <killerspaz> aaaaand i just founddocker-compose:aliases
[2017-01-13 19:18:41] <killerspaz> has anyone useddocker-registry-web??? Not understanding this config
[2017-01-13 19:18:51] <killerspaz> why have 2 urls?! both pointing to the registry?
[2017-01-13 19:36:03] <dragon788> are you using a bleeding edge version that supports the new trusted binaries facilities?
[2017-01-13 19:41:59] <killerspaz> of what in particular?
[2017-01-13 19:42:10] <killerspaz> bleeding edge version of what, that is
[2017-01-13 19:43:31] <killerspaz> hmm... looks like you have to enable auth if you want to access the registry with TLS... LAME
[2017-01-13 19:44:09] <killerspaz> i have TLS to enable exposure of theregistry, but auth disabled since it's behind a firewall... butdocker-registry-webassumes the only way to enable TLS is to also enable auth :/
[2017-01-13 19:52:44] <dragon788> do you have a link to the config where you are seeing the two URLs?
[2017-01-13 19:55:11] <killerspaz> dragon788: yep, this is their config ref file: [<-LINK->] 
[2017-01-13 19:56:03] <killerspaz> takes like a minute for this damn tomcat instance to fully come up.... i hate java so much
[2017-01-13 19:56:16] <killerspaz> testing this is a royal pain
[2017-01-13 20:11:04] <killerspaz> dragon788:  [<-ISSUE->] hopefully that explains it better
[2017-01-13 20:21:37] <killerspaz> I'm sure i'm missing something simple, i just can't figure out what the hell it is
[2017-01-13 20:40:04] <SISheogorath> yay another Java hater ^^ "Since I hate Java getting friends is so easy" xD
[2017-01-13 20:55:15] <killerspaz> Well, i found [<-LINK->] , which i got up and running in less than 3 minutes... so fuck that other java project :P
[2017-01-13 20:56:02] <killerspaz> it's not the prettiest, but it gets the job done for now... i just want my devs to know what images are available to them
[2017-01-13 20:56:44] <dragon788> lol
[2017-01-13 21:20:30] <galvesribeiro> Hey guys, I saw a curious message here
[2017-01-13 21:20:39] <galvesribeiro> Stopping Container hypervisor based on LXC: (not running).
[2017-01-13 21:21:00] <galvesribeiro>  [<-LINK->] 
[2017-01-13 21:21:31] <galvesribeiro> that happen while updating Bash for Windows here... I wonder if they are eventually giving up that docker VM on windows (for linux containers) and use bash for windows...
[2017-01-13 21:22:50] <killerspaz> i can't use bash for windows until you can write to the linux fs from within windows
[2017-01-13 21:23:00] <killerspaz> too painful otherwise
[2017-01-13 21:23:34] <patrickleet> Hey - I'm trying to figure out how depends_on and healthcheck work in docker-compose 1.10https://github.com/docker/compose/releasesI see it vaguely documented but can't find any examples of how to use it. It says refer to the docs but I can't find docs for 1.10.Can anyone point me in the right direction?I want to use depends_on but wait for the service that I depend on to report as healthly before starting the next service.
[2017-01-13 21:25:30] <patrickleet> I've tried just adding a healthcheck to the dockerfile of the first image, and can verify it is working independently, however, depends_on does not wait for the healthcheck to be valid
[2017-01-13 21:31:46] <galvesribeiro> killerspaz: what you mean? bash for windows has a linux fs...
[2017-01-13 21:54:10] <killerspaz> if you write to it from windows it won't be accessible from LFW/UFW/whatevertf you wanna call it these days
[2017-01-13 21:54:32] <galvesribeiro> yes it
[2017-01-13 21:54:35] <killerspaz> they finally fixed the inotify issues about a month ago, though.. so that's nice
[2017-01-13 21:54:37] <galvesribeiro> there is a mount point
[2017-01-13 21:54:49] <killerspaz> no, that's from linux subspace
[2017-01-13 21:54:51] <killerspaz> not windows
[2017-01-13 21:55:07] <killerspaz> i can't open file explorer and place a file into the linux filesystem's home directory and see it in bash
[2017-01-13 21:55:26] <killerspaz> i can from bash write to the mount into linux though, yes
[2017-01-13 21:55:45] <galvesribeiro> you can put it on the C:\\something that will be available on /mnt/c/something
[2017-01-13 21:55:58] <killerspaz> that's not what i'm referencing
[2017-01-13 21:56:13] <galvesribeiro> you mean write directly to the linux partition... I got it
[2017-01-13 21:56:29] <galvesribeiro> I just don't know why you want to do that if the mount point works
[2017-01-13 21:56:34] <galvesribeiro> I use it all day
[2017-01-13 21:56:43] <killerspaz> i just said... i want to, FROM WINDOWS, WRITE TO LINUX
[2017-01-13 21:57:09] <galvesribeiro> yes, but I don't see why you need that :D
[2017-01-13 21:57:34] <galvesribeiro> you can write on the windows FS and use the file on linux thru the mount point
[2017-01-13 21:57:47] <galvesribeiro> I have linux C++ code in a windows directory
[2017-01-13 21:58:00] <galvesribeiro> which I build on linux but edit the files on windows
[2017-01-13 21:58:39] <killerspaz> it's not integrated enough for daily use imo.... if you wanna jump through hoops be my guest.. i have more important shit to do
[2017-01-13 21:59:01] <killerspaz> but write anything to %localappdata%\\Lxss\\rootfs and you'll never see it in bash
[2017-01-13 21:59:15] <galvesribeiro> yes, you are right, not the ideal
[2017-01-13 21:59:19] <galvesribeiro> but works for me
[2017-01-13 21:59:29] <galvesribeiro> I even call the build from windows
[2017-01-13 21:59:49] <galvesribeiro> bash -c /mnt/c/somepath/myscript.sh
[2017-01-13 21:59:55] <killerspaz> they have it Linux->Windows just great, now they just need the other way around and i'll be all ove rit
[2017-01-13 22:00:12] <killerspaz> can finally get off this horrible git bash
[2017-01-13 22:00:32] <galvesribeiro> yeah they will eventually get there
[2017-01-13 22:00:42] <galvesribeiro> the point is, the idea of bashfor windows is to be a tool
[2017-01-13 22:00:46] <SISheogorath> git bash works nice and since I have vim on windows I can actually edit files :D
[2017-01-13 22:00:47] <galvesribeiro> not a complete OS inside windows
[2017-01-13 22:05:50] <galvesribeiro> anyway, was just a though... in all cases, docker for windows on windows 10, is just a dev tool. Its ok to have a VM hosting linux containers... in production, run in a real Linux, and windows containers on windows... docker is good enough to have a heterogeneous environment
[2017-01-13 22:06:24] <gdeward> any chance someone can take a look at this question:... [<-LINK->] 
[2017-01-13 22:07:17] <gdeward> trying to figure out how to move the context, of a docker-compose file, up to the parent level:
[2017-01-13 22:07:48] <gdeward>  [<-CODE->] 
[2017-01-13 22:36:18] <galvesribeiro> killerspaz: 
[2017-01-13 22:36:29] <galvesribeiro>  [<-LINK->] 
[2017-01-13 22:36:30] <galvesribeiro> they are not that far ;)
[2017-01-13 22:39:26] <galvesribeiro> the client already works fine... only the dockerd which obviously require changes at kernel level
[2017-01-13 22:46:00] <galvesribeiro> killerspaz: there you go: [<-LINK->] 
[2017-01-13 22:46:03] <galvesribeiro> vote there :)
[2017-01-14 03:46:45] <dragon788> with PowerShell for Linux you could probably add the Windows Filesystem as another "PSProvider" for cross system access
[2017-01-14 03:53:32] <galvesribeiro> dragon788: good idea
[2017-01-14 03:54:18] <galvesribeiro> although PS on linux is very unstable yet... and last time I tried on bash for windows it blow up the stdin/out
[2017-01-14 03:55:41] <dragon788> yeah, I think they are also working on the stdin/stdout in conjunction with the OpenSSH native binary for Windows
[2017-01-14 03:56:02] <galvesribeiro> yeah, that is a big win
[2017-01-14 03:56:46] <galvesribeiro> there are multiple libraries that work well today and allow SSH on powershell on windows
[2017-01-14 03:58:58] <dragon788> yeah, the native one that the OpenSSH for Windows team is working on is apparently hoping to go back upstream as well
[2017-01-14 04:00:45] <galvesribeiro> great
[2017-01-14 05:22:22] <ketchupmonkey> Did anyone have any issues running centos in docker? especially when restart services I keep on getting an error.
[2017-01-14 08:46:07] <sabrehagen> How do I set docker to pull from my local registry by default, not check docker.io by default
[2017-01-14 09:08:48] <SISheogorath> sabrehagen:  [<-LINK->] 
[2017-01-14 09:19:24] <Bajix> sudo service docker statusdocker dead but subsys locked
[2017-01-14 09:19:36] <Bajix> So this is a thing… any ideas?
[2017-01-14 10:07:57] <SISheogorath> sounds not really nice :D first idea -> reboot
[2017-01-14 10:08:38] <Bajix> Yea… I just made a new instance, reconfigured my load balancers, and cloudfront instead
[2017-01-14 10:09:04] <Bajix> I think it’s for automating things ;o
[2017-01-14 10:16:18] <SISheogorath> what exactly are you talking about?
[2017-01-14 18:20:06] <dragon788> ketchupmonkey: 
[2017-01-14 18:20:14] <dragon788> typically you don't restart services, you restart containers
[2017-01-14 18:20:47] <dragon788> if you are trying to run a complex multi-service application you need to use something liketinito manage the initialization, because "init" isn\'t running in most containers
[2017-01-14 18:21:04] <dragon788> containers != VMs, so don't try to run a full OS in them
[2017-01-14 20:18:00] <ketchupmonkey> dragon788: oh the reason why i ask is because when i am just troubleshooting an apache service that is serving up my JS app when I use docker exec to see why the node died I was shocked with the error message when I just restarted the service, which I never faced that issue when I am using let's say an ubuntu image
[2017-01-14 20:25:55] <dragon788> were you using systemd in your Ubuntu image as well or was it using Upstart or something else?
[2017-01-14 20:35:58] <ketchupmonkey> i was using the latest ubuntu base image so i believe it should be systemd
[2017-01-14 20:36:48] <ketchupmonkey> I just found it weird why the ubuntu container image would allow me to restart an apache service while a centos:latest won't let me
[2017-01-14 20:46:13] <SISheogorath> ketchupmonkey: containers are more like a big single binary you're running on your server than a VM. (If we speak about how to handle it) so yeah don't try to do things like writing systemd.service files in containers. it's waste of time
[2017-01-15 06:51:51] <sabrehagen> Is it true to say that theswarmimage on docker hub ( [<-LINK->] ) is the old docker swarm, and not 'swarm mode'?
[2017-01-15 13:11:34] <galvesribeiro> sabrehagen: te
[2017-01-15 13:11:42] <galvesribeiro> Yes
[2017-01-16 03:32:44] <sabrehagen> galvesribeiro: thanks
[2017-01-16 03:33:06] <sabrehagen> I keep gettingError response from daemon: Timeout was reached before node was joined. The attempt to join the swarm will continue in the background. Use the "docker info" command to see the current swarm status of your node.when I try and join nodes to my swarm. What could be making them take so long to join?
[2017-01-16 03:34:41] <galvesribeiro> I was never able to get swarm to work
[2017-01-16 03:34:53] <galvesribeiro> The swarm init just stuck and dont do anything
[2017-01-16 03:37:41] <sabrehagen> damn
[2017-01-16 03:39:57] <kinghuang> Do you have all the required ports open and accessible between your nodes?
[2017-01-16 03:40:36] <kinghuang> I have multiple swarms running. Once I got all the ports and stuff set up, they connected without problems.
[2017-01-16 03:42:05] <kinghuang> See [<-LINK->] for the list of ports. Note that 4789 and 7946 are both tcp and udp.
[2017-01-16 03:45:35] <sabrehagen> kinghuang: this is the state i'm in, and not sure how to get out of it: [<-LINK->] 
[2017-01-16 03:47:31] <galvesribeiro> kinghuang: I meant docker for windows on windows 10
[2017-01-16 03:47:50] <kinghuang> Hmm, I'm not very familiar with using docker-machine. But, it looks like the swarm is broken, in any case.
[2017-01-16 03:48:05] <kinghuang> How about forcing manager1 out of swarm mode, and re-initializing it as a manager?
[2017-01-16 03:48:27] <sabrehagen> kinghuang: agreed. will try that now...
[2017-01-16 03:48:40] <kinghuang>  [<-CODE->] 
[2017-01-16 03:50:00] <sabrehagen> kinghuang: my cluster seems to be broken. i keep encountering this: [<-LINK->] 
[2017-01-16 03:50:15] <kinghuang> galvesribeiro: Ah, I haven't tried on Windows 10, either! My server nodes as RHEL 7 VMs. And, I've used Docker for Mac.
[2017-01-16 03:51:42] <kinghuang> sabrehagen: Hmm, manager1 is probably stuck trying to process other swarm commands.
[2017-01-16 04:19:04] <kinghuang> sabrehagen: For what it's worth, I've just downloaded VirtualBox and used docker-machine to create a two-node swarm without problems. Here's a copy of my terminal commands and output. [<-LINK->] 
[2017-01-16 04:42:19] <sabrehagen> kinghuang: thanks for running the experiment. disappointing that mine doesn't work. i deleted all my virtual machines and started a fresh. my current issue is that my workers are not listed in my swarm, however they appear to be added. your workers seem to be listed successfully (yourswarm-2machine). Here's my state: [<-LINK->] 
[2017-01-16 04:59:51] <kinghuang> sabrehagen: That's really weird that it thinks worker1 is already part of the swarm. You're totally sure that $WORKER1_IP is correct? What happens if you leave out the --listen-addr argument?
[2017-01-16 05:09:12] <sabrehagen> kinghuang: Yep, definitely correct. --listen-addr is used when there are multiple networks on the host and it doesn\'t know which one to listen on. I\'ve avoided this by running the command directly within the machine. This gist shows the current state of my system. Worker 1 has attempted to join, leave, then rejoin and it\'s swarm state gets the error "context cancelled". Worker 2 never attempted to leave and it\'s still in a pending state: [<-LINK->] 
[2017-01-16 05:16:11] <kinghuang> sabrehagen: Not sure what to suggest! The only major difference that I can see is you're using Docker 1.12.6, while my test run was using Docker 1.13.0-rc7.
[2017-01-16 05:16:34] <kinghuang> That said, I've never had problems with 1.12.x like this. But, that was on RHEL 7 VMs, not VirtualBox VMs created with docker-machine.
[2017-01-16 05:18:00] <sabrehagen> kinghuang: thanks for the help nonetheless :) where can i get 1.13.0-rc7?
[2017-01-16 05:19:57] <kinghuang> Not sure how it works with docker-machine. That's just what it downloaded for me when I created my first docker-machine machine.
[2017-01-16 05:23:44] <kinghuang> sabrehagen: Sorry, I don't know much about docker-machine! For installs on your own VM, you can get release candidates by installing fromhttps://test.docker.com/. Good luck!
[2017-01-16 09:34:24] <vaskaloidis> Hey I have a bunch of different Docker containers running a bunch of different web apps
[2017-01-16 09:34:50] <vaskaloidis> How do I create a container on 80 that will forward any incoming requests to the corresponding container, based on the Domain in the URL
[2017-01-16 09:35:33] <vaskaloidis> I am trying to configure Traefik, but its been acting annoying - am I going about htis the right way? Nginx config also drove me crazy when I tried it
[2017-01-16 09:51:50] <milanvdmria> I have the following compose to setup Airflow: [<-CODE->] But when I do a docker-compose, I dont see the echos of the entrypoints of those two dockerfiles. How can I execute the entrypoints with a compose (so that the database for examples gets initialized).
[2017-01-16 10:51:00] <milanvdmria> I got it running, had the parameter -d so I couldnt see the output of my entrypoints and therefore thought it was not running.
[2017-01-16 10:51:21] <milanvdmria> Other question, Airflow needs to connect to the docker with postgres.
[2017-01-16 10:51:55] <milanvdmria> Therefore I have to create a jdbc url but I am unsure on how to create that. What is the host for example?
[2017-01-16 12:48:28] <milanvdmria> The host seems to be the name in the docker compose file
[2017-01-16 12:48:37] <milanvdmria> So that is solved too now
[2017-01-16 16:31:16] <Crizstian> Hello community, i want to share one of articles that i wrote at medium, about how to implement a MongoDB replica set using Docker, it will be nice to receive some feedback or contributions.https://medium.com/@cramirez92/how-to-deploy-a-mongodb-replica-set-using-docker-6d0b9ac00e49#.wlcexv47p
[2017-01-16 17:25:16] <galvesribeiro> ok... just got confirmation... Swarm-mode is not available on windows yet (D4W or Windows Server containers)
[2017-01-16 17:25:24] <galvesribeiro> so, I have a question...
[2017-01-16 17:29:07] <galvesribeiro> Is there a way to create a container network in Docker that span multiple nodes/servers?
[2017-01-16 17:29:24] <galvesribeiro> (without using swarm. for example 2 stand alone docker hosts)
[2017-01-16 17:30:05] <kinghuang> galvesribeiro: No, you need swarm mode and overlay networks for that.
[2017-01-16 17:30:19] <galvesribeiro> :(
[2017-01-16 17:31:04] <galvesribeiro> kinghuang: so create a new orchestrator/cluster management is impossible?
[2017-01-16 17:32:24] <kinghuang> Well, you could certainly use other networking tools to create your own VLANs and  stuff. But, to use Docker's native functionality for spanning networks across multiple engines, you'll need Swarm mode.
[2017-01-16 17:33:21] <galvesribeiro> :(
[2017-01-16 17:38:13] <galvesribeiro> that is frustrating :(
[2017-01-16 17:44:06] <galvesribeiro> kinghuang: looks like would need to create a network driver/plugin [<-LINK->] 
[2017-01-16 17:59:48] <jeud> hi when downloading an image what are in the list of this download ?
[2017-01-16 18:02:05] <jeud> i meant, the image is split into multiple pieces or each piece is a commit of the image repository ?
[2017-01-16 18:07:25] <kinghuang> Each item in that list is a layer in the image.
[2017-01-16 18:08:51] <kinghuang> Images are composed of layers. When an image is created from a Dockerfile, each instruction results in a new layer. See [<-LINK->] in Docker Overview.
[2017-01-16 18:09:13] <jeud> thanks@kinghuang:)
[2017-01-16 18:58:50] <diegoaguilar> I trieddocker run --name mongo -d mongo -p 27017:27017to start a mongo container with port 20017 exposed to host
[2017-01-16 18:59:06] <diegoaguilar> however its not shown started whendocker ps
[2017-01-16 19:18:11] <kinghuang> The publish argument is in the wrong place. You've passed-p 27017:27017as a command to the container. So, when the container starts, it tries to run-p 27017:27017instead ofmongodas the command, fails, and exits.
[2017-01-16 19:18:15] <kinghuang> What you want isdocker run --name mongo -d -p 27017:27017 mongo.
[2017-01-16 19:19:10] <kinghuang> That way-p(--publish) is an argument to theruncommand.
[2017-01-16 20:21:14] <milanvdmria> Can a Docker on a host call another docker container on the same host?
[2017-01-16 20:21:44] <milanvdmria> (if they are on the same network due to docker-compose)
[2017-01-16 20:21:56] <kinghuang> milanvdmria: Containers on the same docker network can communicate with each other.
[2017-01-16 20:22:44] <kinghuang> If you don't specify a network for your Docker Compose services, they'll both be on thedefaultnetwork for that compose project.
[2017-01-16 20:23:08] <milanvdmria> kinghuang: Oke, because I find [<-LINK->] quite confusing on what the exact command is to execute adocker runfrom the other container.
[2017-01-16 20:28:41] <kinghuang> milanvdmria: Are you trying to connect to a network created from a Docker Compose project, from a container started outside of compose usingdocker run?
[2017-01-16 20:29:01] <milanvdmria> kinghuang: Inside the docker compose
[2017-01-16 20:29:38] <milanvdmria> kinghuang: So one container of the compose to another one in the compose.
[2017-01-16 20:29:38] <kinghuang> milanvdmria: All the services inside your Docker Compose project belong to the same network, unless you specify otherwise.
[2017-01-16 20:30:21] <milanvdmria> kinghuang: So can you just calldocker runthen? Will it link to the container running in the compose network?
[2017-01-16 20:30:31] <milanvdmria> Or do you need some extra parameters?
[2017-01-16 20:31:05] <kinghuang> No, if you calldocker runto start a container that's not started by Docker Compose, then you will need to specify the network that Docker Compose created to access those services.
[2017-01-16 20:32:05] <kinghuang> Assuming you didn't specify any networks in your Docker Compose file, the network will be named$PROJECT_NAME_default. If you didn't specify a project name, it is based on the name of the directory that your compose file is in.
[2017-01-16 20:33:10] <kinghuang> So, let's say your compose file is in a directory named “myproject”. Then, to run a separate container attached to the network that your Docker Compose services are in, you'd dodocker run ---network myproject_default ….
[2017-01-16 20:36:13] <milanvdmria> kinghuang: Thanks!I found that defining a project name in the compose file is still not possible, is that correct? Because that makes it quite awkward to know this parameter for the network.
[2017-01-16 20:37:36] <kinghuang> milanvdmria: There's a few ways to define the project name.
[2017-01-16 20:38:10] <kinghuang> First, you can pass--project-nameor-pto thedocker-composecommand.
[2017-01-16 20:38:56] <kinghuang> Docker Compose can also pick up the project name from theCOMPOSE_PROJECT_NAMEenvironment variable.
[2017-01-16 20:39:31] <kinghuang> Personally, I set my project name in a.envfile to go with my compose files.
[2017-01-16 20:40:09] <milanvdmria> kinghuang: I like that last one. Can docker compose read this file as input?
[2017-01-16 20:41:20] <kinghuang> milanvdmria: Yes, Docker Compose reads everything in.envand uses it for default environment variables. See “ [<-LINK->] ” for more info.
[2017-01-16 20:41:46] <milanvdmria> Thats cool, thanks!
[2017-01-16 20:43:40] <kinghuang> milanvdmria: You're welcome!
[2017-01-16 21:39:26] <milanvdmria> kinghuang: Ive set everything up to come to the conclusion that you need docker in docker to run adocker runcommand of course.Ive looked around and it seems that this kind of behaviour is discouraged. Is there any workaround to execute adocker runcommand without installing docker in docker?
[2017-01-16 21:40:13] <milanvdmria> You can do it with the-vflag it seems. How would this translate into docker-compose?
[2017-01-16 21:40:40] <kinghuang> milanvdmria: I assume you're talking about callingdocker run …from within a container? What would you like do accomplish with it?
[2017-01-16 21:42:06] <milanvdmria> kinghuang: I would like to run a python script in another container from another docker in the same network.
[2017-01-16 21:43:18] <kinghuang> milanvdmria: Ok, and you want to issue the command to run the Python contain from inside another container?
[2017-01-16 21:43:57] <milanvdmria> kinghuang: Indeed. Something asdocker run --network ... python script.py
[2017-01-16 21:45:43] <kinghuang> milanvdmria: If you really need to do that from inside the container, mounting /var/run/docker.sock into the calling container will work. In the Docker Compose file, you would simply have the following in the service declaration: [<-CODE->] 
[2017-01-16 21:47:14] <kinghuang> Then, the container can communicate with the Docker Engine that it's running on.
[2017-01-16 21:49:38] <milanvdmria> kinghuang: It still gives the error that thedockercommand is not found.
[2017-01-16 21:50:11] <milanvdmria> I only need to add the line to volumes for the docker container I want to run the command in I suppose?
[2017-01-16 21:50:16] <kinghuang> milanvdmria: Well, that just gives you access to the socket. You still need the Docker client installed.
[2017-01-16 21:50:22] <milanvdmria> Ah
[2017-01-16 21:50:50] <milanvdmria> kinghuang: So I still need to install docker on my alpine then.
[2017-01-16 21:52:02] <kinghuang> milanvdmria: Yes. Depending on what your needs and design are, you can also start with the [<-LINK->] . I do this for CI tasks that build Docker images and other Docker operations.
[2017-01-16 21:52:54] <kinghuang> Not the dind tags, but the plain (or git) tags, with/var/run/docker.sockmounted in.
[2017-01-16 21:55:02] <kinghuang> For example: [<-CODE->] 
[2017-01-16 23:23:05] <milanvdmria> kinghuang: How could I solvedial unix /var/run/docker.sock: connect: permission denied.?
[2017-01-16 23:40:38] <kinghuang> milanvdmria: Do you modify the user in your container? If it's not running as root, then you'll need to set permissions as appropriate to your setup so that the user inside your container can access/var/run/docker.sock.
[2017-01-17 05:04:09] <dragon788> milanvdmria: you also need to put the user running docker outside of the container in the docker group or use sudo, this gives them access to that socket
[2017-01-17 05:05:38] <dragon788> If you have a full example of what you are trying to do we may be able to propose a better way
[2017-01-17 09:30:51] <milanvdmria> @dragon788 [<-CODE->]  [<-CODE->] 
[2017-01-17 09:31:32] <milanvdmria> And the airflow one runs under aUSER airflow
[2017-01-17 11:09:25] <jaguarg> hi, I have been trying to figure out an issue for a few days.
[2017-01-17 11:09:50] <jaguarg> my containers is running a service on port 8080
[2017-01-17 11:10:04] <jaguarg> this ports is exposed
[2017-01-17 11:37:13] <jaguarg> a68c91a7977b        d7d996294eb6        "/usr/bin/run_authori"   About a minute ago   Up About a minute   0.0.0.0:8080->8080/tcp, 0.0.0.0:8545->8545/tcp, 8180/tcp, 0.0.0.0:30302->30300/tcp   lonely_cori
[2017-01-17 11:37:38] <jaguarg> but I can't connect to these ports on my host
[2017-01-17 11:37:42] <jaguarg> any idea ?
[2017-01-17 11:38:02] <jaguarg> when I login to the container, I can confirm that the services are running on the ports
[2017-01-17 11:38:12] <jaguarg> but not accessble from the host
[2017-01-17 12:02:58] <milanvdmria>  [<-CODE->] Im trying todocker runfrom inside a docker to another docker container on the network. But I got a permission denied on the socket. I looked around and it seemed that I had to add the user to the docker group.But im using Alpine and it says in my setup it cannot find the docker service.
[2017-01-17 12:32:28] <milanvdmria> I also am looking into [<-LINK->] and check the--privilegedparameter. But it is quite unclear on how to use this to call another container.
[2017-01-17 13:12:43] <marcelmfs> milanvdmria: don't use privileged, you'll have to mount the docker socket from the host into the container, don't do docker in docker, it's best to do docker outside docker as in [<-LINK->] ;)
[2017-01-17 14:48:16] <sdikby> how can i upgrade my docker installation to 1.12.6 ??
[2017-01-17 14:52:26] <marcelmfs> it's stable, so it should be safe to do it
[2017-01-17 16:30:42] <jaguarg> hello is anybody using docker to package parity ?
[2017-01-17 16:33:55] <jaguarg> looks like I can't access the any of the parity ports from the host
[2017-01-17 16:34:10] <jaguarg> when connected to the vm, i can see all is working ok
[2017-01-17 16:34:17] <atul1989> can anyone help me to configure the docker private registry , i am hooked one place , i launched registry 2 container , and service is running , dont know where which config file need to configure , docker tag is working fine , but while push the image into same registry it is giving me following message , dont know what it is ?
[2017-01-17 16:59:31] <killerspaz> atul1989: you didn't post any message
[2017-01-17 17:03:56] <marcelmfs> Has anyone here been able to use hardware acceleration (DRI) in a headless Xvfb container to run protractor tests on WebGL enabled pages?
[2017-01-17 17:05:05] <marcelmfs> I've tried to share the/tmp/.X11-unixsocket,/dev/drmdevices, and enablexhost +forwarding but still getting timeout when trying to target a page with canvas with protractor...
[2017-01-17 17:09:33] <killerspaz> haven't attempted DRI yet, but will need to soon, I'd be interested to see your findings
[2017-01-17 18:44:41] <SISheogorath> sdikby: how did you install docker?
[2017-01-17 18:54:47] <sdikby> SISheogorath: folloying the instrcution in the docker website
[2017-01-17 19:04:18] <SISheogorath> in case you are on linux you should upgrade it using your regular package managment.
[2017-01-17 19:04:46] <SISheogorath> In case you are on windows or osx download the package you used to install and install it over your existing setup
[2017-01-17 19:05:47] <SISheogorath> please notice that upgrading the dockerengine should stop all your currently running containers
[2017-01-17 19:06:20] <SISheogorath> make sure they are up again after an upgrade. In case you did not use the--restartparameter you may have to restart them manually
[2017-01-17 19:18:08] <jacobus-brogly> killerspaz: your ignorance of how a package manager works, right?_thats a retarded remark since there is no docker installed on my system what so ever... yes i checked with yum...has nothing to do with Docker, has to do with how your system already has a docker daemon installed.I explicitly stated docker on centos distro is trying to install 2 conflicting packages, again no docker isntalled; nada!  I commend you for having telepathic abilities so you can see what I have on my machine
[2017-01-17 19:20:49] <SISheogorath> Are you still stugeling with the SELinux rules@jacobus-brogly?
[2017-01-17 19:25:11] <jacobus-brogly> Sheogorath, no i explictly installed  with the package full name  .docker...noarch.x84...
[2017-01-17 19:25:16] <jacobus-brogly> instead of docker-engine
[2017-01-17 19:25:25] <jacobus-brogly> and the  error went away
[2017-01-17 19:28:17] <SISheogorath> I see. Any way to reproduce the error if it\'s not a "personal setup problem" :D As we should file a bug report in case there are conflicts that are based on common setups
[2017-01-18 02:25:53] <galvesribeiro> hey guys
[2017-01-18 02:26:14] <jeffsui> hi what's up
[2017-01-18 02:26:25] <galvesribeiro> is there any doc that describe the structure of docker Monitoring events reported by/eventsremote API?
[2017-01-18 02:26:36] <galvesribeiro> I want the json structure
[2017-01-18 02:26:44] <galvesribeiro> there is just a couple of sample in docs page
[2017-01-18 02:26:52] <galvesribeiro>  [<-LINK->] 
[2017-01-18 02:35:52] <galvesribeiro> anyone?@SISheogorath?
[2017-01-18 02:43:17] <SISheogorath> galvesribeiro: related to [<-ISSUE->] there should be a swagger specs somewhere
[2017-01-18 02:43:48] <galvesribeiro> I found this [<-LINK->] 
[2017-01-18 02:43:54] <galvesribeiro> done if it is just it
[2017-01-18 02:43:55] <SISheogorath> Not sure where ^^ but somewhere it should exist
[2017-01-18 02:45:20] <galvesribeiro> yay
[2017-01-18 02:45:23] <galvesribeiro> indeed it has
[2017-01-18 02:45:23] <galvesribeiro>  [<-LINK->] 
[2017-01-18 02:45:25] <galvesribeiro> :P
[2017-01-18 02:45:28] <galvesribeiro> thanks! >D
[2017-01-18 02:46:30] <SISheogorath> You're welcome
[2017-01-18 02:48:41] <galvesribeiro>  [<-CODE->] 
[2017-01-18 02:48:43] <galvesribeiro> :P
[2017-01-18 02:56:30] <SISheogorath> Ew so muchgetandset
[2017-01-18 02:58:02] <galvesribeiro> hahaha
[2017-01-18 02:58:19] <galvesribeiro> it is called automatic properties
[2017-01-18 02:58:27] <galvesribeiro> to avoid you have backing fields
[2017-01-18 02:58:32] <galvesribeiro> the compiler generate them for you
[2017-01-18 03:06:56] <SISheogorath> I still prefer pointer
[2017-01-18 03:09:52] <galvesribeiro> hahahahah
[2017-01-18 03:09:56] <galvesribeiro> :D
[2017-01-18 06:13:15] <nischay30> hi tell me one thingif i have containers running with docker compose and network is created ..no if i want to link the same network to other docker compose file..can i link?
[2017-01-18 06:13:23] <nischay30> *now
[2017-01-18 06:15:13] <gadget_mnky_twitter> Just define the network as external
[2017-01-18 06:15:18] <gadget_mnky_twitter> In the other compose file
[2017-01-18 06:17:17] <nischay30> thanks a lot
[2017-01-18 06:40:05] <NargiT> Hey guys is there a gitter for hub.docker ? Or I can complain here 
[2017-01-18 06:40:06] <NargiT> ?
[2017-01-18 13:06:24] <cedvdb> Hey, I'm a bit rusty with docker,  I have an instance of cassandra that is in a docker, assuming it's running on port 9042 can I connect from my pc onto it ? [<-CODE->] 
[2017-01-18 13:17:42] <cedvdb> 0.0.0.0:9042->9042/tcp
[2017-01-18 13:22:22] <gadget_mnky_twitter> You should be able to
[2017-01-18 13:22:30] <gadget_mnky_twitter> Oh wait
[2017-01-18 13:22:34] <gadget_mnky_twitter> The port is not bound yet
[2017-01-18 14:02:15] <cedvdb> I'm out, going on holiday, have a nice day
[2017-01-18 14:16:42] <buts101> how to sync php-mysql web application sync on two docker host?
[2017-01-18 15:21:23] <SISheogorath> NargiT: currently there is no channel for Hub. Maybe try the docker forums
[2017-01-18 15:21:53] <SISheogorath> buts101: how would you do it without docker?
[2017-01-18 18:09:12] <JnMik> cedvdb: docker exec -ti <image_id> bash for connect into shell
[2017-01-18 18:09:13] <killerspaz> Using docker registry:2, TLS enabled, I can't seem to get a CURL request to the v2 api to delete images... Server keeps saying not a TLS handshake, but I'm using--cacertwith my curl command... Any ideas?
[2017-01-18 18:10:00] <JnMik> cedvdb: if you wanna check if 9042 is listening on your host, try telnet onto it or just use netstat -tulpn and see if your computer is listening on that port
[2017-01-18 18:15:42] <killerspaz> omfg, i figured it out... i was hitting http, but it requires https... DUHHHH
[2017-01-18 18:19:32] <galvesribeiro> :P
[2017-01-18 18:19:36] <galvesribeiro> that happens :D
[2017-01-18 18:21:34] <killerspaz> alright, still having issues though... i can query the catalog, but can't access any of the actual repositories... also, just hitting /v2 gives me an empty json object, where docs say it should indicate version info and pathing
[2017-01-18 21:56:45] <milanvdmria> From inside a docker container, I calldocker-compose -f file.yml run some-name python script.pymultiple times.I getCannot create container for service some-name: Conflict. The name...as error. Does this mean that I cannot run multipledocker-compose runin parallel?
[2017-01-18 22:16:55] <dragon788> milanvdmria: you want to do a "docker-compose scale" if you want to run more containers iirc
[2017-01-19 01:11:56] <neiled> I want a docker container to build my assets, then I want nginx to server them in another container. Should I use volumes for that? Should I serve the generated assets from a volume?
[2017-01-19 02:41:48] <SISheogorath> If it's a simple build process it's easier to extend the nginx container and build your assets during a docker build process. Reason: it's a lot easier to scale. But if you really want to build it in separated containers, yes, volumes are the way to go.
[2017-01-19 02:42:14] <SISheogorath> neiled: see above
[2017-01-19 02:54:16] <brunocfnba> Hey, I need to run a simple docker compose file with 2 services. I\'m using the entrypoint command in compose and getting this error when I run itinvalid header field value "oci runtime error: container_linux.go:247: starting container process caused \\"exec: \\Anyone faced this already?
[2017-01-19 05:50:02] <atul1989> how can you please let me know how can configure private docker registry first tiem, i has been install and start the registry server on centos 7
[2017-01-19 05:50:58] <nischay30> hello,suppose i have compose file in which there is only one service named dockercloud/hell-world . now i want to do host-mapping for this service.how should i do it?i dont want to make a entry in /etc/hosts manually
[2017-01-19 08:06:34] <SISheogorath> nischay30: Hostmapping? Can you explain what exactly you mean?
[2017-01-19 08:09:20] <SISheogorath> brunocfnba: In most cases this error appears when your entrypoint script orCMDis not intended the right place, Missing +x or has another error like missing Linux file endings if you build the container on Windows. You can may explain or link how you created the image
[2017-01-19 13:58:09] <arputcu> hello i use docker with restart policy always where can i found any history when the docker conatiner was restarted?
[2017-01-19 13:58:20] <arputcu> i only can found the last start time
[2017-01-19 13:58:33] <am0nshi> arputcu: docker ps?
[2017-01-19 13:58:52] <arputcu> am0nshi: docker ps shows me the last start
[2017-01-19 13:58:59] <arputcu> but not all bevore
[2017-01-19 13:59:05] <arputcu> not?
[2017-01-19 14:45:42] <killerspaz> brunocfnba: can you give us more info about how you're starting?
[2017-01-19 14:46:42] <killerspaz> nischay30: check out docker networking, which is built into docker-compose through config: [<-LINK->] and [<-LINK->] 
[2017-01-19 15:56:51] <marcusrios> Hello guys, [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] Anyone have this problem?
[2017-01-19 16:00:25] <killerspaz> marcusrios: just dealt with this last night... did you get the image digest first?
[2017-01-19 16:01:37] <killerspaz> use-vwhen curling to see the header response onGET /v2/<name>/manifests/<tagName>, you'll see aDocker-Content-Digestheader which is the SHA you need to use to delete with
[2017-01-19 16:04:29] <marcusrios> Yes@killerspaz. I run the follow command:curl -i -XGET "http://docker-registry-server:5000/v2/any-app/manifests/tag1"And I using the Docker-Content-Digest in the DELETE command
[2017-01-19 16:04:32] <killerspaz> marcusrios: I made some dumb functions to help me out with it: [<-LINK->] 
[2017-01-19 16:05:31] <killerspaz> also, i think the key isenablednotenable
[2017-01-19 16:06:09] <killerspaz>  [<-CODE->] 
[2017-01-19 16:06:19] <killerspaz> yep.... i was bit by the same thing... change that and restart
[2017-01-19 16:06:31] <killerspaz> fyi, if that's all you're changing, i suggest using the env var(s)
[2017-01-19 16:08:25] <killerspaz> Here's my compose config for npm, bower, docker, and docker web services: [<-LINK->] 
[2017-01-19 16:08:59] <killerspaz> you can see I useREGISTRY_STORAGE_DELETE_ENABLED: "true"
[2017-01-19 16:17:15] <killerspaz> marcusrios: any luck?
[2017-01-19 16:18:41] <marcusrios> killerspaz: Until now nothing.The delete really option was wrong, but even after changing the problem persists
[2017-01-19 16:19:35] <killerspaz> hmmm... not sure why you'd still get that error....
[2017-01-19 17:12:48] <marcusrios> @killerspazProblem solved. [<-CODE->] Thank's for the help :D
[2017-01-19 17:57:30] <thiagopecanha> Hey guys, I am trying to use secret in docker beta 1.13.0-rc7 to share my local ssh-key to my dev container, however I have a few questions about it... as it is something RC, I've not found too much support for that yet.... Do you have any advice or another way to do it? pls...
[2017-01-19 18:01:35] <killerspaz> marcusrios: - I've tried without it, and it was working for me.... so i figured I'd leave it off... still, that's lame to have to accept that header for a DIGEST.
[2017-01-19 18:03:19] <killerspaz> marcusrios: also, that won't delete the images off disk, it just marks it for garbage collection and removes it from the db.. you need to run manual garbage collection to delete them [<-LINK->] 
[2017-01-19 23:55:16] <killerspaz> Has anyone messed with rsyslog in containers? I got it running, but hostnames are some kind of UUID and not the service name I was expecting... curious if anyone knows any tricks
[2017-01-20 00:57:41] <dragon788> I believe there are some options for capturing the output of containers, typically you run the service in the foreground and have it dumped to standard out and then use Docker commands to capture the standard out or attached to that process
[2017-01-20 02:10:19] <killerspaz> i'm trying to think of the best way of gathering all the various information outputs... lshw, lsusb, etc etc....  i was originally thinking rsyslog, but now that seems cumbersome in a way.
[2017-01-20 02:10:57] <killerspaz> i wanted each container to tell me their knowledge to build a profile of the compose
[2017-01-20 02:11:33] <killerspaz> from a sysadmin pov that is.... was thinking of rsyslog to elasticsearch
[2017-01-20 02:54:13] <redhedded1> I wrote this the other day, it is long and filled with code, but may give you some ideas. [<-LINK->] 
[2017-01-20 02:54:53] <redhedded1> it is my first attempt at doing any monitoring/logging management - feedback/corrections are welcome of course
[2017-01-20 03:18:19] <dragon788> killerspaz: that sounds more like reverse engineering the host which is limited by the cgroup permissions granted to containers
[2017-01-20 03:20:25] <killerspaz> dragon788: not sure what you mean fully... but I want to see a profile of the system information; stuff i'm messing with deals a lot with connected devices, data streams through said devices, and logging. So i wanted to capture that from the various containers into a single container that would batch send them to a central system.
[2017-01-20 03:20:32] <dragon788> Since the OS inside the container is really secondary to the application (s) it is hosting all that information doesn't seem incredibly useful, if you really need it a container with puppet or chef would have 'facts' you could examine regarding all that info
[2017-01-20 03:21:09] <killerspaz> well, for example, one container is responsible for all the udev controls, so in theory I would make it responsible for logging necessary information
[2017-01-20 03:22:02] <dragon788> Ahhh, are you doing USB connected devices and other types with a single container sharing to others?
[2017-01-20 03:22:04] <killerspaz> and the other thing i didn't mention is there could be thousands of these deployments, not just one, and internet connectivity isn't guaranteed. So in a common case, data will have to persist locally until it can be brought online.
[2017-01-20 03:22:07] <killerspaz> yeah
[2017-01-20 03:22:22] <killerspaz> lots of crazy volume stuff, misc communcation ports, sub nets, etc etc
[2017-01-20 03:22:32] <killerspaz> wel, crazy to me, maybe not to others
[2017-01-20 03:23:39] <killerspaz> your typical "cloud instance manager" wouldn\'t really cut it for this i don\'t believe
[2017-01-20 03:23:47] <dragon788> Are containers really the best way to do this? I know it's a buzz word technology but sometimes the overhead of architecting that kind of solution kills the advantages of containers vs VMs
[2017-01-20 03:24:04] <killerspaz> well our system is very modular so it actually fits very well imo
[2017-01-20 03:24:23] <killerspaz> easier than building custom images and compiling them every time, we just have services that we swap out
[2017-01-20 03:25:07] <killerspaz> just different rancheros configs for different setups
[2017-01-20 03:48:36] <dragon788> That's pretty slick
[2017-01-20 03:55:37] <killerspaz> i think so, it's been a lot of fun and headaches :P
[2017-01-20 04:29:58] <originalsosa> Has anyone solved the issue with a host with multiple network interfaces being able to route traffic to the docker container? e.g I have eth0 and eth1 serving external traffic that needs to be routed to my container.
[2017-01-20 08:44:34] <nischay30> hii have one issuei created a swarm with two systems.1 is manager and 1 is workernow i have deployed two services1 is deployed on my manager system and other one on my vagrant box which is worker.1 service is occupying 3000 port and other one 8080 port.now when i try to curl the service which is deployed on my system i am able to do that but the other service i am not able to>
[2017-01-20 08:44:44] <nischay30> can anybody explain me why?
[2017-01-20 10:34:48] <argeas> hi all ! anyone has managed to get containers with maven isntalled ... withouth needing to install maven everytime a container starts ?
[2017-01-20 10:39:38] <SISheogorath> originalsosa: As containers are kind of abtraction on userspace level (mostly) and routing is something you do in kernel space it's not the best idea to do it in container. Sure you can do it with docker but it possibly breaks the isolation. I would recommend you the usage of a VM in this case. it's better for isolated kernel operations. If you only need to route traffic directly to your container thant you should use another network driver like macvlan or ipvlan
[2017-01-20 10:40:19] <SISheogorath> nischay30: did you create an overlay network for you application and joined your services in? if not you should do that ;)
[2017-01-20 10:40:45] <SISheogorath> argeas: How about installing maven while your docker build process?
[2017-01-20 12:47:04] <argeas> SISheogorath: do you mean : mvn install ? or the package of maven while I build the docker?
[2017-01-20 13:23:10] <nischay30> SISheogorath: Thanks i figured out later.that was the issue
[2017-01-20 13:23:44] <nischay30> any reference to use the docker events for services through Apis
[2017-01-20 19:10:16] <SISheogorath> argeas: What every you want to install :D
[2017-01-20 19:12:55] <SISheogorath> nischay30: services like? [<-LINK->] ?
[2017-01-21 15:26:39] <galvesribeiro> anyone ever used Kafka in docker?
[2017-01-21 15:27:33] <galvesribeiro> ouch
[2017-01-21 15:27:41] <galvesribeiro> there is no official container :(
[2017-01-21 15:40:50] <buts101> SISheogorath: how then?
[2017-01-21 16:31:44] <erichermansson> Anyone know how to get bridged networking in docker?
[2017-01-21 16:37:12] <SISheogorath> buts101: context?
[2017-01-21 16:38:05] <SISheogorath> erichermansson: What kind of network bridge do you mean? Docker uses a Linux network bridge by default. (in case you are on Linux)
[2017-01-21 16:39:22] <SISheogorath> galvesribeiro: 
[2017-01-21 16:41:07] <galvesribeiro> SISheogorath: ?
[2017-01-21 16:41:13] <SISheogorath> Lol I can't paste into the gitter.im app x.x
[2017-01-21 16:41:20] <galvesribeiro> hhahaha
[2017-01-21 16:41:26] <SISheogorath> I'll send it to you in slack
[2017-01-21 16:41:26] <galvesribeiro> man, gitter and slack are terrible
[2017-01-21 16:41:34] <galvesribeiro> freaking slow and buggy
[2017-01-21 16:41:37] <galvesribeiro> ok ;)
[2017-01-21 16:43:45] <SISheogorath> I prefer IRC but not for docker. As it is located on Freenode and my backlog on Freenode has thousands and thousands of messages :/ I try to avoid opening it
[2017-01-21 16:44:08] <galvesribeiro> hehehe
[2017-01-21 16:44:10] <galvesribeiro> yeah
[2017-01-21 16:44:15] <galvesribeiro> I loved IRC
[2017-01-21 16:44:22] <galvesribeiro> unfortunately people dropped it
[2017-01-21 16:44:23] <galvesribeiro> anyway
[2017-01-21 16:44:28] <galvesribeiro> I got your message there
[2017-01-21 16:44:33] <galvesribeiro> and yes, I saw the spotify one
[2017-01-21 16:44:44] <galvesribeiro> but it has the zookeeper server in it
[2017-01-21 16:44:52] <galvesribeiro> not sure if it is a good approach for production
[2017-01-21 16:44:55] <galvesribeiro> will research on that
[2017-01-21 16:45:08] <galvesribeiro> thanks
[2017-01-21 16:52:12] <erichermansson> SISheogorath: the bridge im talking about is the kind of bridge I use on my KVM. Like the instans can be accessible via my router
[2017-01-21 17:00:02] <kinghuang> galvesribeiro: We use Kafka in Docker. Ended up building our own images for [<-LINK->] , [<-LINK->] , and [<-LINK->] .
[2017-01-21 17:00:43] <galvesribeiro> kinghuang: nice :D so we don't need zookeeper?
[2017-01-21 17:00:48] <kinghuang>  [<-LINK->] has images, too, which we started with. But, they're not very well maintained and too bulky.
[2017-01-21 17:01:53] <kinghuang> galvesribeiro: You still need ZooKeeper. We switched to the [<-LINK->] . It got added recently.
[2017-01-21 17:02:06] <galvesribeiro> ok
[2017-01-21 17:02:08] <galvesribeiro> understood
[2017-01-21 17:02:30] <galvesribeiro> I'm considering add a Stream provider for Orleans usign Kafka
[2017-01-21 17:02:52] <galvesribeiro> today there are abunch  others like Azure Queue services and Azure ServiceBus/EventHub
[2017-01-21 17:03:02] <galvesribeiro> but linux users are asking us to have it
[2017-01-21 17:03:11] <galvesribeiro> and I have a project here that will run on linux
[2017-01-21 17:03:29] <galvesribeiro> so I probably will need Kafka as it is the most used stream solution
[2017-01-21 17:03:56] <galvesribeiro> just considering that it needs a lot of things to get to work
[2017-01-21 17:04:11] <galvesribeiro> too much moving parts :D
[2017-01-21 17:05:06] <kinghuang> galvesribeiro: Cool. It's working well for us deployed as a stack on Docker (swarm mode). We're mainly using it for stream data out of PostgreSQL with [<-LINK->] right now. We'll be doing more development in the upcoming months.
[2017-01-21 17:06:00] <galvesribeiro> nice! thanks@kinghuang, will have a look on that :D
[2017-01-21 17:07:01] <kinghuang> We've got our own image for bottledwater, too. It's being migrated from our private GitLab server to GitHub and Docker Hub next week.
[2017-01-21 17:17:42] <galvesribeiro> kinghuang: I'm new on kafka and ZK, so as much as a read, I have the feeling that its performance and resiliecen relytoo muchon ZK...
[2017-01-22 17:25:39] <w0rldart> Hey guys! I have created a Swarm (1 manager, 3 workers) on DigitalOcean, each of 512mb
[2017-01-22 17:25:58] <w0rldart> Now, I was wondering what's best in terms of deploying an image to production
[2017-01-22 17:26:18] <w0rldart> this Docker image, is built to handle multiple sites
[2017-01-22 17:26:27] <w0rldart> this one exactly [<-LINK->] 
[2017-01-22 17:26:56] <w0rldart> now, so far I have been reading that it's best to deploy one container per app
[2017-01-22 17:27:14] <w0rldart> under what case I would deploy one container that can serve multiple apps?
[2017-01-22 18:52:58] <SISheogorath> @w0rldart There should be no case where you deploy multiple apps per container. But there are some images out there who does it. Reason for this is that those images are more or less a bootstrap script for a virtual machine. Not really good. But very simple to build.I took a short look at the side and I'm not sure if it is a good idea to use it as they describe. For example I would place one container per wordpress side using the official wordpress image and also let TLS handled by an API driven Reverse proxy like Traefik. So you never run into a problem with certificates and you can really microservice it.By the way: Another important benefit from one Site per container is that you can create backups by simple snapshot the volume. And if you have to restore a blog you can simple take a snapshot, boot your database and blog up again from that snapshotted volume and everything is fine. While you have to run ugly backup scripts etc. when you have all blogs in a single database as you run a mutli-site setup.
[2017-01-22 18:55:40] <galvesribeiro> I just realized that docker for Mac is a VM as well...
[2017-01-22 18:55:58] <galvesribeiro> once were VirtualBox, now on 1.13 it is HyperKit
[2017-01-22 18:56:03] <galvesribeiro> still a VM
[2017-01-22 19:29:19] <w0rldart> SISheogorath: fantastic explanation! Thank you so much
[2017-01-22 19:29:22] <w0rldart> I thought so too
[2017-01-22 19:29:41] <w0rldart> but it just gets confusing with people doing so many alternatives
[2017-01-22 19:31:02] <w0rldart> Question is though, knowing that Docker Swarm already does some load balancing, should I look into additional load balancing for Nginx via HaProxy?
[2017-01-22 19:32:55] <SISheogorath> We don't do additional load balancing. You have x Instances of you reverse proxy and X instances of your service. Trafik itself handles the traffic than and/or  if you use nginx you can simply address the service you want to use. For short therm connections it's not a problem
[2017-01-22 19:33:53] <SISheogorath> if we talk about long therm connections with heavy resource usage you can start writing custom load banancing or scale your service because right now the L4-LB in swarm mode only does RR over all tasks
[2017-01-22 19:36:00] <w0rldart> Sorry, would you mind defining L4  and RR please? I have not seen those terminologies before
[2017-01-22 19:38:26] <SISheogorath> L4 := Layer 4 (referring to the ISO/OSI model in therms of protocols TCP/UDP)RR := Round Robin
[2017-01-22 19:38:42] <w0rldart> oh right! Thank you  very much for your help
[2017-01-22 19:39:17] <w0rldart> going to stalk you for a bit on github now 
[2017-01-22 19:39:45] <SISheogorath> Further information: L4 -> [<-LINK->] RR-> [<-LINK->] 
[2017-01-22 19:40:03] <SISheogorath> Feel free to do that and take a stop at my blog :D
[2017-01-23 00:29:40] <w0rldart> thanks@SISheogorathvery useful information
[2017-01-23 00:30:56] <w0rldart> What is the way to deploy my local volumes for my project (wordpress and mysql) to my swarm? Any thoughts guys?
[2017-01-23 00:33:05] <w0rldart> I am working with this docker-composer.yml
[2017-01-23 00:33:08] <w0rldart>  [<-LINK->] 
[2017-01-23 00:48:39] <w0rldart> Looking into Flocker... seems that, that might be the best solutions so far
[2017-01-23 01:10:02] <SISheogorath> depending on the size of your project and where you set it up you can also user glusterfs. [<-LINK->] 
[2017-01-23 02:00:06] <w0rldart> glusterfs is no longer maintained [<-LINK->] 
[2017-01-23 02:01:11] <w0rldart> "UNMAINTAINED: This library is not maintained anymore. Fork it, copy it or do what you please the the code, but this repository won\'t get updates and fixes."
[2017-01-23 02:02:56] <w0rldart> weird because the article you share is from January 7, 2017 whilst GlusterFS repo hadn't had any updates since 6 months ago
[2017-01-23 02:55:10] <SISheogorath> glusterfs itself is still maintained. the docker glusterfs driver you linked maybe not
[2017-01-23 02:56:11] <SISheogorath> In my project where I used this glusterfs setup we mounted it withbinddriver and have the glusterfs volumes itself mounted on all nodes directly
[2017-01-23 02:57:04] <SISheogorath> And you should check the network for the project you linked: [<-LINK->] 
[2017-01-23 02:57:12] <SISheogorath> there are some maintained forks ^^
[2017-01-23 02:58:10] <SISheogorath> But currently flocker is hyped so may use flocker :D haven't tried it right now :X
[2017-01-23 03:17:43] <w0rldart> Flocker is shutting down 
[2017-01-23 03:17:45] <w0rldart>  [<-LINK->] 
[2017-01-23 03:33:21] <w0rldart> What do you think is best, a generic volume called mysql (as an example) of 10gb where all the databases live, or a volume per database?
[2017-01-23 03:33:40] <w0rldart> problem with a volume per database is that I'd might end up with a lot of volumes
[2017-01-23 03:57:16] <SISheogorath> I would recommend you one container per database. which should also result in one volume per database. As mentioned that's a good for multiple reasons. I menioned backups above but there is also scalability, security, etc. you should try to isolate your services as much as you can in order to prevent bad effects and simplify your further way.
[2017-01-23 03:59:03] <w0rldart> Fair point
[2017-01-23 03:59:05] <w0rldart> Thank you
[2017-01-23 04:01:43] <SISheogorath> btw thanks for following me on Twitter ;)
[2017-01-23 04:04:37] <w0rldart> *github :D
[2017-01-23 04:05:00] <w0rldart> twitter now too
[2017-01-23 04:05:01] <w0rldart> hah
[2017-01-23 04:05:59] <SISheogorath> Oh I missread it :D it was another alex xD
[2017-01-23 04:06:26] <w0rldart> Alright, so what I am going to do next (after a bit of sleep) is to get my self a volume on Digital Ocean on AWS EBS where I can push my volumes, and that way have everything nicely in sync
[2017-01-23 04:06:49] <w0rldart>  [<-LINK->] 
[2017-01-23 04:06:56] <w0rldart> if you didn't know about it
[2017-01-23 04:07:17] <w0rldart> and they try and run a docker-composer up on the swarm manager
[2017-01-23 04:07:28] <w0rldart> and see whether all hell breaks loose or not
[2017-01-23 04:26:29] <SISheogorath> :D Most of the time I read "don\'t use cloud storage providers" no further explaination but I read it multiple times not :D Maybe they are too expensive or they do other crazy stuff ^^ I can refer to myself and run my backups using snapshorts of my volumes so using cloud storage not sure hot it\'ll end
[2017-01-23 05:03:12] <vigneshchalapathy> can anyone tell me how to edit source code of project deployed in docker
[2017-01-23 05:03:23] <vigneshchalapathy> Operatin system windows
[2017-01-23 05:19:40] <soapoperator> Hello, i am progressing step by step with docker, i successeed to run an httpd container. Then i try to run php:7.1.0-apache... it works well for html but not for php?phpinfo() was empty... How explain that?When i run the container which kind of command i have to run?http-foregrounddoes have any sens?
[2017-01-23 05:20:55] <SISheogorath> @vigneshchalapathy So you have this project you want to modify? (moved from private back to channel) [<-CODE->] 
[2017-01-23 05:24:56] <vigneshchalapathy> I dont want it in docker.I just want to edit the source code of [<-LINK->] that is available through docker.
[2017-01-23 05:25:15] <SISheogorath>  [<-CODE->]  [<-CODE->] 
[2017-01-23 05:26:07] <SISheogorath> vigneshchalapathy: you linked the sourcecode... If you don't want to do anything in docker this channel is the wrong place to ask
[2017-01-23 05:26:43] <vigneshchalapathy> sheogorath: yeah ok
[2017-01-23 05:26:57] <SISheogorath> mail the developer or anything else. It's provided by GPLv3 so it's open source and you can change what every you want as long as you republicate your changes
[2017-01-23 05:27:14] <SISheogorath> And name the authors
[2017-01-23 05:27:22] <vigneshchalapathy> But i am asking  how to use docker as a development environent
[2017-01-23 05:27:37] <vigneshchalapathy> environment
[2017-01-23 05:27:45] <vigneshchalapathy> in windows
[2017-01-23 05:27:57] <SISheogorath> well, do your changes, build the container, check if it works. Same game like everywhere else
[2017-01-23 05:28:17] <qiyue49> install windows toolbox
[2017-01-23 05:28:29] <vigneshchalapathy> ok
[2017-01-23 05:28:37] <SISheogorath> but I should mention that their Dockerfile is not the best for using it in a development environment
[2017-01-23 05:29:10] <SISheogorath> You can also use Docker for Windows. Depends your way to work
[2017-01-23 05:29:49] <vigneshchalapathy> ok thank you
[2017-01-23 05:32:23] <vigneshchalapathy> sheogorath: where can i find docker project's source code
[2017-01-23 05:36:42] <SISheogorath> Depending on what exactly you're searching for under the docker organisation on github: [<-LINK->] 
[2017-01-23 05:38:39] <vigneshchalapathy> No,I have deployed a project in docker.where can i find the sourcecode of the project deployed in docker
[2017-01-23 05:39:24] <vigneshchalapathy> /mnt/sda1/var/lib/docker/containers/f5bc5e550b7d146b09ebcc573b342b1e61a7be545868ef088ccc0b320ba
[2017-01-23 05:41:03] <vigneshchalapathy> even i was not able to reach the above directory
[2017-01-23 05:44:21] <SISheogorath> where ever you copied it into the container. Please notice that the containers itself are using layered file systems so you can't see it directly as long as the file system is not mounted. Easiest way  to mount it: Run the container and inside the container an sh instance.
[2017-01-23 05:47:22] <SISheogorath> may want to read [<-LINK->] 
[2017-01-23 05:47:56] <SISheogorath> In order to learn how docker handles files in its file system
[2017-01-23 05:58:47] <vigneshchalapathy> thank you
[2017-01-23 05:58:51] <vigneshchalapathy> will see it
[2017-01-23 06:28:24] <soapoperator> SISheogorath: thank you for the answer. i change right of my file and it seems to work now (?). If i want to enable mod_rewrite, the better practice if to run the commandea2enmod rewriteat start or to modify the container with terminal?
[2017-01-23 06:31:15] <SISheogorath> I personally would extend the container. But you can do it also by running it at startup. Depends on what works better for you. In case you extend the container (means you run it during build process) you can also copy the sources of you application in there. That helps to create a real and useful container application. If you already do it. Place it in the container build process.
[2017-01-23 09:23:29] <matglas86_twitter> Hi there. I have a question about docker compose. I want to assign a new memory limit to a container but on restart it does not propogate from my adjusted compose file to the container. Is there a way to force that without throwing away the container?
[2017-01-23 09:24:06] <SISheogorath> docker update<-- ?
[2017-01-23 09:24:51] <matglas86_twitter> but that does not work with compose does it?
[2017-01-23 09:27:11] <matglas86_twitter> ooh wait I had to use docker-compose up
[2017-01-23 09:27:35] <matglas86_twitter> But it did recreate the container :(
[2017-01-23 09:27:41] <matglas86_twitter> I hoped it did not
[2017-01-23 09:33:01] <SISheogorath> in regular that's what docker compose do if something changed
[2017-01-23 09:33:28] <SISheogorath> you should change your setup if it is a problem when your container gets destroyed
[2017-01-23 09:41:20] <matglas86_twitter> Thanks. I understand now. Fortunately all data is stored outside the container :)
[2017-01-23 11:45:29] <nischay30> HIi am using docker 1.13 in debian and created a swarm of 3 machines.now when i type 'docker events' it gives me events for a particular nodei want to get all events on the manager node of the swarm.so any suggestions?
[2017-01-23 12:19:02] <nischay30> ??
[2017-01-23 12:50:06] <huangyanxiong01>  [<-CODE->] hello every one,how fix it
[2017-01-23 12:52:16] <ImFlog> Hello,vossibility-stack docker deploy  --bundle-file vossibilitystack.dab YOUR_STACK_NAME
[2017-01-23 12:52:46] <ImFlog> The stack name argument is missing in your last line
[2017-01-23 12:59:28] <huangyanxiong01> thank you
[2017-01-23 13:00:59] <huangyanxiong01> Deployment stack Specifies the name
[2017-01-23 17:03:22] <Crizstian> Hello, this week i want to share with community the first chapter of the series "Build a NodeJS cinema microservice", that i wrote @medium, it would be great some feedback or contributions.https://medium.com/@cramirez92/build-a-nodejs-cinema-microservice-and-deploying-it-with-docker-part-1-7e28e25bfa8b#.4nat33ucy
[2017-01-23 19:42:47] <smahi> Hi,I have a dockerfile that throws an error at build time`FROM node:6.9MAINTAINER ABESSE SMAHIRUN groupadd -r  nodejs \\    &&  useradd -m -r -g nodejs nodejsUSER nodejsRUN mkdir -p /home/nodejs/appRUN mkdir -p /home/nodejs/app/clientCOPY package.json /home/nodejs/appCOPY client/package.json /home/nodejs/app/clientCOPY . /home/nodejs/appWORKDIR /home/nodejs/appRUN npm install --productionWORKDIR /home/nodejs/app/clientRUN npm install --productionRUN npm build:prodWORKDIR /home/nodejs/appEXPOSE 3001CMD ["node", "index.js"]`The log output`npm ERR! Linux 4.9.4-mobynpm ERR! argv "/usr/local/bin/node" "/usr/local/bin/npm" "install" "--production"npm ERR! node v6.9.1npm ERR! npm  v3.10.8npm ERR! path /home/nodejs/app/clientnpm ERR! code EACCESnpm ERR! errno -13npm ERR! syscall accessnpm ERR! Error: EACCES: permission denied, access \'/home/nodejs/app/client\'npm ERR!     at Error (native)npm ERR!  { Error: EACCES: permission denied, access \'/home/nodejs/app/client\'npm ERR!     at Error (native)npm ERR!   errno: -13,npm ERR!   code: \'EACCES\',npm ERR!   syscall: \'access\',npm ERR!   path: \'/home/nodejs/app/client\' }npm ERR!npm ERR! Please try running this command again as root/Administrator.npm ERR! Linux 4.9.4-mobynpm ERR! argv "/usr/local/bin/node" "/usr/local/bin/npm" "install" "--production"npm ERR! node v6.9.1npm ERR! npm  v3.10.8npm ERR! path npm-debug.log.3370068000npm ERR! code EACCESnpm ERR! errno -13npm ERR! syscall opennpm ERR! Error: EACCES: permission denied, open \'npm-debug.log.3370068000\'npm ERR!     at Error (native)npm ERR!  { Error: EACCES: permission denied, open \'npm-debug.log.3370068000\'npm ERR!     at Error (native)npm ERR!   errno: -13,npm ERR!   code: \'EACCES\',npm ERR!   syscall: \'open\',npm ERR!   path: \'npm-debug.log.3370068000\' }npm ERR!npm ERR! Please try running this command again as root/Administrator.npm ERR! Please include the following file with any support request:npm ERR!     /home/nodejs/app/client/npm-debug.logThe command \'/bin/sh -c npm install --production\' returned a non-zero code: 243`What is wrong with my Dockerfile ? did i miss something ?
[2017-01-23 19:44:01] <rightisleft> Whats the best way to persist a docker log file to disk?
[2017-01-23 19:44:24] <rightisleft> If i have 6 containers and i just want to be able to cat / grep the historical data
[2017-01-23 19:58:50] <soapoperator> i try to run a simple container with docker-compose withphp:7.1-apache.Unfortunatly when i connect tohttp://0.0.0.0:10003/, i get a 403 error. I notice my volume are/usr/local/apache2/htdocs:rw. Is there a way to solve this right issue?
[2017-01-24 00:03:40] <SISheogorath> soapoperator: Check that the user running the container can read the file (means the user inside the container)
[2017-01-24 00:04:52] <SISheogorath> rightisleft: You can use a logging driver to send the logs to a central logging instance or usedocker logsinstead of cat
[2017-01-24 00:06:40] <SISheogorath> smahi: move theUSERstatement behind your run statement and it works.USERworks likesuand all following commands running as the specified user
[2017-01-24 00:11:49] <SISheogorath> Crizstian: Nice article! Some hints for your Dockerfile:
[2017-01-24 00:12:31] <SISheogorath> Use node:7.2.0-alpine (didn't check but should be there)
[2017-01-24 00:13:18] <SISheogorath> And 2. Move the NPM Install part directly behind your copy process of the package.json
[2017-01-24 00:15:19] <SISheogorath> And 3. Create the user in yourRUNstatement where you do thechownminimizes the
[2017-01-24 02:02:56] <overstart> Is there a client for docker registry  http api v2 ?
[2017-01-24 02:06:44] <SISheogorath> overstart: what kind of "client" do you mean? something like a cli to perform things?
[2017-01-24 02:08:33] <overstart> cli is ok . but a gui app is better.
[2017-01-24 02:15:35] <SISheogorath>  [<-LINK->] or [<-LINK->] 
[2017-01-24 02:15:48] <SISheogorath> I guess the first one is better because I saw more recent commits :D
[2017-01-24 02:17:45] <overstart> Nice, that is what I want. Tks!  :D
[2017-01-24 02:23:47] <SISheogorath> You're welcome
[2017-01-24 07:56:00] <soapoperator> SISheogorath: thank you for the answer.  It was a misconfiguration with the volumes.
[2017-01-24 07:58:18] <smahi> soapoperator: do i have to putUSER nodejsbeforeCMD ["node", "index.js"]?
[2017-01-24 08:37:15] <SISheogorath> yes
[2017-01-24 08:59:04] <smahi> soapoperator: it works Thank you very much
[2017-01-24 10:43:25] <4406arthur> hi, is there have diff between docker-compose[entrypoint, command] , dockerfile [ENTRYPOINT, CMD] ?
[2017-01-24 12:25:09] <nischay30> hi i am using dockerode library fro nodejsbut i am not able to get the expected result from docker.getEvents function of that library.so anyone can tell me how to get that function working
[2017-01-24 12:33:37] <argeas> hi all !
[2017-01-24 12:33:59] <argeas> does anyone now the default location of where maven depndencies get install in container ?
[2017-01-24 14:45:08] <dragon788> The Maven cache is in your users home directory in a folder named m2 I think,~/.m2
[2017-01-24 16:27:26] <killerspaz> 4406arthur: docker compose overrides the dockerfile
[2017-01-24 16:28:56] <killerspaz> overstart: @SISheogorathI use [<-LINK->] .... it doesn't support deleting (probably never will)... I might switch to Portus eventually, but that required more work than i cared to deal with
[2017-01-24 16:29:54] <killerspaz> Here's my compose config for npm, bower, docker, and docker web services: http://pastebin.com/nLXjumgR
[2017-01-24 20:16:28] <rightisleft> Howdy - if the trailing values on a run command are the following, how do i convert them to docker compose:    syslog+tls://logs.papertrailapp.com:55555
[2017-01-24 20:16:29] <rightisleft> from [<-LINK->] 
[2017-01-24 20:16:55] <rightisleft> is that a logging option? i dont understand the syntax
[2017-01-24 20:19:58] <killerspaz> rightisleft:  [<-LINK->] 
[2017-01-24 20:20:16] <killerspaz>  [<-LINK->] 
[2017-01-24 20:20:24] <killerspaz> ENTRYPOINT ["/bin/logspout"]
[2017-01-24 20:23:31] <rightisleft> so they are args passed to the entry point - got it
[2017-01-24 20:23:33] <rightisleft> thx!
[2017-01-24 20:28:35] <killerspaz> yep, np
[2017-01-24 20:50:47] <rightisleft> awesome - logspout is exactly what i wanted
[2017-01-24 20:51:07] <rightisleft> ive been going back and forth on splunk/elk/graylog/ etc
[2017-01-24 20:51:28] <rightisleft> and papertrail is a stupid simple endpoint for now
[2017-01-24 20:51:46] <rightisleft> anyone have a good container that mimcs papertrail/syslog functionality?
[2017-01-24 20:52:10] <rightisleft> cloud services are not an option for us
[2017-01-24 21:43:00] <w0rldart> Hey guys!
[2017-01-24 21:43:04] <w0rldart> Quick question
[2017-01-24 21:43:17] <w0rldart> Having created a Swarm from another machine of mine
[2017-01-24 21:43:27] <w0rldart> at DigitalOcean
[2017-01-24 21:43:40] <w0rldart> how can I list them on my other machine?
[2017-01-24 21:44:04] <w0rldart> so, doingdocker-machine lson machine 1 will list all the machines I have created
[2017-01-24 21:44:18] <w0rldart> but doing that onmachine 2will list nothing
[2017-01-25 02:53:50] <4406arthur> hi , does any one meet this problem,In docker-compose(version3, swarm mode )  use  image from private repo on dockerhubdocker daemon response as above:unable to pin image xxx/xxx to digest: errors:denied: requested access to the resource is deniedunauthorized: authentication requiredso is there have any options to solve this problem ?
[2017-01-25 05:45:03] <SeanSassenrath> Hi everyone! Does anyone have experience with the nginx-proxy image by jwilder? [<-CODE->] Any thoughts would be greatly appreciated!
[2017-01-25 12:40:55] <SISheogorath> 4406arthur: actually yes. I met that issue without compose but the service was starting and worked so I ignored it :X
[2017-01-25 12:43:47] <SISheogorath> SeanSassenrath: rewrite and proxy pass in the same statement? Sounds like your server answers before it passes the request? (guess) I really prefer Traefik as reverse proxy these days
[2017-01-25 14:42:31] <driverpt> Hello guys. Quick question, how do i configure Docker Daemon so that docker-compose uses by default our custom Bridge ?
[2017-01-25 14:42:44] <driverpt> we changed the Default Bridge CIDR so it doesn't conflict with out Private Network IP's
[2017-01-25 14:43:06] <driverpt> but Docker Compose is creating it's own Network with the Default Docker bridge settings
[2017-01-25 16:16:38] <Thoughtscape2014> hey guys anyone there?
[2017-01-25 17:22:13] <killerspaz> rightisleft: what exactly are you trying to do? I have rsyslog up and running for all my containers (distributed clusters on physical boxes as a product)
[2017-01-25 17:22:34] <killerspaz> each system has a rsyslog "server," all other containers are "clients" that log to the server
[2017-01-25 19:11:48] <SISheogorath> Thoughtscape2014: If you check the list to your right. What do you think? Are 3179 people "anyone"?
[2017-01-25 22:28:13] <killerspaz> anyone have any experience with nodejs hanging immediately if volume mounting/dev?
[2017-01-25 22:48:40] <killerspaz> aaaactually i realized i didn't need it, and in my mind I think it isn't working because /dev/{stdin,stdout} do not exist since it's an empty volume created.....
[2017-01-26 02:19:42] <SeanSassenrath> SISheogorath: Thanks! Rewrite got left in by accident. Just can't seem to get location to do anything :/
[2017-01-26 04:08:25] <buts101> any tutorial on docker swarm to setup web app in two host with web load balancer and two database (replica) on those two host/
[2017-01-26 04:44:59] <SISheogorath> buts101: Currently I don't know any, but it love it to tell you that I'm working on something like that :)
[2017-01-26 15:30:49] <w0rldart> Hey guys, quick question! [<-CODE->]  [<-CODE->] 
[2017-01-26 19:29:20] <killerspaz> Is there a way to add dns entries on an external service in a docker-compose?  I want my containers to always access the host as "healthSystem" (or something similar), but the real ip/hostname is facaded by docker
[2017-01-26 21:02:10] <killerspaz> damn gitter was down
[2017-01-26 21:02:24] <killerspaz> ok, i think i found what i needed: [<-LINK->] 
[2017-01-26 21:03:07] <killerspaz> i wish it was available on the network level rather than on the service level :/
[2017-01-26 21:05:01] <killerspaz> unless i'm missing something? Seems like having to add an extra_host to every service is kinda lame
[2017-01-26 21:22:47] <SISheogorath> killerspaz:  [<-LINK->] <----aux-address? It's mainly to exclude addresses iirc but maybe it works with external hosts too :X
[2017-01-26 21:25:11] <killerspaz> but is there any guarantee there's a 1 to 1 mapping of these flags for docker-compose?
[2017-01-26 21:28:29] <killerspaz> i.e., [<-CODE->] 
[2017-01-26 21:32:51] <SISheogorath> doesn't really looks like :/ Another reason for not using docker compose :X
[2017-01-26 21:33:52] <SISheogorath> wait there it is: [<-LINK->] 
[2017-01-26 21:34:00] <killerspaz> what's the alternative? writing a bunch of scripts by hand?
[2017-01-26 21:34:12] <SISheogorath> I write systemd files :D
[2017-01-26 21:34:28] <SISheogorath> with a start command with many many arguments ^^
[2017-01-26 21:35:18] <killerspaz>  [<-CODE->] lol
[2017-01-26 21:35:32] <killerspaz> gonna give it a whirl
[2017-01-26 21:36:39] <killerspaz> actually config is an array, so even slightly funkier: [<-CODE->] 
[2017-01-26 21:40:27] <killerspaz> i must have butchered the syntax cuz it keeps failing....
[2017-01-26 21:40:58] <killerspaz> i guess i'm having a hard time understanding is the ipam config a top-level, or under a network?
[2017-01-26 21:44:15] <killerspaz>  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2017-01-26 21:58:07] <killerspaz> SISheogorath: yeah don't think that'll suffice... apparently any defined hosts there have to be within the subnet
[2017-01-26 21:58:59] <killerspaz> AND ihaveto define a subnet, which isn't ideal in my situation
[2017-01-26 23:18:14] <SISheogorath> I'm even not sure what you need this for :X there is dns outside ^^
[2017-01-27 07:37:57] <coding-yogi> HI
[2017-01-27 07:38:15] <coding-yogi> my docker compose fails with a weird opath not found error
[2017-01-27 07:38:29] <coding-yogi> WindowsError: [Error 3] The system cannot find the path specified: 'C:\\work\\ResumeMatching\\geoip_service\\target\\streams\\$global\\assemblyOption\\$global\\streams\\assembly\\12f412bc8ebacb72a18791e529e71f7f31eeeb4d_a306c7db15a0f1da8a785f6cf5279c49791d77af_da39a3ee5e6b4b0d3255bfef95601890afd80709\\akka\\parboiled2\\CharPredicate$$anonfun$1.class'docker-compose returned -1
[2017-01-27 07:38:51] <coding-yogi> path given by me in COPY is C:\\work\\ResumeMatching\\geoip_service\\target
[2017-01-27 07:39:47] <coding-yogi> sorry not the above one but this one "target\\scala-2.11\\geoip-service-assembly-1.0.jar"
[2017-01-27 07:40:38] <coding-yogi> not sure why its searching unintended stuff
[2017-01-27 14:08:21] <anand79> Hi, I just installed docker toolbox for windows and on running it I got error -
[2017-01-27 14:08:24] <anand79>  [<-LINK->] 
[2017-01-27 14:09:02] <anand79> Any idea how to fix it? Thanks
[2017-01-27 14:09:14] <jeffsui> which toolbox version ?
[2017-01-27 14:09:30] <anand79> 1.12.6
[2017-01-27 14:09:44] <jeffsui> win7 ?
[2017-01-27 14:09:49] <anand79> yes
[2017-01-27 14:10:40] <jeffsui> try to delete default container and recreate again
[2017-01-27 14:11:31] <anand79> sorry, but not sure how
[2017-01-27 14:12:28] <jeffsui> Docker Quickstart  Terminalyou can use this to start docker
[2017-01-27 14:14:34] <jeffsui> t will create  default machine with ip 192.168.99.100
[2017-01-27 14:19:30] <anand79> The screenshot  I sent is of Docker Quickstart Terminal
[2017-01-27 14:21:18] <anand79> The issue seems to be with SSH command, not sure how to fix that?
[2017-01-27 14:21:39] <jeffsui> ssh error ？
[2017-01-27 14:22:18] <anand79> the first line in the screenshot says that, I guess that must be the reason
[2017-01-27 14:27:47] <jeffsui>  [<-ISSUE->] the same issue
[2017-01-27 14:28:05] <jeffsui> eval $(docker-machine env default)
[2017-01-27 14:29:01] <jeffsui> docker-machine restart defaultthen eval $(docker-machine env default)
[2017-01-27 14:31:56] <anand79> I am trying it now, Thanks
[2017-01-27 14:32:09] <jeffsui> np
[2017-01-27 15:33:31] <killerspaz> I'm sure I know the answer, but there isn't a way to just declare ENV vars in docker-compose.yml is there? Like a block of variable definitions? They have to be defaulted in EVERY single place used?
[2017-01-27 15:37:47] <SISheogorath> You mean a central place like for the creation of networks? No. But you can use ENV files and include them
[2017-01-27 15:39:32] <killerspaz> mmm not exactly, I want the opportunity for whoever is spinning up teh service to supply ENV vars, but it's hard to know which ones are needed without scanning an entire config setup (which spans 3 different files as it is).... I'd like to be able to just have a block of variables defined, and their default values: [<-CODE->] 
[2017-01-27 15:42:45] <killerspaz> that way a user can instantly scan all the values
[2017-01-27 15:51:22] <killerspaz> @SISheogorathI'm even not sure what you need this for :X there is dns outside ^^I don't want to run my own DNS, plus a DNS isn't very flexible when working in various environments (dev, test, prod) without creating tons of entries.... The way I'm approaching it is just supply a variable to docker-compose and it'll override the host IP in /etc/hosts
[2017-01-27 15:59:27] <SISheogorath> killerspaz: default values are something I assign in the entrypoint script of the container, not the compose file.
[2017-01-27 16:03:15] <killerspaz> I can't affect the compose if it's in an entrypoint script, which we dont' use entrypoints, only commands
[2017-01-27 16:05:41] <killerspaz> i think i can get away with multiple env-files
[2017-01-27 16:12:12] <playground> Hi, I start getting this error today when try to create a docker image Error response from daemon: write /var/lib/docker/image/aufs/.tmp-repositories.json437787979: no space left on deviceHow can I increase space in docker without having to recreate virtualbox?
[2017-01-27 16:13:08] <killerspaz> clear volumes that aren't being used
[2017-01-27 16:13:10] <killerspaz> docker volume ls
[2017-01-27 16:13:28] <killerspaz> docker volume rm $(docker volume ls -qf dangling=true)
[2017-01-27 16:14:54] <killerspaz> that's dangerous btw, only run that if you don't mind losing persisted data
[2017-01-27 16:15:37] <playground> I see three local volumes, how do I know which one to remove
[2017-01-27 16:19:03] <playground> killerspaz: How do those volumes get created?
[2017-01-27 16:20:30] <killerspaz> based on images you might use from dockerhub, or any volumes you're defining when running containers
[2017-01-27 16:20:59] <killerspaz> docker volume inspect VOL_ID | less
[2017-01-27 16:29:25] <playground> ok, i try this commanddocker volume rm $(docker volume ls -qf dangling=true)but it\'s  complaining ""docker volume rm" requires at least 1 argument(s)."
[2017-01-27 16:29:44] <playground> am I using the command correctly?
[2017-01-27 16:30:07] <SISheogorath> yes
[2017-01-27 16:30:20] <SISheogorath> but that means that you volumes are assigned to a running/existing container
[2017-01-27 16:31:19] <playground> hmm
[2017-01-27 16:32:04] <SISheogorath> maybe it is easier to dodocker rmi $(docker images -q)but make sure you don't have any non running self build images that you want to keep
[2017-01-27 16:36:53] <playground> thanks guys for your help
[2017-01-27 16:38:39] <playground> killerspaz: I got one other question, I have this app that I\'m trying to dockerize, when running in the container "docker run -p 49168:4200 new-ng-project", it runs with no error but i can\'t access the app via localhost:49168. Any idea why?
[2017-01-27 16:38:55] <killerspaz> if you just want to blast everything you possibly can, here's an alias i wrote i use often while developing: [<-CODE->] 
[2017-01-27 16:39:42] <playground> that is handy, thanks for the script
[2017-01-27 16:39:51] <SISheogorath> btw with docker 1.13 it'sdocker system purge
[2017-01-27 16:40:06] <killerspaz> hmmm nice.. still on 1.12.6
[2017-01-27 16:40:22] <SISheogorath> killerspaz: you are so leagcy xD
[2017-01-27 16:40:29] <killerspaz> playground: assuming you're on windows or OSX, the docker daemon runs in a VM, not on your host OS... OS-ception... Windows/OSX > VM (boot2linux) > Your container
[2017-01-27 16:40:41] <killerspaz> lol i just installed last week from a fresh wipe!
[2017-01-27 16:40:49] <playground> I'm on OSX
[2017-01-27 16:40:54] <killerspaz> playground: usedocker-machine ip
[2017-01-27 16:41:51] <playground> killerspaz: how does it work, I haven't tried that yet, I'm very new to docker
[2017-01-27 16:42:34] <killerspaz> might wanna spend some time reading the docs, loooooots to learn that I couldn't just give you in a 10 second spiel.
[2017-01-27 16:43:02] <jeffsui> or you can  read [<-LINK->] first :)
[2017-01-27 16:43:10] <playground> I know, I lots commands to learn
[2017-01-27 16:43:26] <jeffsui> step by step
[2017-01-27 16:44:32] <SISheogorath> lol I don't know but everytime someone want me to read a book about an application I think it is more useful to read the sourcecode itself :X
[2017-01-27 16:45:45] <killerspaz> never found books to be all that great, imo.... but that's just me... different people learn differently
[2017-01-27 16:46:08] <killerspaz> exactly... books are usually full of bloat, or out dated (granted that one says it's always up to date, i have my doubts)
[2017-01-27 16:46:23] <SISheogorath> I love reading books but not for technical things.
[2017-01-27 16:47:06] <killerspaz> lol i'm too busy reading docs and source to read anything else :/
[2017-01-27 16:47:20] <killerspaz> i've always said I should dedicate time to read fiction
[2017-01-27 16:48:40] <jeffsui> that's ok .different people learn docker in different way.
[2017-01-27 16:49:21] <playground> so what is a good concise docker reference doc that you can point me to :-)?
[2017-01-27 16:49:53] <killerspaz> so i've been fighting this issue where my scripts with +x on them are -x in the container.... compose not telling me why, etc... finally build manually with docker engine, and of course it tells me:SECURITY WARNING: You are building a Docker image from Windows against a non-Windows Docker host. All files and directories added to build context will have '-rwxr-xr-x' permissions. It is recommended to double check and reset permissions for sensitive files and directories.
[2017-01-27 16:50:17] <killerspaz> buuuuuuut... those aren't the permissions on the file
[2017-01-27 16:50:43] <playground> is this a good start [<-LINK->] ?
[2017-01-27 16:51:11] <jeffsui> yeah, and all code can find on github .
[2017-01-27 16:51:56] <jeffsui>  [<-LINK->] 
[2017-01-27 16:52:49] <playground> ok, thanks@jeffsui
[2017-01-27 16:53:04] <jeffsui> np
[2017-01-27 16:53:13] <killerspaz>  [<-CODE->] WTF!?!?!
[2017-01-27 16:54:06] <killerspaz> even this [<-ISSUE->] says it should be +x... wtf gives
[2017-01-27 16:57:02] <jeffsui> I've got to sleep. bye all.
[2017-01-27 16:57:58] <SISheogorath> playground: I would still prefer the [<-LINK->] 
[2017-01-27 16:59:19] <SISheogorath> killerspaz: you are on windows and have unix file permissions? Hopefully you do not use bash for windows to build docker... as far as I know that ends in something broken :X
[2017-01-27 16:59:30] <playground> SISheogorath: it's so much to read :-(
[2017-01-27 17:00:05] <SISheogorath> playground: there are some getting started parts
[2017-01-27 17:00:09] <killerspaz> i'm currently using gitbash, haven't had issues until now
[2017-01-27 17:00:52] <SISheogorath> playground:  [<-LINK->] 
[2017-01-27 17:01:02] <SISheogorath> killerspaz: not sure :/ can you try powershell?
[2017-01-27 17:02:16] <killerspaz> i despise powershell
[2017-01-27 17:02:33] <killerspaz> i'd rather use a stone tablet
[2017-01-27 17:09:50] <SISheogorath> ok
[2017-01-27 17:11:52] <killerspaz> lol sorry i'm not cooperative on that... but i did just upgrade to 1.13 :D
[2017-01-27 17:12:03] <killerspaz> docker system pruneworks great
[2017-01-27 17:12:50] <killerspaz> but damn, every command pumps out:system root pool is not available on Windows
[2017-01-27 17:12:54] <killerspaz> annoying af.
[2017-01-27 17:16:33] <killerspaz> actually everything broke... fuck
[2017-01-27 17:24:38] <SISheogorath> ._. sounds great. you should continue  (irony)
[2017-01-27 18:42:11] <soapoperator> hello, i run a container with php/apache + mariadb + phpmyadmin with docker-compose in a custom network. I would to run  another container... Is it possible to get phpmadmin works with all network together to get one url? Is sharing container recommand by the guidelines of docker?
[2017-01-27 18:52:05] <SISheogorath> The recommendation by best practice says 1 process per container. Now you can think about is phpmyadmin an own process? not really but it's an own application so it's maybe better to  split it into another container because in case you have to scale there is no need in scalaing phpmyadmin. And maybe the scaling of phpmyadmin ends up in race conditions you don't want to have. So my personal answer is: split it out. and to bring them together on the same subdomain use a reverse proxy. My recommendation for this is: traefik.io
[2017-01-27 18:52:21] <SISheogorath> but you can also add a simply reverse proxy rule to your apache config
[2017-01-27 22:54:35] <soapoperator> @SISheogorath Thank you for your answer.I am trying to split it out. In my container php + mariadb (container 1), i pass environment variable MYSQL_USER and MYSQL_PASSWORD. In my phpmyadmin container (container 2), i pass environment variables MYSQL_USERNAME=root, MYSQL_ROOT_PASSWORD and PMA_HOSTS (i try : the ip address of the container 1 and the network name). Unfortunatly i get an error when i try to login: [<-CODE->] Do i have to add php to the container 2? Could it explain the issue?
[2017-01-27 22:58:20] <killerspaz> I feel you're kinda missing the point of containers and how they work; might want to research docker a bit more... Try starting here: [<-LINK->] 
[2017-01-27 22:58:26] <killerspaz> soapoperator: ^^
[2017-01-27 23:36:00] <SISheogorath> soapoperator: looks like your phpmyadmin is not configured to use the network
[2017-01-28 00:27:32] <killerspaz> Anyone have any ideas why my rsyslogd dies withRUN rsyslogdin my dockerfile? but if I exec into it, I can start it fine (after killing the pid file erroneously left around)
[2017-01-28 01:09:53] <SISheogorath> maybe it needs tty?
[2017-01-28 01:40:15] <killerspaz> tty for what? it's the host
[2017-01-28 01:40:33] <killerspaz> and even when disabling the tcp stuff it still crashes
[2017-01-28 02:14:45] <killerspaz>  [<-LINK->] my dockerfile.... it seems to run, but no output in docker logs, so i can't even think of where to start debugging
[2017-01-28 02:15:10] <killerspaz> CMD is set through docker-compose, that's working fine (runs a node app)
[2017-01-28 03:10:25] <killerspaz> bah, figured it out.... I forgotRUNstatements execute during build, not runtime :/ can't believe i was hung up on that!
[2017-01-28 03:24:06] <SISheogorath> lol just saw your most and message
[2017-01-28 11:49:39] <soapoperator> @killerspaz Thank you for the advice  I read a lot of thing without practicing. It'svery new for me. Finaly i progress faster when i face to the problem. The problem was with a volume for config.inc.ini.@SISheogorath Finaly i succeed to make phpmyadmin communicate with the container help with: [<-CODE->] But when i add another external, it doesn't work. I will try to inverse: add the phpmyadmin network to my mysql container...
[2017-01-28 17:15:58] <galvesribeiro> is it possible to “import” a docker-compose file into another?
[2017-01-28 17:17:15] <galvesribeiro> I mean, I have multiple projects inside a same solution (a .Net Core application) and each project has its own docker-compose file… I want to have a solution level docker-compose file which describe all that services relationship… is it possible?
[2017-01-28 17:17:48] <galvesribeiro> SISheogorath: ideas?
[2017-01-28 17:47:55] <ioleo> I'm running cassandra (official image) inside a docker. Another service (app) is in another container, and it seems the underlaying library makes a connection as soon as the service is started. That connection will fail, if there is no keyspace in cassandra, and the app will shutdown with an exception.
[2017-01-28 17:50:24] <ioleo> I was trying to figure out how can I make sure that as soon as cassandra starts - first thing it does is check if it has a keyspace, and if not - create it.
[2017-01-28 17:50:54] <ioleo> Anyone had this problem? Google & stackOverflow did not help much :(
[2017-01-28 17:58:56] <Awiu_twitter> As far as I understand this responsibility is of the App which is using Cassandra. I am also having a technology stack where my App is using Cassandra, it looks for keyspace and tables and if it's not there, it creates it.
[2017-01-28 19:34:44] <SISheogorath> galvesribeiro: there is a import statement in version 2.1(?) I know it is there and not working in version 3 xD
[2017-01-28 19:35:05] <galvesribeiro> hahahaah
[2017-01-28 19:35:20] <galvesribeiro> I’m playing with v3
[2017-01-28 19:35:39] <galvesribeiro> too much text files and command lines for us Windows users :P
[2017-01-28 19:36:03] <SISheogorath> In this case sry :/
[2017-01-28 19:36:36] <galvesribeiro> so the import isnt working on v3, it is a bug, and will be fixed, right?
[2017-01-28 19:37:11] <galvesribeiro> I mean, it is something that will be fixed and not something that was deprecated, correct?
[2017-01-28 19:38:13] <SISheogorath> Not sure. The try to keep local dependencies away from v3
[2017-01-28 19:39:49] <galvesribeiro>  [<-LINK->] 
[2017-01-28 19:39:58] <SISheogorath> See [<-LINK->] 
[2017-01-28 19:39:59] <galvesribeiro> this is what I'm trying to achieve
[2017-01-28 19:41:46] <galvesribeiro> the idea is whe I calldocker-compose upat the root of the solution, it will put up those 2 inner compose files on the same composition
[2017-01-28 19:42:02] <galvesribeiro> each of the inner files has only its own dependencies and itself
[2017-01-28 19:42:28] <galvesribeiro> let me see the extends
[2017-01-28 19:42:50] <SISheogorath> It'll come to v3
[2017-01-28 19:43:35] <galvesribeiro> ok, so today extends will not help me
[2017-01-28 19:43:37] <galvesribeiro> understood
[2017-01-28 19:46:25] <galvesribeiro> Note: This option is not yet supported when deploying a stack in swarm mode with a (version 3) Compose file. Use docker-compose config to generate a configuration with all extends options resolved, and deploy from that.
[2017-01-28 19:46:28] <galvesribeiro> humm
[2017-01-28 19:46:33] <galvesribeiro> extends
[2017-01-28 19:46:56] <galvesribeiro> at least it can be useful for my .debug files
[2017-01-28 19:47:07] <galvesribeiro> they can extend the original ones
[2017-01-28 19:47:20] <galvesribeiro> it is just a diff image with a DEBUG env variable
[2017-01-28 19:57:03] <galvesribeiro> weird@SISheogorath
[2017-01-28 19:57:19] <galvesribeiro>  [<-CODE->] 
[2017-01-28 19:57:24] <galvesribeiro> what is wrong here
[2017-01-28 19:57:25] <galvesribeiro> ?
[2017-01-28 19:57:41] <galvesribeiro> ERROR: The Compose file './docker-compose.debug.yml' is invalid because:Unsupported config option for services.silotest: 'extends'
[2017-01-28 19:58:35] <SISheogorath> Extends is iirc for usage in root not under services
[2017-01-28 19:58:52] <galvesribeiro>  [<-LINK->] 
[2017-01-28 19:59:07] <galvesribeiro> that says otherwise if I understood correctly
[2017-01-28 20:00:51] <SISheogorath> Mhm yes
[2017-01-28 20:08:15] <galvesribeiro> In all cases, I think the proper way to handle this debug/prod stuff, is by using overrides
[2017-01-28 20:08:17] <galvesribeiro> not extends
[2017-01-28 20:27:36] <galvesribeiro> SISheogorath: any way to conditionaly call aRUNfrom a docker file?
[2017-01-28 20:27:50] <galvesribeiro> I mean, without generate an extra layer
[2017-01-28 20:28:09] <galvesribeiro> for example, I have this:
[2017-01-28 20:28:17] <galvesribeiro>  [<-CODE->] 
[2017-01-28 20:28:27] <galvesribeiro> I want this to only run if I’m in debug
[2017-01-28 20:28:34] <galvesribeiro> today I have 2 dockerfiles
[2017-01-28 20:28:56] <SISheogorath> No. But you can use--squashfrom experimental to simply create it as a single layer
[2017-01-28 20:28:59] <galvesribeiro> if I could have just one and check if I’m in debug run this, otherwise not…
[2017-01-28 20:29:14] <galvesribeiro> humm
[2017-01-28 20:29:21] <galvesribeiro> but the caller of this docker file is a compose file
[2017-01-28 20:29:36] <SISheogorath> eh okay, that's bad
[2017-01-28 20:29:48] <galvesribeiro> I want to pass this command as a ARG
[2017-01-28 20:29:55] <SISheogorath> I would may simply use a--build-arg:D
[2017-01-28 20:30:11] <galvesribeiro> so only when I’m using the compose file that is for debug, this is passed
[2017-01-28 20:30:23] <SISheogorath> than it's easy :D
[2017-01-28 20:30:41] <galvesribeiro> Define easy :P
[2017-01-28 20:31:27] <SISheogorath> This: [<-CODE->] 
[2017-01-28 20:32:11] <galvesribeiro> ok but, that will generate the extra layer for that RUN even it it doesnt run the command, right?
[2017-01-28 20:32:20] <galvesribeiro> or the layers are only generated on write operations?
[2017-01-28 20:32:25] <SISheogorath> right so it's an empty layer
[2017-01-28 20:32:35] <galvesribeiro> ok, I want avoid that
[2017-01-28 20:32:36] <galvesribeiro> :)
[2017-01-28 20:32:40] <SISheogorath> why?
[2017-01-28 20:32:59] <galvesribeiro> why do I need an empty layet in a production image? :D
[2017-01-28 20:33:00] <SISheogorath> as long as you stay lower than 42 layers it doesn't hurt anything ^^
[2017-01-28 20:33:14] <galvesribeiro> ok ok
[2017-01-28 20:33:15] <galvesribeiro> got it
[2017-01-28 20:33:32] <galvesribeiro> btw, just curious, why this cabalistical number 42?
[2017-01-28 20:33:35] <SISheogorath> well the other option is to maintain two images :D
[2017-01-28 20:34:19] <galvesribeiro> hehehe that is what I’m trying to avoid
[2017-01-28 20:34:20] <galvesribeiro> :)
[2017-01-28 20:35:11] <galvesribeiro> I can’t pass a command expression thru ARGs from a docker-compose.yml, can’t I
[2017-01-28 20:35:11] <galvesribeiro> ?
[2017-01-28 20:38:53] <SISheogorath> in general you shouldn't be able to build any image in docker-compose v3 anyways
[2017-01-28 20:39:21] <SISheogorath> reason: v3 is for distributed deployment and builds are only available locally
[2017-01-28 20:39:21] <galvesribeiro> oh
[2017-01-28 20:39:29] <galvesribeiro> ic
[2017-01-28 20:39:42] <galvesribeiro> So avoid build: in compose
[2017-01-28 20:39:43] <galvesribeiro> ic
[2017-01-28 20:39:55] <galvesribeiro> makes sense
[2017-01-28 20:40:24] <galvesribeiro> so lets keep 2 docker files instead
[2017-01-28 20:41:41] <galvesribeiro> but in all cases, build should be available so people can develop using it
[2017-01-28 20:42:09] <galvesribeiro> but I agree that the compose file for production shouldn’t have any build statements and assume the images are available in the registry
[2017-01-28 23:37:52] <galvesribeiro> SISheogorath: question for a linuxer :P
[2017-01-28 23:37:57] <galvesribeiro> how to make this:
[2017-01-28 23:38:03] <galvesribeiro>  [<-CODE->] 
[2017-01-28 23:38:10] <galvesribeiro> to fit in a single line?
[2017-01-28 23:38:28] <galvesribeiro> tried this and not work:
[2017-01-28 23:38:32] <galvesribeiro> "dotnet build DockerTest.sln; docker-compose build; danglingImages=$(docker images -q --filter \'dangling=true\') if [[ ! -z $danglingImages ]] then docker rmi -f $danglingImages fi"
[2017-01-28 23:40:00] <SISheogorath> why are you do this? do [<-CODE->] 
[2017-01-28 23:40:36] <galvesribeiro> that way I’m calling docker twice
[2017-01-28 23:40:36] <galvesribeiro> :)
[2017-01-28 23:40:44] <galvesribeiro> it slow down the build :)
[2017-01-28 23:40:46] <SISheogorath> wc -l-> count lines
[2017-01-28 23:41:04] <galvesribeiro> yes, but docker images doesnt
[2017-01-28 23:41:06] <galvesribeiro> :)
[2017-01-28 23:41:14] <galvesribeiro> it call the API twice
[2017-01-28 23:41:48] <galvesribeiro> I mean, it call the API twice to check for dangling
[2017-01-28 23:41:52] <galvesribeiro> when it should do once
[2017-01-28 23:45:42] <SISheogorath> if you really want:
[2017-01-28 23:46:15] <galvesribeiro> it works I just tested, it just not optimal when you have tons of images dungling arount :)
[2017-01-28 23:46:20] <galvesribeiro> but thanks :D
[2017-01-28 23:46:29] <SISheogorath>  [<-CODE->] 
[2017-01-28 23:46:49] <SISheogorath> in general with docker 1.13 the new docker system commands are better :X
[2017-01-28 23:48:42] <galvesribeiro> the last one didnt worked
[2017-01-28 23:48:50] <galvesribeiro> the dungling are there :(
[2017-01-28 23:48:56] <galvesribeiro> btw, I’m on 1.13
[2017-01-28 23:49:07] <SISheogorath> than throw the shit away xD
[2017-01-28 23:49:17] <galvesribeiro> ?
[2017-01-28 23:49:26] <galvesribeiro> what do I do then? :P
[2017-01-28 23:49:52] <SISheogorath> the bad scripts :D usedocker system prune
[2017-01-28 23:50:55] <galvesribeiro> hehehe it hang the build process with
[2017-01-28 23:51:02] <galvesribeiro>  [<-CODE->] 
[2017-01-28 23:51:39] <galvesribeiro> I can’t do that… who knows if the developer has a stopped container outside this given project heheh
[2017-01-28 23:51:41] <SISheogorath> there is-f
[2017-01-28 23:51:48] <SISheogorath> did I missed to tell that? xD
[2017-01-28 23:52:00] <galvesribeiro> better to stick with the ugly script
[2017-01-28 23:52:26] <SISheogorath> as you wish ^^
[2017-01-28 23:52:52] <galvesribeiro> ok so what do I need do to fix the last script you pasted?
[2017-01-28 23:59:44] <galvesribeiro> screw that
[2017-01-28 23:59:49] <galvesribeiro> docker prune will be
[2017-01-28 23:59:58] <SISheogorath> ok
[2017-01-29 00:00:59] <galvesribeiro> scared
[2017-01-29 00:01:00] <galvesribeiro> Deleted Networks:docker_gwbridge
[2017-01-29 00:01:04] <galvesribeiro> it removed this network
[2017-01-29 00:01:20] <galvesribeiro> I never created that so I assume it is from docker4Mac o.O
[2017-01-29 00:01:26] <galvesribeiro> I hope it didn’t break anything
[2017-01-30 11:51:53] <jorgemmsilva> Hi guys, I'm getting started with docker.. I want to be able to create and deploy a windows container running IIS ( [<-LINK->] ), then be able to access is through IIS manager remotely.  Can I do this using the default ContainerAdministrator user, or should I create a new one?
[2017-01-30 11:52:57] <jorgemmsilva> If so, how does one create a default login on the Docker image build?
[2017-01-30 11:53:12] <jorgemmsilva> Cheers :)
[2017-01-30 15:37:07] <argeas> hey allo ! anyone know how to target a specific device when running container  ?  from here it says : [<-LINK->] docker run -d --privileged -v /dev/bus/usb:/dev/bus/usb -e "DEVICE_SERIAL=yyyy"
[2017-01-30 15:37:24] <argeas> what is the device serial? the actual android device serial ? or the usb serial ?
[2017-01-30 17:13:04] <jorgemmsilva> btw i found a solution here
[2017-01-30 17:13:05] <jorgemmsilva>  [<-ISSUE->] 
[2017-01-30 17:47:37] <akinhwan> Hello
[2017-01-30 18:19:31] <SISheogorath> hi
[2017-01-30 20:03:47] <w0rldart> Is it the registry that contains the history of mydocker-machineoperations?
[2017-01-31 06:41:56] <DJQTDJ> how to solve this? [<-CODE->] 
[2017-01-31 10:14:50] <coding-yogi> RUN chmod +x ./download_db.shRUN ./download_db.sh
[2017-01-31 10:14:56] <coding-yogi> 1st line works
[2017-01-31 10:15:05] <coding-yogi> 2nd fails saying file not found
[2017-01-31 10:15:08] <coding-yogi> any idea?
[2017-01-31 10:15:35] <coding-yogi> Step 10/13 : RUN chmod +x ./download_db.sh---> Running in da6eab2d5a1d---> 191f4b488d24Removing intermediate container da6eab2d5a1dStep 11/13 : RUN sh -c ./download_db.sh---> Running in dc2fd5e50d90sh: 1: ./download_db.sh: not found
[2017-01-31 10:31:25] <jMonsinjon> Maybe Docker don\'t like your local path. Did you tried to use WORKDIR instruction before and remove the "./" prefix ?
[2017-01-31 10:31:46] <coding-yogi> yes
[2017-01-31 10:59:46] <jMonsinjon> I already had this issue....
[2017-01-31 11:00:17] <jMonsinjon> DId your script starts with a "shebang" ?
[2017-01-31 11:00:18] <coding-yogi> actually its not issue with file
[2017-01-31 11:00:29] <jMonsinjon> like #!/bin/sh
[2017-01-31 11:00:42] <coding-yogi> I searched for error, error means command not found
[2017-01-31 11:00:56] <jMonsinjon> yep
[2017-01-31 11:01:21] <jMonsinjon> it happends to me when i forget to add the shebang
[2017-01-31 11:01:29] <coding-yogi> shebang is added
[2017-01-31 11:01:34] <coding-yogi> in sh script
[2017-01-31 11:02:08] <coding-yogi> ah I got it
[2017-01-31 11:02:14] <coding-yogi> its using bash shell
[2017-01-31 11:03:28] <jMonsinjon> the #!/bin/bash doesn't work in alpine (if you use an alpine base image)
[2017-01-31 11:04:13] <jMonsinjon> Tell me when you'r ok
[2017-01-31 11:06:04] <coding-yogi> tried something like this without luck
[2017-01-31 11:06:05] <coding-yogi> SHELL ["/bin/bash", "-c"]RUN ./download_db.sh
[2017-01-31 11:16:22] <coding-yogi>  [<-LINK->] mentions how to run bash
[2017-01-31 11:16:37] <coding-yogi> so i tried RUN ["/bin/bash", "-c", "./download_db.sh"]
[2017-01-31 11:17:03] <coding-yogi> but i get error like this /bin/bash: ./download_db.sh: /bin/bash^M: bad interpreter: No such file or directory
[2017-01-31 11:54:44] <elcolie> Hi
[2017-01-31 11:55:12] <elcolie> I have searched over the stackoverflow and some other sources, but not get the correct answer
[2017-01-31 11:55:31] <elcolie> My question is "How to use Django container connect to host postgres?"
[2017-01-31 11:56:17] <elcolie> I had configure the host-postgres to accept all the connection and let container connect to host-postgres by this line [<-CODE->] 
[2017-01-31 13:48:11] <SISheogorath> DJQTDJ: I guess you picked the wrong channel. That's an HTTP CORS violation. Check for CORS in you favorite search engine.
[2017-01-31 13:51:35] <SISheogorath> aniket-21: Alpine has no bash installed. You can maybe add it byapk add --no-cache bashbut in general that sounds bad. Write  the script to work with/bin/sh
[2017-01-31 13:53:08] <jMonsinjon> aniket-21: @SISheogorathagree, that's why I asked what was the basic image used
[2017-01-31 13:59:03] <coding-yogi> jorgemmsilva: @SISheogorath, I am using scala-sbt image
[2017-01-31 13:59:25] <coding-yogi> And it has bin/bash
[2017-01-31 13:59:38] <coding-yogi> I am just not using it correctly
[2017-01-31 14:08:13] <coding-yogi>  [<-LINK->] 
[2017-01-31 14:09:55] <argeas> argeas: hi all . i have 2 android devices..  I start the container like this  docker run -d --privileged -v /dev/bus/usb:/dev/bus/usb --name auto1 appium/appium-project-base:latesti can see both devices..but second container cant either device
[2017-01-31 14:13:26] <dragon788> aniket-21: if you runwhich bashin your container it should return the correct path to bash if it is in your PATH, if not check/usr/bin/bash
[2017-01-31 14:14:48] <dragon788> I don't know if Alpine includesenvbut you could also try#! /usr/bin/env bashwhich looks for it automatically
[2017-01-31 14:15:36] <coding-yogi> Bash is not a prob, i tried running some other commands and they work
[2017-01-31 14:15:59] <coding-yogi> Problem is my file has windows new line char and hence causing problem
[2017-01-31 14:16:27] <coding-yogi> ^M denotes that
[2017-01-31 14:16:33] <dragon788> Ah, using notepad++ or vim is a good way to fix that
[2017-01-31 14:16:50] <coding-yogi> Yeah
[2017-01-31 14:17:42] <dragon788> I'm so used to reading past the ^M I didn't notice it, bash definitely cares though
[2017-01-31 14:53:59] <iDVB> anyone know of a workflow to successfully usenpm linkwhile developing in a docker container? Eg. I'd like to setup a link inside the docker node_modules folder that is able to link to the host machine custommodule that I'm developing
[2017-01-31 15:02:51] <SISheogorath> iDVB: copy it into the container and usenpm linkas usual?
[2017-01-31 15:04:57] <iDVB> SISheogorath: yup, guess that is what I'll have to do. Just seems dirty. Liked the idea that usingnpm linklocally (not in docker) didn't make ANY changes to the source files, yet let you dev that module.
[2017-01-31 15:06:30] <SISheogorath> or mount it on container startup
[2017-01-31 15:15:54] <iDVB> SISheogorath: can you provide a sample command for mounting on startup?
[2017-01-31 15:16:50] <iDVB> Guess I'm getting caught up on the fact that the containers node_modules folder will already contain the public module and not the symlink
[2017-01-31 15:48:49] <SISheogorath> Oh yes that's possible. Never tried but using-v /path/to/module:/lokal-moduleand runnpm linkin entrypoint script maybe works
[2017-01-31 16:06:38] <iDVB> Really struggling with this. can't seem to get it to work
[2017-01-31 16:07:31] <iDVB>  [<-CODE->] 
[2017-01-31 16:08:31] <iDVB> the react-player module is failing on launch saying it can't find the deps.Error: Cannot resolve module 'react' in /deps/react-player/lib/players
[2017-01-31 16:11:45] <killerspaz> galvesribeiro: @SISheogorathbtw, that dangling alias is useless with 1.13... [<-LINK->] 
[2017-01-31 16:12:08] <galvesribeiro> yeah I’m using prune now
[2017-01-31 16:12:32] <galvesribeiro> I’m just afraid that it may remove stopped containers in the developer machine that it isn’t suppose to
[2017-01-31 16:12:34] <galvesribeiro> anyway
[2017-01-31 16:12:58] <killerspaz> well it's a development machine, it's meant to break :P
[2017-01-31 16:13:09] <galvesribeiro> hahahah
[2017-01-31 16:13:12] <killerspaz> i assume all development to be stateless while i work in containers
[2017-01-31 16:13:12] <galvesribeiro> true
[2017-01-31 16:13:19] <galvesribeiro> yes it is
[2017-01-31 16:13:37] <killerspaz> i run purge like 40x a day :P
[2017-01-31 16:14:00] <galvesribeiro> in my case it run every time I build the .net project :P
[2017-01-31 16:14:18] <galvesribeiro> actually not anymore...
[2017-01-31 16:14:22] <galvesribeiro> I just made a volume
[2017-01-31 16:14:28] <galvesribeiro> pointing to the build output
[2017-01-31 16:14:40] <galvesribeiro> now Idocker-compose up -donce
[2017-01-31 16:14:45] <galvesribeiro> and keep the containers running
[2017-01-31 16:14:57] <galvesribeiro> the entrypoint istail -f /dev/null
[2017-01-31 16:15:04] <galvesribeiro> so it keep up forever
[2017-01-31 16:15:17] <galvesribeiro> and my tooling is starting the debugger and the app viadocker exec
[2017-01-31 16:15:44] <galvesribeiro> so if I stop debug, it close the debugger process… so just need to run again :)
[2017-01-31 16:15:50] <galvesribeiro> the cycle got easy now
[2017-01-31 16:18:57] <SISheogorath> iDVB: sounds more like a problem with your dependencies than with docker itself
[2017-01-31 16:19:31] <iDVB> well... its definitly a combo... since this works fine withoutnpm link
[2017-01-31 16:20:27] <iDVB> near pulling my hair out though. Since I need to get on with module dev but docker at this moment is more of an obstacle would love to understand how to get this to work.
[2017-01-31 16:20:55] <iDVB> in my head.... I just need to add the volume (docker-compose in my case )- ./../react-player:/deps/react-player
[2017-01-31 16:21:49] <iDVB> which maps the host's local git clone of the react-player module then mapping it over to a folder that the container can ref
[2017-01-31 16:22:43] <iDVB> then I try to link that container's folder ...
[2017-01-31 16:22:53] <iDVB>  [<-CODE->] 
[2017-01-31 16:23:13] <SISheogorath> File permissions?yarn install -fmaybe ignores the problem that it possibly has no write permissions to the module directory
[2017-01-31 16:23:32] <iDVB> yup.... tried that andyarn upgrade
[2017-01-31 16:23:55] <iDVB> :( thought for sure someone had a workflow for this
[2017-01-31 16:24:36] <SISheogorath> I personally prefer Dockerfiles in my repos and copy everything in
[2017-01-31 16:24:49] <iDVB> or is there just a way to get COPY docker command to support symlinks
[2017-01-31 16:25:17] <iDVB> going to try the dockerfile next
[2017-01-31 16:26:18] <SISheogorath> O.o if you copy Symlinks you have pointers to dead endpoint if you don't copy the target to the correct location, too
[2017-01-31 16:27:07] <iDVB> sorry.... not following
[2017-01-31 16:27:34] <iDVB> I would just expect it to copy over the result of following the symlink
[2017-01-31 16:32:19] <killerspaz> Usinglinkin that context is super strange.... Highly suggested to avoid that like the plague.
[2017-01-31 16:32:32] <killerspaz> You should actually commit it as a module and define it as a dependency in yourpackage.jsonproperly
[2017-01-31 16:32:49] <killerspaz> also, depending on your environment, links do not work (esp with virtualbox)
[2017-01-31 16:34:39] <iDVB> killerspaz: npm link/yarn linkis a very typical module dev workflow. It allows you to develop a specific module while in the context of a larger app without having to add/commit/push/yarn upgrade each time you make a single line change to the component.
[2017-01-31 16:35:27] <iDVB> for us... it might be a docker-for-dev show stopper if there isnt a work around.
[2017-01-31 16:35:58] <iDVB> I just tried making the changes to the dockerfile and gotERROR: Service 'web' failed to build: Forbidden path outside the build context: ../react-player ()
[2017-01-31 16:35:59] <killerspaz> DEV workflow, not deployment, which is what docker is, a deployment mechanism
[2017-01-31 16:36:25] <killerspaz> I know precisely what linking modules does
[2017-01-31 16:37:27] <killerspaz> This is also a "won\'t fix" on both docker and virtualbox\'s issue lists
[2017-01-31 16:37:29] <iDVB> killerspaz: I sense an abstract debate.... but is it not fair to say that people use docker as their dev workflow? so rather then deving on the host... you instead dev in docker? This is what we've been doing for a few months now... successfully too, this has been the first road block.
[2017-01-31 16:38:16] <killerspaz> you've been doing it locally only, it's not feasible in docker as it's not a best practice to deploy a dev workflow
[2017-01-31 16:39:19] <killerspaz> the other issue about the build context means you can't include anything above your build folder
[2017-01-31 16:40:20] <iDVB> no I mean in response to your"DEV workflow, not deployment, which is what docker is, a deployment mechanism"we\'ve been using docker as our dev workflow.... the only piece of that typical workflow is the linking of modules.
[2017-01-31 16:40:47] <SISheogorath> What makes no sense to me is that you build from directoryA while developing directoryB.
[2017-01-31 16:41:26] <killerspaz> eh, that part can make sense.... chicken or the egg issue with dependencies
[2017-01-31 16:41:27] <iDVB> wait.... what are we debating here.... docker-for-dev or docker+npmlink ?
[2017-01-31 16:41:48] <killerspaz> you start working on something, then realize you can abstract some logic, then your main work involves iterating a dependency
[2017-01-31 16:42:13] <SISheogorath> You can work around your issue by running you container as the same user as you normal user and use yarn install to relink your dependencies but be aware of the possibility that this breaks your local dependencies
[2017-01-31 16:43:20] <iDVB> SISheogorath: that sounds hopeful.... just not sure what it means in application
[2017-01-31 16:44:16] <killerspaz> first, what environment are you@iDVB
[2017-01-31 16:44:41] <SISheogorath> Not sure what platform you're on :D try-u $(whoami)with docker run
[2017-01-31 16:44:46] <iDVB> Anyway@killerspazdon't shatter my perspective of docker. :D so far things have been REALLY great as the dev workflow.... even got it pushing blue/green deploys to AWS EB (prod) so we are so far very happy
[2017-01-31 16:45:03] <iDVB> host or container env?
[2017-01-31 16:45:06] <killerspaz> host
[2017-01-31 16:45:11] <iDVB> macOS
[2017-01-31 16:45:14] <killerspaz> this is actually a virtualbox issue, not docker
[2017-01-31 16:45:30] <killerspaz> yeah, so virtualbox on windows NOR osx support links
[2017-01-31 16:45:36] <killerspaz> from the host fs
[2017-01-31 16:45:57] <killerspaz> been an issue for about 6 years now
[2017-01-31 16:46:02] <iDVB> killerspaz: I need to read up more on that .... was not aware that vbox was used at all under the covers of docker.
[2017-01-31 16:47:00] <SISheogorath> killerspaz: docker4mac shouldn't use virtualbox anymore, should it?
[2017-01-31 16:47:05] <killerspaz> ??? it's part of the install to install vbox if it's not on your system
[2017-01-31 16:47:07] <killerspaz>  [<-LINK->] 
[2017-01-31 16:47:29] <iDVB> complete miss on my part... but coincidentally ran into this topic last night.  We're someone was saying that--net=hostalso does not work on macOS host and that you have to explicitly declare the ports with-p port:port
[2017-01-31 16:47:33] <killerspaz> oh well i suppose that's the key, was Docker Toolbox used?
[2017-01-31 16:48:52] <iDVB> With Docker for Mac, you have a new, native virtualization system running (HyperKit) which takes the place of the VirtualBox system.
[2017-01-31 16:49:22] <iDVB> sounds to me like vbox is not a dep? I DO have vbox installed though... just was not aware it was using it.
[2017-01-31 16:50:37] <killerspaz> did you use Docker for Mac, or DockerToolbox to install?
[2017-01-31 16:50:43] <killerspaz> easy test would bedocker-machine ls
[2017-01-31 16:50:55] <killerspaz> if it comes up at all, you have toolbox installed
[2017-01-31 16:51:35] <iDVB> I have it installed
[2017-01-31 16:51:49] <iDVB> does that mean I'm oldschool or newschool
[2017-01-31 16:51:51] <iDVB> :P
[2017-01-31 16:52:42] <killerspaz> i'm still using docker toolbox myself, so i guess we're both oldschool
[2017-01-31 16:53:15] <killerspaz> last i tried native docker it was too much a PITA to get running, so i'm just letting them iron out all the major issues first
[2017-01-31 16:54:12] <iDVB> ya I thought I heard there was some kinda update recently
[2017-01-31 16:55:53] <iDVB> anyway... it sounds like others have gotten a work around working... [<-LINK->] it's just its pushing my understanding of docker.
[2017-01-31 16:56:41] <iDVB> also... he's further complicating things by using Vagrant. :P
[2017-01-31 16:58:31] <SISheogorath> You mac guys... :D Running Docker in linux is so simple, works out of the box and has no problems with anything :D
[2017-01-31 16:58:58] <killerspaz> the only workaround i know is to manually symlink them
[2017-01-31 17:06:51] <iDVB> killerspaz: in application... how do I do that? I thought I had tried everything :P
[2017-01-31 17:07:56] <iDVB> SISheogorath: ha. Use the tool for the job. Didn't know Sketch and Photoshop work on Linux. ;)
[2017-01-31 17:08:53] <dragon788> he's saying run a Vagrant box that is Linux and do your Docker fun inside that :P
[2017-01-31 17:09:04] <dragon788> aka boot2docker phat style :)
[2017-01-31 17:09:29] <iDVB> ah... simlar to what this dude is doing I guess.... [<-LINK->] 
[2017-01-31 17:09:47] <iDVB> which may be a requirement to get this workflow working
[2017-01-31 17:09:48] <dragon788> the other advantage is that Vagrant provides another isolation layer, so you aren't doing un-reproducible stuff on your host+Docker that you can't perform on another machine
[2017-01-31 17:10:20] <iDVB> fair nuff..... thats my newb showing...... I thought I was doing that by using docker in the first place
[2017-01-31 17:10:21] <iDVB> :D
[2017-01-31 17:10:33] <iDVB> makes sense now though
[2017-01-31 17:11:11] <dragon788> yeah, that's a pretty good start, it's a bit complex, but one thing I found with node is the stupid depth and magic symlinking they do always ends poorly on Windows, and trying to manage your code outside of Vagrant and sharing it in using a shared folder is a recipe for pain
[2017-01-31 17:12:31] <dragon788> yeah, Docker gives you some isolation, but especially on anything but Linux, you are using additional layers of abstraction you don\'t know about (boot2docker/Virtualbox) that makes troubleshooting and the basic "link"/"expose" stuff tricky to debug
[2017-01-31 17:12:47] <SISheogorath> iDVB: If you really want everything works on linux :D :D :D
[2017-01-31 17:13:19] <dragon788> if you do it in a Vagrant box you have a simple entrypoint that works on ANY system the same way, and then you can use Docker in Linux via the Vagrant box, which keeps things very consistent
[2017-01-31 17:13:38] <SISheogorath> best example: Wine for Microsoft Office :D Don't know why people do that but there are people doing that :D
[2017-01-31 17:16:26] <dragon788> sometimes you just need that one stupid proprietaryFLOOR()function that OpenOffice might not have yet :P
[2017-01-31 17:16:47] <dragon788> I bought a license for CrossOver Office quite a while ago when it was cheap, still haven't gotten around to using it yet
[2017-01-31 17:19:17] <dragon788> if you really want a mind blowing trip, check out Jess Frizzel's (sp?)  dotfiles repository, she operates almost completely within Docker, she's using a Docker container for Firefox, for Mutt, for IRC, pretty much anything that can be shoved into a container and shared to a host session she has done so, gives an ultimate portable experience, and she even has a SICK alias that looks for a binary locally, if it can't find it then it checks the namespace to see if there is a Docker container for that command and pulls it down, otherwise it returns 'command not found'
[2017-01-31 17:19:58] <SISheogorath> Today I am nearly convinced that there is no need for most non-console software on a machine anyways. Simply caused by the fact that everything else is able to run in a webbrowser today. Nearly every usecase already has an electron/webapp :D
[2017-01-31 17:21:51] <SISheogorath> Hyper is the best example :D A terminal emulator in as electron app :D So lovely
[2017-01-31 17:24:15] <SISheogorath> I'm not sure if docker is the solution for everything :D But her dotfiles look interesting :D
[2017-01-31 17:32:34] <sbromberger> hi all
[2017-01-31 17:33:11] <sbromberger> I have a really stupid docker question. I had to reinstall docker on my mac, and now my ubuntu images don’t persist any of the apt-get updates I run in the container. Did something change? How do I get back “persistent” containers?
[2017-01-31 21:19:35] <dragon788> if you rundocker stop <containerid>they should persist if you start them again, but any time you rundocker run <imagename>it will typically create a new container
[2017-01-31 21:19:45] <phonoloop_twitter> Anyone knows how to load a .env file inside a docker file? I would like to use some data from that file to complete my build.
[2017-01-31 21:23:53] <SISheogorath> phonoloop_twitter: currently not possible explicit by Dockerfile ordocker build. You can maybe load it like in a usual shellscript in your run part.
[2017-01-31 21:24:32] <phonoloop_twitter> ok, thank you
[2017-01-31 21:24:46] <SISheogorath> you're welcome
[2017-01-31 23:41:35] <N0bl3> Hello docker community, i have trouble setting it up with webstorm am i in the right place? :)
[2017-01-31 23:42:48] <SISheogorath> In general the docker community is may not the right place to discuss problems of a JavaScript IDE :D
[2017-01-31 23:43:11] <SISheogorath> but if you have a problem with docker and webstorm working together we maybe can help
[2017-01-31 23:44:33] <SISheogorath> In general the best way to get an answer is asking the explicit question. I can also recommend: [<-LINK->] Which explains in detail the best way to get answers in IRC Channels, Forums and other community driven platforms
[2017-01-31 23:51:48] <N0bl3> SISheogorath: well ... i was able to find that this is directly to webstorm as in powershell all works fine :) So thank you anyway :D
[2017-01-31 23:52:07] <SISheogorath> you're welcome
[2017-02-01 04:35:03] <raul782> hi guys, I’ve been using docker-compose to build my local stack [<-CODE->] 
[2017-02-01 04:35:52] <raul782> The issue is that my apache server can’t connect to my redis server
[2017-02-01 04:36:12] <raul782> when It tries to connect through  localhost:6379
[2017-02-01 04:36:21] <raul782> Is there something that I’m missing
[2017-02-01 04:36:40] <raul782> I’ve checked my /etc/hosts and the only reference is the web server ips
[2017-02-01 04:36:44] <raul782> and container id
[2017-02-01 04:36:48] <raul782> I’m using docker 1.13
[2017-02-01 04:37:37] <raul782> What is strange is that I can connect to my database through localhost:3306
[2017-02-01 04:51:49] <SISheogorath> in your container you have to use you database container name/link-alias to connect to it. (in your casedatabase) instead of local host.
[2017-02-01 04:52:22] <SISheogorath> Containers don't have the loopback ports of your host environment
[2017-02-01 04:52:50] <SISheogorath> as they have their ownlodevice
[2017-02-01 05:27:01] <patsissons> dockerfile question, if my base image defines a volume, is it just redundant to also define the same volume?
[2017-02-01 05:30:47] <raul782> SISheogorath: thanks, you were right I needed to use redis on apache, you made my day :)
[2017-02-01 05:56:52] <gadget_mnky_twitter> patsissons: do you really need to define it? Most of the host mounted volumes are usually -v and done iirc
[2017-02-01 05:57:07] <gadget_mnky_twitter> To answer your question specifically, it is redundant
[2017-02-01 06:40:18] <soapoperator> hello, i use docker-compose to run some container (wordpress for exemple), do you have a clever solution to deal with the permission issue: volumes use ww-data:www-data.I try to adduser :"1000:1000"but it get a connexion error.The only solution i find is to add my usr to www-data group thenchmodthe folder. But it\'s not very elegant and a n arg in docker-compose could be more consistent.
[2017-02-01 06:41:06] <gadget_mnky_twitter> that sounds a bit off
[2017-02-01 06:41:10] <gadget_mnky_twitter> odd*
[2017-02-01 06:41:12] <gadget_mnky_twitter> could you elaborate a tad more
[2017-02-01 06:41:29] <gadget_mnky_twitter> on how you are running the container? and where is the folder ?
[2017-02-01 06:48:29] <soapoperator> @gadget_mnky_twitter for exemple, i run the file: [<-CODE->]  [<-CODE->] 
[2017-02-01 06:50:39] <soapoperator> But i try to install directly in another container apache + mariadb + php but i get an 500 error during the install... And i suspect the container user don't have right to copy and edit wp-config file.
[2017-02-01 07:01:47] <patsissons> gadget_mnky_twitter: thanks, that was my suspicion.
[2017-02-01 07:16:09] <coding-yogi> Does docker-compose up also build the image?
[2017-02-01 07:16:29] <coding-yogi> or i explicitly need to build and then run up
[2017-02-01 07:17:01] <coding-yogi> also is run only used to start a single docker container?
[2017-02-01 08:10:38] <ahmadiq> @aniket-21 docker-compose up will build the image if it doesn't exist already.after that it will run without rebuild the image unless run with --build optiondocker-compose run is used to execute a one-time command in one of the services  configured in the docker-compose file
[2017-02-01 08:11:46] <coding-yogi> thanks@ahmadiq
[2017-02-01 08:12:26] <coding-yogi> I have a docker compose file where I am creating an image for my microservice and also it needs a rabbitmq image..so I have both in compose file
[2017-02-01 08:13:00] <coding-yogi> now before I bring up the containers, can i run a command with "run" in rabbitmq image?>
[2017-02-01 08:16:23] <ahmadiq> it will execute the command in the container one time, but if the service has links,  it will start those containers as well, but probably wont stop them i think
[2017-02-01 08:17:12] <ahmadiq> what kind of command are you trying to run in the rabbitmq image btw.there may be an easier way of what you're trying to accomplish
[2017-02-01 08:17:57] <coding-yogi> just a work around for now, microservice is expecting one exchange to be available and its not creating the same if its not available
[2017-02-01 08:18:08] <coding-yogi> this needs a code fix on microservice side
[2017-02-01 08:18:29] <coding-yogi> but as a workaround, I wish to use rabbitmq commandline to create that exchange
[2017-02-01 08:18:44] <coding-yogi> before my microservice starts
[2017-02-01 08:22:14] <ahmadiq> perhaps you can use thecommandoption in the compose file to specify the command to run in the rabbitmq container, and specifydepends_onoption in the other service so that the rabbitmq container always starts before the other one
[2017-02-01 08:23:38] <coding-yogi> but it says it overrides default command
[2017-02-01 08:24:09] <coding-yogi> does that mean it overrides CMD from Dockerfile?
[2017-02-01 08:24:21] <gadget_mnky_twitter> yes
[2017-02-01 08:24:37] <gadget_mnky_twitter> if compose has a separate command specified, the one in Dockerfile will be overridden.
[2017-02-01 08:24:44] <gadget_mnky_twitter> rule of thumb: There is always 1 command that is executed
[2017-02-01 08:25:07] <coding-yogi> yep, that's why I am not using that
[2017-02-01 08:25:26] <coding-yogi> cos default command starts the rabbitmq server
[2017-02-01 08:25:40] <gadget_mnky_twitter> you can always add to that in your dockerfile using &&
[2017-02-01 08:25:47] <gadget_mnky_twitter> though it may not be the best thing to do
[2017-02-01 08:28:39] <coding-yogi> that can be one of the options
[2017-02-01 09:03:38] <pkariz> hi, i have docker-compose.yml which starts 4 containers (all needed always). Whats the \'sequence\' i should use for development? im thinking "docker-compose up" and "docker-compose down" after i finish...is that ok?
[2017-02-01 10:22:14] <gadget_mnky_twitter> that should be just fine
[2017-02-01 10:22:40] <gadget_mnky_twitter> if you are building a service at runtime using compose, you can also use reload/restart
[2017-02-01 11:51:25] <pkariz> ok ty
[2017-02-01 18:29:54] <anand79> Hi I am new to docker. When I do docker run hello-world in windows 7 where does the image files get copied to?
[2017-02-01 18:33:10] <anand79> I downloaded docker toolbox and running it from the docker terminal
[2017-02-01 19:14:31] <leon> Hi! I’m playing around with docker and spring boot.Spring boot apps get built with gradle and outputs a fat jar.But when I want to deploy said fat jar, I only need the JRE, not the JDK.What are the best practices when it comes to apps that need a build step, such as angular-cli apps, spring boot apps?
[2017-02-01 19:15:45] <leon> I want to be able to use the docker cloud auto build / test features to build my spring boot apps, and my angular apps, but then take the output of the build and store it in another image which only contains the artifacts from the first build
[2017-02-01 19:16:06] <leon> which is optimized for runtime
[2017-02-01 19:18:55] <SISheogorath> Why ship the output around? Simply build it and keep it in your image. Install all build dependencies, build your app and delete the dependencies and unnecessary packages/libraries/etc.
[2017-02-01 19:19:35] <SISheogorath> But if you really want use a buildhook for it and do crazy things
[2017-02-01 19:28:05] <SISheogorath> leon: But I also know some people who try to avoid a rebuild in the docker image so they simply install their build artifacts to the container and start them
[2017-02-01 19:29:47] <leon> Since I’m thinking about using docker cloud to do continuous deployment, it would be best if everything was build and tested by docker cloud
[2017-02-01 19:30:01] <leon> if this is a pipe dream or not time will have to tell
[2017-02-01 19:31:19] <leon> I’ve been using gradle’s docker plugin to build and push images which workes great, so I could still use that for deployment, but use docker cloud’s auto test feature to run the gradle tests on git pushes and pull requests
[2017-02-01 22:35:58] <Vernuft123> Hi, im using kitematic and downloaded an image. Its started up and i can see the IP. I also have Virtual Box Boot 2 Dock running.
[2017-02-01 22:36:04] <Vernuft123> How can i acces this image?
[2017-02-01 22:36:26] <Vernuft123> I tried [<-LINK->] 
[2017-02-01 22:46:23] <Vernuft123> i can also ping it 192.168.99.100:32768
[2017-02-02 00:41:45] <dragon788> is the image setup with an "EXPOSE" or can you supply that as part of your run command?
[2017-02-02 01:02:22] <robdoesstuff> Hi Guys, I'm super frustrated with a really basic networking issue and am wondering if anyone could shed some light on this. It's really pretty simple: I have a little webserver (karma) that runs on port 9876, and it spawns another process (phantomjs) which connects to port 9876 and runs the tests. None of this is to be exposed or externally mapped. All I need is karma binding to 0.0.0.0:9876 and phantomjs to connect to <whateverinterface>:9876. The problem is that this doesn't seem to work at all in Docker 1.12 or 1.13 on Linux or OSX. Any ideas?
[2017-02-02 01:38:32] <SISheogorath> @robdoesstuff if you can share some run statements, sure we will have some ideas. [<-CODE->] 
[2017-02-02 03:02:36] <robdoesstuff> Same container. You can test this with any container which has any port.
[2017-02-02 03:02:55] <robdoesstuff> just run your container and then exec -t -i <container> sh
[2017-02-02 03:03:07] <SISheogorath> and what did you run there?
[2017-02-02 03:03:08] <robdoesstuff> an in the shell, do netstat -ln to see what ports it is listening on internally
[2017-02-02 03:03:32] <robdoesstuff> and then try to telnet to localhost or the container internal ip at the port and see if you establish a connection
[2017-02-02 03:03:42] <robdoesstuff> Sorry, what do you mean what did I run there?
[2017-02-02 03:03:47] <robdoesstuff> "docker run <container>"
[2017-02-02 03:04:32] <robdoesstuff> Steps are: 1) Run container. 2) Go into shell inside container. 3) Try to connect to any internal service port.
[2017-02-02 03:04:35] <SISheogorath> I know it works because I have done that mutiple times ._. That's howHEALTHCHECKs work
[2017-02-02 03:04:48] <robdoesstuff> really?
[2017-02-02 03:05:01] <robdoesstuff> I spent 4 hours today trying this every which way
[2017-02-02 03:05:18] <robdoesstuff> I can access the port externally from outside the container when I map it (-p port:port)
[2017-02-02 03:05:42] <robdoesstuff> so I can connect my host browser into karma running in the container like that
[2017-02-02 03:05:43] <SISheogorath> trydocker run -d --name inspircd inspircd/inspircd-docker && docker exec -it inspircd telnet 127.0.0.1 6667
[2017-02-02 03:05:45] <robdoesstuff> but that's really not the objective :)
[2017-02-02 03:06:00] <robdoesstuff> let me check that out.
[2017-02-02 03:07:06] <robdoesstuff> wtf
[2017-02-02 03:07:17] <SISheogorath> not sure thattelnetexists in the container :D if case it doesn't you can also runnc:D
[2017-02-02 03:07:30] <robdoesstuff> right I was using alpine so didn't have nc
[2017-02-02 03:07:41] <robdoesstuff> Ok so I see a difference
[2017-02-02 03:07:43] <robdoesstuff> I'll show you.
[2017-02-02 03:07:47] <robdoesstuff> btw it does work right there
[2017-02-02 03:07:58] <robdoesstuff> telnet localhost 6667 from inside the container connected and jumped into ident
[2017-02-02 03:09:56] <robdoesstuff> Here is the netstat from the working container:
[2017-02-02 03:09:58] <robdoesstuff> tcp        0      0 :::6667                 :::*                    LISTEN
[2017-02-02 03:10:02] <robdoesstuff> and from the non-working one:
[2017-02-02 03:10:13] <robdoesstuff> tcp        0      0 0.0.0.0:9876            0.0.0.0:*               LISTEN
[2017-02-02 03:10:24] <robdoesstuff> So apparently you must bind to IPv6
[2017-02-02 03:10:31] <robdoesstuff> in order for ip4 to work...
[2017-02-02 03:10:33] <robdoesstuff> :(
[2017-02-02 03:10:44] <robdoesstuff> Sounds like a familiar bug
[2017-02-02 03:10:48] <SISheogorath> not sure. can you share the container?
[2017-02-02 03:10:54] <robdoesstuff> I can't unfortunately, private repo
[2017-02-02 03:11:00] <SISheogorath> I see, no problem
[2017-02-02 03:11:00] <robdoesstuff> let's see
[2017-02-02 03:11:19] <robdoesstuff> yeah there isn't a super fast way for me to share that
[2017-02-02 03:12:37] <robdoesstuff> Can I see your dockerfile?
[2017-02-02 03:12:51] <SISheogorath>  [<-LINK->] 
[2017-02-02 03:12:57] <robdoesstuff> ty
[2017-02-02 03:13:46] <robdoesstuff> that's a beautiful run layer for building inspircd :)
[2017-02-02 03:14:14] <SISheogorath> yes :D more-vvv-> [<-LINK->] 
[2017-02-02 03:14:32] <robdoesstuff> I came across a similar one today for building phantomjs
[2017-02-02 03:14:37] <robdoesstuff> yeah alpine has been working great for us
[2017-02-02 03:14:47] <robdoesstuff> other than the issue I'm having right now
[2017-02-02 03:15:08] <SISheogorath> phantomjs on alpine is a bit unperfect
[2017-02-02 03:15:19] <robdoesstuff> I'm thinking of making a new base layer which is node alpine w/headless browser for running tests
[2017-02-02 03:15:24] <robdoesstuff> why unperfect?
[2017-02-02 03:15:39] <robdoesstuff> the bin hardly added any footprint
[2017-02-02 03:17:16] <SISheogorath>  [<-LINK->] <-- working to fix their phantomJS setup but currently still broken :/
[2017-02-02 03:17:58] <robdoesstuff> oh I found a totally different way to do that today that worked for me
[2017-02-02 03:18:12] <robdoesstuff> well first of all there is a prebuilt version we're using now that's in an npm
[2017-02-02 03:18:15] <SISheogorath> share it?
[2017-02-02 03:18:28] <robdoesstuff> but I found this run command to build it on alpine and delete all the deps, leaving just the bin
[2017-02-02 03:18:31] <robdoesstuff> yeah finding..
[2017-02-02 03:18:53] <robdoesstuff>  [<-LINK->] 
[2017-02-02 03:22:39] <robdoesstuff> Ugh, perhaps this was a red herring
[2017-02-02 03:22:44] <robdoesstuff> Here's my new netstat -ln
[2017-02-02 03:22:47] <robdoesstuff> tcp        0      0 :::9876                 :::*                    LISTEN
[2017-02-02 03:22:53] <robdoesstuff> and I still can't establish connection...
[2017-02-02 03:27:33] <robdoesstuff> I'm wondering if there's something about the incoming connection that makes node.js freeze and not establish?
[2017-02-02 03:42:24] <SISheogorath> not sure as mentioned I had some crazy problems with phantomJS on alpine not sure if it is involved here
[2017-02-02 08:44:32] <ioleo> how to push to insecure docker registry? I'm getting this error:[error] Get https://10.10.10.181/v1/_ping: dial tcp 10.10.10.181:443: getsockopt: connection refused
[2017-02-02 08:45:02] <ioleo> the registry was run bydocker run -n registry -p 5000:5000 registry:2
[2017-02-02 08:48:01] <ioleo> Ubuntu 16 client, systemd upstart, I\'ve modified the/etc/docker/daemon.jsonto include{ "insecure-registry": ["10.10.10.181:5000"] }, I also added/lib/systemd/system/docker.service.d/override.confwith following contents: [<-CODE->] 
[2017-02-02 08:48:55] <ioleo> then I startedsudo service docker startandps aux | grep dockergives me:0:01 /usr/bin/dockerd -H fd:// --insecure-registry=10.10.10.181:5000
[2017-02-02 08:50:35] <ioleo> I can [<-CODE->] 
[2017-02-02 09:54:49] <sudharsans> I have a deployed a springboot app and mysql db on docker swarm. The app unable to connect to the mysql on port 3306. It works perfect in docker single host using "docker run" command but not on docker swarm mode. any help? I dont see any errors in the docker logs.
[2017-02-02 10:57:11] <SISheogorath> sudharsans: create an overlay networkdocker network create -d overlay somenetworknameand start mysql and your app with--network somenetworkname
[2017-02-02 10:58:24] <SISheogorath> loostro: what's your push command?
[2017-02-02 10:59:05] <coding-yogi> I am facing this issue of file name too long with sbt build [<-LINK->] 
[2017-02-02 10:59:23] <coding-yogi> and setting max file name size to 72 doesn't help
[2017-02-02 10:59:36] <coding-yogi> issue happens cos docker storage is encrypted
[2017-02-02 11:00:00] <coding-yogi> anyway to have unencrypted storage on docker? I didnt get any solution around this
[2017-02-02 11:25:47] <ioleo> SISheogorath: docker push 10.10.10.181:5000/myimage
[2017-02-02 11:27:26] <SISheogorath> looks fine ._.
[2017-02-02 13:35:16] <argeas> hi all:I am trying to start a container and have it see a specific device(phone) is it possible instead of : docker run -d  -t -i --device=/dev/bus/usb/001/066 .   to use the device serial number? at the docker run command ?
[2017-02-02 14:04:00] <dragon788> it probably can't see the device's serial number with that USB access, what you'd need to do is a pre-script that queries the serial number on the host side and resolves it to the correct USB bus and passes that into the run command
[2017-02-02 14:18:34] <argeas> dragon788: thought the same.. thanks !
[2017-02-02 15:26:47] <killerspaz> having a hell of a time compiling v4l on alpine cuz of damn musl crap
[2017-02-02 19:17:58] <austinfrey> is there any downtime to currently running services when running astack updateto  add a new service to the stack?
[2017-02-02 19:19:01] <killerspaz> i'd assume existing connections will yield to their TTL while new ones are routed to the new container instances
[2017-02-02 19:21:19] <austinfrey> so you'd guess that only changes would be implemented, current services would be untouched.  just wasn't sure if it essentially stops the current stack and starts everything all at once with the new stack config or just looks for changes in the config and implements those
[2017-02-02 19:21:20] <austinfrey> thanks
[2017-02-02 21:07:11] <SISheogorath> currently docker starts the new service, waits until it's healthy and once that's done it stops the old instance or stops the update process
[2017-02-02 21:18:14] <killerspaz> Any idea what i'm doing wrong? [<-CODE->] 
[2017-02-02 21:18:29] <killerspaz> is it because there's a space?
[2017-02-02 21:19:16] <killerspaz> oh wait, i just realized the destination is all wacky... wtf?
[2017-02-02 21:32:03] <killerspaz> ah... some reason i need an extra / a the beginning beforepwd
[2017-02-03 04:28:45] <ely029> hey gang how to setup a database in dockerized mssql server
[2017-02-03 04:28:59] <gadget_mnky_twitter> ely029: could you be more specific ?
[2017-02-03 04:29:21] <gadget_mnky_twitter> you can mount a set of sql files in a given location and those would be executed when you start the container
[2017-02-03 04:29:27] <gadget_mnky_twitter> official documentation provides that
[2017-02-03 04:29:54] <ely029> Awww I will set it up in volume in yaml file
[2017-02-03 04:30:04] <gadget_mnky_twitter> yeps
[2017-02-03 04:30:15] <ely029> damn haha I just a beginner
[2017-02-03 04:30:16] <gadget_mnky_twitter> just mount the volume with .sql files and map it to entrypoint folder
[2017-02-03 04:30:18] <gadget_mnky_twitter> that’s all
[2017-02-03 04:30:47] <ely029> How to test it if the database is created?
[2017-02-03 04:30:57] <gadget_mnky_twitter> or trace logs
[2017-02-03 04:30:59] <gadget_mnky_twitter> just login :)
[2017-02-03 04:31:38] <ely029> docker run -it?
[2017-02-03 04:31:45] <ely029> in the container?
[2017-02-03 04:31:55] <gadget_mnky_twitter> if you are exposing the mysql port to host, just directly run mysql and connect
[2017-02-03 04:32:14] <gadget_mnky_twitter> or you can do a docker logs -f <ID> and you will see if those files are picked up and executed; or not
[2017-02-03 04:33:11] <ely029> <ip>:<port> i just run it on the browser?
[2017-02-03 04:33:26] <gadget_mnky_twitter> command line login for mysql?
[2017-02-03 04:34:16] <ely029> I just try the docker logs -f ^_^
[2017-02-03 04:34:23] <ely029> it works haha
[2017-02-03 04:34:48] <ely029> thanks@gadget_mnky_twitter
[2017-02-03 08:53:59] <4406arthur> Hi all,I wonder that  the lantency  in swarm replicated services model ,if  I set redis replica = 3,  the state of them always keep same ?
[2017-02-03 09:32:23] <SISheogorath> what type of state are you talking about? docker doesn't manage the memory and process management of the application. If you run redis and scale it up to 3 swarm makes sure that there are always 3 redis instances running. How they kept in sync is your/the applications problem
[2017-02-03 09:47:47] <4406arthur> you are right, but I didn’t setup redis cluster config, swarm mode also sync it
[2017-02-03 20:42:32] <killerspaz> Hopefully a quick question... Running Win10, Docker Toolbox, rancheros as docker-machine, and trying to volume mount/dev:/devi get\\dev: "\\\\dev" includes invalid characters for a local volume name, only "[a-zA-Z0-9][a-zA-Z0-9_.-]" are allowedWHYYYY??
[2017-02-03 21:18:27] <dragon788> on a Linux guest /dev might be valid, but on Windows that wouldn't fly without a drive specification, and it looks like it is auto escaping possibly which could make the path look like a network share instead of a local drive, really not sure of the inner workings of that
[2017-02-03 21:41:31] <killerspaz> but shouldn't it use the the  VM as the host fs?
[2017-02-03 22:18:44] <dragon788> so you aren't running the new Hyper-V Windows 10 containers Docker?
[2017-02-03 22:30:18] <killerspaz> no, i'm not on win10 pro
[2017-02-04 00:33:38] <nicerobot> Any thoughts on why I can't push to the hub:The push refers to a repository [docker.io/gomatic/consul-counselor]8dc0cc6f4569: Preparing5219b78e6a9f: Preparingf1694154f634: Preparing80dbddac2850: Preparing5a08f956331b: Preparing7cbcbac42c44: Waitingdenied: requested access to the resource is deniedI'm pushingdocker push gomatic/consul-counselor:latest
[2017-02-04 00:40:29] <killerspaz> did you docker login?
[2017-02-04 00:42:16] <nicerobot> yea but my login is a different account/namespace.gomaticis configured as an org that my account admins. is there a  way i'm supposed to specify that? likedocker push [account]/gomatic/consul-counselor:latestor something? (i think i've tried that, i don't remember, tried so many variations)
[2017-02-04 00:45:46] <killerspaz> I'm not certain on dockerhub honestly, i use a private registry, just threw it out there
[2017-02-04 00:55:23] <nicerobot> No worries. I mostly use a private registry too but this is a little opensource project i work on and was just hoping to put the container out there.
[2017-02-04 01:10:41] <myuseringithub> Persist environment variables to docker-machine: How can I pass environment variables from host to virtual docker machine, and persist them even after ssh'ing ?e.g. export X=value; docker-machine ssh <VM>; echo $X;Using Git Bash on Windows
[2017-02-04 01:15:22] <byhub> Hi there everyoneit is nice to be part of your group :slightly_smiling_face:Want to be close to where freelancers/nomads feel home.. since I am starting a new service for freelancers very soon.. I dont like making too much noise; but in case anyone interested , please contact me directly..and here is my short pitch :slightly_smiling_face:Get freelance projects delivered to your inbox every week - sign up at http://freelance.kobikit.com    #freelance #leads #webdev #design #ux #ui
[2017-02-04 01:53:45] <myuseringithub> Workarounddocker-machine ssh machine "echo \'export VAR=$PWD\' >> ~/.profile"
[2017-02-05 10:21:51] <revisualize> What is currently the best way / website / option for learning Docker?
[2017-02-05 10:22:24] <gadget_mnky_twitter> revisualize: just go through [<-LINK->] #/ this is something i always pass on to new folks
[2017-02-05 10:22:35] <gadget_mnky_twitter> it should be good to build up on fundamentals
[2017-02-05 10:23:03] <revisualize> gadget_mnky_twitter: I'll check it out. Thanks.
[2017-02-05 10:26:59] <revisualize> Are there any good video walkthroughs?
[2017-02-05 12:33:45] <LuisUrrutia> Hi everyone, i have a little noob question about Dockerfile.This file is executed entirely everytime that i run "docker run image"? or it executes only what it\'s in CMD or ENTRYPOINT?
[2017-02-05 12:49:14] <snimavat> does any one know why the time is out of sync for docker native on osx
[2017-02-05 12:49:16] <snimavat>  [<-ISSUE->] 
[2017-02-05 12:50:25] <snimavat> I am unable to pull my own public image
[2017-02-05 12:50:46] <snimavat> it downloads some layers, and thn fails with unauthorized error
[2017-02-05 16:34:11] <egyptianpharoh> I am facing device mapper issues, the following error occurs after I restarted the docker daemon:level=fatal msg="Error starting daemon: error initializing graphdriver: devmapper: Base Device UUID and Filesystem verification failed: devmapper: Current Base Device UUID: does not match with stored UUID:696f3567-83d7-48d7-9675-688e8543534b. Possibly using a different thin pool than last invocation" the workarounds could cause docker image/container data loss, is there any other work around?
[2017-02-05 17:37:32] <egyptianpharoh> Any help? this is an urgent matter
[2017-02-05 17:37:33] <egyptianpharoh> Thank you
[2017-02-05 17:40:42] <snimavat> Does bigger docker images take more RAM ?
[2017-02-05 17:41:00] <snimavat> for exaple mysql in debian jessie vs mysql on alpine ?
[2017-02-05 19:03:38] <killerspaz> Not because it's a bigger image, but because more is operating.... You can have an Alpine based image with a 2gb file copied to it and it'd consume less memory than a standard debian image.
[2017-02-05 19:05:08] <killerspaz> snimavat: likely the daemon hung a short bit, enough for the timediff to be great enough to invalidate requests. You should be able to restart the daemon (docker-machine restart)
[2017-02-06 00:59:27] <SISheogorath> egyptianpharoh: if you rely on docker and have no time to fix everything yourself I really recommend you Docker CS. To your actual problem I can't really help you with it as there are tons of information missing like that you did before, what you did when it caused and what work arounds you are talking about. But as this is a chat it's not the right place for all this information. Maybe open an Thread on [<-LINK->] or on Stack Overflow.
[2017-02-06 01:08:05] <SISheogorath> LuisUrrutia: Dockerfile is something like a makefile for Docker images. So it runs ondocker buildin case you usedocker runand the image has information about an "entrypoint script" it runs the entrypoint script withCMDas parameter (in case you don\'t specify anything else after the image name in you run statement). If there is no entrypoint script specified it runs theCMDstatement directly. Here we depend on your way to specify it. In case you writeCMD "./somecommand arg1 arg2"it\'ll call the specified command with the defined default shell (in regular/bin/sh -c). In case you use the array notation (CMD ["somecommand", "arg1", "arg2"]) it calls the command directly without the shell.
[2017-02-06 13:07:59] <marcelmfs> egyptianpharoh: here's one fix: [<-LINK->] 
[2017-02-06 15:09:22] <snimavat> killerspaz: -- i am on osx, i did not create any docker-machine
[2017-02-06 15:09:32] <snimavat> when i do date command on osx, i see ist time
[2017-02-06 15:09:44] <snimavat> when i do docker info command, it shows me UTC time
[2017-02-06 15:26:16] <marcelmfs> snimavat: osx's docker VM is set to be UTC, you don't have an option there.
[2017-02-06 15:27:19] <marcelmfs> What you CAN do, however, is to create a docker image with a different TZ setting, it's up to you to set that up.
[2017-02-06 15:28:19] <marcelmfs> in order to check the TZ setting of the docker machine (VM served by Xhyve hypervisor on osx), do the following:
[2017-02-06 15:28:22] <marcelmfs> screen -AmdS docker ~/Library/Containers/com.docker.docker/Data/com.docker.driver.amd64-linux/tty
[2017-02-06 15:28:30] <marcelmfs> screen -S docker -p 0 -X stuff
[2017-02-06 15:28:41] <marcelmfs> screen -r docker
[2017-02-06 15:28:49] <marcelmfs> then:cat /etc/TZ
[2017-02-06 15:29:36] <marcelmfs> you can also change the contents of/etc/TZ, but that will be volatile, if you reinstall/restart docker you'll lose that change.
[2017-02-06 15:30:48] <marcelmfs> to disconnect from thescreensession, doControl-A, D, and then to kill the screen:screen -S docker -X quit
[2017-02-06 15:36:30] <killerspaz> snimavat: i was under the impression that docker for osx still requires a VM, which must be created via docker-machine
[2017-02-06 15:50:11] <snimavat> nope, now its a native application, and dont need docker-machine
[2017-02-06 16:43:03] <LuisUrrutia> SISheogorath: Thanks u very much for the explanation! :D
[2017-02-06 18:32:52] <SISheogorath> killerspaz: Docker still uses a VM but it doesn't rely on any non-native libraries to do it. It uses some kind of Virtualisation layer based in MacOS kernel.
[2017-02-06 18:33:25] <SISheogorath> LuisUrrutia: you're welcome
[2017-02-06 21:11:20] <Crizstian> Hello community this week, i’m bringing to you the third part of the series in "Build a NodeJS cinema microservice", that i wrote @medium and  it’s fully charged of nodejs development, as always i’m open to get feedback, contributions, or just a comment below =]https://medium.com/@cramirez92/build-a-nodejs-cinema-booking-microservice-and-deploying-it-with-docker-part-3-9c384e21fbe0#.4il886ym9
[2017-02-06 22:13:00] <phonoloop> Hey, i’m trying to set up a static ip for my service. I’m following the [<-LINK->] guide but I keep getting “Service app uses an undefined network app_net”. Am I missing something?
[2017-02-06 22:27:28] <SISheogorath> Depends on your docker-compose file
[2017-02-06 22:29:17] <phonoloop>  [<-CODE->] 
[2017-02-06 22:29:23] <phonoloop> i have this now
[2017-02-06 22:29:58] <phonoloop> and it's giving me the following error: ERROR: The Compose file './../../docker-compose.yml' is invalid because:Unsupported config option for services.networks: 'app_net'
[2017-02-06 23:14:34] <killerspaz> phonoloop: ,networksneeds to be an array:
[2017-02-06 23:14:39] <killerspaz>  [<-LINK->] 
[2017-02-06 23:38:27] <LuisUrrutia> Hi there,I have 3 webapps (angular), so i want to know if i want to deploy it through docker i have to:create 1 docker for every webapp and (3 dockers) + 1 docker of nginx? \ncreate 1 docker for every webapp with nginx in every container (3 dockers webapp + nginx)?\ncreate a single docker with all of this?I want to update every single webapp in isolated way.. so what is the best way to archive that?
[2017-02-06 23:40:42] <dragon788> You could use a single nginx to front and potentially load balance your applications but you'll need to manage service discovery using one of the many tools available
[2017-02-06 23:41:09] <dragon788> Keeping your other applications isolated is a good idea
[2017-02-06 23:42:11] <LuisUrrutia> So, i have to create 1 container with nginx, and 1 container for every webapp right? 4 container in total, right?
[2017-02-06 23:43:03] <SISheogorath> I personally would prefer traefik instead of nginx as loadbalancer
[2017-02-06 23:45:00] <SISheogorath> As an API driven reverse Proxy its more or less the future
[2017-02-06 23:48:24] <LuisUrrutia> oh, all right, but with traefik my webapps must be served by a web server or not? i mean, reverse proxy doesn't serve files right? this just link to an internal service running in a port, or not?
[2017-02-06 23:52:42] <SISheogorath> yes, that's correct
[2017-02-06 23:54:08] <LuisUrrutia> Which webserver would you recommend? express, nginx, apache, other?
[2017-02-06 23:57:04] <SISheogorath> if you already serve your webpage using NodeJS than express is the right choice. In case you have no backend: nginx as fastest or apache as most common webserver.
[2017-02-07 00:01:50] <killerspaz> nginx is good and can be a super simple setup, but the docs are horrible
[2017-02-07 00:02:35] <killerspaz> let me rephrase, the docs are good, but not even near thorough
[2017-02-07 00:13:02] <LuisUrrutia> oh ok, thanks u very much@dragon788@SISheogorath@killerspaz! :D
[2017-02-07 00:23:33] <SISheogorath> killerspaz: the wonderful docs from apache are the reason I still stay with it :D
[2017-02-07 00:29:13] <killerspaz> the wonderful memory leak it's had since it's inception is the reason i don't :P
[2017-02-07 00:29:36] <killerspaz> honestly i just started using nginx about a year ago, and not in too advanced of ways yet
[2017-02-07 00:29:45] <killerspaz> hardest thing i've done with it is ssl websockets
[2017-02-07 00:29:49] <killerspaz> and that wasn't that hard
[2017-02-07 00:31:01] <SISheogorath> nginx as reverse proxy in docker -> If it can't resolve the ip of the service the container dies... That was annoying and there is only a ugly workaround
[2017-02-07 01:49:44] <w0rldart> A bit unrelated, but would anybody have any thoughts on this GlusterFS matter? [<-LINK->] trying to setup a shared volume where I'd eventually replicate it for private docker images
[2017-02-07 01:55:17] <SISheogorath> w0rldart: -> [<-LINK->] 
[2017-02-07 01:55:40] <w0rldart> reading time
[2017-02-07 01:55:41] <w0rldart> thank you
[2017-02-07 03:10:12] <raul782> Hey guys, I have a rails app and a redis service using docker for Mac, I want to configure redis to be master/slave in different IPs, I believe I need to use docker-machine correct?
[2017-02-07 03:12:15] <killerspaz> you can spin up another docker machine, sure
[2017-02-07 03:12:35] <killerspaz> would it suffice to build a separate docker-compose and use an alternate network?
[2017-02-07 03:12:41] <killerspaz> that would be less overhead on your system
[2017-02-07 06:36:53] <ely029> guys in the production server? what do you prefer in booting a docker container? create a .sh file or start it from running docker-compose up in the terminal?
[2017-02-07 06:39:10] <ixiadev1_twitter> we should run it from docker-compose
[2017-02-07 06:39:37] <ixiadev1_twitter> but usually, I have installed Rancher to manage it
[2017-02-07 06:53:56] <ely029> I have problem in docker. It seems the php and apache is started up but When I was refreshing the php file its looks like a text file
[2017-02-07 06:55:03] <trongtranit_twitter> Can you share your problem here
[2017-02-07 06:55:15] <trongtranit_twitter> maybe someone will help you
[2017-02-07 06:55:33] <ely029> alright
[2017-02-07 06:55:42] <ely029> here is the scenario.
[2017-02-07 06:55:47] <trongtranit_twitter> and also, you should ssh into the container to see error log
[2017-02-07 06:56:59] <ely029> I ran the docker-compose then its all up then WHen I refresh the php file is not working correctly but when I running a html file its looks fine
[2017-02-07 06:57:08] <ely029> I think the problem is the php?
[2017-02-07 06:58:20] <trongtranit_twitter> does the Apache not run or your web app failed?
[2017-02-07 06:59:20] <ely029> the apache is up and running
[2017-02-07 06:59:51] <ely029> I am just make a sample phpinfo in a php file
[2017-02-07 07:00:04] <ely029> thats weird
[2017-02-07 07:00:21] <ely029> this is my docker-compose and dockerfile codes
[2017-02-07 07:00:43] <trongtranit_twitter> hum, weird
[2017-02-07 07:02:22] <ely029> docker-compose.yml [<-CODE->] 
[2017-02-07 07:03:07] <ely029> dockerfile [<-CODE->] 
[2017-02-07 07:03:39] <ely029> when I use html file it is working perfectly
[2017-02-07 07:03:41] <ely029> weird
[2017-02-07 07:07:51] <trongtranit_twitter> see these links, maybe it help you
[2017-02-07 07:07:52] <trongtranit_twitter>  [<-LINK->] 
[2017-02-07 07:07:58] <trongtranit_twitter>  [<-LINK->] 
[2017-02-07 07:08:12] <ely029> thasnks I will check that out
[2017-02-07 07:08:24] <trongtranit_twitter> it was not came from docker
[2017-02-07 07:12:28] <ely029> yeah my I think the problem is on the configurations
[2017-02-07 07:12:46] <ely029> of ini files I will this one out
[2017-02-07 07:13:52] <ely029> thanks by the@trongtranit_twitter
[2017-02-07 07:14:00] <trongtranit_twitter> you are welcome
[2017-02-07 09:33:24] <jeserkin> hey guys
[2017-02-07 09:34:18] <jeserkin> can there be multipleEXPOSEcalls in same Dockerfile?
[2017-02-07 09:36:40] <jMonsinjon> Hi, not a best practice but yes you can !
[2017-02-07 09:44:07] <jeserkin> I've just looked at 3 different components
[2017-02-07 09:44:25] <jeserkin>  [<-LINK->] 
[2017-02-07 09:44:48] <jeserkin>  [<-LINK->] 
[2017-02-07 09:45:05] <jeserkin>  [<-LINK->] 
[2017-02-07 09:45:27] <jeserkin> and at the end two of them have different ports
[2017-02-07 09:46:09] <jeserkin> I would like to group those 3 components under 1 Dockerfile :)
[2017-02-07 10:08:12] <jMonsinjon> Hi@jeserkin, lot of work for doing that. Keep in mind that your container's lifecycle will be associate to the PID 1 lifecycle. (That's why in httpd and apache2, the CMD instruction launchs the applications in foreground). So you have to choose wich one will run in foreground...
[2017-02-07 10:43:05] <jeserkin> I did hope, that it would be easier, but I haven't found any suitable container for my needs...sadly
[2017-02-07 10:43:34] <jeserkin> As mentioned I do require debian, apache2.4, mysql and php7
[2017-02-07 10:43:56] <jMonsinjon> In the same container ?
[2017-02-07 10:44:01] <jeserkin> Yes
[2017-02-07 10:44:05] <jeserkin> As one vm
[2017-02-07 10:44:25] <jMonsinjon> Couldn't mysql stay in its own container ?
[2017-02-07 10:45:17] <jeserkin> What would I win with that? Generaly on hosting everything is in same place if we are not talking about AWS of course.
[2017-02-07 10:46:17] <jMonsinjon> In Docker philosophy, a container only run a single process
[2017-02-07 10:46:46] <jMonsinjon> If you want to use Mysql, run a mysql container
[2017-02-07 10:47:10] <jMonsinjon> You want tu run an apache server with httpd ? Run an apache container
[2017-02-07 10:47:23] <sopanshewale> in service - one container
[2017-02-07 10:48:34] <Vernuft123> Hi everyone, I want to use docker but i am receiving this error [<-LINK->] 
[2017-02-07 10:48:45] <Vernuft123> An this is how i setup my BIOS: [<-LINK->] 
[2017-02-07 10:49:00] <Vernuft123> Im ready to give up on docker because i cant seems to get it working on Windows 10
[2017-02-07 10:49:24] <Vernuft123> Looking for some advice
[2017-02-07 10:52:31] <jMonsinjon> jeserkin: In your case, I would take the Apache Dockerfile, and I would add a RUN instruction to install php. And I will use another container for MySQL.
[2017-02-07 10:54:58] <jMonsinjon> Vernuft123: What about your Task Manager ? [<-LINK->] 
[2017-02-07 10:55:29] <jMonsinjon> Did virtualization enabled ?
[2017-02-07 10:55:57] <Vernuft123> jMonsinjon: Yes
[2017-02-07 10:56:09] <jMonsinjon> Windows 10 64b ?
[2017-02-07 10:56:39] <Vernuft123> Yes
[2017-02-07 10:57:06] <Vernuft123> This is my worklaptop atm, it does have VMware installed,
[2017-02-07 10:57:10] <Vernuft123> will that still be a problem?
[2017-02-07 10:57:28] <Vernuft123> My other PC has exactly the same issues
[2017-02-07 10:57:36] <Vernuft123> as i am having on my laptop
[2017-02-07 10:58:21] <jMonsinjon> Hummmm I'm not an expert but, old VMWare apps uses VTx for virtualization, and Docker needs new Hyper-V virtualization
[2017-02-07 10:59:02] <Vernuft123> Hyper-V needs to be enabled at OS level am i right?
[2017-02-07 10:59:07] <jMonsinjon> If you disable Hyper-V to run VMWare with VTx, it seems that Docker will not run
[2017-02-07 10:59:19] <jMonsinjon> I think so...
[2017-02-07 10:59:40] <Vernuft123> Ok, il try at my Home PC to see if task manager shows virtualisation as enabled
[2017-02-07 10:59:47] <Vernuft123> then il set HYPER-V in windows
[2017-02-07 10:59:51] <Vernuft123> hpefully that will work
[2017-02-07 10:59:56] <Vernuft123> thanks for your input
[2017-02-07 11:00:18] <jMonsinjon> you're welcome
[2017-02-07 13:35:38] <SISheogorath> jeserkin: The practice to have one container per process makes sure everything is scalable. A container in Docker is not a VM. The whole Docker ecosystem is not build to work like that. So if you push everything in a single container you'll run in trouble soon. It's easier and better to follow the one process per container rule and use one of the tutorials who explain how to setup application this way
[2017-02-07 15:55:09] <thePedroPaulino> Hello guys!
[2017-02-07 15:57:13] <thePedroPaulino> I have two services that run in containers
[2017-02-07 15:57:29] <thePedroPaulino> Do I need two Docker files or can use just one ?
[2017-02-07 16:31:21] <woowe> Hello everyone, I am extremely new to docker and I am still a bit fuzzy on how to use docker to help out with the development of your sofware. Right now I am working on an Angular 2 app that integrates with Firebase. From my understanding the workflow with docker is to have a docker file in the directory in which you are doing development, then have docker mount your working directory and build everything inside of the container?
[2017-02-07 16:33:42] <woowe> oops sorry, didn't read the heading
[2017-02-07 18:33:44] <LuisUrrutia> Hi again, what's the best way to have data persistence? I was reading about data only containers, but some people says that isn't necessary with named volumes, so I'm a mess with too much information that says something different
[2017-02-07 21:35:20] <SISheogorath>  [<-CODE->] In genereal you can mount the volume to a directory in your filesystem. In this case you make sure it is accessible on all nodes in your multi node setup or use it like a regular directory in a single node setup.If you have a more complex structure it highly depends on your backend. In general on multinode setups you want to use a volume driver like rexray or gluster or s3. If you are on a single node setup you may want to use named volumes. [<-CODE->] 
[2017-02-07 21:36:57] <SISheogorath> thePedroPaulino: Dockers best pratice say one process per container. And your image should be as minimal as possible. So you should use 2 dockerfiles
[2017-02-08 01:31:44] <douglasmakey> Guys they know on this problem:debconf: unable to initialize frontend: Dialogdebconf: (TERM is not set, so the dialog frontend is not usable.)debconf: falling back to frontend: Readlinedebconf: unable to initialize frontend: Readlinedebconf: (This frontend requires a controlling tty.)debconf: falling back to frontend: Teletypedpkg-preconfigure: unable to re-open stdin:
[2017-02-08 01:57:24] <bajajsweta> Hello everyone, I am new to Docker.. I have made a python script that does some exploratory analysis on a dataset.. I want to now add this to a docker image and share it with my classmates.. Could someone please guide
[2017-02-08 02:30:26] <adrian011494>  [<-LINK->] 
[2017-02-08 02:45:10] <SISheogorath> douglasmakey: addENV DEBIAN_FRONTEND=noninteractive
[2017-02-08 02:45:24] <SISheogorath> Should help
[2017-02-08 02:47:53] <SISheogorath> bajajsweta: check [<-LINK->] 
[2017-02-08 09:00:54] <comeUpWithItLater> hello ,
[2017-02-08 09:01:02] <comeUpWithItLater>  [<-LINK->] 
[2017-02-08 09:01:53] <comeUpWithItLater> i 'm going through [<-LINK->] 
[2017-02-08 09:02:31] <comeUpWithItLater>  [<-LINK->] 
[2017-02-08 09:03:24] <comeUpWithItLater> my service wouldn't start ,  0  REPLICAS
[2017-02-08 09:03:38] <comeUpWithItLater> anyone help
[2017-02-08 11:58:33] <LuisUrrutia> SISheogorath: Thanks u. Well, i wanna use it with Kubernetes, so it will be multihost. I'm going to check RexRay and volumes from Kubernetes.
[2017-02-08 12:05:54] <florianwittmann> I use Docker for Windows (Current Stable 1.13.0) and try to run this docker image: https://hub.docker.com/r/fossology/fossology/But it fails for me with permissions issues with postgresql (I don't need a seperate postgres container for now, as it's just a short evaluation of fossology):C:\\Users\\dockeruser>docker run -p 8081:80 fossology/fossologyWARNING: No database host was set and therefore theinternal database without persistency will be used.THIS IS NOT RECOMENDED FOR PRODUCTIVE USE!chmod: changing permissions of '/var/run/postgresql': Operation not permitted
[2017-02-08 12:07:04] <florianwittmann> Any ideas? Shouldn't that work out of the box, as it's just using permissions inside the container? Or is there anything I understood wrong?
[2017-02-08 14:23:49] <jeserkin> SISheogorath: any tutorials, that you would suggest? And another questions is about, what is probability of running into problems with container to container communication?
[2017-02-08 15:19:01] <sopanshewale> florianwittmann: - may be [<-ISSUE->] this can help you
[2017-02-08 18:00:33] <atorefrank> atorefrank: Getting the following error when I attempt to tunnel into my azure container cluster through port 2200. I have my SSH2 public key used to provision the swarm container.connect to host XXXXXXXXXXXXX port 2200: Operation timed out.Here is the commandssh username@XXXXXXX.westus.cloudapp.azure.com -p 2200 -L 22375:127.0.0.1:2375
[2017-02-08 18:40:14] <verwilst> I'm wondering how to run docker in production.. do you start loads of docker containers on the OS of the physical server? Or do you guys contain the containers per customer for example in an additional qemu vm for example?
[2017-02-08 19:12:25] <dragon788> RancherOS and some others let you manage these boundaries more easily
[2017-02-09 06:02:38] <mingsterism> hi guys
[2017-02-09 06:02:52] <mingsterism> i want to stream data between 2 docker containers on the same network within a single host
[2017-02-09 06:03:05] <mingsterism> how can that  be done?
[2017-02-09 07:54:47] <ely029> I have a problem about networking. How can I make a same gateway to connect 2 image containers here is my docker-compose.yml```version: '2'services:  frontend:   build: .   container_name: erp2_frontend   networks:      erp2_frontend:          ipv4_address: 172.25.0.1   ports: [<-CODE->] volumes: [<-CODE->] links: [<-CODE->] backend:   image: alpine:latest   container_name: erp2_backend   networks:     erp2_backend:         ipv4_address: 172.25.0.2   ports: [<-CODE->] networks:   erp2_frontend:      driver: bridge      ipam:        config: [<-CODE->] erp2_backend:      driver: bridge      ipam:        config: [<-CODE->] ```
[2017-02-09 07:56:28] <ely029> sorry I pass it again
[2017-02-09 07:56:53] <ely029>  [<-CODE->] 
[2017-02-09 08:16:18] <comeUpWithItLater>  [<-LINK->] 
[2017-02-09 08:16:41] <comeUpWithItLater> What if i want to use other dir outside out /Users?
[2017-02-09 08:17:09] <comeUpWithItLater> What if i want to use other dir outside of  /Users?
[2017-02-09 08:29:13] <ely029> how can I connect them?
[2017-02-09 08:50:07] <ely029> connect the 2 containers I dont have any idea? with different gateway they can coomunicate?
[2017-02-09 09:31:01] <ely029> how can I ran a docker command in the docker-compose.yml file?
[2017-02-09 11:17:15] <jMonsinjon> ely029: Why did you create 2 different networks with the same subnet ? If you want them to communication, the easiest way is tu put them into same bridge subnetwork
[2017-02-09 11:17:53] <jMonsinjon> ely029: In the bridge subnetwork, containers can communicate by service name
[2017-02-09 11:19:40] <jMonsinjon> ely029: I do not use "link" anymore since DNS resolution in bridge networks
[2017-02-09 11:22:48] <jMonsinjon> ely029: Consider this docker-compose file :
[2017-02-09 11:23:12] <jMonsinjon>  [<-CODE->] 
[2017-02-09 11:24:33] <jMonsinjon> In your container 'erp2_frontend' you can execute a request like ' [<-LINK->] ' and it will respond
[2017-02-09 11:25:43] <jMonsinjon> ely029: And if you must have two separate networks, your frontend service could be registered in both
[2017-02-09 11:51:36] <atul1989> i want to build new docker images from my container, means once i hit command docker build so to go instead of public docker hub it should pick FROM OS , to private docker registry which i configured , Please help to find out solution for same problem
[2017-02-09 16:05:24] <dragon788> to push to a private registry you need to tag the image with the address of your registry as the first portion of the name and then when you push it will use that to know where to push it
[2017-02-09 16:06:17] <dragon788> egdocker tag myimage my.repository.url/myimage:latestand when you push it then it should push it to your internal repository, but double check the docs on that because I'm going from memory that's nearly a year old
[2017-02-09 16:07:23] <ciminuv> Hi everyone, I am new to Docker, I have just successfuly deployed a new Rails app to Docker Cloud. But It looks like everything (all services describled in docker-compose) is packed as a single image running on Docker Cloud. So that on the production, I cannot check to see the status ofpostgres,redis,sidekiq, etc.
[2017-02-09 16:07:53] <ciminuv> Everything work well on development mode by following command:docker-compose up, but production.
[2017-02-09 16:09:41] <ciminuv> Any ideas?
[2017-02-09 16:54:35] <onerealfunnyguy> can anyone point me in the right direction to get docker networking set-up to run home-assistant run inside docker and still be able to scan all the devices on the pysical lan?
[2017-02-09 17:13:45] <killerspaz> Quick question, I had my head wrapped around this and now i'm stumped... I have nvm installing node in the build, works fine, but when i useCMD  node /app/index.jsit says node isn't found... Also when runningenvmy node env vars are missing (it actually appears to show my LOCAL environment vars) ... When I run the image and bash in, it DOES find node, and my env vars are fine. WHYYYYY
[2017-02-09 17:14:12] <killerspaz> usingENTRYPOINT node .orENTRYPOINT ['node', '.']neither work
[2017-02-09 17:14:47] <killerspaz> however, if i copynode .into anentrypoint.shand doENTRYPOINT ./entrypoint.shit works juuuuust fine, but i don't want an entire file for a single command like that
[2017-02-09 17:15:21] <killerspaz> note:ENTRYPOINT /bin/sh -c "node ."DOES work, but I don\'t want to reference/bin/shin any fashion.
[2017-02-09 17:21:22] <killerspaz> I'm sure@dragon788or@SISheogorathhave some wisdom to dole out
[2017-02-09 17:23:12] <dragon788> so you have node installed inside the container? have you inserted the install location to the PATH inside the container as well?
[2017-02-09 17:27:43] <killerspaz> yep
[2017-02-09 17:28:17] <killerspaz> like i said, if i run the container manually but pass/bin/bashat the end to bash in, it shows all the right env vars, binary points to the right path, my PATH is right, etc etc
[2017-02-09 17:28:34] <killerspaz> it's literally like OUTSIDE of the container executing IN doesn't work, and it's stumping the hell out of me
[2017-02-09 17:36:42] <killerspaz>  [<-LINK->] 
[2017-02-09 17:36:44] <killerspaz> my setup
[2017-02-09 17:37:39] <killerspaz> actually, that's latest in git, we've fixed the ENV vars to hold the proper paths, if anyone catches that... there's a/versions/missing out of theNODE_PATHandPATHvars
[2017-02-09 17:38:07] <killerspaz> i just hate seeing /bin/sh in front of the command
[2017-02-09 17:39:19] <killerspaz> we're doing this a ton in alpine images, this is our only ubuntu based image... that's about the only major difference
[2017-02-09 18:03:08] <dragon788> so just calling node without a full path works in Alpine?
[2017-02-09 18:05:17] <dragon788> after you do annvm install $node_versiondon't you also need to do annvm use nodein order to create the proper symlinks?
[2017-02-09 18:05:32] <dragon788> that should eliminate the need to do anything else
[2017-02-09 18:21:45] <killerspaz> Back in the day you had to, now it automatically does that, the output even indicates it's setting an alias default -> v7.2.1 and setting up symlinks
[2017-02-09 18:21:55] <killerspaz> which btw, again, when i bash in, all exist correctly
[2017-02-09 18:54:11] <killerspaz> even withnvm use nodedoesn't seem to fix anything :/
[2017-02-09 19:03:34] <DrummerKH> Hi guys, sorry for the offtop. But i think my issue is very stupid :). I have launched nginx container using docker-compose, but from inside the container i cant reach any remote connections differ from 80 or 443 ports. May be you know such problem? For example, i have running webserver on 48002 port on the another machine, i trying using curl connect to it but i got Connection refused, and same error with any port except 80 and 443.
[2017-02-09 19:04:29] <killerspaz> what\'s confusing the hell out of me isCMD executable param1should be/bin/sh -c executable param, but for some reason i\'m having to doCMD /bin/sh -ic executable param1.. which wouldn\'t that translate to/bin sh -c "/bin sh -c \\"executable param\\""????
[2017-02-09 19:05:49] <DrummerKH> killerspaz: i think you need useCMD ["executable", "param1"]
[2017-02-09 19:05:57] <dragon788> ahhhh,@killerspazdoes thenvm install $node_versionmodify the.bashrcor.bash_profileor something? if yousource .bashrcafter you do thenvm installyou may be able to call node without having to do much else
[2017-02-09 19:08:55] <killerspaz> DrummerKH: i've done both
[2017-02-09 19:09:11] <killerspaz> scroll up some for my full details of what i've attempted
[2017-02-09 19:09:29] <killerspaz> dragon788: it does... but i'm trying to avoid a ton of stupid stuff to start the container
[2017-02-09 19:09:40] <killerspaz> in every single Alpine image built literally 100% the exact same way i do not have this issue
[2017-02-09 19:09:54] <DrummerKH> killerspaz: Ok sorry, may be you know the fix of my issue?
[2017-02-09 19:09:57] <killerspaz> i can use the exact same docker file and just change to alpine instead of ubuntu and it works as expected
[2017-02-09 19:10:31] <killerspaz> DrummerKH: sounds like a bad bridge/ip tables config
[2017-02-09 19:10:47] <dragon788> I wonder if the nvm script for alpine does something different for alpine vs ubuntu, like installing to/usr/share/binwhich exists in the path on Alpine but not Ubuntu or something like that
[2017-02-09 19:10:59] <killerspaz> DrummerKH: see if this helps: [<-ISSUE->] 
[2017-02-09 19:11:11] <killerspaz> dragon788: there is no "script for alpine", i\'m installing it via the 100% same way
[2017-02-09 19:11:19] <killerspaz> it's not adding from the package manager, it's adding from a curl request
[2017-02-09 19:11:38] <killerspaz> curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.0/install.sh | bash
[2017-02-09 19:11:42] <dragon788> you are using the nvm.sh script, I'm assuming that has distribution detection and runs different depending on the distro it's installed to
[2017-02-09 19:11:47] <killerspaz> nope
[2017-02-09 19:12:28] <killerspaz> i checked for that, read the entire source
[2017-02-09 19:13:14] <killerspaz> i have no clue why this works with one base image, and not another... neither alpine nor ubuntu define an entrypoint, only a CMD, which i override in both cases withnode .... alpine works, ubuntu doesn't
[2017-02-09 19:17:04] <killerspaz> if my ENV vars would work, i think this would be a moot point
[2017-02-09 19:24:28] <killerspaz> dragon788: i posted relevant dockerfile and docker-compose setup.... it has something to do with env vars not being available for some reason... i just can't figure it out
[2017-02-09 19:25:07] <dragon788> are you passing in any via ENV that would make it weird? but you said it works fine when Alpine and only breaks on Ubuntu?
[2017-02-09 19:26:03] <killerspaz> nope, literally can change the FROM ubuntu to FROM alpine, and get rid of the apt-get stuff, and it works fine here
[2017-02-09 19:28:50] <killerspaz> whatever, i'm over this bullshit.... just gonna/bin/sh -cit and hate life for a short bit and move on
[2017-02-09 21:22:25] <dragon788> lol
[2017-02-09 22:03:59] <killerspaz> Anyone notice how docker-compose is only outputting stderr? I have to check logs manually while developing, kind of a PITA
[2017-02-09 22:11:37] <killerspaz> that damn/bin/shthing put me in a fowl-ass mood.
[2017-02-09 22:39:37] <kbluescode> killerspaz: just jumping in here, but what services are you running in docker-compose where you're only seeing stderr?
[2017-02-09 22:53:58] <killerspaz> any... i use a simple node script to write to stdout or stderr, and only stderr shows unless i specifically usedocker-compose logs... the output fromdocker-compose up(in foreground) is only showing stderr output
[2017-02-09 22:57:30] <kbluescode> and running just the container by itself withdocker runoutputs the logs fine?
[2017-02-09 22:57:45] <killerspaz> yep
[2017-02-09 23:01:19] <kbluescode> weird, I get the same logs back and forth from my go web servers indocker-compose upanddocker-compose logs
[2017-02-09 23:03:44] <kbluescode> I'm just going to spin up a custom node container I have and try to run some code in it through compose
[2017-02-09 23:11:08] <kbluescode> so yeah, just got it to run fine with docker-compose up
[2017-02-09 23:11:17] <kbluescode> just ranconsole.log('hi')and it logged
[2017-02-09 23:11:38] <killerspaz> i'm on docker 1.13 on winows, using a rancheros docker-machine (which iirc is 1.12.6)
[2017-02-09 23:11:42] <killerspaz> dunno if that's the problem
[2017-02-09 23:11:58] <kbluescode> I'm on Elementary OS LInux, Docker 1.13 on my host machine
[2017-02-09 23:12:14] <kbluescode> what are you calling to log to stdout?
[2017-02-09 23:17:51] <killerspaz> same as you, console object
[2017-02-09 23:17:54] <killerspaz> log/error
[2017-02-09 23:17:59] <killerspaz> bbiab, driving home
[2017-02-09 23:28:58] <kbluescode> killerspaz: just tested it with docker-machine runningdocker-compose upand it worked fine there too
[2017-02-10 03:58:29] <ciminuv> Hi everyone, I am new to Docker, I have just successfuly deployed a new Rails app to Docker Cloud. But It looks like everything (all services describled in docker-compose) is packed as a single image running on Docker Cloud. So that on the production, I cannot check to see the status ofpostgres,redis,sidekiq, etc.Everything work well on development mode by following command:docker-compose up, but production.
[2017-02-10 06:39:52] <atul1989> dragon788: : Thanks for your reply, I was that once i will run docker build command first time to build any image so instead of going public repo(docker Hub) i want it pull base image (FROM os) from our configure private docker registry , That i want to do ,  hope now it will clear
[2017-02-10 09:50:55] <weickmanna> building a container with a docker version that is greater than the docker version that will eventually run that container … is that a safe thing to do?
[2017-02-10 13:04:49] <jMonsinjon> weickmanna: depends on the number of gap versions
[2017-02-10 13:05:17] <jMonsinjon> weickmanna: most important is kernel's hosts versions
[2017-02-10 13:06:08] <jMonsinjon> weickmanna: I use my Docker 1.13 for building images and run it on Docker 1.10 in production
[2017-02-10 14:32:24] <dugusanfeng> hi, Has anyone encountered error parsing command line: unrecognised option --configdb when docker run mongos --configdb
[2017-02-10 15:50:29] <jacobcamm> Hey, we're outputting docker logs to an elk stack and had to restart elk and the daemon seems to have stopped logging during  it's down time, is there a way to get it to start logging again without just restarting it?
[2017-02-10 16:47:07] <killerspaz> kbluescode: wtf... i\'ve tried on OSX, Linux, AND windows, literally a simple node scriptconsole.log("STDOUT information here"); console.error("STDERR info here");and all i ever see when i rundocker-compose upisSTDERR info here.. i have to usedocker-compose logs <service>to see STD out info
[2017-02-10 18:18:52] <kbluescode> killerspaz: what version of docker-compose?
[2017-02-10 18:19:02] <kbluescode> also it might just be the container itself, honestly
[2017-02-10 18:25:25] <killerspaz> i mean i made these docker images, and i know it's not the container
[2017-02-10 19:10:54] <donny-dont> with a windows container in docker is there a cap on the amount of memory it can use?
[2017-02-10 19:11:18] <donny-dont> i have ms build integrated into a container and it keeps reporting its out of heap space
[2017-02-10 19:13:41] <killerspaz> toolbox or hyper-v?
[2017-02-10 19:13:51] <killerspaz> or... virtualbox or hyper-v?
[2017-02-10 19:14:30] <donny-dont> its hyper-v docker for windows 1.13.1 running an image thats descended from microsoft/windowsservercore
[2017-02-10 19:14:37] <killerspaz>  [<-LINK->]  [<-LINK->] 
[2017-02-10 19:15:03] <killerspaz> you supply them while creating.. Never used hyper-v myself, but i'm sure there's a way to change it after the fact
[2017-02-10 19:15:17] <donny-dont> ah cool didnt see those options
[2017-02-10 19:15:51] <donny-dont> saw a cpu and memory slider when working in linux but nothing in the ui when i switched to windows
[2017-02-10 19:16:29] <killerspaz> Speaking of... does anyone have any sources for discussion around the future of docker on windows? I keep hearing that docker-toolbox isn't going to be supported in the near future, and want to know what that means for us that can't run hyper-v
[2017-02-10 19:23:04] <donny-dont> killerspaz: i think this might be for the linux machines
[2017-02-10 19:23:27] <donny-dont> i dont see anything virtual machines for the windows instance
[2017-02-10 19:23:35] <donny-dont> granted im new to this so could be missing something
[2017-02-10 19:25:35] <killerspaz> i use docker-toolbox which utilizes the virtualbox driver... the main instructions discuss hyper-v installation as the only alternative for windows, which runs native windows vm's. So i'm pretty sure either way, it's virtual machines. In my linux environments, the docker daemon runs natively in linux, and doesn't require any docker machines
[2017-02-10 19:26:29] <donny-dont> k ill keep digging around
[2017-02-10 19:26:31] <donny-dont> thank you!
[2017-02-10 19:26:35] <killerspaz> sure thing, good luck
[2017-02-10 22:35:01] <donny-dont> killerspaz: in case anyone else ends up asking something similar
[2017-02-10 22:35:04] <donny-dont> i got it to work
[2017-02-10 22:35:14] <donny-dont> built WebKit for windows in a docker container using MSBuild
[2017-02-10 22:35:57] <donny-dont> --memory=Xgand--cpu-count=8
[2017-02-10 22:36:01] <donny-dont> solved my problem
[2017-02-10 22:36:07] <donny-dont> where X was a stupid number :)
[2017-02-10 22:36:21] <donny-dont> doesnt have anything to do with the hyperv settings
[2017-02-10 22:41:57] <playground> hi, I\'m installing some cli tools when building the image.  I can see the cli is being installed and  "RUN /usr/local/bin/wsk -v" does what it is supposed to.  And the image completed successfully.  However, when I do "docker exec -it my-image bash", ls -l /usr/local/bin there is nothing under /usr/local/bin.  Why is it?
[2017-02-10 22:47:20] <rewiredpictures> Hi, I’m working on a script to move images from one registry to another without having to pull the entire image first. I’ve integrated with the registry API and have gotten the fs layers to pull from the source and push to the destination, but I’m not sure how to get the key for the JWS signature in the manifest. Anyone know where the signing key come from for the  manifest signature?
[2017-02-10 23:24:04] <mevric> playground: what is the base image you are using?
[2017-02-11 01:13:44] <killerspaz> donny-dont: i was gonna ask if it was actually running out of mem or if your runtime needed more allocated
[2017-02-11 01:15:43] <jeff-h> anyone know of a tutorial explaining how to add/edit/delete users via REST?
[2017-02-11 01:17:46] <jeff-h> sorry! Wrong room!
[2017-02-11 06:08:01] <donny-dont> killerspaz: it wasnt clear what things were defaulting to with windows containers with linux it was pretty clear what the VM had
[2017-02-11 06:08:05] <donny-dont> but all good now :)
[2017-02-11 15:10:20] <vyscond> why boot2docker needs at least 512mb to run? :(
[2017-02-11 15:11:38] <gadget_mnky_twitter> vyscond: it's a vagrant vm.   Believe that's the minimum for Linux vm these days unless alpine
[2017-02-11 15:12:31] <vyscond> gadget_mnky_twitter: No. alpine is not the only one who can run on lower RAM
[2017-02-11 16:59:34] <SISheogorath> hint: boot2docker is based on alpine
[2017-02-11 17:25:26] <vyscond> SISheogorath: Nope.
[2017-02-11 17:25:37] <vyscond> It's based on busybox, Sir.
[2017-02-11 17:28:45] <SISheogorath> oh thanks I remember myself that someone told in the dockercommunity that it's based on alpine but I verified myself now. It's based on [<-LINK->] 
[2017-02-11 18:36:23] <scippio> Hi all, I know this is not a specific Docker question... but exists some auto-deploy system? I mean... I have some servers with docker-compose services ... but every service need "dynamic" configuration. All configurations are connected via mounted volumes from host system. I have this configs in git ... and everytime I pushed I need pull on defined servers + do some actions (like restart http server etc..).
[2017-02-11 18:37:05] <scippio> ..or I must write my own utility for this? :-|
[2017-02-11 19:27:44] <SISheogorath> In genereal I prefer it to use environment variables to configure my services. Those you can easily edit and docker swarm (for example) will regonize the changes (as you change those variables by using thedocker service updatecommand) and redeploy the service. But I guess you search something like ansible, saltstack, puppet, ... If you really want to do that with files
[2017-02-11 19:29:04] <SISheogorath> Another maybe easy way is to use hooks for your version control which then runs something like an ansible playbook to your environment. (Hint: Ansible Tower has these things working nearly out of the box but is not free)
[2017-02-11 19:29:20] <SISheogorath> scippio: See above
[2017-02-11 19:34:48] <scippio> I prefer files ... because I have dozens complex nginx config files... maybe some export into env variable is possible... but I think it's too ugly have this files in env variable ...
[2017-02-11 20:00:45] <scippio> SISheogorath: thanks for response... I think I\'ll write my "deployment tool" ... when I push to repository -> hook call my server/s a they run some script/s ...
[2017-02-11 20:01:40] <SISheogorath> well basically that's what ansible would do if you add it as a final deployment step :D
[2017-02-11 20:03:35] <SISheogorath> btw depending on what you use nginx for you can maybe replace it with traefik which would update it's settings based on the docker API, on the fly or check jwilder's nginx setup which is really awesome if you don't want to use traefik
[2017-02-11 20:07:57] <scippio> hmm.. traefik I don't need another web server... I like nginx. and it's not only about nginx but any other dozens services.
[2017-02-11 20:19:06] <SISheogorath> traefik is mainly used as reverse proxy and configured by API interface which makes it so powerful. and don't feel offended it was just a recommendation
[2017-02-11 20:34:30] <scippio> it's fine.. I understand, but I think traefik isn't what I need...
[2017-02-12 12:24:26] <vyscond> scippio: you mean kubernetes?
[2017-02-12 20:57:01] <soapoperator> hello, i run a docker-compose config with nginx + php-fpm on a same network.  Unfortunatly, my php file are not interpreted but downloaded. I double check nginx config. My docker-compose file: [<-CODE->] Any idea?
[2017-02-12 21:00:26] <killerspaz> soapoperator: what's the default.conf look like
[2017-02-12 21:08:06] <soapoperator> killerspaz:  [<-CODE->] 
[2017-02-12 21:13:38] <killerspaz> I could be wrong ,but i think it's yourlocation /block triggering
[2017-02-12 21:14:00] <killerspaz> put it after thelocation ~ \\.php$block n see if that fixes it
[2017-02-12 21:21:05] <soapoperator> killerspaz: It doesn't change anything.  Could it be an problem with permissions of the html folder
[2017-02-12 21:22:22] <killerspaz> i don't believe so, because something is clearly reading them; php is interpreted, not a runtime, so +x isn't required
[2017-02-12 21:22:50] <killerspaz> just try completely removing that block you moved
[2017-02-12 21:22:54] <killerspaz> or commenting it out rather
[2017-02-12 21:26:08] <killerspaz> btw, you removed and recreated the container, right? when you did that conf change?
[2017-02-12 21:27:54] <killerspaz> oh well wait, i just noticed in your paste you have thedefault.confvolume commented out
[2017-02-12 21:32:12] <soapoperator> i try to removelocaltion /without anychange.
[2017-02-12 21:32:40] <killerspaz> did you see my reference to the comment?
[2017-02-12 21:32:54] <soapoperator> for default.conf, i use it in sites-available.
[2017-02-12 21:33:55] <killerspaz>  [<-LINK->] 
[2017-02-12 21:34:27] <killerspaz> your changes aren't taking affect because it's not there
[2017-02-12 21:35:19] <soapoperator> i comment it because i was thinking to use nginx default conf, didn't i?
[2017-02-12 21:36:23] <soapoperator> if i uncomment it i have to copy the file before, doesn't i?
[2017-02-12 21:36:25] <killerspaz> default doesn't use fastpass_cgi for php-fpm to do it's thing
[2017-02-12 21:36:51] <killerspaz> your default.conf you pasted does, but you're not putting that into the container for nginx to actually DO that
[2017-02-12 21:37:55] <killerspaz> uncomment,docker-compose down && docker-compose up -dand try again
[2017-02-12 21:44:44] <soapoperator> Things are changing... When i try to access to my php file i get anERR_CONNECTION_RESET... conf.d/default.conf is empty. I have to populate it.
[2017-02-12 21:46:09] <killerspaz> how are you verifying the conf is empty?
[2017-02-12 21:57:14] <soapoperator> i was thinking there is a duplication between./config/sites-available/default.conf:/etc/nginx/sites-enabled/default.confand./config/conf.d/default.conf:/etc/nginx/conf.d/default.confin my volume...
[2017-02-12 21:58:21] <soapoperator> maybe i have to mount in a volume/etc/nginx/nginx.conf
[2017-02-12 22:01:16] <killerspaz> if anything i'd volume mount /etc/nginx/sites-enabled
[2017-02-12 22:01:24] <killerspaz> if i have it correct
[2017-02-12 22:06:32] <killerspaz> but really it's your config, good luck, i gotta go
[2017-02-12 22:06:45] <soapoperator> killerspaz: thank you for your help, i will retry tomorow. Now i know it-s only a nginx config issue. I am lost between the config file.
[2017-02-12 23:23:29] <simoami> hello, simple question, regarding tagging and pushing an image. if you tag an image (0.0.2) withlatest, does the previous image (0.0.1) lose the latest tag?
[2017-02-13 01:47:55] <kinghuang> simoami: Yes.
[2017-02-13 08:15:03] <kschlesselmann> What's the way to go if you build on an image that's not on docker hub?FROM <myRegistryUrl>/my/imageCan I insert the source registry with an external config somehow?
[2017-02-13 09:01:50] <ketchupmonkey> hi everyone! I have a question about docker swarm in particular the load balancing aspect. I just wanted to clear up something. In a scenario where you have two physical machines and one is the swarm manager while the other one is the worker and they have a docker service which propagated containers to both hosts. If I do changes to my DNS server and point it to one of the physical machines(let's say the manager) and it wants to direct the request to the other machine(the worker) does that mean it will do an additional hop?
[2017-02-13 09:02:43] <ketchupmonkey> to reach the worker machine and as a result you don't have the same performance findings when comparing both machines?
[2017-02-13 09:03:09] <ketchupmonkey> or is there a way where both machines share a single IP?
[2017-02-13 09:04:34] <ketchupmonkey> the other solution I could think of is having a load balancer(like AWS elasticloadbalancer) in front of it but I am worried that if aws forwards the request to one of the nodes(manager) what if that nodes tries to send it to the other host(worker) then that adds an additional hop to reach the service/site
[2017-02-13 09:04:47] <ketchupmonkey> am I understanding this correctly or I've just confused myself
[2017-02-13 09:14:44] <ugurarpaci> The second case works exactly the same as you explained. In swarm mode, the daemon process aquires @ binds the published port and route the requests to the instances which is either manager or worker.
[2017-02-13 09:15:27] <ugurarpaci> Hope that helps
[2017-02-13 09:16:29] <ugurarpaci> on ELB case, even if the ec2 is not behind the elb the hop operation you mentioned emerges.
[2017-02-13 09:53:50] <verwilst> How would you setup multiple httpd vhosts on a server with docker?
[2017-02-13 09:54:25] <verwilst> Each website its own php-fpm container and httpd container with shared webroot, i get that. But then you need an ip per website..
[2017-02-13 09:54:42] <ugurarpaci> You can use a reverse proxy ?@verwilst
[2017-02-13 09:54:53] <verwilst> Do you guys put a proxy in front of it? and the individual httpd containers listen on other ports?
[2017-02-13 09:55:12] <ugurarpaci> This is a dynamic proxy [<-LINK->] 
[2017-02-13 09:55:26] <ugurarpaci> there is also haproxy version of that
[2017-02-13 09:55:28] <verwilst> so client -> httpd:80 -> httpd:8001 for example
[2017-02-13 09:55:54] <ugurarpaci> client -> proxy:80 -> httpd:80
[2017-02-13 09:56:06] <ugurarpaci> you wont have to expose & bind http's port
[2017-02-13 09:56:24] <ugurarpaci> so, all of your httpd processes can use the same port
[2017-02-13 09:56:48] <ugurarpaci> proxy will be routing it with the proper hostname
[2017-02-13 09:57:50] <verwilst> hm, but is linking new containers to the proxy once it's running even possible?
[2017-02-13 09:59:26] <ugurarpaci> proxy container mounts the docker socket daemon and listens docker events, this is what makes it dynamic actually. When a new container comes comes in with "docker run",  its event generation enables the routing thing.
[2017-02-13 09:59:55] <ugurarpaci> This process is actually explained in github page
[2017-02-13 10:04:32] <verwilst> i see
[2017-02-13 10:05:31] <ugurarpaci> I run more than 30 containers behind it, I must say it is smooth as hell
[2017-02-13 10:05:35] <ugurarpaci> so take a shot
[2017-02-13 10:06:09] <verwilst> i'd rather use apache, but i can base my knowledge off of the nginx-proxy thing :-)
[2017-02-13 10:06:48] <verwilst> is it secure to mount the docker unix socket?
[2017-02-13 10:07:04] <ugurarpaci> you mount it as read-only
[2017-02-13 10:07:27] <ugurarpaci> therefore no action is taken by the proxy
[2017-02-13 10:07:56] <verwilst> yeah, but maybe it could read sensitive data ;-)
[2017-02-13 10:32:47] <ugurarpaci> You are right, since it is a public image you can be cautious, you can create your own proxy image
[2017-02-13 15:47:00] <verwilst> you can read events through the ruby api, but the python api doesn't seem to have that feature
[2017-02-13 17:05:56] <Crizstian> Hello community this week, i’m bringing to you the third part of the series in "Build a NodeJS cinema microservice", that i wrote @medium and  it’s fully charged of nodejs development, as always i’m open to get feedback, contributions, or just a comment below =]https://medium.com/@cramirez92/build-a-nodejs-cinema-booking-microservice-and-deploying-it-with-docker-part-3-9c384e21fbe0#.4il886ym9
[2017-02-13 17:49:30] <ugurarpaci> you can use go as well@verwilst
[2017-02-13 20:00:45] <verwilst> i'd rather use python :-D
[2017-02-13 23:49:24] <scippio> vyscond: no... kubernetes is absolute different what I need... I just need deploy tool only.
[2017-02-13 23:50:02] <ketchupmonkey> thanks@ugurarpacisorry for the late reply. Thank you for the info. I guess that is the drawback if we use docker swarm to distribute multiple containers
[2017-02-13 23:50:41] <ketchupmonkey> ugurarpaci: oh although I have a question what happens if the manager dies? as far as  I know you can only have one manager in a cluster right? or can you have multipler managers in a docker swarm?
[2017-02-14 00:29:33] <SISheogorath> ketchupmonkey: It depends on what swarm you use. If you use swarmmode multiple managers are easy. If you use classic swarm multiple managers are possible but way more complex
[2017-02-14 00:31:51] <SISheogorath> verwilst: you can also take a look at Traefik. It works great and is more and more widely used
[2017-02-14 00:39:17] <ketchupmonkey> SISheogorath: thanks i'll try to read up on the swarm modes i'm not really familiar with that.
[2017-02-14 00:41:19] <SISheogorath> ketchupmonkey: checkout [<-LINK->] 
[2017-02-14 00:42:16] <ketchupmonkey> SISheogorath: thank you so much for link
[2017-02-14 00:42:17] <ketchupmonkey> :)
[2017-02-14 05:32:40] <ely029> how can I attach a bak file in a mssql server container?this is my docker-compose code: [<-CODE->] 
[2017-02-14 12:04:38] <RobertBroersma> Hi Guys. I'm trying to build an angular2 app in a docker container and sharing the code via a volume with my nginx container. However I'm not seeing the dist folder appear in my container/volume. Am I doing something wrong?
[2017-02-14 12:06:02] <RobertBroersma> This is my angular dockerfile [<-CODE->] /usr/src/client is my volume folder
[2017-02-14 12:17:45] <SISheogorath> RobertBroersma: how did you share the volume?
[2017-02-14 12:24:47] <RobertBroersma> atm like so: [<-CODE->] 
[2017-02-14 12:25:49] <RobertBroersma> However I don't see the dist folder appearing either when I dodocker-compose run client ls /usr/src/clientIt seems like it only creates it and copies files to it the first time it runs, and it doesnt change after that
[2017-02-14 12:43:40] <RobertBroersma> It takes new files only when I dodocker-compose downand thendocker-compose up -d, so only first run
[2017-02-14 12:47:33] <RobertBroersma> Hmm, not even always then :/
[2017-02-14 13:35:58] <RobertBroersma> It works when I remove the volume and then docker-compose down and up
[2017-02-14 13:36:19] <RobertBroersma> I'm fairly new to docker, is there a better way, with some kind of non-persistent volume?
[2017-02-14 15:38:56] <SISheogorath> I'm actually not sure why you share the code by volume >.>
[2017-02-14 15:43:03] <dragon788> ideally you would do the copies in your Dockerfile, you would simply volume mount your code directly where you need it in the container
[2017-02-14 15:43:10] <dragon788> then any changes you require will sync both ways
[2017-02-14 15:43:33] <dragon788> if you need a one way sync where it mounts the code but can't change it, you can change the volume mount options for that
[2017-02-14 16:42:58] <RobertBroersma> I just read that I shouldn't ask my questions here. Should I go somewhere else?@SISheogorath Like I said I'm new to docker. I'm not sure why either. I just searched how to share my code with another container.@dragon788 I'm not sure what you mean. How is it different to volume mount in Dockerfile than in compose file? Basically what I have on my client container is a dist folder that I want to share with my nginx container
[2017-02-14 16:44:22] <dragon788> RobertBroersma: there don't appear to be a lot of folks from Docker actually here discussing the project and how to contribute so there is a lot of Q&A, there is also the #Docker channel on IRC where people hang out, and it isn't currently synced up to this channel so asking in either place usually gets some sort of response
[2017-02-14 16:44:26] <killerspaz> RobertBroersma: no he's saying copy in your dockerfile, don't mount via ANYTHING
[2017-02-14 16:45:23] <killerspaz> COPY . /pathand notVOLUME /pathor-v path:/pathOR the volumes listed in your docker-compose
[2017-02-14 16:47:21] <dragon788> yeah, ideally you do it one way or the other, you either copy in everything every time it is run, or you do a straight volume mount at runtime (via docker run or docker compose) instead of doing both
[2017-02-14 16:47:58] <RobertBroersma> @dragon788 I'll take from that I can continue here ;) [<-CODE->] 
[2017-02-14 16:52:15] <killerspaz> you might need to elaborate fully on what your requirements are
[2017-02-14 16:54:52] <RobertBroersma> I have container 1: client. It has a ready for production dist folder.I have container 2: nginx. It runs nginx with a configuration to serve my static dist folder.I want to access the dist folder of client in nginx.
[2017-02-14 16:55:39] <RobertBroersma> It is for production. No need to update when I update code on my host
[2017-02-14 18:23:50] <killerspaz> use a volume in dockerfile and volumes-from in nginx
[2017-02-14 18:24:08] <killerspaz> i'm fighting dynamic ssl certs with IP changes :S
[2017-02-14 19:03:45] <Crizstian> Thanks for the advice i will check it@SISheogorath
[2017-02-14 20:22:34] <RobertBroersma> Will try tomorrow, thanks@killerspaz
[2017-02-15 08:03:53] <ugurarpaci> ketchupmonkey: do not even dare to use a single master on production :D
[2017-02-15 08:05:01] <ugurarpaci> If you like the action and high blood tension use 3, If you like to have a barbecue away from work, use 5 =)
[2017-02-15 08:05:33] <ugurarpaci> It depends on the CAP theorem, all in all It is what it is
[2017-02-15 08:08:00] <tleguijt> ugurarpaci: I'm wondering; since you are on this topic, what if you have an average-load website. Right now we are running an Django application on a EC2 instance but want to convert my deployment to a Docker Swarm one (or utilize AWS Docker orchestration). Big plus is rolling updates and easy scaling. However, most of the times two small instances both running 1 docker instance of that application will be sufficient
[2017-02-15 08:08:27] <tleguijt> However, it will mean I will have at most 1 swarm master (or 2 masters that both controls the only 2 nodes that are in the swarm - if that even makes sense..)
[2017-02-15 08:09:16] <tleguijt> or will I instead have three running instances; one tiny one acting as KVS + swarm master, one running the application and acts as a second swarm master, and one node with only the application (part of the swarm as well)
[2017-02-15 08:09:32] <tleguijt> in case of scaling up we could spin up our 4th, 5th, etc.. EC2 instances
[2017-02-15 08:16:24] <ugurarpaci> -swarm seems working fine on auto-scaling on aws. Even if you are running a single ec2 instance, It is a nice practice to spin them up in autoscaling groups.-this is a general advise. If this is a development or pre-production environment, I guess it is okay to run it on a single EC2; first it is cost effective and It is easy to maintain since your are dealing with one EC2 (as soon as you do the backing up swarm directory to some other place like S3).On the other hand, If this environment is on production, you will still need at least 2 EC2 on different AZ to satisfy best practises of AWS. You can spin up a "t2" type instance master-only instance to satisfy consensus alongside to these 2 production servers.
[2017-02-15 08:21:37] <tleguijt> with those master-only instances in each AZ you mean just an instance that acts as a master or one that also runs the application instances? (in other words; only 1 instance that does-it-all per AZ or 2 instances per AZ (one acting as master, one acting as the node running the actual application)
[2017-02-15 08:24:15] <ugurarpaci> behind the elb, 2 managers. In addition to that 1 more manager-only (releatively a cheap instance just to satisfy the consensus) which does not accepts any requests.
[2017-02-15 08:26:02] <tleguijt> sounds reasonable, the manager-only instance could also serve as KVS
[2017-02-15 08:26:28] <ugurarpaci> sure
[2017-02-15 08:27:26] <ugurarpaci> If cost is not the concern, you can spin up identical 3 ec2 as kick-off all managers, then add rest of the incoming instances as workers
[2017-02-15 08:28:46] <tleguijt> you mean those 3 ec2 instances divided over 3 AZs?
[2017-02-15 08:29:00] <ugurarpaci> exactly
[2017-02-15 08:29:13] <ugurarpaci> in the VPC, of course
[2017-02-15 08:29:50] <tleguijt> we have to be cost-efficient, so the following setup might be a good trade-off:AZ1:   node1 (manager-only), node2 (manager + worker), node3 (worker-only)AZ2:  node4 (manager + worker)AZ3: node5 (worker-only)
[2017-02-15 08:29:57] <tleguijt> having the managers also span at least 2 AZs
[2017-02-15 08:31:03] <ugurarpaci> looks good
[2017-02-15 08:31:43] <tleguijt> great, thanks for your thoughts :-)
[2017-02-15 08:51:58] <ugurarpaci> NP
[2017-02-15 14:43:34] <murbanowicz> anyone here using nginx-proxy ?
[2017-02-15 17:02:16] <austinfrey> i\'m getting the following errorcontainer_linux.go:247: starting container process caused "exec: \\"node\\": executable file not found in $PATH"but node is definitely in the path and i can start my application manually from inside a running container, but not from command line with docker run or from the dockerfile withCMD ["node", "server.js"]
[2017-02-15 17:03:21] <austinfrey> ic an provide more details if needed, but this seems to work on one machine an not the other, any help is appreciated
[2017-02-15 17:18:56] <killerspaz> aafrey: Had this problem as well, no clue why it doesn\'t work the way docs say it should (i.e.,CMD node server.jsshould translate tosh -cexecution).... So I had to manually doCMD sh -c "node server.js"
[2017-02-15 17:19:43] <killerspaz> And actually I think i neededsh -icfor interactive login (i.e., reads user bash profile/bashrc)
[2017-02-15 17:19:44] <austinfrey> I'll try it, thanks. weird though, that it works on one machine but not another
[2017-02-15 17:20:08] <killerspaz> For my alpine images,CMD nodejs .works fine, for debian-based it isn't for some reason
[2017-02-15 17:24:24] <austinfrey> killerspaz: CMD sh -c "node server.js"did the trick, thanks! you saved me an afternoon of misery!
[2017-02-15 17:28:49] <SISheogorath> aafrey: use ["node", "server.js"] instead
[2017-02-15 17:29:03] <killerspaz> he was
[2017-02-15 17:29:10] <killerspaz> same problem i was having the other day
[2017-02-15 17:29:25] <killerspaz> it doesn't appear to be an interactive login, so env vars are just completely ignored
[2017-02-15 17:30:17] <killerspaz> I'm sure it's a bug, but I don't have the patience or time to formulate the proper words to describe it :P maybe after this insane rush to deadline i can contribute more
[2017-02-15 17:31:03] <SISheogorath> Nope he said he usedCMD "node server.js"which is something else thanCMD ["node", "server.js"]
[2017-02-15 17:31:54] <austinfrey> well i spoke to soon, usingCMD sh -c "node server.js"just leaves me withsh: not foundinstead
[2017-02-15 17:32:23] <austinfrey> and@SISheogorathif you look at my first post I was using your suggestion and that when I received the error
[2017-02-15 17:37:14] <SISheogorath> Oh yes, now I see. Sry. I just tested and it works in my case. What base image are you using?
[2017-02-15 17:40:23] <SISheogorath> node:6as well asnode:6-alpinework fine for me
[2017-02-15 17:43:27] <austinfrey> SISheogorath: I'm using alpine but i rolled my own image.
[2017-02-15 17:58:15] <SISheogorath> Possibly there is a problem. Is it a fork of the original image?
[2017-02-15 18:01:23] <killerspaz> aafrey: alpine usesashshell
[2017-02-15 18:21:29] <austinfrey> guys... i'm feeling foolish... i'd accidentally set my env PATH variable to something else...
[2017-02-15 18:23:51] <austinfrey> thanks for lending a hand
[2017-02-15 18:31:20] <lev-kuznetsov> Anybody here uses [<-LINK->] ? I'm trying to find API to get the host IP address of my container if I'm running in a Swarm
[2017-02-15 18:58:14] <lev-kuznetsov> More general then; I started a docker-machine VM on my Mac and did a swarm init.docker infoshows swarm active. When I start a container and dodocker inspect <container>it doesn't have theNodefield I would expect
[2017-02-16 03:09:53] <killerspaz> Trying to get docker volume mounted into my jenkins container, anyone had success? I currently have: [<-CODE->] When I "exec" in i indeed see the binary, it is +x, but when i run it, it says not found still.... permissions look "ok" inside container [<-CODE->] 
[2017-02-16 03:10:35] <killerspaz> started down the path via: [<-LINK->] 
[2017-02-16 03:22:16] <killerspaz> and to mention i'm running the official alpine image
[2017-02-16 03:38:26] <killerspaz> my understanding is i need docker out of docker as i've seen it coined in DooD in a blog post here: [<-LINK->] 
[2017-02-16 03:38:39] <killerspaz> which i'm attempting, and apparently failing :/
[2017-02-16 04:27:35] <SISheogorath> Did you start Jenkins privileged?
[2017-02-16 04:28:02] <killerspaz> mm no, never saw that anywhere, i can try that
[2017-02-16 04:29:57] <killerspaz> still nope
[2017-02-16 04:35:37] <SISheogorath> If you really run docker in docker you need it. In you case you want to use the CLI. Not sure why it breaks. Can you runlddfor the docker command? To make sure nothing is missing
[2017-02-16 04:37:36] <SISheogorath> Oh and try to run your container with-u root
[2017-02-16 04:37:58] <killerspaz> so if i'm using compose, how do i do that? didn't see a reference in the compose format
[2017-02-16 04:39:09] <SISheogorath> Eh nice question >.> I'm not a fan/user of compose files
[2017-02-16 04:39:26] <SISheogorath> Not use about it but maybe there is a userflag too
[2017-02-16 04:41:08] <killerspaz> i saw group_add, which i added a user/group in the host, and added that user to docker group as well, so i'm expecting it to have elevated permissions
[2017-02-16 04:43:23] <SISheogorath> Yes, that's maybe it I guess it's a problem of your docker socket
[2017-02-16 04:44:23] <killerspaz> i'm running jenkins in a docker, which needs docker for the pipeline
[2017-02-16 04:44:47] <killerspaz> if i could avoid building a custom image by volume mounting the host docker, i'd prefer that
[2017-02-16 06:20:12] <coding-yogi> Hi guys, I am unable to access our intranet nexus repo from inside the docker
[2017-02-16 06:20:20] <coding-yogi> I get the error, connection refused
[2017-02-16 06:20:29] <coding-yogi> any idea about how to get this working?
[2017-02-16 08:24:04] <ugurarpaci> murbanowicz: yeah
[2017-02-16 09:04:16] <soapoperator> Hello, i try to add some extension to php with docker compose. After some reading, i am trying to add it like that: [<-CODE->] Unfortunatly i get a 502 error.Who can i add multi commande line correctly?
[2017-02-16 09:07:00] <soapoperator> Maybe i have to add this line to the server :nginx:latest
[2017-02-16 09:11:38] <soapoperator> Without this, the container works well.
[2017-02-16 09:12:23] <sopanshewale> soapoperator: - i think you need to add  this inside Dockerfile
[2017-02-16 09:12:33] <sopanshewale> not in docker-compose, right?
[2017-02-16 09:13:00] <sopanshewale> under "build" value - mention the directory where you have "Dockefile"
[2017-02-16 14:13:35] <matrixbot> xav19hi
[2017-02-16 14:14:10] <matrixbot> xav19i'm trying to implement 'docker exec' in [<-LINK->] (a rust lib to talk to docker daemon)
[2017-02-16 14:14:54] <matrixbot> xav19i'd like to dump/log the http requests made by docker cli to debug what i'm doing
[2017-02-16 14:16:41] <matrixbot> xav19i'm on docker for mac
[2017-02-16 14:17:32] <matrixbot> xav19i tried to disable tls and use wireshark, but the daemon doesn\'t seem to like {"tls": false, "tlsverify": false}
[2017-02-16 14:17:42] <matrixbot> xav19is there an other way to do it ?
[2017-02-16 15:42:05] <dragon788> xav19: does the docker CLI use HTTP or does it use a direct socket connection?
[2017-02-16 15:46:21] <matrixbot> xav19@dragon788, not sure... is there a way to know it?
[2017-02-16 15:46:32] <killerspaz> what's with that xav19 crap
[2017-02-16 15:46:55] <killerspaz> matrixbot wth
[2017-02-16 15:47:50] <matrixbot> xav19i'm not on gitter, i'm on riot.im (a matrix server)
[2017-02-16 15:48:06] <killerspaz> Interesting...  Hadn't heard of that
[2017-02-16 15:49:12] <xpayn> oh now i (xav19) see the crap
[2017-02-16 15:50:13] <killerspaz> Anyone successfully been able to get docker volume mounted inside another container? Running official Jenkins alpine image, which needs docker inside of it to run a pipeline. Trying to use the host docker daemon to alleviate version mismatches. I can't get it to work!
[2017-02-16 15:56:27] <xpayn> dragon788: i guess it uses the socket, boondock uses it on any unix system, and it works
[2017-02-16 15:57:10] <xpayn> it certainly mimics how the cli works
[2017-02-16 15:57:23] <xpayn> but that's just guesses
[2017-02-16 16:34:29] <killerspaz> my understanding is the socket, which is why i'm trying to mount it inside a container (unsuccessfully)
[2017-02-16 16:37:28] <xpayn> killerspaz: did you see this [<-LINK->] ?
[2017-02-16 16:38:04] <xpayn> it's a bit old but maybe there's something useful in it
[2017-02-16 16:38:10] <killerspaz> yeah but i want to avoid actually installing docker inside the container... I want it to be 100% the same docker daemon/client on the host
[2017-02-16 16:39:08] <killerspaz> I'm trying to avoid installing anything primarily to keep administration easy, and keep the version fracturing to zero.
[2017-02-16 16:42:38] <xpayn> did you try something likedocker run -it -v /var/run/docker.sock:/var/run/docker.sock -v /path/to/docker/cli:/path/to/docker/cli ubuntu:latest /bin/bash?
[2017-02-16 16:43:35] <killerspaz> sure did
[2017-02-16 16:43:40] <killerspaz> that doesnt' even work as it is
[2017-02-16 16:43:50] <killerspaz> not sure if yo utried that
[2017-02-16 16:44:27] <xpayn> nope, i'm on mac, i would be surprise it's even possible on it
[2017-02-16 16:44:47] <killerspaz> err yeah, you'd have to do that ON the docker machine
[2017-02-16 16:44:53] <killerspaz> very possible though
[2017-02-16 16:44:59] <killerspaz> docker-machine ssh "docker run -it ...."
[2017-02-16 16:45:10] <killerspaz> i do it often when i need to mount linux-specific volumes
[2017-02-16 16:46:29] <killerspaz> but right now i'm on linux native
[2017-02-16 16:49:01] <killerspaz> i think it's linked libs are missing...
[2017-02-16 16:50:43] <xpayn> docker for mac seems to be very peculiar beast based on hyperkit,docker-machine lsreturns nothing, not sure you can access the vm as it what possible with docker-toolbox/boot2docker
[2017-02-16 16:51:41] <killerspaz> oh yeah i remember someone telling me they changed that.... the landscape for docker is very confusing right now imo
[2017-02-16 16:52:56] <killerspaz> HUZZAH!
[2017-02-16 16:52:58] <killerspaz> I got it!
[2017-02-16 16:53:45] <killerspaz>  [<-LINK->] 
[2017-02-16 16:53:51] <killerspaz> Needed all the dynamic linked files
[2017-02-16 17:00:13] <xpayn> well done!
[2017-02-16 17:07:51] <killerspaz> damn, ok so via cli i can access, but jenkins still can't :/Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock
[2017-02-16 18:46:28] <killerspaz> can get it working with sudo added to the container image, but i really don't want that
[2017-02-16 20:31:45] <killerspaz> Finally got it all working, just took some stupid guid swap: [<-LINK->] 
[2017-02-16 21:13:57] <soapoperator> sopanshewale: interesting approch i don't know. I will try.
[2017-02-16 21:23:38] <killerspaz> soapoperator: it's identical to dockerfile
[2017-02-16 21:23:58] <killerspaz>  [<-CODE->] 
[2017-02-16 22:31:11] <ketchupmonkey> ugurarpaci: haha thanks for the tip I'm just playing around with it no prod plans yet haha
[2017-02-17 04:57:51] <soapoperator> @killerspaz i try this way with for example: [<-CODE->] But the container is running well but i get an 502 error when i try to access to php files.
[2017-02-17 05:00:22] <killerspaz> i'd assume you'd need some volume to share files to the container, right?
[2017-02-17 05:01:44] <soapoperator> right, i didn't give all the config: [<-CODE->] 
[2017-02-17 08:05:58] <comeUpWithItLater> hi there
[2017-02-17 08:06:14] <comeUpWithItLater>  [<-LINK->] 
[2017-02-17 08:07:49] <comeUpWithItLater> socket doesn't  work  on   docker PHP  image,  erro :  Could not open socket
[2017-02-17 08:07:56] <comeUpWithItLater> how to fix this
[2017-02-17 10:12:03] <jaksky> Hello, I am new to docker and docker registry. I have one particular question regarding tagging images. Does thelatestwork in a similar fashion as SNAPSHOT in maven (latest points to the latest image in the repository)?
[2017-02-17 10:41:52] <jyapujuju> i have installed docker and docker-compsor in arch as wiki said and created new rails app everything is okay and build successfully but don't know where  my all files goes :(
[2017-02-17 10:42:02] <jyapujuju> can somebody help me
[2017-02-17 11:10:30] <SISheogorath> What files are you searching?
[2017-02-17 11:11:46] <SISheogorath> In general docker stores everything in/var/lib/docker/but that something you should never touch until you are very familiar with docker internals
[2017-02-17 11:12:23] <jyapujuju> i want them on Document /myapp
[2017-02-17 11:12:55] <jyapujuju> how can i do that?
[2017-02-17 11:13:32] <SISheogorath> I'm still not sure what exactly you are asking for
[2017-02-17 11:13:42] <SISheogorath> What type of files?
[2017-02-17 11:14:43] <jyapujuju> files which are build by docker
[2017-02-17 11:14:55] <jyapujuju>  [<-LINK->] 
[2017-02-17 11:15:04] <jyapujuju> i follow the above wiki
[2017-02-17 11:15:29] <jyapujuju> i put all 4 files in /documnets/myapp
[2017-02-17 11:15:35] <SISheogorath> jaksky: latest is a custom tag which docker uses if nothing else is defined. On registry you have to create it explicitly
[2017-02-17 11:15:36] <jyapujuju> its build
[2017-02-17 11:17:12] <SISheogorath> jyapujuju: well in this case the files are stored inside your container filesystem. You can access it only while you are in the container or when you run some very ugly mount commands.
[2017-02-17 11:17:55] <jaksky> SISheogorath: So what is common workflow used when you want to have versioned history of builds but having your compose everytime pull the latest for development purposes??
[2017-02-17 11:18:01] <SISheogorath> To enter the container start it and then rundocker exec -it containerid /bin/sh
[2017-02-17 11:19:01] <SISheogorath> jaksky: simply have tags with versions and tag assign thelatesttag to your device build
[2017-02-17 11:19:56] <SISheogorath> You can assign multiple tags to the same image.
[2017-02-17 11:21:18] <jaksky> SISheogorath: Don't they override each other that the only last one is valid? That was my impression. Are you aware of any documentation where I could find that?
[2017-02-17 11:23:35] <SISheogorath> If you assignlatestto a new image, the old image will loose it, yes, but you can assign 9, 9.1, 9.1.3, and latest to the same image
[2017-02-17 12:58:09] <jyapujuju> SISheogorath: so am not doing any wrong?
[2017-02-17 14:04:27] <jaksky> SISheogorath: Is it somehow comparing timestamps on images? Let say you have a build server building images and you build it locally for a given tag - will it eventually download new one from repo?
[2017-02-17 15:04:02] <SISheogorath> If a tag exists locally it won't download the image. This includes self build images
[2017-02-17 15:07:39] <jaksky> SISheogorath: latestis not an exception
[2017-02-17 15:08:34] <SISheogorath> latestis not an excemption. it is handled like any other tag. It's just the default value if there is nothing specified
[2017-02-17 15:22:16] <felixheck> is there an easy way to get host's IP in docker-compose.yml w/o passing envs within thedocker-compose up?
[2017-02-17 15:34:30] <SISheogorath> felixheck: why do you need the IP?
[2017-02-17 15:36:18] <felixheck> need the IP of the host in the inside of my application.The idea was to pass the IP dynamically as env into the container
[2017-02-17 15:39:45] <SISheogorath> O.o can't you use the containers IP? In genereal you should not need the hosts IP. If you need connections between services you can use docker networks.
[2017-02-17 15:42:58] <felixheck> Don't think so :DThe toolkit (seneca/seneca-mesh) uses SWIM as gossip algorithm to build a mesh across multiple maschines.They suggest to use--net=host. So it's the host ip what I need, isn't it? It's quite confusing. I'm new to docker and it's maybe not the simplest project to start with :D
[2017-02-17 16:19:15] <SISheogorath> in case you use--net=hostyou have all interfaces of the host inside your container
[2017-02-17 16:28:24] <jyapujuju> docker-compose run web rake db:setup\nNo Rakefile found (looking for: rakefile, Rakefile, rakefile.rb, Rakefile.rb)
[2017-02-17 16:28:36] <jyapujuju> :(
[2017-02-17 16:43:19] <SISheogorath> jyapujuju: check your working directory
[2017-02-17 16:43:37] <SISheogorath> (in your container)
[2017-02-18 00:27:55] <killerspaz> jaksky: considerlatestsame asmasteron scm. It's up to the team to manage what that means: latest stable, or latest edge (i.e., unstable, yet stable enough for RC or public testing)
[2017-02-18 00:30:24] <killerspaz> felixheck: hey, fellow seneca user, and about to tackle the mesh myself. However, from my knowledge of both,net=hostis probably not needed, just the containers that need external access to have ports exposed so they CAN be reached by the public IP
[2017-02-18 00:31:21] <killerspaz> i have APIs built that are exposed on various ports, running on the default 10101 and 8080, but the 8080 is mapped to specific ports of our choosing
[2017-02-18 03:45:06] <scheung38> Is there Windows container for Docker thanks, need to run Wins apps on my Mac
[2017-02-18 04:17:39] <SISheogorath> There are Windows Containers, but they only run on Windows. As docker is a container runtime environment it uses a shared kernel. And this doesn't work for Windows on a non-windows platform. In case of Linux containers on Windows or Mac there is a VM running in background but you can imagine that this is not possible for Windows Containers for license reasons.
[2017-02-18 11:38:48] <vatsalparekh> any docker-compose contributer here? need help in codebase
[2017-02-18 17:05:31] <killerspaz> scheung38: docker isn't virtualization, so that's not possible without some proxy to a daemon within a virtual machine running windows (how docker-toolbox works on windows/osx to communicate to a VM running linux)
[2017-02-19 06:49:22] <vito-c> what's the best wan to handle building libraries to be used in other images?
[2017-02-19 06:50:12] <vito-c> i keep filing up my disk space too
[2017-02-19 06:50:26] <vito-c> is there a way to find out how much space is allocated to my images
[2017-02-19 07:50:05] <felixheck> docker Images?
[2017-02-19 10:12:23] <sandys> is there a way to get docker secrets during build time ? for example to access a private git repo?
[2017-02-19 12:05:04] <madpipeline> hello
[2017-02-19 12:05:18] <madpipeline> why is this not valid: [<-CODE->] 
[2017-02-19 12:05:51] <madpipeline> I get this error while trying to docker-compose up:services.server.volumes contains an invalid type, it should be a string
[2017-02-19 12:06:40] <madpipeline> I'm usingversion: '2'
[2017-02-19 12:32:27] <felixheck> Cause it should be a string ('...')
[2017-02-19 12:43:55] <madpipeline> and I should encapsulate the whole thing in quotes?
[2017-02-19 12:44:06] <madpipeline> or just the container path??
[2017-02-19 12:44:17] <madpipeline> felixheck: ^
[2017-02-19 12:46:45] <madpipeline> if I do: [<-CODE->] I get this: [<-CODE->] 
[2017-02-19 14:17:28] <felixheck> Why is there a bunch of whitespace between host and container definition?
[2017-02-19 14:18:45] <felixheck> In general there are no quotes need but the scheme is HOST:CONTAINER
[2017-02-19 14:30:08] <jyapujuju> my files are locked after docker-compose build ...
[2017-02-19 14:30:13] <jyapujuju> what to do?
[2017-02-19 15:03:27] <SISheogorath> sandys: no, docker secrets are swarm mode only and images are never build using swarm mode. I would suggest you to use git submodule or got subtree in your Repository and simply useADDorCOPY.  Never use secrets during build. There is no way to keep them secret right now
[2017-02-19 15:05:03] <SISheogorath> vito-c: in case you run docker 1.13 or higher:docker system df
[2017-02-20 06:22:42] <4406arthur> hi all,  in docker(1.13) swarm mode,I am going to build jmeter distributing load testing in docker swarm.Is it possible communicate between container crossing node use container’s ip,I am using default overlay network and ingress network, created by docker stack deploy.
[2017-02-20 06:23:24] <gadget_mnky_twitter> hey@4406arthurwould be keen on taking a look at your solution as well (we are dealing with a similar problem stmt)…care to oss if permitted ?
[2017-02-20 06:38:24] <4406arthur> gadget_mnky_twitter: in my point of view, I thought cross node communicate depends on build-in LoadBalancing ? Thats why I wonder is there a probability use container’s ip
[2017-02-20 10:35:37] <jyapujuju> following this tutorial [<-LINK->] stuck atsudo chown -R $USER:$USERchown: invalid group:
[2017-02-20 10:35:43] <jyapujuju> please help me
[2017-02-20 14:07:33] <seltsam23> Whats the docker-compose equivalent to CMD from the dockerfile? What is setup in CMD is executed like its typed into the command line, right? Is it executed form the workpath, or the root of the container?
[2017-02-20 14:08:35] <kschlesselmann> jyapujuju: chown set the file ownership. Apprently you don't have a group like$USER. Just pick some other group that's appropriate.
[2017-02-20 14:10:07] <SISheogorath> seltsam23: it'scommandand it is handled likeCMD
[2017-02-20 14:11:28] <seltsam23> SISheogorath: ok, so command heaves exactly the same like cmd and overrides it, correct?
[2017-02-20 14:11:32] <seltsam23> *behaves
[2017-02-20 14:11:53] <SISheogorath> So in general if there is a entrypoint scriptCMDprovides it's parameter. In case of no entrypoint script it is placed after default shell. In general that should be/bin/sh -c
[2017-02-20 14:12:13] <SISheogorath> Yes it overwrite it
[2017-02-20 14:12:37] <seltsam23> ok, is that the point where i run my app? like "npm start" "nodemon" pm2 start ..." ?
[2017-02-20 14:12:51] <SISheogorath> Yes
[2017-02-20 14:12:56] <seltsam23> excellent
[2017-02-20 14:14:15] <seltsam23> so this should work? [<-CODE->] 
[2017-02-20 14:15:07] <SISheogorath> 4406arthur: you can connect to Containers by their IP by first lookuptasks.<servicename>and use the results.
[2017-02-20 14:16:38] <SISheogorath> seltsam23: you should addCMDas JSON array instead of normal string. In this case you don't use the default shell and avoid possible problems.
[2017-02-20 14:17:14] <SISheogorath> See the officialCMDreference in the docs and also best practices
[2017-02-20 14:17:30] <seltsam23>  [<-CODE->] 
[2017-02-20 14:17:43] <seltsam23> SISheogorath: Yeah, thats where i spent the last hour
[2017-02-20 14:19:09] <SISheogorath> ["pm2", "start",  "./bin/www"]
[2017-02-20 14:19:41] <seltsam23> SISheogorath: Ah, i see. And this is executed in the workdir, correct?
[2017-02-20 14:19:50] <SISheogorath> Yes
[2017-02-20 14:20:33] <4406arthur> SISheogorath: ,  thank your respond, but I found Its blocked by my iptables, I modify my iptable  Foward/Input  accept 10.0.0.0/24 (default overlay subnetwork), now I can use Service Name across node, but still can’t direcly use container’s ip
[2017-02-20 14:21:45] <seltsam23> SISheogorath: This errors like this: "starting container process caused "exec: \\"pm2 start\\": executable file not found in $PATH"just using "CMD nodemon" works flawless though
[2017-02-20 14:22:01] <SISheogorath> 4406arthur: sounds broken, not sure what you do in your setup.
[2017-02-20 14:22:18] <SISheogorath> seltsam23: maybe use the absolute path to pm2
[2017-02-20 14:24:40] <SISheogorath> 4406arthur: maybe try it on play-with-docker.com there the environment should be fine
[2017-02-20 14:26:37] <4406arthur> SISheogorath: , Thanks , But I know the problem is iptables config, I stop iptable service betwe
[2017-02-20 14:26:49] <4406arthur> all my node , everything is fine
[2017-02-20 14:27:07] <SISheogorath> Ah nice have fun while debugging ;)
[2017-02-20 14:30:02] <seltsam23> SISheogorath: Thanks mate, now its working!
[2017-02-20 14:32:21] <SISheogorath> You're welcome
[2017-02-20 15:14:07] <sn00pster> Hi guys, I have a slightly strange issue with docker.  I have used the linux binaries to create a synology SPK package with the latest docker and it\'s all working fine....  Except, when I do "docker top <container>" I get no processes listed as running.  If I do a "ps axjf" on the host I can see the docker containers and the child processes running (all the containers are working correctly).
[2017-02-20 15:14:22] <sn00pster> Any thoughts on where I should begin to look for the cause of this?
[2017-02-20 16:37:11] <Crizstian> Hello community this week, i want to share a mind blowing article from the series “Build a nodejs cinema microservice”, that i have published @medium, this article is fully charged with docker and its ecosystem, as always you are welcome to give me a feedback, contributions or just put a comment below =]https://medium.com/@cramirez92/deploy-a-nodejs-microservices-to-a-docker-swarm-cluster-docker-from-zero-to-hero-464fa1369ea0#.4cd2vpjcy
[2017-02-21 02:27:33] <comeUpWithItLater> I have  site1.com,   site1.com  ...  site*.com  runing on their own container,   how to config all these containers all  listen to port 80?  just like apache  vhost
[2017-02-21 05:36:53] <SISheogorath> comeUpWithItLater: use a reverse proxy. jwilder's nginx is nice. I personally prefer traefik.
[2017-02-21 06:06:32] <comeUpWithItLater> so i have to install nginx on the host machine ?
[2017-02-21 06:07:17] <comeUpWithItLater> or one of the image ,say site1.com
[2017-02-21 08:39:55] <ely029> Hey guys How can I connect the mssql server in my local to the mssql server installed in linux?here is my docker-compose.yml [<-CODE->] 
[2017-02-21 08:40:20] <ely029> awww sorry for that
[2017-02-21 08:41:25] <ely029> this is my docker-compose yml code [<-CODE->] 
[2017-02-21 08:41:35] <ely029> I dont know how
[2017-02-21 08:42:11] <ely029> to connect my local mssql server to the dockerized mssql server
[2017-02-21 09:28:57] <hblaise> Hi, I have a bash script which runs when you do docker-compose up  and has the following content [<-LINK->] 
[2017-02-21 09:29:18] <hblaise> the directory is there but it does not get mounted, could someone maybe tell me why?
[2017-02-21 09:53:13] <comeUpWithItLater> let me  have a look at the  *.yml  file?
[2017-02-21 10:04:40] <hblaise> comeUpWithItLater: the yml file doesnt ahve anything concerning the mount
[2017-02-21 10:35:06] <hblaise> this is pretty much the same issue i have [<-LINK->] 
[2017-02-21 10:35:14] <hblaise> but privileged param didnt help
[2017-02-21 11:42:46] <daniel-halito> Anyone knows a good solution to use php-cli and keep the container running it alive?
[2017-02-21 12:18:23] <kschlesselmann> daniel-halito: What do you want to achieve?
[2017-02-21 12:28:48] <daniel-halito> I’m trying to run a micro service (Lumen) by only using php-cli.
[2017-02-21 12:29:18] <daniel-halito> But the problem is that my container exits by itself
[2017-02-21 12:29:34] <daniel-halito> Probably because php-cli is not running a daemon
[2017-02-21 13:51:13] <atul1989> i am getting following error while pushing image into registry
[2017-02-21 13:52:31] <atul1989> [root@gcs-build-doc~]# docker imagesREPOSITORY          TAG                 IMAGE ID            CREATED             SIZEregistry            2                   d1e32b95d8e8        4 weeks ago         33.2 MBcentos              latest              67591570dd29        2 months ago        192 MB[root@gcs-build-doc~]# hostnamegcs-build-doc.pbi.global.pvt[root@gcs-build-doc~]# docker tag 67591570dd29 152.144.219.129:5000/centos1:latest[root@gcs-build-doc~]# docker push  152.144.219.129:5000/centos1:latestThe push refers to a repository [152.144.219.129:5000/centos1]Get [<-LINK->] : EOF[root@gcs-build-doc~]#
[2017-02-21 13:52:47] <atul1989> Get [<-LINK->] : EOF
[2017-02-21 14:45:16] <tulpn> Hi guys, I have a few questions, as I am just starting with docker and I am a bit confused after the books, tutorials and whatever else I read. A lot of infos to get into.... At the moment we are working with vagrant to be as close to the server arch as possible. What we want to do is get rid of our monolith system and move to a microservice structure. From what I read each line in the docker config will create a new hash for a layer, therefore it is better to get a base container where all the apt stuff is done, all dependencies are created etc and use that as a FROM for the actuall app deployment container, where I only have to copy the app pretty much. This would also speed up the deployment as far as I am concerned since no heavy installs need to be done. But how does the actual deployment work ? I am developing on my vagrant vm, do my git commits etc and at some point I say we can deploy a new version. Would a git pull be in the docker file ? Is the vhost configuration within the docker instance or will it use the webserver from the host system the docker container runs from ?
[2017-02-21 15:02:43] <sopanshewale> soapoperator: - i am sorry, i missed your comment. I was away from gitter long time. let me know if anything i need to catch?
[2017-02-21 15:36:41] <verwilst> by default when you do docker login your.own.registry, it tries to connect to port 443 it seems. I think it looks ugly to specify docker login your.own.registry:5000
[2017-02-21 15:36:59] <verwilst> should i just run the registry on port 443 then instead of 5000?
[2017-02-21 15:44:37] <SISheogorath> tulpn: I could explain the whole thing but it would take me long time as I am on a smartphone. I recommend you to read the user guide in the docs [<-LINK->] 
[2017-02-21 15:46:06] <SISheogorath> comeUpWithItLater: you can run the reverse proxy on your host but I would recommend you to run it in a container too. Make a lot things easier. The mentioned images are both for containers
[2017-02-21 15:46:14] <verwilst> yes! 443:5000 works!
[2017-02-21 15:48:54] <SISheogorath> felyx: you should mount a tmpfs or ramdisk via docker run, not inside the container
[2017-02-21 15:51:32] <pgrekovich> Hi guys. On Windows 10, what better use docker toolbox or native with hyper-v? Why? p.s. sorry for my english.
[2017-02-21 15:51:41] <SISheogorath> daniel-halito: in worst case use a bash script as wrapper and restart what ever you want to keep. Not sure what's the point of running something with the php-cli and don't want to get the container exited. In general think about the fact that should not have any persistent data in your container
[2017-02-21 15:52:45] <SISheogorath> pgrekovich: the current, official recommendation is docker for Windows. But it maybe depends on your use case
[2017-02-21 15:54:12] <SISheogorath> Docker for Windows is recommended because it's better integrated and able to run Windows Containers if you want (have to switch to Windows container mode)
[2017-02-21 15:54:51] <pgrekovich> SISheogorath: ok, but if i'm use docker for Windows, and other guys in team use docker toolbox we will have some problems in future?
[2017-02-21 15:54:56] <SISheogorath> The toolbox is maybe better for people already running VM in virtualbox and want don't need Windows containers
[2017-02-21 15:55:20] <SISheogorath> As long as both develop Linux containers that is no problem
[2017-02-21 15:55:34] <SISheogorath> But keep an eye on your line endings ;)
[2017-02-21 15:57:14] <pgrekovich> SISheogorath: in production we using Linux servers :) i think docker toolbox better way for me
[2017-02-21 15:57:40] <SISheogorath> Maybe you simply use docker-machine ^^
[2017-02-21 15:58:30] <pgrekovich> SISheogorath: yeap, thanks for help 
[2017-02-21 15:58:45] <SISheogorath> You're welcome
[2017-02-21 16:03:51] <daniel-halito> SISheogorath: How would you approach it? You have a micro service where no apache/nginx is needed, it just receives and sends commands.
[2017-02-21 16:04:51] <SISheogorath> Maybe add awhile 1loop?
[2017-02-21 16:05:00] <SISheogorath> Make it a service :D
[2017-02-21 16:05:29] <daniel-halito> :)
[2017-02-21 16:05:53] <SISheogorath> If you are unable to do that you can letnclisten and push everything incoming to the command :D
[2017-02-21 16:06:26] <SISheogorath> (Disclaimer: I'm in love with crazy setups)
[2017-02-21 16:06:41] <daniel-halito> I’ve noticed
[2017-02-21 16:06:43] <daniel-halito> ;)
[2017-02-21 16:10:10] <SISheogorath> #commandlinemagic
[2017-02-22 05:14:17] <soapoperator> sopanshewale: it works with dockerfile. thank you for the follow-up.
[2017-02-22 06:24:38] <thebuccaneersden> so, im using docker on my raspberry pi. im needing to build a docker image. I’ve built it fine, but what do i then need to run to create a container from my locla build?
[2017-02-22 06:27:25] <thebuccaneersden> it shows up underdocker imageslike so:
[2017-02-22 06:27:35] <thebuccaneersden> `REPOSITORY                    TAG                 IMAGE ID            CREATED             SIZE<none>                        <none>              fbe0097c1fb5        6 minutes ago       10.89 MB`
[2017-02-22 06:38:03] <4406arthur> thebuccaneersden: , docker run -itd fbe0097c1fb5 /bin/bash
[2017-02-22 06:39:00] <sopanshewale> soapoperator: - great to hear that!
[2017-02-22 06:54:20] <mixer2> good morning. i've a question about docker cache invalidation.in my docker file i have: [<-CODE->] package.json, bower.json and Dockerfile itself are unchanged. for some reason the RUN instruction invalidates the cache, which, as far as i understand shouldn't if the run instruction isn't changed. [<-CODE->] 
[2017-02-22 06:59:01] <mixer2> and in another container i've nearly the same problem with composer. but in that container it invalidates already the composer.json and composer.lock ADD instructions even if they are unchanged. what is very surprising, because the adding works fine from cache with package.json and bower.json. [<-CODE->]  [<-CODE->] 
[2017-02-22 09:05:05] <sn00pster> Can anybody come up with an explanation as to why docker is not creating iptable FORWARD rules?  I've just got a default DENY rule and containers can't be accessed, if I do iptables -P FORWARD accept then the containers can be accessed.
[2017-02-22 09:05:36] <sn00pster> Normally docker creates FORWARD rules but since reinstallation it's not doing that.  It's creating other rules, just nothing in FORWARD.
[2017-02-22 12:09:32] <sujaypillai> Any suggestion for a volume driver other than AzureFile driver to use with a postgres container?
[2017-02-22 21:32:10] <vito-c> Is there a room to ask questions about accessing docker go client or docker libcompose?
[2017-02-22 21:32:41] <vito-c> I'm having issues with it authenticating against my registry
[2017-02-22 21:35:19] <SISheogorath> @vito-c in general the docker community is a good place to ask. Also the docker forums are good for detailed questions or ideas. Last but not least there is StackExchange where you can ask your question and mark it as a docker question.But you can also ask the question here and maybe someone can help you
[2017-02-22 21:38:01] <vito-c> Pretty straight forward I'm just trying to get the go libcompose to recognize my private registry: [<-CODE->] but I can see it parsing the auth configs when I added log dumps to the libcompose. There is probably some simple call I am missing?
[2017-02-22 21:38:34] <vito-c> when I use just docker-compose it works fine
[2017-02-22 21:42:11] <SISheogorath> did you use [<-LINK->] ? There is anauthLookup-object passed
[2017-02-22 21:44:37] <killerspaz> has anyone had success with dockerized jenkins running docker within? I've volume moutned docker, and from within the container i am able to fully do anything i want with docker, but jenkins is complaining access denied (i'm testing with jenkins user of course).... this was working earlier today just fine, i just restarted all the services due to a non-related service change. now all of a sudden it's access denied non-stop from the jenkins ui (again, inside the container works fine)
[2017-02-22 21:47:20] <vito-c> SISheogorath: ic I am using this one though [<-LINK->] 
[2017-02-22 21:48:08] <vito-c> the one I linked should be doing the samething but for all the images in the compose file
[2017-02-22 21:51:24] <SISheogorath> I traced it... The project calls pull for each service and each service calls pull for each image...
[2017-02-22 21:51:47] <killerspaz> bahhhh, that was 6 hours of wasted fuckin time
[2017-02-22 21:51:52] <SISheogorath> Well, that was expected but I'm not completely sure where the configs are get passed
[2017-02-22 21:51:56] <killerspaz> all i needed was to restart the daemon :/
[2017-02-22 22:05:22] <vito-c> SISheogorath: I think it gets set in the Project struct when I was trying justupit wasn't working and returning an empty auth config object but when I changed it to pull this updated. [<-CODE->] 
[2017-02-22 22:07:23] <vito-c> SISheogorath: what did you use to trace the call I have intellij setup but it dies when I try to debug
[2017-02-22 22:07:47] <SISheogorath> I simply used the docs ^^
[2017-02-22 22:07:59] <SISheogorath> and the sourcecode
[2017-02-22 22:09:44] <vito-c> k cool
[2017-02-22 22:15:58] <SISheogorath> I'm not a big fan of IDEs ^^ And as I'm not a go programmer...
[2017-02-22 22:17:20] <SISheogorath> but it calls it here: [<-LINK->] which calls: [<-LINK->] 
[2017-02-22 22:17:30] <SISheogorath> possibly there is currently an option missing
[2017-02-22 22:17:33] <vito-c> yeah I can confer
[2017-02-22 22:18:10] <SISheogorath> the lib is marked as experimental :D So not sure if it is a problem of the concept or your usage
[2017-02-22 23:15:23] <vito-c> the lib is also a bit behind the main docker client repo
[2017-02-23 02:07:31] <vito-c> SISheogorath: fwiw I added to the existing ticket [<-ISSUE->] 
[2017-02-23 05:39:47] <soapoperator> Anybody use traefik as proxy. Here is my docker-simple simple config: [<-CODE->] I had an simple app to test: [<-CODE->] I can connect to traefix interface but it stay desesperatly empty:http://i.imgur.com/IHRBJCN.pngAny idea?
[2017-02-23 06:32:56] <ahmadabdullah247> Hi guys I am getting an issue starting docker container,docker start <container-id> command  not working for a stopped container.Connecting via putty from windows [<-CODE->] 
[2017-02-23 08:50:45] <tomVeloso> If I conect thought bash to a container and from inside  run the command everithing is fine... but if I try to pass directly the command from outiside
[2017-02-23 08:50:50] <tomVeloso> I getlibarpack.so.2: cannot open shared object file: No such file or directory
[2017-02-23 09:12:01] <SISheogorath> tomVeloso: right working directory?
[2017-02-23 09:13:27] <SISheogorath> ahmadabdullah247: The error message tells you the problem. Check that the path to your binary is in$PATHor better use the absolute path.
[2017-02-23 09:17:40] <SISheogorath> soapoperator: looks like your config and the parameters are not working together. Not sure which one is higher. Maybe checkout [<-LINK->] 
[2017-02-23 09:23:40] <ahmadabdullah247> SISheogorath: absolute path worked
[2017-02-23 09:55:00] <tomVeloso> SISheogorath: how can specify the full path?
[2017-02-23 09:57:30] <tomVeloso> I mean how can I say to look in a specify directory?
[2017-02-23 10:04:04] <tomVeloso> SISheogorath: ok .. found the solution I need to wrup my command in abash -c
[2017-02-23 12:35:42] <SISheogorath> tomVeloso: not sure that this is the best solution. Maybe you can check that your Dockerfile follows the docker best practices
[2017-02-23 15:27:53] <skoddowl> Hi, can anyone help me with docker compose setup? I'm getting an error trying to start db psql service: [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2017-02-23 16:18:14] <sbbowers__twitter> Hello, I have muiltiple docker builds that pull out specific things from a monolithic codebase, and hence my build context is large.  I want to use .dockerignore to reduce this context, but I don't know how to ignore things on a per-build basis.  How do I manage ignoring different directories with multiple builds in a repository?
[2017-02-23 16:19:42] <killerspaz> maybe instead of ignoring, you include per-build basis?
[2017-02-23 16:20:13] <killerspaz> you can accomplish that by segregating files into common and per-build environments, and use env vars to indicate which hierarchy you want to include in the build
[2017-02-23 16:21:16] <sbbowers__twitter> so the only way to solve this problem is through re-structuring the codebase?
[2017-02-23 16:22:13] <killerspaz> typically that's the wisest and most maintainable way
[2017-02-23 16:22:21] <killerspaz> i wouldn't say the ONLY though
[2017-02-23 16:24:11] <killerspaz> alternatively if you want to exclude things, your build system will need to probably dynamically create the .dockerignore file to your desires. But honestly that just sounds like a time bomb waiting to explode
[2017-02-23 16:27:57] <sbbowers__twitter> ok. thanks for your suggestions.
[2017-02-23 20:55:52] <chrismpalmer> Friends! Has anyone had success exporting DISPLAY env variable ? I need to run some python that generates graphs and will need graphics support. I think I'll need Xfvb running?
[2017-02-23 21:06:40] <SISheogorath> The DISPLAY ENV var? Why? You can run Xfvb, yes, if you need to run headless. If you run on a desktop machine, you can mount your X session
[2017-02-24 01:48:33] <chrismpalmer> SISheogorath: thanks for the reply, yes mount my x session sounds good I didn't know you could do that . Dumb question I assume this is done inside docker container right?
[2017-02-24 03:17:52] <SISheogorath> I never did that before,@chrismpalmer
[2017-02-24 03:18:01] <SISheogorath> Maybe checkout [<-LINK->] 
[2017-02-24 04:18:12] <matrixbot> lanyangyang [<-LINK->] 
[2017-02-24 04:37:53] <chrismpalmer> SISheogorath: thanks !!
[2017-02-24 07:58:43] <drahnr> Hi
[2017-02-24 07:59:01] <drahnr> I have a bit of an awkward issue regarding container to container connectivity
[2017-02-24 08:00:21] <drahnr> whatever I export or publish, I only getConnection refusedwith curl
[2017-02-24 08:01:24] <drahnr> full details here: [<-LINK->] 
[2017-02-24 08:01:36] <drahnr> it would be awsome if someone could have a look on that
[2017-02-24 12:36:00] <jeserkin> Hello guys.
[2017-02-24 12:37:47] <jeserkin> Was wondering whether it is possible after installing machine through existing image somehow further to automate project setup on installed machine. Like git pull repository from github for example. Or any other required task.
[2017-02-24 12:39:04] <drahnr> jeserkin: map your project directory in your docker container, that is usually the fastest, maybe put a script in the docker container to allow easy setup if it is a first run
[2017-02-24 12:41:26] <jeserkin> map your project directoryWhat exactly do you mean? Kitematic volume setup?
[2017-02-24 12:42:13] <drahnr> Not sure what scale you operate on, but-vmight do the job (if the scale is suffiently small)
[2017-02-24 12:44:52] <jeserkin> Used this btw [<-LINK->] 
[2017-02-24 12:45:32] <jeserkin> I am new to Docker and to the way it operates. So sorry in advance.
[2017-02-24 13:35:36] <jeserkin> Okay, I think I will be able to manage getting files from local system to docker vm at hand. Other question involves additional moves during setup step if it is possible. Is it possible?
[2017-02-24 14:04:03] <vyscond> I got huge question here fellas, so i posted here [<-LINK->] to not flood the channel
[2017-02-24 14:45:01] <SISheogorath> vyscond: I would recommend you to ask this question in [<-LINK->] because it's a setup which possibly needs addition information etc.
[2017-02-24 17:41:28] <pavel-sindelka> Hi guys! How to install docker on ubuntu?
[2017-02-24 17:49:01] <adelsjnr_twitter> Hi@pavel-sindelka, Docker web site has a great documentation on how to install it on ubuntu. Follows the documentation: [<-LINK->] 
[2017-02-24 17:51:00] <pavel-sindelka> adelsjnr_twitter: thanks a lot
[2017-02-24 17:51:44] <adelsjnr_twitter> pavel-sindelka: ;)
[2017-02-24 20:23:54] <ryanturner> Hi, I'm having trouble getting docker daemon to connect to the registry. I get the following message when I try docker run hello-world:docker: Error response from daemon: Get https://registry-1.docker.io/v2/: dial tcp 54.236.131.143:443: getsockopt: connection refused.
[2017-02-24 20:24:27] <ryanturner> When I do a curl of [<-LINK->] I get a json response biody with code UNAUTHORIZED and detail null
[2017-02-24 20:25:10] <ryanturner> I don't know how to troubleshoot this; I'm behind a proxy that sometimes reterminates SSL, but I have the root cert installed for the CA that reterminates, and I have the proxy configured on docker
[2017-02-24 20:25:34] <ryanturner> and in my curl command at least, the SSL cert that I see is the real rapidssl cert, as if it were e2e and not reterminated.
[2017-02-24 20:26:49] <ryanturner> I read something that said that it could be because of an out of sync clock, something related to auth with the registry, but my clock is set appropriately
[2017-02-24 20:26:57] <ryanturner> This is on centos 7
[2017-02-24 20:30:34] <ryanturner> docker logingives me the same failure
[2017-02-24 20:32:03] <killerspaz> Hopefully a quick question, I have a service like so: [<-CODE->] And another like so: [<-CODE->]  [<-CODE->] 
[2017-02-24 20:32:41] <killerspaz> ryanturner: what exact command are you running to try hello-world?
[2017-02-24 20:38:05] <killerspaz> Problem with dial: dial tcp: lookup mysql on 127.0.0.11:53: no such host. Sleeping 5sis what I keep getting, as if it has no clue where to hit a DNS?
[2017-02-24 20:54:13] <killerspaz> hmm... I'm t hinkinghostnamedoesn't actually have an effect on the DNS config, i think it jsut sets the hostname of the container in /etc/hostname
[2017-02-24 22:02:40] <jeserkin> Where should I start in documentation if I'm new to Docker and wish to create own build process, e.g. specify existing image from hub and additional steps like execution of a shell script on resulting VM?
[2017-02-24 22:05:35] <dragon788> well downloading an image gets you the base, and then you create a Dockerfile that can run additional steps to build a "container", containers != VMs, a VM can emulate other hardware to run the OS, Docker containers require the host OS to have a similar kernel (ie Linux containers on Linux, Windows containers on Windows) though sometimes you can work around this running a container within a VM, but that\'s not a common requirement
[2017-02-24 22:09:05] <jeserkin> Hmmmm. Not sure I'm following. Doesn't Docker automatically create VM entry in either Hyper-V or VirtualBox (e.g. on Windows)?
[2017-02-24 22:28:00] <jeserkin> So yeah. In any case question still remains about where to start in docs.
[2017-02-24 23:19:02] <SISheogorath> jeserkin: in genereal I would recommend [<-LINK->] 
[2017-02-24 23:20:59] <SISheogorath> But in genereal Docker for Windows and docker for Mac create a VM for running linux containers. But they run all docker commands inside this VM. So the docker image itself is not a VM template. Docker itself uses linux kernel internals to isolate containers. For Windows containers the same applies to windows. In this case docker doesn't run a VM. But I can't say much about windows containers. As it's nothing I use.
[2017-02-24 23:25:55] <Niko-La> anyone know how to leave an -it container and have it running daemon upon exit from the bash console?
[2017-02-24 23:27:04] <SISheogorath> you want to use a docker container likescreen?
[2017-02-24 23:27:25] <killerspaz> docker run -it -d --name test MYIMAGE tail -f /dev/nullthendocker exec -it test /bin/bash
[2017-02-24 23:27:42] <killerspaz> assuming a bash-based image
[2017-02-24 23:28:26] <Niko-La>  [<-LINK->] 
[2017-02-24 23:29:07] <Niko-La> essentially i have to run emark simulator during docker run.is it possible to get thse console outputs
[2017-02-24 23:33:07] <killerspaz> like i said
[2017-02-24 23:38:48] <Niko-La> awesome i was able to bash into the container with exec. now I run "embark simulator" in bash.  now if i press  cntrl c it takes me back to bash in container and exit now means i am back at square one ?
[2017-02-24 23:40:08] <killerspaz> embark simulator &
[2017-02-24 23:40:26] <Niko-La> i  need that "embark simulator" which is node application to run as 1 terminal and get access to another terminal.  This very easy to do with native docker as u can open up another terminal and docker exec.
[2017-02-24 23:40:43] <killerspaz> Fromman bash: [<-CODE->] 
[2017-02-24 23:42:09] <Niko-La>  [<-LINK->] 
[2017-02-24 23:52:54] <Niko-La> @killerspaz thanks for your help.  i think it would be if i pipe out the embark blockchain to a file and open it in my computer then exec it. i just need to know the accounts and keys.windows is killling me 
[2017-02-24 23:54:34] <Niko-La> )
[2017-02-25 00:28:04] <killerspaz> can you not utilize the logs? or is something programmatic needing this information?
[2017-02-25 00:28:20] <killerspaz> brb, my dpi is all jacked up
[2017-02-25 03:53:14] <Niko-La> i will have to look into how to get stdout to logs.Is it there a way to run docker native on Windows 10 Home?
[2017-02-25 11:35:58] <jonlambert> Hey guys! Having real troubles installing docker on Ubuntu Vivid. I'm getting the following:Depends: libdevmapper1.02.1 (>= 2:1.02.97) but 2:1.02.90-2ubuntu1 is to be installed\n                 Depends: libltdl7 (>= 2.4.6) but it is not going to be installed
[2017-02-25 11:36:41] <jonlambert> Could anybody offer advice as to what's going wrong? Will gist my apt policy
[2017-02-25 11:37:21] <jonlambert>  [<-LINK->] 
[2017-02-25 19:23:24] <SISheogorath> jonlambert: in your case the Docker engines dependencies conflict with your setup. For some reason you can't install the needed version of a dependency. It's neither wrong with your pins nor with the docker engine package it's simply the combination of the packages installed on your system
[2017-02-26 02:16:18] <Niko-La> hey guys. I have a docker image that ends with\'CMD ["node", "/usr/src/app/index.js"]\'now when i do a docker run -it containernum bashi am just getting the bashnow if i remove bash from the run command it exits the docker after running the index.jshow can i run the index.js and reamain in the bash console
[2017-02-26 02:35:44] <SISheogorath> in general you can write an entrypoint script, which runs the nodeJS application and then runs a normal bash process
[2017-02-26 02:36:10] <SISheogorath> in this case you can replace the CMD with an entrypoint statement
[2017-02-26 02:36:18] <SISheogorath> which calls the entrypoint script
[2017-02-26 02:37:14] <Niko-La> CMD ["bash", "/usr/src/app/boot.sh"]
[2017-02-26 02:38:02] <Niko-La> ! /bin/shnode index.js
[2017-02-26 02:38:19] <Niko-La> this was my booth.sh script.
[2017-02-26 02:40:03] <SISheogorath> use [<-CODE->] 
[2017-02-26 02:42:02] <Niko-La> hi how are you guys getting the code to highlight when pasting in gitter.
[2017-02-26 02:42:34] <Niko-La>  [<-LINK->] 
[2017-02-26 02:43:34] <Niko-La>  [<-LINK->] 
[2017-02-26 02:44:38] <SISheogorath> use Markdown syntax
[2017-02-26 02:45:39] <SISheogorath> That a cert error. NodeJS has some problems with custom certificates
[2017-02-26 02:46:26] <SISheogorath> And you use windows lineendings
[2017-02-26 02:46:35] <SISheogorath> which is a bad idea as you run a linux container
[2017-02-26 02:47:41] <SISheogorath> and maybe use/bin/bashinstead of bash in your entrypoint script
[2017-02-26 02:50:39] <Niko-La> hmm wierd.  i took out the node index.js and just did exec bash: not foundp/boot.sh: line 2: exec: bash
[2017-02-26 02:51:10] <SISheogorath> As I said use the full path
[2017-02-26 02:53:21] <Niko-La>  [<-LINK->] 
[2017-02-26 02:53:47] <Niko-La> u added uname -a to the first bash entry as well to see if that runs
[2017-02-26 02:58:08] <Niko-La> ya removed all the node and just tried ls command it gave and error for that as well. 
[2017-02-26 03:06:24] <SISheogorath> you should useexec /bin/bashinstead ofexec bash>.>
[2017-02-26 03:06:40] <SISheogorath> that was what I'm saying :D
[2017-02-26 03:15:47] <Niko-La> hahaha this is :( it worked once  then not again
[2017-02-26 03:16:45] <Niko-La> the one time it worked. it ran the node script then: No such file or directory2: /bin/bash
[2017-02-26 03:16:51] <Niko-La> :|
[2017-02-26 03:25:47] <SISheogorath> on build run dos2unix on your script to make sure that it uses linux linendings
[2017-02-26 03:29:26] <Niko-La> http://stackoverflow.com/questions/6643152/nodejs-bash-cant-find-nodeseems like i got a head scratcher. thanks for your help
[2017-02-26 03:40:39] <Niko-La> ENV NODE_PATH probaly is the issue for bash scriping node commands
[2017-02-26 03:56:00] <SISheogorath> in this case you should stop calling the entrypoint script in a subshell
[2017-02-26 03:56:19] <SISheogorath> simply useCMD ["/path/to/script.sh"]
[2017-02-26 08:01:53] <Niko-La> nice. also ran the srcipt.sh through doc2unix.  Have the node file running fine but  the   exec /bin/bash is not causing the docker comtainer to stay in bash terminal. its exiting :/overall its been a very good day of learning this tech. @SISheogorath much appreciate the time.
[2017-02-26 08:11:06] <Niko-La> CMD bash -C '/usr/src/app/boot.sh';'bash'      this works out nicey :D
[2017-02-26 10:13:03] <sandys> hey guys - i deployed a stack using docker swarm and compose.yml. Now, I have updated a few environment variables in my compose.yml. How do I update the service so that it picks up these new environment flags ? updating the service is not picking up the new configuration
[2017-02-26 12:01:01] <sandys> Niko-La: i use the full path btw "dumb-init /opt/nodejs/node-v7.5.0-linux-x64/bin/node /oms/server.js" , where dumb-init is a tool that i use for graceful restarts of node.
[2017-02-26 12:27:26] <jeserkin> Mornin'
[2017-02-26 12:27:58] <jeserkin> Guys, how can I enable network connection to the internet from docker container
[2017-02-26 12:28:27] <jeserkin> So for example my project in container requires files to be downloaded through curl
[2017-02-26 12:29:01] <jeserkin> But I'm getting [<-CODE->] 
[2017-02-26 12:29:27] <jeserkin> ping command is sadly missing as well
[2017-02-26 12:30:49] <jeserkin> Sry guys. Seems VPN network somehow conflicted with that. Once it was off, everything was fine.
[2017-02-26 17:17:58] <SISheogorath> sandys: if you make changes in the docker compose file and rerun stack deploy everything should be updated
[2017-02-26 20:39:43] <jeserkin> When one references an image e.g. in commanddocker run ...., then is image a repo at hub.docker.com or do I understand it wrong way?
[2017-02-26 20:51:39] <racinmat> jeserkin: mostly yes
[2017-02-26 20:52:53] <racinmat> jeserkin: or it can be just your own image
[2017-02-26 21:38:00] <SISheogorath> @jeserkin In genereal it don't have to be on docker hub. Let's see: First of all it highly depends on your configuration but let's asume everything is on default settings from a setup from https://get.docker.com. [<-CODE->]  [<-CODE->] Hopefully this helps
[2017-02-26 21:38:29] <SISheogorath> (Last hint: In case of port 443 you don't have to specify the port)
[2017-02-26 23:34:11] <jeserkin> It did help a bit. My main question would be, what is considered to be an image? e.g. I've created aDockerfileon my system. Can I specify to run it somehow as an image? e.g.docker run /path/to/local/Dockerfile
[2017-02-26 23:35:54] <briantyr> jeserkin: : docker build -t image-name:[tagoptional] -f PATH/Dockerfile
[2017-02-26 23:36:49] <briantyr> or just exclude  -f PATH/Dockerfile and do "docker build -t image-name ." to build an image.   I think the . should work to show the build context anyway :P
[2017-02-26 23:38:12] <briantyr> then type "docker images" to see your "image-name" in the list and you can run a container from that image with "docker run -p host-port:container-port image-name"
[2017-02-26 23:38:57] <briantyr> Syntax should more or less be right - I mostly use docker-compose nowadays but you can type docker <CMD> --help to get more help on a command.
[2017-02-26 23:40:50] <racinmat> jeserkin: When you create the Dockerfile, it is like when you write a recipe for an image. Then, you must "cook" this image by using thedocker build. And when the image is built, you can create instances of it a.k.a. containers
[2017-02-27 00:11:22] <SISheogorath> Docker parts translated to classic schemas:Dockerfile - Source CodeDocker image - Programm (compiled binary)container - ProcessIt's not completely correct but to understand how it works, that's maybe helpful
[2017-02-27 00:14:13] <jeserkin> Thank you guys
[2017-02-27 00:15:04] <SISheogorath> checkout the getting started docs at [<-LINK->] 
[2017-02-27 00:18:46] <jeserkin> On this chapter atm [<-LINK->] 
[2017-02-27 07:08:32] <476678244> Hi, Can I ask a question about docker-compose? I`m writing docker compose file and how can I make a service as the effect of "docker run -t" to prevent the container exit ?
[2017-02-27 07:40:11] <comeUpWithItLater> hi , i  just import an image with docker import comand:
[2017-02-27 07:40:26] <comeUpWithItLater>  [<-LINK->] 
[2017-02-27 07:41:25] <comeUpWithItLater> but  "$docker-compose up -d  "  doesn\'t use the image i just imported
[2017-02-27 07:42:47] <comeUpWithItLater> Hi@476678244,   add me on QQ:1637051798
[2017-02-27 09:30:35] <jeserkin> @SISheogorathhey.  When I writeFROMinDockerfiledoes it mean mean, that I'm referencing only image orDockerfilefrom what image was built?
[2017-02-27 10:26:37] <jeserkin> Does it matter whereEXPOSEis located inDockerfile? I am marking, thatEXPOSE 80 443, but in resulting container there are no ports provided out of the box. Only if I add myself.
[2017-02-27 12:02:49] <jeserkin> So few questions left from my interaction with Docker. [<-CODE->] 
[2017-02-27 13:47:34] <seltsam23> Is there a way to run two commands in parallel via compose-file command ? Trying to run nodemon and grunt together
[2017-02-27 13:59:58] <SISheogorath> jeserkin: you reference an image withFROM
[2017-02-27 14:02:12] <iosven> I am having a problem updating to docker 1.3 on CentOS 7.3 - added the docker repo to yum andsudo yum install docker-engineyields--> Finished Dependency Resolution\nError: docker-engine conflicts with 2:docker-1.12.5-14.el7.centos.x86_64\nError: docker-engine-selinux conflicts with 2:container-selinux-1.12.5-14.el7.centos.x86_64\n You could try using --skip-broken to work around the problem\n You could try running: rpm -Va --nofiles --nodigestAny hints appreciated.
[2017-02-27 14:02:19] <SISheogorath> For Details aboutEXPOSEplease read [<-LINK->] 
[2017-02-27 14:03:18] <SISheogorath> To have a tagged image you need to add the-tflag to yourdocker buildcommand
[2017-02-27 14:04:26] <SISheogorath> seltsam23: you can run an entrypoint script with utilize&like in a regular shell script.
[2017-02-27 14:06:29] <SISheogorath> sourcekick: You have an dependency conflict. Depending on your setup you can possibly solve it by uninstalling the conflicting packages. But be aware of the possible problem that this breaks your setup if you don't know what you're doing
[2017-02-27 14:30:13] <seltsam23> SISheogorath: Do you mean like "command: ["nodemon" && "npm run grunt"]" ?
[2017-02-27 14:31:39] <SISheogorath> No. I'm not sure that it works with array notation
[2017-02-27 14:32:37] <SISheogorath> I was thinking about something likenpm run grunt & ; nodemon
[2017-02-27 14:33:04] <seltsam23> command:  npm run grunt & ; nodemon
[2017-02-27 14:34:06] <SISheogorath> As mentioned placing it in a shell script should work. For command or similar I can't speak
[2017-02-27 14:34:31] <seltsam23> I have no experience with shellscripts
[2017-02-27 14:34:43] <seltsam23> are they placed next to to the compose-file?
[2017-02-27 14:36:28] <SISheogorath> They should placed inside the container and you call them like an executable
[2017-02-27 14:39:05] <seltsam23> alright, will look into that, thank you!
[2017-02-27 14:52:07] <iosven> SISheogorath: The server is still blank, so I could even uninstall docker engine and then reinstall it. There is one catch, I already also installed docker-compose. Do you think uninstall then install of docker engine would be feasible in this scenario?
[2017-02-27 14:52:37] <iosven> The installed docker-compose is the latest release.
[2017-02-27 14:53:58] <SISheogorath> Simply uninstallingcontainer-selinux-1.12.5should help
[2017-02-27 14:57:15] <iosven> Thanks! I am on it now, so far no problems.
[2017-02-27 14:58:26] <jonleopard> Hello everyone
[2017-02-27 15:20:16] <iosven> It worked, however I went with the full uninstall of docker in the following perhaps somewhat "individual" way: [<-CODE->] 
[2017-02-27 15:21:20] <iosven> Thereafter I didyum -y install docker-engine-1.13.1-1.el7.centos(yum also being completely up to date before this command)
[2017-02-27 15:22:08] <iosven> docker-composewas just sitting there unchanged during all this and now just works :)
[2017-02-27 20:39:39] <killerspaz> Anyone run into an issue with a node project wheredocker-composesetup is yielding errors about a node module not found, yet you can run the container manually and it works?
[2017-02-27 20:51:12] <SISheogorath> I'm not completely sure but I would say there is a difference between the run statement and the settings you pass by compose
[2017-02-27 20:54:32] <killerspaz>  [<-CODE->] vs [<-CODE->] 
[2017-02-27 20:56:26] <killerspaz> should be pretty straightforward
[2017-02-27 21:00:23] <karanhiremath> killerspaz: I’ve had this issue with docker-compose in general before with npm modules. switching to yarn w/ a yarn.lock file solved them for me but I’m not sure what the real issue here is and whether it’s with npm or docker-compose
[2017-02-27 21:06:37] <killerspaz> not sure how that would solve any problems related to this?
[2017-02-27 21:10:42] <SISheogorath> killerspaz: do you run an entrypoint script or similar?
[2017-02-27 21:11:12] <killerspaz> it's 100% listed just above... dockerize is the only thing i have added besides node
[2017-02-27 21:11:33] <killerspaz> no entrypoint set
[2017-02-27 21:11:37] <SISheogorath> Maybe runenvinstead ofnodeto see what environment variables are available
[2017-02-27 21:12:04] <SISheogorath> I guess it's aNODE_PATHproblem
[2017-02-27 21:12:38] <killerspaz> but it should by default look in the project...
[2017-02-27 21:12:46] <killerspaz> also, same env vars when ran from docker vs when i run manually
[2017-02-27 21:13:30] <killerspaz>  [<-CODE->] 
[2017-02-27 21:14:03] <killerspaz> node should be looking innode_modulesin the app root, which it seems to do fine when running manually
[2017-02-27 21:14:44] <killerspaz> ahhh my teammate figured it out
[2017-02-27 21:14:55] <SISheogorath> What was it?
[2017-02-27 21:15:21] <killerspaz> silly me, had an ovverride set indocker-compose.override.ymlthat mounted my code as a volume, but since i'm testing build process there's nonode_modulesthus when ran asdocker-composei'm wiping the modules
[2017-02-27 21:15:47] <SISheogorath> >.>Makes sense
[2017-02-27 21:15:56] <killerspaz> wish i had thought of that sooner
[2017-02-28 01:11:10] <Niko-La> hi guys running docker toolbox for Windows on MinGW64. I am running a container which has localhost port 8000 exposed.  Because of this vm machine set-up for Windows Home.
[2017-02-28 01:13:08] <Niko-La> is there a way to find out which ip it is exposed now on this container?  I have had success with server all containers with ip 192.168.99.100
[2017-02-28 02:31:48] <killerspaz> docker-machine ip <machine name>will show you the ip addy of your vm
[2017-02-28 02:33:17] <killerspaz> docker inspect CONTAINER_IDwill show you a ton of meta-data about the container, specifically which ports are exposed or mapped
[2017-02-28 03:08:56] <Niko-La>  [<-LINK->] 
[2017-02-28 03:09:14] <Niko-La> EXPOSE 22 8545 8000  is in my dockerfile
[2017-02-28 03:09:43] <Niko-La> i am getting portainer to show up on [<-LINK->] 
[2017-02-28 03:11:09] <Niko-La> when i do      docker run -p 8000:8000 -it embark-container
[2017-02-28 03:12:40] <Niko-La>  [<-LINK->] 
[2017-02-28 03:46:02] <killerspaz> and for sure it's running on 8000 inside the container?
[2017-02-28 03:48:23] <killerspaz> sorry, maybe i misunderstand your point. As per your question earlier, you should be using whatever daemon you're attached to viadocker-machine
[2017-02-28 03:56:34] <Niko-La> maybe there is another way to get access to the index.html file.COPY embark_demo/ /usr/src/embark_demodocker run -v " xxxxxx " -it embark-container
[2017-02-28 03:57:50] <Niko-La> how do i run the container so the embark_demo folder is exposed in my laptop.Also would this work when my container is running the app.  Will I be able to open the index.html this way?
[2017-02-28 04:00:46] <comeUpWithItLater>  [<-LINK->] 
[2017-02-28 04:01:22] <comeUpWithItLater> what \'s  "Segmentation fault"  anyway?
[2017-02-28 04:04:35] <killerspaz> Niko-La: look up volumes
[2017-02-28 07:47:43] <Niko-La>  [<-LINK->] 
[2017-02-28 07:47:44] <Niko-La> nice managed to lick up the volumes. are the changes made to the container folder show up in the host folder in real time and vice-versa?
[2017-02-28 07:48:11] <Niko-La> looks like the container is properly networked
[2017-02-28 08:07:03] <Niko-La>  [<-LINK->] 
[2017-02-28 09:47:26] <matrixbot> lanyangyangHi
[2017-02-28 09:47:27] <matrixbot> lanyangyangIs there anyone uses a GUI manager for docker in Linux ?
[2017-02-28 10:40:29] <SISheogorath> langangyang: portainer is a nice GUI manager. Works on all platforms, for everything else I have to say no. I prefer the CLI anyways
[2017-02-28 11:27:37] <SISheogorath> Maybe take a look at rancher but notice that it's not pure docker anymore
[2017-02-28 11:40:41] <sumeshkanayi> I have been trying and found that you cant change the port forwarding /volume mounting etc once the container after it is created
[2017-02-28 11:40:50] <sumeshkanayi> is there a way we can achieve this?
[2017-02-28 12:57:42] <SISheogorath> In genereal: If you have a problem with restarting/recreating your containers the image or container is broken. Containers are there to be rebuild.In your special case: You can, but not without a very hacky solution. The hacky solution is using iptables to rewrite your ports
[2017-02-28 17:01:07] <intellix> trying to bring up some services and keep getting mkdir errors: [<-CODE->] 
[2017-02-28 17:03:42] <intellix> just reset to factory settings. Feel like I do that all the time :D
[2017-02-28 18:02:23] <racinmat> Hello, I tinkered with GUI applications in docker. I have some app for simulations and it just needs the GUI. when I want to run simulations in it.But this required for example X server running elsewhere in the time it runs.I want to deploy the simulations for example to AWS, and I just want to send the GUI to dev/null or omething like that. Is there any option to "mock" the GUI output in docker do the app in docker whinks it has GUI, but just runs without GUI in container in AWS or somewhere?
[2017-02-28 19:38:42] <dragon788> xvfb
[2017-02-28 19:38:50] <dragon788> is the older package for a virtual X server
[2017-02-28 19:38:55] <dragon788> there is a newer one that always slips my mind
[2017-02-28 19:40:05] <dragon788>  [<-LINK->] 
[2017-02-28 19:40:24] <dragon788> ahh, Xpra is the newer option, with XDummy that uses a dummy driver for the actual Xorg server
[2017-02-28 19:40:30] <dragon788> if you are using a headless install Xvfb may be easier
[2017-02-28 19:40:38] <dragon788> Xephyr is another option
[2017-02-28 20:04:15] <racinmat> dragon788: so I can have one image with GUI app for simulations and the other image with xvfb as the X server? The xvfb does the X server to which app can connect, but does not output anything? So it can happily run anywhere in the cloud, without any monitor and the GUI app does not notice? Neat, thanks!
[2017-02-28 20:04:57] <dragon788> you could either run the Xvfb in the same container with your app or run it as a separate "linked" container running the Xorg/Xvfb server
[2017-02-28 20:13:45] <racinmat> dragon788: this is exactly what I needed, thanks
[2017-03-01 12:08:17] <joshbedo> Hey everyone, is docker really cheaper than running an app on an instance? I keep seeing posts sayings its cheaper but nobody really explains why or how. I'm starting a new business and looking for a cost effective way to get it going.
[2017-03-01 12:19:06] <racinmat> I do not think using docker is cheaper for one app than running the app directly on machine. But if you want your app scalable, docker is cheaper than dedicated machine, because you pay only for what you actually use and with docker on properly configured cloud service is not the same problem as.with dedicated server where you pay for machine to be online during the peak but big part is completely unused big part of time when the load is not so big.
[2017-03-01 12:25:11] <gadget_mnky_twitter> I would like to think running docker is cheaper when you have multiple components in a given service
[2017-03-01 12:27:19] <joshbedo> The docker hardware for say Microsoft Azure or AWS isn't more expensive to run than a non-containerized app? excluding the registry cost of course.
[2017-03-01 12:28:25] <joshbedo> Just trying to make sure i don't get in over my head. I've used docker at larger corporations who have the funding i'm just wondering if it's a cost effective option for a startup.
[2017-03-01 12:29:58] <joshbedo> Oh sorry@racinmatmissed your message.. it's early here :D
[2017-03-01 12:33:05] <joshbedo> racinmat: yeah thats what i was kind of thinking. It pays off with higher amounts of traffic but on a new site with no traffic it probably won't.
[2017-03-01 12:46:00] <racinmat> yes. But the docker also has other advantages. It enables smoother deployment process and is almost necessary to continuous integration. In dockerized app, it is also easier to run it for new developer in team, because there is noo need to install db, interpreter and so on, just docker and download image. So it may lead to easier development and thus should lower some price of development. But this is ptobably  little bit another topic than you asked.
[2017-03-01 12:50:49] <joshbedo> racinmat: No thats great! I like thinking about different perspectives and trade-offs.
[2017-03-01 14:06:17] <joshbedo> What is a good way to handle authorization with docker?
[2017-03-01 14:19:39] <racinmat> joshbedo: which kind of authorization is in your mind?
[2017-03-01 14:46:10] <joshbedo> I was planning on using JWT Tokens i'm using Node.JS
[2017-03-01 15:15:13] <joshbedo> But i'm open to other suggestions i'm just curious on the best way to handle it.
[2017-03-01 18:16:31] <jdevillard> hello all! I'm using Docker on windows (beta 17) , using Linux Container, and I would like to configure my container to use a host proxy to be able to analyse traffic using fiddler on my host
[2017-03-01 18:16:38] <jdevillard> is anyone already done this?
[2017-03-01 20:01:07] <dragon788> I think maybe if you run with--net hostyou can do this, but I haven't tested that
[2017-03-01 20:01:14] <dragon788> jdevillard: ^^
[2017-03-01 20:53:26] <ioleo>  [<-CODE->] I've read many blog posts about diffrent techniques, but some of them are outdates and I'm confused (none of them worked so far for me, or maybe I made some mistakes).
[2017-03-01 20:53:44] <ioleo> Is there a good solution to this problem?
[2017-03-01 21:30:05] <dragon788> not sure if there is a good way other than having the containers chown or chmod it, or create a container with an attached volume that changes the permission and then simply use-volumes-frominstead of a separate named volume
[2017-03-01 21:41:40] <ioleo> dragon788: other than having the containers chown or chmod itlike this? [<-CODE->] 
[2017-03-01 21:41:58] <ioleo> or in entrypoint?
[2017-03-01 22:50:58] <dragon788> I've only really seen it done in the run or as part of a script that runs as the default entrypoint
[2017-03-01 23:24:42] <SISheogorath> chmod 777is something you should never do
[2017-03-02 02:00:40] <joshbedo> anyone have suggestions on handling authentication with docker using Node.JS?
[2017-03-02 02:37:26] <SISheogorath> What kind of authentification are you talking about? In general for you webapp it should stay as it is.
[2017-03-02 02:38:34] <SISheogorath> For authentification for thedocker.socksee [<-LINK->] 
[2017-03-02 04:45:57] <ely029> hey guys who is here using godaddy as a hosting site?
[2017-03-02 04:46:32] <ely029> Because I want to have a multiple domain site and can host it with database? what account should I get?
[2017-03-02 05:24:59] <MaksimKiselev> Hi guys I was tried run binary file in container, but cath strange error: [<-CODE->]  [<-CODE->] 
[2017-03-02 05:40:10] <thebuccaneersden> does drone 0.5 have a caching option for things like npm dependencies?
[2017-03-02 05:40:23] <thebuccaneersden> seems 0.4 has some documentation for this, but cant find it for 0.5
[2017-03-02 06:06:40] <MaksimKiselev> Issue was resolved, need i386 arch.
[2017-03-02 10:12:22] <renothing> recently. docker pull from china always failed in authorization, even I used registry mirror.  can't we change default registry ?
[2017-03-02 10:12:56] <tkant> hehe get out of china man!
[2017-03-02 10:13:36] <renothing> .................
[2017-03-02 12:06:06] <MaksimKiselev> how to add support to run i386 programs on amd64 containers?
[2017-03-02 12:24:57] <MaksimKiselev> ResolvedRUN dpkg --add-architecture i386 && apt-get update && apt-get install -y libc6:i386
[2017-03-02 16:56:59] <tulpn> Hi everyone, I am currently trying to setup docker-compose for local development with 2 services (just to get the understanding), I have a django app and nginx running. The nginx part is working fine. However,  the django project files are not getting into the container.  Thedocker-compose logscommand leaves me with a[Error 2] No such file or directoryMy docker-compose.yml looks as followed: [<-CODE->] 
[2017-03-02 17:00:18] <tulpn> I was going over " [<-LINK->] " to get an understanding for the volume configurations. I dont want to re-build and up/down the service once I have changed my project files. But I don\'t get how the named volume is working. Also, when I inspect the named volume via the docker command, there is no destination parameter.
[2017-03-02 18:57:39] <Niko-La>  [<-LINK->] 
[2017-03-02 18:58:02] <Niko-La> can anyone explain why i have two ubunut images with the same id?and also what are these images with no names on them :S
[2017-03-02 21:54:34] <soapoperator> Hello,I try to run a container with docker-compose (traefik). I notice i get some error in the log: [<-CODE->] I check lot of page and the only solution i found was to add my user to docker's group. I did it without solve the problem.It's the first time i face this case and other container work well.Any idea?
[2017-03-02 22:01:52] <soapoperator> In docker-compose.yml, they suggest to add : [<-CODE->] I notice to creat docker.sock as a folder... Maybe it is a interessting way to follow...
[2017-03-02 22:26:14] <SISheogorath> Niko-La: Because they have different tags, but are actually the same image. One for latest, the other for 16.04
[2017-03-02 22:32:21] <SISheogorath> soapoperator: it\'s"- /var/run/docker.sock:/var/run/docker.sock"not"- ./var/run/docker.sock:/var/run/docker.sock"
[2017-03-02 22:33:42] <SISheogorath> tulpn: for named volumes use"- volumename:/path/inside/the/container"without the leading dot.
[2017-03-03 02:20:22] <Niko-La> '''docker run -it --device /dev/video0:/dev/video0 alpy bash'''
[2017-03-03 02:21:06] <Niko-La> is this how you enable the webcam on a docker. I installed debian jessie and added v4l-utils
[2017-03-03 03:16:54] <Niko-La> adding --privileged flag didnt help
[2017-03-03 06:30:39] <killerspaz> Niko-La: you do need privileged, and you need video-dev module probed
[2017-03-03 06:31:25] <killerspaz> and if using virtualbox you'll need to mount the webcam to the machine
[2017-03-03 06:48:24] <Niko-La> killerspaz: can you please expand on video-dev module requirement is this v4l?
[2017-03-03 06:53:48] <soapoperator> SISheogorath: thank you and sorry for the inattention. It works. Next step add basic authentification.
[2017-03-03 07:25:21] <ImanMh> Anyone knows how to fix 0 replicates?
[2017-03-03 07:25:24] <ImanMh>  [<-LINK->] 
[2017-03-03 07:26:04] <ImanMh> I accidently stopped manager and when I started it again replicates are 0
[2017-03-03 08:42:07] <comeUpWithItLater> I have the same problem.   I can't even start the vote app
[2017-03-03 11:33:38] <bigperson> I have the problem. Cannot share drive. Who knows how to share the console through? [<-LINK->] 
[2017-03-03 19:39:47] <verwilst> let's say i have an index.php i want to run in docker-compose. How would i do that? Create a datacontainer that has the index.php, then link a php-fpm and a httpd container to it?
[2017-03-03 20:05:26] <kschlesselmann> verwilst: Yeah, for example. Another approach would be to include the index.php in both containers.
[2017-03-03 20:07:13] <verwilst> kschlesselmann: with a shared volume you mean?
[2017-03-03 20:07:30] <verwilst> or create a custom httpd and php container for each project?
[2017-03-03 20:07:42] <verwilst> that will get you A LOT of containers though :-)
[2017-03-03 20:08:04] <kschlesselmann> verwilst: I'm not sure what you're going to do but basically yeah: Pack your app in containers.
[2017-03-03 20:08:42] <verwilst> just want to get it right conceptually
[2017-03-03 20:08:54] <verwilst> and what if i put the code on a shared volume on the host?
[2017-03-03 20:09:32] <verwilst> or volumes_from ?
[2017-03-03 20:09:32] <kschlesselmann> That's fine too. I did that with an app here as well. IMHO just a little more complicated though
[2017-03-03 20:10:59] <kschlesselmann> You should play around a little and find out what works best for you. I'd advise to automate the build process though.
[2017-03-03 21:03:46] <sbbowers__twitter> Is it possible to use docker's COPY command to glob/wildcard through directories and copy preserving the directory path?
[2017-03-03 23:01:46] <tulpn> Hey guys, I have been using docker-compose to build up a service which runs fine. Its there to serve me in development with a MySQL (official), Nginx (alpine official) and a web (our custom) service. We work with django and have a medium sized app. However, during development the requests become super slow. Its almost like the system has to wakeup first. Does anyone have an idea what might cause this? Lets say, when I test something on the website everything is fine,  then I leave the window and  read something for 2 minutes. When I then go back and refresh the page, that is served from my docker, it takes like 20 seconds until I see something happening. I develop on windows 10 pro with hyper-v, i76900k, 64gb ram -> allocated 4cpu/4gb in the docker settings (also confirmed in hyperv)
[2017-03-03 23:49:21] <sawhney_ankur_twitter> Hey,a simple question. I intend to create a docker file to install Oracle jdk8 but everytime I keep failing at trying to install the webupd8 ppa for java silently. Any ideas ?
[2017-03-04 01:10:53] <SISheogorath> tulpn: Maybe check the the RAM usage and swapping of your system. I'm not sure how well HyperV works with high RAM usage and I/O for MySQL. There are many reasons why it works like it works right now :/
[2017-03-04 01:12:46] <SISheogorath> sawhney_ankur_twitter: what base image are you using?
[2017-03-04 01:59:47] <sawhney_ankur_twitter> ubuntu
[2017-03-04 02:04:58] <sawhney_ankur_twitter> SISheogorath: ubuntu. I googled. I was asked to manually type the docker file in case some unseen characters were causing problems. Didn't change anyhing
[2017-03-04 02:45:37] <SISheogorath> Can you share the error message?
[2017-03-04 02:53:57] <sawhney_ankur_twitter> SISheogorath: I will type the exact error in a few hours...4sure. Thanx for helping. Hwever, in short, the error said that webup8 repo for java not found. One user suggested I install shared-common pack before this in which case I started getting the error that that pack wasn't found. None of these statements give error when I execute them manually on same machine. They ask for password. Kindly note here that the user already has admin privileges and I am generally able to execute all sudoku commands without adding 'sudo' from dockerfile
[2017-03-04 03:28:15] <SISheogorath> I tried to reproduce the issue and think I found the problem. It's the fact that the installer needs a confirmation to process. This can't work with docker build.
[2017-03-04 03:28:49] <SISheogorath> Maybe search for a better way to install Oracle Java
[2017-03-04 05:37:59] <sawhney_ankur_twitter> SISheogorath: thanx a lot . I went ahead with openjdk
[2017-03-04 13:27:02] <johnmcbride> Hi everyone, I'm trying to create a private registry with the registry Container from [<-LINK->] but when I try to interact with the API in the container I always get 404s. Does this container come with the API or am I doing something wrong. Any help would be appreciated.
[2017-03-04 17:51:44] <tulpn> Is there a best practice guide on how to organise a private AWS docker repository ? Does it make sense to store both dev and prod containers ? Should they be in different repos ? Or should the version tag be different, for instance with a -dev appended? There should be a online test env and a prod env, in both cases though the env should define a bool DEBUG flag. However, when developing locally should the same repos be used / referenced ? I am a bit confused in that regards - my end goal would be to COPY the source code into a docker container for a webapp and not use git or anything like that. in addition the source code directory needs to be shared between the containers.
[2017-03-04 18:50:27] <cristim> Recently I started to create an ECR repo per app environment, and I am using a Terraform custom resource to tag and push the Docker image to the current environment's ECR prior to rolling it our to the ECS cluster
[2017-03-04 18:51:16] <cristim> the ECS cluster is in a dedicated stack and is used by multiple apps
[2017-03-04 18:54:27] <cristim> the image is identical everywhere, and has the same name and tag, it is just tagged to contain the ECR URL
[2017-03-04 18:58:21] <zawarski>  [<-LINK->] 
[2017-03-04 18:58:22] <zawarski>  [<-LINK->] 
[2017-03-05 00:48:53] <matrixbot> YvesWith swarms, docker stats outputs identical values for.Containerand.Name. Is there a way to truncate the latter to display only chars up to a specific character? I would like to truncateselenium_chrome.1.b8jdwzntnikmr0xelgjpt63kitoselenium_chrome
[2017-03-05 08:03:21] <matrixbot> AlgramDocker is creating tons of btrsf subvolumes: [<-LINK->] How can I clean those up?
[2017-03-05 08:27:24] <cristim> I think that's how the btrfs storage driver works, you can only get rid of those if you delete all your images and containers
[2017-03-05 08:27:51] <matrixbot> AlgramBut I only have like 10 images and hundreds of volumes
[2017-03-05 08:27:57] <matrixbot> Algramit seems old ones just don't get deleted
[2017-03-05 08:28:20] <cristim> your images may have multiple layers, each layer gets a subvolume
[2017-03-05 08:28:58] <matrixbot> Algramis there a way to delete all volumes that dont refer to a currently running container?
[2017-03-05 08:33:06] <cristim>  [<-LINK->] 
[2017-03-05 13:55:10] <SISheogorath> tulpn: I personally wouldn\'t store all dev images in the private registry. Registry tend to use a lot of storage fastly depending on your images it can escalate quickly. Everything you deploy to test environments should already be "stable" as you want to use the same image in production. It should also build by a CI. So use an optimized Dockerfile for this. For development on local machine I would recommend you to use an build-cache optimized image which has small Delta and allows you to rebuild your image very fast, but don\'t share them. Keep your code tested with unit and integration tests. In general you should store your images in the same repo, as they are the same software (or would you use another git repository for your dev version? O.o) you can tag them as-devsuffix as it is useful togrepfor those versions. Also I\'m not sure why you need multiple containers of the same codebase. Easiest way is prepare a base image for your code/binaries and then a new image with this base to have your special versions. This way you don\'t have the need to copy your sources multiple times. In general just as hint of you want to serve static content from another container: use a HTTP cache (nginx/varnish) instead of an own container for those files. (Reason: you don\'t have to keep track of both containers/services to be in sync)
[2017-03-05 20:37:32] <tulpn> SISheogorath: thanks for your detailed answer! I will need to think and fully understand it, before I can practically do that. But its a good starting point
[2017-03-05 20:53:07] <SISheogorath> jaksky: what kind of stream are you talking about? Docker logs? Network?
[2017-03-05 20:56:41] <SISheogorath> tulpn: I hope so :D I should write a lot more blog entries to answer all those things :D
[2017-03-06 05:32:58] <ely029> hey guys
[2017-03-06 05:33:12] <ely029> how can I connect the dockerized mssql server to our network?
[2017-03-06 05:34:17] <ely029> I want to connect my dockerized mssql server to the network for easily to connect the mssql server management studio that are installed in our laptop thanks :)
[2017-03-06 05:38:28] <ely029> this is my docker-compose.yml code [<-CODE->] 
[2017-03-06 05:49:13] <ely029>  [<-CODE->] 
[2017-03-06 15:08:31] <johnmcbride> HI all -  I'm trying to create a private registry with the registry Container from [<-LINK->] but when I try to interact with the API in the container I always get 404s. Does this container come with the API or am I doing something wrong. Is there something specific you would have to enable to make sure the API endpoints are available? Any help would be appreciated.
[2017-03-06 15:29:25] <marcelmfs> Anyone here using overlay/overlay2 in production?
[2017-03-06 22:20:17] <killerspaz> johnmcbride: can you elaborate on your approach? I haven't had many issues other than actually UNDERSTANDING the api, very much requires research
[2017-03-06 22:22:10] <killerspaz> ely029: you need to map ports to your daemon host for routing to let you access it
[2017-03-06 23:09:58] <killerspaz> Anyone utilizing ccache for cross-build object caching? Thinking of doing some shared volume for ccache integration without increasing the image layer size
[2017-03-06 23:20:22] <cristim> guilty as charged :)
[2017-03-06 23:20:41] <cristim> with shared volume as well, works like a charm for 2 years now
[2017-03-07 00:00:54] <killerspaz> nice, think i might try that soon on my jenkins server.... tons of wasted time recompiling the same crap
[2017-03-07 00:23:52] <johnmcbride> killerspaz: I think it was a user issue, after digger deeper into the API i think I have a better understanding. Once found and called the /v2/_catalogs it returned the valid data :)
[2017-03-07 02:03:19] <comeUpWithItLater> Hi ,
[2017-03-07 02:05:42] <comeUpWithItLater> only 2 video tutorials on [<-LINK->] ?
[2017-03-07 02:06:29] <comeUpWithItLater> where  to find the rest?  they looks great
[2017-03-07 11:04:26] <intellix> possible to pass in args to a build? example: [<-CODE->] 
[2017-03-07 11:05:18] <tudvari-nng> intellix: you can set environment variables via a -e args
[2017-03-07 11:07:38] <intellix> seems not during build (at least for Docker 1.13). Will need to create a runtime script that accepts args I suppose to do a block of things
[2017-03-07 11:09:24] <tudvari-nng> in build time, it is not relevant, you can define in run time and also use it..
[2017-03-07 13:26:51] <itknight> ultra noob
[2017-03-07 13:26:52] <itknight> comes
[2017-03-07 13:27:52] <itknight>  [<-LINK->] 
[2017-03-07 13:29:00] <itknight> i'am wonderin' if i wanna create a container ,should i use
[2017-03-07 13:29:01] <itknight>  [<-CODE->] 
[2017-03-07 13:29:15] <itknight> all the time ? so many params
[2017-03-07 14:05:26] <killerspaz> intellix: you want build args for build time variables
[2017-03-07 14:51:04] <intellix> ah, the build args worked :) thanks
[2017-03-07 16:17:03] <Shalsh23> Hello, I am trying to install bigchaindb using docker on Mac OS. The backend database rethinkdb is installing correctly, and even the bigchaindb is installed correctly in the container, but the problem is that bigchaindb is not able to connect to rethinkdb becasue the ip address 172.17.0.1 being used to connect is different for Macs as Macs do networking differently..or so I was told by the Bigchaindb folks -I am getting the error:docker: Error response from daemon: driver failed programming external connectivity on endpoint rethinkdb (a19c0eaae3f27661c3ee736baa7a5b653794181a4433fadf55f14ad826d7819b): Error starting userland proxy: listen tcp 172.17.0.1:58080: bind: cannot assign requested address.And they pointed me to this urlhttps://github.com/docker/docker/issues/22753to solve the error. But I am fairly new to docker and I can't really make sense of the comments on this site. I would appreciate it if someone can help me figure out how to resolve this error.
[2017-03-07 18:51:23] <brianveltman> Is there anyone who got opensshd working inside a Windows container? I’m stuck with this for about a week now. Authentication with password works fine, but it throws a permission denied when using public keys.
[2017-03-07 19:46:14] <killerspaz> you stored the private key on the internal container?
[2017-03-07 19:46:30] <killerspaz> and permissions are set right on.ssh/*?
[2017-03-07 19:46:54] <killerspaz> Permission info: [<-LINK->] 
[2017-03-07 19:50:32] <brianveltman> killerspaz: Yes. Although windows does not handle permissions the same way Unix does.
[2017-03-07 19:54:39] <killerspaz> inside the container it's linux, your dockerfile should do some permission changes on it if you're building in windows
[2017-03-07 19:55:20] <killerspaz> i assume you're copying something during the build? like the key(s)?
[2017-03-07 20:21:24] <brianveltman> killerspaz: The docker engine runs on Windows server 2016, during the build I copy the public key of the docker engine and sshd_config to the container.
[2017-03-07 20:22:06] <brianveltman> With Linux it all works fine. Seems like i’m missing something on Windows. Not a Windows user at all 
[2017-03-08 00:51:06] <rcjsuen> Correct to say thatHEALTHCHECK NONEwill disable health checks from the base image as well as the base image's base image and so on and so forth? AllHEALTHCHECKinstructions in the chain will be disabled, correct?
[2017-03-08 05:17:00] <SISheogorath> Only the lastHEALTHCHECKstatement is used. So if you define one in your image the one from the base image is obsolete
[2017-03-08 05:17:13] <SISheogorath> rcjsuen: ^
[2017-03-08 05:32:34] <killerspaz> brianveltman: right, i'm suggesting that the copy is copying with 777 or 755, i forget what the windows default is... and the user is probably the right user, but since permissions aren't right, it won't work... I would do some chmod's in your dockerfile to set them on build... i haven't done that on hyper-v but i have on virtualbox with boot2linux
[2017-03-08 05:35:34] <killerspaz> quick quetion for the room... docs ( [<-LINK->] ) sayIf the path /webapp already exists inside the container’s image, the /src/webapp mount overlays but does not remove the pre-existing content... however when i attach a volume, the files go away... not exactly what I expect in "overlay" of a mount.... anyone done something like this?
[2017-03-08 05:37:21] <killerspaz>  [<-CODE->] 
[2017-03-08 05:44:22] <killerspaz> Hmm.. seems as if docs are just poorly worded: [<-ISSUE->] 
[2017-03-08 06:50:50] <soapoperator> Hello, anybody use traefik as proxy?I try to use a custom configuration with traefik.toml... But the file seems to be skipped. It's not a permission issue. Any idea?My docker-compose file: [<-CODE->] 
[2017-03-08 06:52:40] <soapoperator> Where can i find the log? I can't connect into the container with bash...
[2017-03-08 07:56:01] <SISheogorath> soapoperator: if/bin/bashis not working try/bin/shbut in general I'm sure Traefik doesn't ignore the config file. Also I would suggest you to kill the config file and place everything as parameter using thecommandstatement. Anyways the log is placed where it is placed by any good containerized application in thestdoutIf you miss something higher the log level. All this is also available in the Traefik documentations.
[2017-03-08 07:56:31] <SISheogorath> Last but not least I see no reason to label the Traefik container itself
[2017-03-08 10:21:52] <rcjsuen> SISheogorath: Thank you for your explanation!
[2017-03-08 10:26:52] <raj_adroit_twitter> Hello, am new to docker and this group.. I just need to know, what is the use of volume in the following code, i see its working without volume also..`version: '2'services:  db:    image: postgres:9.6.2    ports: [<-CODE->] 
[2017-03-08 15:03:08] <killerspaz> just so you can back it up should you need to
[2017-03-08 16:53:27] <austinfrey> is it possible to attach a swarm service to the bridge network?
[2017-03-08 17:28:05] <vrancurel> Hello, what is the most used/popular/standard NFS volume driver ?
[2017-03-08 17:28:36] <matrixbot> YvesIs it possible to adjust the number of dockerd daemon on a Linux box? My server is tight in memory.
[2017-03-08 19:47:42] <toftware> I have installed Docker for windows. Do you have a good guide for how to bridge the windows host and linux host so they are linked and they can resolve from eachother?
[2017-03-09 00:05:58] <tulpn> Still learning docker, [<-LINK->] in the web service where do the volumes get mounted ? or are that the destinations ? if so what is the source ? the ./web folder ? In other words, does the ./web folder get mounted as /usr/src/app ? Why 2 times with /usr/src/app/static ? so that the nginx can access it as well ?
[2017-03-09 03:22:44] <SISheogorath> tulpn: that are unnamed volumes (bad habit of compose v1)
[2017-03-09 05:16:19] <soapoperator> SISheogorath: Thank you for your answer. It put me on the right way. I finaly notice,  either we use command and flags or we use traefix.toml. But both don't work together...
[2017-03-09 05:50:48] <soapoperator> finaly incomand, it doesn't find the flagweb.auth.basic.users. So the solution .toml could be more robust.
[2017-03-09 14:02:19] <tulpn> When working with docker on windows, I am not able to delete files that were created during the runtime of a container. For instance, I am using Django, and the py files become compiled pyc files. Some of them cannot be deleted, unless I restart the computer. Has anyone run into the problem and how can I solve that in more developer friendly way ?
[2017-03-09 14:26:55] <LoiKos> Hi, I'm new to docker community and I have an issue with Kitematic, I want to install it but I wish I could do it without the docker toolbox because I work with docker Mac native app. Is there a way to achieve that ?
[2017-03-09 14:42:32] <saifulhoque26> Hi All,
[2017-03-09 14:44:26] <saifulhoque26> Is it possible to map node\'s device (usbport ) to a service?Similar to "docker create --device=/dev/ttyACM0:/dev/ttyACM0".I am starting on a specific node, using --constraint.Greetings.In reference I could not find.
[2017-03-09 14:56:06] <BretFisher> LoiKos: yes, do you use brew? two ways, either click in DforMac menu bar and click Kitematic and it'll download a zip, or you canbrew cask install kitematic
[2017-03-09 15:02:51] <BretFisher> saifulhoque26: if you're talking about swarm, I don't think so yet, see [<-ISSUE->] but if you're doing justdocker runthen sure
[2017-03-09 15:03:26] <LoiKos> BretFisher: thank for your answer... I use Brew but I didn't know cask for brew it look amazing. Do you think I should reinstall docker Mac app with brew too ?
[2017-03-09 15:03:41] <BretFisher> naw
[2017-03-09 15:03:52] <BretFisher> cask is just a easy way to install .app's the first time
[2017-03-09 15:03:57] <BretFisher> but the app themselves has to update
[2017-03-09 15:04:03] <BretFisher> there is no brew cask update, etc
[2017-03-09 15:04:56] <BretFisher> but i do put a bunch ofbrew cask installs in mymacbuild.shfor when i get a new machine.  have dozens of open source .app that it installs
[2017-03-09 15:08:32] <LoiKos> ok nice too bad for update maybe it will be coming ... yeah easier way when u have plenty to install
[2017-03-09 15:30:14] <gonzalomedinacl_twitter> /notify-all Hi ! :)
[2017-03-09 15:30:24] <savotagge> gonzalomedinacl_twitter: Hi <3
[2017-03-09 15:31:20] <gonzalomedinacl_twitter> savotagge: 
[2017-03-09 15:36:17] <racinmat> Hi, I am using docker to run many linux-only programs, and not for developing web apps.Therefore, I got stuck many times because the canonical ubuntu image, from which are most docker images, is minimal, does not have vim, nano, file, software-properties-common, and many, many other libraries.I know the main use of docker is for web apps where you ust have git, web server, interpreter and that is mainly everything and you do not need anything else.But for my purpose, everytime I try to run some software, I got stuck for many hours because of some missing library (because the program simply does not say it is missing library, it simply crashes).This is very tiring, and I would like to avoid it in the future.So I am asking here, is there any docker image with ubuntu with libraries more close to classicla desktop ubuntu rather than minimal image used mostly in docker?
[2017-03-09 16:12:57] <jMonsinjon> racinmat: I don't think so...
[2017-03-09 16:13:11] <jMonsinjon> Maybe you should make yours
[2017-03-09 16:14:04] <jMonsinjon> And every time you find a missing package, you install it in your base image for the next time
[2017-03-09 17:09:52] <saifulhoque26> BretFisher: I was talking about swarm. While creating a service. Your answer is exactly what I was asking. Thanks. I am checking the issue.
[2017-03-09 21:15:18] <killerspaz> Anyone run into this problem? (Can't connect via hostname) [<-ISSUE->] Works fine on Docker 1.13 on Linux/Windows, but won't resolve the hostname with dockerize on RancherOS. Feels really strange.
[2017-03-09 21:46:20] <dlwhitehurst> Can someone recommend an architecture where I have a Spring-Boot/Angular WAR (Tomcat embedded) where I can economically host each WAR with a 1GB VM? E.g. I know that it will run on a t2.micro with MariaDB but I'm looking to do automated hosting and deployment. I'm here because I think Docker might be my solution.
[2017-03-09 21:58:06] <rbuckland> Docker will work for you@dlwhitehurst. But bear in mind .. Everything about your resource footprint is entirely in your Java app. Docker is a control group around processes that run on the host
[2017-03-09 22:15:09] <dlwhitehurst> rbuckland: I can define the resource needs for my web app with tools that are already built in, mem, heap, stack, JVM stuff. And, since I do everything but create the database schema now, I need to consider the database requirements and probably build a database instance (server) to be scalable. I don't think the individual web apps will need to scale because the user count (obtaining sessions) will be low. I'm trying to offer a private hosting per client (unique URL) economically. And, I'm an application architect but the cloud infrastructure consideration is new to me.
[2017-03-09 23:27:38] <smashingx1> I ran the Garbage Collector for Docker registry and it's sowhing me this: 12530 blobs marked, 0 blobs eligible for deletion
[2017-03-09 23:27:57] <smashingx1> but it's not deleting any image, any ideas why this might be happening?
[2017-03-09 23:32:29] <killerspaz> it will never delete them, currently GC only removes from db
[2017-03-09 23:55:41] <smashingx1> killerspaz: so how can I get back hard drive space?
[2017-03-09 23:56:29] <smashingx1> killerspaz: I was getting out of space errors every time I wanted to build a new image. So I need to get space back
[2017-03-10 02:13:04] <killerspaz> i usually go manually delete it after gc
[2017-03-10 02:13:18] <killerspaz> then rebuild anything i want back
[2017-03-10 02:13:24] <killerspaz> docker is kinda messy still
[2017-03-10 03:57:52] <killerspaz> sorry, i meant to say private registry is, not necessarily docker itself
[2017-03-10 06:11:54] <anargund> does anyone know any good link i could use for debugging docker image through intellij? I am running few microservices using vert.x in the docker....
[2017-03-10 07:54:24] <ely029> Hey guys when I ping 192.168.1.1 inside the docker it can connect, but when I connecting my yii server not connected?
[2017-03-10 10:19:13] <ely029> hey guys I have a question again
[2017-03-10 10:20:32] <ely029> I read some of the videos about docker network. It seems I learned a lot of things. there is one thing that I cannot get. How can I change the subnet of a driver to connect to the network of my docker image?
[2017-03-10 14:19:39] <iDVB> Anyone have issues with getting AWS to pull from private DockerHub registry? (Err:  CannotPullContainerError) This is a piece of our Dockerrun.aws.json (works with ECR and fails when I change to DockerHub)… [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2017-03-10 14:20:24] <iDVB> googled and tried random things for about two days now
[2017-03-10 14:41:41] <iDVB> sigh….. worst docs ever...
[2017-03-10 14:42:17] <iDVB> Elastic Beanstalk currently requires the older ~/.dockercfg format configuration file. To convert a config.json file, remove the outer auths key and flatten the JSON document to match the old format.
[2017-03-10 15:14:37] <ancashoria> hi, I'm using Docker Community Edition for mac. How can I find the ip of the docker machine?
[2017-03-10 15:15:00] <ancashoria> docker-machine -ip=>Error getting IP address: Host is not running
[2017-03-10 15:15:51] <ancashoria> I'm trying to connect a nodejs container to a mongodb container andlocalhost:32768is not working
[2017-03-10 17:20:57] <smashingx1> killerspaz: you say you delete what after gc?
[2017-03-10 17:24:03] <killerspaz> the blobs for the specific image
[2017-03-10 17:24:21] <smashingx1> yes but the one that actually deletes the blows is the GC
[2017-03-10 17:24:33] <smashingx1> you can only soft delete the blobs
[2017-03-10 17:24:36] <pabloocastro> ancashoria: Is your docker daemon running?
[2017-03-10 17:25:11] <killerspaz> You didn't read what I said.... I said AFTER a GC, i manually delete the blobs.
[2017-03-10 17:25:26] <killerspaz> rmis mostly permanent, not soft.
[2017-03-10 17:26:34] <smashingx1> yes I did read it but I'm confused about what you are saying because the one that actually deletes the blobs is the GC
[2017-03-10 17:27:33] <smashingx1> or just to understand what you do to clean up your registry is: you soft delete the images, then run the GC and then you delete the blobs with rm? Am I missing something?
[2017-03-10 17:37:33] <killerspaz> sometimes i get lazy and just delete the entire image and say screw it, then GC
[2017-03-10 17:37:41] <killerspaz> then rebuild whatever tags i want
[2017-03-10 17:38:11] <killerspaz> i'm not suggesting i have the best workflow for that :P just more a comment on how sloppy docker registry is atm
[2017-03-10 17:38:42] <killerspaz> only pain is the one image that takes over an hour to compile :/
[2017-03-10 17:39:22] <smashingx1> yes, I understand you. At this point I don't know what to do. There's no documentation about the problem I'm having. It's really bad because we need this server running again, and I can't find information anywhere :(
[2017-03-10 17:51:24] <anargund> does anyone know any good link i could use for debugging docker image through intellij? I am running few microservices using vert.x in the docker....
[2017-03-10 18:01:18] <killerspaz> vforsythe: what is your env like... is the registry hosted on the same physical volume as your build system?
[2017-03-10 18:01:28] <killerspaz> for us it is.... so we prune and delete frequently
[2017-03-10 18:07:04] <ancashoria> pabloocastro: it's running, the mongo container is accessible through robomongo
[2017-03-10 18:37:43] <smashingx1> killerspaz: the registry is in a docker container
[2017-03-10 19:02:43] <soapoperator> Hello, any idea to add basic authetification to an app running with the docker image php:7.1-apache? To i have to pass it  through dockerfile or is it possible with label or command?
[2017-03-10 20:01:11] <pabloocastro> ancashoria: Have you exposed the container on this port?
[2017-03-10 20:07:39] <SISheogorath> soapoperator: I used a simple container in front of it. If you use Traefik you can simply use it to do this.  Otherwise there is the possibility to use one of those nginx images which are laying around on docker hub and provide basic auth
[2017-03-10 20:12:19] <soapoperator> SISheogorath: Thank you for your answer. I start to use traefik. As far as i know, traefik give some auth basic opportunity for the backend or entrypoint but not for frontend? And i run multi container which are exposed on port 80.
[2017-03-10 20:55:06] <bitsofinfo> I would like to create a docker service and scale it to 3 instances. These 3 instances form a cluster, and each one of the containers needs one of its arguments to have a unique valuedocker run  -e "UNIQUE_ID=[something unique]"  myimageHow can I do this w/ swarm services?
[2017-03-10 20:59:57] <killerspaz> vforsythe: but how do images get into it, is it built in another container on that system or just pushed by a dev? I ask, because there may be layers in your daemon that could be pruned as well. I typically clear up anywhere between 30-100GB/day on our build system
[2017-03-10 21:51:32] <toftware> There aren't any sort of Dedupe?
[2017-03-10 22:22:21] <SISheogorath> soapoperator: maybe check [<-LINK->] 
[2017-03-10 22:24:26] <SISheogorath> bitsofinfo: possibly you should try to use go templates. Not sure if it's possible for environment variables. I should read the sources related to this later. If you can edit the container maybe simply use the hostname
[2017-03-10 22:49:25] <bitsofinfo> hmm so this, how can I have swarm service create seed a unique value for a placeholder? Seems like there should be some sort of ability to do this kind of thing no? Problem is this is not docker run, so i have no access to the actual invocation that starts the containerdocker service create --replicas 3 --name myapp -e "UNIQUE_ID=[uniqueVal]" myimage -myarg1 [uniqueVal]
[2017-03-11 05:46:57] <Maruthi1302> Hi
[2017-03-11 05:47:51] <Maruthi1302> Hi i have pulled an new postgres on the already exisiting one and when i tired to start the new postgerss docker deamon is giving error.
[2017-03-11 05:48:05] <Maruthi1302> Error response from daemon: Cannot start container postgres: Error getting container 798e21ab095019d7128722da98610b142387b564164c49e21ea023c5b536bad7 from driver aufs: error creating aufs mount to /var/lib/docker/aufs/mnt/798e21ab095019d7128722da98610b142387b564164c49e21ea023c5b536bad7: invalid argument
[2017-03-11 05:48:20] <Maruthi1302> can any one help me with this
[2017-03-11 05:48:22] <Maruthi1302> ?
[2017-03-11 07:50:29] <khanhnguyenneka> Hi everyone
[2017-03-11 07:51:11] <khanhnguyenneka> I just built docker image and after that I ran docker run <image_name> but it raise/bin/sh: 1: source: not found
[2017-03-11 07:51:28] <khanhnguyenneka> how to I fix this issue ? Many thanks
[2017-03-11 10:01:39] <thedrint> Hi everyone.Does anyone know, why docker-compose show error "Container ... is not started"?
[2017-03-11 10:03:26] <thedrint> It show error for data-only containers, other started as expected
[2017-03-11 12:52:27] <jeserkin> Hello.
[2017-03-11 12:52:59] <jeserkin> Is it possible to transfer existing VirtualBox vms under Docker (Windows)?
[2017-03-11 17:23:52] <lenovouser> Hello. I have a root with 128 IPv4 addresses. Now when I do any network related requests to the internet it always comes from the main IP of the root. Is there a possibility of making these addresses available to the container so that I can send from them? While still enabling other containers to send from them too? Like it does with the main IP
[2017-03-12 02:35:16] <mateomorrison> Anyone to help me on [<-ISSUE->] 
[2017-03-12 11:31:55] <Shuliyey> do you mean docker automated build?@mateomorrison
[2017-03-12 14:39:40] <soapoperator>  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2017-03-12 15:03:51] <soapoperator> Finally, i solve the isue by changing the user foruser nginx;I am not sure, it's a good practice but it works!
[2017-03-12 15:42:27] <mateomorrison> Shuliyey: Yes
[2017-03-12 17:32:25] <pavel-sindelka> Hi guys, Im new in Docker and have a question... I have project with Docker file, I donedocker build .and how to run the image now please?
[2017-03-12 17:45:13] <jeserkin> pavel-sindelka: docker run image_name
[2017-03-12 17:52:59] <ioleo> docker build . -t mytag
[2017-03-12 17:53:24] <ioleo> Then docker run -it mytag
[2017-03-12 17:54:32] <ioleo> Where mytag can take form imageName:tag
[2017-03-12 17:54:55] <ioleo> Or repository/imageName:tag
[2017-03-12 18:01:10] <pavel-sindelka> jeserkin: @loostroI did it but where it running?
[2017-03-12 18:01:10] <jeserkin> What he said :)
[2017-03-12 18:01:37] <jeserkin> You can connect to running imagedocker exec -it container_name bashfor example
[2017-03-12 18:02:17] <jeserkin> You can see containers likedocker ps
[2017-03-12 18:02:25] <jeserkin> If I'm not mistaken
[2017-03-12 18:03:08] <ioleo> jeserkin: you're not :)
[2017-03-12 18:04:22] <jeserkin> loostro: you know if it is possible to open VirtualBox vm's under Docker?
[2017-03-12 18:04:41] <jeserkin> Or on windows it is only Hyper-V for Docker?
[2017-03-12 18:17:28] <pavel-sindelka> jeserkin: OK I will do: 1. docker build 2. docker run 3. docker exec -it container_name bash
[2017-03-12 18:20:22] <ioleo> It is
[2017-03-12 18:21:19] <ioleo> But im opening docker in virtualbox vm :) so the other way
[2017-03-12 18:22:21] <ioleo> I recommend a xubuntu vm for development under Windows
[2017-03-12 18:22:51] <jeserkin> pavel-sindelka: docker exec is only for accessing yout containers console
[2017-03-12 18:23:56] <jeserkin> loostro: darn. I have some time ago installed VB and now have few VMs there.
[2017-03-12 18:24:10] <jeserkin> Okay. Thanks. Will try to find alternatives and move over.
[2017-03-12 18:28:52] <jeserkin> What was confusing to me though. Was the fact, that I had large number of semi-images (if it is a right term). When I ran build.
[2017-03-12 18:29:54] <mateomorrison> jeserkin: Container name or ID?
[2017-03-12 18:30:19] <pavel-sindelka>  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] What is wrong? :/
[2017-03-12 18:37:28] <jeserkin> mateomorrison: I think it is or/or
[2017-03-12 18:37:40] <mateomorrison> or/or is?
[2017-03-12 18:44:09] <jeserkin> either container name or id
[2017-03-12 18:44:34] <jeserkin> Just read help. Dodocker exec -h
[2017-03-12 18:46:48] <matrixbot> YvesI am having problem with dns-search not taken into account and Docker version 17.03.0-ce, build 60ccb22. Can anyone confirm it is working elsewhere?
[2017-03-12 18:47:01] <jeserkin> loostro: still a bit not used to create vm for each project with docker :D Kinda all in one man :D
[2017-03-12 18:47:20] <matrixbot> Yvesposted an image:
[2017-03-12 18:50:46] <pavel-sindelka>  [<-CODE->]  [<-CODE->] How to visit in browser?
[2017-03-12 18:59:57] <pavel-sindelka> Some ideas? :/
[2017-03-12 19:08:34] <ioleo> jeserkin: I'm not creating a VM for each project
[2017-03-12 19:09:58] <ioleo> I've got 4 VM's right now, 2 of them are backups :)
[2017-03-12 19:10:56] <ioleo> One VM is for my general development (it's where I keep InteliJ and all my projects) <-- this is where I run docker images
[2017-03-12 19:11:34] <ioleo> Another VM is for workshops - I don't want to pollute my regular working environment with all the libs I have to install during workshops
[2017-03-12 19:15:01] <ioleo> So, in general, I recommend Linux for development. You can do it on Windows... but why suffer? :D
[2017-03-12 20:06:55] <pavel-sindelka> Please help :/ How to visit docker container in browser? [<-CODE->] 
[2017-03-12 20:07:35] <matrixbot> AlgramPavel indelka (Gitter): That container does not expose any port so you can't visit the webserver it provides in the browser
[2017-03-12 20:14:22] <pavel-sindelka> matrixbot: ok how to do? :D
[2017-03-12 21:14:21] <jeserkin> loostro: I know that development is easier on Unix, but all programs and so on take less time to install setup and find in general on windows. My personal experience.
[2017-03-12 21:15:29] <mateomorrison> How to runmeteor addon a Docker container. (or) How can I access a Docker container (not machine) and run commands
[2017-03-12 21:16:45] <mateomorrison> Other question is... I've updated some files in the folder, how to upload it or update it to my container?
[2017-03-12 21:16:52] <mateomorrison> Thanks!
[2017-03-12 21:22:30] <SISheogorath> mateomorrison: as far as I know running meteor in docker is not recommended if you want to do that maybe check how rocket.chat does it. Anyways, to run commands inside a running container usedocker exec <containerid> <command>
[2017-03-12 21:25:55] <mateomorrison> What do I put on <command>?@SISheogorath
[2017-03-12 21:34:40] <SISheogorath> The command you want to execute in your case I guessmeteor add
[2017-03-12 21:36:01] <SISheogorath> If you want a shell rundocker exec -it <containerid> /bin/shorbashinstead ofshdepends on your base image
[2017-03-12 21:41:00] <mateomorrison> Not working 
[2017-03-12 21:41:02] <mateomorrison> SISheogorath: 
[2017-03-12 21:41:03] <mateomorrison>  [<-LINK->] 
[2017-03-12 22:03:21] <SISheogorath> Your apparmor is against you :D
[2017-03-12 22:04:05] <SISheogorath> Not sure about the rules that are applied to you container.
[2017-03-12 22:04:38] <mateomorrison> Does this fix it: [<-LINK->] 
[2017-03-12 22:04:40] <mateomorrison> ?
[2017-03-12 22:06:13] <Shuliyey> have you tried this@mateomorrison [<-LINK->] 
[2017-03-13 02:51:04] <ely029> hey guys is that better to use docker-compose.yml instead of just running the docker images?
[2017-03-13 07:09:52] <ely029> how can I create a docker network with a specific sub net?
[2017-03-13 07:10:16] <ely029> I want to create a docker network with a subnet of 192.168.1.1
[2017-03-13 07:11:29] <matrixbot> YvesThis should do in your docker-compose file: [<-CODE->] 
[2017-03-13 07:13:09] <ely029> I dont need to configure the docker network?
[2017-03-13 07:13:42] <ely029> matrixbot: 
[2017-03-13 07:13:56] <fanux> docker network create --helpUsage:    docker network create [OPTIONS] NETWORKCreate a networkOptions:      --attachable             Enable manual container attachment      --aux-address map        Auxiliary IPv4 or IPv6 addresses used by Network driver (default map[])  -d, --driver string          Driver to manage the Network (default "bridge")      --gateway stringSlice    IPv4 or IPv6 Gateway for the master subnet
[2017-03-13 07:14:38] <fanux> create a network with --gateway option I think
[2017-03-13 07:15:31] <matrixbot> Yvesely029 (Gitter): Yes you do. Point you images to that network and docker-compose will make it. Or do it manually like ^^^
[2017-03-13 07:17:32] <fanux> docker network create --subnet 192.168.1.0/24 test
[2017-03-13 07:17:42] <ely029> okay I will come back and lets see what is those
[2017-03-13 07:17:51] <ely029> thanks@fanuxand@matrixbot
[2017-03-13 11:19:19] <CertainLach> Hello, how to install docker on CentOS running on RPI3? I am usedcurl -SsL https://get.docker.com | sudo sh, but this command does't work: [<-CODE->] 
[2017-03-13 11:40:26] <vyscond> Any particular reason we are not using sparse images format instead of the qcow2 on Docker for Mac?
[2017-03-13 11:52:17] <SISheogorath> Creeplays: not sure if there is an arm image for CentOS. In this case docker would possibly not work. There is a channel full of arm specialists in docker Community. Feel free to join: [<-LINK->] and checkout #arm
[2017-03-13 11:53:52] <jaksky> Which user is used to run docker container when USER is not specified in dockerfile?
[2017-03-13 12:06:19] <SISheogorath> root
[2017-03-13 12:24:03] <jaksky>  [<-CODE->]  [<-CODE->] Do I really need to specify full repository path?
[2017-03-13 12:24:33] <jaksky> Isn't possible somehow to set it as default?
[2017-03-13 12:24:52] <jaksky> No need to specify path before ...
[2017-03-13 15:18:17] <killerspaz> jaksky: yes it is required. Maybe you could set up an CNAME transfer on your name server
[2017-03-13 16:35:24] <joeyciechanowicz> I was wondering if anyone could quickly tell me if running a VPN inside of docker isolates the VPN? So could one use docker to run one process through a vpn?
[2017-03-13 16:37:19] <killerspaz> You'll need to expose any ports necessary to connect to the VPN to the host, then yes you will be essentially jailed inside the container.
[2017-03-13 16:37:37] <joeyciechanowicz> fantastic, thanks!
[2017-03-13 16:38:00] <killerspaz> otherwise if you choose net=host, you'll be essentially tunneling TO the host
[2017-03-13 16:38:51] <killerspaz> we use hamachi atm, and net=host to gain access to remote deploys
[2017-03-13 16:38:59] <killerspaz> but will eventually be using a websocket and reverse ssh
[2017-03-13 16:55:41] <CertainLach> SISheogorath: , this link doesn't work. Anyway, i am compiled docker and everything is now ok. Thanks.
[2017-03-13 17:01:22] <SISheogorath> Oh yes >.> I'm wonderung why in general it should work Have to check why it doesn't. Check [<-LINK->] instead should be redirect there anyways :D
[2017-03-13 19:45:36] <JnMik> Hello peps! We had a weird issue with Docker swarm this afternoon.We deploy containers using the stack yml file, and we currently don't specify networks in yml, so by having it empty, swarm creates one with a name like stack_name_default and use it.Today, we ended up with a container having it's IP address assigned in the same subnetwork as the docker nodes, and the container lost all connectivity with external services. From inside the container, I was able to ping the other replicas, but wasn't able to curl google.ca or other external services. I tried dropping the service & stack and relaunch it but seems swarm was already redeploying it with the same non-working subnetwork.So I dropped the stack, create an overlay network that I forced to another IP subnetwork, and then re-launched the stack using that pre-created network.It's working for now.Anyone had this issue before, is that a known behavior ? Should we always create network overlay at first, for production servers ?
[2017-03-13 20:00:08] <SISheogorath> Are your servers all in the same subnet or on different subnets than the swarm managers?
[2017-03-13 20:00:55] <SISheogorath> JnMik: ^
[2017-03-13 20:06:45] <JnMik> Yes they are in the same subnet
[2017-03-13 20:06:53] <JnMik> SISheogorath: 
[2017-03-13 20:08:13] <SISheogorath> mhm because in general docker does a lookup to the hosts routing table. (iirc) You should definitely open an issue for this on github
[2017-03-13 20:11:08] <JnMik> Ok I'll do that. Are you aware if there is a daemon parameter to specify a custom subnet for the overlay networks creation ?
[2017-03-13 20:12:48] <JnMik> Should I create the issue on docker/libnetwork ?
[2017-03-13 20:28:32] <matrixbot> YvesHi. I\'m trying to remove thendots:0option in/etc/resolv.confusing docker-compose. Any suggestion? I also triedDOCKER_OPTS="--dns-opt=ndots:15"in/etc/default/dockerwithout success.
[2017-03-14 19:11:00] <tudvari-nng> hi guys, Can I ask a short question please? It is possible to create a encrypted data folder inside a docker container? (it would also good for me, if the host has this encrpyted folder and it is possible to attach it into the container)
[2017-03-14 19:49:03] <allx2> hi guys, i've started with dockers but i'm little confused, where can i  a manual?
[2017-03-14 20:10:28] <jspadafore202> you can a manual here: [<-LINK->] 
[2017-03-14 22:18:44] <smashingx1> I created a service with no error in swarm but I get replicas 0/1
[2017-03-14 22:18:45] <smashingx1>  [<-LINK->] 
[2017-03-14 22:18:57] <smashingx1> Do you know how can I debug the problem?
[2017-03-15 07:39:52] <vkrot> Hello guys,I wanted to ask - is it okay for docker swarm to restart ALL containers in a cluster after leader reelection? I had a leader dropped by network split, and after reelection (which took 20min!) all running containers get restarted. Is it an expected behaviour?
[2017-03-15 09:19:20] <foreversunyao_twitter> vkrot: 20 mins is not a normal phenomenon，container restarted may be caused by this abnormal, any error log or other information ?
[2017-03-15 10:27:13] <SISheogorath> vkrot: on what side of the netsplit the containers got restarted?
[2017-03-15 10:30:29] <SISheogorath> tudvari-nng: simply encrypt the directory before you share it with your container. Like you would do without docker
[2017-03-15 12:41:42] <DevOpsEvents> [ Анонс ]Привет! Приглашаем на мастер-класс.  Тема: KUBERNETES FOR DEVOPS .Дата: 08.04.17 (СУББОТА) С 10:00 ДО 18:00  ( Киев. Украина )Подробнее здесь: [<-LINK->] 
[2017-03-15 12:47:17] <karolykass> In case you missed this: [<-LINK->] 
[2017-03-15 13:30:24] <aios> DevOpsEvents: офигели вы в принципе уже.
[2017-03-15 13:30:29] <aios> DevOpsEvents: пишите на английском
[2017-03-15 13:30:56] <aios> i am so sorry for that two messages
[2017-03-15 13:54:14] <DevOpsEvents> ok sorry
[2017-03-15 15:11:14] <vkrot> foreversunyao_twitter: , I have logs for journalctl. They tried to elect a new leader for long time, reported network disconnectivity all the time. And all containers got restarted, on both sides on split, but only after new leader was elected. I saw something similar before also, but didn't dig into details that time
[2017-03-15 17:36:18] <mtcaddy> Hallo
[2017-03-15 17:37:40] <mtcaddy> I have installed HAProxy localy on my root server.  I have certoboot in docker. I have not managed to get Jira (docker) to run behind haproxy + ssl. Any advise or link you might give me for future study?
[2017-03-15 18:08:31] <wcgcoder> mtcaddy: For both JIRA and Confluence, you'll need to set the tomcat connector in ${INSTALL_DIR}/conf/server.xml to have the right proxy name, port, scheme and set secure to true. There are many Atlassian resources with details on this like [<-LINK->] 
[2017-03-15 18:24:12] <mcarpenterjr> Hey, anyone happen to have a link to a good resource, or know how to make data persistent for a mysql container? I would like to setup an environment where i could fire up a mysql instance and have it load some "development" tables and data. Load might not be the right word in this instance. As of right now I\'m creating a mysql container and then creating some tables and importing data to them. What I envisioned however was being able to create the mysql container and a have a data structure created when the container was created or have the container load an external data structure. I can\'t seem to figureout how to do either.
[2017-03-15 18:25:22] <caveman-dick> mcarpenterjr: does the data need to be reset each time?
[2017-03-15 18:46:44] <mcarpenterjr> caveman-dick: nope.
[2017-03-15 20:07:43] <MariusDiacu_twitter> Hi. Can anyone suggest me a light solution for a local docker environment? I have a coupe of containers managed by docker-compose. I use fixed exposed ports to access different services , but I would like some virtualhosts defined, so I don't have to access [<-LINK->] . I tried with reverse proxy, but I cannot make it work. Any idea?
[2017-03-15 20:08:37] <thisisthekap> MariusDiacu_twitter: Have a look at the reverse proxy configuration at [<-LINK->] 
[2017-03-15 20:09:39] <thisisthekap> MariusDiacu_twitter: Or use [<-LINK->] for a solution with even less configuration effort.
[2017-03-15 20:14:06] <MariusDiacu_twitter> thisisthekap: I tried jwilder/nginx-proxy but the network configuration used with compose v2 syntax is not working. Switching to v1 is not an option..
[2017-03-15 20:16:06] <thisisthekap> MariusDiacu_twitter: I will try jwilder/nginx-proxy in a few hours. I will inform you about my results.
[2017-03-15 20:35:39] <SISheogorath> MariusDiacu_twitter: also don't miss to checkout [<-LINK->] 
[2017-03-15 20:35:43] <SISheogorath> Traefik
[2017-03-15 20:35:50] <SISheogorath> O.o
[2017-03-15 20:36:14] <SISheogorath> Nice gitter... Kill my markdown
[2017-03-15 20:40:19] <SISheogorath> mcarpenterjr: best way to handle SQL data in docker (as far as my experience is) setup the schema on startup of your application. Also make the application aware of the fact that sometimes a database server disappears (for what ever reason) without crashing. In general docker is very good in preventing your setup to die. But sometimes it happens that the restart of a database container takes a little moment and in this case your application should not die. Instead send a useful error and try again.
[2017-03-15 20:42:12] <SISheogorath> In general to persist databases use simple volumes (local volumes of you need performance). A detailed guide about where to point that volumes you can find in the README of the official MySQL and mariadb
[2017-03-15 20:43:17] <SISheogorath> vkrot: how many managers do you have?
[2017-03-15 21:04:37] <vkrot> SISheogorath: 4 managers. You know, I've just figured I was wrong - only containers on one side of network split were restarted, the side that was left without leader. Sorry for disinformation.
[2017-03-15 21:06:32] <SISheogorath> In General it's a bad idea to use a  even number of managers. Because raft won't find the bigger part of the split
[2017-03-15 21:07:12] <MariusDiacu_twitter> SISheogorath: thanks, this is exactly what I need. I'll try it tomorrow 
[2017-03-15 21:07:41] <SISheogorath> vkrot: see [<-LINK->] 
[2017-03-15 21:08:20] <SISheogorath> That is what is used between managers so hopefully you understand why an odd number of manager nodes is important
[2017-03-15 21:19:37] <thisisthekap> SISheogorath: I didn’t know about [<-LINK->] , thanks for pointing out that possibility!
[2017-03-15 21:20:21] <SISheogorath> Traefik ist lovely :) hope you have as much fun with it as I have :D
[2017-03-15 21:22:44] <vkrot> SISheogorath: , thanks!
[2017-03-15 21:32:04] <JasonShin> hey guys
[2017-03-15 21:32:20] <JasonShin> Is it a good idea to use Docker as development environment like Vagrant?
[2017-03-15 21:35:08] <SISheogorath> JasonShin: it depends on what you want to write but in general, yes, docker can help here and do pretty awesome things
[2017-03-15 21:35:17] <JasonShin>  [<-LINK->] 
[2017-03-15 21:35:35] <JasonShin> I've wrote my docker-compose and dockerfile inside .docker folder for development
[2017-03-15 21:36:00] <JasonShin> SISheogorath: yeah right
[2017-03-15 21:37:15] <JasonShin> I guess in my docker-compose, if I want my development environment to be like Vagrant(ish) I would probably need to give it-itflags so when my contributors dodocker-compose upthey immediately go into the container bash
[2017-03-15 21:38:21] <JasonShin> SISheogorath: In docker, when dockerfile fails to build an image, is there a way to provision it again so it attempts to install again from where it failed?
[2017-03-15 21:38:46] <SISheogorath> Simply add layers
[2017-03-15 21:39:10] <SISheogorath> Docker will check changes and rerun from the layer where things changed
[2017-03-15 21:39:20] <SISheogorath> Maybe checkout [<-LINK->] 
[2017-03-15 21:40:28] <JasonShin> nice
[2017-03-15 21:41:33] <JasonShin> that's a pretty useful article, thanks.
[2017-03-15 21:43:27] <JasonShin>  [<-LINK->] BTW, I was actually asking what's the best way to provision docker build again from where it failed. For example yournpm install node-gypfailed (lost internet connection), is there a way to reboot the build fromnpm install node-gyp?
[2017-03-15 21:45:52] <SISheogorath> If you run it in an own layer docker will simply start from the layer before if you rundocker buildagain
[2017-03-15 21:47:04] <JasonShin> hmm right
[2017-03-15 21:47:30] <SISheogorath> So you maybe should add a dev version of your dockerfile and a production version of you Dockerfile (production version is what you build using CI dev image is the one you build locally
[2017-03-15 21:49:02] <JasonShin> right, thanks
[2017-03-15 21:49:22] <johnjackson17> Hi Everyone,   I wanted to know if I should have two docker hub accounts one for stage/prod and another account for developers for repos?  thanks!
[2017-03-15 21:50:34] <JasonShin> I think you can just manage your dockerfile in your version control system
[2017-03-15 21:50:39] <JasonShin> that's what I do at work
[2017-03-15 21:50:44] <JasonShin> and my project
[2017-03-15 21:53:30] <johnjackson17> JasonShin: the reason I ask this is because we have strict requirements from clients that repos need to be scanned all the time for any security vulnerabilities, and what I was thinking is having two account and have developers push to one account and then moved to another account for stage and production..
[2017-03-15 22:03:58] <JasonShin> are you using Docker Security Scanning atm?
[2017-03-15 22:13:06] <johnjackson17> JasonShin: We will in few weeks..
[2017-03-15 22:30:27] <JasonShin> johnjackson17: Hmm, not sure exactly how you want it to work but I feel like you can use just one account and separete prod, dev, staging images using tags
[2017-03-15 23:16:07] <SISheogorath> johnjackson17: why should developers push to any account? Build on docker hub and/or your registries should be build by a CI.
[2017-03-16 00:09:34] <mcarpenterjr> SISheogorath: Thanks, I'll keep that in mind.
[2017-03-16 00:28:00] <sameetn> johnjackson17: are you talking in terms of a promotion pipeline? That is possible, but you can do it withouyt multiple accounts. You can do this byt also having separate repositories in the accounts and then creating the teams for clients to controll access. THat way you can use the approach that@SISheogorathmentioned by using the CI to build your images and also to promote them after they are scanned successfully
[2017-03-16 01:24:33] <JasonShin> SISheogorath: @sameetnHey guys, I am wondering, how does Security Scanning works in CI pipelines? Doesn't it require you to build your images in Docker Cloud?
[2017-03-16 01:31:33] <SISheogorath> Not really. There are many ways to do security scans. Docker cloud offers one. (Yes a nice way to display) But in general you can for example check [<-LINK->] and run it as part of your CI workflow
[2017-03-16 01:34:59] <JasonShin> that's awesome
[2017-03-16 01:35:08] <JasonShin> I will store that in my google keep =)
[2017-03-16 01:37:31] <JasonShin> I like to have all these security checks, linting, etc in my CI pipeline as many as possible. I know it slows down the builds but it feels so satisfying
[2017-03-16 01:37:41] <SISheogorath> If you are a "link hunter" keep an eye on my link collection: [<-LINK->] 
[2017-03-16 01:39:33] <JasonShin> I likehttps://youtu.be/ArK70YZN3S8?t=27m28s. Thanks.
[2017-03-16 01:40:21] <SISheogorath> :D yes, lovely ^^
[2017-03-16 01:42:31] <smashingx1> Not sure what this error is about:  Error response from daemon: rpc error: code = 4 desc = context deadline exceeded
[2017-03-16 01:43:10] <smashingx1> when I executed sudo docker service create --replicas 1 --name helloworld alpine ping docker.com
[2017-03-16 01:43:24] <SISheogorath> how many managers does your swarm have?
[2017-03-16 01:44:43] <smashingx1> 1
[2017-03-16 01:45:15] <smashingx1> I'm pretty sure, but how can I see for sure?
[2017-03-16 01:45:27] <SISheogorath> docker node ls
[2017-03-16 01:48:16] <smashingx1> SISheogorath:  [<-LINK->] 
[2017-03-16 01:48:34] <smashingx1> I wonder why it says swarm-01 is down
[2017-03-16 01:49:03] <smashingx1> does that mean that it's not connected to it?
[2017-03-16 01:49:07] <SISheogorath> yes not really good is your firewall on all needed ports open?
[2017-03-16 01:49:26] <allx2> Hi guys , is there a maximum number of containers?
[2017-03-16 01:50:03] <smashingx1> SISheogorath: well it was connected before
[2017-03-16 01:50:16] <smashingx1> SISheogorath: can I just try to connect it again?
[2017-03-16 01:50:24] <SISheogorath> allx2: not as far as I know. but it depends on your setup. For sure the limits of your normal systems are the same for containers
[2017-03-16 01:50:54] <SISheogorath> vforsythe: yes. did you reboot the server or similar?
[2017-03-16 01:51:21] <smashingx1> SISheogorath: yes I did
[2017-03-16 01:51:35] <smashingx1> do I have to connect to it every time I reboot the server?
[2017-03-16 01:51:40] <smashingx1> or one of the nodes?
[2017-03-16 01:51:55] <SISheogorath> vforsythe: in this case simply check the firewall. I guess it came up when you restarted the node which prevents it from rejoin the swarm
[2017-03-16 01:56:50] <smashingx1> SISheogorath: I tried to join the node to the swarm again and I get this error: Error response from daemon: This node is already part of a swarm. Use "docker swarm leave" to leave this swarm and join another one.
[2017-03-16 01:57:01] <SISheogorath> yes, that's normal
[2017-03-16 01:57:10] <SISheogorath> as mentioned did you check the firewall?
[2017-03-16 01:58:09] <smashingx1> I flushed all the rules in iptables
[2017-03-16 01:58:14] <SISheogorath> See: [<-LINK->] 
[2017-03-16 01:58:16] <smashingx1> but how can I retry to connect it?
[2017-03-16 01:58:38] <SISheogorath> docker swarm reconnects itself as soon as it is possible
[2017-03-16 01:58:46] <SISheogorath> make also sure those ports are open on the manager
[2017-03-16 02:00:55] <smashingx1> ok
[2017-03-16 02:01:00] <smashingx1> I will try with nmap
[2017-03-16 02:10:22] <SISheogorath> are the ports open? if so and the docker node is still not up again restart the docker daemon on that node. If that really doesn't help. Usedocker swarm leaveand join again
[2017-03-16 02:20:12] <smashingx1> ok the manager is having some networking problems
[2017-03-16 02:20:38] <smashingx1> I'm thinking I will make the node that is working a manager and join another server
[2017-03-16 02:20:59] <smashingx1> do I have to leave the swarm to promote that server a manager?
[2017-03-16 02:35:58] <smashingx1> ok now they are connected
[2017-03-16 02:36:12] <smashingx1> the problem was indeed the network
[2017-03-16 02:37:14] <smashingx1> but the cryptic error keeps showing up
[2017-03-16 02:37:26] <smashingx1> Error response from daemon: rpc error: code = 4 desc = context deadline exceeded
[2017-03-16 02:53:03] <SISheogorath> what version of docker are you running?
[2017-03-16 02:57:14] <smashingx1> for some reason that error is gone
[2017-03-16 02:57:17] <smashingx1> thanks for the help
[2017-03-16 03:01:12] <SISheogorath> You're welcome
[2017-03-16 04:29:18] <khanhnguyenneka> Hi guys, I want to run two project with gunicorn in Docker
[2017-03-16 04:29:37] <khanhnguyenneka> ENTRYPOINT ["_env/bin/gunicorn"]\nRUN _env/bin/gunicorn car_element.app -b 0.0.0.0:5000 --reload --log-file=- &\nCMD ["intent_classifier.app", "-b", "0.0.0.0:8000", "--reload"]
[2017-03-16 04:29:41] <FrankYu> Hi, is there is kubernetes rooms?
[2017-03-16 04:29:54] <khanhnguyenneka> this is my command in Dockerfile
[2017-03-16 04:30:12] <khanhnguyenneka> but  it's run only the last command with gunicorn
[2017-03-16 04:30:43] <khanhnguyenneka> How do I need to do something to run multiple project with gunicorn in Docker ? Many thanks all
[2017-03-16 04:35:09] <JasonShin> khanhnguyenneka: can you format it little bit better?
[2017-03-16 04:39:51] <JasonShin> I have a question about dockerfile's caching feature.According to this video: https://www.youtube.com/watch?v=Soh2k8lCXCAIf there's a dockerfile like [<-CODE->]  [<-CODE->]  [<-CODE->] Would docker curl version 7 and run apt-get install -y nodejs again?
[2017-03-16 09:04:48] <vvsh_twitter> Hi, I posted an issue on github, but did not receive answer: [<-ISSUE->] , could you please help? Thanks
[2017-03-16 09:37:08] <argeas> hi All , anyone know why typing in the terminal ( after ive connected to the docker vm (ubuntu) ) is super laggy ?
[2017-03-16 09:37:22] <argeas> e.g . wana stop a container and it just hangs..
[2017-03-16 09:37:32] <argeas> have to ctrl c
[2017-03-16 09:38:06] <argeas> was using boot2docker... in the begining was ok .. swaped to ubuntu .. initially ok .. then started lagging also..
[2017-03-16 09:38:25] <argeas> will buy you ice creams? :)
[2017-03-16 12:52:49] <argeas> when i say laggin I mean that even typing in the terminal after connected via ssh
[2017-03-16 12:53:09] <argeas> e.g. docker stop command hangs..
[2017-03-16 12:53:12] <argeas> etc
[2017-03-16 13:33:20] <SISheogorath> FrankYu: check the k8s slack channel linked in their webpage
[2017-03-16 13:36:20] <SISheogorath> JasonShin: yes. Caching always go from top to down. Everything below the last  that did not changed anything will run again
[2017-03-16 14:15:27] <sbbowers__twitter> Is it possible to convert a docker container into a standalone binary? so something likedocker load <myimage.tgz>; docker run <myimage> <options>could be wound up into a distributable binary run-able likemybinary <options>
[2017-03-16 15:28:42] <shreram> Hi, newb here. Recently I installed Docker on Raspberry Pi using [<-LINK->] 
[2017-03-16 15:29:04] <zhouteng> Hi, a question for the "users" in portainer.io web interface, so how can I set up the users so that certain users can not see the containers they are allowed to see? It seems there is nothing you can set up for users there except that I can add users and change their passwords, thanks!
[2017-03-16 15:29:10] <shreram> I would like to install MySQL database in that Docker container. How do I that?
[2017-03-16 15:30:36] <zhouteng> sorry, I posted the wrong place, I thought it's portainer.io....
[2017-03-16 15:58:55] <sbbowers__twitter> shreram: Normally you don't want to install mysql in the container because 1) it won't persist between multiple image runs and 2) databases can have horrible performance if their files are inside the container.
[2017-03-16 16:00:27] <sbbowers__twitter> shreram: If this is just a local/development docker use, I normally just expose my local mysql database socket file by mounting it to the container directly.
[2017-03-16 16:02:57] <sbbowers__twitter> something likedocker run -v '/var/run/mysqld/mysqld.sock:/var/run/mysqld/mysqld.sock'works for me (on ubuntu 16.10)
[2017-03-16 16:06:51] <sbbowers__twitter> If you just want a mysql docker instance that your other service can link to, you can use this as a reference: [<-LINK->] 
[2017-03-16 18:04:52] <toftware> So i've heard that Windows containers does not support service discovery in Swarm, can any of you confirm that?
[2017-03-16 18:22:29] <shreram> sbbowers__twitter: Thank you. I installed Docker on Pi but wanted to use MySQL database on Docker instead of built-in SQLite
[2017-03-16 18:24:22] <sbbowers__twitter> ok. well you can use that link I gave you and then mount a volume into the container where you want the database files to be stored on the host system.
[2017-03-16 18:28:21] <shreram> \'\'\'pi@rpi3:~ $ docker run -v \'/var/run/mysqld/mysqld.sock:/var/run/mysqld/mysqld.sock\'"docker run" requires at least 1 argument(s).See \'docker run --help\'.Usage:  docker run [OPTIONS] IMAGE [COMMAND] [ARG...]\'\'\'
[2017-03-16 18:32:25] <shreram> I will check other documentation link for docker run command usage
[2017-03-16 19:44:33] <fholm> Hey! I'm super new to docker, and just looking for some advice if it's even applicable to my problem domain. Basically I am working on a large game server for a persistent world, where I wil have maybe 3-4 fairly big machines doing the world simulation in together using Project Orleans (microsoft virtual actors thingy)
[2017-03-16 19:44:52] <fholm> And all the documentation and videos I\'ve found on docker seem to talk about having small "micro services" and things like that.
[2017-03-16 19:46:15] <fholm> Would I benefit from using docker to deploy something like that?
[2017-03-16 19:47:21] <mattoni> fholm: at the end of the day, a container is just an isolated process.  If you are able to split up your application so that you have a stateless system to build the world from a central database or something, you could benefit greatly being able to scale without a second thought
[2017-03-16 19:47:59] <mattoni> not sure on your exact requirements
[2017-03-16 19:48:00] <fholm> mattoni: thanks, exactly the answer i was looking for pretty much, so (my understanding is somewhat correct of docker)
[2017-03-16 19:48:09] <fholm> mattoni: currently I am not either :)
[2017-03-16 19:48:15] <mattoni> lol
[2017-03-16 19:49:07] <mattoni> just a bit of a disclaimer, I'm the CTO of a company doing super simple docker container deployment (think digital ocean for containers) [<-LINK->] . If you need any advice or assistance send me a DM and I'd be happy to help when I get some time :)
[2017-03-16 19:50:35] <fholm> mattoni: thanks :) I'm not even sure I will end up using docker, but felt I needed to ask a few questions, a lot of the benefits seem to do with isolation of processes and lower overhead per applicaiton, etc.
[2017-03-16 19:50:58] <fholm> and most of those are non issues to me, because it is just one massive application sharded over several machines using orleans
[2017-03-16 19:51:18] <mattoni> Yeah, I'm obviously a bit biased since we're building a whole company around the concept, but I firmly believe any application can benefit from containerization
[2017-03-16 19:52:24] <fholm> Yeah for sure, I pretty much assumed people in here would be slightly biased :P
[2017-03-16 19:55:14] <SISheogorath> toftware: not sure about discovery but as the whole networking thing is more or less missing yes, sounds reasonable
[2017-03-16 19:56:01] <toftware> Yes that's my understanding at well
[2017-03-16 19:57:39] <SISheogorath> sbbowers__twitter: it depends a bit on how much load you create with your database containers. They can run without problem if you set them up correctly. Like using something like lvm-direct as volume driver and place it on SSDs. Works wonderful over here :)
[2017-03-16 19:59:38] <SISheogorath> shreram: not sure if the official mysql image runs on raspberry pi because raspberry is running arm. Maybe check for an arm image like the hyperiot guys provide
[2017-03-16 21:22:00] <rasouza> Hey a newbie question: does make sense to use docker on a single VPS to create more containers and host your apps? Isn't docker made for physical servers (with high amount of resources) so you have enough resources (CPU and RAM) to share between containers?
[2017-03-16 22:19:17] <SISheogorath> I use docker to increase the security and application isolation on my VPS so yes, it makes sense to use it there :)
[2017-03-16 22:40:08] <CarlosAmaral> hey got a question, im using Dokku and when deploying, I need to run a script that takes 3 inputs, how the syntax should be for the inputs? anyone got a clue?
[2017-03-16 22:41:04] <CarlosAmaral> as in “predeploy”: “node whatever.js user=kewl pass=lol"
[2017-03-17 00:09:53] <JasonShin> hi docker people
[2017-03-17 00:09:54] <JasonShin> =)
[2017-03-17 00:11:36] <aios> JasonShin: hi
[2017-03-17 00:39:34] <JasonShin> hey
[2017-03-17 05:58:48] <lox> I'm trying to figure out an issue with docker 1.13.1 in our CI service. I'm periodically seeingIntermittent ERROR: Couldn't connect to Docker daemon at http+docker://localunixsocket - is it running?after about 10-20 minutes of use. The logs I am seeing for this issue are at [<-LINK->] .
[2017-03-17 05:58:52] <lox> Anyone seen anything similar?
[2017-03-17 05:59:21] <wcgcoder> JasonShin: hey
[2017-03-17 06:00:25] <wcgcoder> lox: I haven't quite seen that error, but I've seen issues recreating a container where it says another.jsonfile can't be opened.
[2017-03-17 06:00:42] <lox> Yup seems like it's exactly the same as this: [<-LINK->] 
[2017-03-17 06:00:52] <lox> e.gstate.json: no such file or directoryand a hard hang.
[2017-03-17 06:01:20] <wcgcoder> Mine is something about atmp.____.jsonfile
[2017-03-17 06:02:24] <wcgcoder> Wow, is it really 17:00 in Melbourne? I'm still working in CA, US
[2017-03-17 06:03:18] <lox> 5pm, yup :)
[2017-03-17 06:03:35] <wcgcoder> It's 23h here
[2017-03-17 06:03:36] <lox> Ah-hah! [<-LINK->] 
[2017-03-17 06:04:17] <mattoni> haha, 11pm checkin in from Reno
[2017-03-17 06:04:39] <wcgcoder> Interesting that that bug has a host of RHEL 7 with non-loopback devicemapper
[2017-03-17 06:05:12] <wcgcoder> I hope I don't come across that problem; yet, I'm still having intermittent with the root device being busy on a similarly configured host
[2017-03-17 06:05:21] <wcgcoder> mattoni: Nice.
[2017-03-17 06:05:43] <wcgcoder> Anyone going to Dockercon?
[2017-03-17 06:05:47] <mattoni> yep!
[2017-03-17 06:06:00] <mattoni> bringing my dev team :)
[2017-03-17 06:06:50] <wcgcoder> mattoni: Awesome! I'd like to meet up with other devs in the thick of production and see what they're doing
[2017-03-17 06:07:14] <mattoni> Definitely! I love Austin, I have fam there so I'm super pumped for it this year
[2017-03-17 06:07:21] <wcgcoder> I'm nearly single handedly trying to guide development and ops. Hashtag devops /s
[2017-03-17 06:07:25] <mattoni> lol
[2017-03-17 06:07:38] <mattoni> well, we've launched our platform recently
[2017-03-17 06:07:42] <mattoni>  [<-LINK->] 
[2017-03-17 06:07:47] <mattoni> check it out some time :)
[2017-03-17 06:07:53] <mattoni> but we'll definitely be there.
[2017-03-17 06:08:54] <wcgcoder> Nice, some fontawesome in there
[2017-03-17 06:09:05] <mattoni> yeah, actually working on redoing the site right now
[2017-03-17 09:02:34] <DJQTDJ> is there anyone who knews html5I need some help
[2017-03-17 09:39:12] <vvsh_twitter> mattoni: , I have a question regarding cycle.io, do you have an internal docker registry where I can upload my images from my local machine or I have to create private one on hub.docker.com and upload there?
[2017-03-17 12:14:52] <Pritz_P_twitter> Hi guys, im having a problem successfully being able to curl from the docker container to itself.i have node express application within a container running on port 8080. I have used EXPOSE 80:8080 to allow me to send requests from my browser/postman/etc to node application. My application is posting to itself (within container) but i get connection refused…ive tried http://127.0.0.1/endpoint, http://127.0.0.1:8080/endpoint no avail.Doing docker inspect <containerId> | grep IPAddress = 172.18.0.2 so I tried http://172.18.0.2/endpoint, http://172.18.0.2:8080/endpoint also no avail.Anyone have any ideas?
[2017-03-17 12:34:37] <matrixbot> Rahulkrishnan(rark)Hi all, is there any way to  autoscale the container based on cpu usage
[2017-03-17 13:04:57] <danielitit> Pritz_P_twitter: Have you tried telnet 172.18.0.2 8080 ? Are you sure that appropriate service is running and listening on port 8080 in container?
[2017-03-17 13:06:28] <danielitit> Pritz_P_twitter: Maybe make dock exec -i -t $container bash
[2017-03-17 13:06:36] <danielitit> and type ss -lnt or netstat
[2017-03-17 13:06:45] <danielitit> and check if something is listening
[2017-03-17 13:11:50] <vvsh_twitter> mattoni: , also I see that you store raw images, not compreseed. e.g. [<-LINK->] weighs only 80 mb, but built image that I see on portal.cycle.io, is about 360 mb. Are you planning to store compressed images, if it is technically possible? Otherwise it might not be enough space you provide if for Tricycle account (e.g. on my notebook images for 3 projects weighs around 25 GB or even more).
[2017-03-17 13:22:21] <Pritz_P_twitter> danielitit: thanks for the reply - not sure how i resolved it - but i created a network. docker network create <mynetworkname>, docker network connect <mynetworkname> <containerID>
[2017-03-17 13:23:58] <Pritz_P_twitter> After inspecting container id, i noticed it created bunch of stuff including gateway ip. That seem to let me post to the gateway 172.0.0.1:8080/endpoint.
[2017-03-17 13:25:04] <Pritz_P_twitter> This was after lots of googling… Not great as i dont understand what docker network does.. more reading required…
[2017-03-17 13:25:58] <Pritz_P_twitter> appreciate the reply@danielitit
[2017-03-17 13:26:41] <danielitit> nice! congrats
[2017-03-17 17:22:53] <mattoni> vvsh_twitter: We’re waiting on the OCI Image spec to be finalized before releasing our registry. We want to be able to support all image types. As for compression, I’m going to be releasing an update this weekend that should significantly improve the size of stored images :) hope that helps! DM me if you have any more questions
[2017-03-17 17:45:14] <vvsh_twitter> mattoni: , thank you very much, I am going to try to run one of my projects on Cycle, but I have to wait until registry is available as I have my images only locally.
[2017-03-17 17:55:14] <dev-gbassanini> Hi all
[2017-03-17 17:55:39] <dev-gbassanini> I was hoping you guys could help me with an issue I'm having with a docker file
[2017-03-17 17:56:20] <dev-gbassanini> I get a file not found error
[2017-03-17 17:56:26] <dev-gbassanini> when building
[2017-03-17 17:56:31] <dev-gbassanini> the dockerfile
[2017-03-17 17:56:35] <dev-gbassanini> FROM eclipse/ubuntu_jdk8RUN sudo apt-get updateRUN sudo apt-get install nanoADD sqla1201_client_linux_x86x64.tar.gz /tmp/RUN cd /tmp/./client1201/RUN ./setup
[2017-03-17 17:58:29] <dev-gbassanini> I'm trying to install the tar.gz file (odbc driver) when building the image
[2017-03-17 17:59:49] <dev-gbassanini> I know docker creates an intermediate container everytime it successfully executes a RUN command
[2017-03-17 18:00:41] <dev-gbassanini> but I'm not sure how to make this work
[2017-03-17 18:54:58] <mwspitzer> Not sure what your exact error is. I'm assuming the tar.gz is in the Dockerfile directory. More than likely it's not finding setup. Instead of 'RUN cd /tmp/./client1201', try 'WORKDIR /tmp/client1201'.
[2017-03-17 19:24:26] <dev-gbassanini> txs
[2017-03-17 19:24:30] <dev-gbassanini> I'll give it a try
[2017-03-17 19:24:57] <dev-gbassanini> this is the exact error msg I got
[2017-03-17 19:25:00] <dev-gbassanini> Step 7/7 : RUN ./setup---> Running in 64622705e7fb/bin/sh: 1: ./setup: not foundThe command '/bin/sh -c ./setup' returned a non-zero code: 127
[2017-03-17 19:29:45] <dev-gbassanini> Great!
[2017-03-17 19:29:48] <dev-gbassanini> it worked
[2017-03-17 19:29:51] <dev-gbassanini> thanks
[2017-03-17 19:29:56] <dev-gbassanini> for your help
[2017-03-17 19:30:18] <dev-gbassanini> now I'm having an issue. It seems the setup requires some user input
[2017-03-17 19:30:49] <dev-gbassanini> how can I manage to setup the configuration during the build?
[2017-03-17 19:31:04] <dev-gbassanini> or maybe I'll just have to start the container in bash
[2017-03-17 19:31:23] <dev-gbassanini> and from that point install the required driver manually?
[2017-03-17 19:33:53] <mwspitzer> setup -silent -I_accept_the_license_agreement
[2017-03-17 20:29:54] <killerspaz> anyone here a RancherOS power user? Trying to do some manual networking and docker start/stop orchestration, and not getting the results i want. Basically for networking getting the error about not able to write over/etc/resolve.conf. I have a temp workaround for that, but when rancheros comes up it's starting all the containers, even though they're marked as create only. Stumped like woah.
[2017-03-17 22:37:51] <mattoni> vvsh_twitter: just an FYI, you can host on a private docker registry and Cycle will be able to connect to it
[2017-03-17 22:42:09] <vvsh_twitter> mattoni: , do you mean as a container?
[2017-03-17 22:42:36] <mattoni> well, if you’re hosting your own docker registry (could be hosted as a container) or if you’re using a private repo on docker hub, we have support for that
[2017-03-17 22:49:35] <vvsh_twitter> mattoni: , second option is quite expensive, as most of my projects are just for study, but they have up to 7 different images..
[2017-03-17 22:50:16] <mattoni> ah yeah, i understand. I haven’t done it personally, but I believe one of my devs is running a copy of docker registry on Cycle.
[2017-03-17 22:50:25] <mattoni> might be worth investigating :)
[2017-03-17 22:52:48] <vvsh_twitter> I run such on my notebook, so I think it should work. Thanks! What will be the price of your registry?
[2017-03-17 22:56:51] <mattoni> I believe when we implement it, it will be a tier feature.
[2017-03-17 22:57:01] <mattoni> so our billing is very simple
[2017-03-17 22:57:26] <mattoni> you have a tier for your account, which is what features/resources etc you want for your account
[2017-03-17 22:57:31] <mattoni> then you pay per container instance you deploy.
[2017-03-17 22:57:34] <mattoni> first tier is free
[2017-03-17 22:57:37] <mattoni> :)
[2017-03-17 22:57:45] <mattoni> not sure where we’ll land with the registry yet
[2017-03-17 23:00:04] <mattoni> another option
[2017-03-17 23:00:08] <mattoni> is that we support git integration
[2017-03-17 23:00:23] <mattoni> so if you have a docker file in your git repo (wherever it is located)
[2017-03-17 23:00:26] <mattoni> we’ll build the image for you
[2017-03-17 23:09:55] <vvsh_twitter> I have quite complex deployment:1) some images are built using maven, gradle and npm2) then I have docker-compose.yaml which builds some other complex images (where FROM is public one or image from step) and those final images are deployed
[2017-03-18 06:23:26] <JasonShin> hey guys, what is an alternative to docker for windows if you cannot install it on ur computer ? (I don't have windows professional)
[2017-03-18 06:23:43] <JasonShin> docker machine is great btw
[2017-03-18 07:33:08] <vvsh_twitter> JasonShin: , you can try to install Docker Toolbox.
[2017-03-18 17:32:22] <vito-c> Anyone know why the latest docker update messed up libcompose's registry authentication? [<-LINK->] 
[2017-03-18 17:32:51] <vito-c> I'm trying to figure out how to fix it
[2017-03-18 17:38:07] <vito-c> is there a way to have docker login generate the json file it used to?
[2017-03-18 17:58:39] <ryanberckmans> Is there a reason to install Docker for Mac "Docker.dmg" instead of brew install docker?
[2017-03-19 14:48:44] <SISheogorath> vito-c: check [<-LINK->] 
[2017-03-20 03:06:27] <fanux> I am run gogs:0.10.8 in container, using https, came out an error:Certificate type not approved for application. when git push -u origin masterI use the command to generate .pem:./gogs cert -ca=true -duration=8760h0m0s -host=10.1.86.51
[2017-03-20 03:48:13] <ghost~56fc9ded85d51f252abbbbad> hey guys good morning
[2017-03-20 05:44:12] <4406arthur> hi, for some reason, is’t possible let container keeping running but cannot enter it ?
[2017-03-20 09:30:55] <SISheogorath> 4406arthur: if you want to debug and the container keeps dieing usedocker run -it --rm --entrypoint /bin/bash <image is>
[2017-03-20 12:07:21] <richard-ball> How many servers do you need in order to justify the use of container clustering? Is it appropriate for two servers deployments for instance?
[2017-03-20 12:09:22] <toftware> Seems like somebody deleted their answer
[2017-03-20 12:22:44] <richard-ball> Are there any books that cover DevOps tools to use when and where etc?
[2017-03-20 13:02:09] <4406arthur> SISheogorath: , the context is .. dont let anyone to change container’s content and view, the only way to update container is update image, i have a poor solution.. just remove shell  in Dockerfile
[2017-03-20 13:41:22] <AnthonyWC> 4406arthur: you can just use unix account permission [<-LINK->] 
[2017-03-20 13:44:00] <SISheogorath> richard-ball: I wouldn't use 2 server (it's possible but a bad idea) 3 servers are the ideal minimum but from 3 to 1000 it's no problem. Reason why 3 and not 2 is raft
[2017-03-20 13:45:26] <SISheogorath> 4406arthur: o.o--read-only?
[2017-03-20 15:07:51] <IvanDmytrenko> Hello to everyone. Maybe someone could help me. I have dockerized my php project, but can't run it on docker-machine, it works on my localhost instead of 192.168.99.100. Env: Ubuntu 16.04.
[2017-03-20 16:01:39] <austinfrey> what does yourdocker runcommand look like and what kind of machine are you running it on?
[2017-03-20 16:08:24] <IvanDmytrenko> aafrey: I'm running the project with docker-compose, not with docker run. The project is accessible on docker machine (192.168.99.100:8082) on OS X by the docker-compose up --build -d but on Ubuntu it's accessible on localhost:8082 instead, seems that it runs natively on my Ubuntu layer, but not in docker machine
[2017-03-21 00:29:40] <cjus> Anyone successfully using--with-registry-authwithdocker service createwith a docker swarm on AWS.  Having trouble pulling a private container from our account on hub.docker.com
[2017-03-21 06:22:10] <parth22594> how to publish port with docker run using hostname?e.g. docker run -p ip:hostPort:containerPort its working.but,  docker run -p hostname:hostPort:containerPort its not working.
[2017-03-21 09:10:12] <DJQTDJ> During the interview did not understand the interviewer saidHow can I tell him to repeat it?
[2017-03-21 13:17:18] <marcusrios> If metadata is added after node creation, can this interfere?
[2017-03-21 19:23:38] <lnyousif> Anyone had issues of running images  on Windows vs Mac , I keep getting Windows build fail when adding files into /etc/my_init.d/  this issue explain it , and coker team (away from this link) are not answering [<-ISSUE->] 
[2017-03-22 08:59:24] <chrischambers> Hey guys! Quick query: what's the best way to handle a web app with an API backend and a heavy js frontend (Ember), particularly one that makes use of yarn? I'm creating separate docker files for the frontend and backend, although the frontend file doesn't actually have an entrypoint/command associated with it at the moment, it just fetches the node/bower bits and then builds out the relevant static assets
[2017-03-22 10:32:06] <elcolie> Does anyone know when thepostgres 9.5image start usingpostgresas a user notroot?
[2017-03-22 10:32:59] <elcolie> postgres_1      | /docker-entrypoint.sh: running /docker-entrypoint-initdb.d/prepare_db.sh\npostgres_1      | Could not create directory '/home/postgres/.ssh'.\npostgres_1      | Host key verification failed.\nException in thread Thread-3:I remember container always userootas  a default user in the system
[2017-03-22 16:27:02] <daniel-halito> Anyone knows how to insert a shell variable into a makefile?
[2017-03-22 17:34:22] <wcgcoder> DJQTDJ: @daniel-halitothis is a chat room about Docker
[2017-03-22 17:44:05] <killerspaz> elcolie: if only there was a way to review source history......................................... [<-LINK->] 
[2017-03-22 17:45:41] <killerspaz> chrischambers: you need to serve it. Can be a simple node http server, or use nginx to serve. I choose the node http server and use an nginx reverse proxy for all my containers
[2017-03-22 20:47:21] <wcgcoder> If anyone else here is a user of Rancher, I created a channel: [<-LINK->] 
[2017-03-22 22:16:37] <SISheogorath> parth22594: it's currently not possible. It also doesn't make a lot of sense as you have to bind ports to sockets. IP based sockets. So use the IPs. If you need to use hostname first resolve them to IP-Addresses
[2017-03-22 22:17:57] <SISheogorath> chrischambers: serve you webapp by an nginx container or use express to host ist and put a reverse proxy in front of it.
[2017-03-23 01:45:36] <vietdien2005> hello everyone
[2017-03-23 01:46:23] <vietdien2005> why i can't create bridge nerwork with docker-compose on MacOS Sierra
[2017-03-23 07:41:39] <ndaidong> hi everyone, how I can hide the first part "docker.io/" in images\' name while listing images with "docker image"
[2017-03-23 07:42:57] <ndaidong>  [<-LINK->] 
[2017-03-23 07:44:19] <ndaidong> I'm using fedora 25
[2017-03-23 07:45:06] <ndaidong> in the ubuntu based machines, it just displays repository name without "docker.io/" at first
[2017-03-23 07:48:31] <papaiatis> hi guys! is it possible to build a new image from a running docker container? so I mean with "docker run" I start a new container, perform the necessary steps by hand (install packages, config stuff, etc), then without creating a Dockerfile that does the same thing, just build an image from this running container?
[2017-03-23 07:51:22] <ndaidong> I think that you can tag it to another image
[2017-03-23 07:52:13] <ndaidong> ah, no, forget it, container is container
[2017-03-23 08:00:49] <papaiatis> I think "docker commit" is what I want
[2017-03-23 08:02:07] <sopanshewale> yes.@papaiatis, you should be using docker commit
[2017-03-23 08:02:09] <ndaidong> yes, thanks, a new thing for me
[2017-03-23 08:03:14] <sopanshewale> Example is:docker commit -m"updated perl modules" 2327e636355c sopanshewale/gdrive_php
[2017-03-23 08:03:49] <sopanshewale> here - "2327e636355c" is actually your running docker container instance\'s id
[2017-03-23 08:04:09] <sopanshewale> "sopanshewale/gdrive_php is my container tag/name .
[2017-03-23 09:09:30] <SISheogorath> I really suggest you not to do it, but it's your choice and possibly okay as long as you do it with a really special reason in mind.
[2017-03-23 09:12:00] <SISheogorath> ndaidong: that's normal. Fedora uses iirc the build for atomic which has own repositories. So it has to show you which repos you downloaded the images from. Docker.io is the docker hub registry
[2017-03-23 09:16:19] <ndaidong> thanks@SISheogorath,  can I hide it from screen for shorter and easier reference?
[2017-03-23 09:17:27] <ndaidong> now when I want to use "mongo" image, I have to type " [<-LINK->] " instead of just "mongo"
[2017-03-23 09:17:59] <ndaidong> the terminal's autocomplete feature does not work as normal
[2017-03-23 09:24:01] <SISheogorath> Not sure about that. As far as I can say and I use fedora myself I never had a problem with autocomplete .-.
[2017-03-23 09:25:56] <SISheogorath> But that's possibly based on the fact that I use zsh and the oh my zsh  docker extension
[2017-03-23 09:27:37] <papaiatis> can someone tell me how to expose the http port 80 from a container to the outside world when docker host is in virtualbox?
[2017-03-23 09:30:29] <SISheogorath> papaiatis: how would you do it without docker? If you found this way you can do it with docker, too. I guess there are a bunch of examples on StackOverflow
[2017-03-23 09:32:02] <papaiatis> with docker -p 80:80 I can expose the http port from container to host. But the port 80 on host still mapped to localhost, which is the virtualbox machine.
[2017-03-23 09:35:47] <papaiatis> okay, this is the solution: "docker -p <VBOXIP>:80:80 ...", where VBOXIP is the IP address of the vbox machine
[2017-03-23 09:36:11] <papaiatis> sadly, VBOXIP cannot be an FQDN...
[2017-03-23 09:55:12] <sopanshewale> papaiatis: - you can add entry in your /etc/hosts file
[2017-03-23 09:55:19] <sopanshewale> it can FQDN then
[2017-03-23 10:36:51] <ndaidong> thanks,@SISheogorathfor replying my question
[2017-03-23 10:41:09] <papaiatis> what does this expression mean? [::]:80
[2017-03-23 10:41:48] <papaiatis> is that the IPv6 version of a bound address?
[2017-03-23 10:42:03] <MonXBZH> There is a thing, which still listenning on the port 80 .. ?
[2017-03-23 10:42:47] <MonXBZH> Can you print here, ur prompt when you seen this pls ?
[2017-03-23 10:43:04] <MonXBZH> see*
[2017-03-23 10:43:42] <elcolie> killerspaz: Although I have no idea how to read it. Thank you anyway
[2017-03-23 11:42:29] <papaiatis> MonXBZH: I found that in an nginx config, and that's indeed means IPv6 binding
[2017-03-23 11:43:11] <papaiatis> another question: the "EXPOSE" command in a Dockerfile, what does it do exactly? If I have "EXPOSE 5000" is that mean I can get rid of the "-p 0.0.0.0:5000:5000" argument? Because it doesn\'t seem so
[2017-03-23 11:44:44] <elcolie> Help [<-LINK->] 
[2017-03-23 12:47:05] <MonXBZH> papaiatis: EXPOSE seems to be an specialy Dockerfile command. She is used to EXPOSE a port for link containers together. Not sure.
[2017-03-23 14:29:41] <killerspaz> elcolie: why can't you read it?
[2017-03-23 14:30:18] <killerspaz> papaiatis: no, it merely expresses intent to expose a port, it does nothing more.
[2017-03-23 14:30:43] <killerspaz> if only sharing ONE port, you are able to simply do-p localPortand leave off the container port map
[2017-03-23 14:30:50] <killerspaz> but that is ill-advised
[2017-03-23 16:23:50] <killerspaz> in the process of dockerizing a whooooole bunch of services, and have gotten a few core ones dockerized with nginx-proxy.. However the remaining services are manually deployed and served with a host-based nginx. Any suggestion on how to make them both co-exist while we transition?  I couldn't find a way for nginx-proxy to serve my projects, even when volume mounted to the same project location, and including the conf files for them in/etc/nginx/conf.dinside the image.
[2017-03-23 16:24:29] <killerspaz> i'm sure it's because ofpassenger, but i'm just not ready to build 10 more dockerfiles and debug them right now
[2017-03-23 19:42:14] <vito-c> anyone know how to compile a go application that uses the docker api inside a docker container? I keep getting gcc/linker errors
[2017-03-23 19:42:48] <killerspaz> sounds like you're missing libs of some sort
[2017-03-23 19:43:17] <killerspaz> but alas i have not
[2017-03-23 20:10:36] <vito-c> let me get you the errors
[2017-03-23 20:10:48] <vito-c>  [<-ISSUE->] 
[2017-03-23 20:10:55] <vito-c> it's having issues with cgo
[2017-03-23 20:41:40] <vito-c> how does one use the Dockerfile in the docker repo to run dind?
[2017-03-23 22:09:51] <wcgcoder> vito-c: You mean something like this?docker run --privileged --name some-docker -d docker:1.8-dind(from [<-LINK->] )
[2017-03-24 02:03:13] <fanux> I can't access to the docker rpm site `This XML file does not appear to have any style information associated with it. The document tree is shown below.<Error><Code>AccessDenied</Code><Message>Access Denied</Message><RequestId>5643F81B6A696E8C</RequestId><HostId>2QFn/05FXr55DMuYMUbOdaux1MlXmeyfagJsZnqZMGN6j00tMqZtHVfEUsW3tfHo6Rq4tgBu6j8=</HostId></Error>`    https://download.docker.com/linux/centos/7/x86_64/stable/Packages/     I want to download the offline docker1.13 rpm package
[2017-03-24 03:16:08] <dragon9783> Hi, all, Why docker event doesn't implement the function that watch image creat?
[2017-03-24 07:18:52] <MonXBZH> Hello there o/
[2017-03-24 07:19:17] <MonXBZH> ANyone can explain me what's the difference between the CMD and the RUN commands in a Dockerfile pls ? Thx !
[2017-03-24 07:43:09] <rcjsuen> AVOLUMEcan take a JSON string array.I tried usingVOLUME [ "/dataandVOLUME [ "/data"and the image built without any problems. Is this intended? lol
[2017-03-24 07:44:04] <rcjsuen> MonXBZH: Well, for starters, you can only have oneCMDin a Dockerfile.
[2017-03-24 07:45:47] <rcjsuen> RUNaffects the built image.CMDdoesn't.
[2017-03-24 09:56:50] <pro100filipp> Hello! I have a question about how to collect test results from image. I'm using Visual Studio Team Services for CI and my build process is so: push the code -> build test image -> collect test data -> build prod image -> push prod image to registry. When all tests have passed it's OK, but how can I obtain test data from docker image and at the same time stop further building when there are failed tests?
[2017-03-24 11:14:43] <SISheogorath> In general I wouldn't suggest you to run you test against another image than you want to use in production. (In speech of integration tests) unit tests etc can be built in a own test environment image if you need additional frameworks, packages and libraries for that. But the idea of container is to use the same image on as many platforms as possible so it's better to test your production image instead of testing a test image and build the production image after it.
[2017-03-24 12:00:29] <pro100filipp> SISheogorath: ok, I thought the same, but wanted to keep production image cleaner. However I will reconsider this) nonetheless the problem remains as I want to collect test results (e. g. XUnit.xml) from the image with failed tests. If I run tests with "RUN", an image won\'t be built. And if I run with "CMD" it will be in production with failed tests.
[2017-03-24 13:53:33] <earthquakesan> Hi everyone! Is there a doc with all event types somewhere?
[2017-03-24 13:53:52] <earthquakesan> Or there it is not achievable, because each event type is generated by different components
[2017-03-24 13:54:25] <earthquakesan> Can someone please point me to a code snippet for event emitting please?
[2017-03-24 13:56:11] <earthquakesan> I am interested in container events
[2017-03-24 13:58:23] <papaiatis> hi guys! how can I set a default value to a an Environment variable in Dockerfile? so lets say if BUILD_TARGET is not set, give it a default value of "development"
[2017-03-24 13:59:14] <earthquakesan> papaiatis: see example here [<-LINK->] 
[2017-03-24 14:00:06] <earthquakesan> Are there docs for the whole event system in docker-engine somewhere?
[2017-03-24 14:00:41] <papaiatis> so lets say I have this in Dockerfile: "ENV BUILD_TARGET development". What if I execute this: "docker run --env BUILD_TARGET=production ..." ? Will the BUILD_TARGET overwritten with the ENV command?
[2017-03-24 14:01:00] <earthquakesan> yes
[2017-03-24 14:01:23] <papaiatis> So that's not helping.
[2017-03-24 14:09:08] <papaiatis> also, it seems "docker build" doesn\'t accept the "env" argument
[2017-03-24 14:10:59] <papaiatis> I found the solution here: [<-LINK->] 
[2017-03-24 14:36:59] <jscheel> I have been experiencing a really frustrating issue for the past few months with docker. I have a boot2docker VM on vmware fusion 8, set up through docker-machine. I am on osx 10.11.6, and all of my docker tooling is up to date. When my computer goes to sleep, everything is fine. But, when it transitions from sleep to hibernate, I get a sleep wake failure, and my computer reboots. This happens, without fail, every single time I leave my docker machine running. If I shut it down beforehand, my computer is fine. I initially thought it might be related to this issue here: [<-ISSUE->] , but I’m not running docker for mac. Anyone else experiencing this issue?
[2017-03-24 16:40:56] <wcgcoder> jscheel: I reallyreallysuggest you migrate to Docker for Mac
[2017-03-24 16:41:42] <wcgcoder> Unless you're doing something very specific where you need to test and configure things using docker-machine
[2017-03-24 16:41:50] <jscheel> wcgcoder: polling causes super-high cpu usage on mac
[2017-03-24 16:41:54] <jscheel> was a non-starter
[2017-03-24 16:42:06] <jscheel> technically, I’m using dinghy to run everything
[2017-03-24 16:42:15] <jscheel>  [<-LINK->] 
[2017-03-24 16:42:23] <wcgcoder> What's using polling? For host mapped volumes?
[2017-03-24 16:43:39] <wcgcoder> Working with a mid-2015 MBP model here; gave Docker 4 CPUs and 6 GB. No problems with CPU usage at all (except when running java in a container, and that's just java).
[2017-03-24 16:46:37] <jscheel> it’s been a while since I last looked at it, but iirc, the issue was file access in mounted volumes was cpu bound
[2017-03-24 16:46:44] <jscheel> made things waaaaay too slow
[2017-03-24 16:47:15] <jscheel> this guy, iirc: [<-ISSUE->] 
[2017-03-24 16:47:51] <wcgcoder> I'm not feeling the pain right now; what's still slow is doing builds with large amounts of code or resources that needs to be copied in.
[2017-03-24 16:50:27] <wcgcoder> jscheel: are you mapping in code and other resources from your host for development purposes?
[2017-03-24 16:50:47] <jscheel> wcgcoder: yes
[2017-03-24 16:56:41] <wcgcoder> It's interesting. On my Mac, I don't have these disk IO problems, but maybe it's because I've provisioned half my CPUs to the VM. But my colleague on the other hand has some pretty awful Docker IO problems. I'll check in on his Docker 4 Mac settings.
[2017-03-24 17:33:24] <matrixbot> YvesI need to be able to set ndots and preventndots:0in container's resolv.conf using Linux Docker 17.03.0-ce. No matter what I try, I end up with something like:`\nnameserver 127.0.0.11\noptions ndots:15 ndots:
[2017-03-24 17:33:55] <matrixbot> Yvesnameserver 127.0.0.11\noptions ndots:15 ndots:0
[2017-03-24 17:34:13] <matrixbot> YvesAny suggestion?
[2017-03-24 19:20:27] <stanzacal_twitter> What are people's thoughts on smart calendar tools?
[2017-03-24 20:18:13] <chrismpalmer> Friends, I frequently get suggested that running  docker isn't as good as bare metal and I explain on Linux it should be. I understand that a vm is not used therefore it should be quite close. Does anyone have a link to empirical data. I guess I don't believe what I am being told but data is factual...
[2017-03-24 21:07:22] <FibbenacciB_twitter> Hello
[2017-03-24 22:00:44] <wcgcoder> chrismpalmer: Kind of crappy for people to be making incorrect claims and put the burden of proof on you for the defense.
[2017-03-24 22:02:17] <wcgcoder> chrismpalmer: you can get the Docker "evangelism" ebook for admins, here: [<-LINK->] 
[2017-03-24 23:07:13] <chrismpalmer> wcgcoder: thanks I'll check it out
[2017-03-25 12:20:26] <vyscond> Hey guys
[2017-03-25 12:20:30] <vyscond> what's uppp
[2017-03-25 12:21:02] <huiqiangyang> Hey guys
[2017-03-25 12:21:33] <maximl337> HAPPY saturday
[2017-03-25 12:22:14] <huiqiangyang> Happy !
[2017-03-25 12:22:23] <vyscond> great saturday
[2017-03-25 12:24:03] <vyscond> Dudes and dudettes. DevOps question here. Do you guys have a tutorial to make a docker server hosting various application under subdomains?
[2017-03-25 12:25:41] <huiqiangyang> private docker server?
[2017-03-25 12:25:55] <vyscond> Yeah.
[2017-03-25 12:26:07] <vyscond> Like a droplet on DigitalOcean
[2017-03-25 12:28:36] <huiqiangyang> About private docker server,I have a question
[2017-03-25 12:29:16] <huiqiangyang> My docker client push images to private server showThe push refers to a repository [tunnel.qydev.com:41176/alpine]\nGet https://tunnel.qydev.com:41176/v1/_ping: http: server gave HTTP response to HTTPS client
[2017-03-25 12:30:16] <huiqiangyang> And my docker client config file I addADD_REGISTRY='--insecure-registry tunnel.qydev.com:41176'
[2017-03-25 12:30:57] <huiqiangyang> Have some people tell me docker push images useHTTPorTCP?
[2017-03-25 12:32:08] <huiqiangyang> vyscond: 
[2017-03-25 12:54:36] <vyscond> huiqiangyang: not quite sure about that man :/
[2017-03-25 12:55:05] <vyscond> I can confirm that's not HTTP
[2017-03-25 13:05:19] <huiqiangyang> vyscond: Not http,but I addADD_REGISTRY='--insecure-registry tunnel.qydev.com:41176'
[2017-03-25 16:36:00] <MonXBZH> Hello there
[2017-03-25 16:36:16] <MonXBZH> ANyone can gimme the repo for Docker for ARM aupport (Raspberry PI)
[2017-03-25 16:36:18] <MonXBZH> ?
[2017-03-25 17:59:06] <JT-Bruch> anyone know how to restart a docker from inside?  I'm installing windows features some of which require a reboot... and I'm doing this on the docker build command... not sure of the best way to proceed
[2017-03-25 17:59:50] <JT-Bruch> actually... would /shutdown /t 10 work? (windows docker)
[2017-03-25 18:06:05] <dragon788> JT-Bruch: nano-server or server-core?
[2017-03-25 18:06:13] <JT-Bruch> server-core
[2017-03-25 18:06:39] <dragon788> if you doRestart-Computervia powershell it may work, seeman Restart-Computerfor additional arguments
[2017-03-25 18:07:09] <dragon788> nano-server doesn't have some of the non-PowerShell stuff so I stick with the most compatible which is usually using PowerShell
[2017-03-25 18:07:46] <JT-Bruch> actually thats exactly what I'm trying
[2017-03-25 18:09:08] <JT-Bruch> good timing! :D
[2017-03-25 18:09:20] <dragon788> did it work?
[2017-03-25 18:10:09] <dragon788> otherwise you might have to do something crazy like mapping in the docker socket/remote api uri and send the command to the container "from the inside"
[2017-03-25 18:10:57] <dragon788> MonXBZH: I believe there are a couple approaches to Docker for ARM, but you haven't found that installing from the Docker repository according to the directions works on the Raspberry Pi under Raspbian/etc?
[2017-03-25 19:52:03] <jeserkin> Hey
[2017-03-25 19:53:16] <jeserkin> Guys, is there a way to map exposed volume without loosing it content inside container?
[2017-03-25 20:41:59] <jeserkin> I see, that it is possible to add mappings relative to current directory with docker-compose, but I can find how areRUNcommands handled in docker-compose in comparison to Dockerfile.
[2017-03-26 00:38:19] <SISheogorath> There are noRUNcommand in compose. Compose is used to orchestrate local docker containers while the Dockerfile is there to build images
[2017-03-26 00:41:49] <SISheogorath> And when you mount a named volume to your directory the structure stays. If you mount a directory from your host it's always empty or contains the things you place into the location on your host. So you maybe run your container one and copy everything out or change the image to bootstrap the filestructure into you volume if it doesn't exist.
[2017-03-26 05:53:29] <k82cn> hello :).
[2017-03-26 11:21:08] <MonXBZH> Hello therte o/
[2017-03-26 11:21:26] <MonXBZH> ANyone know how to fake the system date in a container ?
[2017-03-26 11:33:20] <SISheogorath> What do you me by fake? Change the local date inside the container?
[2017-03-26 11:34:08] <MonXBZH> Yes, i would want to stay on an unique date.
[2017-03-26 11:34:22] <SISheogorath>  [<-LINK->] 
[2017-03-26 11:34:51] <SISheogorath> You want to do something like a time stop?
[2017-03-26 11:35:03] <SISheogorath> Not sure if this is a good idea
[2017-03-26 11:37:59] <MonXBZH> It's just foir a container, without affecxting the host
[2017-03-26 11:38:35] <MonXBZH> Maybe a script which can be launched everyday at 00:01 to make teh system 1 day before
[2017-03-26 11:38:36] <MonXBZH> ?
[2017-03-26 17:51:29] <vlashchanka> Hello guys, I can not find the place where the created volumes are stored (Windows 10)?(docker volume create mongodbdata)
[2017-03-26 17:55:31] <MonXBZH> /var/lib/docker/volumes/ ?
[2017-03-26 18:05:35] <vlashchanka> /var/lib/docker/volumes/ ?I am on windows. Please, tell where it is localed?
[2017-03-26 18:05:59] <MonXBZH> Oups, miss undertstanding
[2017-03-26 18:06:21] <MonXBZH> Sry, i dont use Docker on Windows
[2017-03-26 18:06:25] <MonXBZH> Can't herlp you
[2017-03-26 18:06:29] <MonXBZH> //
[2017-03-26 18:06:31] <MonXBZH> :/
[2017-03-27 14:05:05] <eshepelyuk> Hello, is there any easy way of getting health status of a service in swarm cluster, i.e. health of the all containers that are created for particular service ?
[2017-03-28 07:54:33] <Orpere> any one is woorking with alpine ?
[2017-03-28 07:54:43] <Orpere> I can't export vars
[2017-03-28 07:54:55] <Orpere> when i echo show empty
[2017-03-28 07:57:51] <mattoni> Orpere: what do you mean export vars?
[2017-03-28 07:59:12] <hazim1093> Orpere: can you provide any specific material on what exactly you're trying to achieve?
[2017-03-28 07:59:49] <Orpere> i need to add   export JBOSS_HOME=/opt/wildfly  but when  i echo the var is empty
[2017-03-28 08:00:30] <hazim1093> in the dockerfile or while running you're container?
[2017-03-28 08:00:48] <Orpere> I am on a container
[2017-03-28 08:01:00] <Orpere> FROM docker.io/alpineinstall packagesRUN apk update && apk upgradeRUN apk --update add openssh openjdk8  bash wget bash curl lsofconfigure java envinstall wildflyRUN mkdir -p /opt && \\    wget -O wildfly-servlet-10.1.0.Final.zip http://download.jboss.org/wildfly/10.1.0.Final/servlet/wildfly-servlet-10.1.0.Final.zip && \\    unzip  wildfly-servlet-10.1.0.Final.zip -d /opt/ && \\    cp -R /opt/wildfly-servlet-10.1.0.Final.zip /opt/wildfly    export JBOSS_HOME=/opt/wildfly && \\    $JBOSS_HOME/bin/add-user.sh admin admin && \\    rm -fr wildfly-servlet-10.1.0.Final.zip && rm -fr /opt/wildfly-*;#CMD ["/usr/bin/java", "-version"]
[2017-03-28 08:01:10] <Orpere> that is the dockerfile
[2017-03-28 08:01:30] <Orpere> is very simple i have no ideia why is not working
[2017-03-28 08:01:50] <hazim1093> instead of  theexport JBOSS_HOME=/opt/wildflylinecould you try adding theENVcommand in the dockerfile?
[2017-03-28 08:02:03] <hazim1093> ENV JBOSS_HOME /opt/wildfly
[2017-03-28 08:02:21] <Orpere> kthanks a lot I will try ]
[2017-03-28 08:03:35] <hazim1093> plus, you're missing a&& \\aftercp -R /opt/wildfly-servlet-10.1.0.Final.zip /opt/wildfly
[2017-03-28 08:04:11] <Orpere> thanks more one time
[2017-03-28 08:04:31] <hazim1093> :) let me know if it does the trick
[2017-03-28 08:04:38] <Orpere> ok
[2017-03-28 08:04:43] <Orpere> one minut
[2017-03-28 09:05:18] <cantgis> anyone use atomic ?
[2017-03-28 10:49:44] <SISheogorath> You have to use ENV instead of export and it's not about the base image it's about how docker builds images.
[2017-03-28 13:17:17] <ael-g> Hello guys, I'm declaring overlay networks in a compose file and creating stack from it. The thing is that if in my compose file, I declare network
[2017-03-28 13:17:36] <ael-g>  [<-CODE->] 
[2017-03-28 13:18:08] <ael-g> and then I create a stack with commanddocker stack deploy -c ci.yml ci
[2017-03-28 13:18:21] <ael-g> I end up with a network with name
[2017-03-28 13:18:29] <ael-g> ci_ci-network
[2017-03-28 13:19:15] <ael-g> I'd like to reference thisci_ci-networkfrom my compose file because I need to pass it as an env var to a particular container
[2017-03-28 13:20:45] <ael-g> would some special variable exist in compose that would be expended to actual names ? like if I write something like${network:ci-network}, it will be extended toci_ci-networkat stack creation time?
[2017-03-28 15:37:32] <killerspaz> w00t, just got my dockercon ticket
[2017-03-28 15:50:29] <austinfrey> jelly
[2017-03-28 16:31:37] <killerspaz> anyone had issues with alpine suddenly not wanting to install a package that works on the exact same base docker image on another deploy?????? I keep getting:ERROR: unsatisfiable constraints: mysql-10.1.22-r0:  breaks: world[mysql=10.1.21-r0]
[2017-03-28 16:51:38] <killerspaz> bah, figured it out after staring at this message... i had an older version referenced
[2017-03-29 02:46:44] <fanux>  [<-CODE->] 
[2017-03-29 02:46:47] <fanux> why?
[2017-03-29 09:37:09] <mreis1> Hello Guys,I’m running an image with a docker volume mapped to a container volume.I would like to be able to export that container and it’s docker volume to a new computer. Is there a way to do that?Here’s my setup [<-CODE->] I did saw container_export but I’m afraid it will not work as expected. https://docs.docker.com/engine/reference/commandline/container_export/
[2017-03-29 09:40:23] <papaiatis> Hi all! Can you please recommend a great and valuable online docker training course (video)? It can be both free or paid.
[2017-03-29 10:03:27] <ael-g> Hi! Do you know if there's a way to manage swarm stacks with docker's golang API?
[2017-03-29 10:03:40] <ael-g> Seems like there's nothing about stacks in [<-LINK->] ...
[2017-03-29 10:17:21] <anurudda_twitter> papaiatis:  [<-LINK->] 
[2017-03-29 11:10:46] <srollinet> Hi! Using docker for windows, is it possible to access a volume from my windows host if I mount it here:/var/log/apache/:/var/log/apache2/?
[2017-03-29 11:20:02] <mreis1> @srollinet since you are on windows I would say that your volume mount should look something like this-v c:\\Users\\<user>\\logs\\:/var/log/apache2again, this is just how I imagine the behaviour, I didn’t test it at all
[2017-03-29 11:30:37] <srollinet> mreis1: My problem is that this is in a docker-compose file that will be used with linux and windows hosts. So I hoped it was possible to have the same mounts.Maybe the easiest solution for me is to have another docker-compose file for windows, and that overrides this config.
[2017-03-29 11:32:25] <apt-getyou> use   '~/to/you/path'  ?
[2017-03-29 11:35:55] <srollinet> apt-getyou: It seems to work. Thanks!
[2017-03-29 11:37:04] <apt-getyou> really？
[2017-03-29 11:39:47] <srollinet> apt-getyou: at least on windows, so I think it will work on linux as well, I will try soon
[2017-03-29 12:04:07] <apt-getyou> Execute docker-compose up where you change the user , will  something  wrong？
[2017-03-29 12:04:20] <apt-getyou> srollinet: 
[2017-03-29 19:07:22] <stanzacal_twitter> Hi everyone
[2017-03-29 19:08:21] <stanzacal_twitter> Just curious if anyone has any thoughts on dynamic calendar tools - specifically around predictive user behavior. We utilize Docker for our platform and wanted to get general thoughts
[2017-03-30 01:36:05] <DJQTDJ> if there anyone who goot at apache
[2017-03-30 09:22:12] <ahurt2000_twitter> Just now I'm preparing some apache-2.4.10
[2017-03-30 09:32:45] <ahurt2000_twitter> DJQTDJ: Any question ?
[2017-03-30 10:36:28] <slvrtrn> Hi all, I have a question regarding containers started via Docker in Mac OS X.They become unresponsible after certain amount of time, and that's quite annoying.I have to restart daemon every time.My situation is just like described here: docker/for-mac#1009I tried to increase connections (4000 instead of default 900) for docker as described in djs55's post, but it doesn't seem to work for me.In logs I still see: [<-CODE->] and that's very strange, cause at the same time [<-CODE->] Docker version: 17.03.0-ce-mac2 (15657)Any ideas? I had same troubles on stable version as well.
[2017-03-30 15:57:52] <pckeyan> Hi all, Can you help me on how to/where to get the number of connections  and where do I configure the maximum number Connections?
[2017-03-30 16:18:23] <SISheogorath> What kind of connections?
[2017-03-30 16:45:08] <pckeyan> I have a similar behaviour of container goes unresponsive after a period of time like mentioned by@slvrtrn. Interested to check whether it is an issue in my environment. Can you please help me here?
[2017-03-30 16:55:52] <allx2> Hi! guys, I have a little problem I bought a vps with Oracle 7, I'm tried
[2017-03-30 20:49:12] <l3x> Hi all, I'm looking for help making a basic tcp connection from a container to a server running on port 1443 on the host (127.0.0.1).EXPOSE (and using the -p command line option) works great for exposing  container ports.I didn't think there would be any problems connecting to a container's host port.  I was wrong.Here's what it looks like: [<-CODE->] Any ideas?
[2017-03-30 21:26:50] <l3x> Was thinking it may have something to do with the docker bridge ... So when I rundocker run -d -p 3000:3000 --name ddi-prod --dns 172.17.0.1 debugging-docker-imagesand then open a shell and attempt totelnet 172.17.0.1 1443still no luck.  Any ideas?
[2017-03-30 21:59:48] <l3x> Figured it out... The trick was to use my actual host ip address.  localhost/127.0.0.1 in the context of the container is the docker engine, not the host computer (which in my case is a mac).  Cheers!
[2017-03-31 13:41:19] <pecigonzalo> Hello!
[2017-03-31 13:41:38] <pecigonzalo> Anyone knows ifDocker for AWSbinaries and images are documented somewhere?
[2017-03-31 13:42:06] <pecigonzalo> Im trying to look for things like buoy, metaserver, l4balancer which do not seem to be documented, and while i would like to deploy this
[2017-03-31 13:42:13] <pecigonzalo> without docs, it would be a pain to support
[2017-03-31 14:21:52] <jdaltonchilders> Hey everyone!I'm fairly new to docker so I have a few questions about a project I'm trying to get off the ground. I need to create multiple celery instances, which should be executing a python script. These celery instances will be making api calls to a service, but I'd like for each instances to get its IP from the DHCP servers and not share localhosts IP. I'd still like to have the internal network so the container can communicate, but the api calls need to be coming from separate IPs. I've seen people mention setting a static IP, but I was trying to make it more flexible than that...
[2017-03-31 14:24:59] <ChipWolf> take a look at consul
[2017-03-31 14:25:20] <ChipWolf> there's probably a native way to do it with Docker thinking about it
[2017-03-31 14:25:54] <jdaltonchilders> I was thinking there maybe but...I'm just missing it or something haha
[2017-03-31 16:03:23] <eshepelyuk>  [<-CODE->]  [<-CODE->] 
[2017-04-01 10:10:51] <ScreamingDev_twitter> Hi there. Has someone a solution to override the umask? Like indocker-compose exec -T --user www-data php check-umask.php. No matter what I do (~/.bashrc, /etc/...) the umask stays the same.
[2017-04-01 18:39:26] <LouisWayne> Hey guys
[2017-04-01 18:40:04] <LouisWayne> Can anyone recommend web server hosting website for TOMCAT serer?
[2017-04-01 18:40:08] <LouisWayne> server*
[2017-04-01 18:41:11] <LouisWayne> DigitalOcean looks good - but I wanna know other good options
[2017-04-01 20:05:02] <mac2000> Em, why tomcat? I mean if you are going to self managing solutions DO is ok as absolutely any other VM provider, but if you are going for PaaS then it is not your problem, I'am not sure but bet that both beanstalk from aws and web app from azure can host your jar
[2017-04-01 20:06:07] <LouisWayne> Just because I like Spring Framework lol
[2017-04-02 00:38:52] <bima_gregory_twitter> Hello, some french here ?
[2017-04-02 02:04:59] <greta-burp-bonus> hey there
[2017-04-02 04:44:38] <chkm8> Hi, i am using ms sql server linux docker container for my other project(requirement is ms sql), do you know any tools that I can use to view the database via admin panel same like phpmyadmin? I found this container [<-LINK->] but I cant make it work or connect to my ms sql container. Im hoping for your inputs.
[2017-04-02 07:07:34] <mac2000> SQL Server Management Studio is a free one fully featured thing for that but unfortunately its not a web based but still may be a thing to look at
[2017-04-02 07:09:19] <chkm8> Yup but im using linux distro., Though, ive seen tools that could be run via wine, but i my sql server is in a docker container.
[2017-04-02 07:12:42] <mac2000> If all you need is simple querying stuff then may be DataGrip from JetBrains may be a choice
[2017-04-02 07:14:58] <mac2000> Or even Visual Studio Code with sql extension - [<-LINK->] but in both cases you will need to manually query master database for desired sql server internals (metrics, stats, etc)
[2017-04-02 07:41:15] <chkm8> hmmp vs code might be of use, it also has a docker image [<-LINK->] , ill check on this, thanks@mac2000
[2017-04-02 09:19:00] <chkm8> mac2000: , the vscode docker container works in my ubuntu 16. I just pulled the image and setup the connection I can now execute queries from vs code and vs code output it. thanks for it. :)
[2017-04-02 09:24:47] <mac2000> chkm8: can you please try run something likeselect * from sys.sysprocessesjust wondering will it work on linux box
[2017-04-02 09:29:13] <chkm8> sure,@mac2000it has a result but i dont think we can upload image here.
[2017-04-02 09:30:03] <mac2000> cool, seems that ms really ported everything
[2017-04-02 09:31:32] <chkm8> if thats the case , they did a great work. And also credits to the creator of the image also.
[2017-04-02 20:25:25] <georgeedwards> Hi, I am not able to start Docker on Windows because of a memory issue - would really appreciate some help - [<-LINK->] 
[2017-04-02 21:03:20] <pecigonzalo> Try directly starting the VM from Hyper-V@georgeedwards
[2017-04-02 21:03:31] <pecigonzalo> Just to ensure that works
[2017-04-02 21:07:22] <chkm8> georgeedwards: , how many GB of memory you have? In windows, it is required to have atleast 4G, but if you run plenty of application it will consumed more of your memory having this error, you can still run docker but make sure to manage your memory consumption well. You can increase your memory.
[2017-04-02 21:07:43] <pecigonzalo> He has 4GB from the link
[2017-04-02 21:09:15] <chkm8> ahh, 4GB is not enough, i dont know what windows needed that much memory, even if it uses Hyper V. I needed to change my memory to make docker works in windows.
[2017-04-02 21:09:48] <pecigonzalo> As far as i recall, you can make it work by manually managing the Hyper-V memory and startup
[2017-04-02 21:09:54] <pecigonzalo> it just doesnt work from the "nice gui"
[2017-04-02 21:12:47] <chkm8> hmmp., ah I did not changed the memory in hyper v, I was running plenty of application at the same time, I have ms sql server running and multiple browser in chrome, so it would end up eating all the memory, though could be a temporary solution.
[2017-04-02 21:23:31] <chkm8> mac2000: , somebody told me from another forum that adminer is an alternative for phpmyadmin, [<-LINK->] and it runs on docker.
[2017-04-03 01:56:41] <greta-burp-bonus> any the walking dead fans here?
[2017-04-03 08:28:26] <mac2000> Wondering, can i run both windows and linux containers at same time with docker for windows? (windows containers are always up and running, so while i'm on linux containers to me it seems to be possible just to point docker client to another docker server instance))
[2017-04-03 08:28:55] <pecigonzalo> Anyone knows ifDocker for AWSbinaries and images are documented somewhere?Im trying to look for things like buoy, metaserver, l4balancer which do not seem to be documented, and while i would like to deploy thiswithout docs, it would be a pain to support
[2017-04-03 09:54:09] <georgeedwards> When I try to modify the VM settings in Hyper-V (Windows), theMobyLinuxVMonly appears whilst docker is starting, after it fails, the VM disappears so I can't change the settings?
[2017-04-03 10:26:21] <jeserkin> Good day everyone!
[2017-04-03 10:26:49] <jeserkin> Is there a way to order commands in docker-compose? Thank you.
[2017-04-03 12:59:37] <pecigonzalo> order commands?
[2017-04-03 12:59:49] <pecigonzalo> I dont think i understand the question
[2017-04-03 14:06:19] <georgeedwards> I am using Docker on Windows, and trying to get started with this [<-LINK->] , so I ran the command:docker run --name test-ng -v //C:/Users/George/Source/Repos/existing%20project:/opt alexsuch/angular-cli -p 4200:4200 angular-cli:latesthowever, I get:docker: Error response from daemon: invalid bind mount spec "/C:/Users/George/Source/Repos/existing%20project:/opt": invalid mode: /optI copied that from the docs, what is wrong with the /opt directory and why is it being referred to as a mode?
[2017-04-03 14:46:14] <mac2000> @georgeedwards  you do not need double slashes in front of c drive, also really important to wrap path with spaces into double quotes [<-CODE->]  [<-CODE->] 
[2017-04-04 10:04:06] <georgeedwards> mac2000: Thanks so much!
[2017-04-04 11:51:22] <georgeedwards>  [<-LINK->] 
[2017-04-04 13:04:36] <mac2000> georgeedwards: I'm not an angular expert but bet that you will have troubles trying to run something that requires X inside docker, try to swap chrome with phantomjs inside your test runner it should work
[2017-04-04 13:31:11] <jeserkin> any docker experts? :)
[2017-04-04 14:00:02] <pecigonzalo> Ill try and help, drop the question
[2017-04-04 14:41:16] <jeserkin>  [<-CODE->]  [<-CODE->] it runs all tasks as expected at sets up the environment as needed, but it does exit in the end and when I try to start it exists all the time.
[2017-04-04 14:42:06] <pecigonzalo> Does you image havebash? Whats setup.sh?
[2017-04-04 14:42:25] <pecigonzalo> Do you have this in a public repo? I can go give it a look
[2017-04-04 14:43:39] <jeserkin>  [<-LINK->] 
[2017-04-04 14:47:07] <pecigonzalo> Quick overiew, you install and exit so that is what happens
[2017-04-04 14:47:28] <jeserkin> How can I keep it working?
[2017-04-04 14:47:40] <pecigonzalo> You need to "run" something
[2017-04-04 14:48:05] <pecigonzalo> how do you run your node app?
[2017-04-04 14:48:07] <pecigonzalo> normally
[2017-04-04 14:48:27] <jeserkin> If it worked with base image, that I am using, then this behaviour should be present there, right?
[2017-04-04 14:48:55] <pecigonzalo> Well you are changing the command you execute / script i assume
[2017-04-04 14:49:03] <pecigonzalo> let me check the base image
[2017-04-04 14:50:22] <pecigonzalo> the base image runs NGINX
[2017-04-04 14:50:37] <pecigonzalo> sorry, apache
[2017-04-04 14:52:21] <pecigonzalo> Also, are you trying to build code in the container, or this is the image you are going to run the app on?
[2017-04-04 14:52:44] <jeserkin> Yep.
[2017-04-04 14:52:54] <pecigonzalo> ?
[2017-04-04 14:52:56] <pecigonzalo> run or build?
[2017-04-04 14:54:01] <jeserkin> First I build, then I map, then I run
[2017-04-04 14:54:06] <pecigonzalo> Ok
[2017-04-04 14:54:43] <jeserkin> At least that is the plan
[2017-04-04 14:54:50] <jeserkin> But not working so far.
[2017-04-04 14:54:54] <pecigonzalo> ok 1 moment
[2017-04-04 14:54:57] <jeserkin> Sure
[2017-04-04 14:57:17] <pecigonzalo> your Dockerfile should be something like [<-CODE->] 
[2017-04-04 14:57:24] <pecigonzalo> that adds the setup, and setups everything on BUILD
[2017-04-04 14:58:24] <jeserkin> I think I tried this way and whendocker-composeadded mapping with host system, then contents of mapped volumes went down the drain
[2017-04-04 14:58:49] <jeserkin> That is why I calledsetup.shas last strep
[2017-04-04 14:58:59] <jeserkin> after build and mapping
[2017-04-04 14:59:12] <pecigonzalo> yeah but then your build is local to your pc
[2017-04-04 14:59:19] <pecigonzalo> does not stay in the container
[2017-04-04 14:59:28] <pecigonzalo> so if you send me the container, i need to run setup again
[2017-04-04 15:01:15] <pecigonzalo> If you build inside the container, you shouldnt need to mount the volume
[2017-04-04 15:01:26] <jeserkin> that was the plan
[2017-04-04 15:01:50] <pecigonzalo> docker-compose.yml [<-CODE->] 
[2017-04-04 15:02:15] <jeserkin> I need to mount it, because I need access to files from host system and not through terminal
[2017-04-04 15:02:19] <pecigonzalo> Im trying o read where the apache-php image expects the files
[2017-04-04 15:02:38] <pecigonzalo> Ok
[2017-04-04 15:02:40] <pecigonzalo> then do this
[2017-04-04 15:02:41] <jeserkin> in the app directory
[2017-04-04 15:02:44] <pecigonzalo> change your setup.sh
[2017-04-04 15:02:49] <pecigonzalo> at the end add the following
[2017-04-04 15:04:03] <jeserkin> nothing came through
[2017-04-04 15:04:29] <jeserkin> what should be added in the end ofsetup.sh?
[2017-04-04 15:07:10] <pecigonzalo> exec /opt/docker/bin/entrypoint.sh supervisord
[2017-04-04 15:07:23] <pecigonzalo> that will execute the original process daemon that your base image uses
[2017-04-04 15:07:39] <pecigonzalo> but TBH i dont think its aniceway of running your app
[2017-04-04 15:13:58] <jeserkin> Haven't found better one with automated port and volume mapping and without the loss of mapped volumes content
[2017-04-04 16:01:40] <LuisUrrutia> Hi everyone, who lives in NYC?
[2017-04-04 16:02:18] <jeserkin> That came out of the blue 
[2017-04-04 16:08:01] <AnthonyWC> jeserkin: you need to have an entry point/cmd that run a process that doesn\'t exist immediately, e.g. CMD ["nginx"]
[2017-04-04 16:08:15] <AnthonyWC> (for the run container)
[2017-04-04 16:34:15] <jeserkin> AnthonyWC: not sure I am following. Any examples with provided earlier context?
[2017-04-04 16:58:13] <AnthonyWC>  [<-LINK->] 
[2017-04-04 21:06:39] <jeserkin> Thanks everyone for help
[2017-04-04 23:44:08] <hhimanshu> I am trying to install docker on machine which is [<-CODE->] I followed article https://docs.docker.com/engine/installation/linux/centos/#install-from-a-package [<-CODE->]  [<-CODE->] can someone please help
[2017-04-05 00:15:32] <mbonig> hey all
[2017-04-05 00:15:41] <mbonig> my name is matt, I'm a docker noobie
[2017-04-05 00:16:25] <mbonig> got a question for y'all... I'm looking for a tool that will allow me to manage local docker image and runtime (I'm a developer), same functionality as the cli, just a nicer UI version for that. Is there something already out there?
[2017-04-05 05:05:12] <mixpix3ls> mbonig: Perhaps Kitematic is what you’re looking for.
[2017-04-05 05:05:13] <mixpix3ls>  [<-LINK->] 
[2017-04-05 06:47:16] <hbasria> mbonig: I use it on my own computer, very successful. [<-LINK->] #demo
[2017-04-05 11:47:39] <jeserkin> pecigonzalo: btw, it seems, that use ofcommandindocker-composeorCMDinDockerfileautomatically tells, that the terminal where one will run it requires admin. permissions.
[2017-04-05 12:54:20] <mbonig> mixpix3ls: @hbasria, thanks, I'll check um out!
[2017-04-05 15:54:01] <pecigonzalo> jeserkin: I dont understand the comment
[2017-04-06 10:45:33] <mgangelov> Hello, can somebody tell me what are the available statuses for swarm nodes availability, when using the legacy swarm mode (the one with theswarmdocker image)? So far I've only encounteredHealthyandPending, but was wondering if there are more and couldn't find anything in the documentation. Thanks in advance!
[2017-04-06 17:04:21] <pecigonzalo> FYI: Docker Swarm for AWS based on Terraform (Instead of CloudFormation) and using mostly public code images (Working on a replacement for l4controller) [<-LINK->] 
[2017-04-06 17:59:29] <AnthonyWC> hhimanshu: cenots 6.7 doesn't have systemd by default (started w/ 7)
[2017-04-06 18:36:49] <killerspaz> To anyone here that is associated with Docker and DockerCon.. When I pay $1100 per ticket, this shit DOES NOT FUCKING FLY: [<-LINK->] 
[2017-04-06 18:39:10] <killerspaz> also whoever's in charge of scheduling should be fired.  putting all the advanced topics at the same time has to be the dumbest thing i've heard of at a convention.
[2017-04-06 18:39:18] <vito-c> in my parent image I have: ONBUILD RUN echo "FOO" > /bar.txt but when I build the child image there is no bar.txt
[2017-04-06 18:40:05] <vito-c> anyone ever have issues withONBUILD RUN?
[2017-04-06 18:46:05] <killerspaz> @vito-c that's how it works, as per docs:Triggers are cleared from the final image after being executed. In other words they are not inherited by “grand-children” builds.
[2017-04-06 18:46:38] <killerspaz> at least that's how i'm reading it... personally never used ONBUILD
[2017-04-06 18:46:59] <killerspaz> i just have scripts that my children builds either at build time or on entrypoint
[2017-04-06 19:00:09] <vito-c> but i'm just trying to get the child to run and create the file why... why would it clear the file?
[2017-04-06 19:00:15] <vito-c> it doesn't make sense
[2017-04-06 19:18:57] <killerspaz> looks like i'm wrong anyway:The ONBUILD instruction adds to the image a trigger instruction to be executed at a later time, when the image is used as the base for another build. The trigger will be executed in the context of the downstream build, as if it had been inserted immediately after the FROM instruction in the downstream Dockerfile.
[2017-04-06 19:19:13] <killerspaz> but only for immediate children?
[2017-04-06 19:29:26] <jeud> hi, is it possible to restart an existing container with new options ? e.g. new volume mapping
[2017-04-06 21:52:51] <AnthonyWC> jeud: sure just change your docker-compose.yml
[2017-04-06 22:15:46] <realisation> Hey there, I was surprised that an empty node 6.10.2 image is 660 mb large
[2017-04-06 22:20:24] <AnthonyWC> this is cool [<-LINK->] 
[2017-04-06 23:26:46] <vito-c> killerspaz: yah I can even see the RUN command execute but the file doesn't exist in my child image
[2017-04-07 03:42:17] <vito-c> well it is node 
[2017-04-07 15:59:04] <Nilesh20> is anyone have problem statements for docker want to practice on docker
[2017-04-07 17:26:01] <killerspaz> vito-c: and the user at the time theechois exec'd is root? Your root folder/(not user) should be owned by the root user, so if you're switching users that will essentially fail, possibly silently
[2017-04-07 17:27:58] <vito-c> killerspaz: Isn't the user in the container during the build process always root?
[2017-04-07 17:28:16] <vito-c> killerspaz: for example RUN apt-get .... you don't need to sudo
[2017-04-07 17:28:36] <killerspaz> not if you switch users using theUSERinstruction
[2017-04-07 17:28:51] <killerspaz> but if you're not doing that (or the parent), then it's a moot point
[2017-04-08 11:35:02] <yuvgeek> how to host multiple site in same domain using docker?
[2017-04-08 11:35:07] <yuvgeek> apache server
[2017-04-08 12:38:52] <SISheogorath> YuvarajMe: you search for a Reverse-Proxy. Checkout Traefik or nginx as reverse proxy
[2017-04-08 13:40:14] <xiaozhongliu> does any one have experience on setting a static ip to a container?
[2017-04-08 13:40:45] <xiaozhongliu> if so could u share a specific blog or some
[2017-04-08 17:53:07] <yuvgeek> SISheogorath: can we use nginx as reverse proxy if i use apache?
[2017-04-09 00:49:58] <SISheogorath> You can use apache
[2017-04-09 00:50:11] <SISheogorath> No need for nginx in this case
[2017-04-09 12:29:10] <SISheogorath> XiaozhongLiu: any special reason? Because you should avoid it when ever possible. And you should know that based on the isolated network stack you can't reach those static IPs from outside. If you still want it, checkout the docker-compose file from mailcow-dockerized. But I recommend you not to do it and use DNS names instead
[2017-04-10 16:17:47] <developer-guy> Hello everyone
[2017-04-10 16:17:55] <developer-guy> what is the solution of this error : Exiting: error loading config file: config file ("filebeat.yml") must be owned by the beat user (uid=0) or root
[2017-04-10 16:18:31] <kenchilada> chown the file to uid 0 ?
[2017-04-10 16:19:03] <developer-guy> no
[2017-04-10 16:19:08] <developer-guy> what is that command of this
[2017-04-10 16:21:33] <kenchilada> $ sudo chown root /path/to/filebeat.yml
[2017-04-10 16:21:58] <kenchilada> $ chown --help
[2017-04-10 16:23:51] <developer-guy> i am getting the same error nothing happene
[2017-04-10 16:23:53] <developer-guy> d
[2017-04-10 21:01:08] <arkadiossi> Can you verify? bysudo ls -a /path/to/filebeat.ymlOtherwise, tell us more about how are you getting to this error, I guess.Bottom line: this is an ownership problem
[2017-04-11 00:23:30] <SISheogorath> I currently ask myself if it is a docker error or an error of the application you want to run in docker. I guess it's the latter so you should may ask the developer of your application.
[2017-04-11 00:27:30] <SISheogorath> And an additional hint@developer-guyas this is not a support hotline and all help is someone else spending his free time for your problem, try to be nice and explain what you did, what you are about to do and what you already did to resolve the problem. Very helpful in general is to read and follow this guide: [<-LINK->] 
[2017-04-11 12:07:31] <RyoIkarashi> Does anyone have an answer for this? [<-LINK->] 
[2017-04-11 16:38:05] <synelang> RyoIkarashi: shared mysql instance but indenpent data for each databse ?  just indenpend mysql instance.
[2017-04-11 16:39:53] <RyoIkarashi> synelang: Thanks for the reply! I just want to use only one shared mysql instance. Do you know any workaround to accomplish this?
[2017-04-11 16:43:42] <synelang> RyoIkarashi: what you want to do is not in Docker way
[2017-04-11 16:47:29] <RyoIkarashi> synelang: I'm very new to Docker and I thought it'd be easy to maintenance if other containers share one mysql instance because I don't need to change port number for each mysql instance for example. But could you please explain why it's not in Docker way?
[2017-04-11 17:24:41] <synelang> RyoIkarashi: wordpress container already got the hostname of  mysql container, so no longer need to expose port 3306
[2017-04-11 17:40:53] <dragon788> RyoIkarashi: like mentioned you could use linked containers to link your wordpress containers to the central database, but it would be better to create a single DB per wordpress site to make them more portable and also so you can backup each on their own
[2017-04-11 17:41:23] <thebuccaneersden> RyoIkarashi: This kinda works for me. I threw it together pretty quickly, so I’m sure some of it could be tweaked better
[2017-04-11 17:41:33] <thebuccaneersden>  [<-CODE->] 
[2017-04-11 17:43:04] <thebuccaneersden> dragon788: I kinda disagree with that (that the docker way is to have separate dbs per wordpress site)
[2017-04-11 17:43:40] <thebuccaneersden> it can be, but its really down to how you want your infrastructure to scale
[2017-04-11 17:43:54] <thebuccaneersden> and $$$
[2017-04-11 17:47:29] <dragon788> thebuccaneersden: I completely agree, he mentioned wanting shared, I'd suggest one per site but that isn't always possible
[2017-04-11 17:48:05] <dragon788> if it isn't going into production there are many ways to accomplish it
[2017-04-11 17:48:12] <dragon788> if you want to scale, there are definitely best practices
[2017-04-11 17:48:35] <RyoIkarashi> dragon788: yes, I totally agree with you. I'm not planning to scale sites and wanna cut the cost as much as I can. So in this context, having one shared DB should be enough.
[2017-04-11 17:49:43] <thebuccaneersden> well, my example above worked for me and seems to me what you wanted to achieve...
[2017-04-11 17:52:07] <RyoIkarashi> thebuccaneersden: Thanks for sharing your code! Does that compose file create two DBs, foo and bar right? Is there any way to initialize each WP site with some data by sql?
[2017-04-11 17:53:57] <thebuccaneersden> RyoIkarashi: No, the example above creates 3 containers - 1 db container & 2 wordpress containers and the wordpress containers are sharing the db container
[2017-04-11 17:55:46] <RyoIkarashi> thebuccaneersden: Ah I mean two DB name, foo and bar in one maria DB?
[2017-04-11 17:55:49] <thebuccaneersden> as for your second question, i dont know. lemme check the documentation. if there is a way to run commands when docker-compose goes up, then you could have a script that checks to see if the db for the wordpress instance exists, if not, import sql file
[2017-04-11 17:56:23] <thebuccaneersden> yes. two dbs - foo and bar on one db instance - correct
[2017-04-11 17:57:22] <RyoIkarashi> thebuccaneersden: Gonna check out the documentation. Thanks anyway! :)
[2017-04-11 18:03:10] <thebuccaneersden> RyoIkarashi: I can’t test it for you, but you could possibly usecommand: something.sh?
[2017-04-11 18:03:45] <thebuccaneersden> and in something, have the logic that checks if it needs to import the db or not, based on whether the db (ie.foo) exists in the db instance
[2017-04-11 18:09:17] <RyoIkarashi> thebuccaneersden: I think your suggestion should meet my requirements. Im gonna give it a try. Thanks!
[2017-04-11 18:10:25] <thebuccaneersden> np amigo
[2017-04-11 18:11:05] <RyoIkarashi> thebuccaneersden: Appreciate your kindness 
[2017-04-11 18:11:37] <thebuccaneersden> thanks :)
[2017-04-12 09:11:18] <brokleen> hello
[2017-04-12 09:12:27] <brokleen> I have problem with mounted volume and file permission
[2017-04-12 09:14:40] <brokleen> My webapp failed to write file to disk
[2017-04-12 09:33:08] <brokleen> If I try to change the ownership, nothing happen..
[2017-04-12 10:53:58] <pecigonzalo> maybe the webapp is not running as root
[2017-04-12 10:54:02] <pecigonzalo> but as nginx or apache
[2017-04-12 10:54:11] <pecigonzalo> and the files are owned by someone else
[2017-04-12 10:56:24] <brokleen> pecigonzalo: apache, I use eboraas/apache-php image
[2017-04-12 10:57:37] <pecigonzalo> can you show us how you are running the contianer
[2017-04-12 10:57:39] <pecigonzalo> and the permissions
[2017-04-12 11:00:52] <brokleen>  [<-CODE->] 
[2017-04-12 11:03:05] <pecigonzalo> and als -laHon /wwwplease
[2017-04-12 11:03:17] <pecigonzalo> also
[2017-04-12 11:03:36] <pecigonzalo> docker-compose exec php ls -laH /var/www/html
[2017-04-12 11:03:51] <pecigonzalo> given that /www is the directory it fails to write
[2017-04-12 11:06:10] <brokleen> 1000:staff  drwxr-xr-x
[2017-04-12 15:07:26] <w0rldart> Hey guys! Quick question... whilst with a Vagrant box I can define and bring all my required services up for a project (i.e.: its APIs, Daemons and so on), what would be the best way of doing so with Docker? I am aware I can use Docker's compose to launch services based on custom images, but not sure how to manage that with compose for a project broken down into a lot of small pieces
[2017-04-12 15:21:04] <hatrena> w0rldart: i am not sure if i got your question exactly, but you can config your setting in your docker-compose.yml plus you can have your specific image configuration in the DockerFile. what do you mean by "a project broken down into smal pieces" ?
[2017-04-12 15:21:18] <dragon788> w0rldart: you basically define dependencies between the services in your compose file and it will handle bringing them up in the right order
[2017-04-12 15:40:37] <w0rldart> Say my project is called Invoices, when I power up my development environment on Vagrant,  everything is configured so that all of its dependencies (the small pieces that makes it whole) are ready to work. I.E.: Afront-end,two APIs,a mailing daemonand aqueue worker(say they're all located in/srv/invoices/{www,api-individuals,api-business,mailer,worker}
[2017-04-12 15:41:13] <w0rldart> what I am looking for, is the way to convert that to a Docker alternative because the VM is quite heavy on the resources
[2017-04-12 15:41:19] <w0rldart> but I guess@dragon788is right
[2017-04-12 15:42:18] <w0rldart> have a docker-compose.yml that initiates all those services based on their custom images
[2017-04-12 15:42:40] <w0rldart> with a custom network and exposing the appropriate ports
[2017-04-12 15:46:16] <w0rldart> I apologise for the not so clear initial question. Rushed into it and I'm quite tired
[2017-04-12 17:46:26] <dragon788> yup,  the nice part about Docker is you get the "same network" for free, unless you want additional isolation in which case you can add that, but you can also limit the amount of things you need to start if you do only link the directly dependent containers, once you do a link you can easily reference the various services without having to know IPs (great for portability)
[2017-04-13 09:02:52] <w0rldart> coo! thanks dude
[2017-04-13 09:02:55] <w0rldart> cool*
[2017-04-13 10:46:27] <MaxGoh> Hi guys. How can I use Docker with Angular CLI? I want to be able to build my app and push it to a production docker container that is serving nginx as well.
[2017-04-13 10:47:08] <MaxGoh> So the problem is, I want to build a dist folder in the docker container, and during development
[2017-04-13 10:47:20] <MaxGoh> I would be able to watch the folder and serve the webapp
[2017-04-13 10:47:35] <MaxGoh> Anyone could provide some guidance on how I could do this?
[2017-04-13 10:51:58] <carljmosca> MaxGoh: not an Angular guy but I would start by looking at what others have done [<-LINK->] 
[2017-04-13 10:53:33] <Asiddiki> How to tag a image which is already in docker repository?
[2017-04-13 10:56:30] <Asiddiki> Lets say when I am using docker images  i am gettingREPOSITORY       TAG               IMAGE ID              CREATED                  SIZEHello                       world           136ase5f2bb       1 days ago              50MBNow i want this Hello:world as  Hi:Example
[2017-04-13 11:36:44] <MaxGoh> carljmosca: Thanks for that, didn’t know I can read other’s dockerfile.
[2017-04-13 11:36:51] <MaxGoh> But anyway, what’s the point of building images?
[2017-04-13 11:37:01] <MaxGoh> Isn’t everything run via docker-compose?
[2017-04-13 11:37:07] <MaxGoh> Why would I build an image?
[2017-04-13 11:48:34] <carljmosca> MaxGoh: I am not sure I can sufficiently answer that in a few short lines.  Containerization has many benefits…portability, lower overhead, simplfied maintenance, etc.  Ultimately, your image can be deployed (as a container) to  production…is that not your goal?
[2017-04-13 11:48:53] <MaxGoh> Yes! Haha
[2017-04-13 11:49:03] <MaxGoh> I don’t quite understand the docs, despite reading them countless times.
[2017-04-13 11:49:21] <MaxGoh> I could just do a docker-compose up and it all runs nicely
[2017-04-13 11:49:25] <MaxGoh> And there’s no image that is built
[2017-04-13 11:49:36] <pecigonzalo> That is correct, the image is to distribute
[2017-04-13 11:49:51] <MaxGoh> So if I’m only using it for myself
[2017-04-13 11:49:54] <pecigonzalo> EG: distribute a base NGINX instalation like thenginxone
[2017-04-13 11:49:55] <MaxGoh> There’s no need to build images?
[2017-04-13 11:50:03] <pecigonzalo> if its just for running locally, there might be no point
[2017-04-13 11:50:18] <pecigonzalo> unless you need to "store" a base image
[2017-04-13 11:50:24] <pecigonzalo> EG: i built myself a SBT image
[2017-04-13 11:50:28] <MaxGoh> SBT?
[2017-04-13 11:50:38] <pecigonzalo> scala stuff, for running builds
[2017-04-13 11:50:51] <pecigonzalo> so then i use that trough compose in other projects
[2017-04-13 11:51:06] <MaxGoh> Oh
[2017-04-13 11:51:09] <MaxGoh> Um
[2017-04-13 11:51:15] <MaxGoh> So in my docker compose
[2017-04-13 11:51:20] <MaxGoh> I don’t really need a image: right
[2017-04-13 11:51:54] <pecigonzalo> On the contrary, lets say you build your own NGINX image, in your compose you just reference that, instead of running a build
[2017-04-13 11:52:23] <pecigonzalo> now, i dont understand if you use i locally or on a server, or want to deploy, as you mentioned before:I want to be able to build my app and push it to a production docker container that is serving nginx as well.
[2017-04-13 11:52:35] <MaxGoh> Um
[2017-04-13 11:52:46] <MaxGoh> Okay, let me try to explain in depth okay?
[2017-04-13 11:52:49] <pecigonzalo> Sure!
[2017-04-13 11:52:53] <MaxGoh> Cause I have been stuck on this quite long
[2017-04-13 11:52:58] <MaxGoh> and I’m really appreciating your help right nw
[2017-04-13 11:53:01] <MaxGoh> now*
[2017-04-13 11:53:04] <MaxGoh> Okay here goes
[2017-04-13 11:58:43] <MaxGoh> @pecigonzaloI’m currently getting start to build an Angular web app using Angular-CLI. So my current objective is to implement Docker & Gitlab CI. So right now, my current stage is that I’m able to run a local development container that is able to compile during live coding, which is great! (Step 1 complete).Step 2 ) Create a flow for Production, and the way production works is that I have a command call ng build, which watches the folder and compiles a dist/ folder. I would like to COPY that in the container, and use nginx to serve it.Step 3/4 would be similar, which is to have a flow where I can to stimulate like my local laptop is the server itself so I can run it and test it out if it works (development and production)
[2017-04-13 11:59:24] <MaxGoh> Sorry if it’s alittle vague. I’m really not familiar with the Docker scene. But I’m really happy I got into it
[2017-04-13 12:03:38] <hatrena> For any command line you can use DockerFile to execute the sh file through CMD command. then it execute all your necessary commands in your sh file after your container is ready
[2017-04-13 12:04:09] <MaxGoh> Dockerfile first then work on docker-compose?
[2017-04-13 12:05:10] <pecigonzalo> Im trying to look for a tutorial that will explain the steps
[2017-04-13 12:05:16] <hatrena> docker-composer is just a way to link services at one, you can link many images which each has its own dockerfile
[2017-04-13 12:07:17] <MaxGoh> Do I have to care about ‘images’ as I’m not really planning to build any image
[2017-04-13 12:07:27] <MaxGoh> and stuff like nginx, I will just use FROM nginx
[2017-04-13 12:08:13] <hatrena> once you use "FROM" ngin, you just need EXPOSE it in the DockerFile
[2017-04-13 12:08:49] <pecigonzalo> Saeed, i think you are just jumping between things and assuming his knowledge of all this stuff
[2017-04-13 12:08:56] <hatrena> i don\'t get you by "caring about" images
[2017-04-13 12:09:42] <hatrena> that the thing, these are very generic concepts, and circumstances are totally different between scenarios
[2017-04-13 12:10:29] <hatrena> we need very specific question.
[2017-04-13 12:10:54] <MaxGoh> Hm
[2017-04-13 12:11:05] <MaxGoh> It might be because I have been jumping around the docs
[2017-04-13 12:11:15] <MaxGoh> And now my understanding of docker is pretty jumbled up
[2017-04-13 12:13:32] <pecigonzalo> writing something, 1 moment
[2017-04-13 12:14:57] <MaxGoh> Cool
[2017-04-13 12:26:22] <pecigonzalo> lets see if it fits
[2017-04-13 12:26:33] <pecigonzalo> @MaxGohA docker image is always use when you use dockerEG: [<-CODE->] You are using the nginx:latest image.Images are used to "bundle" things up and distribute, think of it like a "zip" file in a way.Dockerfiles are used for building docker imagesEG: [<-CODE->]  [<-CODE->] Now, lets say i want to serve some static content that i have on my html folder using NGINX, ill create the following: [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2017-04-13 12:30:55] <pecigonzalo> Now, with this in mind, as it was mentioned before, the workflow for your particular app really depends on how you build it and how you run it, a good idea would be to as mentioned in my example build an image out of your Angular application and somehow (by the registry or otherwise) get it to your production server and run it there. How to build your app, really depends on your workflow and the type of app your are running.You can use this as a good example: [<-LINK->] 
[2017-04-13 12:31:36] <MaxGoh> Thanks@pecigonzalo! I’m going to read that.
[2017-04-13 12:31:48] <pecigonzalo> Np
[2017-04-13 12:32:01] <pecigonzalo> Hope it helps
[2017-04-13 12:32:05] <hatrena> Well said@pecigonzalo
[2017-04-13 12:34:20] <pecigonzalo> <3
[2017-04-13 12:44:40] <pecigonzalo> Oh by the way, found this the other day@MaxGohv
[2017-04-13 12:44:41] <pecigonzalo>  [<-LINK->] 
[2017-04-13 12:44:48] <pecigonzalo> could help you get started and learning
[2017-04-13 12:46:54] <MaxGoh> pecigonzalo: Sorry! I was in a skype call earlier.
[2017-04-13 12:47:02] <MaxGoh> Thanks for the write-up and the URL. I'm reading them now!
[2017-04-13 12:54:17] <MaxGoh> pecigonzalo: Hey, what if I don’t have a DockerHub account
[2017-04-13 12:54:35] <MaxGoh> I can’t do a docker push, so where I can’t grab image: yeah?
[2017-04-13 12:57:20] <pecigonzalo> If you dont have a DockerHub account you cant push to the dockerhub, so you can just run locally build images or other public images on the hub
[2017-04-13 12:57:34] <MaxGoh> Haha yup
[2017-04-13 12:57:42] <MaxGoh> But I feel alot clearer after reading your write-up
[2017-04-13 12:57:46] <MaxGoh> One thing would be key
[2017-04-13 12:57:50] <MaxGoh> environment variables
[2017-04-13 12:58:02] <MaxGoh> How does that work though? I saw some files that says
[2017-04-13 12:58:10] <MaxGoh> environment:-DEBUG=1
[2017-04-13 12:58:18] <pecigonzalo> You will need an account or your own registry to be able to push somewhere, otherwise, you candocker image saveto save an image and thendocker image importto import it somewhere else
[2017-04-13 12:58:45] <MaxGoh> Understood
[2017-04-13 12:58:49] <pecigonzalo> in thedocker-compose.ymlfile?
[2017-04-13 12:58:52] <MaxGoh> Yes
[2017-04-13 12:59:06] <MaxGoh> As I think that might be key for me to set multile environments?
[2017-04-13 12:59:12] <pecigonzalo> they are basically environment variables passed to the command that you run, like bash environment variables
[2017-04-13 12:59:33] <pecigonzalo> everything you can do on compose, you can do on regulardockercli
[2017-04-13 12:59:48] <MaxGoh> so say I wanna do a docker-compose up —prod?
[2017-04-13 12:59:53] <MaxGoh> or docker-compose up —dev
[2017-04-13 13:00:15] <pecigonzalo> docker run -e DEBUG=1 -e THISVAR=false nginxfor doing vars from docker cli
[2017-04-13 13:00:42] <MaxGoh> Haha
[2017-04-13 13:00:52] <pecigonzalo> docker-compose upwill just bring the declaration on thedocker-compose.ymlfile
[2017-04-13 13:00:54] <MaxGoh> Okay this part is pretty confusing
[2017-04-13 13:01:05] <pecigonzalo> you can have multiple vars by just having
[2017-04-13 13:01:10] <MaxGoh> Just like docker run -it --rm -p 80:80 -v html:/usr/share/nginx/html MyStaticSite:latest
[2017-04-13 13:01:20] <MaxGoh> I should read the man page and understand stuff like -it —rm
[2017-04-13 13:01:26] <pecigonzalo>  [<-CODE->] 
[2017-04-13 13:01:39] <pecigonzalo> yes, that will be idea
[2017-04-13 13:01:48] <pecigonzalo> rundocker run --help
[2017-04-13 13:02:04] <MaxGoh> But, say I set DEBUG=1
[2017-04-13 13:02:14] <MaxGoh> How does that dictate it to be production or development?
[2017-04-13 13:02:47] <pecigonzalo> unless you have 2 service declarations on yourdocker-compose.ymlyou cant
[2017-04-13 13:02:53] <pecigonzalo> ondocker-compose up
[2017-04-13 13:02:54] <MaxGoh> I see
[2017-04-13 13:03:01] <MaxGoh> I read to use production.yml
[2017-04-13 13:03:12] <MaxGoh> as in docker-compose -f docker-compose.yml -f production.yml
[2017-04-13 13:03:14] <MaxGoh> is the way to do it haha
[2017-04-13 13:03:19] <pecigonzalo> you can overwrite if you dodocker-compose run -e DEBUG=0 MyStaticSite
[2017-04-13 13:03:37] <pecigonzalo> Oh yeah, you could use that, but i was trying to avoid the "chaining" of docker-compose files
[2017-04-13 13:03:52] <pecigonzalo> as it might make it more complex for a begginer
[2017-04-13 13:05:15] <MaxGoh> I just saw the training website
[2017-04-13 13:05:19] <MaxGoh> I’m going to play with it haha!
[2017-04-13 13:05:22] <MaxGoh> I see.
[2017-04-13 13:05:45] <pecigonzalo> this guys [<-LINK->] also have nice interactive trainigns
[2017-04-13 13:05:57] <MaxGoh> Wow
[2017-04-13 13:05:59] <MaxGoh> Cool
[2017-04-13 13:06:23] <pecigonzalo> alsodocker-compose.ymlsupports variable interpolation
[2017-04-13 13:06:35] <MaxGoh> Which means?
[2017-04-13 13:07:50] <pecigonzalo> so you can do this [<-CODE->]  [<-CODE->] 
[2017-04-13 13:08:15] <MaxGoh> What does that affect though
[2017-04-13 13:08:16] <MaxGoh> As in
[2017-04-13 13:08:24] <MaxGoh> I understand I would set DEBUG=0
[2017-04-13 13:08:32] <MaxGoh> Is something awaiting the DEBUG value?
[2017-04-13 13:08:45] <pecigonzalo> Well, it depends on your app, i was just giving you an example
[2017-04-13 13:09:03] <pecigonzalo> lets say you have something that i the Evironment variable DEBUG is set to 1 prints debug logs
[2017-04-13 13:09:08] <MaxGoh> I see
[2017-04-13 13:09:18] <MaxGoh> So I have to code that out as in my angular app?
[2017-04-13 13:09:24] <MaxGoh> It’s not exactly Docker related yes?
[2017-04-13 13:09:35] <pecigonzalo> I was giving it as an example in the case oyu had different stuff for prod, you can also interpolate
[2017-04-13 13:09:39] <pecigonzalo> correct
[2017-04-13 13:09:48] <pecigonzalo> its just environment varialbes
[2017-04-13 13:09:54] <pecigonzalo> like any other application
[2017-04-13 13:10:46] <MaxGoh> I see!
[2017-04-13 13:11:41] <pecigonzalo> if you dont want to use interpolation, you can use what you mentioned before (or a combination of both)
[2017-04-13 13:11:51] <MaxGoh> Okayy
[2017-04-13 13:12:08] <MaxGoh> pecigonzalo: I’m going to play around with the interactive training to get a better feel of Docker
[2017-04-13 13:12:18] <MaxGoh> I just wanna say a huge thank you man.
[2017-04-13 13:12:20] <MaxGoh> Really appreciate.
[2017-04-13 13:12:43] <pecigonzalo> NP! hope you get into it, docker is really cool!
[2017-04-13 13:12:52] <MaxGoh> I am definitely getting into it
[2017-04-13 13:12:56] <MaxGoh> Nothing’s gonna stop me haha!
[2017-04-13 14:42:28] <autosquid> hi, I have a program written and tested on mac, and now I want to make it easy to distribute -- can docker help in this case?
[2017-04-13 14:46:32] <pecigonzalo> I theory, ye
[2017-04-13 14:46:32] <pecigonzalo> s
[2017-04-13 14:46:36] <pecigonzalo> but its not a given
[2017-04-13 14:46:43] <pecigonzalo> what is the program written on?
[2017-04-13 14:46:58] <autosquid> mac
[2017-04-13 14:47:07] <pecigonzalo> Mac is the OS, but what language
[2017-04-13 14:47:15] <autosquid> a mix of python and c++
[2017-04-13 14:48:04] <pecigonzalo> Honestly, its a really broad question, in general Docker can help you either distribute it inside a docker image or at least compile it for different platforms.
[2017-04-13 14:48:08] <autosquid> when writing the program, I considered how to build it on osx, which makes it hard to transport to linux/windows
[2017-04-13 14:48:32] <pecigonzalo> If you are using OSX specific things, then no, docker is not going to help "transport" that
[2017-04-13 14:49:02] <autosquid> Indeed, there is something specific to OSX
[2017-04-13 14:49:19] <pecigonzalo> Then AFAIK docker is not going to magically "solve" that
[2017-04-13 14:49:30] <pecigonzalo> maybe someone else knows different
[2017-04-13 14:49:35] <autosquid> so I am wondering if there is something like an "osx image"?
[2017-04-13 14:50:04] <autosquid> so that I can build the program based on the "osx image"
[2017-04-13 14:51:20] <pecigonzalo> No, unfortunately not at this time as far as i know, OSX also has a different kernel and this complicates things
[2017-04-13 14:55:11] <autosquid> even for docker for Mac?
[2017-04-13 14:55:28] <pecigonzalo> docker for mac, unless something changed, uses a linux vm to run docker
[2017-04-13 14:56:12] <autosquid> aha, I see.
[2017-04-13 14:57:00] <autosquid> xhyve runs a linux vm though it is for osx.
[2017-04-13 14:57:03] <andyneff> So "docker for mac" will allow you to run a linux specific docker image. So if you can convert your code to a linux specific image, then docker will help you
[2017-04-13 14:59:38] <autosquid> got it. Thanks!
[2017-04-13 15:00:49] <autosquid> I though "docker for mac" would run a vm with the same kernel as the host.
[2017-04-13 15:00:56] <autosquid> I was wrong
[2017-04-13 15:09:14] <andyneff> Unfortunately, no. I had high hopes when the BSD added the linux support, that MAYBE someday Mac OSX would too. But it looks unlikely.
[2017-04-13 18:56:49] <rcreasey> So I have a really odd problem.  I use docker to do different build chain compiles (ie: i have a container with gcc 4.1 and another with 4.8).  Those containers run on my build host that has an autofs mount to remote artifact storage (build artifacts go here)
[2017-04-13 18:57:17] <rcreasey> when I run the my buildchain container, it will volume mount onto the host's autofs mount point
[2017-04-13 18:58:06] <rcreasey> On rare occasions I've had my builds fail becausedocker: Error response from daemon: mkdir /mnt/artifacts: file exists
[2017-04-13 18:58:33] <rcreasey> presumably because i'm doingdocker run -v /mnt/artifacts:/artifacts gcc4.1chain build
[2017-04-13 18:59:32] <rcreasey> and docker seems to want to try and create the path if it doesn't exist when the command is executed
[2017-04-13 20:10:55] <etsuo> hi, is there a way to block a specific container from sending smtp?
[2017-04-13 21:30:57] <dragon788> etsuo: probably firewall it with iptables
[2017-04-13 22:17:51] <etsuo> dragon788: thanks for the feedback - the problem is that these containers are being managed by AWS ECS - they get launched dynamically on demand and they might get moved around… I need some way of defining on the container itself that it should block outbound port 25… it looks like —cap-add with the right options might have given me the ability to turn on IP tables within the container… but that’s not supported by AWS ECS for some insane reason
[2017-04-13 22:28:10] <SISheogorath> etsuo: doesn't ECS also allow security groups?
[2017-04-13 22:29:01] <etsuo> SISheogorath: yes, the problem is that’s all or nothing… I need to constrain a set of containers in the cluster to disallow them from using port 25 while not blocking the other containers
[2017-04-13 22:32:45] <etsuo> what’s crazy is that AWS didn’t implement the —cap-add flags, but the went ahead and gave us —privileged… but that just seems foolish to run that on a production container to get iptables access so I can secure the container from sending smtp… so to prevent smtp, I make my container less secure… ?? thanks amazon
[2017-04-15 12:14:34] <yuvgeek> how to deploy the newly pushed code hosted at GitHub to our production server ?
[2017-04-15 14:55:02] <SISheogorath> YuvarajMe: that's something you have to define in your deployment process.Depending on what your setup looks like you may want to use TravisCI, circleCI Docker hub, Docker Cloud, ... In combination with Ansible, SaltStack, Puppet, Chef or a Shell script with SSH, ...
[2017-04-15 15:43:16] <dancancro> Is this statement above true? "This chat is intended for contributors new to the Docker project or new to open source. For user help, please goto #docker on freenode. "I tried to get into #docker on freenode.net and got this: "#docker Cannot join channel (+r) - you need to be identified with services"
[2017-04-15 16:13:31] <yuvgeek> SISheogorath: Oh. thanks
[2017-04-15 16:15:54] <yuvgeek> I can't install Node v6 in ubuntu. Everytime i runapt-get install -y nodejs, it installs v4.
[2017-04-15 16:16:09] <yuvgeek> This is my Dockerfile
[2017-04-15 16:16:42] <yuvgeek> FROM ubuntu:16.04RUN apt-get update && apt-get install -y --no-install-recommends apt-utils \\    curl && \\    curl -sL https://deb.nodesource.com/setup_6.x | bash - && \\    apt-get install -y nodejs \\    npmADD . /var/www/htmlWORKDIR /var/www/htmlRUN npm installEXPOSE 80`
[2017-04-15 18:57:05] <Csini> YuvarajMe:  [<-LINK->] 
[2017-04-15 19:37:20] <yuvgeek> Csini: Tried those but not working. Ended up using nvm.
[2017-04-15 21:03:57] <MaxGoh> Hey guys, how can i create a docker-compose file to link up nginx and my dist folder?
[2017-04-15 21:04:01] <MaxGoh> It’s 2 different container yeah
[2017-04-15 22:20:38] <SISheogorath> YuvarajMe: why not use node as base image?
[2017-04-15 22:21:03] <SISheogorath> MaxGoh: two different containers who use the same data?
[2017-04-15 22:21:24] <MaxGoh> SISheogorath: I’m assuming to use one container for nginx, another for angular
[2017-04-15 22:21:32] <MaxGoh> and I want to then copy my angular dist files to the nginx folder
[2017-04-15 22:21:47] <MaxGoh> am I right to do that?
[2017-04-15 22:21:56] <MaxGoh> and hopefully from there, i can use elastic-beanstalk to deploy
[2017-04-15 22:28:15] <SISheogorath> MaxGoh: I would recommend you to build the angular App duringdocker buildprocess. As angular doesn't provide any server-side code, so put it into an own container makes only sense as long as you want to develop and rebuild it on the fly
[2017-04-15 22:28:44] <MaxGoh> SISheogorath: I’m using docker-compose to develop locally
[2017-04-15 22:28:51] <MaxGoh> which is working pretty nicely for now
[2017-04-15 22:28:55] <MaxGoh> and I don’t need nginx for it
[2017-04-15 22:29:01] <MaxGoh> but I wanna use docker in my ec2 instance
[2017-04-15 22:29:14] <MaxGoh> and entire flow from gitlab-ci to elastic beanstalk
[2017-04-15 22:30:47] <SISheogorath> For a productive setup build your app in your final image, containing the webserver
[2017-04-15 22:31:09] <MaxGoh> docker-compose build?
[2017-04-15 22:31:11] <MaxGoh> or docker build?
[2017-04-15 22:31:19] <SISheogorath> Docker build
[2017-04-15 22:31:23] <MaxGoh> because it’s going to be a multi container
[2017-04-15 22:31:29] <MaxGoh> shouldn’t it be docker-compose?
[2017-04-15 22:31:50] <MaxGoh> wait, am I being correct to use multiple container? one for nginx one for angular?
[2017-04-15 22:31:56] <MaxGoh> or should i merge them together
[2017-04-15 22:34:34] <SISheogorath> You should do it similar to this: [<-LINK->] 
[2017-04-15 22:35:17] <SISheogorath> It's an example Dockerfile to build a Jekyll webpage on the nginx image to provide it in production
[2017-04-15 22:35:34] <MaxGoh> but i need to build my files first
[2017-04-15 22:35:37] <MaxGoh> using ng build
[2017-04-15 22:35:46] <MaxGoh> so that dist can be generated
[2017-04-15 22:36:34] <SISheogorath> That's what I do in this dockerfile for Jekyll
[2017-04-15 22:36:52] <MaxGoh> you copy . /app
[2017-04-15 22:37:04] <MaxGoh> but dont’ i have to
[2017-04-15 22:37:10] <MaxGoh> npm install && ng build?
[2017-04-15 22:37:12] <MaxGoh> hm
[2017-04-15 22:37:26] <SISheogorath> Because it's Jekyll not angular
[2017-04-15 22:37:32] <SISheogorath> And app are the sources
[2017-04-15 22:38:29] <SISheogorath> I only wanted to show you the basic concept
[2017-04-15 22:38:37] <MaxGoh> understood
[2017-04-15 22:38:47] <MaxGoh> so should i have another docker container to build my angular app?
[2017-04-15 22:39:52] <SISheogorath> No, do it during the build process inside your Dockerfile and base it on nginx
[2017-04-16 05:12:43] <MaxGoh> SISheogorath: sorry, so I have to install node and nginx in the same dockerfile?
[2017-04-16 06:51:58] <yuvgeek> Which is best approach? git clone in docker file or ?
[2017-04-16 06:52:41] <yuvgeek> SISheogorath: Ubuntu 16.04 is my base image
[2017-04-16 07:40:47] <thebuccaneersden> nice. I finally got a fully end to end pass of docker container that gets built through travis ci for the armhf arch and automatically tagged and pushed to dockerhub. that was a fun challenge, but I’m wondering if there is a general convention that the community follows? or does everyone have their own unique way of doing this (automating bulding of docker containers and automatically pushing them to dockerhub on build success)?
[2017-04-16 09:26:00] <SISheogorath> thebuccaneersden: as sad as it is, there is no really common way to do it. Feel free to share yours it you want
[2017-04-16 09:28:45] <SISheogorath> YuvarajMe: maybe check out [<-LINK->] way more useful than Ubuntu as base image and improves caching
[2017-04-16 09:32:26] <SISheogorath> And it highly depends on what you are about to do. Having Dockerfile and sources in they same repository is very nice. In this case copy the sources. If you have separated repositories, use git clone or install tarballs (official best practices) of releases.
[2017-04-16 09:38:05] <SISheogorath> MaxGoh: as you need NodeJS only to build your application, install all needed packages and also NodeJS into your container, which is based on nginx. Build your application, copy the build results into/var/www/html/and delete the source directory. Also delete NodeJS and clean the package cache. At the end (docker diff) only the/var/www/htmldirectory should have changed (containing your application)
[2017-04-16 11:44:13] <yuvgeek> SISheogorath: When we clone from GitHub repo in Dockerfile, it has to be re-build..so what happen at the down time?
[2017-04-16 11:44:34] <yuvgeek> because when container is already running, we have to stop and re-create
[2017-04-16 11:45:05] <yuvgeek> those down time when we clone and build the new docker image?
[2017-04-16 11:45:25] <MaxGoh> Um you guys know how to deploy from gitlab CI to AWS EC2?
[2017-04-16 11:45:28] <MaxGoh> for docker
[2017-04-16 11:48:57] <SISheogorath> YuvarajMe: it's mostly about sharing layers between your nodes. Also you can very easy specify what exact version you want to install. The official best practice says you should use the language your application is written in as base container, if one is available for it. Reasons: 1. You can update the version by changing the from line 2. They are kept up-to-date but without breaking 3. base image is cached so if you run 10 applications using node:6.10 you only download it once. Results in smaller images
[2017-04-16 11:50:22] <SISheogorath> MaxGoh: depends on your setup. Is it a single host? A swarm? A K8s cluster? A K8s Cluster managed by Amazon?
[2017-04-16 11:50:36] <MaxGoh> SISheogorath: just a simple nginx haha
[2017-04-16 11:50:43] <MaxGoh> Not that advanced to use stuffs like swarm
[2017-04-16 11:51:04] <SISheogorath> MaxGoh: I was talking about the EC2 instance not what you are about to deploy xD
[2017-04-16 11:51:15] <MaxGoh> oops
[2017-04-16 11:51:19] <MaxGoh> Is there differences?
[2017-04-16 11:51:24] <MaxGoh> I’m just using the normal instance ubuntu 16.04
[2017-04-16 11:51:30] <SISheogorath> Ah okay
[2017-04-16 11:52:25] <SISheogorath> Well, first of all are you using docker-compose on your instance?
[2017-04-16 11:52:31] <MaxGoh> that’s right! :)
[2017-04-16 11:52:41] <yuvgeek> SISheogorath: I wasn't talking about Node
[2017-04-16 11:53:06] <SISheogorath> YuvarajMe: same applies to python, go, ruby, ...
[2017-04-16 11:53:23] <SISheogorath> MaxGoh: You can use a shellscript or ansible
[2017-04-16 11:53:32] <MaxGoh> I’m using gitlab
[2017-04-16 11:53:40] <MaxGoh> shell script as in bash script?
[2017-04-16 11:53:44] <SISheogorath> yes
[2017-04-16 11:54:00] <MaxGoh> what would i DO WITH THAT? O.O
[2017-04-16 11:54:42] <MaxGoh> oops
[2017-04-16 11:54:47] <MaxGoh> what would I do with that? as in
[2017-04-16 11:54:51] <MaxGoh> install aws cli or something?
[2017-04-16 11:54:53] <SISheogorath> simply use something to ssh to your machine and pull the git repository containing your updated docker-compose file (for the new version you want to deploy) rundocker-compose  pull && docker-compose up -d
[2017-04-16 11:54:59] <MaxGoh> I’m using GItlab CI
[2017-04-16 11:55:09] <SISheogorath> doesn't matter
[2017-04-16 11:55:13] <MaxGoh> is there a way for me to do a push to git, and CI/CD?
[2017-04-16 11:55:23] <SISheogorath> O.o
[2017-04-16 11:55:29] <yuvgeek> We use docker-compose to create container. Container per service. So, Apache/nginx uses 1 container, mysql uses another container. We use gitlab CI. Suppose if we make changes in Dockerfile and code repo and pushing a code to gitlab, it will perform the build test and in deploy it will  create new images and pushes to dockerRegistry.
[2017-04-16 11:55:57] <yuvgeek> Through web hook, we tell our production server running to rebuild the image with changed source code
[2017-04-16 11:56:17] <SISheogorath> YuvarajMe: oh wait I think I mixed up conversations in my head :D sry ^^
[2017-04-16 11:56:58] <yuvgeek> Generally, we will stop the running container and pull the latest image from registry and rebuild it. So, when we use git clone..it will take time during the build process.
[2017-04-16 11:57:07] <MaxGoh> I’m confused haha
[2017-04-16 11:57:10] <yuvgeek> Meanwhile, our app will go down right? Downtime.
[2017-04-16 11:57:12] <MaxGoh> Which message is to who now.
[2017-04-16 11:57:29] <yuvgeek> SISheogorath: Yeah..thats why i am explaining you clearly.
[2017-04-16 11:57:38] <yuvgeek> Hope you understood atleast now :D
[2017-04-16 11:57:59] <yuvgeek> hey@MaxGoh, how do you deploy from gitlab ci?
[2017-04-16 11:58:05] <SISheogorath> YuvarajMe: you shouldn't rebuild the image. You should use the same image you tested in your production because a newly build image is not proven to work
[2017-04-16 11:58:28] <SISheogorath> And you can pull before for you stop the container :D
[2017-04-16 11:58:36] <SISheogorath> that would minimize the downtime
[2017-04-16 11:58:39] <yuvgeek> SISheogorath: Gitlab CI runs that test.
[2017-04-16 11:58:41] <MaxGoh> do you guys mind explaining a proper deployment flow?
[2017-04-16 11:58:54] <yuvgeek> but still it is a down time right
[2017-04-16 11:59:09] <SISheogorath> if you want to eliminate the downtime completely you should run docker swarm with more than 1 instance of your application
[2017-04-16 11:59:36] <yuvgeek> Docker swarm for mid level apps?
[2017-04-16 11:59:58] <SISheogorath> YuvarajMe: you need it if you want 0 downtime
[2017-04-16 12:00:43] <yuvgeek> MaxGoh: do you use CI? if so, once it goes to deploy stage, you have to push the new image and trigger the production server through hook to apply new changes.
[2017-04-16 12:00:55] <yuvgeek> SISheogorath: Ahh
[2017-04-16 12:01:43] <SISheogorath> YuvarajMe: the problem is that when you recreate the container it works like a restart of a regular application. There you have also downtime on restart :D
[2017-04-16 12:01:43] <yuvgeek> is that correct approach cloning our source code in docker image?
[2017-04-16 12:02:10] <yuvgeek> Yea i understood@SISheogorath.
[2017-04-16 12:02:29] <SISheogorath> YuvarajMe: as already mentioned it depends. I personally prefer copy when I keep the Dockerfile in the same repository as the source code
[2017-04-16 12:03:00] <yuvgeek> where you hosted your source repo?
[2017-04-16 12:03:40] <msgeissler> hey everyone,can someone give me a hand with the docker-compose format?I have the following compose file [<-CODE->]  [<-CODE->] I just can't find the reason for the error
[2017-04-16 12:03:48] <SISheogorath> reason: Versioncontrol. The Dockerfile and the sources stay in the same commit and it's better to copy the source inside because you don't need to reference it during your build process.
[2017-04-16 12:05:12] <SISheogorath> msgeissler: use [<-CODE->] 
[2017-04-16 12:05:24] <SISheogorath> not with dash
[2017-04-16 12:06:31] <yuvgeek> yeah.. our code hosted in gitlab and GitHub. We have Dockerfile along with source code. Also we have some files in .gitignore. how should we handle this approach? bringing source code from gitlab/github to our production server along with files which are in gitignore
[2017-04-16 12:06:34] <SISheogorath> YuvarajMe: on Github? But as I use a lot of software not written by me I have a lot of repositories whom are separated from the original sources, there I clone the sources during build process
[2017-04-16 12:06:39] <msgeissler> still the same error :(@SISheogorath
[2017-04-16 12:07:28] <msgeissler> official documentation is sadly only showing version 2 examples in the version 3 reference documentation
[2017-04-16 12:08:46] <msgeissler> but other examples I have found online using version 3 show the dash notation
[2017-04-16 12:09:27] <SISheogorath> msgeissler: can you check this: [<-LINK->] 
[2017-04-16 12:09:49] <msgeissler> the Example Compose file version 3 [<-LINK->] shows the dash variant as well
[2017-04-16 12:11:20] <msgeissler> SISheogorath: your snippet gives me the same error
[2017-04-16 12:11:53] <msgeissler> I am using Docker version 17.03.1-ce, build c6d412e btw
[2017-04-16 12:13:35] <msgeissler> 17.04.0-ce does not seem to be available for ubuntu xenial yet
[2017-04-16 12:14:31] <SISheogorath> YuvarajMe: O.o I don't see your problem. Your application should be build like you do normally and be configured by environment variables which configure your docker container once it's landed in production.
[2017-04-16 12:15:31] <SISheogorath> msgeissler: yes, to be honest I tried it like this a few times, always ended up in an error message so I droped it and always use thenetworkname:way.
[2017-04-16 12:16:11] <msgeissler> so it would be worth creating an issue for this?
[2017-04-16 12:16:41] <msgeissler> SISheogorath: do you have an example for the usage of networkname? I can't find it in the docker compose reference
[2017-04-16 12:17:22] <SISheogorath> msgeissler: I found the issue :D
[2017-04-16 12:17:24] <SISheogorath>  [<-LINK->] 
[2017-04-16 12:17:30] <SISheogorath> check the last change ^^
[2017-04-16 12:18:03] <SISheogorath> you setnetworkone level too deep
[2017-04-16 12:18:49] <msgeissler> oh shi*
[2017-04-16 12:19:24] <msgeissler> SISheogorath: thanks a bunch, I probably would have wasted a ton more hours before I would have noticed that :D
[2017-04-16 12:19:43] <SISheogorath> you're welcome ^^
[2017-04-16 12:20:02] <yuvgeek> Okay
[2017-04-16 12:21:07] <SISheogorath> YuvarajMe: maybe you can file an example then I can suggest something
[2017-04-16 12:23:02] <yuvgeek> Can you be bit more clear?
[2017-04-16 12:30:08] <SISheogorath> well, where you are unsure about cloning the repository vs.COPYin dockerfile
[2017-04-16 15:55:36] <MaksimKiselev> Hi guys. What you are use for reverse proxy?
[2017-04-16 16:07:42] <thebuccaneersden> I more often than not use varnish@MKiselev, but sometimes haproxy
[2017-04-16 16:59:19] <SISheogorath> MKiselev: Traefik is nearly perfect if you want to use it with docker. And also take a look at jwilders nginx image. HAproxy is also use by rancher for their setup iirc.
[2017-04-16 17:01:23] <thebuccaneersden> havent played with traefik. heard nice things about it recently, but cant recommend without trying it
[2017-04-16 17:01:37] <thebuccaneersden> seems like it was made with docker in mind
[2017-04-16 17:02:45] <SISheogorath> thebuccaneersden: yes, made as API based proxy with dynamic reconfiguration
[2017-04-16 17:07:09] <MaksimKiselev> SISheogorath: @thebuccaneersdenyep, right now we use nginx-proxy... But today I was found Traefik project and wanted to know who what use more. Maybe Traefik has killer features vs nginx-proxy.
[2017-04-16 17:12:37] <thebuccaneersden> oh ya, i forgot about nginx as well, the swiss army tool of do whatever you want
[2017-04-16 17:14:05] <thebuccaneersden> well, hard to say. the thing that would strike me is that traefik is a younger project, so it may have better features, but at the same time, hasnt been tested out in the wild for as long
[2017-04-16 17:23:54] <msgeissler> I used nginx-proxy in the past for my private projects ( [<-LINK->] ) but recently swtiched to traefik as well
[2017-04-16 17:36:19] <SISheogorath> MKiselev: I would hardly recommend Traefik as it provides automatically reconfigure itself based on docker API along with let's encrypt and more
[2017-04-16 19:38:59] <msgeissler> it also works with docker swarm, although it seems like it is buggy (i.e. gitlab generates wrong avatar and project logo URLs in swarm mode with traefik)but the letsencrypt support works like a charm (so far)
[2017-04-16 20:42:54] <msgeissler> huh, did some more testing, looks like the URL problem isn't traefik's fault after allgitlab is buggy deployed on swarm, so go ahead and use traefik for docker swarm :)
[2017-04-16 22:13:16] <thebuccaneersden> gitlab is buggy in general imo
[2017-04-16 22:13:30] <thebuccaneersden> is why i decided to go with gogs (or gitea, a fork)@msgeissler
[2017-04-16 22:18:28] <thesamet> docker on mac trick question: is there any way to make a container mount a directory on the docker VM? It would be nice to have some directory on the VM to be persisted between runs, since filesystem access between docker and the mac is really slow
[2017-04-16 22:18:57] <thebuccaneersden> volumes: ?
[2017-04-16 22:20:02] <thebuccaneersden>  [<-LINK->] 
[2017-04-16 22:20:05] <thebuccaneersden> thesamet: 
[2017-04-16 22:21:45] <thesamet> thebuccaneersden: this is showing how to mount a directory from the Mac OS filesystem, not from the Docker VM.
[2017-04-16 22:22:23] <thebuccaneersden> so you want to mount a directory from the docker container to the host?
[2017-04-16 22:25:46] <thesamet> On Mac, docker runs a Linux virtual machine which is where the docker daemon actually runs. I want to make a directory on that virtual machine available to a container.
[2017-04-16 22:36:31] <thebuccaneersden> thesamet: Are you running an old version of docker-engine on the mac? Because, docker no longer requires virtual box and supports native virtualization called hyperkit
[2017-04-16 22:36:32] <thebuccaneersden>  [<-LINK->] 
[2017-04-16 22:36:45] <thebuccaneersden> just curious
[2017-04-16 22:37:28] <thebuccaneersden> whether you are still using virtualbox or native virtualization
[2017-04-16 22:39:42] <thesamet> native virtualization.
[2017-04-16 22:41:18] <thebuccaneersden> sorry. i guess i assumed that with native virtualization, the vm was transparent and you can use docker as if you were on linux. no need to thinking of a vm as a middle man. am i wrong in this assumption? (i will give it a test later)
[2017-04-16 22:47:28] <thesamet> There's an actual VM, though it's very light weight.
[2017-04-16 22:47:52] <thesamet> Apparently it allocates 60GB for disk.
[2017-04-16 22:48:08] <thesamet> Here is a command to get into it:docker run -it --privileged --pid=host debian nsenter -t 1 -m -u -n -i sh
[2017-04-16 22:48:21] <thesamet> FWIW, I can probably solve for my use case with named volumes.
[2017-04-16 22:48:29] <thebuccaneersden> oh i know, but i assumed it was more like hyperv virtualization, where it doesn’t require fulkl paravirtualization
[2017-04-17 11:08:57] <MaksimKiselev> Hi guys. I try to add letsencrypt for my nginx-proxy which installed globally.I found goo sample for docker compose https://github.com/fatk/docker-letsencrypt-nginx-proxy-companion-examples/blob/master/docker-compose/v2/simple-site/docker-compose.ymlBut I can't understand some things....
[2017-04-17 11:54:10] <SISheogorath> Wow that's super complicated .-. you use one container to generate nginx configs, one to serve TLS and jwilder's to reverse proxy everything. I would suggest you to use Traefik it's a hundred times simpler .-.
[2017-04-17 11:55:24] <SISheogorath>  [<-LINK->] see theproxyservice... That's all you need
[2017-04-17 12:41:48] <MaksimKiselev> SISheogorath: I reconfigure now globally nginx proxy container and now that's work.... 
[2017-04-17 12:51:45] <MaksimKiselev> Oh shi~. But how off ssl encrypt 4 some containers?
[2017-04-17 13:25:57] <jbelmont> Hello All
[2017-04-17 13:26:58] <andyneff> Hello@jbelmont
[2017-04-17 13:27:16] <jbelmont> I am trying the following docker.compose.yml [<-CODE->] and Dockerfile [<-CODE->] 
[2017-04-17 13:27:31] <jbelmont> sorry for the long post here
[2017-04-17 13:27:56] <jbelmont> I keep getting connection refused with couchdb when I run with docker
[2017-04-17 13:28:21] <jbelmont> error:  Error: connect ECONNREFUSED 127.0.0.1:5984
[2017-04-17 13:28:53] <jbelmont> I am using node.js and wrapper library called nano for Couchdb
[2017-04-17 13:29:08] <jbelmont> Anyone here know how to fix this possible issue
[2017-04-17 13:31:44] <andyneff> I think your nodejs is trying to access the DB locally. When it needs to point to the other docker instead.
[2017-04-17 13:33:08] <jbelmont> andyneff: so I am doing the following commandsdocker-compose builddocker-compose up
[2017-04-17 13:33:53] <andyneff> It's a problem with your nodejs setup. It needs to access the DB on hostnamedb
[2017-04-17 13:34:33] <jbelmont> here is my db setup [<-CODE->] 
[2017-04-17 13:35:10] <jbelmont> so is the hardcoded value in the nano call the problem@andyneff
[2017-04-17 13:35:20] <andyneff> So I'm guessing line 3 needs to say db instead of 127.0.0.1
[2017-04-17 13:35:52] <andyneff> That's how it's done [here](
[2017-04-17 13:36:42] <andyneff>  [<-LINK->] 
[2017-04-17 13:38:14] <jbelmont> so@andyneffconst nano = require('nano')(‘db’);are you saying I need to update to this
[2017-04-17 13:40:02] <andyneff> const nano = require('nano')(‘ [<-LINK->] );
[2017-04-17 13:43:17] <jbelmont> so I updated it to that and see this now
[2017-04-17 13:55:18] <jbelmont> db_1   | [info] [<0.105.0>] 172.18.0.3 - - PUT /softwaretesting 401db_1   | [error] [<0.150.0>] Could not open file /usr/local/var/lib/couchdb/softwaretesting.couch: no such file or directorydb_1   | [info] [<0.106.0>] 172.18.0.3 - - GET /softwaretesting/users 404web_1  | error:  Error: no_db_file
[2017-04-17 13:55:48] <jbelmont> it is a different message
[2017-04-17 14:01:13] <andyneff> Don't know anything about couchdb and I'm not near a computer ;-)
[2017-04-17 14:02:13] <jbelmont> andyneff: I appreciate you helping me though thanks, will look into this more
[2017-04-17 14:52:36] <SISheogorath> jbelmont: in general you have to use the docker internal networking. Thumb-rules: [<-CODE->] 
[2017-04-17 14:57:09] <SISheogorath> Also remember that the docs for your couchdb image says it is created in [<-LINK->] . So you have to create the database with our application or by hand if you expose the port (wich you don't do)
[2017-04-17 16:05:06] <andyneff> thesamet: , I believe what you want to do is create a data volume. I do this on docker for Windows all the time to get speed back.
[2017-04-17 16:23:35] <andyneff>  [<-LINK->] 
[2017-04-17 16:40:42] <jbelmont> SISheogorath: thanks for those pointers, yeah I am still trying to learn docker and I will look at the docs again
[2017-04-17 16:41:53] <jbelmont> SISheogorath: so could I doEXPOSE 5984in theDockerfile
[2017-04-17 16:42:26] <SISheogorath> jbelmont: you actually don't need theEXPOSEstatement
[2017-04-17 16:43:15] <SISheogorath> EXPOSE is mainly used when you do things likedocker run -Pwhich I never did because why should I want to provide a random port?
[2017-04-17 16:44:45] <jbelmont> SISheogorath: where should I expose the port in thedocker-compose.yml?
[2017-04-17 16:45:13] <SISheogorath> But yes, I add it to my containers to because it allows you to show possible used ports indocker pseven if you lack in documentation
[2017-04-17 16:45:31] <SISheogorath> jbelmont: yes. use theports:section
[2017-04-17 16:46:11] <SISheogorath> but only if you want to expose them. Otherwise ignore it. As you don't need it for internal networking
[2017-04-17 16:46:16] <andyneff> jbelmont: You only need to expose your nodejs port. You don't need to expose the db port. dockers on the same network can already see each other's ports
[2017-04-17 16:46:49] <SISheogorath> andyneff: the problem is that he has to create the database when using this couchdb image
[2017-04-17 16:47:09] <SISheogorath> and that's why I mentioned that he possibly has to expose the database port to create it
[2017-04-17 16:47:10] <andyneff> nodejscan already see all the ports in thedbcontainer without usingexpose
[2017-04-17 16:47:34] <jbelmont> here is mydocker-compose.yml [<-CODE->] 
[2017-04-17 16:48:09] <SISheogorath> delete the second ports line, you don't need it
[2017-04-17 16:48:26] <jbelmont> okay
[2017-04-17 16:48:36] <SISheogorath> IF you want to expose the port, you have to do that underneath thedbsection
[2017-04-17 16:49:17] <andyneff> Also , youmaywant"COUCHDB_HTTP_BIND_ADDRESS=0.0.0.0"if you are using that feature.
[2017-04-17 16:49:20] <jbelmont>  [<-CODE->] 
[2017-04-17 16:49:22] <SISheogorath> but as already mentioned you only need to do this if you want to create the database by hand. Otherwise simply make your NodeJS app create the database if it doesn't exists
[2017-04-17 16:49:24] <jbelmont> like this
[2017-04-17 16:49:37] <SISheogorath> yes
[2017-04-17 16:49:53] <SISheogorath> but delete it after you setup the database
[2017-04-17 16:49:59] <jbelmont>  [<-CODE->] 
[2017-04-17 16:50:11] <SISheogorath> .-.
[2017-04-17 16:50:14] <jbelmont> so I am creating the database in a file called db.js in my node app
[2017-04-17 16:50:55] <andyneff> jbelmont: for your scenraio, creating the db inside the node app, you do not need to expose the 5984 port. italready workswithout using expose
[2017-04-17 16:52:29] <jbelmont> so do you meanconst nano = require('nano')('http://db');something like this
[2017-04-17 16:53:01] <jbelmont> I tried running without specifying the port and I was getting connection refused
[2017-04-17 16:54:19] <andyneff> So if thedbcontainer  is binding to127.0.0.1I don't think it will work. ( I could be wrong here). I'd have it bind to0.0.0.0so it binds to all IP address, which will include whatever network IP it is given (which is usually a 172.x.y.z).
[2017-04-17 16:56:03] <andyneff> So ifCOUCHDB_HTTP_BIND_ADDRESSis for some website admin page that has nothing to do with how the database works, then it doesn't matter. But ifCOUCHDB_HTTP_BIND_ADDRESSis for the database that server on 5894, then it does matter.
[2017-04-17 16:57:29] <andyneff> Like@SISheogorathwas saying earlier, the containers still need to talk to each other just like servers do. Servers don\'t talk to each other via localhost(127.0.0.1), they have to use the other IP address. and0.0.0.0simple means "use all of them" inside of the container.
[2017-04-17 17:01:09] <jbelmont> sorry for ignorance here@andyneffto bind should I doconst nano =require(‘nano’)(‘http://0.0.0.0');
[2017-04-17 17:01:33] <andyneff> No I was talking about the setting in docker-compose.yml
[2017-04-17 17:02:17] <andyneff>  [<-CODE->] 
[2017-04-17 17:02:25] <jbelmont> ah okay
[2017-04-17 17:02:48] <jbelmont> well then what shouldconst nano = require('nano')('http://db');this line become
[2017-04-17 17:03:12] <andyneff>  [<-CODE->] 
[2017-04-17 17:03:35] <andyneff> I believe
[2017-04-17 17:04:58] <jbelmont> okay and should I keep the ports section in docker-compose.yml [<-CODE->] 
[2017-04-17 17:05:37] <andyneff> It would be useful for you to keep it during development, and remove it during production.
[2017-04-17 17:06:29] <jbelmont> okay
[2017-04-17 17:06:50] <andyneff> Well, I gotta hop on a plane in a sec. Anyone going to be in Austin tonight/tommorrow?
[2017-04-17 17:07:15] <jbelmont> cool many thanks to@andyneffand@SISheogorathfor helping me I appreciate it
[2017-04-17 17:14:12] <SISheogorath> andyneff: Me not but I hope you'll meet a lot of awesome people there :)
[2017-04-17 17:50:49] <yuvgeek> yarn command not found
[2017-04-17 17:51:08] <yuvgeek> same as for npm. NPM command not found
[2017-04-17 18:28:33] <ael-g> Hi Guys! Just a non-code related question: We have AWS ECS, GKE for Kubernetes, isn't there a Swarm As a Service service out there somewhere?
[2017-04-17 18:28:50] <ael-g> With persistent volume configured?
[2017-04-17 18:29:46] <ael-g> You just come to the cluster with a docker compose file, anddocker stack deployit ?
[2017-04-17 19:12:39] <SISheogorath> ael-g: I'm pretty sure someone was talking about it in the [<-LINK->] but can't say it for sure.
[2017-04-17 19:15:01] <SISheogorath> YuvarajMe: do you still try to create a dockerfile for your app? Is it the one you have on github?
[2017-04-17 20:40:39] <paulius005>  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2017-04-17 20:42:52] <paulius005> weird part is that it's able to load assets [<-LINK->] 
[2017-04-17 20:45:42] <SISheogorath> paulius005: usually it has a gateway, wondering why yours doesn't have one
[2017-04-17 20:49:04] <paulius005> SISheogorath: would that possibly result in the issues Im running into?
[2017-04-17 20:49:50] <paulius005> Im starting up my server using/usr/local/bin/docker-compose -f /docker-compose/docker-compose.yml up -d
[2017-04-17 20:50:17] <paulius005> although the bridge is setup independent of that
[2017-04-17 20:51:11] <SISheogorath> I'm not sure. what doesip r sshow inside the container
[2017-04-17 20:52:51] <paulius005>  [<-CODE->] 
[2017-04-17 20:56:09] <SISheogorath> andnslookup google.com
[2017-04-17 20:56:58] <paulius005> SISheogorath: from the container?
[2017-04-17 20:57:13] <SISheogorath> yes
[2017-04-17 20:57:53] <paulius005>  [<-CODE->] 
[2017-04-17 20:59:40] <SISheogorath> looks fine, I would say yourDNS_PROBE_FINISHED_NXDOMAINis from somewhere else
[2017-04-17 21:00:45] <SISheogorath> where did you get it? in your chrome browser on your Note-/Macbook?
[2017-04-17 21:02:05] <paulius005> yep!
[2017-04-17 21:03:07] <paulius005> if you go toec2-52-53-84-186.us-west-1.compute.amazonaws.com
[2017-04-17 21:03:11] <paulius005> you should be able to reproduce
[2017-04-17 21:30:26] <SISheogorath> Yes I am. You're problem is not related to docker. It's a normal DNS error. I'm not completely sure about the full issue but it's related to how your DNS requests are answered
[2017-04-17 21:30:52] <paulius005> thanks a lot@SISheogorath
[2017-04-17 21:31:11] <SISheogorath> it works fine as long as you use 8.8.8.8. you should research this. [<-CODE->] 
[2017-04-17 21:40:33] <paulius005> woahh
[2017-04-17 21:42:13] <paulius005> btw sorry changes to ec2-54-241-135-70.us-west-1.compute.amazonaws.com
[2017-04-17 21:42:19] <paulius005> took one of the boxes down
[2017-04-17 21:42:23] <paulius005> either way
[2017-04-17 21:42:46] <paulius005> I really appreciate your help :)
[2017-04-17 21:57:21] <SISheogorath> You're welcome
[2017-04-18 00:21:57] <alexeydemin>  [<-CODE->] I have read tons of manuals and still can't grasp how to run services in a running container automatically. Now I have to attach to each and run it manually.
[2017-04-18 00:22:21] <alexeydemin> Hi, first of all.
[2017-04-18 00:32:29] <realisation> Can anyone give me some momentary support on spinning up a mongodb docker container?
[2017-04-18 00:33:09] <realisation> I'm trying to figure out how to access the mongo cli from my command line
[2017-04-18 00:35:17] <thebuccaneersden> you could try going into your container and working with mongo directly from there? ie. typedocker psto see a list of all your containers, find the CONTAINER ID for your mongo container, then executedocker exec -i -t <CONTAINER ID> /bin/bashreplacing<CONTAINER ID>with the actual container id (a hash likecdd536e1fb5f).
[2017-04-18 00:35:20] <thebuccaneersden> realisation: 
[2017-04-18 02:55:17] <realisation> thebuccaneersden: Thanks!
[2017-04-18 02:55:25] <realisation> I'm working with a container that has an entry-point
[2017-04-18 02:55:51] <realisation> but/bin/bashwould usually spin up a shell executing inside that particular container ?
[2017-04-18 03:24:36] <andyneff> Whatever yourCMDis gets runs when a docker image is run. Many base images set this to bash so you can poke around in the images by default. When an entrypoint is set, this gets run instead. Depending on the "form" used in the dockerfile, eitherSHELL ENTRYPOINTis execute when a container starts, orSHELL ENTRYPOINT CMDis executed.
[2017-04-18 03:26:48] <andyneff> When you usedocker execnone of that matters, and it just executes whatever command you tell it to in a running container.
[2017-04-18 03:41:04] <thebuccaneersden> Yeh@realisationeven if it container has an entry point you can still do this  to get shell access to your running container and poke around and what not
[2017-04-18 06:49:03] <SISheogorath> alexeydemin: you can't start MySQL using the service file. A docker container is not a VM and only stays alive as long as the first process of the container doesn't exit. If you start MySQL using the service file, it forks into background which exits the initial process and end up in a dead container. Check the official [<-LINK->] or [<-LINK->] image on docker hub if you want to know how to run MySQL inside a docker container
[2017-04-18 14:00:52] <intellix> internal power struggle?vieux added shykes to docker/docker  9 minutes ago
[2017-04-18 16:45:06] <yuvgeek> SISheogorath: yea
[2017-04-18 20:25:03] <Hirayuki> Hi guys, I have an issue with docker-storage-setup, it says:INFO: Volume group backing root filesystem could not be determinedERROR: /dev//dev/vdc is not a valid block device.tried taking out everything accept vdc, then even vdc, tried it without any config. any ideas ?
[2017-04-18 21:56:21] <alexeydemin> SISheogorath: thank you for your reply, I read them again, but still didn't find an answer to my question.
[2017-04-18 22:02:04] <SISheogorath> alexeydemin: did you build themls-mysqliyourself? And if so which repository did you use? (if it's open source)
[2017-04-18 22:05:09] <alexeydemin> Yes, that's an exact (I believe so, I mean I did just docker commit for it) copy of the official _/mysql:5.7 container
[2017-04-18 22:08:24] <realisation> thebuccaneersden: thanks! - is there a way I can map my local port 12707 to refer to my mongo docker instance ?
[2017-04-18 22:20:03] <realisation> actually, I'm only wondering that to know if the thing is working at first
[2017-04-18 22:20:41] <realisation> ultimately I'll just have a dockerized mongo DB connected to my dockerized app
[2017-04-18 22:20:58] <realisation> it looks like docker compose takes care of that
[2017-04-18 22:22:43] <thebuccaneersden> useports:in your docker compose service definition
[2017-04-18 22:22:48] <thebuccaneersden> realisation: 
[2017-04-18 22:23:44] <thebuccaneersden> ie. [<-CODE->] 
[2017-04-18 22:45:21] <realisation> can you explain the context there, is that port12345on my local host that pipes into port80on the docker container?
[2017-04-18 22:58:01] <SISheogorath> alexeydemin: you should avoiddocker commit(as a low level docker command) in general because it prevents you  from providing reproduceable images
[2017-04-18 23:01:25] <SISheogorath> Use the official mysql or mariadb images. [<-CODE->] 
[2017-04-18 23:12:05] <buyology> if you launch a container withdocker runand keep it alive, but have say 100s of versions of the same docker. how can I effectively check which docker to dodocker execon?
[2017-04-18 23:13:09] <thebuccaneersden> realisation: - “hostport:containerport”
[2017-04-18 23:13:44] <buyology> are there any short hands for this or do I first have to list all running containers with e. g.docker psand then if the correct version is running exec on that imageid?
[2017-04-18 23:52:21] <SISheogorath> buyology: you can usedocker ps -fto filter your container to get the right id. If you use docker compose you can also dodocker-compose exec composename binaryor if you need an interactive shelldocker exec -it $(docker-compose ps -q composename) binary. There are many ways to achieve your target. Stay creative :)
[2017-04-18 23:52:51] <SISheogorath> And in general using container names is a good advice ^^
[2017-04-19 00:01:19] <realisation> thebuccaneersden: thanks :)
[2017-04-19 00:02:06] <thebuccaneersden> any time@realisation
[2017-04-19 00:02:38] <thebuccaneersden> su docker mi docker
[2017-04-19 00:10:09] <realisation> lol
[2017-04-19 00:13:10] <alexeydemin> SISheogorath: Ohh cool, it works, I can't believe it didn't work because I committed working container to an image and then tried to launch it from that image.
[2017-04-19 00:16:22] <alexeydemin> The same way I have to use official nginx container and separate official php-fpm container, one-container-per-process approach, right?
[2017-04-19 05:59:10] <buyology> SISheogorath: thanks!!
[2017-04-19 08:00:54] <MariusDiacu_twitter> Can someone recommend me a Docker based tool for managing a development server with multiple web projects (each project with 3-4 containers)? Something simpler than Openshift. I dont want high scaling with swarm mode, just to be able to run and created multiple instances of projects based on some docker-compose or such kind of config files.
[2017-04-19 08:39:06] <SISheogorath> MariusDiacu_twitter: swarm-mode should be fine. Checkdocker stack deploy
[2017-04-19 10:16:33] <sandys> hi guys - anyone know how to configure logging with docker-swarmkit and supervisord running in containers ? confused on whether to share the /var/log directory or redirect to stderr, etc . what are you guys doing ?
[2017-04-19 10:24:09] <SISheogorath> You should redirect the logs to/dev/stdoutand/dev/stderr. The reason is dead simple: this way docker logging mechanisms work and it allows everyone to redirect/read/collect logs by using docker logging drivers ordocker logscommand/API
[2017-04-19 11:31:56] <sandys> SISheogorath: thanks for this - my host is running journald. is there a way to ensure that docker logs go to journald and are tagged with name, container-id, etc ?
[2017-04-19 12:05:02] <SISheogorath> sandys: check the whole logging docs: [<-LINK->] 
[2017-04-19 12:05:33] <SISheogorath> it should point out how to log to journald including all settings you want to use :) Details to journald: [<-LINK->] 
[2017-04-19 13:37:48] <sandys> @
[2017-04-19 13:38:45] <sandys> SISheogorath: wow this was a big EFFORT. how to properly tag docker logs with swarm names and container labels and then making that available to query from journalctl. it is not documented anywhere - had to pull from bugs filed in other places.
[2017-04-19 13:59:36] <sniper0110> Hello everyone,I've been working on implementing an API that uses a tensorflow model. I used MLDB (Machine Learning Database) to implement the API. I am completely new to this and I was asked to deploy this API to a remote ubuntu machine that I have access to. I used a docker container for mldb and everything I'm using is inside that container. Is it possible to deploy the container so that someone else can test my API? Is deploying a container the same thing as deploying an API?Thanks in advance.
[2017-04-19 15:37:04] <pecigonzalo>  [<-LINK->] 
[2017-04-20 04:13:31] <alexforever86_twitter> MariusDiacu_twitter: Try Rancher. It's easy to get started with Rancher
[2017-04-20 06:24:59] <MariusDiacu_twitter> alexforever86_twitter: Thanks, I'll try it.
[2017-04-20 07:55:59] <coding-yogi> Hi, In my CI job of building Docker image, I see that COPY command doesn't invalidate the cache despite of files inside the folder being updated
[2017-04-20 07:56:10] <coding-yogi> any idea why this should be happening
[2017-04-20 14:05:29] <rusbob> Hi,
[2017-04-20 14:05:49] <rusbob> Are you sure the content of the files has changed ?
[2017-04-20 14:06:15] <rusbob> See reference:COPY - the contents of the file(s) in the image are examined and a checksum is calculated for each file. The last-modified and last-accessed times of the file(s) are not considered in these checksums. During the cache lookup, the checksum is compared against the checksum in the existing images. If anything has changed in the file(s), such as the contents and metadata, then the cache is invalidated.
[2017-04-20 19:24:21] <chrisRubiano> hello! im using docker-compose for a django server, and im having trouble with an installed pip package, is there any way to view the files from a docker volume or container? like /usr/local/lib/python...
[2017-04-20 19:27:49] <SISheogorath> in most cases you can run a normal shell inside your container (with mounted volumes) or you mount those volumes to another container which provides a shell and let you check it out. Or is it a problem comping up during build?
[2017-04-20 19:36:06] <talkimhi11> https://twitter.com/polvi/status/855085219602243584https://github.com/moby/moby/pull/32691#issuecomment-295036771Docker is dead. call it moby
[2017-04-20 19:47:49] <rusbob> Docker is dead. call it mobyThis is real provocation. Moby has many references to Docker resources and you call it "dead" ? LOL
[2017-04-20 19:48:37] <talkimhi11> I meant the docker brand
[2017-04-20 19:53:16] <chrisRubiano> SISheogorath: how can i connect to the volume? here's the bit of code from the docker file im using to build [<-CODE->] 
[2017-04-20 19:56:37] <SISheogorath> O.o that something you should really not do... You mount the app into the image?
[2017-04-20 19:56:39] <rusbob> talkimhi11: Ok, I've got it. Docker will be spitted into components and Moby will be like a assembler project for multiple docker components.
[2017-04-20 19:59:15] <SISheogorath> moby is more or less the Docker framework ^^
[2017-04-20 19:59:19] <SISheogorath> that's all
[2017-04-20 20:02:42] <rusbob> Looks like Moby will be an oss project and docker will be more like commercial product.
[2017-04-20 20:03:14] <rusbob> clever and in-time marketing approach ))
[2017-04-20 20:16:24] <SISheogorath> Docker stays open source. The point is: they want to allow people to build their own products based on moby without all the branding problem that are cause because everyone says it's build with docker. So split it out allows everyone to talk about containerd and moby while docker itself is more clearly the product of the Docker Inc. like the docker CE or Docker EE. Docker CE is simply the build of tools like swarmkit, moby, etc. so it's a useful collection of tools build to work together. And as Docker CE stays free it's only in parts about commercial. The Docker EE is in parts closed source but it's a bit like Redhat, Fedora and RHEL.
[2017-04-20 20:25:00] <rusbob> yep, looks like this:Moby is just open source projectDocker CE is free product based on Moby OSS with additional functionality.Docker EE is commercial product based on Docker CE.
[2017-04-21 01:36:28] <alexeydemin> SISheogorath: Is that true that container created from commited and renamed official mysql image doesn't launch mysql service automatically on container sturtup?
[2017-04-21 01:40:27] <SISheogorath> alexeydemin: can't say for sure, never tried. In general, as already mentioned,docker commitis something you should not use as long as you are not about to do really crazy things with docker containers. I would say it's possible that it breaks theCMDand/orENTRYPOINT. In this case the mysql server wouldn't start anymore. If you want to add your database to a container (like prefilling it for deployments) I would suggest you to use a volumes you ship or extent the mysql image.docker commitis a dead way.
[2017-04-21 01:46:10] <SISheogorath> Hint: As there is aVOLUMEdefined in the [<-LINK->] you can\'t prefill the data inside the mysql database. You have to fill it by add your sqldump into the init directory that is mentioned in the README on Docker Hub. More details about this "problem" of theVOLUMEkeyword can be found here: [<-LINK->] 
[2017-04-21 01:46:25] <SISheogorath> See the second note
[2017-04-21 01:47:16] <alexeydemin> SISheogorath: Cool, thank you for the explanation.
[2017-04-21 15:51:33] <chkm8> How could I edit or add extension in php.ini via dockerfile?
[2017-04-21 15:54:38] <SISheogorath> how would you do it in a shellscript?
[2017-04-21 15:55:11] <SISheogorath> sedis your friend :)
[2017-04-21 17:50:53] <viveleroi> I\'ve been reading intros/guides to docker but there\'s one thing I\'m still not clear on - where does the installed software "go"? As a vagrant user, the VM concept is clear to me. If i install node or nginx or mongo it\'s in the VM and will never touch my host system. I can boot the vm like any other server. I\'m trying to understand how docker handles software installation and execution.
[2017-04-21 18:03:57] <SISheogorath> viveleroi: In genereal there is some kind of filesystem like you know it from your normal host system. What docker does is using a layer filesystem which is splitted (depending on your volume driver) into multiple files/blobbs. Those blobbs are read by your kernel in an isolated cgroup and also written like (a bit like a swap file or a vhd). this way you can address the things. All these blobb files ware located in/var/lib/dockerby default. And when you install somethings that's the place where your bits and bytes are located
[2017-04-21 18:04:34] <SISheogorath> please notice that's the very, very short version :D I guess we could talk a day about that without the need to search for new topics ^^
[2017-04-21 18:12:34] <viveleroi> so are virtual machines still involved, just not unique to every container? If I start something I pulled from the hub which runs node, mongodb, is docker still going to download an ubuntu image, boot it, etc (assuming the scripts FROM is based on an ubuntu image)? I'm just trying to make sure I have a clear mental image of this. with a vm, you'd modify the actual vm to start up servers on boot but it sounds like with docker, you need to ensure that's done in your script
[2017-04-21 18:23:49] <SISheogorath> it depends on your definition of a virtual machine. In general a virtual machine emulates (virtual) hardware (like a CPU, a graphic card, network interfaces, ...). Docker doesn't do that. Docker provides filesystems with a shared kernel and isolates them (as good as possible)
[2017-04-21 18:24:56] <SISheogorath> that's the reason why you can't run a Windows based image on a linux based kernel
[2017-04-21 18:26:21] <SISheogorath> And theubuntu,alpine, etc. base images are simply snapshots of a filesystem. So it looks like you're on a ubuntu machine because all tools and configs are in same place as you have them in ubuntu
[2017-04-21 19:03:17] <ghost202> What is more of the docker convention? one container per project, or all projects in one container? or is it just personal preference?
[2017-04-21 19:03:36] <ghost202> project meaning web application
[2017-04-21 19:05:37] <SISheogorath> on process per container. And if you have like multiple websites: one container per webpage. Isolate as much as possible into an own image/container
[2017-04-21 19:06:24] <SISheogorath> so you maybe end up with multiple container per project
[2017-04-21 19:07:15] <ghost202> SISheogorath: okay, thanks
[2017-04-21 19:07:17] <SISheogorath> At the end for sure it's personal preference but best practices are very clear. When you check the docker hub you'll find tons and tons of bad designed containers :/ as sad as it is
[2017-04-21 19:08:00] <ghost202> Are they changing the project over to "moby"?
[2017-04-21 19:09:35] <SISheogorath> moby is part of docker. It's splitted out to make more clear that moby is only one part of the docker engine and to break it up in smaller, more reusable pieces
[2017-04-21 19:10:05] <ghost202> i see.
[2017-04-21 19:10:37] <SISheogorath> so if you don't develop the docker engine, you can simply ignore it. Docker engine stays docker engine
[2017-04-21 19:19:13] <viveleroi> SISheogorath: I think that makes sense. I'll have to toy around with it and get a better feel for the process. I can see how docker can simplify deployment but I don't see how I can share a dev environment script with someone on another platform. docker mentions that in the sales pitch, but if someone on windows can have a local ubuntu dev server, how would the environments be the same
[2017-04-21 19:21:10] <SISheogorath> Docker4Windows as well as Docker4Mac are a special topic. They actually use virtual machines in background to run a minimal linux machine with docker behind the scenes as long as you want to work with linux containers. (Docker also offers windows containers, but I can't say much about them. As I don't use them)
[2017-04-21 19:23:53] <SISheogorath> The important thing is: with the Dockerfile you define an environment. You make sure that everyone uses (for example) ubuntu:16.04 as baseimage and all files are always in same place. regardless of the fact that the person actually runs arch, fedora or Windows. the programm will run in a defined environment as ubuntu:16.04 and also uses all libraries and configs that are provided by ubuntu:16.04 and not the ones they use on their normal system
[2017-04-21 19:25:06] <SISheogorath> that makes the whole development easier as you don't have to figure out anymore where they have placed this stupid library X on this system. Also it allows you to use a specific version of a library or binary without a fear of conflicts if you have another base system
[2017-04-21 19:25:20] <viveleroi> ok, so to "ensure everyone uses ubuntu 16.04" is that possible with the dockerfile or something they\'d have to manually setup?
[2017-04-21 19:25:46] <viveleroi> that\'s what we do now with vagrant, but obviously downloading a whole disk image for every "box" is inefficient
[2017-04-21 19:26:01] <SISheogorath> simply placeFROM ubuntu:16.04in your dockerfile (at the top) and instantly everything inside the container is working like in ubuntu
[2017-04-21 19:27:18] <viveleroi> ok cool, thanks
[2017-04-21 19:27:49] <viveleroi> so if they wind up having 4 different containers/dockerfile projects, they really only download that base image once?
[2017-04-21 19:28:15] <SISheogorath> The point is vagrant uses more ressources than docker as you always have a full VM running. and also "testing if the whole application works on python 3 as well as on python 2" is easier with Docker ^^ simply changeFROM python:2toFROM python:3and rundocker build .again and see if it works ^^
[2017-04-21 19:28:43] <SISheogorath> if all those containers are based on the same base image, yes
[2017-04-21 19:29:10] <viveleroi> ok, I think I have a clear picture now. thanks
[2017-04-21 19:29:16] <SISheogorath> same base image means something likepython:3. Another base image is:python:2
[2017-04-21 19:29:26] <SISheogorath> but also applies to ubuntu and debian and alpine
[2017-04-21 19:29:38] <SISheogorath> in fact python is based on debian for example
[2017-04-21 19:30:03] <SISheogorath> so if you already have debian base image on your machine it'll only download the diff to the python image
[2017-04-21 19:30:39] <viveleroi> so FROM python:* refers to what kind of image?
[2017-04-21 19:31:44] <SISheogorath>  [<-LINK->] <-- this (if no other registry  is specified and there is no image with this name and version, docker hub is used as default)
[2017-04-21 19:32:04] <SISheogorath> if you want to look deeper: [<-LINK->] 
[2017-04-21 19:32:14] <SISheogorath> that's a nice visualisation of the layers ^^
[2017-04-21 19:35:02] <viveleroi> ok so if I used that, somewhere upstream docker would download/use a debian image? FROM: ubuntu makes sense since that's an OS but I wasn't sure how FROM: python:* dictated which OS/image it was used against
[2017-04-21 19:36:56] <viveleroi> I guessFROMwould only allow a single base? so if I wanted python, but also mysql and a few more tools, I\'d sayFROM ubuntu:something"and then include the theaptcommands to install the tools
[2017-04-21 19:37:45] <SISheogorath> in general you should only place one application per container/image
[2017-04-21 19:38:17] <SISheogorath> and use for example and own mysql container for mysql
[2017-04-21 19:39:00] <SISheogorath> the best practices talks about: one process per container. Which is not always possible but a good advice.
[2017-04-21 19:40:38] <viveleroi> ok, new avenue for me to look into I guess, since I'm not clear what you mean. if I have a node server application, it would need node, postgres, maybe redis. those all need to be running for my app to work, and with vagrant those would all go in the same VM, but you're saying with docker they should, ideally, be run separately with different docker files/images?
[2017-04-21 19:41:42] <SISheogorath> yes. you would have 3 container. one for node, one for redis and one for postgres. That's why docker-compose exists. See for example the wordpress tutorial: [<-LINK->] 
[2017-04-21 19:42:14] <SISheogorath> or django: [<-LINK->] 
[2017-04-21 19:42:42] <SISheogorath> Or if you like it a bit more interactive: [<-LINK->] 
[2017-04-21 19:42:51] <viveleroi> cool thanks, I'll look at those
[2017-04-21 23:37:39] <bomholtm> hello everyone... just getting familiar with docker and started playing around. I followed [<-LINK->] and im stuck on "docker-machine ip MACHINE_VM". It returns: Host does not exist: "MACHINE_VM". The wordpress setup is available under 0.0.0.0:8000 though.
[2017-04-21 23:48:45] <SISheogorath> Do you actually use docker-machine?
[2017-04-22 02:40:38] <alexw10> Does anyone know how  I can take environment variable that are on the system and pass certain ones to the docker container?
[2017-04-22 07:28:37] <elcolie> alexw10: You have to use os script replace theymlfile after thatdocker-composeup
[2017-04-22 09:24:51] <SISheogorath> alexw10: if you usedocker runordocker servicethere is the parameter-eyou can use-e VARIABLENAME=$VARIABLEor if you use docker-compose you can use the same way in theenvironment:section of you service
[2017-04-22 10:22:07] <bomholtm> SISheogorath: i am completely new to docker and follwed the getting started and [<-LINK->] 
[2017-04-22 10:22:57] <bomholtm> docker-machine is installed but it seems like the problem is i run docker for mac and i read something like docker-machine isnt available this way
[2017-04-22 10:28:41] <bomholtm> seems like i have to install docker for mac and docker toolbox as well to have docker-machine working on a mac ...
[2017-04-22 10:36:52] <SISheogorath> You don't need docker-machine
[2017-04-22 10:37:37] <SISheogorath> bomholt: simply replaceMACHINE_IPwith localhost and it should work
[2017-04-22 10:57:13] <bomholtm> SISheogorath: okay I just removed the containers, default network and the wordpress database. I will reinstall everything and try again. thanks for your advice. but without docker-machine I wouldn\'t be able to reach different wordpress or nodejs containers from different "IPs" would I? I saw a development environment where every folder in his workspace was available in browser  by "<folder>.dev".
[2017-04-22 10:59:41] <bomholtm> sorry for all my dumb questions but I did a lot of javascript lately as i got back into development and the last local dev environment i set up was LAMP like 10 years ago or something  no fucking clue what I am doing but docker seems amazing. probably have to read more documentation than I did yet
[2017-04-22 11:24:18] <SISheogorath> I think the tutorial isn't really clear :D maybe checkout training.play-with-docker.com there you'll get a more interactive tutorial :)
[2017-04-22 11:29:08] <bomholtm> SISheogorath: i will thanks again
[2017-04-23 12:48:20] <vunguyenhung> Hi everyone, I'm new to docker. How can we attach to container's /bin/bash when it've already had entrypoint?
[2017-04-23 12:50:04] <jonasbn> vunguyenhung: have you tried the layer just before the entrypoint?
[2017-04-23 12:51:24] <jonasbn> vunguyenhung: I am pretty new too
[2017-04-23 13:09:02] <duane-stubbs> Does this help? [<-LINK->] 
[2017-04-23 14:59:27] <SISheogorath> vunguyenhung: There are multiple ways: [<-CODE->] 
[2017-04-23 16:14:06] <vunguyenhung> jonasbn: @duane-stubbs@SISheogorathThanks you guys for your help! I've tried to run /bin/bash into nginx:alpine, it turns out alpine do not have bash :D
[2017-04-23 16:15:45] <jonasbn> I normally use a slim variant of debian
[2017-04-23 16:17:39] <vunguyenhung> jonasbn: yup, it'd be more easy for newbie like me to use those :D.
[2017-04-23 16:33:14] <SISheogorath> I really prefer alpine based setups. Way smaller and cheaper in speech of ressources
[2017-04-23 17:40:19] <jonasbn> SISheogorath: alpine looks very promising, just haven't figured out what using musl and not glibc means for my stack
[2017-04-23 21:10:06] <MaksimKiselev> Hi guys) I just try use traefic, and has one simple question. How ON auto write container frontend host to/etc/hostsfile?
[2017-04-24 06:54:07] <MaksimKiselev>  Hey, where is everyone? 
[2017-04-24 07:19:05] <SISheogorath> I guess your question is not really clear
[2017-04-24 08:14:58] <MaksimKiselev> Sorry, not actualy.
[2017-04-24 08:15:45] <jonasbn> SISheogorath: your tips for@vunguyenhungon shell/bash access just saved my day - thanks :-)
[2017-04-24 08:16:39] <MaksimKiselev> Now actually question what use for monitoring? :Dhttps://github.com/veggiemonk/awesome-docker#monitoring--logging
[2017-04-24 08:36:16] <thebuccaneersden> newrelic, if you are happy paying money for it
[2017-04-24 08:36:27] <thebuccaneersden> munin if not
[2017-04-24 09:52:31] <MaksimKiselev> @thebuccaneersden I'm don't happy pay money)Are you has examples how to use munin with docker?
[2017-04-24 10:02:51] <SISheogorath> Datadogs does a great job for monitoring docker. They have a free plan for 5 or 10 hosts (Without alerts).
[2017-04-24 10:08:39] <SISheogorath> For a on prem solutions I would suggest Prometheus
[2017-04-24 14:11:44] <thebuccaneersden> MKiselev: I dont have any examples, but setting up munin is simple. All the docker containers you want to monitor should have the munin client installed. And then you have 1 docker container with the munin server which is configured with the nodes it should monitor. ie. like with this ~> [<-LINK->] 
[2017-04-24 14:18:39] <MaksimKiselev> thebuccaneersden: thank you for unswer. I will try later.
[2017-04-24 14:47:18] <thebuccaneersden> np
[2017-04-24 16:29:30] <wcgcoder> So... Monday problems... trying to track down why whenever I restart docker, all ipv6 addresses are removed from my NICs
[2017-04-24 16:30:23] <wcgcoder> When I reload sysctl, I getnet.ipv6.conf.all.disable_ipv6 = 0, but when I restart docker and check again, it's set asnet.ipv6.conf.all.disable_ipv6 = 1
[2017-04-24 16:30:38] <wcgcoder> Not seeing anything obvious in my system logs
[2017-04-24 16:34:55] <wcgcoder> Looks like setting--ipv6breaks docker. Need to specify my own CIDR. Annoying
[2017-04-24 16:47:56] <wcgcoder> Even after adding--fixed-cidr-v6 2001:db8:1::/64to the daemon in systemd, docker still seems to be wiping out my ipv6 addresses
[2017-04-24 17:09:16] <SISheogorath> wcgcoder: possibly related to: [<-ISSUE->] 
[2017-04-24 17:38:24] <SISheogorath> In general I can say I noticed a similar behavior related tonet.ipv6.conf.all.disable_ipv6
[2017-04-24 17:38:51] <SISheogorath> fixed it with a few scripts and a systemd.timer :D
[2017-04-24 18:03:17] <Trezamere> is there a good solution to managing volume permissions on a host mounted filesystem yet?  I think the two best options are to have an entrypoint script to gosu as the user or to pass the /etc/passwd and /etc/group as ro and pass the --user UID:GID; both have drawbacks
[2017-04-24 18:03:23] <Trezamere> something like a volume plugin?
[2017-04-24 18:06:23] <SISheogorath> Trezamere: check the [<-LINK->] 
[2017-04-24 18:06:49] <SISheogorath> I would suggest you to use direct-lvm if you run on a single host or hosts with vhds
[2017-04-24 18:15:56] <wcgcoder>  [<-CODE->] That sounds awful
[2017-04-24 18:16:39] <wcgcoder> SISheogorath: looks related, you're right
[2017-04-24 18:17:36] <wcgcoder> SISheogorath: Nice, looks like a fix is coming down the pipe for 17.05
[2017-04-24 18:17:38] <SISheogorath> wcgcoder: do you use any container withnetwork_mode: hostor--net host?
[2017-04-24 18:17:44] <SISheogorath> I know
[2017-04-24 18:18:09] <SISheogorath> If you do than the bug is related to this container :D
[2017-04-24 18:22:56] <Trezamere> SISheogorath: interesting read but I don't see how using devicemapper solves the problem of writing everything as root back to the host system?
[2017-04-24 18:25:11] <SISheogorath> Trezamere: in case you use a volume driver and named docker volumes you don't run in that issue. You only run into it while using the bind driver and mount existing directories and mounts inside your container.
[2017-04-24 18:26:50] <SISheogorath> the common solution is to do, like you said, a chown and then su-exec or gosu but I don't like that solution. Using docker volumes is the better way to go
[2017-04-24 18:27:18] <wcgcoder> SISheogorath: docker inspect -f "{{.HostConfig.NetworkMode}}" rancher-agent=> host
[2017-04-24 18:27:52] <wcgcoder> SISheogorath: (i.e. yes).
[2017-04-24 18:28:32] <SISheogorath> wcgcoder: oh.. Rancher... :/ sounds like a lot of fun for your environment with this bug :D
[2017-04-24 18:28:57] <wcgcoder> SISheogorath: I love Rancher, there are just a few gotchas
[2017-04-24 18:29:50] <SISheogorath> Oh yes, Rancher is nice :D but since you have to run their agent everywhere and it runs on host network it's not really nice to use with this bug :D
[2017-04-24 18:30:18] <wcgcoder> Yeah... I'm experience some weird issues.
[2017-04-24 18:30:31] <Trezamere> Is there an intuitive way to pull files out of a docker volume?  e.g. for a build server, or running local builds?  we use docker to provide a build environment and so we need to write and move things on the host system
[2017-04-24 18:30:49] <Trezamere> I know volumes are in general preferred for containers but it seems like maybe this is an edge case or maybe I'm unaware
[2017-04-24 19:00:52] <dragon788> Trezamere: what kind of files are you wanting to pull out of the volume?
[2017-04-24 19:02:15] <dragon788> if you have say a "data volume" in docker speak that lives in a data container, you could map in additional volumes from the host eg$host/builds/logsand map that onto$buildcontainer/datavolume/builds/logsand instead of writing those logs into the container they would drop back out to the host
[2017-04-24 19:03:00] <dragon788> it's very similar to having multiple bind mounts in Linux where you can override specific subpaths to go to different volumes or directories if they grow large or need different speeds of disk
[2017-04-24 19:11:05] <Trezamere> Yes but the data container will still be writing files as root; just as if I use a named volume it's writing things into /var/lib/docker/ which is also owned by root so I still have the problem of writing things as root.  I already know the suggested workarounds that I mentioned above I was asking if there was a better way to handle it or if that's still the best we got
[2017-04-24 19:17:25] <dragon788> have you looked at the differences between named volumes and data containers? I'm not sure if they fixed the permissions or if it allows overriding the user for the named volume on creation but I thought I saw something to that effect recently
[2017-04-24 19:27:53] <SISheogorath> Trezamere: writing outside of a docker container as root is not a problem ._.
[2017-04-24 19:28:15] <SISheogorath> That's completely normal for docker
[2017-04-24 19:43:16] <Trezamere> I can't tell if you're being sarcastic or not; but there is an entire market dedicated to securing docker and running least privilege containers.  Which is besides the point as I am specifically asking to write files out as specific users so, yes, it is a problem
[2017-04-24 19:44:02] <Trezamere> dragon788: I'm not really following you :( are you suggesting I create a data container as the user in question and volume map it to the other container?  I'm pretty sure the files will still be written into that volume with the UID of whoever is doing teh writing
[2017-04-24 19:52:10] <Trezamere> reiterating the question as there seems to be something lost in translation; basically is it possible to mount a volume with specific ownership; either natively or via a plugin, so I could do something like-v /dir:/dir:rw:$(id -u $USER):$(id -g $USER), I know you can create custom entrypoint scripts and share the same base image to do similar things or pass /etc/passwd and group and use--user, however both have limitations
[2017-04-24 19:54:41] <Trezamere> user-namespaces has to many restrictions
[2017-04-24 20:03:50] <SISheogorath> Trezamere: I guess you should refer to this: [<-LINK->] 
[2017-04-24 20:04:49] <dragon788> could always try the s6-overlay that works around this as well, [<-LINK->] 
[2017-04-24 20:26:26] <vladimnir> i don't see the benefit of using docker
[2017-04-24 21:01:10] <thebuccaneersden> whats confusing you@vladimnir
[2017-04-24 21:37:26] <SISheogorath> vladimnir: that's possible. There are cases where you can't benefit from docker. Mostly that are cases where you work a lot with kernel internals or low level communication. Also the benefit of docker is limit for regular desktop users. So as@thebuccaneersdenhas pointed out, if you describe your possible use-case for docker a bit more detailed, we can clear things up :)
[2017-04-25 07:54:24] <Scapal> Hi, what is the best practice to aggregate content from multiple sources (each being a git repo) with differente release cycles: base website, translations, dev/prod configurations... ?Should I create a with_translation container using 'FROM base_website' ... or have an independent container for the translations and use a volume_from?
[2017-04-25 08:19:07] <themue> Scapal: git add submodule
[2017-04-25 08:20:52] <SISheogorath> git submodule addif you want to use ithides
[2017-04-25 08:21:36] <themue> Hehe
[2017-04-25 08:38:49] <Scapal> git submodulesdoesn't allow me to compose different configurations. Also I don't like submodules since here the submodule will change more often than the main content. Submodules are linked to a particular commit if I remember correctly.Having the build process for the translation separated from the main website is also a +.I will also have to add bundled Angular apps to the main website and I prefer to keep that build process isolated as well.
[2017-04-25 08:59:59] <SISheogorath> I agree that submodules aren't the perfect solution. The best practices in your case mainly depend on your way to build your application. In most cases you simply use something like i18n support, which would solve the problem without running into this problem.
[2017-04-25 09:02:02] <SISheogorath> As a general rule of thumb: if you have the same base with multiple versions create a base image and create variations. (As you said yourself) for development/testing/production config you should use environment variables to generate those configs
[2017-04-25 09:03:28] <SISheogorath> That makes it better maintainable and allow to ship the same image you used to test and verified to work fine in your CI process as well as in production
[2017-04-25 09:04:00] <SISheogorath> So your CI/CD process becomes reliable
[2017-04-25 09:15:53] <Scapal> What about using volume-from? Is it a no-no?
[2017-04-25 09:31:21] <SISheogorath> You should avoid volumes-from if you run docker swarm because it is a local thing and not really compatible.
[2017-04-25 09:31:34] <themue> Another way could be vendoring by cloning the different repos into the main one. But may need some automation to checkout the correct branches or tags.
[2017-04-25 14:28:58] <finspin> In my docker-compose.yml I runcommand: bash -c "npm install && tail -f /dev/null". I need to do tail -f to keep the container up and running. Is there some other, cleaner way? I tried couple of things like tty: true and stdin_open: true but container always stops unless I pass tail -f to the command.
[2017-04-25 14:43:11] <SISheogorath> finspin: docker has very simply logic here: If the first process of the command (the one you call byCMD,ENTRYPOINT,entrypoint:orcommand:) exits, the whole container dies. So what ever you want to do inside the container, make sure it won't exit.
[2017-04-25 14:56:51] <finspin> SISheogorath: got it, thanks
[2017-04-25 18:19:45] <Hasnayeen> how can i add my host machine volume to a running container?
[2017-04-25 18:20:09] <enriquemanuel> Hasnayeen: with the -v flag localpath:remotepath
[2017-04-25 18:20:39] <Hasnayeen> enriquemanuel: to a running container?
[2017-04-25 18:21:01] <enriquemanuel> hmm not to a running container, but more to when the container starts running
[2017-04-25 18:21:01] <enriquemanuel>  [<-LINK->] 
[2017-04-25 18:36:57] <Hasnayeen> how can i create a named volume using a host machine directory?
[2017-04-25 19:29:49] <dragon788> Hasnayeen: see the previous answer with -v or read the docs linked
[2017-04-25 22:42:05] <FuzzOli87> Did version 3 of Docker compose change the way it handles volumes? I have/home/app/node_modulesas a volume which used to create a node_modules with all the packages, now it just leaves it empty
[2017-04-25 22:42:17] <FuzzOli87> Then again, I can't recall if it ever behaved this way on Linux
[2017-04-26 01:32:53] <SISheogorath> FuzzOli87: When do you create that volume and how?
[2017-04-26 12:06:12] <timilsinabishal> How can I access the host port from the container?
[2017-04-26 12:19:32] <SISheogorath> timilsinabishal: the current "mostly used" way is to simply access it like your host is a remote computer. (means use it\'s public hostname) and then go the regular way. If you try to connect some kind of loopback TCP port: No, not possible as long as you don\'t use--net hostornetwork_mode: host. Problem with those modes is they break the network isolation of your container and also possibly cause trouble related to IPv6 since there was a bug in libnetwork
[2017-04-26 12:20:50] <mostafa> timilsinabishal: you should expose it
[2017-04-26 12:21:24] <mostafa> timilsinabishal:  [<-LINK->] 
[2017-04-26 12:23:09] <timilsinabishal> SISheogorath: thanks for your swift and detailed answer. I will look into network_mode: host to see if it solves my problem.
[2017-04-26 12:24:41] <timilsinabishal> mostafa: thanks for your reply. But that is not the problem I am facing.
[2017-04-27 10:00:57] <4406arthur> Hi all,Did anyone success to downgrade docker from 17.X.ce version to docker 1.12 ?my centos7 machine occurs conflicts problem .any workflow suggestions ?
[2017-04-27 10:40:19] <damilare> anyone using python with docker here, I would like to know how to attach to a running container and get a pdb shell
[2017-04-27 11:11:05] <mostafa> damilare:  [<-LINK->] 
[2017-04-27 11:11:20] <chadlyon> damilare: Check out [<-LINK->] 
[2017-04-27 11:14:24] <chadlyon> damilare: Your question needs a little clarification. Are you trying to use python to access the docker container or are you running python in your docker container and trying to simply execute pdb?
[2017-04-27 11:14:34] <chadlyon> The latter would be something like:
[2017-04-27 11:16:18] <chadlyon>  [<-CODE->] 
[2017-04-27 11:34:44] <papaiatis> Hi Guys! I\'d like to achieve the following:create two containers, that hosts (using nginx) two different websites. Container A will expose port 5000, Container B will expose port 5100 but not accessible from outside\ncreate a third container where nginx will run and expose port 443 to the bridge network, so that it is accessible from outside\nconfigure nginx in a way that it behaves like a proxy: it forwards incoming traffic to either Container A or Container BQuestion is: how should I configure these containers so that the nginx container can access the other containers on the 5000 and 5100 ports?What I believe is that I need to create a "user-defined network" so that these three containers can access each other using container name .
[2017-04-27 11:37:03] <chadlyon> 4406arthur: I haven't tried it but I would remove with yum and then try to yum install the specific version like so:
[2017-04-27 11:39:15] <chadlyon>  [<-CODE->] 
[2017-04-27 11:41:15] <chadlyon> This assumes you have the following: [<-CODE->] 
[2017-04-27 11:47:39] <lukewatts> Hi all, I'm on my 3rd day of learning Docker. Going well. I'm just wondering about volumes. When something is changes or generated inside a running container is that reflected on the host? Or is just from host to container changes are reflected?
[2017-04-27 11:54:50] <chadlyon> lukewatts: If the volume is mounted to a host dir then yes. eg [<-CODE->] 
[2017-04-27 11:55:05] <SISheogorath> If you use-v localpath:containerpaththen all changes made by the container are also applied to the local directory. To be clear: these are normal mount points. So if you know those kernel concepts it's nothing magical :)
[2017-04-27 11:55:56] <lukewatts> chadlyon: @SISheogorathPerfect! Thanks
[2017-04-27 11:56:57] <SISheogorath> 4406arthur: officiallydowngrades are not supported. i would suggest to clean up the setup by removing docker completely and reinstall 1.12.x
[2017-04-27 11:58:17] <SISheogorath> Make sure you also kill/var/lib/docker. Note that this will delete all containers and named volumes (if you used the default volume driver)
[2017-04-27 12:02:52] <SISheogorath> papaiatis: checkout jwilder's nginx reverse proxy project if you really want it to be nginx you use as reverse proxy. Otherwise I suggest Traefik. You can serve your webpages by extending the nginx image and don't need to expose any port for your nginx containers. Simply put them together with jwilder's nginx or Traefik in a compose file and do the needed configs in there. Docker compose creates a network for the project and puts all services in there. Services on the same network don't need to expose ports to access each other so Traefik other the nginx proxy can simply connect to both webpages using port 80
[2017-04-27 12:07:34] <papaiatis> SISheogorath: thanks! that looks promising
[2017-04-27 12:15:01] <damilare> chadlyon: so the picture is there is a process running in a container already, a web app process. if I put a pdb statement in a line, and I hit the URL, I want to be able to drop into a shell to introspect the data
[2017-04-27 13:03:18] <lukewatts> I have a volume related question. I created a Node app and I run the container withdocker run -tid -p 80:80 -v ~/html:/usr/share/nginx/html --name nodeapp1 nodeapp:1.0. I log in upload images etc and then when I check~/htmlon my host nothing is saved. But the changes persist when I stop and start the container. I've checkdocker volume lsand I have no named volumes. Where the hell are those changes being stored?
[2017-04-27 13:08:50] <lukewatts> Anddocker inspect nodeapp1shows that Mounts has the correct values I expect."Source": "/home/ubuntu/html", "Destination": "/usr/share/nginx/html"
[2017-04-27 13:43:07] <chadlyon> damilare: without more specifics I still can't really get an idea of exactly what you are trying to do but play around with my second comment to you above. That will get you a debug shell inside your docker container. That will give you a good start. Alternatively, running a regular interactive shell like bash in your container would be:
[2017-04-27 13:58:59] <chadlyon>  [<-CODE->] 
[2017-04-27 14:03:29] <chadlyon> lukewatts: Perhaps your nginx config is not pointed at the correct dir in your container. You should see changes in the container reflected on your host path. As a test you can do: [<-CODE->] 
[2017-04-27 14:26:05] <rybruscoe> Does anyone know if it is possible to get a VNC type graphical connection into a Windows Server 2016 Container? I want to be able to view some apps I have running I side of Windows Containers visually.
[2017-04-27 15:11:52] <4406arthur> SISheogorath: ,@chadlyon, thank for replying, but something I notice need to do,  remove /var/lib/docker will occur cannot-remove-device-or-resource-busy, explanation in  here [<-LINK->] ,I think reboot is more convienent..to much process I need kill..and also need uninstall a dependency lib - docker-engine-selinux, for solving conflic problem
[2017-04-27 15:24:54] <vito-c> does anyone know if network aliases work with libcompose?
[2017-04-27 15:40:21] <SISheogorath> 4406arthur: Just a question out of interest? What Monitoring do you use? (if you use one)
[2017-04-27 15:47:05] <4406arthur> SISheogorath: , I am little confuse.. Monitoring or orchestration?
[2017-04-27 15:47:38] <SISheogorath> vito-c: Check [<-LINK->] 
[2017-04-27 15:47:44] <SISheogorath> there is an Aliases field
[2017-04-27 15:48:51] <SISheogorath> 4406arthur: Monitoring :D I have the theory that it is caused by monitoring checking the volume usage and mount points :x
[2017-04-27 15:50:43] <vito-c> SISheogorath: yea I see the network alias info being passed but when I use docker inspect it doesn't show up
[2017-04-27 15:51:18] <vito-c>  [<-LINK->] 
[2017-04-27 15:52:20] <4406arthur> SISheogorath: , I have tested with sematext
[2017-04-27 15:55:13] <SISheogorath> 4406arthur: is it running right now?
[2017-04-27 15:56:25] <4406arthur> SISheogorath: , not running, I kill all containers firstly
[2017-04-27 16:15:11] <SISheogorath> I see. Mhm...
[2017-04-27 17:08:05] <FuzzOli87> SISheogorath: Sorry this is a late response. But in reference to my node_modules volume on my host machine being empty, I set it up like this:
[2017-04-27 17:08:10] <FuzzOli87>  [<-LINK->] 
[2017-04-27 17:09:02] <FuzzOli87> So now it creates the node_modules directory on my house, but it's empty. I am using yarn to do my installs, not sure if that matters.
[2017-04-27 17:11:05] <vito-c> SISheogorath: I'm making modifications now to libcompose to see if I can find the issue... basically when I call up it doesn't create the aliases
[2017-04-27 17:12:38] <vito-c>  [<-CODE->] 
[2017-04-27 17:13:32] <vito-c>  [<-CODE->] 
[2017-04-27 17:14:19] <vito-c> is there a docker-dev chat?
[2017-04-27 17:17:55] <vito-c> Here is the response: [<-CODE->] 
[2017-04-27 17:21:22] <SISheogorath> FuzzOli87: you create a separate, unnamed volume for your node_modules. It's normal that this wouldn't be visible to your host.  The content of node_modules is a mountpoint in you container so you can't see it outside
[2017-04-27 17:22:00] <FuzzOli87> SISheogorath: But this worked in the past, did something chang?
[2017-04-27 17:39:59] <SISheogorath> FuzzOli87: no, nothing changed in perspective of mountpoint handling. If you remove the first entry in yourvolume:section the node modules will be installed to the host directory as you expect
[2017-04-27 17:41:28] <SISheogorath> vito-c: I can only refer to the docker community slack. The title of gitter says it's for development but to be honest since I'm here I saw maybe two small conversations about development and iirc in all of them you were the person who asked :D
[2017-04-27 17:41:50] <vito-c> weeee
[2017-04-27 17:42:02] <SISheogorath> Maybe the freenode channel is another option :D
[2017-04-27 17:42:06] <FuzzOli87> SISheogorath: You're right. Thanks!
[2017-04-27 17:42:17] <vito-c> how do i get on the docker slack chat?
[2017-04-27 17:42:17] <SISheogorath> You're welcome@FuzzOli87
[2017-04-27 17:42:46] <SISheogorath> vito-c: -> [<-LINK->] 
[2017-04-27 17:43:01] <SISheogorath> Or try the docker forum if you prefer
[2017-04-27 17:44:12] <SISheogorath> In general I read something about a mailingliste that is possibly found for moby which then would be the place for development :D
[2017-04-27 17:44:31] <ripper2hl> Hi , i need some help with docker , this is the right place ?  D:
[2017-04-27 17:45:40] <ripper2hl> :(
[2017-04-27 17:45:43] <SISheogorath> ripper2hl: depending on what you need help with, you'll may get some :D
[2017-04-27 17:46:03] <vito-c> don't ask to ask just ask!
[2017-04-27 17:46:04] <vito-c> :D
[2017-04-27 17:46:12] <SISheogorath> The easiest way to find help is to ask the question instead of asking for asking ;)
[2017-04-27 17:46:37] <ripper2hl> okay okay, i try explain my problem xD
[2017-04-27 17:47:18] <vito-c> but what if i'm not sure if I can ask my question? should I ask if it's ok to ask if I can ask my question?
[2017-04-27 17:47:22] <SISheogorath> vito-c: -> [<-LINK->] The best description how to get answers :D
[2017-04-27 17:48:25] <vito-c> post your question to a forum where it's off topic
[2017-04-27 17:48:27] <vito-c> lol
[2017-04-27 17:50:13] <SISheogorath> I hope you read the sentence before :D
[2017-04-27 17:52:11] <ripper2hl> My problem is how run google-chrome in docker container for e2e testing , i make an Dockerfile from official jenkins image, but when try run google-chrome this crash and show the next error [<-CODE->] the jenkins docker image use debian jessie. [<-CODE->] 
[2017-04-27 17:52:35] <ripper2hl> this is my docker file
[2017-04-27 17:52:36] <ripper2hl>  [<-LINK->] 
[2017-04-27 17:52:51] <ripper2hl> jenkins official image
[2017-04-27 17:52:53] <ripper2hl>  [<-LINK->] 
[2017-04-27 17:54:17] <ripper2hl> and the repo an person run google chrome with GUI from docker , my english is very bad xD
[2017-04-27 17:54:57] <ripper2hl>  [<-LINK->] 
[2017-04-27 17:56:22] <ripper2hl> My first aproach is used xvbf but the process is more simple when use--headlessflag [<-LINK->] 
[2017-04-27 17:56:39] <ripper2hl>  [<-LINK->] 
[2017-04-27 18:08:09] <SISheogorath> ripper2hl: can you run it with the--no-sandboxflag and check if the problem persist?
[2017-04-27 18:10:19] <ripper2hl> I try but send this [<-CODE->] 
[2017-04-27 18:16:00] <SISheogorath> oh sounds wonderful :D at least you get another error message. Your problem is based in the very strict isolation rules for docker containers. The problem is that chrome and chromium do tons of low-level isolation things with the kernel. Docker in permit them by default. That's why Jessie wrote an own ruleset. sounds like a lot of work to do to run it really headless in docker :/
[2017-04-27 18:17:20] <SISheogorath> Maybe check their image: [<-LINK->] 
[2017-04-27 18:17:28] <ripper2hl> :( i try this [<-LINK->] 
[2017-04-27 18:17:32] <SISheogorath> and replace the base image with the jenkins one
[2017-04-27 18:17:47] <ripper2hl> :O
[2017-04-27 18:17:51] <SISheogorath> that's also an option
[2017-04-27 18:18:02] <ripper2hl> okay very nice aproach
[2017-04-27 21:49:47] <KramKroc> Hi folks. Moving from docker-compose 2 to docker-compose 3. We previously had a log aggregator container which defined the host location to write all our container logs to. The other containers used volumes_from to pull that together. With volumes_from being dropped in version 3, I wondered what the best advice was to achieve the same end result. e.g. [<-CODE->] 
[2017-04-27 21:53:51] <KramKroc> I thought this would allow me to define the volume externally, so that e.g. I could have logsMarks set up for dev and another volume definition for cloud etc. So example for dev/local would be: [<-CODE->] But when I run the docker-compose up command, it doesn’t make use of the logsMark volume, but instead uses one that appears to be based on the folder the compose file is based, e.g. fragglerock_logsMark.
[2017-04-27 21:54:38] <KramKroc> So what am I doing wrong here, why is my definition not be aligned to the named one in the docker-compose definition?
[2017-04-27 23:58:40] <SISheogorath> KramKroc: docker compose always prefixes a project name. By default it's the name of the folder you started docker-compose in.
[2017-04-28 00:00:21] <SISheogorath> if you want to use the volume you created in a separated step, useexternal: truein your compose file. [<-LINK->] 
[2017-04-28 07:12:57] <KramKroc>  I’ll give that a go@SISheogoraththanks!
[2017-04-28 10:11:55] <KramKroc> Does anyone have a steer on what the best practice for volumes and compose files is? In particular if you may have different volume needs depending on whether you are in dev, on prem or in cloud?
[2017-04-28 10:33:38] <SISheogorath> KramKroc:  [<-LINK->] ?
[2017-04-28 11:49:31] <hlogeon> Hello, guys! I'm trying to dockerize my Laravel application, but it looks like it consumes too much memory(15GB RAM)
[2017-04-28 11:49:51] <hlogeon> I don't even know where to start researching what can be wrong
[2017-04-28 11:50:17] <hlogeon> How to debug docker-compose build command?
[2017-04-28 15:03:01] <AnthonyWC> hlogeon: you can use the verbose flag
[2017-04-29 03:57:48] <thebuccaneersden> hlogeon: The docker container you are using for your laravel app uses 15GB of memory????
[2017-04-29 05:56:52] <yuvgeek> Installing Node Version 6 in ubuntu base image tells, npm command not found.
[2017-04-29 07:34:45] <thebuccaneersden> you get that error while trying to install node?@YuvarajMe
[2017-04-29 07:55:56] <Asiddiki> All: How can I use depends_on in docker-compose.yml .I will use this yml with Docker-stack .Please suggest me is there any way to make dependency on Docker-stack ?
[2017-04-29 08:15:56] <ael-g> Hi guys, do we have a convenient way to backup/import local docker volumes?
[2017-04-29 08:16:07] <ael-g> Smthg likedocker volume export/import
[2017-04-29 08:18:02] <ael-g> It looks like we just have to backup data in volumes/$volume + dump the right data in volumes/metadata.db
[2017-04-29 11:28:52] <SISheogorath> YuvarajMe: apt-get install npmshould fix the problem
[2017-04-29 11:41:14] <SISheogorath> ael-g: the official docs says/suggestion is to use a separated container and tar/untar your data to the data volume or use shared data volumes by adding a volume driver which talks to an external API.
[2017-04-29 12:13:22] <yuvgeek> That's fixed@SISheogorath@thebuccaneersden
[2017-04-29 12:13:30] <yuvgeek> npm ERR! addLocal Could not install /@angular-cli\nnpm ERR! path /@angular-cli\nnpm ERR! code ENOENT\nnpm ERR! errno -2\nnpm ERR! syscall open\nnpm ERR! enoent ENOENT: no such file or directory, open '/@angular-cli'
[2017-04-29 12:13:41] <yuvgeek> Installing angular-cli throws this error
[2017-04-29 12:17:12] <SISheogorath> Sounds like a permission problem .-. it tries to install the angular CLI to a place that doesn't exist. Maybe checkout this example I build for angular CLI based applications: [<-ISSUE->] 
[2017-04-29 12:19:15] <SISheogorath> You can fix your original error by runningmkdir /@angular-clibut I would suggest you to not do it because it feels like there is an environment variable missing
[2017-04-29 12:23:23] <yuvgeek> SISheogorath: yeah, that for my app 
[2017-04-29 12:23:32] <yuvgeek> that uses nginx
[2017-04-29 12:25:30] <SISheogorath> Wow I can't help myself I always mix you up xD
[2017-04-29 12:26:33] <yuvgeek> I can able to install Node V6 by having ubuntu as a base image now.. It was a minor issue
[2017-04-29 12:26:42] <yuvgeek> ca-certificate 
[2017-04-29 12:31:21] <SISheogorath> That's totally not what the error message said
[2017-04-29 12:31:58] <yuvgeek> Ahh leave that.
[2017-04-29 12:32:11] <yuvgeek> Now I couldn't install angular cli
[2017-04-30 01:52:11] <Khoa_Truong_twitter> Is dinghy the best docker performance on osx right?
[2017-04-30 02:18:49] <thebuccaneersden> never heard of it, but somewhat concerned about using something that is a wrapper to docker breaking further down the line line vagrant and virtual box occassionally break api compatibility
[2017-04-30 20:54:48] <RStrydom> Hay guys, docker newbie question, I am busy setting up a lamp server on AWS and wanted to tryout docker, I used the docker pull command and have the container up and running, but with the image I have chosen they say they have mapped 4 volumes which I need access to but not sure how. 1. Do I need to setup the mapping to my own filesystem via cmd or the dockerfile? 2. If I used the pull method, where does the dockerfile get stored?I'm using this image https://hub.docker.com/r/fauria/lamp/Thanks for your time :)
[2017-04-30 21:12:30] <thebuccaneersden> RStrydom: You have to link the container volume to a local path on the host when you spin up the container. Specifically with something like this:-v /my/data/directory:/var/www/htmlin the arguments
[2017-04-30 21:13:03] <thebuccaneersden> from [<-CODE->] 
[2017-04-30 21:13:05] <SISheogorath> RStrydom: I wouldn\'t recommend you to use that image. The official docker best practices say "One process per container" which is not always possible but should endup in "one function per container" so a lamp-Stack would endup in 2 or 3 containers.
[2017-04-30 21:13:28] <thebuccaneersden> this is true
[2017-04-30 21:13:44] <thebuccaneersden> there does seem to be a lot of installed packages in this container
[2017-04-30 21:15:01] <SISheogorath> checkout [<-LINK->] if you want to have some very detailed guides
[2017-04-30 21:15:31] <RStrydom> thebuccaneersden: Thank you I saw those lines in the docs, but I was concerned since they were already mapped
[2017-04-30 21:16:10] <thebuccaneersden> no worries. as you said, this is all new to you
[2017-04-30 21:17:00] <thebuccaneersden> i’d probably take the approach of using docker-compose to split up the different things into different containers: ie. one for mariadb, one for php-fpm, one for nginx, etc
[2017-04-30 21:17:11] <thebuccaneersden> its pretty simple to do once you play with it a little
[2017-04-30 21:19:24] <RStrydom> SISheogorath: Thanks man, I see what you are saying about the single responsibility issues of that image. I will go through that guide as well, thanks, have done tutorials in the past but I was just unsure about this one aspect where I had no dockerfile to play around with.
[2017-04-30 21:19:50] <RStrydom> thebuccaneersden: Thanks man, will check it out 
[2017-04-30 21:22:28] <RStrydom> checkout https://training.play-with-docker.com if you want to have some very detailed guides
[2017-04-30 21:22:57] <RStrydom> Just thought I'd let you know that the SSL certificate is currently not working, so just got a bit of a scare on the https link
[2017-04-30 21:23:20] <thebuccaneersden> just noticed that as well
[2017-04-30 21:23:30] <thebuccaneersden> tsk tsk… [<-LINK->] 
[2017-04-30 21:56:30] <SISheogorath> Mhm maybe I should go back to the old time and stop writing https:// in front of links :D
[2017-04-30 22:08:00] <thebuccaneersden> heh, you shouldnt have to
[2017-05-01 09:42:35] <crosofg> hey
[2017-05-01 09:42:43] <crosofg> hwo do I run this dokcer
[2017-05-01 09:42:46] <crosofg>  [<-LINK->] 
[2017-05-01 09:42:55] <crosofg> I have installled docker profram in windows?
[2017-05-01 11:08:57] <Asiddiki> thebuccaneersden: how can i use "--net host" in docker-compose.yml v3 ?..I am using docker stack deploy command to up the service.
[2017-05-01 16:20:05] <SISheogorath> @Asiddiki the only way to set the networkmode to host is this setting: https://docs.docker.com/compose/compose-file/#networkmodeBut as the documentation says: It's ignored during stack deploy. You can't use networkmode host in swarm
[2017-05-01 16:45:16] <RStrydom> SISheogorath: Hay, so yesterday I started going through the training.play link you sent, although on the first tutorial I am going through usingdocker container, but on my AWS Amazon Linux AMI, I cannot usedocker container, I googled it and looked at the help pages and could see that thedocker containersubcommand is under amanagment commandssection , but I could not seem to get a way to get those commands, I searched yum for another possible package, can you kindly let me know what I am missing here?
[2017-05-01 16:48:45] <SISheogorath> These commands are new to docker 1.13 (iirc it was 1.13) and are the first step to "clean up" the docker CLI.  If you use centos or similar you possibly stuck with version 1.12.6 which doesn\'t include these "clean ups". For those versions you should be able to use these commands withoutcontainerin front
[2017-05-01 16:52:57] <RStrydom> SISheogorath: Ah I see, thanks again
[2017-05-01 20:50:41] <djmrr> Hey there, I have been a little stuck on the correct docker networking configuration.I'm working inside a couple Centos 7 VM's, in order to have a working proof on concept on a monitoring system with Prometheus & Grafana for our apis/apps/dbs. [<-CODE->]  [<-CODE->]  [<-CODE->] Any input would be rad!  Thanks :] !
[2017-05-01 20:51:44] <SISheogorath> hint: it's--networknot-network
[2017-05-01 20:53:45] <djmrr> SISheogorath: hahah yeah, good catch, I didn\'t copy and paste my command, manually typed it.  I do however use the--network="blah":)
[2017-05-01 20:54:22] <SISheogorath> okay :) next step: do you run mysql in it's own container or is it running in docker?
[2017-05-01 20:56:08] <djmrr> SISheogorath: I don't run mysql in it's own container, it just runs locally on the machine.  I noticed that that's totally a thing that folks configure, running mysql in it's own container which I think is pretty rad, but our current environment that might be not the best shift.  I'd like to dig into learning more about that nonetheless.
[2017-05-01 20:57:55] <SISheogorath> In this case the next step should be to check that it's really listening on127.0.0.1:3306->netstat -ln | grep :3306should show it to us
[2017-05-01 20:59:17] <djmrr> SISheogorath: rad, yeah, using netstat to discover open ports, checking for the mysql port yields me this: [<-CODE->] 
[2017-05-01 20:59:46] <SISheogorath> can you telnet to it?
[2017-05-01 21:02:44] <djmrr>  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2017-05-01 21:02:59] <SISheogorath> ouch
[2017-05-01 21:03:36] <SISheogorath> wait what other vm?
[2017-05-01 21:03:48] <SISheogorath> can you try on the same host?
[2017-05-01 21:06:44] <djmrr> @SISheogorath  I have two VM's running centos 7 right now.  One runs the grafana image, prometheus node exporter image, and prometheus server. [<-CODE->] 
[2017-05-01 21:07:18] <SISheogorath> chech the routing between the vms :D
[2017-05-01 21:09:57] <djmrr> SISheogorath: - thanks :) - yeah I'll dig into that then... do you feel that if I can telnet on local host into those ports there might be something that is preventing the convo and that's the problem?  I do have SELinux disabled and no iptables live and running.  Any suggestions maybe where to start digging?  Again, thanks a ton for your help
[2017-05-01 21:12:40] <SISheogorath> ip r sshould show first results (orrouteif you prefer oldschool)
[2017-05-01 21:14:12] <djmrr> SISheogorath: oh okay, yeah that yields me this: [<-CODE->] 
[2017-05-01 21:14:40] <SISheogorath> what network is your other vm in?
[2017-05-01 21:15:57] <djmrr> SISheogorath: oh yeah, lemme check, running "ip r s" on the other vm yields me this: [<-CODE->] 
[2017-05-01 21:18:37] <SISheogorath> .-. now things become complicated
[2017-05-01 21:23:04] <SISheogorath> what kind of VM are we talking about? a small virtualbox-like or something that runs in vSphere or xen?
[2017-05-01 21:25:30] <djmrr> @SISheogorath ( △｀) [<-CODE->] @SISheogorath  if it's of any value I was using this github image for the prom/mysqld exporter-> https://github.com/prometheus/mysqld_exporterAnd followed this guideline initially from Digital Ocean:https://www.digitalocean.com/community/tutorials/how-to-install-prometheus-using-docker-on-centos-7?utm_medium=btb_algo
[2017-05-01 21:28:46] <djmrr> SISheogorath: oh, maybe you mean the specs of the vm?The one that I'm working with prom/mysqld-exporter image has 512 MB Memory, 8 GB Virtual Storage\nThe one that runs the main version of prom/prometheus image + prom/node-exporter image + grafana/grafana image has 3072 MB Memory, 20 GB Virtual storage
[2017-05-01 21:28:59] <SISheogorath> has it ever worked to connect between the VMs? If not I suggest to follow: [<-LINK->] 
[2017-05-01 21:29:29] <SISheogorath> it was okay. I guess it's a hypervisor problem which permits communication between the VMs
[2017-05-01 21:35:04] <djmrr> SISheogorath: do you think it could be something to do with the fact I\'m not running mysql in a container?Perhaps, something about using--network="bridge"is working but the local network is what I need to connect to for the mysql server?  When I do use--network="bridge"I can absolutely telnet to it via9104I don\'t think I can telnet to it via3306- again thanks a ton :)
[2017-05-01 21:37:23] <SISheogorath> I would say the general error is somewhere else. If you can't connect between VMs you have another problem than something in docker. Once that is fixed, running the mysql node exporter image on your mysql host with--network=hostshouldn't be a problem
[2017-05-01 21:40:03] <djmrr> SISheogorath: yeah, I'll have to dig a bit more, running it via bridge absolutely allows me to connect to 9104 but not 3306 from another vm... running it on network via host absolutely does not.... Thanks again for all the help, I'll try to uncover what's causing the communication hiccup.  :)
[2017-05-01 21:41:13] <SISheogorath> yes, check the virtual box settings :D Or simply test it on DO instead of in virtual box, that should also avoid that error ^^ (I love public IPs :D)
[2017-05-02 05:15:36] <MaksimKiselev> Hi guys. [<-CODE->] 
[2017-05-02 05:49:29] <MaksimKiselev> Resolved...
[2017-05-02 09:48:05] <dnordberg> Hi, I\'ve got centos 7.3 setup with docker on Azure, have opened up ports 80 and 433 for incoming traffic and running a few services, one of which is nginxdemos/hello:latest, however, can\'t access anything, just get "site can\'t be reached", any tips/ideas to get this working on azure?
[2017-05-02 10:23:42] <Csini> hi! can somebody help me? I want to configure some custom subdomains to my docker container. I have windows7 with boot2docker running in a Virtualbox image.My container runs on [<-LINK->] I want to use for example [<-LINK->] Where should I configure the subdomain? In the Linux of Boot2docker, inside my Docker Container (which is also a Linux) or in VirtualBox itself or in all three places ?
[2017-05-03 13:13:20] <zpydee> hi all. i'm trying to configure docker hub to tag automated builds using my git tag from travis. can anyone help?
[2017-05-03 13:47:33] <richardsondx> I have an issue where I have the EXACT same docker container deployed on two different machine. One one machine I’m getting a Connection reset by peer (errno:EcONRESET) when I’m running a script that makes a simple https request… On the other I’m getting a 200 OK response. The same. request works with no problem when I run it on the same machine; but the net/http request is failing on one maachine but not the other.  Here a gist with more info [<-LINK->] If the problem is not the environment (nor the docker version or the virtual machine version), could it be the network? And what docker settings could differ?
[2017-05-03 14:40:12] <MannikJ> Hi! Is it access to connect a container network created by docker compose via it's network name and host name? I can access the container by getting it's ip fromdocker network inspectbut not via it's hostname
[2017-05-03 14:58:42] <SISheogorath> zpydee: you can configure automated builds to run only on tagged references and use the git tag as tag name. Simply check the automated builds page and select "Tag" instead of "branch" and add some kind of schema you want them to follow
[2017-05-03 15:44:21] <SISheogorath> MannikJ: what kind of connection are you thinking about?
[2017-05-03 16:04:33] <MannikJ> Well, a network connection ;) For example I can access elasticsearch's http api (which is one of the containers specified in compose file) by writinghttp://<ip_from_inspect>:9200. Why can't I access it by it's service name likehttp://elasticsearch:9200or maybe something likehttp://projectname_default.elasticsearch_1:9200
[2017-05-03 16:15:41] <SISheogorath> this is caused by the fact that docker uses an internal DNS service. if you need to access those things you have two options: [<-CODE->]  [<-CODE->] 
[2017-05-04 05:55:37] <Asiddiki> Hey Guys can you please tell me how to configure docker registry on https with certificate directory not with certificate name ?
[2017-05-04 09:16:49] <roolo> Hi, in our team We have some difficulties with mapping host user <-> container user (host user does not own it's files after running container). Could You please point to some nice article or documentation? It seems to me, there is no such mapping in docker, which seems a bit weird to me
[2017-05-04 11:45:27] <sushant91265_twitter> hi guys, within docker container I'm able to connect to the npm registry but not able to connect to the private artifactory. I'm just trying npm install. Error I get is npm ERR! network connect ETIMEDOUT 192.17.132.113:8081 >> any idea how to solve this error ?
[2017-05-04 13:28:29] <pjetr> Hi guys, I am quite new to docker and I have some design questions.Our application consists of 5 sub applications, 2 require PHP, mariadb and redis. The other 3 ar simple JS-applications (and we will need an extra node - redis - mongo stack in the near future). For now we will use docker purely as development environment, but in the near future I would like to modify our CI to use docker. And in the somewhat more distant future I would like our staging and production to also migrate towards docker.But for now, it's purely as a development-environment, moving away from vagrant.My design question is, how would an ideal stack look? Would you do an nginx container for each application, or a single nginx, mariadb, redis, php-fpm for the entire stack? Or would you create a container per app, each containing nginx + whatever?
[2017-05-04 13:57:35] <hatrena> pjetr: you can create a container having your most common technologies, and then inherit it from a new container which is having more specific task.
[2017-05-04 14:02:13] <pjetr> I have written an expanded version of my question on stack overflow: [<-LINK->] 
[2017-05-04 14:03:45] <pjetr> hatrena: interesting, so a base-container with only nginx, a php-container which inherits from the nginx-container, and adds databases / caching /  …
[2017-05-04 14:05:04] <hatrena> yes, in a very simple implementation. you can have more layer of inheritance. another application can inherit your custom php container
[2017-05-04 14:09:28] <pjetr> wouldn't that pose problems towards scalability in the future, when we move our production onto docker?
[2017-05-04 14:11:40] <hatrena> it depends on how you will manage the containers and linkage between them.  and you need to be careful about the dependency between technolgies if exist.
[2017-05-04 14:29:37] <pjetr> so it would be 1 container per app as you are suggesting, thanks
[2017-05-04 14:38:03] <pjetr> Another question, compiling the applications, would you perform this in your container, or on your host? (ie.npm run build)
[2017-05-04 14:49:31] <hatrena> on container, since what i want is a ready application after running docker-compose up for example
[2017-05-04 14:49:39] <hatrena> or applications
[2017-05-04 15:53:25] <dragon788> also with the newer staged docker builds you can easily compile your app with all it's dependencies and then output a container that is ONLY the app and dependencies
[2017-05-04 21:39:16] <MaximZavitaev> Hi. The volumes are mounted only from the host to the container? That is, changes in the container are synchronized to the host, and changes in the host into the container will not fall? Or I something not so do?
[2017-05-04 22:00:22] <dragon788> MaximZavitaev: it depends how your Dockerfile is set up, basically the container does a "bind mount" if you map in a host folder via the volume mount, so it is an immediate write that shows up both places (because they are bound to the same place), if you just want to copy files into the container once, you can use theCOPYcommand in your Dockerfile eg if you wanted to get a compiled artifact into the container in order to run it
[2017-05-04 22:08:59] <MaximZavitaev> @dragon788 i write [<-CODE->] in docker-composechange a file on the host, but the container changes do not fall
[2017-05-04 22:21:41] <MaximZavitaev> Everything is fine
[2017-05-04 22:23:23] <MaximZavitaev> The problem lies elsewhere. Server on NodeJS should watch for the file to load a file and reload the browser page when changing. Changes appear, but it does not reload the file and page browser
[2017-05-05 07:13:14] <pjetr> MaximZavitaev: you can use [<-LINK->] to watch for file changes and rebuilding the app.
[2017-05-05 07:41:22] <MaximZavitaev> pjetr: i use webpack and hot reload.
[2017-05-05 07:41:46] <MaximZavitaev> pjetr: with nodemon it will be long enough to build the project
[2017-05-05 09:11:13] <Floolean_twitter> Hi there
[2017-05-05 09:11:19] <Floolean_twitter> docker newbie here
[2017-05-05 09:12:51] <Floolean_twitter> Does anybody know of good articles/resources about (git-)branch dependent deployment and environment setup?
[2017-05-05 09:13:37] <Floolean_twitter> i.e.: branch develop deploys to certain cloud provider whereas master deploys to another
[2017-05-05 09:13:52] <Floolean_twitter> also setup of unit test containers
[2017-05-05 09:16:59] <hatrena> Floolean_twitter: there were many questions, can you please be more specific ?
[2017-05-05 09:20:20] <Floolean_twitter> I try to
[2017-05-05 09:22:03] <Floolean_twitter> I have a repo with an app. I want to automatically deploy my dev branch in a certain environment and the production branch in another
[2017-05-05 09:22:31] <Floolean_twitter> Different dockerfiles for develop and master I guess?
[2017-05-05 09:23:14] <pjetr> wouldn't it be loads easier to this using CI?
[2017-05-05 09:23:23] <hatrena> you can use github + travis for example. then in your travis based on your branch (dev or master) it can deploy to a specific environment using docker cli
[2017-05-05 09:24:07] <hatrena> it depends if ytou want to use docker cloud for deployment for example or any other solutions
[2017-05-05 09:24:46] <Floolean_twitter> I use an internal gitlab instance for versioning
[2017-05-05 09:25:46] <Floolean_twitter> thanks for the hint, I found a good example project
[2017-05-05 09:25:48] <Floolean_twitter>  [<-LINK->] 
[2017-05-05 09:26:55] <pjetr> I would strongly suggest to add a CI in your workflow, like travis, jenkins, ...
[2017-05-05 09:27:17] <pjetr> that way you can make sure that you don't deploy with failing tests
[2017-05-05 09:27:19] <hatrena> yes, without CLI, you should deal with a lot of manual work
[2017-05-05 09:27:22] <Floolean_twitter> I'm using a gitlab runner
[2017-05-05 09:27:48] <pjetr> I'm not familliar with gitlab runner
[2017-05-05 09:28:12] <Floolean_twitter> it's a CI provider
[2017-05-05 09:28:40] <hatrena> so you can definitely leverage CLI to automate your deployment
[2017-05-05 09:29:08] <Floolean_twitter> yes, thank you very much
[2017-05-05 13:14:59] <SISheogorath> To deploy your stuff use docker-compose with overwrites. See the docker-compose in production page in the docs about how to do it. This was you can simply define the environment you want to go to. And in your CI description add a simply if clause about what branch your are running to decide the Target for deployment
[2017-05-05 17:03:54] <thebuccaneersden> Floolean_twitter: I’m using DroneCI. It’s an open source self-hosted CI solution which leverages docker containers to execute your builds.
[2017-05-05 17:04:44] <thebuccaneersden> I don’t know if you can use Gitlab Runner without having to have the whole Gitlab installation and then you have to do so much more customization to get Gitlab runner set up, in my opinion
[2017-05-05 17:39:35] <scippio> hi all
[2017-05-05 17:40:13] <scippio> I started one image via docker-compose with ports: "ip:1000-50000:1000-50000" ...
[2017-05-05 17:40:35] <scippio> now... everything is unresponsive 
[2017-05-05 17:41:21] <scippio> I don't know how to remove thousand docker-proxy processes 
[2017-05-05 17:41:53] <scippio> I tried restart all computer but everything started again...
[2017-05-05 19:00:40] <simplyageek> kill docker process? boot into safe mode delete/rename docker-copose yml file
[2017-05-05 20:19:36] <SISheogorath> scippio stop the docker service and remove/var/lib/dockerif you have nothing important like volumes on your system
[2017-05-05 20:21:58] <SISheogorath> Alternative is to unassign the IP from your interface and remove the container then
[2017-05-05 20:22:36] <SISheogorath> beniamin-kis: removing the docker-compose.yml shouldn't stop or affect any created service
[2017-05-05 21:27:41] <scippio> SISheogorath: I have volumes in my Host system ...
[2017-05-05 21:46:41] <scippio> ok... I'm resolved the problem... thanks for help...
[2017-05-05 21:47:54] <scippio> After some hours docker started response... so I remove problematic docker process/image via docker-compose rm ...
[2017-05-06 21:20:19] <gdeverlant> Greetings to all
[2017-05-06 21:20:38] <gdeverlant> I'm trying to run a stack with docker
[2017-05-06 21:20:47] <gdeverlant> docker stack deploy ...
[2017-05-06 21:21:09] <gdeverlant> I'm getting this error for the absolute path mounting
[2017-05-06 21:21:09] <gdeverlant>  [<-CODE->] 
[2017-05-06 21:21:52] <gdeverlant> version: "3"services:agency1:image: arangodb/arangodb-arm64:3.2environment: [<-CODE->] 
[2017-05-06 21:22:34] <gdeverlant> I don't know why normally docker create the folders automatically with docker run etc...
[2017-05-06 21:22:53] <gdeverlant> but not in the case of docker stack deploy -f docker-compose.yml
[2017-05-06 21:24:10] <gdeverlant> why docker isn't able to create the folder in my cluster
[2017-05-06 21:24:23] <gdeverlant> what would be the right solution for this
[2017-05-06 21:29:26] <gdeverlant> I might add that I'm running in swarm mode
[2017-05-06 21:53:09] <gdeverlant> Isn't docker already running is root mode
[2017-05-06 21:53:24] <gdeverlant> so   that it can create folder all over the clusters
[2017-05-06 21:54:20] <SISheogorath> it's not wanted to let docker service automatically create the directories
[2017-05-06 21:54:45] <gdeverlant> how do I do it then?
[2017-05-06 21:55:29] <gdeverlant> I have a cluster of 20 I don't want to do all manually
[2017-05-06 21:55:30] <SISheogorath> simple reason: when you use shared volumes means some kind of mount in that path that maybe is simply unavailable at the time of the service creation, the created path would precent you from success mount your shared directory again and break your setup... nothing you want to have
[2017-05-06 21:55:41] <SISheogorath> write a script
[2017-05-06 21:56:03] <gdeverlant> can this plugin help me [<-LINK->] 
[2017-05-06 21:56:26] <gdeverlant> I don't know how to write a script
[2017-05-06 21:57:20] <SISheogorath> I can't say, maybe it helps, haven't tried it ever so best way to find out if it works is to try it yourself
[2017-05-06 21:57:31] <SISheogorath> if you run on arm make sure it provides an arm image
[2017-05-06 21:58:15] <gdeverlant> I already compile and made everything for arm
[2017-05-06 21:58:31] <SISheogorath> I don't know how to write a scriptBest way to change that is writing one ^^
[2017-05-06 21:58:57] <gdeverlant> yeah but I find bash scripting very shitty syntax
[2017-05-06 21:59:20] <gdeverlant> I never undertood why the dudes made it so not attractive
[2017-05-06 21:59:36] <gdeverlant> It's nothing like any programming language
[2017-05-06 21:59:56] <gdeverlant> I can't wrap my head around it right now
[2017-05-06 22:00:03] <gdeverlant> I need to find alternatives
[2017-05-06 22:55:54] <SISheogorath> write a zsh script :D or a csh script :D
[2017-05-06 22:56:19] <SISheogorath> ;) simply POSIX complaint scripting
[2017-05-06 22:56:27] <SISheogorath> works perfectly :D
[2017-05-06 22:57:03] <SISheogorath> it a bit like JS. Runs nearly everywhere... Has always some problems... But at the end of the day the job is done and it works :D
[2017-05-06 23:21:13] <gdeverlant> I think that bash scripting was built by a retarded AI
[2017-05-06 23:23:04] <SISheogorath> doesn't really help you in this situation :D
[2017-05-06 23:38:43] <gdeverlant> lol i prefer to use redtamarin
[2017-05-06 23:38:55] <gdeverlant> best bash scripting ever
[2017-05-07 11:15:29] <sushant91265_twitter> hi, I'm trying to connect to the private npm artifactory within docker container . I tried to create a different network with subnet but still not able to reach the artifactory. Any suggestions?
[2017-05-07 15:16:06] <SISheogorath> how did you try to connect to it?
[2017-05-07 15:23:32] <sushant91265_twitter> currently just trying curl -I vvvv "artifactory.aaa.com"
[2017-05-07 15:39:39] <SISheogorath> and what's the error you get?
[2017-05-07 15:41:13] <sushant91265_twitter> Connection timed out
[2017-05-07 15:42:40] <SISheogorath> is it an internal IP address?`
[2017-05-07 16:41:03] <sushant91265_twitter> yes , for this I've to connect to VPN
[2017-05-07 16:44:50] <SISheogorath> this could be a problem. You can try to run it withdocker build --network host
[2017-05-07 16:44:59] <SISheogorath> with your other flags
[2017-05-07 18:25:49] <sushant91265_twitter> nah not working, is it something related to mac machine
[2017-05-07 18:26:15] <SISheogorath> oh yes
[2017-05-07 18:26:24] <SISheogorath> in case of mac that can't work :D
[2017-05-07 18:26:36] <SISheogorath> because docker running in a VM somewhere behind the scenes
[2017-05-07 18:40:07] <SISheogorath> at least not as far as I know. But I'm not a mac user so maybe someone using Docker4Mac has a solution
[2017-05-08 07:33:32] <coding-yogi> sushant91265_twitter: , try adding host entry in /etc/hosts
[2017-05-08 07:33:42] <mac2000> wondering why might--expose 3000dowork and-p 80:3000do notwork on windows container
[2017-05-08 08:05:08] <mac2000> e.g. [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2017-05-08 09:24:23] <sushant91265_twitter> aniket-21: which host entry are you talking here?
[2017-05-08 09:25:59] <coding-yogi> artifactory.aaa.com
[2017-05-08 09:27:54] <sushant91265_twitter> already tried , still not working
[2017-05-08 09:31:39] <coding-yogi> can you post your Dockerfile?
[2017-05-08 09:33:08] <sushant91265_twitter>  [<-CODE->] 
[2017-05-08 10:38:07] <coding-yogi> where are you making HOST entry?
[2017-05-08 10:43:33] <sushant91265_twitter> in the /etc/hosts file
[2017-05-08 10:44:09] <coding-yogi> you are facing problem during npm install right?
[2017-05-08 10:44:18] <sushant91265_twitter> yes
[2017-05-08 10:44:49] <coding-yogi> so you need to do it as part ofRUN npm install
[2017-05-08 10:46:29] <sushant91265_twitter> actually for this  I  removed the dependency which is fetched from the private artifactory from the package.json file and trying to get that once the container is up with different subnet using docker exec command.
[2017-05-08 10:47:04] <coding-yogi> RUN "echo xx.xx.xx.xx   artifactory.aaa.com" >> /etc/hosts \\\n        npm install
[2017-05-08 10:47:50] <sushant91265_twitter> ok let me try
[2017-05-08 11:01:23] <sushant91265_twitter> The command \'/bin/sh -c "echo 172.18.122.156 artifactory.aaa.com >> /etc/hosts" \\ npm install\' returned a non-zero code: 127my_node build error.
[2017-05-08 11:16:20] <coding-yogi> sorry I missed semi colon after "echo xx.xx.xx.xx artifactory.aaa.com" >> /etc/hosts;
[2017-05-08 11:19:36] <gdeverlant> Greetings fellowship of the wale
[2017-05-08 11:21:16] <gdeverlant> Can someone point me why when I try to run this DockerfileI always get this weird error
[2017-05-08 11:21:42] <gdeverlant>  [<-CODE->] 
[2017-05-08 11:23:53] <NdagiStanley> gdeverlant: what’s the error you’re getting?
[2017-05-08 11:27:23] <gdeverlant> wait i check the log
[2017-05-08 11:28:07] <gdeverlant> /entrypoint.sh: exec: line 12: registry: not found/entrypoint.sh: exec: line 12: registry: not found/entrypoint.sh: exec: line 12: registry: not found/entrypoint.sh: exec: line 12: registry: not found/entrypoint.sh: exec: line 12: registry: not found
[2017-05-08 11:28:14] <gdeverlant> alpine linux is incompetent
[2017-05-08 11:28:27] <gdeverlant> I don't get why it doesn't find the binary
[2017-05-08 11:29:28] <gdeverlant> the entrypoint.sh [<-CODE->] 
[2017-05-08 11:34:17] <gdeverlant> what's Alpine's problem
[2017-05-08 11:34:22] <NdagiStanley> gdeverlant: The log show line 12, which line 12 is it referring to here?
[2017-05-08 11:34:39] <gdeverlant> exec "$@"
[2017-05-08 11:34:48] <gdeverlant> that's line 12
[2017-05-08 11:35:04] <gdeverlant> the last
[2017-05-08 11:35:34] <NdagiStanley> Wierd
[2017-05-08 11:35:39] <anil08250> Hai All
[2017-05-08 11:35:58] <NdagiStanley> Hi@anil08250
[2017-05-08 11:36:58] <gdeverlant> Hihi Captain
[2017-05-08 11:40:32] <sushant91265_twitter> aniket-21: RUN  "echo 172.18.122.156 artifactory.aaa.com" >> /etc/hosts; \\ npm install [<-CODE->] 
[2017-05-08 11:46:03] <NdagiStanley> I can’t figure it out@gdeverlant
[2017-05-08 12:05:08] <SISheogorath> gdeverlant: make sure the libs you're depending on are in place. Remember that Alpine uses musl-lib instead of glibc which results in incompatibility when you simply copy programs from a glibc based build. Even in simple static builds parts of the glibc are not automatically bound statically. So make sure you check that back.
[2017-05-08 12:06:25] <SISheogorath> And swearing about the incompetence of open source software without showing the reason in source code is not really nice, and can prevent people, who are about to help you, to help you.
[2017-05-08 12:07:16] <SISheogorath> As always I suggest [<-LINK->] if you are about to work with an open source Community and want answers
[2017-05-08 12:12:39] <gdeverlant> SISheogorath: thanx for the input
[2017-05-08 12:12:49] <gdeverlant> I knew that alpine was not like other distros
[2017-05-08 12:13:05] <gdeverlant> My intuition told me that I could not just copy binaries and expect to run it
[2017-05-08 12:13:40] <gdeverlant> how can I run binaries built on armhf debian jessie inside Alpine
[2017-05-08 12:13:42] <gdeverlant> ??????
[2017-05-08 12:15:27] <SISheogorath> The simplest answer is: you can't. The longer answer is you have to compile it statically and make sure you have all dependencies in place which is in based case just adding a few Symlinks and in Worst-case really build it in a completely static manner.
[2017-05-08 12:16:53] <SISheogorath> The easiest way around all this is to simply build your application inside the image, this way it searches and uses the musl-lib and in case of problems your compiler should notify you
[2017-05-08 12:17:19] <gdeverlant> I found this
[2017-05-08 12:17:30] <gdeverlant>  [<-CODE->] 
[2017-05-08 12:18:45] <SISheogorath> Looks fine
[2017-05-08 12:19:29] <gdeverlant> but im building for armhf arm32
[2017-05-08 12:19:35] <gdeverlant> this will not work
[2017-05-08 12:20:09] <SISheogorath> Yep, doesn't make the world easier....
[2017-05-08 12:20:25] <gdeverlant> FROM nathanosman/alpine-golang-armhf
[2017-05-08 12:20:31] <gdeverlant> i found something that might help
[2017-05-08 12:20:32] <SISheogorath> The curse of the arm geeks :D
[2017-05-08 12:21:17] <gdeverlant> yeah I had to shit rocks because of arm
[2017-05-08 12:21:22] <gdeverlant> I've setup my own registry
[2017-05-08 12:21:32] <gdeverlant> and building for arm32 and arm64
[2017-05-08 12:21:36] <gdeverlant> since I have a cluster
[2017-05-08 12:21:40] <gdeverlant> from both
[2017-05-08 12:21:56] <coding-yogi> sushant91265_twitter: , you need to use bash shell
[2017-05-08 12:22:24] <gdeverlant> golang is cool but not easy to start using
[2017-05-08 12:22:27] <SISheogorath> You may want to join the [<-LINK->] there is a whole channel full of arm people. I'm not really involved in all the arm stuff
[2017-05-08 12:22:32] <gdeverlant> and alpine is a beast on its own
[2017-05-08 12:30:52] <sushant91265_twitter> aniket-21: can you tell how?
[2017-05-08 12:34:30] <gdeverlant> SISheogorath: thanx i just applied
[2017-05-08 12:34:34] <gdeverlant> but it is pending
[2017-05-08 12:34:44] <renegoretzka> hey... anyone have recommendation for an ftpserver? i want create ftp access for clients for their folder
[2017-05-08 12:34:49] <renegoretzka> i use rancher
[2017-05-08 12:35:13] <gdeverlant> you can use sftp via ssh
[2017-05-08 12:35:36] <renegoretzka> how to make them access just their folder and no bash?
[2017-05-08 12:36:08] <gdeverlant> that's a good question check on google
[2017-05-08 12:36:20] <gdeverlant> how to set user account with linux and sftp
[2017-05-08 12:37:38] <renegoretzka> thx
[2017-05-08 12:38:13] <gdeverlant> noproblem
[2017-05-08 12:38:18] <gdeverlant> say thanx to uncle google
[2017-05-08 12:52:32] <sushant91265_twitter> @aniket-21 I tried this [<-CODE->] but still failing with /bin/sh: 1:  npm: not found
[2017-05-08 13:28:14] <sushant91265_twitter> @aniket-21 worked with this [<-CODE->] but still failing with timeout issue
[2017-05-08 14:27:24] <coding-yogi> oh
[2017-05-08 14:41:39] <chrisaj> Is this the right forum for asking about how docker affects the networking performance on the host?
[2017-05-08 14:58:18] <SISheogorath> chrisaj: in General Docker shouldn't effect the network performance a lot as it doesn't do very special things with the host's network. But I can't explain it completely. In case you want some very experienced and detailed answers the best was to go is asking in the [<-LINK->] or the [<-LINK->] .
[2017-05-08 15:30:36] <nuomi> hi channel, I’d like to know how to setup a "container appstore", which is : 1,  runs on a auto-scalable vps cluster, 2, spin up container on-demand, 3, each container ip:port expose to end user.  I’ve read through docs of k8s, swarm, docker-machine, seems none of them address the exact issue here.  so, any hint?
[2017-05-08 15:30:47] <nuomi> thanks!!
[2017-05-08 16:31:04] <SISheogorath> nuomi: portainer and rancher have something like an "AppStore" but tbh I\'m not a fan of it and I don\'t think they are build to be used by endusers. And for sure not auto-scaling.
[2017-05-08 16:36:42] <SISheogorath> Maybe dokku is something you like to checkout too
[2017-05-08 16:53:30] <nuomi> thank you@SISheogorath,  dokku runs on single server rather than a cluster, so I cant really use it on production.  But yes, I should definitely dig more into Paas.
[2017-05-08 17:01:26] <nuomi> some say deis or Flynn  is the multi host solution to dokku. But I could not find any clue on deis.com website. weird...
[2017-05-08 21:41:12] <scippio> hi all.. I\'m using postfix with option "smtp_bind_address" for interface from which I want send e-mails... how I can add this interface "into" docker for this?
[2017-05-08 21:41:38] <scippio> smtp_bind_address=<IP of the interface>
[2017-05-08 22:12:43] <SISheogorath> scippio: the only way to do that is breaking the network isolation of your container and run it with--network host
[2017-05-08 22:13:01] <SISheogorath> any reason why you need it?
[2017-05-08 22:13:31] <SISheogorath> oh I see you have mutliple interfaces
[2017-05-08 22:14:07] <SISheogorath> not really perfect ._. an alternative would be to redirect traffic that has dport 25
[2017-05-08 22:26:13] <vito-c> what happened to [<-LINK->] ?
[2017-05-08 22:30:44] <vito-c> I guess it's this now [<-LINK->] 
[2017-05-09 00:24:39] <scippio> SISheogorath: I tried --network host, but it's not working...
[2017-05-09 05:18:06] <SISheogorath> vito-c: you should checkout the most recent changes in [<-LINK->] it's possible that it is the case. Can't say much about it but sounds like the plan they had when they splitted out the moby repository
[2017-05-09 05:18:34] <SISheogorath> scippio: on what OS are you?
[2017-05-09 05:20:28] <vito-c> SISheogorath: they broke a lot of stuff :(
[2017-05-09 05:50:01] <shyamsalimkumar>  [<-CODE->] sorry I'll go over to IRC
[2017-05-09 06:33:33] <SISheogorath> vito-c: possibly, yes :D
[2017-05-09 06:37:14] <SISheogorath> shyamsalimkumar: docker-machine is a separated tool to setup VMs with boot2docker and similar images. It's not only useful on windows or mac. You can aslo setup cloud instances on AWS or DO with it. Docker swarm is the orchestrator build in or stand alone provided by docker to allow people to run their containers distributed over the network. So they are not really related to each other but work very nice togehter
[2017-05-09 07:29:04] <scippio> SISheogorath: on Debian
[2017-05-09 07:59:24] <SISheogorath> scippio: in this case it should work. You should see the same network interfaces in your containers, as you see on your host. And this includes you can use them alike
[2017-05-09 08:10:23] <scippio> SISheogorath: oh... it seems I had there another server (exim) on host. I turned it off... and all is functional now. Thanks for help.
[2017-05-09 08:11:22] <SISheogorath> You're welcome
[2017-05-09 10:56:55] <zsjohny> all: 
[2017-05-09 10:57:35] <zsjohny> How to set a  lock for  pushed  image
[2017-05-09 14:15:27] <chrisaj> SISheogorath: Ok thanks. I didn't expect Docker to affect my native network performance but it is! I'm asking the docker community via the Slack channel.
[2017-05-09 18:29:29] <vito-c> SISheogorath: where should I go to ask questions about using the docker/moby api?
[2017-05-09 18:30:06] <vito-c> The current issue i'm having is the usage of a vendor dir in side moby [<-CODE->] 
[2017-05-09 18:30:38] <SISheogorath> vito-c: there is a moby channel in the docker Community slack
[2017-05-09 18:31:13] <SISheogorath> I think that's the most promising place to ask
[2017-05-09 18:31:20] <vito-c> ah yes slack
[2017-05-09 18:31:40] <vito-c> how many chat can a chat bot chat if a chat bot could chat chats
[2017-05-09 22:24:59] <moringaman> Would anyone know why a docker container wouldn’t copy all the files from it’s directory to a mounted volume on the host OS
[2017-05-09 22:25:21] <moringaman> Just one of them
[2017-05-09 22:48:56] <SISheogorath> moringaman: you talk about the way how docker handles normal volumes vs host mounts?
[2017-05-09 23:54:24] <moringaman> I used the following run commanddocker run -it --name AureliaBoilerPlate -v $(pwd):/var/www/src -p 9000:9000 -p 3001:3001 webgnostics/aurelia
[2017-05-09 23:55:50] <moringaman> to mount the volume and only one of the files contained in it appeared on the host although when i nap shot it and browed all files where present in the src folder of the container
[2017-05-10 02:43:09] <zsjohny> How to set a lock for pushed image????
[2017-05-10 06:54:02] <SISheogorath> zsjohny: like makeing sure a tag is not replaced? As far as I know that's not possible right now. But you can use the image ID to make sure you don't get the wrong image
[2017-05-10 06:57:47] <SISheogorath> moringaman: iirc this is not possible because docker uses bind mounts where no creation step happens. That's why it doesn't copy files to your filesystem. If you want to have the files usedocker cpto get them out of your image or named volumes.
[2017-05-10 06:59:28] <zsjohny> SISheogorath: but in my prod maybe will be replaced by staging sometime
[2017-05-10 07:00:33] <zsjohny> SISheogorath: For example, staging 1.4  prod 1.3  and next deploy the image  will be replaced
[2017-05-10 07:01:50] <zsjohny> what way to isolate the image from staging  to prod
[2017-05-10 07:18:49] <SISheogorath> O.o in General you should use version tags. Likeimage:1.3.1andimage:1.3.2.  And specify them in your CD process. If you want to be really sticky, as already mentioned, use the image id, that\'s the only way to be sure you use exactly this image version. Tags likelatestorprodare mutable and should only used as "additional way" to get your image for example if you want to reproduce an issue and want to get the image, that "should" currently run in production.
[2017-05-10 09:00:02] <zsjohny> SISheogorath: Thanks ,but In the process of increasing in version ,the version is still likely to be covered. and  I can’t use the tag likelatestorprod. maybe  I can  use diff namespace  or repo and sync  to control it ?
[2017-05-10 09:07:54] <zsjohny> SISheogorath: BTW ,I saw you blog so cool ,what is with the framework
[2017-05-10 09:48:51] <SISheogorath> which framework? For the header? [<-LINK->] the blog itself runs [<-LINK->] or to be more correct: [<-LINK->] 
[2017-05-10 09:51:03] <SISheogorath> zsjohny: if you can explain a bit more detailed how you roll out your images I can maybe give a better advice.
[2017-05-10 10:59:41] <zsjohny> SISheogorath: ok I will show you my problem ,please check 121 conversations
[2017-05-10 11:08:32] <ctmnz> Hello, I have faced strange (for me) result of the command 'docker service update --rollback servicename'. The strange thing is that when I use docker scale command, it is assumed as an workers image update when when I want to rollback it just scales the service in the swarm down. Should I report this as a bug?
[2017-05-10 12:22:02] <SISheogorath> Sounds like it works as expected. It rolls back to previous specification which is another number of scaling. But feel free to open a issue on GitHub if you want to change the behavior
[2017-05-10 12:27:36] <zsjohny> docker
[2017-05-10 13:09:54] <fthamura> i got this, can help?
[2017-05-10 13:09:55] <fthamura> sudo dockerd -H tcp://0.0.0.0:2375WARN[0000] [!] DON\'T BIND ON ANY IP ADDRESS WITHOUT setting -tlsverify IF YOU DON\'T KNOW WHAT YOU\'RE DOING [!]INFO[0000] libcontainerd: previous instance of containerd still alive (31227)INFO[0000] [graphdriver] using prior storage driver "aufs"ERRO[0002] Error during layer Store.Cleanup(): device or resource busyFATA[0002] Error starting daemon: timeout
[2017-05-10 15:16:10] <SISheogorath> fthamura:  [<-LINK->] 
[2017-05-10 15:16:43] <SISheogorath> Could lead you to the source of the problem
[2017-05-10 17:03:07] <NikIvan> Hey, guys!
[2017-05-10 17:05:26] <NikIvan> I wonder if someone faced issues with 'File not found' on Windows while trying to rundocker-compose upon linux container? ( I am using Win8.1 )
[2017-05-10 17:07:39] <NikIvan> Can it happen because of VirtualBox "shared folder"?
[2017-05-10 17:12:38] <moringaman> Does anyone Know how to get a docker container to run a command after it has started without runningdocker exec -it CONTAINER_ID /bin/bashand running it manually?
[2017-05-10 17:14:01] <NikIvan> My docker-compose.yml: [<-CODE->] 
[2017-05-10 17:38:13] <MajorasJack> Every time I try to run docker-compose up, it hangs when configuring the mysql container, on this line:New password for the MySQL "root" user:Has anyone experienced this before? google results don\'t seem to help much
[2017-05-10 17:38:54] <MajorasJack> My docker-compose.yml file: [<-CODE->] 
[2017-05-10 17:39:02] <MajorasJack> Any help would be amazing
[2017-05-10 17:49:41] <MajorasJack> Already tried removing all containers, images & volumes, still get stuck at the exact same place
[2017-05-10 18:38:46] <MajorasJack> Turns out that the culprit is installing mysql-server on my nginx application container, removing that fixed the issue, unsure why
[2017-05-10 19:16:53] <brittanyrutherford> can we install a complete OS in container?
[2017-05-10 19:17:13] <brittanyrutherford> or are containers just for applications, like DB, etc.. ?
[2017-05-10 19:17:17] <brittanyrutherford> I am still new to this
[2017-05-10 19:17:18] <td444> brittanyrutherford: you can, but defeats the point a bit...
[2017-05-10 19:17:34] <td444> one responsability per container ideally
[2017-05-10 19:17:53] <td444> many presume container = VM, but its really not their intended use
[2017-05-10 19:20:08] <brittanyrutherford> but I see some containers for ubuntu
[2017-05-10 19:20:11] <brittanyrutherford> etc
[2017-05-10 19:20:35] <brittanyrutherford> so isn't this a vm?
[2017-05-10 19:20:52] <td444> yeah, they're a little misleading, more of a very minimal distro (minus system kernel etc) to run your apps or services
[2017-05-10 19:21:23] <td444> see [<-LINK->] for example
[2017-05-10 19:21:23] <brittanyrutherford> so these are minimal OS?
[2017-05-10 19:21:42] <td444> yep
[2017-05-10 19:21:53] <brittanyrutherford> what's this alpine?
[2017-05-10 19:22:10] <td444> have a look - details on page, another very minimal/reduced linux distro, just enough to get stuff going
[2017-05-10 19:22:28] <brittanyrutherford> aha
[2017-05-10 19:22:33] <td444>  [<-LINK->] 
[2017-05-10 19:23:28] <brittanyrutherford> so if containers won't replace vms, what's the usage?
[2017-05-10 19:23:47] <brittanyrutherford> i was watching a pluralsight course, and he says: good bye to vmware, welcome containers
[2017-05-10 19:26:01] <td444> traditionally prior to containers people used VMs per service to host services etc
[2017-05-10 19:26:18] <td444> with containers, you no longer need a big heavy VM just to run a service
[2017-05-10 19:27:07] <td444>  [<-LINK->] 
[2017-05-10 19:27:36] <td444> if your at this level, id suggest going through Docker's own learning material to start with, will help you conceptualise it etc.
[2017-05-10 19:30:26] <brittanyrutherford> which level do u mean
[2017-05-10 19:30:58] <td444> e.g. Docker getting started, work through it a bit?
[2017-05-10 19:31:05] <brittanyrutherford> ah
[2017-05-10 19:31:10] <brittanyrutherford> i was watching a pluralsight course
[2017-05-10 19:31:12] <brittanyrutherford> it confused me a bit
[2017-05-10 19:31:26] <td444> yeah, pluralsight can be hit and miss...
[2017-05-10 19:31:38] <td444> often, doing > watching pluralsight
[2017-05-10 19:32:07] <brittanyrutherford> but how can I do things without understanding first?
[2017-05-10 19:32:39] <td444> follow the getting started guide on Docker's website, its designed for absolute beginners
[2017-05-10 19:32:46] <brittanyrutherford> okay
[2017-05-10 19:32:52] <brittanyrutherford> thanks@td444
[2017-05-10 19:32:58] <td444> rest assured though your not the first person to think container = VM
[2017-05-10 19:33:01] <td444> I get this a lot...
[2017-05-10 19:33:37] <brittanyrutherford> but when u say apps
[2017-05-10 19:33:39] <brittanyrutherford> what kind of apps
[2017-05-10 19:33:49] <brittanyrutherford> for example, I saw a container with mongodb
[2017-05-10 19:33:55] <JinnaBalu> Any apps on the planet
[2017-05-10 19:34:02] <brittanyrutherford> can i get a container with mongodb/express/node together?
[2017-05-10 19:34:31] <td444> you'd get 2 containers ideally - one for mongodb and one for express + node
[2017-05-10 19:34:51] <td444> the idea is to break down the necessary components that make an app into their own containers
[2017-05-10 19:34:58] <brittanyrutherford> aha
[2017-05-10 19:35:21] <brittanyrutherford> can i have windows server as a container?
[2017-05-10 19:35:27] <brittanyrutherford> or that's a stupid question
[2017-05-10 19:35:31] <td444> you can, but its really early days
[2017-05-10 19:35:46] <td444> i.e. much more of a uphill struggle to get working stable compared to linux based containers
[2017-05-10 19:36:01] <brittanyrutherford> aha
[2017-05-10 19:36:34] <brittanyrutherford> how do u know how many apps per container?
[2017-05-10 19:36:45] <JinnaBalu> Yes you can, better you read about docker, come up with the use case.
[2017-05-10 19:37:20] <brittanyrutherford> yeah, i'll start reading the docs
[2017-05-10 19:37:25] <td444> honestly i'd start with the Docker literature and go from there, it seems pluralsight has left you in a confused state
[2017-05-10 19:38:48] <JinnaBalu> docker official docs are pretty clear. and easy to start a basic container.
[2017-05-10 19:39:04] <brittanyrutherford> the thing is, am familiar with windows
[2017-05-10 19:39:11] <brittanyrutherford> will these docs be good for me as a windows user?
[2017-05-10 19:39:19] <brittanyrutherford> or do I need to have experience with linux?
[2017-05-10 19:39:57] <td444>  [<-LINK->] you can use this in Windows to start you off
[2017-05-10 19:39:58] <JinnaBalu> do you want to use your own machine to learn or any cloud?
[2017-05-10 19:40:36] <brittanyrutherford> yea I will use windows 10
[2017-05-10 19:41:31] <JinnaBalu> then you can do with windows?i.e. much more of a uphill struggle to get working stable compared to linux based containers
[2017-05-10 19:42:10] <td444> i thought Docker for Windows fires up a Linux VM in the background, letting you get on ?
[2017-05-10 19:42:12] <brittanyrutherford> no no, I don't wanna make windows containers
[2017-05-10 19:42:21] <brittanyrutherford> I just wanna use my windows OS as host for containers
[2017-05-10 19:42:23] <brittanyrutherford> is it hard?
[2017-05-10 19:44:15] <JinnaBalu> only some port related issues, build related issues, When you run docker in windows it runs on VM, when you try to build a app which is windows based and trying build docker image on docker, there you face and issue with .exe trying to run on linux.
[2017-05-10 19:45:35] <td444> but for what your doing (running linux docker containers) it should be good enough to test
[2017-05-10 19:45:41] <td444> in windows that is
[2017-05-10 19:45:59] <JinnaBalu> Yes.
[2017-05-10 19:46:28] <td444> just give it a try, thats one of the big advanages of Docker vs VM - learning curve is so much smaller to begin with
[2017-05-10 19:50:22] <brittanyrutherford> cool
[2017-05-10 19:50:39] <brittanyrutherford> thanks guys@JinnaBalu@td444appreciate the help
[2017-05-10 19:51:03] <JinnaBalu> please help some one as you learn. hahahahah
[2017-05-10 19:51:19] <brittanyrutherford> hehe, help whom?
[2017-05-10 19:52:36] <JinnaBalu> Whom? there may be someone who is going to ask same here. as you know some you can right?
[2017-05-10 19:53:04] <brittanyrutherford> i am new to this whole thing
[2017-05-10 19:53:26] <brittanyrutherford> if I know something I can help someone with, I will
[2017-05-10 19:54:13] <JinnaBalu> I feel everyone is new to anything as it keeps on evolving
[2017-05-10 19:54:31] <brittanyrutherford> I am just a noob in technology in general
[2017-05-10 19:58:06] <td444> we all started somewhere
[2017-05-10 20:25:38] <SISheogorath> @brittanyrutherford just to make sure you don\'t get container wrong: the base images like "ubuntu", "debian", "fedora" or "alpine" have one reason: Tooling. [<-CODE->] To run Linux containers on windows you can use Docker4Windows. In it\'s default setup it creates a VM in background which runs linux and executes the containers for you. You shouldn\'t notice it. On docs.docker.com you should find a few easy tutorials. But if you want an more interactive way to learn how to use container even if you have no idea about Linux, maybe http://training.play-with-docker.com is the place you want to visit. The tutorials are very detailed and should help you to get started very easy and fast
[2017-05-10 20:27:37] <SISheogorath> moringaman: you can run them directly ->docker exec CONTAINERID /path/to/command arg1 arg2or you have to setup something likesupervisordinside your container which manage these things but I don't recommend it
[2017-05-10 20:30:22] <SISheogorath> MajorasJack: have you tried to access your application when it "hangs"? Becausedocker-compose updoesn\'t detach the log so the command "doesn\'t end" by design (if you want to detach it usedocker-compose up -d). Sry if you know that and you\'re sure it\'s a but, just ask to make sure you don\'t miss anything
[2017-05-10 20:32:40] <SISheogorath> NikIvan: You use the docker toolbox, don't you? Does [<-LINK->] help?
[2017-05-10 20:36:17] <NikIvan> SISheogorath: Yes, I am using toolbox. And start docker with "Docker Quickstart Terminal" and Keenetic doens\'t run at all - some weird errors
[2017-05-10 20:36:48] <NikIvan> Thank you for sharing this link. I think it's the my problem that moment
[2017-05-10 20:37:40] <NikIvan> Because you can setup shared drives with one checkbox in Win10 docker UI and for Win8.1 it makes some pain...
[2017-05-10 20:40:20] <NikIvan> SISheogorath: so, let\'s say, if I want to share whole my D drive then I should input something like this:VBoxManage sharedfolder add "boot2docker-vm" --name "D:" --hostpath "D:\\"??
[2017-05-10 20:42:53] <SISheogorath> looks fine, can't say for sure, as I don't use windows or virtual box the easiest way to see if it works or not is testing it
[2017-05-10 20:48:43] <NikIvan> SISheogorath: Thank you for help. I will try.
[2017-05-10 20:49:19] <NikIvan> By the way, what are you using? Ubuntu? Mac? :)
[2017-05-10 20:50:05] <SISheogorath> Fedora :D
[2017-05-10 20:50:51] <brittanyrutherford> SISheogorath: thanks :)
[2017-05-10 20:51:15] <brittanyrutherford> hello world for docker hehe
[2017-05-10 20:51:29] <NikIvan> For historical reasons or it's the best distro nowadays objectively?
[2017-05-10 20:51:36] <NikIvan> SISheogorath: 
[2017-05-10 20:55:13] <SISheogorath> I think objectively there is no best distro :D All distros have their pros and cons. I use fedora because I like the way how Red hat builds it\'s things and for fast support in case something is broken. I guess otherwise I would use Arch or Gentoo. Ubuntu is very stable but I never really got the "ubuntu love" many people like :D It\'s a good distro for people who want to find solutions fast. Their community is very active and the ubuntu user help is very very good. It\'s like every question you can think about as a beginner is already answered somewhere :D But they are often very universal if you invest a few minutes more and work on other distros, too so I don\'t loose anything :D
[2017-05-10 21:06:03] <brittanyrutherford> why do I need to use container to push my changes to container registry, then to AWS/Azure?
[2017-05-10 21:06:19] <brittanyrutherford> I am not seeing the value of docker if it can't replace virtual machines :(
[2017-05-10 21:41:59] <moringaman> brittanyrutherford: Thanks, what’s the problem with supervisord?
[2017-05-10 21:43:31] <brittanyrutherford> moringaman: what supervisord?
[2017-05-10 21:47:14] <moringaman> brittanyrutherford: - Apologies I meant to address@SISheogorathwith that question, but I think it’s a process manager for docker containers
[2017-05-10 21:54:38] <KramKroc> Hi folks. I’m doing some investigation into docker 1.13 & swarm. We use Spring Boot Microservices with Eureka for service discovery of the services. I’m having problems with getting our services to see each other. Some of the services start on the ingress network, and others on the network I created for the stack. It’s pretty confusing and I’m not entirely sure if it’s an issue that I’ve created in docker stack setup or how I define my service definition in Eureka. I’ve created a much smaller microservice system that reproduces the steps I followed and I wondered if someone could take a look to see if I’m missing something from my network definition or service definition in the compose file: [<-LINK->] 
[2017-05-10 22:14:07] <brittanyrutherford> I am trying to run docker on windows, since I have windows home edition, i must install docker toolbox, so i was walking through the steps here: [<-LINK->] and I ran the command: docker info   but I got this error
[2017-05-10 22:14:28] <brittanyrutherford> error during connect: Get http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.28/info: open //./pipe/docker_engine: The system cannot find the file specified. In the default daemon configuration on Windows, the docker client must be run elevated to connect. This error may also indicate that the docker daemon is not running.
[2017-05-10 22:14:46] <brittanyrutherford> any idea?@td444@JinnaBalu@SISheogorath?
[2017-05-10 22:20:35] <SISheogorath> Docker for Windows doesn't work on Home. (when I recall correct) In this case you have to use the docker toolbox
[2017-05-10 22:21:28] <SISheogorath>  [<-LINK->] 
[2017-05-10 22:25:08] <NikIvan> brittanyrutherford: try to run using the link, that you should have after installation
[2017-05-10 22:25:15] <NikIvan> Docker Quickstart Terminal
[2017-05-10 22:25:26] <NikIvan> It should start daemon
[2017-05-10 22:32:52] <SISheogorath> moringaman: supervisord restart processes inside the docker without let the docker daemon noticing it which possibly breaks some good features. I don't use it in my projects. The official docs recommend it for some cases. [<-LINK->] 
[2017-05-10 22:36:44] <SISheogorath> KramKroc: how did you create the external network? did you use-d overlay?
[2017-05-10 22:45:14] <brittanyrutherford> NikIvan: which link?
[2017-05-10 22:54:15] <SISheogorath> @brittanyrutherfordI am not seeing the value of docker if it can't replace virtual machines :(The idea is that container reduce maintainence work and are reproducible. They are also more efficient in speech of resources like RAM and CPU time. You can imagine that because in a VM you run your own process manager, and own kernel, every kernel process, and remote management software (like SSH or maybe a puppet or Saltstack agent), you run you application, etc. This uses ressources for every VM. And also a VM takes time for booting. which is wasted time. and very expensive time, if your application get's hit by a traffic peak. Container don't need to boot. They need a few milliseconds to setup an isolated kernel environment and their mount points for data and start the process of your application. That's it. Also Containers, other than regular VMs, are images that are not changeable and still maintainable. You build them multiple, maybe more then 20 times a day and deploy them to your entire infrastructure. And as they are immutable you don't have to fear that there is a package corrupt or a config file not correct installed. Last but not least container have a shorter live time than VMs and allow you to run them with a read-only filesystem and minimal tmpfs for needed tempfiles. Which makes them nearly immune against Viruses as there is no place where a virus and other malware can stay.For sure you can build immutable VMs and reproducible VM builds, but there is currently no comparable tooling to docker for that and you still waste tons of resources for nothing when you use VMs instead of Containers
[2017-05-10 23:04:40] <brittanyrutherford> SISheogorath: ummm
[2017-05-10 23:06:40] <brittanyrutherford> but if all containers share the same kernel, and one of the containers causes a problem or memory leak, it would affect all other containers, right?
[2017-05-10 23:07:52] <brittanyrutherford> I am still having issues running either : docker ps or docker info on windows
[2017-05-10 23:08:09] <brittanyrutherford> I am getting this error for docker ps
[2017-05-10 23:08:15] <brittanyrutherford> error during connect: Get http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.28/containers/json: open //./pipe/docker_engine: The system cannot find the file specified. In the default daemon configuration on Windows, the docker client must be run elevated to connect. This error may also indicate that the docker daemon is not running.
[2017-05-10 23:08:29] <brittanyrutherford> and this for running docker info
[2017-05-10 23:08:31] <brittanyrutherford> error during connect: Get http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.28/info: open //./pipe/docker_engine: The system cannot find the file specified. In the default daemon configuration on Windows, the docker client must be run elevated to connect. This error may also indicate that the docker daemon is not running.
[2017-05-10 23:08:47] <brittanyrutherford> which is basically the same error I guess
[2017-05-10 23:11:04] <SISheogorath> As I mentioned did you check the requirements page? Is your system HyperV capable?
[2017-05-10 23:11:46] <brittanyrutherford> i installed docker toolbox, since I don't have hyperv
[2017-05-10 23:11:54] <SISheogorath> I see
[2017-05-10 23:11:56] <brittanyrutherford> so i have oracle virtualboxk
[2017-05-10 23:12:03] <brittanyrutherford> i can run docker --version
[2017-05-10 23:12:12] <SISheogorath> you use the docker quickstart terminal?
[2017-05-10 23:12:13] <brittanyrutherford> docker-compose --version
[2017-05-10 23:12:24] <brittanyrutherford> no, the doc didn't say anything about it
[2017-05-10 23:12:32] <brittanyrutherford>  [<-LINK->] 
[2017-05-10 23:12:38] <brittanyrutherford> they just said open a shell
[2017-05-10 23:12:41] <brittanyrutherford> so am using gitbash
[2017-05-10 23:12:55] <SISheogorath> in this case you are back to the docker4Windows docs. You have to see the docker toolbox docs
[2017-05-10 23:13:10] <brittanyrutherford> ahaa
[2017-05-10 23:13:37] <brittanyrutherford> is it like totally different environment?
[2017-05-10 23:14:26] <SISheogorath>  [<-LINK->] 
[2017-05-10 23:14:27] <brittanyrutherford> if I get a linux VM, would it work?
[2017-05-10 23:21:29] <brittanyrutherford> that's cool, it worked@SISheogorath:D
[2017-05-10 23:21:42] <brittanyrutherford> thanks a lot!
[2017-05-10 23:21:55] <SISheogorath> You're welcome
[2017-05-10 23:22:36] <SISheogorath> And about the memory leak question: docker uses linux cgroups in kernelspace. This way you can limit the memory allocation like you know it from VMs
[2017-05-10 23:23:31] <brittanyrutherford> aha, am not that familiar with VMs, I only used VmWare
[2017-05-10 23:23:46] <brittanyrutherford> i just started learning node/mongodb, and I want to learn about docker as well
[2017-05-10 23:23:58] <brittanyrutherford> and see how I can make everything work together
[2017-05-10 23:24:38] <brittanyrutherford> Question, after the "Step 3: Verify your installation" in the docs, do I return back to the original docs?
[2017-05-10 23:24:42] <brittanyrutherford> for windows?
[2017-05-10 23:25:28] <SISheogorath> you should be able to run docker like docker for windows as long as you use the quickstart terminal. Can't say for sure (never used it myself) but iirc it should work
[2017-05-10 23:26:06] <brittanyrutherford> but I can't follow the this? [<-LINK->] 
[2017-05-10 23:31:09] <SISheogorath> docker run hello-worlddoesn't work?
[2017-05-10 23:31:29] <SISheogorath> you should be able to follow it
[2017-05-10 23:32:02] <SISheogorath> does should work like everywhere (more or less. you may run into trouble with port mappings or host mounts :/)
[2017-05-10 23:33:11] <brittanyrutherford> it works
[2017-05-10 23:33:27] <brittanyrutherford> but I mean, can't i follow the get started link?
[2017-05-10 23:33:32] <brittanyrutherford> not the one for windows?
[2017-05-10 23:45:21] <SISheogorath> you possibly can. In general docker toolbox sets up a docker VM and docker tools for windows so you use it from this powershell environment the quickstart terminal sets up for you. I can't say a lot about details, but it sounds like@NikIvancan maybe explain it more detailed as he uses it actively
[2017-05-11 00:05:54] <brittanyrutherford> SISheogorath: thank you
[2017-05-11 07:06:47] <KramKroc> SISheogorath: hi, yes, I created the network with -d overlay [<-CODE->] 
[2017-05-11 08:19:33] <briantyr> hey everyone, setting up a docker swarm env in AWS on 8 nodes ( 3 manager, 5 swarms - using Docker CE).  Is it fine if I create my own CA and use that to sign the certs for each docker daemon's TLS cert?  If so, can I put something like nginx between the Swarm cluster and the users themselves so they won't see any issues with invalid CA or anything like that?  Finally, if I create my own Docker Registry, will that work alright with the fake CA's / self-signed certs?  I'm doing this on AWS , and have a private hosted zone.swarm.example.com and a public zone of.example.com..   any ideas?
[2017-05-11 08:33:36] <SISheogorath> briantyr: the only sockets you really need to secure are the ones you expose. In this case you shouldn't expose more than needed which means the only should expose the sockets of the manager nodes. But in general if you really want it it also works for worker nodes, too. Yes, you can secure them the same way you secured non-swarm-mode nodes and use thrm alike, even when I don't recommend it.
[2017-05-11 08:34:50] <SISheogorath> For the registry I simply recommend to not use a self-signed certificate. Since Let's encrypt exists there is no real reason to use a self-signed one
[2017-05-11 08:34:51] <briantyr> SISheogorath: thanks, you mean expose the TCP sockets  and not the unix docker.socket?
[2017-05-11 08:35:12] <briantyr> i thought the registry had to use the same as the docker cluster... guess I know nothing
[2017-05-11 08:35:20] <briantyr> acatually it makes sense that it wouldnt
[2017-05-11 08:35:33] <briantyr> considering docker hub and billions of ppl from pulling from it on their own swarm..
[2017-05-11 08:36:00] <SISheogorath> The registry does normal validation like wget or curl when you download something
[2017-05-11 08:36:26] <briantyr> so yeah, basically I already have the nodes running, they are listening on the 2376 port and i'm at the point where I need to generate the CA and self-signed certs... unfortunately this is due in a few hours (that + verifying swarm and testing 15 containers end to end yayyy)
[2017-05-11 08:36:38] <SISheogorath> And yes I was talking about the TCP socket
[2017-05-11 08:36:40] <briantyr> iw was goign to use letsencrypt everywhere else
[2017-05-11 08:37:06] <SISheogorath> In general it doesn't really matter
[2017-05-11 08:37:36] <briantyr> im doing this in AWS, do you by chance thinkk there is an ideal AWS instance type for Docker (that is affordable, like m4.xlarge and less)?
[2017-05-11 08:37:59] <briantyr> I want this for long term development environment by 50+ devs
[2017-05-11 08:38:25] <briantyr> so it will add up quickly, but I have used Packer to create an AMI with an initial 200gb per node and I use LVM
[2017-05-11 08:38:40] <SISheogorath>  [<-LINK->] 
[2017-05-11 08:38:50] <briantyr> yeah im reading that link now :)
[2017-05-11 08:39:16] <briantyr> we have over 200 containers we'll be running initially
[2017-05-11 08:39:31] <SISheogorath> There is docker4AWS if you talk about an "ideal setup" ;)
[2017-05-11 08:39:46] <briantyr> I used nginx (openresty) + consul + consul-template before and was going with  that again probably
[2017-05-11 08:39:47] <SISheogorath> Everything important already preconfigured
[2017-05-11 08:39:51] <briantyr> nooo!
[2017-05-11 08:40:00] <briantyr> well dont you have to pay for it
[2017-05-11 08:40:05] <briantyr> and isnt it somewhat restricted in features?
[2017-05-11 08:41:26] <briantyr> i like to have full control and learn stuff too :)  If I can just get 3-4 nodes up, get swarm with TLS working, and then have an ELB/ALB  work with the external facing load balancer that routes into the swarm, I'm good.  I'll try to get a load balancer on the registry too, from what I understand you're able to use multiple instances of it backed by S3
[2017-05-11 08:41:43] <briantyr> sound right to you@SISheogorath? :)
[2017-05-11 08:42:03] <SISheogorath>  [<-LINK->] 
[2017-05-11 08:42:58] <SISheogorath> Yes you can use multiple instances with S3 backend
[2017-05-11 08:44:01] <briantyr> awesome thats what I thought ... thanks for confirming that for me
[2017-05-11 08:44:06] <briantyr> much appreciated it man
[2017-05-11 08:44:14] <SISheogorath> I'm in general not an Amazon guy so :D can't tell you much about their way to do things in general. My setups are distributed between smaller cloud providers ^^
[2017-05-11 08:45:19] <SISheogorath> KramKroc: how did you check the netwoeks the nodes are on?
[2017-05-11 08:52:10] <KramKroc> Hi@SISheogorathI did a docker network inspect and they seem to be present in both the ingress network and the demo-network
[2017-05-11 09:00:40] <SISheogorath> It's normal they are on the ingress network as long as they expose a port
[2017-05-11 09:32:41] <moringaman> SISheogorath: Good to know, thanks!
[2017-05-11 09:43:39] <KramKroc> SISheogorath: is there any reason why they can’t communicate from one network to the other?
[2017-05-11 10:58:22] <SISheogorath> I'm nit completely sure what you mean here. They need the ingress overlay network in swarm because it's the docker routing mesh for swarm mode and used to find the right container
[2017-05-11 10:58:51] <SISheogorath> And they use the network you created for container-to-container communication
[2017-05-11 11:09:26] <HendrikRoth> Hello i have a basic question.. i would like base my dockerimage on an other automatic docker build. But how can i override the ENTRYPOINT? After trying, the image is not working anymore (no error log, just exists direct)
[2017-05-11 11:13:49] <HendrikRoth>  [<-LINK->] 
[2017-05-11 11:30:08] <SISheogorath> I'm not sure howtiniacts here I'm pretty sure that the Dockerfile is fine and the entrypoint script itself is also okay. The only component that can cause problems in my opinion istinias I never used it and have no idea how exactly it reacts.
[2017-05-11 11:31:38] <NikIvan> SISheogorath: @brittanyrutherfordAt last I've started my project on Win8.1. The main steps I was missing are
[2017-05-11 11:31:52] <HendrikRoth> SISheogorath: without tini i have the same issue
[2017-05-11 11:32:22] <NikIvan> Share project folder using VirtualBox machine preferences to my docker VM
[2017-05-11 11:32:47] <NikIvan> Link ports 80 of my VM to my host 80
[2017-05-11 11:33:38] <NikIvan> So, it looks like I have double port forwarding - from container to VM and then from VM to host
[2017-05-11 11:34:13] <NikIvan> Such a pain... :)
[2017-05-11 11:35:57] <HendrikRoth> or is it not possible to overwrite an entrypoint?
[2017-05-11 12:35:18] <KramKroc> SISheogorath: I meant that fromcontainer Ai canpingthe ip address forcontainer Bfor it’s IP address on the ingress network and the container network. But when I do awgetfrom container A, it only works for the ip address on the container network.
[2017-05-11 13:17:18] <brittanyrutherford> NikIvan: thanks
[2017-05-11 13:19:43] <brittanyrutherford> what is docker hello-world?
[2017-05-11 13:19:54] <brittanyrutherford> they say on the website that it gets an image.. but an image for what?
[2017-05-11 13:19:59] <brittanyrutherford> what did I just download??
[2017-05-11 13:20:50] <JinnaBalu>  [<-LINK->] 
[2017-05-11 13:21:10] <JinnaBalu> follow this steps.
[2017-05-11 13:21:43] <brittanyrutherford> yea am in windows docker documentation, I am going to install ubuntu now
[2017-05-11 13:21:57] <brittanyrutherford> will download the ubuntu container image and start it.
[2017-05-11 13:22:13] <brittanyrutherford> but I didn't understand the hello-world part, what is that
[2017-05-11 13:23:27] <JinnaBalu> It is just a static helloworld page docker image, so that we can test whether docker installed or not.
[2017-05-11 13:23:45] <brittanyrutherford> umm
[2017-05-11 13:23:56] <brittanyrutherford> in the docs, it said:docker run -it ubuntu bash
[2017-05-11 13:24:03] <brittanyrutherford> but how do I use it?\\
[2017-05-11 13:24:16] <JinnaBalu>  [<-LINK->] 
[2017-05-11 13:24:22] <brittanyrutherford> they are just making me execute commands and not telling me what's going on ..
[2017-05-11 13:24:22] <JinnaBalu> this i sthe image.
[2017-05-11 13:25:05] <brittanyrutherford> when I ran this command: docker run -it ubuntu bash
[2017-05-11 13:25:23] <brittanyrutherford> now the terminal is waiting for me to type something, at :root@3aa3a42b80b9:/#
[2017-05-11 13:25:36] <JinnaBalu>  [<-CODE->] 
[2017-05-11 13:25:43] <JinnaBalu> then bash into it
[2017-05-11 13:25:58] <JinnaBalu> so that you can use that container as a OS
[2017-05-11 13:26:15] <brittanyrutherford>  [<-LINK->] 
[2017-05-11 13:26:18] <brittanyrutherford> see here
[2017-05-11 13:26:22] <brittanyrutherford> what should I type?
[2017-05-11 13:26:29] <brittanyrutherford> it's waiting for me to type something
[2017-05-11 13:27:15] <brittanyrutherford> i just typed exit
[2017-05-11 13:27:20] <purefan> brittanyrutherford: when you rundocker run -it ubuntu bashit is saying "hey docker,runan interactive terminal (-i+-t=-it) on the imageubuntuthe commandbash
[2017-05-11 13:27:59] <purefan> its not expecting you to write anything, if you were able to runbashthen it worked
[2017-05-11 13:28:14] <purefan> you can use it for something else but the point of the hello-world is just to test that it worked
[2017-05-11 13:28:22] <brittanyrutherford> am not familiar with ubuntu.. that's why am on windows docs  what is bash
[2017-05-11 13:29:02] <purefan> (hope there are no die hard linux fans here) but bash is like a terminal, its like if you're in CMD and run powershell, or viceversa
[2017-05-11 13:29:20] <brittanyrutherford> i know ubuntu is an OS
[2017-05-11 13:29:26] <purefan> so yeah you can run programs from bash, it's like powershell in many ways
[2017-05-11 13:29:32] <brittanyrutherford> I was expecting to give me an IP so I can navigate to the OS remotely
[2017-05-11 13:29:45] <purefan> I dont think the hello world sets up all that for you
[2017-05-11 13:29:53] <brittanyrutherford> no, not hello world
[2017-05-11 13:29:58] <brittanyrutherford> this
[2017-05-11 13:30:00] <brittanyrutherford>  [<-CODE->] 
[2017-05-11 13:30:17] <brittanyrutherford> didn't i download ubuntu image? why can't I open the OS remotely?
[2017-05-11 13:30:31] <purefan> ok so that is running on a docker container called ubuntu, this docker container may have installed a bunch of stuff automatically, but maybe its just a bare bones OS image
[2017-05-11 13:30:31] <JinnaBalu> You can install on Windows. Use Kitamatics GUI based. for windows users. [<-LINK->] 
[2017-05-11 13:30:41] <purefan> JinnaBalu: I think she's way past that point
[2017-05-11 13:31:16] <brittanyrutherford> I have kitemantics
[2017-05-11 13:31:19] <brittanyrutherford> but am using the CLI
[2017-05-11 13:31:34] <purefan> brittanyrutherford: you did start a docker container that runs ubuntu, but if you want to browse to that container with say google chrome you need to install a webserver inside the ubuntu container
[2017-05-11 13:31:35] <JinnaBalu> Use Kitamatics, it will help you.
[2017-05-11 13:31:37] <brittanyrutherford> am just walking through the docker for windows documentation
[2017-05-11 13:31:47] <rbuckland> brittanyrutherford: the base ubuntu docker image is "bare bones", it has nothing in there really. you would need to add an ssh-server if you want to "connect to it" remotely. but I also don;\'t think you would be looking for that.
[2017-05-11 13:32:03] <brittanyrutherford> ahaa
[2017-05-11 13:32:15] <brittanyrutherford> I thought Ubuntu is like windows, where I can open RDP and navigate to it
[2017-05-11 13:32:19] <brittanyrutherford> and see desktop/icons
[2017-05-11 13:32:32] <purefan> you can do that but you need to install a bunch of stuff
[2017-05-11 13:32:48] <purefan> for example if your ubuntu image is a server it doesn't have a windows manager installed
[2017-05-11 13:32:54] <brittanyrutherford> so why do u use Ubuntu without a GUI?
[2017-05-11 13:33:07] <JinnaBalu> am just walking through the docker for windows documentation Better do this first and come up with questions. and google will help more than everyone else.
[2017-05-11 13:33:17] <purefan> because there's no need for a GUI :) we automate everything with scripts and run commands
[2017-05-11 13:33:25] <JinnaBalu> hahahah
[2017-05-11 13:33:30] <brittanyrutherford> aha
[2017-05-11 13:34:05] <brittanyrutherford> JinnaBalu: I am reading it, but I found myself executing commands and not understanding why am doing them, and I am still clueless in all of this to search on google, I don't know what to search for in the first place
[2017-05-11 13:34:33] <brittanyrutherford> anyway, thanks a lot everyone
[2017-05-11 13:34:38] <brittanyrutherford> sorry for my dumb questions
[2017-05-11 13:35:12] <rbuckland> brittanyrutherford: I politely ask, what are you wanting to learn out of Docker ? What was the reason you came to investigate docker ? (great place to look :-) )
[2017-05-11 13:35:55] <brittanyrutherford> rbuckland: this : [<-LINK->] 
[2017-05-11 13:36:04] <brittanyrutherford> people posted this on freecodecamp page
[2017-05-11 13:36:36] <brittanyrutherford> so I watched this pluralsight course (1 hour introduction), and the guy said that many things will be shifted to docker
[2017-05-11 13:37:00] <brittanyrutherford> so I started checking it out and see if I can take my node apps to docker
[2017-05-11 13:37:03] <brittanyrutherford> and containers
[2017-05-11 13:37:13] <brittanyrutherford> I don't know what am doing or why I might need it
[2017-05-11 13:37:17] <brittanyrutherford> so am checking it out
[2017-05-11 13:37:35] <brittanyrutherford> as I said, I am a windows user
[2017-05-11 13:37:45] <brittanyrutherford> I come from ASP.NET background
[2017-05-11 13:37:52] <rbuckland> Okay - so .. docker is many things - but a "container" is a way to "package" your application and deploy it. or give it to someone else to deploy it ,or automate the deployment of it.
[2017-05-11 13:37:54] <brittanyrutherford> so I am even new to node world
[2017-05-11 13:38:12] <JinnaBalu> create a application simple one and try to run that with docker.
[2017-05-11 13:38:32] <brittanyrutherford> JinnaBalu: yeah, that's what I wanna do eventually, that's why am reading the docs
[2017-05-11 13:38:33] <rbuckland> you can create a "node" application, your next great idea as a web app, and deploy that node application, in a docker container (wrap it up) .. and run it somewhere.
[2017-05-11 13:38:44] <brittanyrutherford> but I got lost with all these commands, and not knowing why am executing them
[2017-05-11 13:39:21] <brittanyrutherford> in the docs they just say: take this command, run it.. u will have a container.. take this next command, run it, u will have a container.. ok ??? :S
[2017-05-11 13:39:25] <brittanyrutherford> that's when I asked u guys
[2017-05-11 13:39:49] <rbuckland> see how you go with this - [<-LINK->] 
[2017-05-11 13:41:11] <rbuckland> where ever that article talks about "boot2docker", that has now been replaced (updated) with "Docker for Mac"
[2017-05-11 13:41:26] <brittanyrutherford> I executed this command:docker run -d -p 80:80 --name webserver nginxas written here: [<-LINK->] 
[2017-05-11 13:41:41] <brittanyrutherford> they said: > Point your web browser at [<-LINK->] to display the start page.
[2017-05-11 13:41:41] <JinnaBalu>  [<-LINK->] 
[2017-05-11 13:41:47] <JinnaBalu> do this course.
[2017-05-11 13:41:59] <brittanyrutherford> i navigated to localhost, but there's nothing ..
[2017-05-11 13:42:00] <JinnaBalu> its about 30minc to complete
[2017-05-11 13:42:13] <brittanyrutherford> thanks@JinnaBalu
[2017-05-11 13:42:20] <brittanyrutherford> rbuckland: I will check that out, thanks
[2017-05-11 13:42:45] <rbuckland> brittanyrutherford: -@JinnaBalu's will better
[2017-05-11 13:43:20] <brittanyrutherford> why am I not seeing anything in [<-LINK->] ?
[2017-05-11 13:43:47] <brittanyrutherford> shouldn't this command run a web server ?docker run -d -p 80:80 --name webserver nginx?
[2017-05-11 13:44:24] <purefan> brittanyrutherford: almost, it depends on the nginx configuration, it assumes that nginx was installed
[2017-05-11 13:44:54] <brittanyrutherford> isn't nginx an image?
[2017-05-11 13:45:00] <brittanyrutherford> do I need to install stuff locally?
[2017-05-11 13:45:07] <JinnaBalu> port issue, goto kitematics and expose the port. Basically try all images in Kitematics. and try to run them using command prompt. so you will understand.
[2017-05-11 13:45:38] <brittanyrutherford> oik
[2017-05-11 13:45:53] <purefan> brittanyrutherford: nginx is a web server, like apache or IIS, it needs to be installed in thewebservercontainer
[2017-05-11 13:45:55] <rbuckland> brittanyrutherford: it should work - I just tried it on my mac and that did show the default "Welcome to nginx"
[2017-05-11 13:45:59] <JinnaBalu> everything runs on container. when you stop container it disapears and your memory will be free.
[2017-05-11 13:46:23] <rbuckland> You're on Windows yes ?
[2017-05-11 13:46:40] <brittanyrutherford> rbuckland: yea
[2017-05-11 13:46:44] <brittanyrutherford> hmmm
[2017-05-11 13:46:56] <brittanyrutherford> what if i have multiple containers with web servers
[2017-05-11 13:47:01] <brittanyrutherford> then i run docker run webserver
[2017-05-11 13:47:07] <brittanyrutherford> which one will be running?
[2017-05-11 13:47:26] <purefan> in your examplewebserveris the name of only one of your containers, you cannot have duplicate names
[2017-05-11 13:47:30] <rbuckland> trydocker run -d -p 8001:80 --name webserver nginxand then navigate to [<-LINK->] 
[2017-05-11 13:47:34] <brittanyrutherford> aaah
[2017-05-11 13:47:40] <brittanyrutherford> purefan: got u
[2017-05-11 13:47:42] <JinnaBalu>  [<-CODE->] 
[2017-05-11 13:47:58] <JinnaBalu> docker run -d -p 80:80 --name sample nginx
[2017-05-11 13:47:59] <brittanyrutherford> that was a misleading server name 
[2017-05-11 13:48:06] <purefan> :D
[2017-05-11 13:48:41] <purefan> here's the [<-LINK->] btw, a lot to read but a good reference when looking for what a specific command does
[2017-05-11 13:49:31] <brittanyrutherford> rbuckland: same thing: [<-LINK->] 
[2017-05-11 13:49:58] <brittanyrutherford> purefan: yeah, am still going through : [<-LINK->] 
[2017-05-11 13:50:02] <brittanyrutherford> but it's confusing
[2017-05-11 13:50:32] <purefan> dont sweat it, in case you haven't noticed there's a bunch of good folks here willing to help :)
[2017-05-11 13:51:16] <purefan> also, it helps that yours are newbie questions, wait until you get to the networking bits and you'll see far less people jumping in 
[2017-05-11 13:51:36] <brittanyrutherford> haha, I opened kitemantics, and navigated to ports
[2017-05-11 13:52:09] <brittanyrutherford> and saw something like this:
[2017-05-11 13:52:17] <brittanyrutherford>  [<-LINK->] 
[2017-05-11 13:52:33] <SISheogorath> KramKroc: I'm not completely sure right now but I guess it's part of the network isolation stack. Check the IPtables forward rules. And in general there is some crazy stuff the with docker-proxy so I wouldn't wonder why the ingress network is handled uncommon
[2017-05-11 13:52:37] <brittanyrutherford> so i opened this: [<-LINK->] .. and it opened my website !!!
[2017-05-11 13:52:45] <brittanyrutherford> no idea why localhost didn't work
[2017-05-11 13:53:15] <purefan> oh boy... now we\'re getting into the"networking bits"xD
[2017-05-11 13:54:16] <purefan> I guess the explanation is becauselocalhostis a loopback interface and it skips the DNS, maybe related to the network bridge docker creates on windows but not really sure
[2017-05-11 13:54:28] <brittanyrutherford> hmmm
[2017-05-11 13:54:34] <purefan> lets throw another word in there --> dhcp
[2017-05-11 13:54:35] <rbuckland> purefan: it is for that reason.
[2017-05-11 13:54:42] <brittanyrutherford> i might just map localhost to 192 in the host file
[2017-05-11 13:54:49] <purefan> Woohooo! :D I was at least 31% unsure
[2017-05-11 13:54:53] <rbuckland> brittanyrutherford: no don't do that.
[2017-05-11 13:55:09] <rbuckland> just know that your docker "container" is running on 99.100
[2017-05-11 13:55:16] <purefan> that would basically implode your windows and make your coffee salty
[2017-05-11 13:55:19] <brittanyrutherford> ok
[2017-05-11 13:55:24] <brittanyrutherford> haha
[2017-05-11 13:55:37] <SISheogorath> HendrikRoth: only the lastENTRYPOINTtag is used for your container. you can overwrite it for sure
[2017-05-11 13:56:05] <brittanyrutherford> when I executed the command second time with a new -name webserver2 .. it made one quickly for me :O
[2017-05-11 13:56:11] <brittanyrutherford> that's cool
[2017-05-11 13:56:46] <rbuckland> purefan: the localhost is still resolved to a local IP 127.0.0.1.. but@brittanyrutherfordcontainer is not running on her windows machine "natively" .. or "locally" it is running ina virt machine, and that virt machine has the ip of 192.168.99.100
[2017-05-11 13:57:17] <purefan> Im running behind a corporate proxy, and part of the set up is thatlocalhostmaps to an external ip, had to addlocal.devto my hosts file and map it to 127.0.0.1 
[2017-05-11 13:57:42] <rbuckland> purefan: I am so sorry :-D
[2017-05-11 13:57:51] <rbuckland> that is a shame.
[2017-05-11 13:58:15] <brittanyrutherford> rbuckland: that explains things
[2017-05-11 13:59:03] <purefan> it reaallyy iss... I also run into a bunch of issues with virtual machines, had debian magically installed when I was handed the computer and have failed to set up a copy of that, dont need vms for day to day work but it does suck big time
[2017-05-11 13:59:52] <rbuckland> your windows box has (most likely) a 192.168.99.x IP address .. so that your windows machine and the docker host (the engine running the containers) can talk to each other.
[2017-05-11 14:00:36] <rbuckland> I am "long time since"running windows .. but Start > run > cmd > ipconfig .. shows you your windows box IP\'s
[2017-05-11 14:00:42] <rbuckland> or ipconfig /all
[2017-05-11 14:00:48] <rbuckland> (there are other ways).
[2017-05-11 14:01:04] <brittanyrutherford> rbuckland: actually my IP is : 192.168.3.40
[2017-05-11 14:01:28] <rbuckland> that is your "internet" one ... it has another .. on the 192.168.99.x (potentially)
[2017-05-11 14:01:39] <brittanyrutherford> this is my lan IP
[2017-05-11 14:01:57] <brittanyrutherford> oracle virtual box IP: 192.168.99.1
[2017-05-11 14:02:10] <rbuckland> Yes - that is your other one.
[2017-05-11 14:02:36] <rbuckland> learning alittleabout networking will help you a long long way.
[2017-05-11 14:03:24] <brittanyrutherford> actually oracle has 2 IPs..Ethernet adapter VirtualBox Host-Only Network:   IPv4 Address. . . . . . . . . . . : 192.168.56.1Ethernet adapter VirtualBox Host-Only Network [<-ISSUE->] : IPv4 Address. . . . . . . . . . . : 192.168.99.1
[2017-05-11 14:04:08] <brittanyrutherford> then I have the Lan adapter: IPv4 Address. . . . . . . . . . . : 192.168.3.40
[2017-05-11 14:04:16] <rbuckland> Yes that is often the case that Virtualbox sets up a few networks for you.
[2017-05-11 14:04:46] <rbuckland> They are all "local" for you only. (unless you do magic hocus to expose them via bridges and the like(.
[2017-05-11 14:04:50] <brittanyrutherford> maybe it's sufficient to have only 2 first numbers to be the same: 192.168 
[2017-05-11 14:05:11] <rbuckland> 192.168.x.xis a private IP address space
[2017-05-11 14:05:12] <brittanyrutherford> anyway
[2017-05-11 14:05:30] <rbuckland> most peoples home routers will also use that IP address - space.
[2017-05-11 14:06:21] <brittanyrutherford> aha
[2017-05-11 14:06:26] <brittanyrutherford> i think am on track now :D
[2017-05-11 14:06:46] <brittanyrutherford> thanks for everything guys@rbuckland@purefan@JinnaBalu
[2017-05-11 14:06:53] <rbuckland> It will help and confuse you to know that your "webserver" container - inside the container hasanotherIP address again.
[2017-05-11 14:07:05] <brittanyrutherford> :O
[2017-05-11 14:07:09] <purefan>  [<-LINK->] 
[2017-05-11 14:07:39] <brittanyrutherford> rbuckland: I don't wanna know that ..
[2017-05-11 14:07:41] <brittanyrutherford> haha
[2017-05-11 14:07:57] <rbuckland> typically that IP address (for docker) is172.16-17.x.x.
[2017-05-11 14:07:58] <purefan> or that you can ssh into your container and ssh into another container and ssh into.... 
[2017-05-11 14:08:09] <brittanyrutherford> :S
[2017-05-11 14:08:19] <brittanyrutherford> formatting windows in 5 mins ..
[2017-05-11 14:08:19] <rbuckland> brittanyrutherford: enjoy!
[2017-05-11 14:08:19] <brittanyrutherford> haha
[2017-05-11 14:08:43] <purefan> yeah!! install some linux distro, come to the dark side! 
[2017-05-11 14:08:56] <brittanyrutherford> I love windows :'(
[2017-05-11 14:09:05] <purefan> ... we have cookies...
[2017-05-11 14:09:11] <brittanyrutherford> I am lost with all the distros stuff
[2017-05-11 14:09:11] <purefan> (I may have lied about the cookies)
[2017-05-11 14:09:15] <brittanyrutherford> it confuses me
[2017-05-11 14:11:17] <purefan> totally side note, we\'re working on aws deployments with terraform and jinja templates, my colleague just said "remember that 1 database rds you finished yesterday? why do I end up with 2 RDSs?"  
[2017-05-11 14:11:50] <brittanyrutherford> on a side note, what's RDS? :S
[2017-05-11 14:13:39] <purefan> its Amazon's Relational Database Server
[2017-05-11 14:13:58] <purefan> have you looked into AWS?
[2017-05-11 14:14:17] <brittanyrutherford> no, I looked into Azure
[2017-05-11 14:14:27] <brittanyrutherford> I am an ASP.NET developer haha
[2017-05-11 14:14:37] <brittanyrutherford> AWS is the dark world for me
[2017-05-11 14:14:47] <purefan> well its almost the same thing, just not tied to microsoft, you can run anything microsoft on it though
[2017-05-11 14:14:54] <brittanyrutherford> note, am not good in azure too
[2017-05-11 14:15:33] <purefan> AWS came before Azure, I trust it way more than Azure but Im biased, most everything I've ever done on cloud is on AWS
[2017-05-11 14:15:41] <rbuckland> brittanyrutherford:  [<-LINK->] 
[2017-05-11 14:15:44] <brittanyrutherford> I have been always a business analyst, for 4 years , switch to ASP.NET for 6 months, and now node and docker 
[2017-05-11 14:15:54] <purefan> node is fun :)
[2017-05-11 14:16:01] <brittanyrutherford> yeah, I like it
[2017-05-11 14:16:04] <purefan>  [<-LINK->] --> just in case
[2017-05-11 14:16:08] <brittanyrutherford> more than ASP.NET
[2017-05-11 14:16:15] <purefan> oh yeah.....
[2017-05-11 14:16:21] <purefan> asp is old too :P
[2017-05-11 14:16:30] <brittanyrutherford> Microsoft released ASP.NET core now
[2017-05-11 14:16:41] <brittanyrutherford> it's very much faster than Node, and runs on Linux
[2017-05-11 14:17:01] <brittanyrutherford> the processes per second is incredible
[2017-05-11 14:17:04] <td444> ASP.NET core itself is quite decent, but it has the same problem as ASP.NET
[2017-05-11 14:17:05] <brittanyrutherford> I just don't like C#
[2017-05-11 14:17:11] <td444> lack of community
[2017-05-11 14:17:15] <td444> lack of OSS loving
[2017-05-11 14:17:22] <brittanyrutherford> yeah, but it's open source now
[2017-05-11 14:17:34] <td444> making it OSS doesnt make people flock to things
[2017-05-11 14:17:45] <td444> as a result Node etc has a far richer, diverse ecosystem (even if its not all good)
[2017-05-11 14:17:47] <brittanyrutherford> and considering it's faster than Node, it might have a value
[2017-05-11 14:17:56] <td444> Node is fast enough for most things...
[2017-05-11 14:18:11] <brittanyrutherford> yeah true
[2017-05-11 14:18:18] <brittanyrutherford> I just hate C#
[2017-05-11 14:18:19] <purefan> I dont really like the arguments of "x programming language is faster", there are waaayyy too many variables to take into account and specific use cases, often a programming language is not designed to handle the same things as another one
[2017-05-11 14:18:24] <brittanyrutherford> i don't like java or c#
[2017-05-11 14:18:28] <brittanyrutherford> that's why I was a business analyst
[2017-05-11 14:18:30] <JinnaBalu> fight should be on docker please, hahahhaha
[2017-05-11 14:18:31] <purefan> brittanyrutherford: Im with you on those!
[2017-05-11 14:18:31] <brittanyrutherford> but I love javascript
[2017-05-11 14:18:55] <brittanyrutherford> when they make asp.net core written in javascript, i will switch to it 
[2017-05-11 14:19:18] <td444> just use node 
[2017-05-11 14:19:23] <brittanyrutherford> yeah I love node
[2017-05-11 14:19:32] <brittanyrutherford> it's what made me love to do programs etc..
[2017-05-11 14:19:40] <brittanyrutherford> with C# it felt like am forced to code
[2017-05-11 14:19:48] <brittanyrutherford> I didn't try things out in my free time
[2017-05-11 14:19:56] <purefan> brittanyrutherford: AWS has lambda, you can run nodejs functions "without a server" ;)
[2017-05-11 14:20:17] <brittanyrutherford> lambda? I hate that word.. reminds me of C# terminologies
[2017-05-11 14:20:27] <brittanyrutherford> "lambda expressions"
[2017-05-11 14:21:08] <JinnaBalu> brittanyrutherford: ,@purefandocker /docker , we need to help people who have doubts on docker. 1-1 window would be better for other discussion may be.
[2017-05-11 14:21:23] <elcolie> I need help
[2017-05-11 14:21:34] <purefan> JinnaBalu: sorry for deviating
[2017-05-11 14:21:59] <purefan> elcolie: whats up? :)
[2017-05-11 14:22:23] <elcolie> My container does not resolve correct IP and Port
[2017-05-11 14:22:27] <brittanyrutherford> what is 1-1 window?
[2017-05-11 14:22:40] <brittanyrutherford> elcolie: ooooh, I can help you with that :D haha
[2017-05-11 14:22:54] <elcolie> Great!
[2017-05-11 14:22:59] <brittanyrutherford> are you on windows?
[2017-05-11 14:23:39] <brittanyrutherford> please say yes :(
[2017-05-11 14:23:50] <brittanyrutherford> or am out
[2017-05-11 14:23:51] <JinnaBalu> hahahhaha
[2017-05-11 14:24:09] <JinnaBalu> brittanyrutherford: having fun with docker now.
[2017-05-11 14:24:15] <brittanyrutherford> oh yeah
[2017-05-11 14:24:20] <brittanyrutherford> am gonna spam containers
[2017-05-11 14:24:23] <brittanyrutherford> haha
[2017-05-11 14:24:48] <elcolie>  [<-CODE->] And the Problem is: [<-CODE->] 
[2017-05-11 14:24:55] <brittanyrutherford> am gonna make a while(true) create containers
[2017-05-11 14:25:32] <elcolie> I have install and hasredis-serverup and running already [<-CODE->] 
[2017-05-11 14:25:39] <brittanyrutherford> elcolie: wow .. sorry can't help with that
[2017-05-11 14:25:45] <elcolie> Host OS is Ubuntu xenial
[2017-05-11 14:25:49] <brittanyrutherford> I was about to say: open kitemantics
[2017-05-11 14:26:11] <brittanyrutherford> but nm me
[2017-05-11 14:28:31] <purefan> I guess this is one of the networking bits I was talking about :P
[2017-05-11 14:29:12] <elcolie> It should not call port53. It must find6379right?
[2017-05-11 14:29:15] <brittanyrutherford> rbuckland: would figure it out i believe
[2017-05-11 14:29:42] <purefan> yeah he seems to know his networking stuff 
[2017-05-11 14:30:06] <elcolie> ok
[2017-05-11 14:30:40] <brittanyrutherford> what's meant by: When Docker is running ... is it a backend service that's running? I thought when u execute a command in terminal, then it runs docker, once it's done, it just goes off.. much like Node when u execute Node .. u can do something
[2017-05-11 14:31:09] <brittanyrutherford> am looking at the windows tray
[2017-05-11 14:31:15] <brittanyrutherford> and there's no whale icon there
[2017-05-11 14:35:36] <purefan> brittanyrutherford: you can run a command against a container and once it finishes you get your terminal back, just like in node. The container doesn\'t stop, just the command that you run, meaning that if you have a container running and you run something likeecho "hello"the container will continue running when that finishes
[2017-05-11 14:46:28] <brittanyrutherford> why am i not seeing this in windows tray: [<-LINK->] 
[2017-05-11 14:51:00] <purefan> brittanyrutherford: do you see like an arrow pointing up? maybe its hidden
[2017-05-11 14:52:29] <brittanyrutherford> I don't think it's installed with docker toolbox
[2017-05-11 14:52:40] <brittanyrutherford> since I used toolbox as am using windows 10 home, not pro
[2017-05-11 14:53:04] <brittanyrutherford>  [<-LINK->] 
[2017-05-11 14:53:30] <brittanyrutherford> also no windows process called Docker
[2017-05-11 14:53:46] <brittanyrutherford> yeah, seems it's different
[2017-05-11 15:06:22] <elcolie>  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2017-05-11 15:06:46] <brittanyrutherford> ah, I knew it
[2017-05-11 15:06:48] <brittanyrutherford> (kidding)
[2017-05-11 15:10:06] <purefan> elcolie: so fromdocker-compose -f production.yml up -d backendtodocker-compose -f production.yml run rq_worker_a python portal/manage.py rqworker default?
[2017-05-11 17:31:30] <brittanyrutherford> so I guess am gonna stop learning Docker .. all examples on the internet are related to how docker for windows is installed.. which is not even what I have.. I have windows home, which can only have docker toolbox ..
[2017-05-11 17:31:57] <brittanyrutherford> i setup a windows enterprise VM on Oracle virtual box
[2017-05-11 17:32:20] <brittanyrutherford> but it gave me errors about hyper-v ..
[2017-05-11 17:32:42] <brittanyrutherford> so until I get rid of windows home and get an upgraded one.. it won't make sense to get into docker :(
[2017-05-11 17:32:53] <brittanyrutherford> thanks all
[2017-05-11 17:35:31] <SISheogorath> brittanyrutherford: it maybe would be easier to simply use a DO droplet :D and learn a few bits of GNU/Linux ^^
[2017-05-11 17:35:42] <SISheogorath> That's how I work
[2017-05-11 17:37:41] <valamorgon> so what is docker anyway? (hope you guys have prize for the person who asked as 100000th time)
[2017-05-11 17:38:04] <valamorgon> instead of whole os vm, can I use docker for app? that s the point?
[2017-05-11 17:53:03] <brittanyrutherford> valamorgon: as far as I understand, it's a package of 1 or more apps, bundled together
[2017-05-11 17:53:25] <brittanyrutherford> it's not a replacement for VM, it's a replacement for the process of searching for app/download/install
[2017-05-11 17:54:00] <brittanyrutherford> like the mongoDB container, it comes with powershell/client/server all together, plus some other apps.. all hosted on your original machine
[2017-05-11 17:54:36] <brittanyrutherford> that's how I understand it, but not sure
[2017-05-11 17:54:51] <brittanyrutherford> SISheogorath: yeah, that would open whole new doors for me am not ready to get into now :(
[2017-05-11 17:54:58] <JinnaBalu> every process runs on some port, we are running any service isolated in docker container by opening that port to the host machine.
[2017-05-11 17:58:42] <JinnaBalu> we install nothing on our machine except the docker. when we run docker container, it uses memory, when we stop them our memory is back, and we can run any image just like that . upgrading the versions becomes easier to run on docker, instead uninstall and install new version on machine.
[2017-05-11 18:01:40] <JinnaBalu> When we are dealing with microservices, we may use different databases different  languages , we make all of them run together with docker. as docker can run any database supports any language by means of container.
[2017-05-11 20:59:52] <SISheogorath> @valamorgoninstead of whole os vm, can I use docker for app? that s the point?Docker Containers are about immutability, minimalism and scale-ability. maybe checkout this answer: https://gitter.im/docker/docker?at=59139a17551ea6485ba83831
[2017-05-11 21:10:44] <brittanyrutherford> can we package atom/node in the same container and reuse them
[2017-05-11 21:22:16] <SISheogorath> not completely sure why you need atom in the container?
[2017-05-11 21:22:34] <SISheogorath> In general maybe interesting for you: [<-LINK->] 
[2017-05-11 21:22:56] <SISheogorath> Live debugging a node application inside a docker container ^^ very nice
[2017-05-11 21:24:57] <SISheogorath> in general yes, you can get them into the same container ._.
[2017-05-11 21:36:33] <brittanyrutherford> I mean, containers bundle apps
[2017-05-11 21:36:44] <brittanyrutherford> why do we consider node/mongo as apps, but not atom?
[2017-05-11 21:36:52] <brittanyrutherford> am still confused and can't understand it 100%
[2017-05-11 21:37:19] <brittanyrutherford> I thought maybe I can have some config in atom, and add it to the container, and make it reusable across developers
[2017-05-11 21:37:30] <brittanyrutherford> so they don't have to do same config across their editors
[2017-05-11 21:37:36] <brittanyrutherford> can't I do that with containers?
[2017-05-11 22:35:22] <rbuckland> brittanyrutherford: apps are notusuallyfor GUI use (web sites, webapps yes) .. having said notusually, you can of course package "atom" inside the container. but you are mixing up two worlds.the container running your webapp is destined for a web server somewhere.. \nthe container with "atom" bundled in .. is for your desktop, not the webserverso it makes no sense to put atom in the container and send atom to the webserver, where it will never be used.
[2017-05-11 22:36:03] <rbuckland> which means .. if youreallywant to have atom and the node webapp docker-ised, then create two containers.
[2017-05-11 22:36:23] <rbuckland> running atom "from" the container will prove to be very complex for you.
[2017-05-11 22:37:05] <rbuckland> suggestion.install atom locally on your workstation .. \ncreate a docker container for your webapp.
[2017-05-11 22:38:43] <rbuckland> brittanyrutherford: to re-distribute youratomconfig across to developers in your team. Just put the atom config ingit(alagithub) .. and share the git repo.
[2017-05-11 23:08:40] <SISheogorath> Well it's not completely true @rbuckland Containers are use for Desktops, too, but in most cases they are not docker containers. (an example would be Ubuntu Snap apps or AppImages. Same applies to Android Apps which use containers, too.)@brittanyrutherford The idea for the docker containers in speech of development is, that it's created to be reproducible and you eliminate issues with dependency conflicts. A common example is: You have 2 Applications running on your Server: 1 needs Node version 4 and can't run with 6 and another needs Node version 6 and can't run with 4. They maybe have some kind of setup script but you can imagine the conflict that will appear when you try to setup both at the same time on your system. You can run then in 2 VMs but you waste tons of RAM for a VM you only use to test an application and you have to copy your source to the VM, maybe write something inside the VM, test it, break it, have to recover, etc. very annoying. Containers are build like you would build a static bound C program. You define what you need, and docker manages it to install all dependencies, makes sure everything is in place and inside your container environment you have a very minimal and controled setup so if you need node version 4 it's there and you don't depend on the version installed on your system. And of course you can rebuild your software over and over again when you do changes switch forward and backward in your history, switch branches and more. The handling stays very simple.
[2017-05-11 23:10:49] <SISheogorath> But this also means that docker containers are not made to develop inside them. So they try to avoid "state" which means any data you might change and want to persist. Docker allows you to use volumes to persist data but it\'s more to make all these container setup that exist really usable. The general idea is too keep containers as Stateless as possible
[2017-05-11 23:17:59] <dimberman> Hi guys, potentially stupid question: Is it possible to run minikube inside of a docker container?
[2017-05-11 23:33:10] <SISheogorath> I'm not sure, but maybe it works with docker-in-docker
[2017-05-11 23:33:21] <SISheogorath> in general I wouldn't recommend it
[2017-05-12 00:05:44] <brittanyrutherford> SISheogorath: @rbucklandbut, some programs are not only server stuff.. for example.. let's say you are hiring 3 devs, instead of asking each of them to have a machine with node installed, with mongodb/express/atom with configs/etc.. why not bundle all of this in a container and devs can pull it? I am not talking about bundling atom with web server for production
[2017-05-12 00:06:51] <brittanyrutherford> isn't this a valid scenario?
[2017-05-12 00:10:28] <SISheogorath> well for mongodb and express/node you have docker/docker-compose (to split it in multiple containers). The thing you don\'t want to "share" is the editor. Reason? Well different people use different editors. And editors are really personal for the most developers. Own shortcuts their very personal list of plugins and tons of different projects. In other words: The editor is on another layer than the project. Because you want to use your editor to edit multiple projects, and not choose the editor based on the project your are about to work with.And as I already mentioned docker is not made for Desktop applications. You can run them in docker with some dirty hacks and work arounds, no problem. But by design docker containers are more build for non-desktop containers.
[2017-05-12 00:15:31] <brittanyrutherford> thanks@SISheogorath
[2017-05-12 00:15:44] <brittanyrutherford> am a bit confused about this whole thing
[2017-05-12 03:10:20] <elcolie> @purefanFrom: [<-CODE->] To: [<-CODE->] 
[2017-05-12 03:38:09] <elcolie> docker-compose -f production.yml run -d rq_worker_a python portal/manage.py rqworker default
[2017-05-12 03:38:32] <elcolie> It need to be in the background job-dis required
[2017-05-12 06:11:22] <purefan> elcolie: gotcha 
[2017-05-12 06:11:37] <elcolie> :D
[2017-05-12 08:03:09] <ygokirmak> Hi guys.. We have a networking problem in docker-swarm. The problem is below;we have virtualized environment over wmware ( vsphere 6.02)\nour servers are created from vmware say server1 and server2\nwe have a docker compose file defining a couple of services\nwe have an overlay-network definition within docker-compose for docker-swarm\nwhen we deploy system using docker-swarm deployment is finished successfully, all containers gets ip from overlay network range.\nBut the problem is if 2 containers (say cnt1 and cnt2) are deployed to different servers they can not ping each other\nI check tcpdump and see that ARP communication is successfull so they know each other mac correctly\nBut when you try to ping to container, ICMP Echo messages are send but are not delivered to second machine..Where should I check, any advices?
[2017-05-12 08:09:20] <purefan> ygokirmak: ARP could be reported from another machine, it doesn't mean that a host can actually reach another one. Assuming that there isn't a configuration dropping ICMP packets can you check that both containers have IPs in the same subnet?
[2017-05-12 08:09:57] <jyapujuju> uninitialized constant Useri don't  know what is happening
[2017-05-12 08:14:40] <ygokirmak> purefan: I double checked it and they are in the same subnet. 192.168.20.40 / 192.168.20.100 .. I am trying to check whether there are someone dropping the ICMP or not .. I can check on server level and see..
[2017-05-12 08:49:38] <rubenjoy> hi .. I read run jenkins on docker container.. when passing the volume  "-v /d/jenkins_host:/var/jenkins_home:z"
[2017-05-12 08:49:40] <ygokirmak> purefan: I think this is a possible duplicate [<-ISSUE->] 
[2017-05-12 08:50:01] <rubenjoy> what does the suffix ":z" mean?
[2017-05-12 08:51:27] <rubenjoy> here is the links on running jenkins in docker container
[2017-05-12 09:03:57] <HendrikRoth> Hm i don't get it. [<-LINK->] 
[2017-05-12 09:04:35] <HendrikRoth> it seams that my if statements are wrong. but i have no idea what is wrong. any one a idea?
[2017-05-12 13:52:56] <tazjin> anyone seen issues with the embedded DNS server used by user-created networks on AWS? It plain and simple won't resolve anything external (not even if --dns is set on the daemon)
[2017-05-12 13:53:31] <tazjin> I dug up an old issue somewhere that mentioned that the lib used for the embedded DNS server had issues with Azure's DNS service, so my suspicion is that the AWS DNS server is causing something similar (though that would be strange)
[2017-05-12 15:49:08] <morpheyesh> need help! i have a requirement where I need to insert a jar and build a new image. I need to be able to do that from another container which does certain steps. For ex: Container A will have the jar(wont really run it) , but it does other things. Now, one of the step is t ocreate another image with this jar. This image runs the actual jar. Does insert API work?
[2017-05-13 00:38:45] <SISheogorath> morpheyesh: maybe this is interesting for you: [<-LINK->] 
[2017-05-13 01:55:23] <gdeverlant> greetings phelowship of the whale
[2017-05-13 01:56:00] <gdeverlant> I was wondering if there is a way in a dockerfile to get the hostname of the parent machine
[2017-05-13 01:56:17] <gdeverlant> like my server name is serverdb
[2017-05-13 01:56:51] <gdeverlant> in my docker file I would like to pass the name serverdb to an entrypoint
[2017-05-13 01:57:13] <gdeverlant> I know of $HOSTNAME but this is the containers hostname
[2017-05-13 04:00:57] <daCodez> Can someone help me setup default asp.net core app in container with seperate container for sqlserver database using ef core?
[2017-05-13 07:07:29] <nischay30> Hi
[2017-05-13 07:09:44] <nischay30> Hii am trying to start cassandra container and i am having a conf. file on my host system and i have to supply it to the container so that cassandra takes that conf. file.one way is that i mount a volume replace the file inside container and commit the change to container.is there any other way i can do it so that i can override the inside container conf. files
[2017-05-13 09:04:32] <indigogoo> gdeverlant: If you’re trying to acces the database server that runs on hostmachine, it would be better to run your database in the container and use docker-compose to set up network easily
[2017-05-13 09:56:42] <SISheogorath> nischay30: write a Dockerfile that is based on the cassandra container andCOPYthe config into the container
[2017-05-13 10:11:01] <gdeverlant> indigogo: Lol I just want the parenthostname in the ENV Variables dude why are you giving me another solution?
[2017-05-13 10:44:01] <vignesh-kumar19> in alpine image rsyslog-kafka package is not available .. any other way to get that package. ?
[2017-05-13 12:48:28] <fthamura> hi all , can we use minio as volume?
[2017-05-13 13:13:30] <yuvgeek> what's the alternative for/usr/sbin/apachectlfor ubuntu 14.04 ?
[2017-05-13 14:25:43] <SISheogorath> fthamura: check minfs, iirc there are people using it. I don't know about performance etc. I guess it's slow
[2017-05-13 14:26:00] <SISheogorath> YuvarajMe: use the apache2 binary?
[2017-05-13 14:26:40] <SISheogorath> vignesh-kumar19: compile it yourself or use something else. As on any other distro, too
[2017-05-13 14:29:33] <SISheogorath> gdeverlant: use a build argument. There is no other way. Main reason: your containers should not depend on anything related to the host. If you need any kind of information inside the container: copy it or use a build argument. That's the way to go
[2017-05-13 17:11:27] <gdeverlant> SISheogorath: what is a build argument
[2017-05-13 17:11:39] <gdeverlant> I would like to run a docker service in a cluster
[2017-05-13 17:11:43] <gdeverlant> and each docker instance
[2017-05-13 17:11:54] <gdeverlant> need to have the name of their respective hostname
[2017-05-13 17:13:13] <gdeverlant> can I execute in an environment a bash function like hostname ?
[2017-05-13 17:14:00] <gdeverlant> like docker run -t --name c1 -e HOSTNAME=(eval hostname) mycontainername/container:3.3.3
[2017-05-13 17:16:10] <SISheogorath> you can maybe use docker templates to add the hostname but it doesn't sound useful, as I'm not sure if that is even possible in environment variables and if it's possible if you can get a nodes name
[2017-05-13 17:17:09] <SISheogorath> in general you can't simply access the hostname of the machine you're running on and what ever you try to inject is executed during the command you use to create the service and not during the creation of the container. (At least if you talk about docker swarm-mode)
[2017-05-13 17:17:32] <gdeverlant> ok
[2017-05-13 17:17:53] <gdeverlant> the best for me is to use pssh in my 12 nodes
[2017-05-13 17:18:34] <gdeverlant> and execute docker create -d --name nameContainer -e HOSTNAME=$HOSTNAME test/test
[2017-05-13 17:19:29] <SISheogorath> why-efor the hostname? You can use the--hostnameflag
[2017-05-13 17:20:15] <SISheogorath> oh I checked back docker-services do support --hostname
[2017-05-13 17:20:34] <gdeverlant> when I run docker service create
[2017-05-13 17:20:36] <SISheogorath> but then you use the same hostname on every host... maybe not what you wanted
[2017-05-13 17:20:42] <gdeverlant> all the nodes get the name of the manager
[2017-05-13 17:20:45] <gdeverlant> I don't want that
[2017-05-13 17:21:31] <gdeverlant> so doing parallel ssh
[2017-05-13 17:21:51] <gdeverlant> and running docker run instead makes more sense
[2017-05-13 17:25:51] <gdeverlant> SISheogorath: where did you find all the variable names supported ?
[2017-05-13 17:26:28] <gdeverlant> SISheogorath: The reason why I want to use -e instead of --hostname is because
[2017-05-13 17:26:31] <SISheogorath>  [<-LINK->] 
[2017-05-13 17:27:10] <gdeverlant> I have a a service which needs one of its config set with the name of the host
[2017-05-13 17:27:17] <gdeverlant> and this has to be unique
[2017-05-13 17:28:26] <SISheogorath> how about mounting it somewhere?
[2017-05-13 17:33:29] <gdeverlant> what do you mean ?
[2017-05-13 17:34:50] <gdeverlant> is there any documentation
[2017-05-13 17:34:54] <gdeverlant> for what you call mounting
[2017-05-13 17:48:46] <SISheogorath> sure ._. host mounts? simply pass-v /some/path/on/host:/some/path/inside/the/containerto your container. Or in case ofdocker service createit\'s-v type="bind",source="/path/on/host",target="/path/in/container"
[2017-05-13 17:51:29] <SISheogorath> for example: [<-LINK->] 
[2017-05-13 17:51:37] <SISheogorath> you can do this with directories as well
[2017-05-13 18:10:11] <gdeverlant> you mean i share the /etc:/host/etc
[2017-05-13 18:10:32] <gdeverlant> and read the hostname file of the host
[2017-05-13 18:10:45] <gdeverlant> and then put the value inside of an ENV variable ?
[2017-05-13 18:34:57] <gdeverlant> Ohh I found that  TEST=$(grep "" /etc/hostname)
[2017-05-13 18:35:12] <gdeverlant> puts the content of the file in the ENV variable TEST
[2017-05-13 18:35:37] <gdeverlant> Can this work inside a Dockerfile
[2017-05-13 18:36:21] <gdeverlant> RUN PARENT_HOSTNAME=$(grep "" /host/etc/hostname) ?????
[2017-05-13 18:37:25] <gdeverlant> RUN export PARENT_HOSTNAME
[2017-05-13 19:06:29] <SISheogorath> That's not how it works ._.
[2017-05-13 19:07:47] <SISheogorath> everyRUNstatement during build is executed INSIDE a container based on the image of the previous build step
[2017-05-13 19:09:03] <SISheogorath> gdeverlant: I'm not really sure what you are about to do. Maybe you can explain why you need it. Maybe it's simply a wrong design of the application ._. or you can work around the issue
[2017-05-14 05:46:40] <yuvgeek> SISheogorath: I have to start apache service for ubuntu 14.04
[2017-05-14 05:47:19] <yuvgeek> i useCMD ["/usr/sbin/apachectl", "-D", "FOREGROUND"]for ubuntu 16.04
[2017-05-14 05:47:27] <yuvgeek> but it doesn't work for 14.04
[2017-05-14 07:42:01] <iamfourh2e> anyone know any documents related to docker setup for scaling mongodb here
[2017-05-14 13:36:21] <SISheogorath> YuvarajMe: search forapachebinary and start it.apachectlis just a wrapper script
[2017-05-14 13:52:58] <morpheyesh> is it possible to inject a file into an image before starting a container from that image?
[2017-05-14 13:53:25] <morpheyesh> ^ideally a config or properties file.
[2017-05-14 13:57:31] <yuvgeek> SISheogorath: i tried for whole day.
[2017-05-14 13:57:53] <yuvgeek> in logs i can see, apache is starting but
[2017-05-14 13:58:01] <yuvgeek> it is not running in foreground
[2017-05-14 14:17:08] <SISheogorath> YuvarajMe: apache2 has a special parameter to run in foreground. (Iirc it's-n)
[2017-05-14 14:18:43] <SISheogorath> morpheyesh: it's name host- or bind-mount and you can do it usingdocker run -v /some/path/on/host:/some/path/inside/the/container imagename
[2017-05-14 16:12:30] <SISheogorath> YuvarajMe: Checkout: [<-LINK->] 
[2017-05-15 01:46:01] <KellySheffield> I can't make sense of the documentation for mounting volumes in version 3 of docker-compose.ymlThis is my current working v2 config: [<-CODE->] How would I write the new master 'volumes:' config?
[2017-05-15 07:00:05] <jeserkin> Good morning everyone
[2017-05-15 07:01:38] <jeserkin> Guys, what is the easiest way to share database container with other containers, that require it? Examples are welcomed.
[2017-05-15 07:11:20] <purefan> jeserkin: Google is your friend: [<-LINK->] 
[2017-05-15 07:12:05] <purefan>  [<-LINK->] 
[2017-05-15 07:40:43] <jeserkin> purefan: sry, forgot to mention, that I am interested in docker-compose setup, not plain dokerfiles. I did try withdepends_on:option.
[2017-05-15 07:40:54] <jeserkin> I know, that there is alinkoption.
[2017-05-15 07:47:11] <purefan> jeserkin: maybe something like this [<-LINK->] ?
[2017-05-15 07:50:12] <jeserkin> Okay, sohost: dbinsidewebcontainer , sincewebimagedepends_on: dbcontainer?
[2017-05-15 08:11:27] <purefan> I believe thats the trick ;)
[2017-05-15 08:28:48] <jeserkin> Okay. Thank you.
[2017-05-15 08:28:57] <jeserkin> And one last thing.
[2017-05-15 08:30:14] <jeserkin> If one docker-compose file, that has multiple services in it references multiple docker-compose files through those services, then how isservicecontainer name formed?
[2017-05-15 09:46:23] <falloutghost> hey, i'm having troubles connecting to amysqldatabase running inside a docker container through anode.js/sequelizeapplication
[2017-05-15 09:46:32] <falloutghost> connecting viamysql-clientworks fine
[2017-05-15 09:47:08] <falloutghost> when trying to connect viasequelizethough i always receive anER_ACCESS_DENIED_ERROR: Access denied for user 'root'@'172.17.0.1' (using password: YES)error
[2017-05-15 09:48:27] <falloutghost> container was started like this: [<-CODE->] 
[2017-05-15 09:48:29] <falloutghost> any ideas?
[2017-05-15 10:19:31] <falloutghost> root (root@'%'androot@localhost) has all privileges on*.*andapp.*
[2017-05-15 10:21:40] <pjetr> and as a "is it plugged in" question, have you checked if sequelize uses the correct password?
[2017-05-15 10:27:13] <falloutghost> yep
[2017-05-15 10:27:35] <falloutghost> also copied it from sequelize config and pasted it intomysql -u root -p -h 127.0.0.1command to verify
[2017-05-15 10:28:54] <pjetr> I'm an absolute beginner, so that's actually as far as my knowledge goes xD
[2017-05-15 10:29:40] <falloutghost> i'mguessingit's a privileges problem since the host name in the error message doesn't match the host i'm originally connecting from (localhost), but then again that's only the host machine for the container image.172.17.0.1is the default docker address, but the container is actually running on172.17.0.2-- however, connecting to the latter still throws the same error
[2017-05-15 10:30:08] <pjetr> I'm using docker-compose to create and link my apps, which works very easily...
[2017-05-15 10:30:40] <pjetr> are they both on the same network?
[2017-05-15 10:30:46] <falloutghost> both on the same machine
[2017-05-15 10:30:52] <falloutghost> so yes ;)
[2017-05-15 10:31:37] <falloutghost> adding--net=hostmakes the error message use127.0.0.1(or localhost) instead of172.17.0.1, but it's still the same issue.
[2017-05-15 11:52:56] <frederikprijck> Hi guys, I have setup a docker container using docker-compose. It works perfect on OSX (and I guess on Windows 10, but I have to double check that later). However, I can't get nginx to work on Docker Toolbox for Windows 8.1. Any idea what has to be done different ? (Code available at [<-LINK->] )
[2017-05-15 11:53:21] <frederikprijck> I'm guessing it's related to the fact that I have the code running on myDdrive, which isn't shared by default in docker ?
[2017-05-15 11:53:42] <frederikprijck> Docker for windows (on win 10) has the option to addDas a shared drive. How do we handle this with Docker Toolbox on Windows 8 ? Preferably I'd like my docker code to be self-contained, and avoid manual actions to be taken (like sharing the folder in VirtualBox / Docker).
[2017-05-15 18:39:19] <SISheogorath> falloutghost: you use docker-compose to setup? you should connect to the service name you gave your database (or by commandline you usedapp-mysqlas name in your run statement). Not127.0.0.1or172.17.0.1. Also you should use the username you set asMYSQL_USERnotroot. And then it'll work.
[2017-05-15 18:39:57] <SISheogorath> And also you should try to avoid exposing the database ports to the public
[2017-05-15 18:43:31] <SISheogorath> Simple example how to use MySQL database and App in a composefile: [<-LINK->] 
[2017-05-16 04:40:49] <ginjo> Hi all, I've been using the binaries at [<-LINK->] to test our services with the very latest fixes. However with the recent shift to Moby, I'm at a loss as to where these binaries are now located. The builds at the above mentioned site appear to be frozen as of May 12. Any guidance appreciated - thanks!
[2017-05-16 08:05:42] <veris-neerajdhiman> I am setting up postgres using docker but when I am doing docker-compose up (after build) database is not created for that container [<-CODE->] 
[2017-05-16 08:15:01] <purefan> veris-neerajdhiman: did you get an error?
[2017-05-16 08:25:11] <veris-neerajdhiman> purefan: no
[2017-05-16 08:26:37] <veris-neerajdhiman> purefan: but If I ran docker-compose run templates_db , then db is successfully created
[2017-05-16 08:43:50] <veris-neerajdhiman> Issue resolved , It was permission error as soon as I mentioned complete path here [<-CODE->] Issue was fixed
[2017-05-16 10:06:04] <CrashyBang> Hey folks I am having an absolute nightmare of a time linking/waiting for containers with docker-compose, I have posted a detailed description on stack overflow [<-LINK->] if any of you could take a look that would be highly appreciated
[2017-05-16 10:08:34] <purefan> CrashyBang: First thing I see isserver_1    | ./setup/wait-for-postgres.sh: line 10: psql: command not foundhave you tried installing psql?
[2017-05-16 10:35:27] <CrashyBang> Hey@purefanpsqlis installed on the postgres container by default and I can use it by connecting to it.
[2017-05-16 10:37:04] <purefan> CrashyBang: but you're running psql in the filewait-for-postgres.shwhich is in theservicecontainer, not thedatabasecontainer
[2017-05-16 10:37:49] <CrashyBang> Hey@purefanyes but the two containers should be connected? Or am I misunderstanding how that works?
[2017-05-16 10:40:10] <purefan> CrashyBang: They can be connected via network but as per your definition they are not sharing the same volume, so files in one container cannot directly be read from the other container. Try to connect to yourservicecontainer and manually run the filewait-for-postgres.shthen try to install psql and run the file again
[2017-05-16 10:41:33] <CrashyBang> Ahhh I see, man that is a pain! thank you though!
[2017-05-16 10:43:27] <purefan> CrashyBang: no problem :) if you're on ubuntu/debian you can just add this line to your wait-for-postgres.sh file:sudo apt-get install postgresql-clientit will not install the entire database, only the client tools
[2017-05-16 10:43:58] <CrashyBang> Yeah that is what I have landed on :) thank you!
[2017-05-16 10:50:31] <purefan> :)
[2017-05-16 12:18:35] <CrashyBang> purefan: could I get you to take a look at this: [<-LINK->] if you have time
[2017-05-16 13:43:33] <veris-neerajdhiman> Hi,I have an app which uses a git fork package. [<-CODE->] But when I tried setup my project with Docker, package is installed from requirement file but when i ran my container , I got got an error that -  ImportError: No module named 'my-pkg'
[2017-05-16 13:44:11] <veris-neerajdhiman> its may be beacuse pkg installed from git fork doesn't got to site-packages ?
[2017-05-16 13:44:23] <veris-neerajdhiman> so any solution ?
[2017-05-16 20:27:26] <realisation> hey everyone
[2017-05-16 20:28:23] <realisation> I'm going to be dockerizing my app for production & development in a few minutes today!!!
[2017-05-16 20:28:58] <realisation> I would love to understand all the code in the docker file for the factory mongodb image
[2017-05-17 06:13:28] <purefan> realisation: what dont you understand?
[2017-05-17 08:07:11] <dasheck0> Hi I have an issue with docker-compose and pre-existing networks. Is there anyone here who can help me with that?
[2017-05-17 08:07:19] <dasheck0> Sorry for that "rude" introduction :O
[2017-05-17 08:08:32] <purefan> dasheck0: its fine to [<-LINK->] , whats the problem you're having?
[2017-05-17 08:10:25] <dasheck0> Alright. So I have a docker compose, which defines a network, where several containers are running in. This is just fine. On the host machine, where the docker-compose file is executed there is already a network available defined in the host machines /etc/hosts file (let\'s call it "ext_db"). So within the docker container a server is running, which tries to connect to the database available on "ext_db"
[2017-05-17 08:10:44] <dasheck0> But I get a host not found error from the ORM telling me that ext_db is not found
[2017-05-17 08:11:07] <dasheck0> I also have [<-CODE->] in my compose file
[2017-05-17 08:34:21] <purefan> isext_dblocalhoston the host machine or is it pointing to an external IP (not another docker container)?
[2017-05-17 10:25:15] <dasheck0> We got support from our hosting provider where the container is running on
[2017-05-17 10:25:38] <dasheck0> The solution was pretty easy to be honest. We had to set the network_mode to bridge and that's it
[2017-05-17 10:25:48] <dasheck0> thanks for the help anyway
[2017-05-17 10:27:58] <KellySheffield> I'm running into a 'operation not permitted error Cannot create FIFO .../erlang.pipe.1.r for writing' when to trying to 'start' an app(basic starter phoenix/elixir project) This is all I can find so far googling: [<-ISSUE->] but I'm using docker for windows. Any ideas?
[2017-05-17 11:05:08] <gdeverlant> what is the easiest way for me to get the informations of the running container from go code ?
[2017-05-17 11:05:32] <gdeverlant> let's say I have an app running inside of a docker container
[2017-05-17 11:05:47] <gdeverlant> that app wants to retrieve all the infos of the current container
[2017-05-17 11:14:08] <purefan> that app wants to retrieve all the infos of the current containerwhat do you mean "all the infos" ?
[2017-05-17 12:01:02] <gdeverlant> like the name of the running image
[2017-05-17 12:01:15] <gdeverlant> the details about -volumes -env variables
[2017-05-17 12:01:47] <gdeverlant> validate if the app is running inside of a docker container
[2017-05-17 12:42:36] <SISheogorath> You can check for the /.dockerenv file and maybe check some typical symptoms of an docker container. But you won't see all the details as long as you don't talk to the docker engine API and even there, if you run inside swarm, you won't see all information if you connect to the API of a worker node.
[2017-05-17 12:44:24] <SISheogorath> In general you shouldn't care about the fact that you're running inside a container. If you want to warn your users that no volume exists, check for a mountpoint.
[2017-05-17 12:44:54] <SISheogorath> I'm sure there is a lib that already checks forinDocker()
[2017-05-17 12:45:19] <SISheogorath> At least there is a lib in NodeJS
[2017-05-17 14:25:57] <iglov> Hi there! I have question about docker and iptables. I my current config, i use iptables=false, but if i create any network with compose - docker don't create NAT rules and masquerading, and my containers can't reach the internet. If i use iptables=true, besides NAT rules docker adds accept rules for any to ports which i exposed. For example, if i saydocker run -p 80:80 -d nginx- docker accept connection from ANY to  port 80 . Maybe i can somehow say docker, what i want create container in new bridge with NAT/MASQUERADING , but i want self create rule ip iptables for exposed ports?
[2017-05-17 14:27:19] <iglov> --iptables=half-false maybe 8D
[2017-05-17 19:19:07] <SISheogorath> iglov: i would suggest to file an issue (or check if there already is one)
[2017-05-18 02:01:42] <fanux> What is the difference between volume typebindandvolume?```
[2017-05-18 02:02:05] <fanux>  [<-CODE->] 
[2017-05-18 02:03:13] <fanux> Has some docs for volume Type?
[2017-05-18 05:28:19] <wenjianhn> iglov: In 17.06, which will be released soon, you can add your own rules. See [<-ISSUE->] .
[2017-05-18 10:11:34] <albertjt> Just started learning docker and have some question to ask, I am using git bash on windows and currently following the guide on docs.docker.com. When I started running "docker run -p 4000:80 friendlyhello" it seems that even though I quit the process, it still runs in the background when I list running process using docker ps. Why is that? Doesn\'t it supposed to run in the background if I use the -d command?
[2017-05-18 10:59:01] <SISheogorath> albertjt: it'll run in background with-dbut your commanddocker run -p 4000:80 friendlyhellohas no-d:D
[2017-05-18 12:50:33] <bpt6576> I randocker volume create --name hello --opt o=uid=1000,gid=1000and can see the volume withdocker volume inspect hello, however when I try to mount the namedhellovolume into a container usingdocker run -it -v hello:/world jenkinsci/blueocean ashI geterror while mounting volume '/var/lib/docker/volumes/hello/_data': missing device in volume optionsAm I missing something in mydocker runcommand? Any clarity/suggestions appreciated.
[2017-05-18 18:40:29] <SISheogorath> it's just a guess but maybe you need to add mount options behind your mount:docker run -it -v hello:/world:options jenkinsci/blueocean ash
[2017-05-18 18:40:46] <SISheogorath> replace options with real mount options
[2017-05-18 19:46:47] <gdeverlant> Hi guy
[2017-05-18 19:47:06] <gdeverlant> I would like to know why does docker not find a plugin that I'm trying to run
[2017-05-18 19:47:20] <gdeverlant> it is a volume persistence plugin
[2017-05-18 19:47:38] <gdeverlant> how can I know that docker recognize a running plugin process
[2017-05-18 19:50:23] <SISheogorath> gdeverlant: do you talk about a v1 or a v2 plugin?
[2017-05-18 19:51:32] <SISheogorath> for a v2 plugin you can rundocker plugin lsfor a v1 plugin I think (can really say) the easiest way is to check the docker log
[2017-05-18 19:53:48] <sandys> this does not work from within a dockerfile, what should I be doing ? I'm trying to add a label from inside the dockerfile .
[2017-05-18 19:53:50] <sandys> LABEL GIT_REF="$(git rev-parse --short HEAD)"
[2017-05-18 19:58:01] <SISheogorath> I'm pretty sure that you can't use$(git rev-parse --short HEAD)inside a LABEL tag. Reason: It doesn't run inside the container context, it only add Metadata to the image manifest (don't quote on me, but that was the conclusion I came to, when I thought about doing it)
[2017-05-18 19:59:40] <gdeverlant> legacy plugins
[2017-05-18 20:00:48] <gdeverlant> this is the plugin
[2017-05-18 20:00:58] <gdeverlant> It is only available for amd64
[2017-05-18 20:01:07] <gdeverlant> but since it is written in go
[2017-05-18 20:01:31] <gdeverlant> I've compiled it on arm64(aarch64)
[2017-05-18 20:01:38] <gdeverlant>  [<-LINK->] 
[2017-05-18 20:03:11] <gdeverlant> I have found it on [<-LINK->] 
[2017-05-18 20:03:43] <gdeverlant> my docker is [<-CODE->] 
[2017-05-18 20:14:53] <sandys> SISheogorath: hmm.. actually i cant run the command itself but i can assign any label inside the image. that's the issue - is there any way to assign a label from the result of a command ?
[2017-05-18 20:19:11] <SISheogorath> sandys: I'm not sure. I couldn't find a nice solution for that. The only way I found was to put the reference into the build process as argument and if you clone the repository inside your container, to usegit clone -b $REF --depth 1 https://hostname/repo
[2017-05-18 20:22:09] <sandys> SISheogorath: hmm... thanks for helping out though :(
[2017-05-18 20:23:52] <SISheogorath> gdeverlant: check if there is a.jsonor.specfile in/usr/lib/docker/pluginsor a.sockin/run/docker/plugins
[2017-05-18 20:24:04] <SISheogorath>  [<-LINK->] 
[2017-05-18 20:24:14] <SISheogorath> sandys: you're welcome
[2017-05-18 20:26:28] <gdeverlant> actually
[2017-05-18 20:26:40] <gdeverlant> there is one on the AMD64 server
[2017-05-18 20:27:01] <gdeverlant> but there is no file on the ARM64
[2017-05-18 20:27:16] <SISheogorath> there is your problem :)
[2017-05-18 20:27:25] <gdeverlant> the plugin seems to run in htop
[2017-05-18 20:28:08] <gdeverlant> do you know why it is not created on the ARM64
[2017-05-18 20:28:17] <gdeverlant> but runs well on the AMD64
[2017-05-18 20:28:52] <gdeverlant> does it have to do with the version of docker ?
[2017-05-18 20:29:16] <gdeverlant> on the AMD64 docker version is [<-CODE->] 
[2017-05-18 20:29:48] <gdeverlant> on the ARM64 docker version [<-CODE->] 
[2017-05-18 20:33:14] <electriccode> I need to run certain cronjob inside docker image php:7.1-apache and the cronjob depends on lots of environment variables, should I create a .env, define all env variables there and source it in Dockerfile? I can then again source it in my cronjob as well. Is this a good practice?
[2017-05-18 20:38:54] <gdeverlant> SISheogorath: Do you have an idea ??? is it simple like folder permissions ?
[2017-05-18 20:45:31] <SISheogorath> electriccode: how did you create the cronjobs?
[2017-05-18 20:46:31] <SISheogorath> gdeverlant: maybe you can ask in their gitter chatroom (if you didn't already)
[2017-05-18 20:49:59] <gdeverlant> SISheogorath: I found the problem
[2017-05-18 20:50:11] <gdeverlant> the plugin was creating the .sock file
[2017-05-18 20:50:26] <gdeverlant> but it was not creating its own name local-persist.sock
[2017-05-18 20:50:34] <gdeverlant> but instead it was root.sock
[2017-05-18 20:50:37] <gdeverlant> why is that ?
[2017-05-18 20:50:59] <gdeverlant> it is runned via systemd this plugin
[2017-05-19 03:25:04] <electriccode> SISheogorath:  [<-CODE->]  [<-CODE->] 
[2017-05-19 03:25:33] <electriccode> its a laravel application as you can see
[2017-05-19 06:42:49] <albertjt> Does anyone know what it means by "Error: Cannot perform an interactive login from a non TTY device"
[2017-05-19 06:43:07] <albertjt> Im trying to login to docker using git bash on windows 7
[2017-05-19 09:35:08] <SISheogorath> electriccode: make sure there is a cron deamon running in your container, because by default there is no
[2017-05-19 12:17:18] <brunomilani> Hi everybody :)
[2017-05-19 12:20:48] <gadget_mnky_twitter> Hello
[2017-05-19 15:58:22] <JinnaBalu> Hoi all, run scala application with docker, any one have the sample repo, simple hello work scala file run on docker container
[2017-05-19 16:43:58] <fthamura> i try to expose docker (-H 0.0.0.0:4243), in centos
[2017-05-19 16:44:07] <fthamura> but i cannot access from outside,
[2017-05-19 16:44:11] <fthamura> is SELinux default block it?
[2017-05-19 16:44:18] <fthamura> any idea to open and test the port?
[2017-05-19 18:47:58] <electriccode> SISheogorath: yes thanks for the tip, I am using cron service in my entrypoint as I am using debian.
[2017-05-19 18:48:40] <electriccode>  [<-CODE->] 
[2017-05-19 18:48:49] <electriccode> this is how my entrypoint looks like
[2017-05-19 18:49:10] <electriccode> so crontab runs in its own shell and larval uses values inside.env
[2017-05-19 18:49:44] <electriccode> some of the values likeDB_HOSTandMAIL_HOSTare overriden byDockerfile
[2017-05-19 18:50:30] <electriccode> And cron doesn't have any access to env variables set by either docker or laravel
[2017-05-19 18:50:36] <electriccode> hence line 1 and 2
[2017-05-19 18:51:15] <electriccode> in line 1.envgets me laravel enviers, and in line 2printenvgets me docker env variables
[2017-05-19 18:51:41] <electriccode> and crontab can only access variable inside/etc/environment
[2017-05-19 18:51:46] <electriccode> its very strange :(
[2017-05-19 20:23:13] <SISheogorath> fthamura: simply run curl against it. Also check if the port is listed in the output ofnetstat -ln. Last but not least check that your firewall isn't blocking
[2017-05-19 20:26:55] <SISheogorath> electriccode: what kind of tasks do you run there?
[2017-05-19 20:27:48] <electriccode> Read some API and update DB, and also send mails periodically based on that data
[2017-05-19 20:51:54] <SISheogorath> You can maybe checkout the indiehoster setups. They build a very crazy way of a cron container for example for nextcloud, but it works fine
[2017-05-19 21:49:00] <chkm8> hi everyone, can we now name an image that is loaded from local path? Everytime I do docker load image <image_path.tar> would name your image to <none>, I dont want to tag it after save specially if you have plenty of images I cant find a hack for this. Any inputs would be appreciate! thanks
[2017-05-19 22:03:04] <cbeach> I'm having trouble with docker-compose and iptables. Something keeps wiping out our iptables, and we can't figure out what/why. Everything pretty much goes to hell when this happens.  We'd love to use a static iptalbe, but there's no guarantee that our exposed container is going to be reachable at the same ip/interface/bridge/what-have-you.
[2017-05-19 22:04:50] <cbeach> How can we fix this? I've played around with creating another bridge, but I can't seem to change it's name on the system. It's dynamically generated and has the formbr-26a6c5ff90b7as listed byifconfig
[2017-05-19 22:44:59] <gdeverlant> SISheogorath: Are you there buddy ?
[2017-05-19 22:45:09] <gdeverlant> I'm having a problem again
[2017-05-19 22:47:20] <SISheogorath> chkm8: thedocker loadreference says it's loaded with the tags you exported it [<-LINK->] 
[2017-05-19 22:47:48] <SISheogorath> gdeverlant: yes, for round about 1 hour
[2017-05-19 22:49:00] <SISheogorath> cbeach: what do you mean by wiped out? the whole iptables rules? When does it happen? And hint:docker-composeitself never touches iptables
[2017-05-19 22:52:00] <cbeach> The docker daemon is setting up a bunch of rules that docker-compose is using for isolation/communication. We're not surewhatis doing it, but yes, something is completely wiping out iptables and breaking our services.
[2017-05-19 22:53:47] <SISheogorath> does it happen on firstdocker-compose upor on everydocker-compose up? or does it happen when you rundocker-compose down?
[2017-05-19 23:17:09] <gdeverlant> cool
[2017-05-19 23:17:26] <gdeverlant> I was able to install the plugin
[2017-05-19 23:17:32] <gdeverlant> and create volumes locally
[2017-05-19 23:17:47] <gdeverlant> without a problem
[2017-05-19 23:17:56] <gdeverlant> the plugin is installed on the 10 nodes
[2017-05-19 23:19:35] <gdeverlant> the problem is in swarm mode
[2017-05-19 23:19:43] <gdeverlant> and docker stack deploy
[2017-05-19 23:19:51] <gdeverlant> with yaml file
[2017-05-19 23:19:59] <gdeverlant> the shit doesn't work men
[2017-05-19 23:20:38] <SISheogorath> what exactly does not work? how did create the volume and what is the error message?
[2017-05-19 23:22:26] <gdeverlant> this is the yaml [<-CODE->] 
[2017-05-19 23:22:37] <cbeach> docker-compose up does actually touch the iptables, as cycling docker-compose fixes the problem.
[2017-05-19 23:23:05] <cbeach> I think wemighthave gotten it fixed.
[2017-05-19 23:24:14] <gdeverlant> the service freeze in pending mode
[2017-05-19 23:24:24] <gdeverlant> and don't do anything
[2017-05-20 02:27:09] <gdeverlant> SISheogorath: It worksss superb thanx for your time
[2017-05-20 02:27:31] <gdeverlant> your help was good
[2017-05-20 09:42:48] <SISheogorath> I didn't do anything but when it helped, you're welcome :)
[2017-05-20 10:36:06] <ketchupmonkey> Hi everyone I have a question about the security of docker. I have read it's features of isolation of namespaces and etc. but what bothers me is  in a scenario that someone infiltrates the application that is running on docker and depending on how you are running docker you mount a directory to the host machine doesn't that give the attacker opportunity to go to the host machine? and another thing that  is bothering is since docker is run as root isn't that a lot scarier that the attacker can get root in the host machine?
[2017-05-20 10:53:12] <SISheogorath> @ketchupmonkey if someone infiltrates the application you can have a look at the mounts. The mount points are bind mounts. Yes, there are security problems with bind mounts for example one is describe here: http://www.openwall.com/lists/oss-security/2015/04/04/4 BUT for example this attack needs to setup an own namespace and also to create mountpoints. Docker prevents this by dropping these capabilities. [<-CODE->]  [<-CODE->] 
[2017-05-20 11:10:00] <ketchupmonkey> SISheogorath: Thanks! I really appreciate the information. I'm trying to endorse it to a few people who are kind paranoid when it comes to security but aren't really up to date on new technologies so knowing the pros and cons of using docker is a big plus. Thanks again for the info.
[2017-05-20 11:12:40] <SISheogorath> you're welcome :D
[2017-05-20 11:13:40] <SISheogorath> Hint: If the attackers manage it to escape namespaces you have way bigger problems than an application running as root ;D
[2017-05-20 11:21:00] <SISheogorath> If you want to go deeper into this (most of those security features are not docker specific) I can suggest you reading: [<-LINK->] 
[2017-05-20 11:22:05] <ketchupmonkey> haha yeah that is true
[2017-05-20 11:22:50] <ketchupmonkey> oh cool. so far I'm just reading Docker's documentation but I think it is always best to check out other resources to confirm it
[2017-05-20 11:22:58] <ketchupmonkey> Thanks for the link
[2017-05-20 13:34:38] <ajithvallabai> hi guys i want help relating XSS vulnerability which room should i approach
[2017-05-20 14:07:43] <SISheogorath> XSS in docker?@ajithvallabaiplease refer to [<-LINK->] 
[2017-05-20 14:08:09] <SISheogorath> if it's related to an application that is dockerized follow the applications vendor instructions
[2017-05-21 15:32:50] <iglov> @wenjianhn thx for answer! [<-CODE->] 
[2017-05-21 20:47:14] <banduk> Guys, I believe its a pretty beginner's problem.I cannot ping my host from a container. Is it normal?I remember to do that before by simply ping my host external IP. But for some reason I can't do that now.Could anyone help me?
[2017-05-21 20:48:35] <banduk> BTW, I'm on mac, Version 17.03.1-ce-mac12 (17661), channel: stable
[2017-05-21 20:55:12] <banduk> Well, updating to edge fixed it. Maybe its because I uninstalled the old version. Could I have any config that could cause the problem?
[2017-05-21 21:18:01] <jitendradrona> Hey, can someone help me with contanerizing an app, any link to the tutorial or anything, for example like a web farm or apache or any application as such
[2017-05-22 00:00:18] <SISheogorath> jitendradrona: There are a bunch of tutorials at [<-LINK->] . You can also checkout [<-LINK->] 
[2017-05-22 02:35:58] <siassaj> once hi hi
[2017-05-22 02:36:09] <siassaj> once? anyway
[2017-05-22 02:37:38] <siassaj> So, i'm building my docker images in a way that I've not seen recommended/taught. It seemed very difficult to do all of this with just a Dockerfile so there's a script; Does this approach make any sense or have I overcomplicated it?
[2017-05-22 02:37:47] <siassaj>  [<-LINK->] 
[2017-05-22 02:40:59] <siassaj> in essence, build.sh takes a bunch of caches that I copied out of the previous image, tars them and shoves them into a build directory. Then it runs docker build in that directory; docker pulls the tarballs in, continues the build process (which is now much faster since the build tools understand that lots of modules already exist, such as my node_modules) and once the images is built, it copies those caches back out
[2017-05-22 02:41:15] <siassaj> Sensible or this donkey is an ass?
[2017-05-22 02:42:04] <siassaj> Actually, nvm i just saw the rules what this chat is intended for; I'll head off to freenode
[2017-05-22 02:47:20] <SISheogorath> The chat is used for everything but I only talked a few times about development :D
[2017-05-22 02:48:22] <SISheogorath> In general I would say it's weird to do that ._.  you should take a look at the new multi-staged builds in 17.05
[2017-05-22 02:49:36] <SISheogorath> It would call your way to build the things overcomplicated. And you create a lot of overhead to your container. There is a lot you can optimize :)
[2017-05-22 03:12:26] <siassaj> SISheogorath: even more confusing is this line: FROM [<-LINK->] 
[2017-05-22 03:12:53] <siassaj> It appears that I'm using my previous image to build my next one, and so one. Unless I'm mistaken, this is going to cause a huge graph of layers isn't it?
[2017-05-22 03:13:22] <siassaj> (I wrote this stuff 6 months ago ... something felt wrong so i moved onto other work)
[2017-05-22 03:14:14] <siassaj> " To write a really efficient Dockerfile, you have traditionally needed to employ shell tricks and other logic to keep the layers as small as possible and to ensure that each layer has the artifacts it needs from the previous layer and nothing else."
[2017-05-22 03:14:27] <siassaj> that statement confirms my feelings about docker files (before multi stage builds)
[2017-05-22 03:17:31] <siassaj> SISheogorath: yeah multi stage makes more sense to me. I don't think it does anything to help with caching stuff between builds (for different app versions, for example caching node_modules between v1.55.1 and 1.55.2 of my app)
[2017-05-22 03:18:01] <siassaj> this FROM [<-LINK->] is causing me a lot of worry
[2017-05-22 03:42:01] <siassaj> nevermind, I'm wrong and dumb
[2017-05-22 08:16:50] <gdeverlant> SISheogorath: I'm having problems again wth docker swarm and docker stack deploy
[2017-05-22 08:17:06] <gdeverlant> 2/3 of the yaml gets deployed
[2017-05-22 08:17:17] <gdeverlant> the last part freeze on pending
[2017-05-22 08:28:12] <gdeverlant> it seems that docker swarm recogizes labels for 2 servers
[2017-05-22 08:28:23] <gdeverlant> and cannot find the labels for the last server
[2017-05-22 11:00:04] <SISheogorath> Can you see the labels on docker node ls? And can you share your yaml file because in generaldocker stack deployis designed to create the services and don't care about placement of the containers
[2017-05-22 17:10:11] <jitendradrona> SISheogorath: Thanks.
[2017-05-22 17:46:34] <gdeverlant> im back let me check
[2017-05-22 17:46:45] <gdeverlant> before i had 17-03 version from docker
[2017-05-22 17:46:52] <gdeverlant> and I updated all nodes to 15-05
[2017-05-22 17:46:56] <gdeverlant> 17-05
[2017-05-22 18:01:34] <gdeverlant> I think you are wrong stating that docker stack deploy doesn't care about placements on docker nodes
[2017-05-22 18:01:44] <gdeverlant> before I upgrade my docker
[2017-05-22 18:01:57] <gdeverlant> this was working with the placement without any problem
[2017-05-22 18:03:03] <gdeverlant> My labels are on nodes not on containers
[2017-05-22 20:24:28] <jorandradefig> Hi guys
[2017-05-22 20:24:45] <jorandradefig> I ran a container like this:
[2017-05-22 20:24:58] <jorandradefig>  [<-CODE->] 
[2017-05-22 20:25:05] <jorandradefig> It's an angular app
[2017-05-22 20:25:09] <jorandradefig> I made changes to the source code
[2017-05-22 20:25:20] <jorandradefig> How can I see the changes in the container
[2017-05-22 20:25:41] <jorandradefig> The container shows the past state
[2017-05-22 20:30:13] <jorandradefig> When I enter localhost:49160
[2017-05-22 22:01:17] <BouchaaraAdil> docker exec {put here the name of the container or his id}
[2017-05-23 02:26:06] <SISheogorath> jorandradefig: If you haven't mounted the filesystem into the cotnainer and didn't rebuild it, it's not going to change anything
[2017-05-23 02:26:26] <SISheogorath> You have to rebuild you container, stop the old one and run a new one with the new image
[2017-05-23 02:28:19] <SISheogorath> Container images are immutable. So you have to inject your sources into the container or rebuild the image and start the new one
[2017-05-23 02:32:37] <ssnyder> total newbie here...need to get an existing Ruby on Rails app dockerized for development purposes (from a Windows box).  Figured it might be easiest to start with the MySQL db, but not sure. Anyone have a pointer to a good tutorial/example for dealing with legacy apps?  I've run through the Code School free Docker course.  It was helpful, but how to do what I want is a few steps beyond.
[2017-05-23 02:45:19] <SISheogorath> ssnyder:  [<-LINK->] 
[2017-05-23 02:46:34] <SISheogorath> In general it's setup your application by a few shell scripts and act like your database and APIs are not located on the same server
[2017-05-23 02:46:38] <SISheogorath> That's it
[2017-05-23 02:51:01] <ssnyder> Thanks@Sheogorath....also I'm on Windows 10 (new machine) - installed Docker, and even though I've been running the tutorials, etc. all of a sudden it says that I may not be running in an elevated client - or that the docker daemon is not running - both of which I know are false because I had just been using it!  Is there any reason why it is so flaky?
[2017-05-23 04:17:17] <jorandradefig> SISheogorath: And how I inject the sources in the container? By rebuilding the image?
[2017-05-23 09:45:27] <SISheogorath> jorandradefig: read about volumes. There are many people out there writing blog posts about how to develop with docker and explain how to inject the sroucecode by volume
[2017-05-23 09:46:18] <SISheogorath> ssnyder: check the moby VM which runs in background
[2017-05-23 09:47:05] <SISheogorath> If you run docker for Windows it is in HyperV. If you run docker toolbox it is iirc in Virtualbox
[2017-05-23 10:17:38] <yuriy-yarosh> I'm getting strange error on Alpine withsha256sumunknown option quiet...Although Ubuntu'ssha256sumhas it and they're both using the samecoreutils
[2017-05-23 10:24:24] <SISheogorath> They are not using the same coreutils. Ubuntu runs a patched version while Alpine runs the default busybox ones
[2017-05-23 10:55:36] <yuriy-yarosh> ic, thank you@SISheogorath
[2017-05-23 11:48:05] <pmaciejewski> hi there, I'm having trouble with docker execution locally (macos) and on CI server (aws ami linux) - while I'm executingdocker exec <containerId> npm testslocally  my tests are executing and on CI server I'm getting:script returned exit code 137
[2017-05-23 11:49:15] <pmaciejewski> and frankly speaking I      even do not know where to look for solution
[2017-05-23 12:37:00] <SISheogorath> Can you show the error message?
[2017-05-23 13:03:40] <sushant91265_twitter> Hi, I need to do integration testing using docker-compose but not sure how to proceed any suggestions or references ?
[2017-05-23 13:09:31] <ssnyder> SISheogorath: I am currently running docker for windows - should I go back and install docker toolbox instead?  (I'm not sure if it is HyperV or Docker that is causing the flakiness). I used to use Vagrant/Virtualbox but it was a bit heavy weight (which is why I am trying to switch to Docker containers).  Unfortunately I am stuck with Windows 10 as my host OS.
[2017-05-23 13:34:15] <SISheogorath> Docker for Windows is fine if you use Windows 10 Pro or higher
[2017-05-23 13:35:06] <SISheogorath> sushant91265_twitter: how would you do it ouside of compose?
[2017-05-23 14:26:14] <ssnyder> I am using Windows 10 Enterprise, so that should suffice.  I'll reboot, maybe that will help remove some of the flakiness I was seeing last night
[2017-05-23 16:59:49] <sushant91265_twitter> SISheogorath: I have no clue how to do so I googled and I found this [<-LINK->] ?
[2017-05-23 21:15:34] <pdampanis> Hi all
[2017-05-23 22:22:19] <gdeverlant> greetings all
[2017-05-23 22:22:34] <gdeverlant> I tried to use the templates variables inside of a docker-compose file
[2017-05-23 22:22:35] <gdeverlant>  [<-LINK->] 
[2017-05-23 22:22:41] <gdeverlant> and it seems to not work at all
[2017-05-24 04:25:39] <sushant91265_twitter> Anybody here has created a integration testing container ?
[2017-05-24 04:53:44] <diegoxro> sushant91265_twitter: ??
[2017-05-24 04:57:24] <diegoxro> create app container and database container , load data and execute test, finally tear down
[2017-05-24 06:07:10] <vito-c> anyone notice that the@completionon github isn't working when you want to tag someone in a PR or is it just me?
[2017-05-24 06:08:07] <vito-c> i can see the name but then when I press enter it doesn't work
[2017-05-24 09:10:46] <harishgadiya> hello there, Iam stuck in a problem m not able to connect my play app to mysql inside container
[2017-05-24 09:11:07] <harishgadiya> iam using docker-compose.yml file for the same version: '3'services:  mysql-service:      image: mysql:latest      environment:        MYSQL_DATABASE: dpm        MYSQL_USERNAME: root        MYSQL_PASSWORD: root        MYSQL_ROOT_PASSWORD: root  website:      image: mc3-v3:3.0      ports: [<-CODE->] 
[2017-05-24 09:11:29] <harishgadiya> any help would be appreciated
[2017-05-24 09:16:06] <rbuckland> harishgadiya: where, in your play app are you telling it that it needs to connect tomysql-service:3306
[2017-05-24 10:00:13] <ersagun> Hi everyone, I'm a user of docker-compose on windows with docker-machine. I have multiple container, each one a  spring micro service. My question is about the excessive memory usage of docker-compose on the current version. When I launch my containers separated, I use less memory then when I launch with docker-compose. Does anybody know why on this version memory is anormally used more on docker-machine ? thanks for you help!
[2017-05-24 10:32:34] <harishgadiya> rbuckland: thanks for replying, Can you please brief what are you trying to say
[2017-05-24 10:33:15] <sushant91265_twitter> diegoxro: do you have any reference for this ? I'm not able to.
[2017-05-24 11:14:16] <fthamura> hi all
[2017-05-24 11:14:31] <fthamura> we try docker-machine to an esx server, and we got that when we restart, all the volume gone
[2017-05-24 11:14:52] <fthamura> we use docker-compose to make volume, can help guys?
[2017-05-24 11:15:53] <fthamura> how to make persistance volume in docker-machine?
[2017-05-24 11:29:37] <rbuckland> harishgadiya: what is your specific error ?
[2017-05-24 12:57:27] <Westen0x> Hi. How can I get g++ in container  withGLIBCXX_3.4.21version? I need that for bcrypt( form node.js ).
[2017-05-24 13:04:39] <matrixbot> Rahulkrishnan(rark)Please let me know how we can add iscsi to the container
[2017-05-24 15:10:38] <mnagen> Hi all, i\'m getting  an error as follows # docker-machine ip MACHINE_VM Host does not exist: "MACHINE_VM
[2017-05-24 18:20:23] <gdeverlant> Hi guys can someone point me out where is the code in docker github
[2017-05-24 18:20:42] <gdeverlant> which handles the docker service create & template variables
[2017-05-24 18:28:37] <gdeverlant> I would like to implement a specific feature
[2017-05-24 18:29:05] <gdeverlant> I'm talking about this to be more precise [<-LINK->] 
[2017-05-24 18:47:15] <jorandradefig> SISheogorath: Thank you man.
[2017-05-24 18:57:26] <matrixbot> Rahulkrishnan(rark)How can we attach iscsi volume in Docker containers
[2017-05-24 21:32:35] <SISheogorath> Rahulkrishnan(rark), if you want to use iscsi volumes as  docker volumes you have to search for a volume driver that supports it, or mount them locally and use the bind driver. I don't recommend using the bind driver for production because it maybe has bad performance.
[2017-05-25 01:10:28] <matrixbot> Rahulkrishnan(rark)Sheogorath (Gitter): I searched for volume driver for docker for iscsi but could get any info related with it
[2017-05-25 12:04:00] <SISheogorath> I think there are storage drivers using iscsi but only from proprietary storage providers/vendors. So probably you have to write an own plugin
[2017-05-25 13:25:49] <SISheogorath> Westen0x: is that inside your container or outside in some docker directory?
[2017-05-25 13:32:00] <Westen0x> SISheogorath: nvm wrong chat :/
[2017-05-25 13:35:00] <SISheogorath>   No problem
[2017-05-25 16:46:05] <iglov> i have question about diskspace in swarm mode. Imagine that i have 2 phisical servers (node1 and node2) and i create docker swarm on it with 2 managers. And then i create service with mount any directory, for ex.docker service create --mount type=bind,src=/var/www,dst=/var/www,readonly --name nginx --publish 80:80 nginx. Question: How i must sync /var/www between node1 and node2 ?
[2017-05-25 17:49:30] <SISheogorath> Well how you sync these directory is up to you. Some people actually use something like rsync in a cronjob, others run drdb I personally like to use glusterfs, but on a 3 node cluster (hint: you can't run swarmmodr on only 2 nodes, without loose the entire cluster when one manager goes down)
[2017-05-26 01:23:25] <megamindbrian> Getting error: connect ENOENT //./pipe/docker_engine on a fresh install.  HyperV MobyLinuxVM is set up and running, DockerNAT is installed and set-privilaged to private.  Any ideas?
[2017-05-26 01:24:05] <megamindbrian> The computer it works on docker-machine doesn't list anything, I assume docker-machine doesn't work on Hyper-V still?
[2017-05-26 03:55:31] <santosh2812> Hi Unable to configure Redis cluster on Docker container. have taken the image of
[2017-05-26 03:55:34] <santosh2812>  [<-LINK->] 
[2017-05-26 03:56:48] <santosh2812> if I try to connect with the Ports exposed it only connects with only one port 7002 which is one of the master. as have 3 master and 3 slave in the cluster config.
[2017-05-26 03:57:19] <santosh2812> I am using it for session management in MVC C3
[2017-05-26 03:57:23] <santosh2812> C#
[2017-05-26 04:02:26] <santosh2812> if the other port is assigned in Connection string it throw below exception
[2017-05-26 04:02:29] <santosh2812> Additional information: Endpoint 172.19.0.2:7002 serving hashslot 12808 is not reachable at this point of time. Please check connectTimeout value. If it is low, try increasing it to give the ConnectionMultiplexer a chance to recover from the network disconnect.  IOCP: (Busy=0,Free=1000,Min=4,Max=1000), WORKER: (Busy=1,Free=4094,Min=4,Max=4095), Local-CPU: 18.84%
[2017-05-26 04:02:56] <santosh2812> this from "Microsoft.Web.Redis.RedisSessionStateProvider"
[2017-05-26 04:05:13] <santosh2812> and when   "RedisSessionStateStoreProvider" it throws Additional information: MOVED 2894 172.19.0.2:7000
[2017-05-26 04:05:50] <santosh2812> unable to figure out is their any configuration problem or Please suggest.
[2017-05-26 09:09:02] <SISheogorath> This image doesn't look really useful to me. It runs the entire cluster on the same machine >.> What's the point of that?
[2017-05-26 09:40:46] <carlosjgp> iglov: You can create a NFS and attach it all your Nginx instances
[2017-05-26 10:38:11] <iglov> ok, thx, i see now. I thought docker has default solution for this issue
[2017-05-28 13:56:31] <lukaskroepfl> hi guys just a quick question. I am building a image from alpine and copying a binary to/main, inentrypoint.shI am executing main withexec /mainbut getting the error/entrypoint.sh: exec: line 8: ./main: not found
[2017-05-28 13:56:42] <lukaskroepfl> anybody an idea what is going on here? :D
[2017-05-28 13:57:30] <lukaskroepfl> funny thing is when i am doingls -labefore exec it listsmainin x mode
[2017-05-28 13:57:45] <vikas027> How are your copying a binary. I am assuming thruCOPY
[2017-05-28 13:57:49] <lukaskroepfl> yes
[2017-05-28 13:58:36] <vikas027> Try docker run /your/image /main
[2017-05-28 13:58:45] <vikas027> does it gets executed ?
[2017-05-28 13:59:13] <Clausewitz45_twitter> I know sounds stupid, but is the./mainfile is executable? Shebang is set?
[2017-05-28 13:59:56] <lukaskroepfl> i tried addingchmod +x /mainbut didnt work out.. whats shebang?
[2017-05-28 14:00:06] <lukaskroepfl> ..in the entrypoint.sh
[2017-05-28 14:00:13] <vikas027> the error would be different if./mainis not executable
[2017-05-28 14:00:43] <vikas027> Shebang is#!/path/to/<your_shell>at the top of yourentrypoint.sh
[2017-05-28 14:00:55] <Clausewitz45_twitter> Shebang: first line of the script, something like this#!/bin/shor similar
[2017-05-28 14:01:25] <Clausewitz45_twitter> vikas027: 's answer is better :-)
[2017-05-28 14:01:45] <lukaskroepfl> ah well thats set to /bin/sh
[2017-05-28 14:02:26] <lukaskroepfl> i trieddocker run -it <image> /mainand gotstandard_init_linux.go:178: exec user process caused "no such file or directory"
[2017-05-28 14:03:09] <vikas027> docker run -it <image> ls -l /?
[2017-05-28 14:03:58] <lukaskroepfl> that listsmain
[2017-05-28 14:04:12] <lukaskroepfl> even as executable
[2017-05-28 14:05:55] <vikas027> Is your script calling./main? Double check that. I would run a script in averbosemode like#!/bin/sh -xor do apwdand/orls -l(in the script) to double check if it is doing the right thing
[2017-05-28 14:08:44] <diegoxro> Clausewitz45_twitter: I was thinking the same thing
[2017-05-28 14:08:56] <lukaskroepfl> so I am doingCOPY build/main /mainand in entrypoint.shexec /mainpwdprints/
[2017-05-28 14:12:42] <lukaskroepfl> wtf I removed exec /main, ran and exec the container, did a ls andmainwas not there
[2017-05-28 14:12:55] <diegoxro> lol
[2017-05-28 14:14:06] <Clausewitz45_twitter> welcome to the matrix
[2017-05-28 14:14:27] <iglov> matrix has you
[2017-05-28 14:15:05] <diegoxro> COPY ./yourscript.sh /ENTRYPOINT ["/yourscript.sh"]
[2017-05-28 14:15:44] <diegoxro> are you using the right image? , that has happened to me before lol
[2017-05-28 14:23:09] <lukaskroepfl> ok whats wrong when i am doing ./main in the running container and sh says main not found?
[2017-05-28 14:23:30] <diegoxro> paste your Dockerfile
[2017-05-28 14:23:50] <iglov> maybe wrong WORKDIR ...
[2017-05-28 14:24:08] <lukaskroepfl>  [<-CODE->] 
[2017-05-28 14:24:42] <lukaskroepfl> note that ls lists main in the container
[2017-05-28 14:24:54] <diegoxro> COPY source destinationpath, no need to specify the name again
[2017-05-28 14:24:59] <iglov> so-o-o, where is really your entrypoint.sh ?
[2017-05-28 14:25:15] <lukaskroepfl> ah kk will try that
[2017-05-28 14:25:17] <diegoxro> and entry point is not really what you want if you want to exec main
[2017-05-28 14:25:52] <diegoxro> COPY main /ENTRYPOINT ["/main"]
[2017-05-28 14:27:01] <diegoxro> although entrypoint scripts are usually are wrapper/helper scripts to call your main program
[2017-05-28 14:27:09] <lukaskroepfl> tried entrypoint ["/main"] gotstandard_init_linux.go:178: exec user process caused "no such file or directory"
[2017-05-28 14:27:32] <lukaskroepfl> well i need to do some more things in entrypoint.sh
[2017-05-28 14:29:27] <diegoxro> how!! lol
[2017-05-28 14:29:49] <lukaskroepfl> no idea 
[2017-05-28 14:29:50] <diegoxro> are you rebuilding the image?
[2017-05-28 14:29:56] <diegoxro> you should
[2017-05-28 14:31:16] <lukaskroepfl> yeah I am rebuilding the image with the same tag every time
[2017-05-28 14:31:34] <diegoxro> ok that works
[2017-05-28 14:34:29] <diegoxro> do one image without the ENTRYPOINT and create a container just make sure the main is being loaded in the right path
[2017-05-28 14:35:32] <lukaskroepfl> ah I think it has to to smth with the binary itself ..
[2017-05-28 14:37:21] <diegoxro> that does not explain the "no such file or directory" error tho :/
[2017-05-28 14:38:47] <lukaskroepfl>  [<-LINK->] ;)
[2017-05-28 14:39:01] <iglov>  [<-LINK->] 
[2017-05-28 14:39:26] <iglov> maybe problem in your "main" ?
[2017-05-28 14:40:01] <lukaskroepfl> lolRUN mkdir /lib64 && ln -s /lib/libc.musl-x86_64.so.1 /lib64/ld-linux-x86-64.so.2and it works
[2017-05-28 14:40:15] <diegoxro> lol
[2017-05-28 14:40:16] <diegoxro> nice
[2017-05-28 14:40:38] <lukaskroepfl> thx@iglov:)I need to compile the go appl differently
[2017-05-28 14:40:42] <iglov> yep, with your "main" ...
[2017-05-28 14:41:05] <matrixbot> Rahulkrishnan(rark)Is it required to add any plugin to while creating a container to access the iscsi storage
[2017-05-28 14:41:27] <Clausewitz45_twitter> nice one
[2017-05-28 14:43:32] <lukaskroepfl> so building the binary withgo build --ldflags \'-extldflags "-static"\' -o ./build/main ./srccreates a static binary and works without theRUNcmd above :)
[2017-05-28 14:44:43] <matrixbot> Rahulkrishnan(rark)I have attached iscsi initiator to the host and format with filesystem and then attach  to the container while creating , its working fine without any volume plugin... Please let me know is this the way attaching iscsi or any other volume plugin available to attach it directly
[2017-05-29 01:52:27] <siassaj> Hi all
[2017-05-29 01:53:45] <siassaj> I think I've asked this question before; given the following: [<-CODE->] Each one of those commands takes a couple seconds to complete. Is that normal?
[2017-05-29 01:54:36] <siassaj> eg. ARG whatever, should that take 2 seconds to complete?
[2017-05-29 02:45:41] <siassaj> does docker cp turn on a container for the image, copy things in/out and then turn off that container?
[2017-05-29 02:46:28] <siassaj> to be more clear, I have several docker cp calls in my build script that copies build artefacts out of the docker image to be held onto as cache, which is then copied back into the docker image before building
[2017-05-29 02:48:24] <siassaj> dumb question, i'm already building a container, it's just not on
[2017-05-29 05:15:27] <santosh2812> Hi@SISheogorath, can you suggest me any redis cluster Image by which we can create 3 master or more with corresponding slaves on different Machine (Docker Container ), as currently am not able to do so and also not able to connect with different master.
[2017-05-29 09:33:42] <SISheogorath> santosh2812: I'm pretty sure there is no out of the box solution right now
[2017-05-29 09:34:20] <SISheogorath> But [<-LINK->] looks promising, maybe you can work on it or write it yourself
[2017-05-29 15:28:34] <JinnaBalu> Hi need help, I am currently runing jenkins on docker,  trying to build docker image and push to registry, through jenkins pipeline. jenkins pipeline passes all the stages except when it need to build docker:build command it fails. it is like jenkins on docker, trying build docker image in it. is it possible?
[2017-05-29 15:38:05] <gdeverlant> Hi guys
[2017-05-29 15:38:13] <gdeverlant> I'Ve posted an issue on [<-ISSUE->] 
[2017-05-29 15:38:25] <gdeverlant> I was wondering if I'm doing something wrong with docker
[2017-05-29 15:38:40] <gdeverlant> I dockerized a 32 bits RethinkDB
[2017-05-29 15:38:52] <gdeverlant> and I was trying to run it inside of a 64 bits server
[2017-05-29 15:39:05] <gdeverlant> since there is no 64 bits of RethinkDB
[2017-05-29 15:39:27] <gdeverlant> and all of this is running on ARM64 Bits servers with docker v17.05ce
[2017-05-29 15:39:47] <gdeverlant> Am I doing something wrong here
[2017-05-29 15:40:08] <gdeverlant> because when I run the binary without docker raw on the server
[2017-05-29 15:40:10] <gdeverlant> it works fine
[2017-05-29 15:40:17] <gdeverlant> but not in dockerized version
[2017-05-29 17:16:03] <SISheogorath> Do you use the exact same binary?
[2017-05-30 00:06:36] <gdeverlant> yes
[2017-05-30 09:26:01] <SISheogorath> In this case it's maybe a dependency problem
[2017-05-30 17:09:53] <renegoretzka> hello, i have a big big problem.. somehow rancher recreated a container and i lost all the data which were in the container.. is there any way to restore it? i did not have a volume attached
[2017-05-30 18:24:54] <imaia> folks, I'm having a trouble declaring named containers in docker-compose
[2017-05-30 18:26:07] <imaia>  [<-CODE->] Shouldn't the code above work? Like, declare a named volume called ux-data mapped to /home/user/volumes/ux-data
[2017-05-30 20:58:43] <shawninder> I just noticed my repos all disappeared from Docker Hub, yet I can stilldocker pullthem. Is anyone here aware of any trouble on the docker hub side?
[2017-05-30 20:59:35] <gdeverlant> renegoretzka: You cannot recover delete container data unless you used a persistent-driver
[2017-05-30 20:59:45] <gdeverlant> to create the volume or the mapping
[2017-05-30 21:00:00] <gdeverlant> I might be wrong here but this is what I've learned
[2017-05-30 21:04:41] <shawninder> I found my answer, there is currently an incident affecting many docker services, more info: [<-LINK->] 
[2017-05-30 23:11:21] <SISheogorath> renegoretzka: there is a little chance. If the image used for the container has decelerated the directory you need to restore asVOLUMEthere is maybe a unnamed volume remaining, that holds the data. Check withdocker volume ls. If not, it's gone
[2017-05-30 23:12:07] <SISheogorath> but in general: no volume, no persistent data
[2017-05-30 23:13:36] <SISheogorath> imaia: you have to declerate the volume path (inside the container) in theservices:inside your container, not in the volume section. There you decelerate things like the volume driver and options
[2017-05-30 23:13:54] <SISheogorath> shawninder: should be fixed now
[2017-05-30 23:53:38] <gdeverlant> renegoretzka: I recommend you to use this amazing plugin that I'm using in my cluster with docker swarm
[2017-05-30 23:53:51] <gdeverlant> It's a legacy plugin but it does the job
[2017-05-30 23:54:02] <gdeverlant>  [<-LINK->] 
[2017-05-30 23:54:18] <gdeverlant> it will create your volumes with persistency and never delete them
[2017-05-30 23:54:46] <gdeverlant> like when you use docker run -v /path/to/my:/path/to/container
[2017-05-30 23:54:52] <gdeverlant> but with volumes
[2017-05-30 23:54:56] <gdeverlant> it is very usefull
[2017-05-31 00:16:36] <chkm8> hi guys, i would like to ask if is it possible to use docker in windows 2008 server?
[2017-05-31 00:18:11] <SISheogorath> chkm8: not as far as I know. You have to use Windows Server 2016 or linux. Especially if you want to go in production. For development using docker toolbox or docker4Windows (warning only for Windows 10) fine, but don't try to use them in production
[2017-05-31 00:20:24] <SISheogorath> gdeverlant: I'm not sure about the idea that a deleted volume remains is the right way. Because exactly that is what you have volume handling for. To explicitly decide what you want to persist and what you want to delete. Anyways, in production you shouldn't use local volumes
[2017-05-31 00:40:00] <chkm8> darn windows, thanks@SISheogorathwe will just look for alternative way
[2017-05-31 00:40:10] <gdeverlant> I use volumes on each nodes
[2017-05-31 00:40:13] <gdeverlant> for DB
[2017-05-31 00:40:33] <gdeverlant> volume mounting
[2017-05-31 00:40:42] <gdeverlant> with the local-persist plugin
[2017-05-31 00:40:53] <gdeverlant> I don't know if this is a bad practice
[2017-05-31 00:41:02] <gdeverlant> I'm running inside docker swarm
[2017-05-31 00:49:41] <gerome0123> Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?
[2017-05-31 00:49:44] <gerome0123> need help :(
[2017-05-31 01:05:39] <SISheogorath> gerome0123: please make sure docker is running, what OS are you using?
[2017-05-31 01:06:06] <SISheogorath> For most OS the commandsystemctl status dockershould give you the answer
[2017-05-31 01:06:18] <SISheogorath> Otherwise tryservice docker status
[2017-05-31 01:25:27] <gerome0123> i install docker toolbox
[2017-05-31 01:28:45] <SISheogorath> So you are on Windows? MacOS?
[2017-05-31 01:31:19] <gerome0123> mac os
[2017-05-31 01:32:04] <gerome0123>  [<-LINK->] 
[2017-05-31 01:33:10] <gerome0123> my postgress restarting??
[2017-05-31 01:33:14] <gerome0123> how to up that>?
[2017-05-31 02:15:16] <gerome0123> i try to sudo my up now its working thanks
[2017-05-31 03:40:10] <jmsherry> Hey guys, I'm new to docker and wondered if you could help?I dockerised a simple express file server from scratch and was able to view it in the browser at localhost and obviously 0.0.0.0 [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] Does anyone know why??
[2017-05-31 04:25:08] <jmsherry> OK, so more research shows that this is a node 7 thing (http://blog.lholmquist.org/promise-rejection-handling/) but I still can't reach the container from the outside. :/Repo at: https://github.com/jmsherry/cd3
[2017-05-31 08:14:44] <mingliang7> I cant run this docker command in cronPATH=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin\n*/2 * * * * /bin/bash docker exec -it mongo mongodump --db restaurant --out /dump/restaurant/$(date +%Y-%m-%d) && docker cp mongo:/dump/restaurant ~/Desktop/mongo && docker exec -it mongo rm -rf dump/restaurant
[2017-05-31 08:42:25] <iglov> maybe cuz need use full path without ~ ?
[2017-05-31 08:44:47] <mingliang7> can you give me example for that ?
[2017-05-31 08:47:14] <dv29> I am working on a nodejs project, and have got docker working on it, have a volume fornode_modulesbut i need to access binaries inside the bin folder, any idea, how can i accomplish that.its give outroot:rootfor owner and group
[2017-05-31 08:53:34] <iglov> something like thisdocker exec -it mongo mongodump --db restaurant --out /dump/restaurant/$(date +%Y-%m-%d) && docker cp mongo:/dump/restaurant /var/mongo/ && docker exec -it mongo rm -rf dump/restaurant
[2017-05-31 08:53:39] <iglov> mingliang7: 
[2017-05-31 08:55:50] <iglov> but  maybe better mount with-vdirectory /dump/restaurant ? It'd be much simple, i think
[2017-05-31 09:00:45] <gdeverlant> @gdeverlant@gdeverlant I'm not sure about the idea that a deleted volume remains is the right way. Because exactly that is what you have volume handling for. To explicitly decide what you want to persist and what you want to delete. Anyways, in production you shouldn't use local volumes@SISheogorath The idea was to persist deleted container's volumes
[2017-05-31 09:08:31] <carlosjgp> dv29: if you are running docker on linuxdocker run -u $UID:$GID .... But as a good practice create your own user insede your container and use it to run your containers " [<-LINK->] "
[2017-05-31 09:14:40] <carlosjgp> jmsherry: What is the output ofdocker ps? Does is shows your container port 8080 exposed?
[2017-05-31 09:15:37] <dv29> carlosjgp: i am using docker-compose, have tried it with $UID on that one
[2017-05-31 09:18:32] <kevinlincg> hi , I am new in docker , I need some suggest.  I have an web application with  golang as backend  and angularjs as frontend  and mysql as database .  Should I seperate they to three different containers?
[2017-05-31 09:20:01] <mingliang7> iglov: it's not working. Yes  -v options is great but i just want to backup db everyday. if you use -v options is not a good idea
[2017-05-31 09:20:19] <carlosjgp> dv29: As far as I knowdocker-composehas no support for the--userflag... try this --> [<-LINK->] but using youruidandgid
[2017-05-31 09:22:51] <carlosjgp> kevinlincg: Yes, try to keep them on their own container. It\'s one of the container principles " [<-LINK->] "
[2017-05-31 10:05:22] <dv29> carlosjgp: i tried that and i think it worked, but now npm cannot create/.npmdirectory
[2017-05-31 10:05:47] <dv29> asks for sudo permission, any idea?
[2017-05-31 10:09:24] <carlosjgp> dv29: This is because now your container is not running using therootuser, but a custom user. In which stage do you have the problem, building or running the container?as workaorund you can map a volume to that folder... so you save all the npm modules outside the container which will save time if you create a new one ;)
[2017-05-31 10:12:13] <dv29> i guess, running, coz i am doingnpm installin entrypoint file
[2017-05-31 10:12:38] <dv29> i am doing exactly that, create a volume for that folder
[2017-05-31 10:14:37] <dv29>  [<-CODE->]  [<-CODE->] 
[2017-05-31 10:14:39] <carlosjgp> dv29: So it's because that folder has been created by the container usingrootas user. Just delete your local folder fornpm_modulesor change the owner and group to yours
[2017-05-31 10:15:09] <dv29> carlosjgp: i am rebuilding everything, but before that i delete everything
[2017-05-31 11:21:51] <jmsherry> carlosjgp: :docker run -it --rm -p 8080:8080 cd:0.0.1docker ps1c5ea5a96d5e        cd:0.0.1            "npm run start:pro..."   About a minute ago   Up About a minute   0.0.0.0:8080->8080/tcp   condescending_hugle
[2017-05-31 11:50:32] <SISheogorath> @gdeverlant I was aware of the idea, but that\'s exactly what volumes are for... Keep data until you want to delete them. And when you delete a volume, the data are gone. Of course you can "hack" something together to just mimes volumes, but as mentioned, it breaks the idea. Maybe checkout the idea behind volumes: https://en.wikipedia.org/wiki/Volume_%28computing%29Hint: In most real production use cases docker volumes are volumes on a storage server so they are handled different. the local behavior is mainly to have something working during development ^^
[2017-05-31 13:53:08] <carlosjgp> jmsherry: Everything looks good here... is npm server/process using por 8080? Can you run the app outside the container without issues?
[2017-05-31 13:53:50] <jmsherry> carlosjgp: Yes, it runs fine outside...
[2017-05-31 13:54:47] <jmsherry> (And yes the port is set to 8080)
[2017-05-31 14:12:11] <jmsherry>  [<-CODE->] That's it, right?! There's nothing else??
[2017-05-31 14:20:51] <jmsherry> The worst thing is that I'm trying to convince people of how easy and good docker is, but stuff like this just gives ammunition to people stuck in their ways...
[2017-05-31 14:21:21] <jmsherry> Like I said, I can run it outside without issue and I can go inside the container and cURL it without issue too! Grrr...
[2017-05-31 14:25:36] <carlosjgp> jmsherry: try to ssh into your contianer and cUrllocalhost:8080
[2017-05-31 14:26:08] <jmsherry> carlosjgp: That's what I did! That works...
[2017-05-31 14:26:39] <jmsherry> Oh, wait, you mean NOT viadocker exec?!
[2017-05-31 14:26:53] <carlosjgp> yep
[2017-05-31 14:32:00] <jmsherry> carlosjgp: I'd have to install something in the image to do that, right?! Likeopenssh-server??
[2017-05-31 14:32:27] <carlosjgp> justdocker exec <container-name>  bash(maybeashif is based on alpine )
[2017-05-31 14:33:21] <jmsherry> carlosjgp: Yes, I did that and it works...
[2017-05-31 14:33:45] <carlosjgp> and did you check the logs?docker logs ...
[2017-05-31 14:35:01] <jmsherry> carlosjgp: I didn't because it seemed to be working fine. Inside the container the local server gives me back what I want. Outside it's just like there's no connection... (I'll go in and check the logs now to see if there's anything interesting...)
[2017-05-31 14:42:23] <jmsherry> carlosjgp: So, I connected to bash fine. I checked the logs withdocker logsand it's just what I see during the boot process. There's nothing afterwards. :/
[2017-05-31 14:43:10] <jmsherry> ( I just pushed the latest version of the project to github, so you can see if you want: [<-LINK->] )
[2017-05-31 14:47:33] <carlosjgp> jmsherry: And the command tobuildandrunthat image?
[2017-05-31 14:49:38] <jmsherry> Yes, in the docker file: [<-CODE->]  [<-CODE->] 
[2017-05-31 14:50:37] <jmsherry> In the npm scripts you've got: [<-CODE->] 
[2017-05-31 14:51:45] <jmsherry> carlosjgp: ^^
[2017-05-31 15:10:15] <carlosjgp> jmsherry: but how do you run your docker image?docker run  ...  cd3?
[2017-05-31 15:13:22] <jmsherry> carlosjgp: docker run -it --rm -p 8080:8080 cd:0.0.1I've just found an issue running outside the app! It cURLs fine but won't attach to browser...Let me get back to you. Sorry and Thanks
[2017-05-31 16:00:48] <carlosjgp> jmsherry: It's really strange... try to run in other portdocker run -it --rm -p 8089:8080 cd:0.0.1. I can't think on anthing else... Hope it works!
[2017-05-31 16:17:34] <jorandradefig> Hi guys
[2017-05-31 16:17:42] <jorandradefig> I'm getting this error but I don't get it
[2017-05-31 16:17:47] <jorandradefig>  [<-CODE->] 
[2017-05-31 16:18:40] <jorandradefig>  [<-CODE->] 
[2017-05-31 16:18:54] <jorandradefig> With
[2017-05-31 16:19:02] <jorandradefig>  [<-CODE->] 
[2017-05-31 16:22:46] <jmsherry> jorandradefig: what's the colon for in the path??
[2017-05-31 16:23:31] <jorandradefig> The right side is for the path in the container
[2017-05-31 16:23:37] <jorandradefig> jmsherry: 
[2017-05-31 18:40:19] <gdeverlant> SISheogorath: I cannot affort to delete them because I don't have a storage server each node has its own 1TB HD which contains DB volumes
[2017-05-31 18:41:19] <gdeverlant> Sometimes the nodes are going down and they need to restart
[2017-05-31 18:41:52] <gdeverlant> They need to find their respective data... If you think that I'm using the wrong architecture please let me know how to improve it
[2017-05-31 20:18:22] <renegoretzka> SISheogorath: Hey thanks for reply, how to mount that volume to a container to check if its the right one?
[2017-05-31 20:28:45] <renegoretzka> is there a way to look into a volume contents?
[2017-05-31 21:00:09] <renegoretzka> damn.. it wasnt the volume i was looking for which i found
[2017-05-31 21:00:18] <renegoretzka> thanks for the support
[2017-05-31 21:45:41] <mmcintyre123> Hi there, wondering if anyone has used Docker for continuous integration for mobile testing on iOS?
[2017-05-31 21:49:33] <mmcintyre123> I have automated mobile app tests setup using Appium, written in Node.js, for testing iOS and Android apps.  I build the iOS app using XCode command line tools, use git for source control, and mocha to run the tests. Currently they run locally in an iOS simulator. I am looking at using Shippable to create continuous integration, and Docker seems like a good way to create an environment Shippable can point to to run the tests on.  But this means I will need to create a Docker image with xcode command line tools, as well as Appium, Mocha, and everything else needed to run the tests.  Is this possible?  I'm worried about the xcode command line tools in particular, since XCode is licensed.  Does anyone know if this is possible or has anyone set it up?
[2017-06-01 06:48:59] <bherila> We have our database running inside a docker image. The VM rebooted for some reason and now I can\'t start our docker image anymore. It fails with "invalid network mode: default."Searching the web informed me I need to change this to "bridge," but for the life of me I can\'t find out how to make that change.Please help if anyone knows!!!
[2017-06-01 06:55:29] <tomVeloso> Hi There, from outised the container I once terminate a  process and now I cannot run command from outside the container
[2017-06-01 06:55:56] <tomVeloso> however I had a container attached with a shell session that still work
[2017-06-01 06:56:14] <tomVeloso> on that container I cannot even do a dockers logs
[2017-06-01 07:09:22] <SISheogorath> tomVeloso: does docker ps show the container
[2017-06-01 07:09:27] <SISheogorath> ?
[2017-06-01 07:42:41] <tomVeloso> SISheogorath: even 'docker ps' is not responding
[2017-06-01 07:43:09] <tomVeloso> it just hang
[2017-06-01 07:58:17] <MaksimKiselev> Hi guys. I use reverse-proxy(nginx-proxy) to my nginx containers and I want pass real IP from user.Now config: [<-CODE->] But real IP passed to X-Forwarded-For header. I use framework and them get IP from REMOTE_ADDR header.What I should to do what get real IP in REMOTE_ADDR? (transparent proxy)
[2017-06-01 08:27:07] <carlosjgp> jorandradefig: try () instead {}docker run -v $(pwd):/usr/src/app -p 49160:4200 -d hq/website
[2017-06-01 09:25:36] <SISheogorath> tomVeloso: that's not good. I guess system usage is low?
[2017-06-01 09:33:53] <SISheogorath> maybe check for existing bugs: [<-LINK->] 
[2017-06-01 09:47:02] <santosh2812> HI I am trying to install redis-sentinel  mode and in the configuration I have set  My system IP, but when i run the container its not showing the IP from which I can connect from out side . its showing the local Ip of the docker. any help   the protected-mode noport 26379sentinel announce-ip 192.168.80.169dir /tmpsentinel monitor mymaster redis-master 6379 $SENTINEL_QUORUMsentinel down-after-milliseconds mymaster $SENTINEL_DOWN_AFTERsentinel parallel-syncs mymaster 1sentinel failover-timeout mymaster $SENTINEL_FAILOVER
[2017-06-01 12:28:24] <fthamura> guys,  what is your recommendation for hypervisor that good for docker-machinewe use esx, work wellbut we try promox, qemu-kvm, still dont know how to use it , we can create vm inside linux (ubuntu for qemu-kvm), but for remote, beacuse the driver dont have username or password. any help?
[2017-06-01 14:29:16] <mmcintyre123> Is it possible to install XCode command line tools in a Docker image?
[2017-06-01 14:33:09] <mmcintyre123> Has anyone done this?
[2017-06-01 14:34:38] <carlosjgp> santosh2812: try network mode host [<-LINK->] 
[2017-06-01 14:39:25] <mmcintyre123> Interesting, thanks Carlos!  So I'm trying to create a Docker image for my automated mobile tests for iOS.  I would then pass that image to Shippable, in order to create continuous integration - Shippable detects a change to the repo, then kicks off tests in the Docker image.  If I created a Docker host in network mode, would this conceivably be able to communicate with my local machine, i.e. actually run the tests on my local machine, after being triggered from Shippable (cloud based)?
[2017-06-01 14:45:07] <carlosjgp> mmcintyre123: Docker network host mode is a good practice and should be avoided. But is ok for a proof of concept.Kicking you local container to run the test is not related with Docker... You can use webhooks and other mechanism to trigger it
[2017-06-01 14:46:19] <mmcintyre123> Ok thanks.  So there's really no method yet to use xcode command line tools in a regular cloud hosted docker container?
[2017-06-01 14:49:37] <carlosjgp> mmcintyre123: No idea... but is own by Apple, so I don't think so
[2017-06-01 15:08:08] <mmcintyre123> lol owned by Apple says it all.  Oh well thanks for the info!
[2017-06-01 17:13:24] <gdeverlant> what does this error mean ?
[2017-06-01 17:13:37] <gdeverlant>  [<-CODE->] 
[2017-06-01 17:14:34] <gdeverlant> -Swarm Manager traefik-network
[2017-06-01 17:18:00] <gdeverlant>  [<-LINK->] 
[2017-06-01 17:18:05] <gdeverlant> This is the Details of traefik-net on the second worker node
[2017-06-01 17:18:29] <gdeverlant>  [<-LINK->] 
[2017-06-01 17:18:41] <gdeverlant> this is the docker-compose.yml
[2017-06-01 17:19:56] <gdeverlant>  [<-CODE->] 
[2017-06-01 17:23:55] <gdeverlant> The problem happens to be that traefik is able to identify all the services running on the swarm manager and creates their endpoint without a problem
[2017-06-01 17:24:33] <gdeverlant> Then traefik seems to be able to identify the other services on the first worker node and creates the endpoints
[2017-06-01 17:24:44] <gdeverlant> but when I type the url in the browser
[2017-06-01 17:27:09] <gdeverlant> Traefik sends in its logs
[2017-06-01 17:28:26] <gdeverlant>  [<-CODE->] 
[2017-06-01 17:30:41] <gdeverlant>  [<-CODE->] 
[2017-06-01 17:41:15] <mahenrique94> good afternoon, I've a private system here on my job build by java, to deploy we use docker with tomcat and to database docker with postgres
[2017-06-01 17:41:30] <mahenrique94> always I that start the both containers using swarm the system take down automatily
[2017-06-01 17:41:32] <mahenrique94> if I start them with docker run or docker-compose, both work perfectily
[2017-06-01 17:41:35] <mahenrique94> any suggestion ?
[2017-06-01 18:26:24] <SISheogorath> gdeverlant: how did you create the overlay network? And do you run your drone setup bydocker runor bydocker stack deploy
[2017-06-01 18:27:18] <SISheogorath> mahenrique94: What doesdocker service ps <servicename>tell you?
[2017-06-01 18:27:33] <gdeverlant> docker stack deploy
[2017-06-01 18:27:54] <gdeverlant> i created an ingress traefik network like in the documentation of traefik
[2017-06-01 18:29:10] <SISheogorath> gdeverlant: do you see the overlaynetwork on your node2?
[2017-06-01 18:29:40] <gdeverlant> look at the picture i posted
[2017-06-01 19:00:53] <gdeverlant> it's there
[2017-06-01 19:01:04] <gdeverlant> I've erased all my cluster
[2017-06-01 19:01:10] <gdeverlant> and I'm starting from scratch
[2017-06-01 19:02:18] <gdeverlant>  [<-CODE->] 
[2017-06-01 19:02:58] <gdeverlant>  [<-CODE->] 
[2017-06-01 19:03:15] <gdeverlant> swarm-net is the network I will use with Traefik
[2017-06-01 19:03:44] <gdeverlant> docker network create -d overlay   --subnet=10.11.0.0/16    swarm-net
[2017-06-01 19:05:19] <SISheogorath> still the problem?
[2017-06-01 19:05:31] <SISheogorath> is the firewall on your nodes enabled?
[2017-06-01 19:08:47] <gdeverlant>  [<-CODE->] 
[2017-06-01 19:11:26] <SISheogorath> well, the important server, server2 is not visible :D
[2017-06-01 19:15:35] <gdeverlant> lol my bad
[2017-06-01 19:15:39] <gdeverlant> I'm freaking tired
[2017-06-01 19:15:44] <gdeverlant>  [<-CODE->] 
[2017-06-01 19:20:53] <gdeverlant> What does this mean
[2017-06-01 19:21:07] <gdeverlant> This is the Swarm Manager [<-CODE->] 
[2017-06-01 19:21:16] <gdeverlant> the 2 first one what are they
[2017-06-01 19:21:54] <SISheogorath> what kind of "server" is your manager node? something physical? something with a modem?
[2017-06-01 19:22:14] <gdeverlant> no
[2017-06-01 19:22:22] <gdeverlant> they are all connected to a switch
[2017-06-01 19:22:31] <gdeverlant> and the router is connecter to a DSL router
[2017-06-01 19:22:50] <SISheogorath> Or does it do some kind of VPN?
[2017-06-01 19:23:03] <gdeverlant> yes i've put a VPN on the Swarm Manageer
[2017-06-01 19:23:11] <gdeverlant> can that pose a problem for docker ?
[2017-06-01 19:23:14] <SISheogorath> That's your problem :D
[2017-06-01 19:23:20] <gdeverlant> PPTPD
[2017-06-01 19:23:24] <SISheogorath> check your routing tables ;)
[2017-06-01 19:23:36] <gdeverlant> how do I do that ?
[2017-06-01 19:23:40] <SISheogorath> shared kernels means also shared routing tables
[2017-06-01 19:23:57] <SISheogorath> create the overlay network outside of 10.0.0.0/8
[2017-06-01 19:25:01] <gdeverlant>  [<-CODE->] 
[2017-06-01 19:25:21] <gdeverlant>  [<-CODE->] 
[2017-06-01 19:25:26] <gdeverlant> is this ok ?
[2017-06-01 19:25:53] <SISheogorath> no... It is still part of the 10.0.0.0/8 network
[2017-06-01 19:26:04] <gdeverlant> how do you know ?
[2017-06-01 19:26:26] <gdeverlant> or how can I move the PPTPD
[2017-06-01 19:26:32] <gdeverlant> to another place ?
[2017-06-01 19:26:58] <gdeverlant> I didn't control the first ingress network docker swarm created it automatically
[2017-06-01 19:27:12] <gdeverlant> the swarm-net I created
[2017-06-01 19:28:19] <SISheogorath> Subnetting -> here you go:https://www.cisco.com/c/en/us/support/docs/ip/routing-information-protocol-rip/13788-3.htmlhttps://en.wikipedia.org/wiki/Subnetwork
[2017-06-01 19:28:40] <gdeverlant> ohhhh that's so stupid I didn't realize that it could mess with docker swarm this pptpd
[2017-06-01 19:29:14] <SISheogorath> want a really easy way to get out of it? use another server as manager and kick out the one with the PPPTD ;)
[2017-06-01 19:30:34] <SISheogorath> You can configure it to not have any problem with it but that's a lot of work and I'm not really in the mood to explain how to use multiple routing tables, network rules and network namespacing in general :D
[2017-06-01 19:30:45] <gdeverlant> sudo apt-get autoremove --purge pptpd
[2017-06-01 19:30:59] <gdeverlant> is this enough ?
[2017-06-01 19:31:13] <SISheogorath> I won't say yes or no, I have no idea of your setup and what it possibly breaks
[2017-06-01 19:31:24] <SISheogorath> that's something you have to know
[2017-06-01 19:31:41] <mahenrique94> SISheogorath: container it’s running, I think that the problem it’s been resolved, I stop postgres container and started it on main host
[2017-06-01 19:31:49] <gdeverlant> i just installed a basic pptpd setup from a tutorial online
[2017-06-01 19:32:35] <SISheogorath> mahenrique94: glad to hear that it works :) still a weird issue
[2017-06-01 19:33:15] <mahenrique94> is it wrong build a database with container ?
[2017-06-01 19:33:18] <gdeverlant> this is the tutorial [<-LINK->] 
[2017-06-01 19:33:40] <mahenrique94> Each person say onething
[2017-06-01 19:34:08] <mahenrique94> Some say “No problem”, anothers “Your data i’ll be corrupted"
[2017-06-01 19:38:35] <gdeverlant> SISheogorath: how can I revert those lines  in step 4
[2017-06-01 19:38:39] <gdeverlant>  [<-CODE->] 
[2017-06-01 19:40:24] <SISheogorath> Here you go: [<-LINK->] 
[2017-06-01 19:42:59] <SISheogorath> mahenrique94: It's difficult to say it completely for sure. First of all it depends on the database itself. Some care more about data consistency other less. Then again it depends on the underlying file system you use as database storage, the configuration of the database, sometimes even the configuration of your host systems kernel...
[2017-06-01 19:43:01] <gdeverlant> from input I know
[2017-06-01 19:43:08] <gdeverlant> but there is nat tables
[2017-06-01 19:43:55] <SISheogorath> gdeverlant: Here you go:iptables -L -v --line-numbers
[2017-06-01 19:46:40] <SISheogorath> or to make it a bit shorter:iptables -t nat -v -L POSTROUTING -n --line-number
[2017-06-01 19:47:59] <gdeverlant> now I get it thanx a lot buddy I will remove all that junk I've put there
[2017-06-01 19:48:10] <gdeverlant> and come reset my setup
[2017-06-01 19:48:14] <gdeverlant> and test again
[2017-06-01 19:48:39] <gdeverlant> what an idiot I am with installing PPTPD  without thinking it might hurt
[2017-06-01 20:31:29] <gdeverlant> SISheogorath: I've cleaned my iptables
[2017-06-01 20:31:45] <gdeverlant> but I was wondering if this many entries are normal in my nat table
[2017-06-01 20:31:50] <gdeverlant>  [<-CODE->] 
[2017-06-01 20:45:40] <SISheogorath> docker has to use NAT, too
[2017-06-01 21:04:29] <gdeverlant> yeah i removed almost all of the things there
[2017-06-01 21:04:47] <gdeverlant> 4 left of the whole crew
[2017-06-01 21:27:27] <gdeverlant> hmmm it doesn't work
[2017-06-01 21:27:37] <gdeverlant> although I restarted all my setup
[2017-06-01 21:28:04] <gdeverlant> can I deploy 3 services on swarm manager via docker service create
[2017-06-01 21:28:20] <gdeverlant> which one of them is Traefik
[2017-06-01 21:28:51] <gdeverlant> and expect Traefik to be able to route other services deployed via docker stack deploy ?
[2017-06-01 21:29:15] <gdeverlant> on the second worker
[2017-06-01 21:30:25] <gdeverlant> hmmmm I just got theses : Message from syslogd@bambuserver2 at Jun  1 21:23:31 ... kernel:[10816.283151@0] unregister_netdevice: waiting for lo to become free. Usage count = 1Message from syslogd@bambuserver2 at Jun  1 21:23:41 ... kernel:[10826.493028@0] unregister_netdevice: waiting for lo to become free. Usage count = 1
[2017-06-01 21:33:15] <gdeverlant> time="2017-06-01T21:32:37Z" level=warning msg="Error forwarding to [<-LINK->] , err: dial tcp 10.11.0.9:8000: i/o timeout"
[2017-06-02 09:03:37] <jaksky> How to propagate a define hostname of one container which I need to specify to another one in docker compose (v.2 which is used by AWS ECS)? I specified hostname for a first container and second one links to the first one
[2017-06-02 09:45:07] <SISheogorath> You can use the service name.
[2017-06-02 12:18:21] <gdeverlant> SISheogorath: I started all from scratch
[2017-06-02 12:18:22] <gdeverlant> time="2017-06-02T12:17:59Z" level=warning msg="Error forwarding to [<-LINK->] , err: dial tcp 10.11.0.13:8000: getsockopt: no route to host"
[2017-06-02 12:19:00] <gdeverlant> this service which is on the first worker node always result bad gateway
[2017-06-02 12:19:12] <gdeverlant> and traefik seems to not find it
[2017-06-02 12:19:24] <gdeverlant> but if you look at all the other services on the manager nodes
[2017-06-02 12:19:40] <gdeverlant>  [<-LINK->] 
[2017-06-02 12:19:53] <gdeverlant> they are recognized
[2017-06-02 12:20:14] <gdeverlant>  [<-LINK->] 
[2017-06-02 12:50:03] <gdeverlant> what does that mean
[2017-06-02 12:50:04] <gdeverlant> kernel:[2292.232893@3] unregister_netdevice: waiting for lo to become free. Usage count = 1
[2017-06-02 13:48:49] <aaronmcadam> Has anybody ever had issues with Docker ignoring.dockerignore?
[2017-06-02 14:27:04] <gdeverlant> Ok guys I think I have found a bug with docker
[2017-06-02 14:27:27] <gdeverlant> related with the following error
[2017-06-02 14:27:27] <gdeverlant> time="2017-06-02T12:17:59Z" level=warning msg="Error forwarding to [<-LINK->] , err: dial tcp 10.11.0.13:8000: getsockopt: no route to host"
[2017-06-02 14:44:13] <gdeverlant> I don't know if the problem is related with my iptables
[2017-06-02 14:44:21] <gdeverlant> or is it with what docker generates
[2017-06-02 15:18:29] <gdeverlant> what does that mean
[2017-06-02 15:18:30] <gdeverlant> unregister_netdevice: waiting for lo to become free. Usage count = 1
[2017-06-02 15:18:44] <gdeverlant> it is on the first worker node
[2017-06-02 15:45:30] <gdeverlant>  [<-ISSUE->] 
[2017-06-02 15:46:01] <gdeverlant> I'm running HypriotOS debian jessie arm32 and arm64
[2017-06-02 16:54:30] <brjadams> The command '/bin/sh -c yum -y install python-pip' returned a non-zero code: 1 on this centos7 image
[2017-06-02 16:54:46] <brjadams> any idea why my image won't find pip?
[2017-06-02 19:51:39] <udaykiran19> brjadams: try installing epel-release first - > sudo yum install epel-release and then try pip
[2017-06-02 20:42:28] <gdeverlant> time="2017-06-02T20:42:03Z" level=warning msg="Error forwarding to [<-LINK->] , err: dial tcp 10.11.0.12:8001: i/o timeout"time="2017-06-02T20:42:03Z" level=debug msg="Round trip: [<-LINK->] , code: 200, duration: 9.711058ms"time="2017-06-02T20:42:05Z" level=warning msg="Error forwarding to [<-LINK->] , err: dial tcp 10.11.0.2:8000: i/o timeout"
[2017-06-02 20:42:42] <gdeverlant> why do I get timeout from Docker Swarm and its mesh network
[2017-06-03 10:42:02] <gdeverlant> Hi guys why do I get this error constantly
[2017-06-03 10:42:03] <gdeverlant> time="2017-06-03T10:41:17Z" level=warning msg="Error forwarding to [<-LINK->] , err: dial tcp 10.11.0.2:8000: i/o timeout"
[2017-06-04 12:48:46] <SISheogorath> aaronmcadam: Nope..dockerignoreshould work fine. But maybe you have to place it in your build context directory. I'm not sure if it works like.gitignoreand also works in subdirectories
[2017-06-04 12:54:11] <SISheogorath> gdeverlant: there are a lot possible reasons for that. First of all please disable the firewall to check if it's a firewall problem. Than check your routing tables to make sure that there are not further routing conflicts. When you did this, please check if you can connect to another container inside your overlay network by pinging it and opening a telnet session. (Please also test, when it's happening, during both services are on the same host? Or only if they are on different hosts?) If all this works and you still get the time outs, please consider to open an issue on GitHub and provide all these information. Also feel free to try to reproduce it on an external setup, like Digital Ocean with their docker 1-click-App
[2017-06-04 16:13:06] <gdeverlant> I wanted to know if which kernel module are mandatory for the overlay networks ?
[2017-06-04 16:13:21] <gdeverlant> because CONFIG_IPVLAN  is missing I'm using kernel 3.10
[2017-06-04 16:15:49] <gdeverlant> I filled a ticket for HypriotOS [<-ISSUE->] 
[2017-06-04 18:48:33] <gdeverlant> SISheogorath: what do you think ?
[2017-06-04 18:54:48] <yuriy-yarosh> o/Just wanted to get some feedback and recommendationshttps://medium.com/@void.nugget/to-orm-or-not-to-orm-is-there-a-life-without-it-17f018960f6aThank you.
[2017-06-04 21:45:46] <SISheogorath> gdeverlant: can't say much about it. maybe it's a but, maybe it's a problem of your setup. I stay away from the arm hell so maybe it's a problem of your kernel.
[2017-06-04 21:46:25] <gdeverlant> it is actually a ipvlan module missing in the kernel
[2017-06-04 21:46:36] <gdeverlant> It took me 3 days to have my euroka Moment
[2017-06-04 21:47:29] <gdeverlant> SISheogorath: there is no ARM hell brother when you know how to handle it or talk to the right guys :D
[2017-06-05 09:58:00] <santosh2812> @carlosjgp Hi, have checked that link but its some thing related to the network configuration. but What I am trying to do is by using sentinel Announce IP to make that sentinel available to the out net work so That I can connect it from the code or local machine. I have made changes in the Docker file which expose the master and also made the slave for that IP but its not working -master:  image: redis:3  ports: [<-CODE->] slave:  image: redis:3  command: redis-server --slaveof 192.168.80.169 6379  links: [<-CODE->] sentinel:  build: sentinel  environment: [<-CODE->] links: [<-CODE->] ---------------- Sentinel file----------------------------protected-mode noport 26379dir /tmpsentinel monitor mymaster  192.168.80.169 6379 $SENTINEL_QUORUMsentinel down-after-milliseconds mymaster $SENTINEL_DOWN_AFTERsentinel parallel-syncs mymaster 1sentinel failover-timeout mymaster $SENTINEL_FAILOVERsentinel announce-ip 192.168.80.169sentinel announce-port $PORT0please have a look.apat from this I Have few more Question related to redis sentinel configuration1.How to expose the port 26379 by using sentinel announce-ip (my system Ip) to connect from out side.2.As we will get the master Information from The sentinels - which one, I have 3.3.Do we need to wright the logic to connect with the master in our application (MVC C#) to connect with the Details got form the point no 2. or How.Do we need to expose the Slaves also. How?
[2017-06-05 11:26:42] <SISheogorath> gdeverlant: the ARM hell exists. It's not because ARM is bad in any way, but because everything has to be cross compiled etc, simply because most free hosted CI solutions don't provide ARM. Also you have multiple versions of ARM, etc.. That's the ARM hell :D it's not easily possible to provide your software for all these platforms. Not to talk from the problems with docker images for these platforms.
[2017-06-05 11:30:07] <gdeverlant> not if your software is written in go
[2017-06-05 11:30:17] <gdeverlant> most of the software I'm using are written in go
[2017-06-05 11:36:17] <SISheogorath> Most software I use is written in C++ and C >.> and rewrite them in golang is not really an option
[2017-06-05 12:13:58] <gdeverlant> yeah I think that one of the reason they created on level of abstraction higher with golang
[2017-06-05 12:14:13] <gdeverlant> they were fedup of the kind of problem you encounter
[2017-06-05 15:02:18] <aaronmcadam> What do people do when they're waiting fordocker build? Is there a game server? :D
[2017-06-05 15:30:58] <SISheogorath> aaronmcadam: playing [<-LINK->] :D
[2017-06-05 15:50:51] <aaronmcadam> ahha that's awesome@SISheogorath
[2017-06-05 16:54:53] <carlosjgp> santosh2812: I'm not an expert on how Redis / Redis-Sentinel works...the only bits I can help here are... [<-CODE->] 
[2017-06-05 16:57:38] <carlosjgp> And can replace (if you want... or is not working) [<-CODE->]  [<-CODE->] 
[2017-06-05 18:44:35] <mahenrique94> SISheogorath: thanks, for while I’m using database on host, I even tried starts it with docker but some bugs have been happened like take down app, so I'v back to host and everything work well.
[2017-06-05 19:11:58] <SISheogorath> mahenrique94: The most important thing as always is that it has to work for you :) And depending on your use-case it's maybe the best way :)
[2017-06-05 20:58:59] <basz> hi newbe question. I read I need to create images via an dockerfile. Since I need to push that image to docker hub and a copy command in the dockerfile (the example I found an example usingCOPY ./ /var/www/html/) doesn’t that mean everything in.is now publicly available? (my super duper secret source code…)
[2017-06-05 23:36:42] <SISheogorath> Yes
[2017-06-05 23:37:23] <SISheogorath> If you used a public repository it's public available
[2017-06-06 03:25:01] <4406arthur> Hi, I found the TTY  with my container indentatation in a messI can reproduce [<-CODE->] 
[2017-06-06 03:27:22] <4406arthur>  [<-LINK->] 
[2017-06-06 03:45:11] <hewen>  [<-CODE->] 
[2017-06-06 03:45:24] <hewen> terminal initialization
[2017-06-06 06:41:57] <nischay30> Hi,I want to know when i am providing
[2017-06-06 06:43:02] <nischay30> what is the difference b/w-v /your/home:/var/dataand -v /var/data
[2017-06-06 06:52:02] <SISheogorath> nischay30: -v /path/on/host:/path/in/containercreates a bind-mount to the local directory.
[2017-06-06 06:53:09] <SISheogorath> -v /path/in/containercreates a unnamed volume and mounts it to the specified path
[2017-06-06 06:55:00] <SISheogorath> 4406arthur: if it's in the current rc it's known
[2017-06-06 06:55:17] <nischay30> I am trying to run jenkins containervolumes: [<-CODE->] 
[2017-06-06 06:55:27] <nischay30> jenkins_1    | touch: cannot touch ‘/var/jenkins_home/copy_reference_file.log’: Permission deniedjenkins_1    | Can not write to /var/jenkins_home/copy_reference_file.log. Wrong volume permissions?dockerfile_jenkins_1 exited with code 1
[2017-06-06 06:55:32] <nischay30> and it shows this error
[2017-06-06 07:03:06] <SISheogorath> nischay30: yes, keep in mind that a bind-mount simply mounts the directory into the container. If your uid and gid inside the container don't have write permissions, it fails. Because it's a mess to take care about all these things it's recommended to use volumes
[2017-06-06 07:04:58] <nischay30> Then how to give permissions
[2017-06-06 07:06:48] <carlosjgp> nischay30: Easy answer?chmod -R 777 ~/Training/volumes/jenkinsGood practice is to use a custom user inside the container and the same user to run the contianer " [<-LINK->] "
[2017-06-06 09:56:55] <santosh2812> carlosjgp: Hi, the port configuration worked and iam able to get connected from local IP but got another problem unable to scale it as we need 4 Sentinel and 2 slave with 1 master.  unable to understand how to configure the redis Sentinel on Docker which can be accessed from code and can work in failover . if you have any link please send. as currently I have followed [<-LINK->] but unable to connect or configure it so that it can be connected from code (C#).
[2017-06-06 11:43:39] <basz> SISheogorath: thought so... how do you work around that? Minimal code and A package installer? Private repositories? Thx
[2017-06-06 11:50:57] <SISheogorath> @basz I work with open source projects, so this is not the biggest problem.Simple advice: Put only things into your image your want to publish. It'll change a bit with 17.06 with multi-staged builds
[2017-06-06 11:55:34] <carlosjgp> santosh2812: I'm sorry but I can't help here... I've never tried to manage Redis cluster :(
[2017-06-06 12:30:01] <nicosmaris> hi, is anyone using gitlab-ci?
[2017-06-06 13:18:03] <guptasaloni> hello,anyone knows about web servises,JSON response
[2017-06-06 13:18:09] <guptasaloni> plz reply soon
[2017-06-06 13:42:48] <nicosmaris> sorry if i am in the wrong room, but which is the right way to run docker commands in a shared gitlab runner?The below .gitlab-ci.yml is not recommended according to [<-LINK->] image: docker:latestvariables:DOCKER_DRIVER: overlayDOCKER_HOST: tcp://docker:2375services:docker:dindtest_job:stage: testscript:docker info
[2017-06-07 01:06:04] <ebetica> Does anyone know if you can build an image in docker and run it with nvidia-docker?
[2017-06-07 06:22:44] <nischay30> hi.i am inside jenkins container and i want to know how i can work TABS inside the docker container
[2017-06-07 07:03:40] <santosh2812> Hi All, How can i create machine in docker and install redis Sentinel on it.
[2017-06-07 07:27:08] <pjetr> hi@santosh2812, what have you tried so far?
[2017-06-07 07:30:24] <pjetr> because, there's an image for that
[2017-06-07 07:30:25] <pjetr>  [<-LINK->] 
[2017-06-07 07:30:50] <pjetr> so you could simply use that, or check out the sourcecode on the github repo
[2017-06-07 07:31:00] <pjetr> and find out how it works there
[2017-06-07 07:36:53] <santosh2812> pjetr: Hi, actually i have followed lots of tutorial but unable to do the configuration with port forwarding so that it can be connect from outt side and from code. have also posted some query above, if possible please have allok.
[2017-06-07 07:38:23] <pjetr> I had to look what redis sentinel is, since I have never used it, and I am a complete docker beginner :D
[2017-06-07 07:39:14] <pjetr> So I'm affraid I won't be able to help you any further than finding that image (that has 10k+ downloads)
[2017-06-07 07:40:35] <pjetr> https://github.com/s7anley/redis-sentinel-docker/blob/master/Dockerfile-3.0\nhttps://github.com/s7anley/redis-sentinel-docker/blob/master/docker-entrypoint.sh
[2017-06-07 07:41:27] <pjetr> Running sentinel with network setting bridge will break Sentinel's auto-discovery, unless you instruct Docker to map the port 1:1. To force Sentinel to announce a specific IP (e.g. your host machine) and mapped port, you should use ANNOUNCE_IP and ANNOUNCE_PORT environment variables. For more information see documentation.
[2017-06-07 07:41:45] <pjetr>  [<-LINK->] 
[2017-06-07 07:42:07] <pjetr> I hope one of those links can provide you some insights :)
[2017-06-07 07:57:17] <santosh2812> pjetr: , Thanks for your reply, but have checked all the links problem is am not able to use this in proper way and the tutorials are only giving that much information that use ANNOUNCE_IP for port forwarding.  as I am also new to docker and Redis.  Any way thanks.
[2017-06-07 20:46:05] <c3s4r> Hi. quick question. What are the bind propagation modes available, that I can use when configuring a bind volume? (can't find anything in the documentation: [<-LINK->] )
[2017-06-08 03:35:18] <crapthings> hello i want to access docker mongo with remote machine
[2017-06-08 03:35:51] <crapthings> i already do flush iptables  and   make mongo bindip to 0.0.0.0
[2017-06-08 03:36:00] <crapthings> 036c6ed4724a        mongo                                          "/entrypoint.sh mongo"   12 months ago       Up 7 minutes                        127.0.0.1:27017->27017/tcp                 mongodb
[2017-06-08 03:36:36] <crapthings> how do i run docker mongo on  0.0.0.0 to allow all connections
[2017-06-08 05:46:02] <vinay-joshi> How can I map volume to nginx to windows directory using docker file.
[2017-06-08 08:57:00] <Iamguy84> Hi folks, I am getting error and it says:
[2017-06-08 09:03:13] <russellriotly> Hi folks, do you know if docker container has limit in high traffic?
[2017-06-08 09:20:23] <koolay> Why I can not access the expose port of the another container  In a container ? But, I can access the expose port on the host.
[2017-06-08 09:20:59] <koolay> ``
[2017-06-08 09:22:17] <koolay> This is my docker info.[xxxxx]# docker info\nContainers: 11\n Running: 9\n Paused: 0\n Stopped: 2\nImages: 20\nServer Version: 17.03.1-ce\nStorage Driver: overlay\n Backing Filesystem: xfs\n Supports d_type: true\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins: \n Volume: local\n Network: bridge host macvlan null overlay\nSwarm: inactive\nRuntimes: runc\nDefault Runtime: runc\nInit Binary: docker-init\ncontainerd version: 4ab9917febca54791c5f071a9d1f404867857fcc\nrunc version: 54296cf40ad8143b62dbcaa1d90e520a2136ddfe\ninit version: 949e6fa\nSecurity Options:\n seccomp\n  Profile: default\nKernel Version: 3.10.0-514.el7.x86_64\nOperating System: CentOS Linux 7 (Core)\nOSType: linux\nArchitecture: x86_64\nCPUs: 4\nTotal Memory: 3.702 GiB\nName: test48s6\nID: DJDK:FVAF:3M75:3246:RLGE:WWFU:IPAB:LBWJ:6PTP:NSVX:ZWPG:HCMK\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): false\nRegistry: https://index.docker.io/v1/\nWARNING: bridge-nf-call-iptables is disabled\nWARNING: bridge-nf-call-ip6tables is disabled\nExperimental: false\nInsecure Registries:\n 127.0.0.0/8\nLive Restore Enabled: false
[2017-06-08 09:23:32] <russellriotly> i guess your two container is in diff network?
[2017-06-08 09:24:51] <carlosjgp> koolay: because the containers run in different namespaces, so they are like different networks
[2017-06-08 09:24:55] <koolay> It 's the default brige mode.
[2017-06-08 09:26:23] <carlosjgp> usedocker run --link="your-container-name"... [<-LINK->] 
[2017-06-08 09:26:51] <koolay> "Networks": {\n                "bridge": {\n                    "IPAMConfig": null,\n                    "Links": null,\n                    "Aliases": null,\n                    "NetworkID": "35ba642f2243a3998fed8025be0fead937a94df3676e0b6d5ba61185704a6a63",\n                    "EndpointID": "0b33e53aea21e411318e9263513c74cf8d8dab23b16d56a22e9ed25d10736924",\n                    "Gateway": "172.17.0.1",\n                    "IPAddress": "172.17.0.7",\n                    "IPPrefixLen": 16,\n                    "IPv6Gateway": "",\n                    "GlobalIPv6Address": "",\n                    "GlobalIPv6PrefixLen": 0,\n                    "MacAddress": "02:42:ac:11:00:07"\n                },\n                "drone": {\n                    "IPAMConfig": {},\n                    "Links": null,\n                    "Aliases": [\n                        "d707fa183176"\n                    ],\n                    "NetworkID": "c8af522c1106ba33ef9b47278756995a62457c2b258a0a5985d565a464e68b46",\n                    "EndpointID": "9636980245eb450cccbb66408f1c271e74c909e8772c10883ab3c6a74299ac9a",\n                    "Gateway": "172.23.0.1",\n                    "IPAddress": "172.23.0.2",\n                    "IPPrefixLen": 16,\n                    "IPv6Gateway": "",\n                    "GlobalIPv6Address": "",\n                    "GlobalIPv6PrefixLen": 0,\n                    "MacAddress": "02:42:ac:17:00:02"\n                }\n            }
[2017-06-08 09:28:52] <koolay> access with   the gateway ip + expose port,  not need link the containers ?
[2017-06-08 09:29:06] <russellriotly> Any one know what is the shutdown policy/condition for docker container?
[2017-06-08 09:29:07] <koolay> access with   the gateway ip + expose port,  not need link the containers ?
[2017-06-08 09:58:04] <SISheogorath> russellriotly: when the initial process dies, the Container stops. Means when you call something that forks into background and exist then, it won't work.
[2017-06-08 09:59:02] <koolay> $ docker run --name hello -p 9008:8000 -d crccheck/hello-world  \n  $ docker run --name hello2 -p 9007:8000 -d crccheck/hello-world  \n  $ docker exec -it hello2 ash  \n  $(hello2)   wget http://172.17.0.1:9008 \n  wget: can't connect to remote host (172.17.0.1): No route to hostIn host, it work well.$ curl http://172.17.0.1:9008
[2017-06-08 10:00:11] <SISheogorath> koolay: check your default gateway inside docker.ip r s
[2017-06-08 10:01:12] <koolay>  [<-CODE->] In host, it work well. [<-CODE->] 
[2017-06-08 10:02:23] <russellwmy> SISheogorath: this is my person account, I notice that,  the docker container, which running Celery Worker (Python) will auto shutdown, and the worst case i met is docker create new container, it is running 3/2 in docker swarm.BTW I am running docker swarm...
[2017-06-08 10:03:36] <koolay> SISheogorath:  [<-CODE->] 
[2017-06-08 10:07:58] <koolay>  [<-CODE->] 
[2017-06-08 13:14:08] <kndt> hi all I have a docker container running on google container engine I was wondering how I connect it a cloudsql
[2017-06-08 17:44:14] <italomaia> How the docker team decides which issues should be worked on?
[2017-06-09 01:17:00] <SISheogorath> arc512: how would you do it without docker? It's the same setup just completely automated and without secrets in the image :) no magic involved ^^
[2017-06-09 01:17:55] <SISheogorath> russellwmy: docker swarm or docker-engine in swarm-mode?
[2017-06-09 01:52:58] <SISheogorath> koolay: that's really strange
[2017-06-09 07:26:34] <oversize> Hey, i have an nginx running on my OS X (not in a container). Then i have a container that wants to access that port (running in bridged network). i am not able to connect to that port. I am confused which interface (ip address?) would be the correct one to use. The DOCKER_HOST_IP from within the container (The one in the routing table)? or one of the local osx addresses (e.g.  the one en5 is assigned). Both dont let me connect. Which oneshouldbe the correct?I can access that port (on OS X) from within the container if using  host network mode though.  Using docker 17.03
[2017-06-09 11:08:35] <carlosjgp> koolay: if(hello2)  ping 172.17.0.1works that means that they are in the same namespace. But you are trying to hit the container IP using your host port (9008)try:wget http://172.17.0.1:8000which is the port the container is using inside the "docker" network where both containers are running
[2017-06-09 13:56:25] <roychri> Hello, I have broken my docker installation. Or at least, an image. My disk space usage kept going to 100%, I kept deleting all unused images and containers using the various tricks I found on the net, but/var/lib/docker/aufs/diffkept growing nontheless. I deleted a few folders in there that were linked to the trials and errors of a docker image part of a docker-compose I am working on. Yesterday, I rebuilt the same image over and over to try to fix a problem, and every once in a while I had to do a cleanup, but I reached a point where I realized that even when I was deleting all the unused containers and images (docker ps -a,docker imagesanddocker-compose psshows very little after cleanup), the disk usage kept growing and I couldn't built anymore without having to cleanup after each single one! Now when I try to rebuild my image, I get [<-CODE->] 
[2017-06-09 16:31:16] <SISheogorath> roychri: checkdocker images -ato not leave the detla images there
[2017-06-09 16:33:12] <SISheogorath> And maybedocker system dfanddocker system prune -ais what you search
[2017-06-09 20:29:12] <ravi3095> Hi,can you please provide me the standards based content on deploying, operationalizing, and supporting a Ruby and Rails framework implementation. From data components, mvc, to web services. I am looking for narrative on how to do this and have this in a docker container. Looking for high level narrative on Ruby and Rails and best approaches. Also include examples from previous work experiences on how to leverage cache for example. can any one help me on this
[2017-06-09 22:12:40] <roychri> SISheogorath: Thanks!
[2017-06-09 23:02:25] <mcpengelly> Hey guys, i deployed a website using docker and for some reason it requires i put the port name in the url to reach the page
[2017-06-09 23:02:28] <mcpengelly> even in production :/
[2017-06-09 23:03:34] <mcpengelly> mattpengelly.com:8080 is reachable but without the port its not. I cant figure out why this happens
[2017-06-09 23:07:25] <SISheogorath> Because it's a non-default port. Use a Reverse-Proxy to proxy your content over 80 and 443. Checkout Traefik
[2017-06-09 23:09:44] <mcpengelly> thanks :_
[2017-06-09 23:09:45] <mcpengelly> :)
[2017-06-09 23:10:50] <SISheogorath> See [<-LINK->] 
[2017-06-09 23:30:46] <mcpengelly> hey@Sheogorath, i didnt end up using a reverse proxy but your tip helped me fix what i was doing wrong. Thanks a bunch!
[2017-06-10 07:57:03] <koolay> carlosjgp: I turn off the firewall of host, then it  worked now.
[2017-06-10 10:22:40] <scriptonist> Hey..i'm using docker python SDK . I have a question like, How do we pipe a file to a command inexec_runfunction
[2017-06-10 11:08:39] <SISheogorath> scriptonist: like usingcat file | docker exec ...?
[2017-06-10 11:09:10] <scriptonist> SISheogorath: Like thiscontainer.exec_run(['echo','5','>','python','test.py'])
[2017-06-10 11:10:09] <SISheogorath> Yes, I was asking what exactly you were referring to as pipe :D there are pipe function and pipes like in a shell
[2017-06-10 11:13:52] <scriptonist> i didn't know that. can u elaborate on that ?
[2017-06-10 11:17:03] <SISheogorath> A pipe function is a function that simply work on streams in general. Pipes like in a shell are a bit more specific. As they use std:in as stream input.
[2017-06-10 11:17:56] <scriptonist> i hope u understood my intention. How can i translate that to code ?
[2017-06-10 11:22:30] <SISheogorath> Well, that's the point, I didn't so I asked  do you want to pipe your file into it like a shell pipe or more like a general pipe with a File object stream?
[2017-06-10 11:34:20] <scriptonist> all i want to do is pipe the contents of a file to a python script i want to run
[2017-06-10 11:34:25] <scriptonist> how can i do that ?
[2017-06-10 11:36:35] <scriptonist> i wanna mimic the following vanila linux commandecho "5" | python myscript.py
[2017-06-10 11:57:04] <SISheogorath> that what I wanted to know :) I'm not perfect with python, but as far there is currently no really nice way to do it. what you can try is to set the stdin parameter true and print your file contense to std:in of your own program. very hacky, a bit crazy, but currently the only way I see
[2017-06-10 11:57:49] <scriptonist> cool thanks   lemme try that
[2017-06-10 12:02:54] <SISheogorath> I think you should open an issue for that on github, maybe you get a more solide advice there or if it's still the only way, an future implementation of it :)
[2017-06-10 12:38:41] <karneaud> morning guys.....and girls(if any)
[2017-06-10 12:38:59] <karneaud> does anybody know if you can "merge" host and container volumes?
[2017-06-10 12:40:03] <karneaud> I have a project using a docker image whose volume already has contents.....I need to merge by project files with the contents yet still persist my contents in the container
[2017-06-10 12:40:23] <karneaud> is there any method of archiving this?
[2017-06-10 12:40:29] <karneaud> methods*
[2017-06-10 13:16:33] <karneaud> anyone?
[2017-06-10 13:16:40] <karneaud> somebody.....scccrreeaaammmm
[2017-06-10 13:16:43] <karneaud> ?
[2017-06-10 13:17:24] <Coffee2CodeNL> Mount the volumes, copy manually
[2017-06-10 13:21:04] <karneaud> so the volumes_from doesn't do that?
[2017-06-10 13:21:17] <karneaud> *doesn;t already do that?
[2017-06-10 13:33:10] <SISheogorath> no, volumes_from simply uses the same volumes at the same mount point as the referenced container
[2017-06-10 13:33:26] <SISheogorath> there is no "merge" function
[2017-06-10 13:35:00] <karneaud> hmmm
[2017-06-10 13:35:15] <karneaud> so there is no way to "keep" the original contents of a mounted directory?
[2017-06-10 13:35:54] <karneaud> I don't think copy is an option as I need to persist the contents of the host to the container
[2017-06-10 13:39:42] <Coffee2CodeNL> mount a folder, manually copy.
[2017-06-10 13:45:47] <karneaud> define "manually copy" as in when I make a change scp into container each time?
[2017-06-10 13:53:36] <SISheogorath> docker cp
[2017-06-10 13:54:17] <SISheogorath> or mount the host directory and the volume and have a script that copies things over
[2017-06-10 13:57:25] <karneaud> hhhhmmmm
[2017-06-10 13:57:29] <karneaud> ok will try that
[2017-06-10 20:50:30] <rossdargan> I'm a bit of a beginner with linux - could anyone help explain why I can't update my docker engine
[2017-06-10 20:51:29] <rossdargan> I've ran: sudo apt-get update which includes Hit:8 [<-LINK->] xenial InRelease
[2017-06-10 20:52:05] <rossdargan> Then i ran sudo apt-get upgrade which said there was nothing to upgrade
[2017-06-10 20:52:14] <rossdargan> docker --versionDocker version 17.03.1-ce, build c6d412e
[2017-06-10 20:54:02] <wenlock> Apt-get update is to update the local package management database for apt, not for upgrading packages .  You probably just need to apt-get install docker again if your updating to a newer version
[2017-06-10 20:55:16] <rossdargan> I thought it had to be called docker-ce
[2017-06-10 20:55:35] <wenlock> True
[2017-06-10 20:55:48] <rossdargan> ah lol well I have said apt-get install docker
[2017-06-10 20:56:10] <rossdargan> didn't help anyway
[2017-06-10 20:56:14] <rossdargan> :(
[2017-06-10 20:56:41] <rossdargan>  [<-CODE->] 
[2017-06-10 21:01:01] <mark_potter_twitter> the version its trying to install there is suuuuper old
[2017-06-10 21:01:18] <rossdargan> yeah I thought it would be.
[2017-06-10 21:01:20] <mark_potter_twitter> like 2014?
[2017-06-10 21:01:36] <rossdargan> I think the default "docker" one is isn\'t it?
[2017-06-10 21:01:52] <rossdargan>  [<-CODE->] 
[2017-06-10 21:02:36] <wenlock> Have you tried the get.docker.com script?
[2017-06-10 21:02:57] <rossdargan> nope
[2017-06-10 21:03:50] <wenlock> curl -sSL [<-LINK->] | sh
[2017-06-10 21:04:32] <rossdargan> If you already have Docker installed, this script can cause trouble, which iswhy we're displaying this warning and provide the opportunity to cancel theinstallation.
[2017-06-10 21:04:41] <rossdargan> hope it works ok :)
[2017-06-10 21:04:58] <wenlock> Yeah it might reset your images
[2017-06-10 21:05:16] <rossdargan> well, they are all managed through docker swarm/docker compose
[2017-06-10 21:05:22] <rossdargan> it'll be easily fixed thankfully
[2017-06-10 21:07:12] <rossdargan> Well... it's certainly doing something! Thanks :)
[2017-06-10 21:08:10] <wenlock> Yep that script is nice, they hide some hard stuff for first timers
[2017-06-10 21:09:03] <rossdargan> That appears to have worked! fab!
[2017-06-10 21:09:11] <wenlock> Nice
[2017-06-10 21:09:43] <rossdargan> And now portainer works :)
[2017-06-10 21:09:45] <rossdargan> fab.
[2017-06-10 21:16:34] <rossdargan> Does docker swarm ever rebalance nodes?
[2017-06-10 21:17:01] <rossdargan> sorry, not nodes services
[2017-06-10 21:18:03] <rossdargan> I know I can run docker service updateservice--force
[2017-06-10 21:18:13] <rossdargan> is there anyway to do it across all services
[2017-06-10 21:40:19] <rossdargan> never mind it did it itself :)
[2017-06-11 04:56:22] <h3ct0rjs> Hi,
[2017-06-12 02:20:50] <fluffywar> how to modify registry.indexServerAddressfor example :if  docker pull myUbuntuthen  docker pull index.docker.io/library/myUbuntu:latest#i want  docker pull myUbuntuthendocker pull 192.168.1.107:5000/myUbuntu:latest
[2017-06-12 02:24:05] <fluffywar> how to disable the markdown
[2017-06-12 02:51:58] <russellwmy> SISheogorath: docker swarm
[2017-06-12 02:55:50] <russellwmy> SISheogorath: in docker swarm mode,  when one node overloaded, the docker create new container, but it cant terminate the old container. in my case, I am using celery with 30 threads and at the end 60 threads are running, so the server freeze.....
[2017-06-12 03:42:32] <foreversunyao_twitter> hello, I have a question, does anyone use Flocker for Persistent Storage ? for example, for mysql ?
[2017-06-12 13:26:52] <rossdargan> I have a reasonable server that I use to host 3 vms all running docker (docker1->3).I have a small media pc that runs docker4.All are configured for docker swarm.Naively I set up all as swarm managers, but I've realized that if I reboot my main server docker4 just gives up because of (N/2)+1.I'm now planning on demoting 2 of the vm's swarms to just workers, and adding in a cheap raspberry pi to act as a manager.This should leave me with 3 managers. Will this allow me to restart my server without issue?
[2017-06-12 14:00:45] <SISheogorath> yes, this should work@rossdargan
[2017-06-12 14:12:46] <jdgiotta> Where can I get help with the docker go sdk?
[2017-06-12 14:29:13] <rossdargan> SISheogorath: fab - ta!
[2017-06-12 15:44:54] <shuntera> I’m not following the previous conversation, I  have Version:      17.04.0-ce on my Raspberry Pi’s and I installed them using the curl -sSL https://get.docker.com | sh command.How should I now upgrade docker from this point on?
[2017-06-12 15:45:20] <rightisleft> does docker-compose support mounting of incremental build numbers?
[2017-06-12 15:45:28] <rightisleft>  [<-CODE->] 
[2017-06-12 15:45:47] <rightisleft> IE: where 0.0.1 increments - how would i tell docker-compose to only mount the latest jar?
[2017-06-12 16:43:52] <SISheogorath> not really. You have to overwrite the file
[2017-06-12 16:44:34] <SISheogorath> shuntera: you can use the same script or useapt-get update && apt-get upgradeas usual
[2017-06-12 16:45:17] <SISheogorath> rightisleft: you can maybe use an environment variable if you want. But that doesn't make the things easier
[2017-06-12 16:45:46] <shuntera> SISheogorath: Do you know what the current version of Docker is for the Pi?
[2017-06-12 16:46:39] <SISheogorath> shuntera: I'm not user of the ARM builds, but in general it should be 17.03 for stable builds and 17.05 for edge builds
[2017-06-12 16:47:38] <SISheogorath> But there was a discussion about it all this recently in the ARM channel in the docker community Slack, so I'm not completely sure
[2017-06-12 16:48:03] <rightisleft> i modified the build script to symlink an artifact
[2017-06-12 16:48:19] <rightisleft> server-XXX -> app.jar which then gets mounted as a volume
[2017-06-12 16:49:09] <SISheogorath> not really sure a symlink works. Because you'll probably only mount the symlink :D
[2017-06-12 17:17:44] <shuntera> @SISheogorath OK, I did the upgrade on my Pi’s and I am now showing:Client: Version:      17.05.0-ce API version:  1.29 Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:30:54 2017 OS/Arch:      linux/arm
[2017-06-12 17:29:16] <jdgiotta> Is the #docker IRC channel dead?
[2017-06-12 17:34:15] <SISheogorath> I'm not sure about that. In general nearly all community related things switched to the docker community Slack
[2017-06-12 17:34:32] <SISheogorath> check [<-LINK->] to join
[2017-06-12 17:35:38] <jdgiotta> I'll take a look, thanks
[2017-06-12 17:37:52] <jdgiotta> SISheogorath: is community a good resource for asking SDK questions?
[2017-06-12 17:39:44] <SISheogorath> I would say yes, there are a lot of people and channels for all kind of topics. If you want to find an answer, that's a good place to start
[2017-06-12 20:22:10] <rossdargan> I have a docker container running on a swarm. It needs access to a device however so I can't create it as a service
[2017-06-12 20:22:21] <rossdargan> Can I still join it to a overlay network?
[2017-06-12 20:24:09] <rossdargan> ok, not sure if it is possible or not, but since the container is part of the host network it is not possible
[2017-06-12 20:48:26] <rossdargan> can anyone tell me whats going on with this service:ross@dar-docker-01:~$ docker service ps plexpyID                  NAME                IMAGE                 NODE                DESIRED STATE       CURRENT STATE             ERROR                              PORTSmdaibk18i4y2        plexpy.1            flxel/plexpy:latest   dar-docker-01       Shutdown            Shutdown 19 minutes agovtp13tj0lo5a         _ plexpy.1        flxel/plexpy:latest                       Shutdown            Pending 20 minutes agoj52k94fcdfof         _ plexpy.1        flxel/plexpy:latest                       Shutdown            Pending 20 minutes agomxzapzl8o365         _ plexpy.1        flxel/plexpy:latest   dar-docker-04       Shutdown            Shutdown 10 hours agoj1ps64ndrrui         _ plexpy.1        flxel/plexpy:latest   dar-docker-03       Shutdown            Failed 2 days ago         "starting container failed: Ad…"
[2017-06-12 20:48:38] <rossdargan> it's just stuck pending I think
[2017-06-12 20:51:37] <sameetn> rossdargan: have you tried putting in on both networks? It may not be possible, but I do recall the ability to specify multiple networks
[2017-06-12 20:52:04] <rossdargan> sameetn: I think because it\'s on the "host" network it deff can\'t
[2017-06-12 20:53:02] <rossdargan> hmm I had to run docker service update plexpy --force to get it running eventually
[2017-06-12 20:53:16] <rossdargan> I don't understand why the scheduler didn't sort it.
[2017-06-13 02:18:34] <Jehanramadhan> Hello
[2017-06-13 02:18:38] <Jehanramadhan> i want to ask something
[2017-06-13 02:19:04] <Jehanramadhan> i run a command like docker stop, docker exec, etc. but, i got this error :
[2017-06-13 02:19:44] <Jehanramadhan> for docker exec :rpc error: code = 2 desc = oci runtime error: exec failed: container_linux.go:1153: sending signal 0 to pid 27592 caused "permission denied"for docker stop :Error response from daemon: Cannot stop container hawk-au: Cannot kill container 6f8594082747d854b009c5d33f00f67bec4f43af95179556d659e7de1208c308: rpc error: code = 7 desc = permission denied
[2017-06-13 12:01:06] <sandys> hi guys - i have a full docker swarm stack running. i made some changes in a single service in the docker-compose.yml . do i have to do a full stack deploy .... or can i just update that service ? the problem is that docker service update does not pick up the new changes from compose file
[2017-06-13 13:56:20] <vroomanj> Does anyone know of a way I can simulate filling a container json log to test if my rotation is working? A command I can run in the container perhaps?
[2017-06-13 14:24:45] <SISheogorath> vroomanj: while true; do sleep 1; echo test; done?
[2017-06-13 14:30:47] <SISheogorath> should look like this:docker run alpine -c 'while true; do sleep 1; echo test; done'
[2017-06-13 14:31:48] <vroomanj> SISheogorath: Ahhh I guess that makes more sense. Was trying to do it within my Jupyter Notebook container :P doesn't matter what type of container I do it in though I guess. Thank you much.
[2017-06-13 14:33:09] <SISheogorath> you're welcome, just make sure you pass it to the shell interpret inside the container
[2017-06-13 14:54:17] <vroomanj> SISheogorath: Worked! Appreciate the help :)
[2017-06-13 15:12:43] <rightisleft> Hello - im having trouble mounting files into an nginx conteiner. My compose entry has the following [<-CODE->] docker inspect po-explorer [<-CODE->] 
[2017-06-13 15:13:05] <rightisleft> when i exec sh into po-explorer the /usr/share/nginx/html is empty
[2017-06-13 15:18:21] <rightisleft> Posted here: [<-LINK->] 
[2017-06-13 15:30:46] <SISheogorath> what OS are you using@rightisleft
[2017-06-13 15:31:28] <SISheogorath> Something RH based?
[2017-06-13 15:34:22] <rightisleft> OS X - i think it might be a problem upstream with the ENV var
[2017-06-13 15:37:16] <SISheogorath> mhm okay, can't really help there :/ Docker for Mac as well as Docker for Windows are weird things :x
[2017-06-13 16:26:14] <MonXBZH> Hey  everybody! o/
[2017-06-13 16:27:18] <MonXBZH> Anyone know how to fix disk space of a container? And, can we change the FS size when a container is already does ? Thx !
[2017-06-13 17:16:00] <dev-gbassanini> Hi all, I'm having an issue, I'm using postgres image and everytime I restart it, the  database is recreated and all the content from previous runs is lost. I'm using the docker-entrypoint-initdb.d and add a sql script that creates the DB and all it's objects
[2017-06-13 17:49:35] <SISheogorath> Did you mount a volume?
[2017-06-13 17:50:25] <SISheogorath> And did you setup your script to only create the structure if it doesn't exist and not drop tables or databases
[2017-06-14 08:56:40] <MariusDiacu_twitter> rightisleft: I also had this issue, I solved by mounting the entire directory. I don't think mounting a files works from host to container.
[2017-06-14 09:29:05] <NilsWild> docker doesnt work at all afer restart attempt with service docker restart can somebody help me? systemctl status docker.service:
[2017-06-14 09:33:20] <NilsWild>  [<-LINK->] 
[2017-06-14 11:42:24] <basz> hello, being newish to docker i set upon creating a rabbitmq container with docker-compose I have so many questions… Hope I good here… Am I correct in assuming its database is not preserved between restarts unless i map it to a local volume? Is providing an entrypoint in the docker-compose.yml preventing the entrypoint DockerFile entrypoint from the image from being run? And if, so how do would I add addional runtime configuration, such a user account etc.
[2017-06-14 11:43:41] <basz> This image [<-LINK->] seems to run allright, but I can’t seem to define ssl options as it (re)creates its own rabbitmq.config
[2017-06-14 11:49:13] <pjetr> Being a starter myself, I can't answer too much of your questions, except: [<-LINK->] 
[2017-06-14 11:49:45] <pjetr> Override the default entrypoint.I'd say this will indeed prevent the original entrypoint
[2017-06-14 11:50:41] <MariusDiacu_twitter> I have an app, akeneo, inside docker and seems that symlinks are not created when containers are created. Do you know how can I fix this? Host in Ubuntu
[2017-06-14 11:51:55] <pjetr> basz: you could take a stroll in the RabbitMQ source files, perhaps it could give you some insight
[2017-06-14 11:51:57] <pjetr>  [<-LINK->] 
[2017-06-14 11:52:44] <pjetr> And, I also found [<-LINK->] to be a good resource for help
[2017-06-14 12:05:40] <rossdargan> I\'m having issues with a docker service that stops, but has the state "complete". Should the scheduler not try and re-start it?!
[2017-06-14 12:06:05] <rossdargan> docker service ls shows it having 0/1 replicas
[2017-06-14 12:08:11] <basz> thanks@pjetr
[2017-06-14 12:08:46] <rossdargan> looks like I probably need to use the restart policy!
[2017-06-14 13:14:36] <basz> awesome I have setup rabbitmq from the official package with a ssl (self signed cert) and an additional plugin. Now I am trying this trick; [<-ISSUE->] but run intostarting container process caused "exec: \\"/wrapper-entrypoint.sh\\": permission denied”
[2017-06-14 13:15:54] <basz> have added thisRUN chmod +x /wrapper-entrypoint.shin DockerFile but it does not help...
[2017-06-14 13:20:02] <papaiatis> Guys, is there a command which I can list all the available images from a custom docker repo?
[2017-06-14 13:24:26] <YoannMa> papaiatis: Calling the API ?
[2017-06-14 13:56:31] <basz> i have renamed every occurance of \'wrapper-entrypoint.sh’ to ‘wrapperentrypoint.sh’ and when i now dodocker-compose up --force-recreate mqit still complains aboutexec: \\"/wrapper-entrypoint.sh \\": permission denied”. Even afterdocker-compose rm mq`. What’s happening here?
[2017-06-14 16:11:17] <miojamo> Hi, I have installed devilbox and configured everything  however I do not know how to edit virtualhost to target directory, currently it is targetting to htdocs
[2017-06-14 17:54:12] <jigneshkhokhani> Hello world, I am jignesh, Glad to join this room. 
[2017-06-14 17:55:59] <jigneshkhokhani> I am new in docker so please any one can suggest best video tutorial ?
[2017-06-14 17:56:33] <iglov> dockercon, i think
[2017-06-14 17:57:07] <iglov>  [<-LINK->] 
[2017-06-14 17:58:16] <sameetn> jigneshkhokhani: also take a look at [<-LINK->] 
[2017-06-14 17:58:25] <sameetn> this a great site for interactive tutorials
[2017-06-14 17:58:27] <jigneshkhokhani> Thank you@iglov
[2017-06-14 17:59:21] <jigneshkhokhani> I definitely go with this also@sameetn, Thank you 
[2017-06-14 18:00:49] <sameetn> wlc
[2017-06-14 23:17:40] <vroomanj> How might I deploy a service on a specific node? Specifically the manager node...
[2017-06-14 23:22:30] <vroomanj> Found it. Sorry.
[2017-06-15 04:39:52] <MaksimKiselev> Hi guys. How the best way to run commands in same container from any container?For example: I wanna cron container which will run commands.
[2017-06-15 08:35:55] <ersagun> Hi everyone, I'm using a new functionality, the multi stage builds and I need to mount a volume during build. There is a way to do it? Thank you for you helps
[2017-06-15 09:08:44] <SISheogorath> Ersagun, why you need that volume?
[2017-06-15 09:13:47] <SISheogorath> MKiselev: cron is a bit difficult. Maybe checkout the indiehoster setups, linked for example in the official nextcloud image
[2017-06-15 09:48:58] <sabrehagen> hi all, following this docker guide: [<-LINK->] i'm trying to create a registry, but it's not contactable despite running. any advice? [<-LINK->] 
[2017-06-15 10:55:18] <ersagun> Im using multi stage build functuonaltiy. I have 2 from in my docker file. On of them is a maven image, taking my src and build it. Second one do a copy --from and get the jar build in first one and execute this in second from. It's an entrypoint
[2017-06-15 10:56:21] <ersagun> I want to share the m2 of maven in a volume, instead of copying because it's very bog
[2017-06-15 10:56:27] <ersagun> Big*
[2017-06-15 11:34:55] <matrixbot> lanyangyangHow to get size of a image  in docker hub
[2017-06-16 08:40:43] <coding-yogi> Does docker build replace the existing image? My docker image is tagged with :latest tag
[2017-06-16 08:43:36] <coding-yogi> got the answer, it seems docker untags the previous image and tags the new one with tag :latest
[2017-06-16 14:16:31] <SISheogorath> Yes, image name + tag are unique. They automatically overwrite the old one
[2017-06-16 15:03:28] <sameetn> matrixbot: it shows in the UI next to the image itself.
[2017-06-16 15:19:30] <SISheogorath> ersagun: as far as I know, that currently not possible.
[2017-06-16 15:20:17] <sameetn> ersagun: the m2 is only needed during the build
[2017-06-16 15:20:21] <sameetn> so you could mount it
[2017-06-16 15:28:09] <prasenjithaty> Hi all
[2017-06-16 15:29:22] <prasenjithaty> I’m trying to usefabric8/java-alpine-openjdk8-jreand bundling ffmpeg static build into the image
[2017-06-16 15:30:41] <prasenjithaty> but after I spin up my container and ssh into it, I cannot execute ffprobe on any video URL.
[2017-06-16 15:30:48] <prasenjithaty> Here is my Docker file
[2017-06-16 15:31:48] <prasenjithaty>  [<-CODE->] 
[2017-06-16 15:59:48] <prasenjithaty> what I realized, is that, ffprobe works if there is no redirection
[2017-06-16 21:54:04] <tknp96_twitter> has anyone had any luck with sharing usb tuners with plex running in a container?
[2017-06-17 22:49:17] <morpheyesh> hello, i have a basic question, I used to pass PortBindings when starting container, when using the docker API. Now I believe, its deprecated, you cannot pass hostConfig when starting container. So, I could set the port binding when creating a container?
[2017-06-17 22:49:30] <morpheyesh> and starting that would work,  i presume..
[2017-06-17 23:29:14] <Spittal>  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2017-06-18 00:48:39] <JasonShin> Hi guys
[2017-06-18 00:48:59] <JasonShin> How do you run multiple docker run (without -d) on a same ssh session?
[2017-06-18 00:49:14] <JasonShin> I have ability to use split screen but it's not tmux
[2017-06-18 00:49:42] <JasonShin> so as soon as I do anotherdocker run blah, previousdocker rungets terminated
[2017-06-18 08:13:47] <SISheogorath> JasonShin: docker is no magical tool. It still follows the rules of a normal terminal application. If you don't want to use-dyou can use&sign.
[2017-06-18 08:14:04] <SISheogorath> But I wouldn't recommend that
[2017-06-18 14:25:24] <todoacien> Hi@all.. any good tutorial/primer for a newbie in Docker as me.? :)
[2017-06-18 14:27:20] <sameetn> katakoda.com
[2017-06-18 15:47:16] <Acidfabric>  [<-CODE->]  [<-CODE->] here is my cron file: [<-CODE->] 
[2017-06-18 15:53:07] <iglov> Acidfabric: try to write full path to ur php
[2017-06-18 15:54:07] <iglov> something like* * * * * root /usr/bin/php /var/www/html/modules/import/cron/pretendentas.php >> /var/log/cron.log 2>&1
[2017-06-18 16:07:12] <Acidfabric> no luck
[2017-06-18 16:07:16] <Acidfabric> cron_1      | /bin/sh: 1: /usr/bin/php: not found
[2017-06-18 16:13:01] <iglov> maybe cuz i told it just for example, and in ur image php found not in/usr/bin/php?
[2017-06-18 16:13:26] <iglov> /usr/local/bin/phpmaybe ?
[2017-06-18 16:20:50] <Acidfabric> I think that was the case. Thank you
[2017-06-18 18:20:56] <nagaraju02> Hello Friends, I am using two centos amchines on my VMWare work station and i was trying to connect one mechine to other but it shows me an error saying there is no route to host? can anyone help me solve this issue?
[2017-06-18 20:55:54] <SISheogorath> nagaraju02: what docker commands did you run? It basically sounds like a VMWare problem in your setup. Check the network isolation and that there is no firewall blocking connections before you try to run docker
[2017-06-18 20:56:15] <SISheogorath> Docker is not magic
[2017-06-18 22:59:46] <vroomanj> Has anyone used the NetApp nDVP plugin with Docker? I sense that it may not do what I wish it did :P looking for confirmation. Basically, I have a home volume on my NetApp which has home folders for all our users. I'd like to be able to have a Docker volume for each user's home directory (not create one, or copy it, just represent their folder as a Docker volume). I sense that the plugin only works at the volume level on the NetApp though.
[2017-06-19 01:49:28] <megamindbrian> SISheogorath: docker IS magic.
[2017-06-19 11:40:16] <karneaud> morning
[2017-06-19 11:40:17] <karneaud> or evening
[2017-06-19 11:40:22] <karneaud> depending on where you are
[2017-06-19 11:41:11] <karneaud> I keep getting the following error trying to install bower globally and run some commands via docker [<-LINK->] 
[2017-06-19 11:41:33] <karneaud> I\'m not sure how to setup the "user" roles so that this can be avoided can anyone help?
[2017-06-19 11:46:46] <karneaud> sigh
[2017-06-19 11:46:47] <karneaud> smh
[2017-06-19 12:40:47] <SISheogorath> karneaud: for development?
[2017-06-19 12:41:45] <SISheogorath> And can you please pastebin/gist the error message?
[2017-06-19 13:11:21] <andrewgy8> Anyone have an idea how to take postgres DBs that are local, contain them and then run a postgres container to fetch data?
[2017-06-19 13:11:52] <andrewgy8> I was looking at Data only containers, but someone said that was a dated solution.
[2017-06-19 13:15:00] <karneaud> SISheogorath: its ok....substituted bower for yarn and I'm good now
[2017-06-19 13:15:02] <karneaud> thanks
[2017-06-19 13:50:57] <mikeleg> Hi i have a problem with alpine:3.5 to install mysqlclient python library
[2017-06-19 15:04:46] <etsuo>  [<-CODE->] What I have are a bunch of low utilization servies that I’m “over subscribing” in this cluster… it’s a bunch of CI/CD stuff that’s really important… but has very few users… so I’d hate to have a cluster of 6 EC2 nodes for something that 2 can clearly handle… I just can’t seem to get the memory utilization any higher than 15% before I get errors like the one above.
[2017-06-19 17:35:04] <jbelmont> Hello AllI have the following docker-compose.yml [<-CODE->] and Dockerfile [<-CODE->]  [<-CODE->] 
[2017-06-19 17:35:44] <jbelmont> and I am trying to installmgowithgo getcommand
[2017-06-19 23:15:00] <dpnova> hey is this the best place to discuss compose?
[2017-06-19 23:15:13] <dpnova> I'm finding some very odd behaviour with relative paths
[2017-06-19 23:15:42] <dpnova> what docker-compose config tells me isn't what it's trying to use when building images
[2017-06-20 00:24:31] <SISheogorath> jbelmont: This can't work. You can use multiple from for multi-staged builds, but you are still limited to oneFROMper image in general. So at the end of the day you can use golang as base image OR mhart/alpine-node. If you need go inside your container use the node base image and install go. Or use the go base image and install node. It mainly depends on when you need what. I personally recommend to use the base image for the environment you want to use in runtime, not during build. But that's more a personal opinion
[2017-06-20 00:25:45] <SISheogorath> dpnova: the best place is the channel #docker-compose in the [<-LINK->] 
[2017-06-20 00:26:07] <dpnova> thanks@SISheogorath
[2017-06-20 00:26:35] <SISheogorath> But you can may share your errors and problems ^^
[2017-06-20 00:26:39] <SISheogorath> maybe I can help
[2017-06-20 00:29:21] <dpnova> SISheogorath: basically i have two compose files foo/1/docker-compose.yml and foo/2/3/docker-compose.yml
[2017-06-20 00:30:12] <dpnova> when i try and rundocker-compose -f foo/1/docker-compose.ym -f  foo/2/3/docker-compose.ymlsomething weird is happening with the build context location
[2017-06-20 00:30:37] <dpnova> my dockerfile isfoo/docker/Dockerfile.base
[2017-06-20 00:31:48] <dpnova> the build context doesn't seem to be repsected
[2017-06-20 00:32:08] <dpnova> docker-compose config is showing something that isn't the same as what the docker daemon is trying to use
[2017-06-20 00:37:29] <dpnova>  [<-LINK->] 
[2017-06-20 00:37:41] <dpnova> this paragraph in the docs is incorrect
[2017-06-20 00:38:01] <dpnova> docker-compose config shows the relative path extended to be relative to where docker-compose is run
[2017-06-20 00:38:14] <dpnova> but the docker daemon gets the path relative to where the compose file is i think
[2017-06-20 00:38:56] <dpnova> so i think the bug is in docker-compose config
[2017-06-20 00:39:57] <dpnova> following from that, trying to use docker-compose with files at different nesting levels in a project doesn't work as  it interprets the relative context path once for all services even though the compose files are in different places
[2017-06-20 00:42:48] <dpnova> just ran with --verbose and confirmed the wrong path is being sent to the docker daemon
[2017-06-20 00:56:58] <dpnova> actually this is documented here: [<-LINK->] paragram above this section
[2017-06-20 00:57:00] <dpnova> that's annoying
[2017-06-20 01:15:20] <jbelmont> SISheogorath: great thanks that makes sense
[2017-06-20 01:16:09] <SISheogorath> dpnova: looks like a known problem: [<-ISSUE->] 
[2017-06-20 01:16:33] <SISheogorath> But I agree that it is annoying
[2017-06-20 01:17:37] <SISheogorath> On the other hand it's a way to overwrite configs. So it makes sense to use the relative path from the first docker-compose file. Not really perfect, I am with you, but it still makes sense
[2017-06-20 01:17:53] <jbelmont> docker-compose.yml [<-CODE->] docker-compose.yml [<-CODE->] 
[2017-06-20 01:17:55] <SISheogorath> jbelmont: You're wekcome
[2017-06-20 01:18:01] <jbelmont> does this seem right@SISheogorath
[2017-06-20 01:19:02] <SISheogorath> jbelmont: no, not really, because now you'll build your image and name itgolang:1.8.3-alpinewhich is not really what you want
[2017-06-20 01:19:34] <jbelmont> oh yeah I forgot about that part
[2017-06-20 01:19:55] <SISheogorath> by the way, yourLABELlooks broken
[2017-06-20 01:21:49] <jbelmont> it should be like this rightLABEL maintainer "SvenDowideit@home.org.au”
[2017-06-20 01:26:30] <jbelmont> great thanks for all the help@SISheogorathyou got me up and running 
[2017-06-20 01:44:11] <watzon> Is anyone here using Rancher currently?
[2017-06-20 01:48:54] <dpnova> Sheogorath: i worked around it by having an empty compose file in the root of the project so all relative paths are anchored from that. I'll just force other devs to make sure it's included on the command line (actually I'll just create some wrappers)
[2017-06-20 01:51:30] <dpnova> I've added a comment on that issue for people looking for a workaround.
[2017-06-20 01:51:36] <dpnova> thanks for the link!
[2017-06-20 02:05:38] <SISheogorath> You're welcome :)
[2017-06-20 02:15:01] <watzon> What is the best way to handle persistency in Docker? I've been trying to find a container that I can mount volumes on, but I'm not having much luck
[2017-06-20 07:43:25] <andrewgy8> Hey all, im having trouble understanding data volumes and mounting them. The concept alone kind of throws me for a loop.  Anybody have suggestions on how to think about them?
[2017-06-20 07:45:25] <andrewgy8> Particularly, im trying to mount multiple postgres db in one and then access it via the postgres container.
[2017-06-20 07:51:48] <SISheogorath> andrewgy8: you know how mount points in Linux work?
[2017-06-20 07:57:01] <andrewgy8> Im just reading about them now. I suppose its a similar concept?
[2017-06-20 07:59:09] <andrewgy8> "the concept can become clearer if directories are instead visualized as nodes, i.e., as points, on a tree diagram of a filesystem from which other directories and files can branch off rather than as containers" from [<-LINK->] 
[2017-06-20 08:51:27] <SISheogorath> Docker (on linux) uses linux mount points :D
[2017-06-20 09:34:12] <andrewgy8> Thanks@SISheogorath!
[2017-06-20 11:38:38] <jbelmont> anybody here know how to resolve webpack-dev-server and docker issues
[2017-06-20 15:46:30] <moisesrodriguez> Hello, I’m having an issue where I’m dumbfounded. As far I understand the issue Docker solves is that once you have a setup containerized with Docker, no matter where you run it be it Linux, macOs, Windows, in AWS, etc. It should be the same and work the same because it’s the exact same setup. Well I have this setup described here [<-LINK->] . When I run Docker in Ubuntu 16.04  and Windows 10 with this setup it runs without any issues and works just fine. However when I run it on my Docker for Mac, I always get an error with one of my Node.js modules. I’ve tried many workarounds I’ve found online about that dependency, but no luck. But the main issue is why the exact same Docker setup works on Ubuntu and Windows, but not in Mac! Any help is appreciated.
[2017-06-20 15:47:00] <jbelmont> I have the following docker-compose.yml and Dockerfile [<-CODE->]  [<-CODE->] npm scripts [<-CODE->]  [<-CODE->] 
[2017-06-20 15:48:07] <jbelmont> sorry@moisesrodriguezdidn’t mean to post over you
[2017-06-20 15:51:58] <moisesrodriguez> jbelmont: no worries, looks like we were both writing at the same time
[2017-06-20 16:06:53] <jbelmont> moisesrodriguez: I added a comment to your gist, not sure if that will help though
[2017-06-20 16:11:24] <moisesrodriguez> jbelmont: question so instead of doingCOPY . /appyou are saying doADD . ${WORKDIR}?
[2017-06-20 16:11:39] <jbelmont> yes
[2017-06-20 16:11:53] <moisesrodriguez> will give it a try
[2017-06-20 16:40:29] <SISheogorath> You should avoidADDas it has some nice, but very special effects. In general: If you can do something withCOPYdon't useADD
[2017-06-20 16:43:34] <SISheogorath> moisesrodriguez: did you build it on macOS or did you download the image?
[2017-06-20 16:45:17] <SISheogorath> And in general there should have been and errormessage during build process
[2017-06-20 16:55:30] <matrixbot>  [<-CODE->]  [<-CODE->] Any obvious mistake?
[2017-06-20 17:12:03] <moisesrodriguez> SISheogorath: I built it on macOS.
[2017-06-20 17:14:49] <SISheogorath> Yves: you should avoid links. They are deprecated. Use the service names instead
[2017-06-20 17:15:15] <SISheogorath> moisesrodriguez: can you try to use an existing image just to verify that it's an issue during build time and not a general issue?
[2017-06-20 17:22:55] <matrixbot> YvesSheogorath (Gitter): I agree, although there won't be any scale up and I was trying to mimic the initial working setup before optimizing.
[2017-06-20 17:41:47] <moisesrodriguez> SISheogorath: I ended up completely uninstalling docker for mac and then installing it again and it worked. Go figure what was going on.
[2017-06-20 18:36:17] <Cmdv> Hi, how can I get a docker id from image name, I'm able to do it from names like:docker ps -q -f name=marklogicbut the problem my images are calledmarklogic+frontend_marklogic
[2017-06-20 18:36:38] <Cmdv> so that returns two values when all I want is themarklogicdocker id
[2017-06-20 19:28:23] <jbelmont> SISheogorath: you weren’t lying when you saidADDhas some side effects that was the main issue with my build problems
[2017-06-21 04:47:03] <crapthings> hello how do i run another instance of mongodb by using existing db ?
[2017-06-21 04:47:33] <crapthings>  [<-LINK->] 
[2017-06-21 04:48:20] <crapthings> i want to run a second docker mongo on 0.0.0.0:27019  and use the same db as 127.0.0.1:27017
[2017-06-21 04:48:23] <crapthings> what should i do
[2017-06-21 07:40:09] <JayZeeGP> good morning everyone. I'm starting to use docker in order to mount a machine and execute a script but I'd love to let the user introduce commands directly after my script ends so they can see the results of the scripts are built... but then the machine exits  when my script ends... i've been googling but i think im missing something about phylosophy here... could some1 help me?
[2017-06-21 08:19:50] <JinnaBalu> I have node application and need to run    npm install to install the packages, and gulp ev to run the application.
[2017-06-21 08:20:07] <JinnaBalu>  [<-CODE->] 
[2017-06-21 08:20:26] <JinnaBalu> To install packages.
[2017-06-21 08:20:49] <JinnaBalu>  [<-CODE->] 
[2017-06-21 08:21:26] <JinnaBalu> To run the app. I want to run this with docker file any inputs please
[2017-06-21 08:23:49] <JinnaBalu> App expects node, npm and gulp installed so that it runs
[2017-06-21 11:15:00] <SISheogorath> JinnaBalu: simply install everything you need. what's the problem?
[2017-06-21 11:15:54] <SISheogorath> JayZeeGP: you want them to write commands on start of your image or during build?
[2017-06-21 11:18:40] <SISheogorath> In general you can do this the same way as outside of docker. Addexec /bin/shfor example at the end of your shell script
[2017-06-21 11:20:04] <SISheogorath> Yves: it's not about scaling it's about general designs.linkshave some ugly side effects
[2017-06-21 11:20:57] <SISheogorath> crapthings: how would you do it outside of docker?
[2017-06-22 03:55:54] <matrixbot> YvesHow can I disable IPV6 in a docker-compose file version 3?
[2017-06-22 08:29:30] <SISheogorath> Yves:  [<-LINK->] setenable_ipv6tofalseshould work
[2017-06-22 08:55:37] <gdeverlant> greetings
[2017-06-22 08:56:15] <gdeverlant> I've just installed a fresh debian jessie distro with kernel 4.12-rc5 on my Odroid C2 arm64 board
[2017-06-22 08:56:32] <gdeverlant> I've installed docker from the debian package
[2017-06-22 08:56:40] <gdeverlant> and tried to run one simple command
[2017-06-22 08:56:41] <gdeverlant> debian@bambuserver12:~$ [<-CODE->] 
[2017-06-22 08:57:47] <gdeverlant> I don't understand why it's not executing
[2017-06-22 08:58:17] <gdeverlant> I've moved the /var/lib/docker folder to an external HD
[2017-06-22 09:03:13] <SISheogorath> gdeverlant: See [<-ISSUE->] 
[2017-06-22 09:03:33] <SISheogorath> could be a problem of your FS
[2017-06-22 09:06:15] <SISheogorath> Also: [<-LINK->] 
[2017-06-22 10:08:50] <gdeverlant> it's weird because I don't have any XFS as backing system
[2017-06-22 10:08:53] <gdeverlant>  [<-CODE->] 
[2017-06-22 10:15:42] <gdeverlant> This is my daemon.log from docker
[2017-06-22 10:15:45] <gdeverlant>  [<-CODE->] 
[2017-06-22 11:20:05] <jeud> i have a very basic question, after running the container e.g.docker run -d -p 9999:80 httpdright now i only can use [<-LINK->] to access the homepage, how can i use [<-LINK->] to access the homepage (i have seen a youtube vdo that is able to do that) please guide thanks
[2017-06-22 11:26:11] <Clausewitz45_twitter> jeud: What is the platform where you try this?  OSX/Linux/Windows
[2017-06-22 11:26:36] <jeud> i'm using windows 10 (docker-machine)@Clausewitz45_twitter
[2017-06-22 11:27:51] <Clausewitz45_twitter> What is the result of this commandping localhostincmd.exe?
[2017-06-22 11:32:32] <jeud> Clausewitz45_twitter:  [<-LINK->] 
[2017-06-22 11:33:05] <jeud> i really though it was returning reply from 127.0.0.1
[2017-06-22 11:35:03] <Clausewitz45_twitter> jeud: HyperV or VirtualBox?
[2017-06-22 13:30:04] <jeud> Clausewitz45_twitter: , virtualbox
[2017-06-22 13:59:07] <JinnaBalu> How to create a docker image for nodejs application
[2017-06-22 16:31:28] <bitsofinfo> Is there any way to force the service vip assigned bydocker service create --network someoverlay...to be within a specific range within the overlay subnet? While also ensure that all containers within that service are only within a certain ip range on that same overlay subnet?
[2017-06-22 16:34:29] <bitsofinfo> I need to ensure that the service vip lets say is < .10, while containers would be assigned to > .10 etc
[2017-06-22 17:05:39] <iglov> requested: [<-LINK->] 
[2017-06-22 18:00:44] <ebetica> Is there a way to force docker to exit on SIGTERM instead of passing it to the child process? I'm working in an HPC cluster and we're experiencing zombie docker processes because SLURM will send a SIGKILL if SIGTERM doesn't end the process.
[2017-06-22 18:55:11] <SISheogorath> ebetica: Can you show us a repository you use for your docker setups? I guess you call your application the wrong way. In general you have to make sure that theSIGTERMis passed correctly. So try to useexecif you use an entrypoint script and don\'t call your application usingCMD /myapporENTRYPOINT /myappbecause that will create a subshell. useCMD ["/myapp"]orENTRYPOINT ["/myapp"]instead
[2017-06-22 19:51:41] <ebetica> SISheogorath: like I said, this is an HPC setup, so we\'re trying to allow the user to run arbitrary commands from the docker image. The CMD is [ "/bin/bash" ]
[2017-06-22 19:52:58] <ebetica> My issue is replicable like this: [<-CODE->] 
[2017-06-22 19:53:25] <ebetica> I don't think there's anyway around creating a subshell
[2017-06-22 19:58:46] <SISheogorath> okay, that's reasonable >.> you kill the docker daemon?
[2017-06-22 20:02:04] <ebetica> I have to do docker stop in this case, I want to avoid that somehow :(
[2017-06-22 20:03:35] <SISheogorath> why can't you use the init-script/system to do so?
[2017-06-22 20:03:46] <SISheogorath> something likesystemctl stop docker
[2017-06-22 20:05:07] <SISheogorath> But yes, in general you create zombies when you do this because you don't execute the command directly. But that's more a kernel thing than a real docker thing :/
[2017-06-22 20:12:32] <ebetica> this is supposed to be working with an HPC scheduler, so there may be other user's docker images running on the same host. I mean, I'm pretty happy even if docker intercepts the signal and kills the container it started with docker stop, but I don't think there's a way to get the docker container ID from the docker run process either
[2017-06-22 20:17:03] <SISheogorath> I can't say :/ sry
[2017-06-22 20:18:31] <SISheogorath> I don't know what you use and how it works in detail, so it's pretty difficult to say
[2017-06-22 20:22:48] <SISheogorath> You should maybe consider to use a more low-level way to solve this issue by not talking to dockerd. Instead check the way K8s uses to schedule tasks
[2017-06-23 09:06:04] <cebor> Hi there was a doc page about how docker handles default hostnames for named docker containers in a docker network. But i cant find it anymore. There was something special with-and_.
[2017-06-24 14:29:24] <cavapoo2_twitter> Anyone use the docker shell (mingw64) on windows with sbt (scala build tool). anyone get weird characters start of each line.
[2017-06-24 23:16:59] <italomaia> hello folks
[2017-06-24 23:17:08] <italomaia> quick question: which user is entrypoint invoked with?
[2017-06-24 23:17:15] <italomaia> root or the user defined by USER
[2017-06-24 23:26:06] <SISheogorath> USERand if not defined thanroot
[2017-06-24 23:26:16] <SISheogorath> or to be more correct: uid 0
[2017-06-25 12:23:27] <Chiefo> Hello, can the partition docker mounts to for its storage driver be changed? E.g., even though docker was installed to /var/lib/docker and contains directories like /var/lib/docker/aufs, for some reason it mounts to the root filesystem partition which I don't want. I had assumed it'd just naturally use whatever partition /var is on, but this isn't happening.
[2017-06-25 12:27:04] <Chiefo> It's annoying in that I discovered /var/lib/docker/aufs has at least 6gb and the root filesystem partition was originally intended to not have much space partitioned, it's filled up unnecessarily. I could not find a simple option anywhere that basically tells docker to stop auto-mounting away from /var/lib/docker, maybe I'm overlooking it.
[2017-06-25 13:16:01] <Chiefo> Solved, a silly mistake was made and assumptions blinded me to the answer until realization struck like a thunderbolt on a clear day.
[2017-06-25 14:04:09] <gdeverlant> hi peps
[2017-06-25 14:04:31] <gdeverlant> is it only me or you guys also experiencing slow download speed from github.com
[2017-06-25 14:04:38] <gdeverlant> I have 50 MB connection
[2017-06-25 14:04:46] <gdeverlant> and All downloads are 200 kb/s
[2017-06-26 09:31:42] <JayZeeGP> do you know a docker for oauth02 mock server? all the ones ive tried are not working for me
[2017-06-26 09:32:38] <JayZeeGP> thanks@SISheogorathfor your previous help. I did it the way you said
[2017-06-26 10:09:21] <andrewgy8> So i am setting up gitlab ci with Docker images being built.  However, Im confisued on one thing.
[2017-06-26 10:10:02] <andrewgy8> When I build the images and am ready to deploy them to the digital ocean server, I dont have all the images in my repo that are necessary for my project.
[2017-06-26 10:10:11] <andrewgy8> For instance my data volume
[2017-06-26 10:10:25] <andrewgy8> That will be on my server "permenantly"/
[2017-06-26 10:11:04] <andrewgy8> When the containers are pushed onto the server, do i rundocker-compose uplike I have been doing locally?
[2017-06-26 15:30:27] <aep> hmm, credsStore can't be set globally on dockerd can it? i'd rather not have it on every client
[2017-06-26 23:48:46] <onerealfunnyguy> sorry to bother, but cant find a good example anywhere, what it the correct way  to share the host network in a docker-compose file, no problems with docker run, just error every time I try docker-compose up
[2017-06-27 00:08:11] <SISheogorath> network_mode: hostbut notice, that this won't work fordocker stack
[2017-06-27 00:08:33] <SISheogorath> at least not on 17.03
[2017-06-27 00:10:02] <onerealfunnyguy> ty, have not used docker stack yet,  so not fimiliar with it
[2017-06-27 03:38:58] <onerealfunnyguy>  [<-LINK->] 
[2017-06-27 03:38:59] <onerealfunnyguy> @SISheogorathno luck.
[2017-06-27 05:47:08] <JinnaBalu> how to configure nginx for multple websites
[2017-06-27 05:54:14] <onerealfunnyguy> JinnaBalu:  [<-LINK->] 
[2017-06-27 06:19:36] <jeud> is it possible to have httpd and php7 on separated containers and setup httpd on the first container to use php on the second container ?just for learning purpose
[2017-06-27 10:27:31] <SISheogorath> jeud: yes, check the many setups for nginx and php-fpm
[2017-06-27 10:50:29] <rgolea> hey there people! I’m new to docker but I have one small question. I’ve configured a swarm but every time a windows/mac machine joins the swarm I get the hostname to bemobybut on my other machines I get it’s own hostname. As far as I’ve been reading, it’s because docker installs moby on top of windows/mac. Can I change that name to anything else?
[2017-06-27 10:50:32] <rgolea> Thank you!
[2017-06-27 13:43:11] <user2301> How to configure docker container to run protractor end to end tests?
[2017-06-27 13:43:41] <user2301> I downlaoded this image [<-LINK->] but the container did not start
[2017-06-27 13:45:46] <basz> following this tut partially [<-LINK->] I am now trying to get secrets going via a stack (docker stack deploy -c /tmp/docker/docker-flow-proxy.yml proxy). I verified the secrets are in the in the running container ats /run/secrets/. But the credentials aren’t accepted…. on the stats [<-LINK->] any idea?
[2017-06-27 18:15:04] <SISheogorath> onerealfunnyguy:  [<-LINK->] 
[2017-06-27 18:44:20] <jbelmont> docker-compose.yml [<-CODE->] Dockerfile [<-CODE->] I am trying to establish a connection with MongoDB driver (Mgo) for golang but my url doesn’t seem to work
[2017-06-27 18:45:01] <jbelmont> When I run this locally mgo connects to mongodb fine but in docker it is failing
[2017-06-27 18:45:48] <jbelmont>  [<-CODE->] 
[2017-06-27 18:46:22] <jbelmont> the `mgo.Dial(‘localhost’) works fine
[2017-06-27 18:46:38] <jbelmont> when running locally
[2017-06-27 23:28:34] <SISheogorath> jbelmont: as the official documentation doesn't show it, you should maybe drop themongodb://from yourMONGO_URL
[2017-06-27 23:28:52] <SISheogorath> and maybe also drop the port
[2017-06-27 23:30:05] <SISheogorath> In general it's more a issue of the library than a docker problem so please consider to ask in a golang related channel for further help
[2017-06-28 03:44:26] <aaronbeall> Is there any way to track the progress of a PULL in NodeJS? I'm usingdockerode. I see the event when thepullis complete, but no download progress.
[2017-06-28 03:48:54] <matrixbot> YvesSheogorath (Gitter): About [<-LINK->] , isn't that syntax only valid in 2.1? I was looking for a 3.0 example.
[2017-06-28 04:37:57] <k2levin> docker-composer.yml should I use version 3 or version 3+ ?
[2017-06-28 07:27:36] <SISheogorath> Ynes: since matrix has a bit ugly linking I can't say what you are referring to :/
[2017-06-28 07:28:08] <SISheogorath> k2levin: depends on what you are about to use
[2017-06-28 08:35:17] <k2levin> SISheogorath: thanks for the info..
[2017-06-28 08:38:58] <SISheogorath> k2levin: what are you about to do? Publish it or only use it in your defined environment?
[2017-06-28 08:39:31] <SISheogorath> The main reason to use older composefile versions is to stay compatible with olderdocker-composeversions
[2017-06-28 08:40:45] <SISheogorath> so if you are sure that all people and systems which should use this file are up-to-date then you can use the latest version, for publishing for example I still stick with version  if possible, because there are still systems out there that use docker-compose 1.9 or earlier
[2017-06-28 08:42:05] <SISheogorath> Same applies for docker stack of course. I'm not sure if 17.03 already supports newer versions than3.0
[2017-06-28 10:01:16] <Vantablack> Hi all, I have a question regarding volumes.It is possible to mount a named volume using host directory? [<-CODE->] 
[2017-06-28 10:26:41] <SISheogorath> Are you on Windows?
[2017-06-28 10:28:05] <SISheogorath> in general it's not possible to use normal host directories as named volumes. On linux there is volume driver to do something similar. For Windows I can't say anything specific
[2017-06-28 10:31:34] <k2levin> SISheogorath: , I'm not using docker compose v2I'm concern with docker compose v3 or v3.1 or v3.2
[2017-06-28 10:32:36] <k2levin> for people who using v3, then many features have to be deprecated
[2017-06-28 10:33:22] <SISheogorath> k2levin: yes, there applies the same. if you can make sure that all hosts where you want to use it support 3.2 then go for 3.2 but that highly depends on your environment. If it's not the case you have to update your hosts or use the older format like 3.0
[2017-06-28 12:44:30] <gdeverlant> Greeting dockerers!
[2017-06-28 12:44:41] <gdeverlant> I have a question concerning chroot in docker
[2017-06-28 12:45:21] <gdeverlant> is it possible to download a file from internet in chroot and save the file outside of the chroot in a docker container folder ?
[2017-06-28 12:45:54] <gdeverlant> like the parent container's folder outside of the chroot
[2017-06-28 12:50:34] <Vantablack> SISheogorath: Hmmmm alright thanks!
[2017-06-28 13:00:40] <SISheogorath> gdeverlant: Why chroot in docker? simply use another container
[2017-06-28 13:04:03] <gdeverlant> I'm creating a system with deboostrap
[2017-06-28 13:04:13] <gdeverlant> inside chroot within docker
[2017-06-28 13:04:18] <gdeverlant> it's a build system
[2017-06-28 13:21:14] <gdeverlant> Everything which is happening in the chroot I want to cache on the HD so that I don't need to redownload everytime the same files
[2017-06-28 13:44:38] <SISheogorath> You can simply exit the chroot, copy your cache and that's it.
[2017-06-28 13:46:06] <SISheogorath> Or monitor your directory and copy data you want to cache automatically outside in a background process
[2017-06-28 14:50:22] <basz> Hello: Is it possible do privision a local box with ubuntu16.04 on it? "docker-machine create --driver virtualbox node-1” gets me an boot2docker os
[2017-06-28 14:54:11] <basz> What I now understand is I need to create a box myself and then usedocker-machine create —driver none node-1
[2017-06-28 16:23:27] <ripper2hl> hi, i have a gitlab in ubuntu server and i use jenkins but recently the merge request hook begin failed and i dont know what happendthe response body :
[2017-06-28 16:24:04] <ripper2hl>  [<-CODE->] 
[2017-06-28 18:48:22] <achekulaev> Does anyone know what is happening with the releases on GitHub?I see there is a 17.06 release here: [<-LINK->] But no 17.06 release on GitHub [<-LINK->] 
[2017-06-28 19:44:14] <aaronbeall> Where can I find the docs on the event data fordocker events? [<-LINK->] 
[2017-06-29 00:02:00] <SISheogorath> achekulaev: they are now at [<-LINK->] 
[2017-06-29 00:35:38] <SISheogorath> aaronbeall: maybe take a look at [<-LINK->] 
[2017-06-29 03:32:25] <aaronbeall> SISheogorath: Thanks that does help... I'm seeing some other properties on my events, though, likestatus, id, from... they seem redundant to other props, maybe... are they old deprecated props?
[2017-06-29 03:32:52] <aaronbeall> Also is there any better documentation onAttributesthan "Various key/value attributes of the object, depending on its type"?
[2017-06-29 03:33:32] <aaronbeall> And what are the values ofType?
[2017-06-29 14:09:58] <user2301> Has anyone used this docker image [<-LINK->] 
[2017-06-29 14:10:24] <user2301> how do u run protractor end to end tests in this docker?
[2017-06-29 14:17:23] <megamindbrian> MythriManjunath: selenium docker repo on GitHub has nice dockerfile images for doing that.
[2017-06-29 14:18:09] <megamindbrian> MythriManjunath:  [<-LINK->] 
[2017-06-29 14:19:18] <megamindbrian> MythriManjunath: you can sidestep the dockerfile and add your protractor tests to one of those images and run it or just run the image as normal and set the address in your protractor.conf to connect to localhost:4444 for example.
[2017-06-29 14:31:19] <user2301> megamindbrian: Okay sure I will try right now..
[2017-06-29 21:41:04] <jbelmont> anybody here can help with mgo (MongoDB driver for golang and docker)
[2017-06-29 22:41:53] <rightisleft> Hi folks - im having some trouble using a container to build docker images for a CI server: [<-LINK->] 
[2017-06-29 22:45:41] <SISheogorath> @jbelmont still this problem? https://gitter.im/docker/docker?at=5952ea2219147ac323131a15 ?If you need further help, please talk the the mgo mailing list, which is their official way for community support: https://labix.org/mgo
[2017-06-29 22:46:33] <jbelmont> yeah still having issues though I got close I saw the database created in the container but can’t reproduce again
[2017-06-29 22:46:47] <jbelmont> I will try the official mailing list for mgo
[2017-06-29 22:47:49] <SISheogorath> did you mount a volume to the mongo database container?
[2017-06-29 22:51:55] <jbelmont> yes here is my docker-compose.yml
[2017-06-29 22:52:11] <jbelmont>  [<-CODE->] 
[2017-06-29 22:55:04] <jbelmont> when I get into containerdocker-compose exec backend /bin/shand runping dbI get a connection
[2017-06-29 22:55:31] <jbelmont>  [<-CODE->] 
[2017-06-29 22:56:00] <jbelmont> I tried doingmgo.Dial(“172.19.0.2”)for the url but no dice
[2017-06-29 22:56:22] <SISheogorath> ._. mounting every data directory directly into your current directory looks crazy
[2017-06-29 22:56:42] <SISheogorath> can you verify that mongo itself has no problem with a db directory full of garbage?
[2017-06-29 22:57:55] <SISheogorath> and are you running your setup on Windows or MacOS? or really on a Linux host?
[2017-06-29 22:58:49] <jbelmont> I am running on MacOS
[2017-06-29 22:58:58] <SISheogorath> In this case:WARNING (Windows & OS X): The default Docker setup on Windows and OS X uses a VirtualBox VM to host the Docker daemon. Unfortunately, the mechanism VirtualBox uses to share folders between the host system and the Docker container is not compatible with the memory mapped files used by MongoDB (see vbox bug, docs.mongodb.org and related jira.mongodb.org bug). This means that it is not possible to run a MongoDB container with the data directory mapped to the host.
[2017-06-29 22:59:15] <SISheogorath> official quote from the mongo image readme
[2017-06-29 22:59:24] <SISheogorath>  [<-LINK->] 
[2017-06-29 23:00:27] <SISheogorath> I'm not completely sure that's still true with docker for Mac as it no longer uses Virtualbox (iirc), but I can't say for sure so maybe you should check that first
[2017-06-29 23:01:17] <jbelmont> ah okay let me check
[2017-06-29 23:01:25] <SISheogorath> There are also additional, potential problems like SELinux policy conflicts, ...
[2017-06-29 23:58:53] <jbelmont> Yeah I posted this in the google group
[2017-06-29 23:59:21] <jbelmont> one thing I can confirm is now is the my mongodb collection is being created in the container I fixed that issue
[2017-06-30 00:00:05] <jbelmont> but thendocker-compose up frontend backend db rediswhen all the containers are running the backend container throws error aboutPanic: no reachable servers
[2017-06-30 00:06:33] <jbelmont> one thing I can’t figure out is why the container isn’t running with webpack though it was running fine before
[2017-06-30 00:13:16] <jbelmont> I changed it back to ports: “3000:8080” and app runs again but still the message Panic: no reachable servers
[2017-06-30 00:41:16] <gdeverlant> why do I have this error on my server ?
[2017-06-30 00:41:21] <gdeverlant>  [<-CODE->] 
[2017-06-30 00:49:10] <gdeverlant>  [<-CODE->] 
[2017-06-30 00:49:26] <gdeverlant>  [<-CODE->] 
[2017-06-30 01:18:21] <SISheogorath> gdeverlant: sounds like a problem with your kernel, check the kernel log for more details and maybe report it to the debian maintainers. They should be able to solve and fix the problem if it is reproducible.
[2017-06-30 01:19:46] <SISheogorath> Wait
[2017-06-30 01:20:47] <SISheogorath> I just saw "backing Filesystem: unknown" please open a bug for it on [<-LINK->] 
[2017-06-30 01:34:17] <gdeverlant> I did put this in daemon.json
[2017-06-30 01:34:45] <gdeverlant>  [<-CODE->] 
[2017-06-30 01:35:14] <SISheogorath> Why?
[2017-06-30 01:35:21] <gdeverlant> and now I get this error
[2017-06-30 01:35:24] <gdeverlant>  [<-CODE->] 
[2017-06-30 01:35:37] <gdeverlant> to test with overlay
[2017-06-30 01:37:13] <gdeverlant> I have 2 identical arm64 board with the same OS
[2017-06-30 01:37:24] <gdeverlant> the other board shows this
[2017-06-30 01:37:28] <gdeverlant>  [<-CODE->] 
[2017-06-30 01:37:47] <gdeverlant> the only difference between the 2 board is that
[2017-06-30 01:38:19] <gdeverlant> I moved the /var/lib/docker folder on a external usb HD with the 1st board
[2017-06-30 01:38:54] <gdeverlant> and didn't changed the 2nd board
[2017-06-30 01:38:54] <SISheogorath> That's the problem
[2017-06-30 01:39:11] <SISheogorath> What file system do you use on the hdd
[2017-06-30 01:39:16] <gdeverlant> ext4
[2017-06-30 01:39:39] <gdeverlant>  [<-CODE->] 
[2017-06-30 01:39:46] <SISheogorath> On the external hdd?
[2017-06-30 01:39:55] <gdeverlant> how do i check that
[2017-06-30 01:40:09] <gdeverlant> I'm not 100% sure
[2017-06-30 01:40:51] <SISheogorath> df -Tshould work
[2017-06-30 01:41:17] <gdeverlant>  [<-CODE->] 
[2017-06-30 01:41:36] <gdeverlant> can it be that
[2017-06-30 01:41:52] <gdeverlant> I mounted the external HD in /mnt/seagate-1TB-01
[2017-06-30 01:42:13] <SISheogorath> Yes, that's the problem
[2017-06-30 01:42:14] <gdeverlant> and then I made a mhddfs fuse mount
[2017-06-30 01:42:45] <SISheogorath> overlay2 only works on ext4 and xfs
[2017-06-30 01:43:06] <gdeverlant> how can I make sure that it works with mhddfs
[2017-06-30 01:43:34] <SISheogorath> It can't
[2017-06-30 01:43:35] <gdeverlant> in the future i'm planning to add 3 more HD
[2017-06-30 01:44:14] <gdeverlant> ok so it' better to just move the path from /mnt/virtual to /mnt/seagate-1TB-01
[2017-06-30 01:44:19] <gdeverlant> for the graph mapping
[2017-06-30 01:44:44] <SISheogorath>  [<-LINK->] 
[2017-06-30 01:45:26] <gdeverlant> ohh schnappp
[2017-06-30 01:45:27] <SISheogorath> Won't work because it's vfat
[2017-06-30 01:45:40] <SISheogorath> Not ext4 or xfs
[2017-06-30 01:45:50] <gdeverlant> no it's not vfat
[2017-06-30 01:46:02] <gdeverlant> the boot partition is vfat but the os is on ext4
[2017-06-30 01:46:12] <gdeverlant> both are on the usd card
[2017-06-30 01:46:14] <SISheogorath> /dev/mmcblk1p1                 vfat
[2017-06-30 01:46:26] <gdeverlant> there is another one ext4
[2017-06-30 01:46:34] <gdeverlant> /dev/root
[2017-06-30 01:47:02] <SISheogorath> Ah checked the wrong line
[2017-06-30 01:47:33] <SISheogorath> Smartphones /o\\
[2017-06-30 01:47:37] <gdeverlant> shit it means I can't use mhddfs
[2017-06-30 01:47:55] <gdeverlant> previously it worked with AUFS
[2017-06-30 01:48:17] <gdeverlant> but I upgraded the kernel to mainline 4.12-rc7
[2017-06-30 01:48:49] <gdeverlant> now I need to change everything
[2017-06-30 01:49:34] <SISheogorath> Good luck :) You'll make it ;) have to sleep now 
[2017-06-30 01:49:50] <gdeverlant> you rock buddy thanx for your expertise
[2017-06-30 01:49:58] <gdeverlant> you are so helpful cheers
[2017-06-30 01:51:14] <gdeverlant> I wish you a sleepy holow !
[2017-06-30 08:19:40] <pjetr> Hello, I have a question. I was reading [<-LINK->] because, well, I'm trying to speed up my magento on my development docker environment
[2017-06-30 08:20:19] <pjetr> The creator of this file has a container to mount volumes in, and share those to hir other containers.
[2017-06-30 08:20:48] <pjetr> why? What is the reason for doing so?
[2017-06-30 08:23:15] <pjetr> and one more, why would this [<-LINK->] be a good idea?
[2017-06-30 08:23:51] <pjetr> chmodding every minute while the container is running... That seems a bit much?
[2017-06-30 09:30:11] <SISheogorath> It's mainly to fix permissions of newly added files
[2017-06-30 10:39:43] <JinnaBalu> In docker how to run cassandra in Multiple machines and get data from one place, And insert into all the node?
[2017-06-30 10:44:41] <supernod3> hanidalia
[2017-06-30 10:45:59] <SISheogorath> JinnaBalu: how would you do it outside docker?
[2017-06-30 10:50:23] <JinnaBalu> I don't have much knowledge on this.
[2017-06-30 10:50:40] <JinnaBalu> some one said that it is easy to run in docker
[2017-06-30 10:51:09] <JinnaBalu> SISheogorath: If you have any idea on running caasanra please let me know
[2017-06-30 11:01:49] <SISheogorath> Docker doesn't free you from the need to know the software you use. There is a part about cassandra clustering [<-LINK->] 
[2017-06-30 14:30:33] <aaronbeall> Is it possible to read the progress fromdocker-composedownloads fromstdout?
[2017-06-30 15:52:06] <tuan3w> Hi everyone,I have an question about docker swarm and would love to hear your advices. I'm building a web service and deploying it on a swarm. Since the docker swarm mode has a built in routing mesh, what nodes in swarm we should request to? As I notice, if I request to only one node, the network throughput in that node will go much higher compare with other nodes. I think the reason is that node will receive all network request to it and forward to other nodes in the swarm. If my understanding is correct, so what is the best way to deal with  network unbalanced problem?I have to request roundrobin manually to every nodes in the swarm.\nI will use a proxy that connect to every nodes in the swarm.Or any better way ?Thanks
[2017-06-30 17:33:59] <aaronbeall> Hm looks likedocker-composedoesn't output progress events unless you're actually running in a terminal: [<-LINK->] 
[2017-06-30 17:34:23] <aaronbeall> I guess I could try usingpty.js... but its going to be really hard to read the output meaningfully
[2017-06-30 19:18:54] <devalexandre> hi dears
[2017-06-30 19:19:30] <devalexandre> did somebody see a errorERROR: for sale  Cannot start service sale: oci runtime error: json: cannot unmarshal object into Go struct field Process.capabilities of type []string
[2017-06-30 19:19:39] <devalexandre> my compose file
[2017-06-30 19:19:40] <devalexandre>  [<-LINK->] 
[2017-06-30 20:20:24] <SISheogorath> tuan3w: it's a pretty simply calculation: What amount of traffic do you think you get? If it's to much for one host, think about RR with up to 4 hosts. If it becomes more, think about external load balancers. Many CDN providers also offer external load balancing.
[2017-06-30 20:22:20] <SISheogorath> aaronbeall: do you need it in detail? if you want to programm something like libcompose is maybe the better address
[2017-06-30 20:32:21] <SISheogorath> devalexandre: What docker version are you running? Worked in my test setup. There was a basic problem with the container itself, based on the fact, that my mounted directory is empty, but in general it worked. Maybe you can provide some more details
[2017-06-30 20:32:53] <devalexandre> 17.06.0-ce
[2017-06-30 20:52:53] <aaronbeall> SISheogorath: Interesting, didn't know aboutlibcompose, that sounds useful but I'm no using Go, I'm using NodeJS... it would also be a pretty big refactor, as I'm working with a lot of existing code that usesdocker-compose
[2017-06-30 23:50:21] <karneaud> I\'m using docker a lot for development locally but its beginning to affect storage space. Because of this I\'ve resorted to running docker projects on a 60G sdcard. But of late I keep running into a lot of "ready system only" failures and inability to remove volumes and images sometimes. This eventually leads me to keep reformatting the card overtime. Is running docker on SDCARDS a good idea?
[2017-07-01 01:26:40] <SISheogorath> SD cards aren't made for many writes. So I would say running docker on them is not very reliable, but fine, if you have to and don't replace your images and containers too frequently. Developing in an SD card is a bad idea, as you will write over and over again
[2017-07-01 02:01:11] <tuan3w> SISheogorath: : As I seen in Ganglia, the network in the node that I connect to goes much higher than in  other nodes (100Mb/s while other only go upto ~7Mbs/s). My swarm consists of 6 cloud nodes (8core, 32G). I changed number of replications from 2 to 4 and still got the same effect.
[2017-07-01 09:16:16] <gdeverlant> you should use an external HD and move your /var/lib/docker folder to /mnt/your-drive/var/lib/docker
[2017-07-01 09:16:52] <gdeverlant> I get 25 to 30 MB/s throughput with an arm64 device on my network
[2017-07-01 09:17:27] <gdeverlant> running with a micro SD boot root
[2017-07-01 14:24:55] <karneaud> gdeverlant: thanks. I have a 700G WD external drive. I moved it across. Its just that is cumbersome to move around with it sometimes( even though its a passport)
[2017-07-01 14:25:07] <karneaud> hey guys I'm trying to run the following [<-LINK->] 
[2017-07-01 14:25:37] <karneaud> but I'm getting so confused on how to setup up permissions so containers can manipulate the files being used on the volume.....
[2017-07-01 14:25:51] <karneaud> How should my permissions be setup
[2017-07-01 14:25:52] <karneaud> ?
[2017-07-01 14:26:02] <karneaud> SISheogorath: @gdeverlant
[2017-07-01 15:05:03] <gdeverlant> try sudo touch yourfilename
[2017-07-01 15:05:26] <gdeverlant> you can also change the permission on any file with
[2017-07-01 15:05:35] <gdeverlant> sudo chmod 777 yourfilename
[2017-07-01 15:05:50] <gdeverlant> it gives acces to read and write to everyone
[2017-07-01 15:26:16] <SISheogorath> That's a very bad idea ._.
[2017-07-01 15:26:32] <SISheogorath> there is (almost) no reason to set 777 to anything
[2017-07-01 15:28:08] <SISheogorath> If you want to share/write to data with multiple parties, the same that applies outside of docker, applies to inside docker: Make sure you setup a group that all users share and make the files writeable to this group. NOT TO EVERYONE
[2017-07-01 15:37:53] <karneaud> thanks but would this work on "named volumes"@SISheogorath??
[2017-07-01 15:38:03] <karneaud> I'm confused as to how permissions are set to it
[2017-07-01 15:43:05] <SISheogorath> the easiest way is to set fixed uids and gids for images, but you have to check that these images support it
[2017-07-01 15:46:47] <karneaud> this is harder than I thought it would be
[2017-07-01 15:54:29] <SISheogorath> Well, Docker makes a lot of things easy, but is still mostly a wrapper around the linux kernel, so you have to follow the rules of the linux kernel. Many people tend to forget it. If you have a problem while creating or start a container, it's possibly related to docker. But almost everything that happens INSIDE your container, is only related to the kernel. So at the end of the day docker sends you all the way down inside classic kernel rulesets.
[2017-07-01 16:13:14] <karneaud> ok cool
[2017-07-01 16:13:31] <karneaud> trying to do some workarounds but I'm getting something weird here
[2017-07-01 16:14:02] <karneaud> why would a ./wordpress/wp-config.php:/var/www/html/wp-config.php try to load it as a directory and not a file?
[2017-07-01 16:14:42] <karneaud> Are you trying to mount a directory onto a file (or vice-versa)? Check if the specified host path exists and is the expected type
[2017-07-01 16:15:03] <karneaud> I've used docker before and it has mounted files as volumes already
[2017-07-01 16:15:31] <karneaud> matter of fact I have ./install.sh:/var/www/install.sh as a volume and I get no quams
[2017-07-01 16:15:34] <karneaud> what gives?
[2017-07-01 16:33:56] <karneaud> I can't get it to work
[2017-07-01 16:38:24] <karneaud> i tried [<-CODE->] Tried setting the composer to [<-CODE->] 
[2017-07-01 16:38:46] <karneaud> Still nothing CAN permissions on named volumes be done in the first place?
[2017-07-01 23:41:35] <karneaud> has anyone ever worked with browser sync and docker volumes?
[2017-07-01 23:42:09] <karneaud> I've setup a browser sync + web pack workflow where files updated trigger reloading of the browser
[2017-07-01 23:42:29] <dthree> Hi.
[2017-07-01 23:42:46] <karneaud> when I update the file from host I can see the changes in the container but browser sync doesn't realod
[2017-07-01 23:43:34] <dthree> I have an NGINX docker container, and 16 load balanced web servers each exposing a port on the host machine, 8081-8096.
[2017-07-01 23:43:35] <karneaud> However if I update the changes from within the container I can see the changes on both sides and browser sync reload is triggered
[2017-07-01 23:43:54] <dthree> How do I allow the Nginx container to talk to each of them? I don't want to make 16 links!
[2017-07-01 23:43:58] <dthree> What's the standard way to do this?
[2017-07-02 01:17:37] <karneaud>  [<-LINK->] 
[2017-07-02 01:37:30] <SISheogorath> dthree: you should use docker networking. You can simply use their names ^^
[2017-07-02 01:38:27] <SISheogorath> actually not even a need to expose them on the host if you loadbalance inside a container. hint: If you want to automate the reverse proxy setup: Checkout out Traefik
[2017-07-02 01:38:49] <dthree> kk thanks will check
[2017-07-02 09:21:06] <MaxGoh> Hey guys, my application is split into 3 parts. frontend/backend/database. Can I dockerize them and run it all on one server?
[2017-07-02 14:04:27] <SISheogorath> MaxGoh: yes.
[2017-07-02 14:05:10] <SISheogorath> And if you give a bit more information we can may point you into the right direction
[2017-07-02 15:07:13] <karneaud> MaxGoh: check this example on my question [<-LINK->] I'm running 4 containers each which its own purpose link by a named volume
[2017-07-02 15:07:49] <karneaud> once your not doing anything like browser sync or web pack you're good to go
[2017-07-03 13:10:14] <icehaunter> Hey guys. Could you please help me with organising my docker-compose file in terms of networking? I have a nodejs server-rendered SPA, python backend, database and, I guess, nginx to distribute requests to statics, uploads and such. I am having problems with server rendering: if point SPA to make requests tonginxinstead of localhost IP, serverside rendering works, but in-browser requests don\'t, because the browser does not know about nginx address. If I point to localhost, serverside rendering does not work, because node is on a different host, I guess, to the backend. Is there a way around this without using docker network mode:host(as it "pollutes" ports on the machine)? Thanks in advance.
[2017-07-03 13:25:16] <SISheogorath> Use a reverse proxy?
[2017-07-03 13:25:44] <icehaunter> SISheogorath: could you explain?
[2017-07-03 13:45:43] <SISheogorath> Use a reverse proxy that manages all needed connection, like Traefik. Then use the "published" names of your containers to talk to them
[2017-07-03 14:03:37] <icehaunter> SISheogorath: Do you mean setting up reverse proxy on the dev machine?
[2017-07-03 14:40:06] <yudilevi> Hi guys, anything looks inherently bad in this dockerfile in regards to permissions? - [<-CODE->] 
[2017-07-03 14:40:43] <yudilevi> Getting an access denied error for npm on package.json file
[2017-07-03 15:23:48] <SISheogorath> icehaunter: You can simply add it to your general setup
[2017-07-03 15:24:47] <SISheogorath> yudilevi: you don't change into the /app directory
[2017-07-03 15:25:07] <SISheogorath> so you won't find the package.json
[2017-07-03 15:25:14] <JinnaBalu>  [<-CODE->] 
[2017-07-03 15:25:50] <yudilevi> SISheogorath: Thanks, but I'm not following you - I do copy all files into the /app directory, so the file should be there, no?
[2017-07-03 15:26:51] <yudilevi> Oh, nm, gotcha :)
[2017-07-03 15:26:53] <yudilevi> Thanks, will try that
[2017-07-03 15:28:02] <yudilevi> Sorry, no - I still don't get it, I do copy all files into the /app folder (including the package.json file)
[2017-07-03 15:28:55] <yudilevi> Do I actually need to manually change into the /app folder? Isn't setting the workdir to /app do that?
[2017-07-03 15:52:20] <SISheogorath> Oh right I missed that sry
[2017-07-03 15:52:33] <yudilevi> Np :) Any other idea?
[2017-07-03 15:53:02] <SISheogorath> Can you copy your stuff first into /app and then change to it?
[2017-07-03 15:53:17] <icehaunter> SISheogorath: , sorry, I still don't get it
[2017-07-03 15:53:19] <SISheogorath> I'm not sure if it exists when you change to it and if that works
[2017-07-03 15:56:19] <SISheogorath> icehaunter: well, as far as I understand your problem is that you have to use the same network name for your backend as you request to work with server-side rendering. So a possible solution for it is: 1. Define a network alias 2. Use a reverse proxy
[2017-07-04 08:25:05] <pjetr> I don't get it... [<-CODE->]  [<-CODE->] 
[2017-07-04 08:27:28] <pjetr>  [<-CODE->] 
[2017-07-04 08:28:57] <pjetr> All my data is in the container, and it rannpm install, because I can see it in my logs.
[2017-07-04 09:53:14] <nonsense> hello! isdocker-machine 0.12.0supposed to work withdocker 17.06.0-ce?
[2017-07-04 09:53:37] <nonsense> i am trying to provision a machine on AWS, which was always working until today, when i am getting:Setting Docker configuration on the remote daemon...\nError creating machine: Error running provisioning: ssh command error:\ncommand : sudo systemctl -f start docker\nerr     : exit status 1\noutput  : Job for docker.service failed because the control process exited with error code. See "systemctl status docker.service" and "journalctl -xe" for details.
[2017-07-04 09:53:57] <nonsense> logging on the machine and trying the run the daemon manually results in:
[2017-07-04 09:54:12] <nonsense> root@orchestrator:/home/ubuntu# /usr/bin/docker daemon -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --storage-driver aufs --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=amazonec2\n`docker daemon` is not supported on Linux. Please run `dockerd` directly
[2017-07-04 09:57:38] <karneaud> Hey guys has anyone any experience with docker and azure? I have a current docker compose wordpress project and would like to deploy on azure...do I need to redo my docker project or can I just add a azure container to the current project?
[2017-07-04 10:16:41] <nonsense> if anyone has the same problem - I had to change driver from auft to overlay2 in/etc/systemd/system/docker.service.d/10-machine.confand start manually the service. the change was somehow introduced from 17.05 to 17.06 , but I couldn't find a binary to revert back to 17.05 to confirm it
[2017-07-04 10:42:38] <orangelynx> Hi everyone! I spent my last two days reading about docker and its concepts, but there's one thing I don't quite get: Take the example of nginx and php-fpm. Each comes in its own container and you would use docker-compose and link to make them work together. but both still have some redundant common base, e.g. alpine, even though they compose a service together. Why is the common way of doing things to link two independent containers instead of creating one container that contains both nginx and php (which would have less overhead, and possibly be more performant).
[2017-07-04 10:54:54] <karneaud> think you answered a bit of your question yourself if you read the last part of your comment in brackets@orangelynx
[2017-07-04 11:03:44] <SISheogorath> orangelynx: in general you should no longer use  the--link. Use normal networking instead.
[2017-07-04 11:04:05] <SISheogorath> And when you use regular networking it becomes clear why you split it up into different container.
[2017-07-04 11:04:57] <SISheogorath> If you have one instance and it becomes too slow you simply setup another instance of your container instead of move it to a more performant server
[2017-07-04 11:05:11] <SISheogorath> and this works way more generic than a scale up
[2017-07-04 11:05:23] <SISheogorath> and is still optimized for ressource usage
[2017-07-04 13:05:51] <przemolb> Hi everyone ! What do you guys use as a internal docker registry ?
[2017-07-04 13:06:41] <przemolb> (I mean not cloud based - it must be on-prem)
[2017-07-04 13:07:22] <carljmosca> artifactory
[2017-07-04 13:09:01] <przemolb> I am looking for something which also in the future could be integrated with Active Directory
[2017-07-04 13:09:32] <carljmosca>  [<-LINK->] 
[2017-07-04 13:12:12] <przemolb> is there any non-commercial version to try out ? I am trying to prepare some POC environment so would like to do that cost-free
[2017-07-04 13:12:58] <carljmosca> we have been using Artifactory for several years now initially for maven but it has been great for docker and yum as well
[2017-07-04 13:13:32] <carljmosca> you could try nexus but we had an issue with the way they secure docker registries
[2017-07-04 13:14:18] <carljmosca>  [<-LINK->] 
[2017-07-04 13:16:19] <przemolb> Thanks@carljmosca:-)
[2017-07-04 13:16:31] <carljmosca> very welcome…hope it helps
[2017-07-04 13:16:48] <przemolb> I did quick research before going to this forum and found there are quite a few
[2017-07-04 13:17:13] <przemolb> pre-selected harbor  (from vmware) and the one from docker
[2017-07-04 13:17:42] <przemolb> but doesn't know about anything about how they behave in production environment etc
[2017-07-04 13:18:01] <carljmosca> not tried either of those on-prem
[2017-07-04 13:18:13] <przemolb> did you use any another else except this artifactory  ?
[2017-07-04 13:18:54] <carljmosca> gitlab and nexus and we have OpenShift’s registry exposed but only the former in production
[2017-07-04 13:19:58] <carljmosca> I really like the UI and setup for Artifactory (I don’t now and never have worked for them but it really is nice) :)
[2017-07-04 13:25:42] <przemolb> Thanks again@carljmosca!  :-)
[2017-07-04 13:26:30] <carljmosca> przemolb: you’re welcome - let us know how it works out :)
[2017-07-04 13:29:03] <przemolb> It's gonna take some time to have some results ;-)
[2017-07-04 13:30:02] <carljmosca> but things are changing so fast in the Docker space right now I am sure your findings will be helpful to someone…good luck
[2017-07-04 16:22:07] <aaronmcadam> Hi everyone, I'm trying to set anENVvariable by reading in a file, but I'm getting the literal command: [<-CODE->] 
[2017-07-04 16:23:35] <aaronmcadam> Is it possible to use a subshell to set anENV?
[2017-07-04 18:19:51] <JnMik> Hello guys, I\'m using Docker swarm and I was wondering if there is anything available to deploy a bunch on containers, but never have  two containers of the same image on the same host ? Something like a constraint "Unique on host"
[2017-07-04 18:20:38] <JnMik> I have a scenario with a cluster of  3 cassandras with a Quorum of 2, And I want to avoid dealing with a failure because a docker node failed and I had 2 cassandra containers on that specific node
[2017-07-04 18:21:03] <JnMik> And it feels like overkill  to deal with tagging  labels on all nodes for that kind of dispatch needs
[2017-07-04 18:26:16] <arunkumar-patange> --mode global?
[2017-07-04 18:26:41] <JnMik> Well I thought about it at first, but I have 4 available nodes
[2017-07-04 18:26:46] <JnMik> I don't want 4 cassandra nodes
[2017-07-04 18:27:02] <JnMik> Because I won't be able to specify a Quorum (total / 2 + 1)
[2017-07-04 18:27:31] <JnMik> Also, I don't want my cassandra cluster to expand as I expand my docker cluster
[2017-07-04 18:28:16] <JnMik> The day I will need 20 docker nodes, I will have a major ressources waste running 20 cassandra containers at minimum 4GB of RAM each
[2017-07-04 18:28:30] <JnMik> and that\'s the requirement for a "dev" setup lol
[2017-07-04 18:28:50] <JinnaBalu> how are you running cassandra?
[2017-07-04 18:28:58] <JnMik> Could you be more specific ?
[2017-07-04 18:29:15] <JnMik> 3 cassandra containers as a cluster, replication factor of 3, Quorum of 2
[2017-07-04 18:31:09] <JnMik> At first I investigate if I could use labels for grouping docker nodesgroup-cassandra [<-ISSUE->] (docker node 1 and 2)group-cassandra [<-ISSUE->] (docker node 2 and 3)group-cassandra [<-ISSUE->] (docker node 3 and 4)But I could endup with 2 cassandra containers on docker node 2 and 3
[2017-07-04 18:31:48] <JnMik> and if I label my docker nodes with singularitynode [<-ISSUE->] = cassandra-label1node [<-ISSUE->] = cassandra-label2node [<-ISSUE->] = cassandra-label3node [<-ISSUE->] = no label, go to waste ?
[2017-07-04 18:32:05] <JnMik> So it's not really what I am looking for
[2017-07-04 18:32:25] <JnMik> I want my cassandra to be able to deploy on any docker nodes, without having 2 containers on the same node.
[2017-07-04 18:32:32] <arunkumar-patange>  [<-ISSUE->] still open
[2017-07-04 18:33:01] <JnMik> nice found
[2017-07-04 18:33:47] <arunkumar-patange> Exposing port might be a workaround, haven't tried it myself
[2017-07-04 18:36:18] <JnMik> Reading the comments atm, I don't understand your port exposing workaround for now
[2017-07-04 18:55:22] <JnMik> Oh
[2017-07-04 18:55:26] <JnMik> look what I found
[2017-07-04 18:55:29] <JnMik>  [<-LINK->] 
[2017-07-04 18:55:36] <JnMik> High availability
[2017-07-04 18:56:57] <JnMik> Not sure how to specify it in my service .yml file tho
[2017-07-04 18:58:31] <arunkumar-patange> Looks like this is only in docker cloud offering
[2017-07-04 18:58:37] <JnMik> yuppp :(
[2017-07-04 18:59:41] <arunkumar-patange> Yeah if you are running your own swarm, then deploy labels would be a w
[2017-07-04 18:59:54] <arunkumar-patange> ay to go for now
[2017-07-04 19:01:21] <JnMik> Bouhouh
[2017-07-04 19:02:42] <SISheogorath> aaronmcadam: currently not possible.  You can pass it to the build process byARG, but not by read it from a file inside your container
[2017-07-04 19:04:35] <SISheogorath> JnMik: yesm you have to way until custom deployment strategies exist :/ currently it's a bit limited
[2017-07-04 19:12:08] <JnMik> My last hope is destroyed, label it's gonna be xD
[2017-07-04 19:12:29] <JnMik> Now I have a sysadmin to convince
[2017-07-04 19:12:33] <JnMik> Wish me luck
[2017-07-04 19:12:36] <JnMik> lol
[2017-07-04 19:13:45] <JinnaBalu> JnMik: i need your help if you success i need to run cassandra in three machines connecting to the same cluster please help me with the docker commands to run.
[2017-07-04 19:37:51] <JnMik> Well I do have my cassandra cluster running at the moment, healthy and everything
[2017-07-04 19:37:57] <JnMik> What's the issue with yours ?
[2017-07-04 19:38:18] <JnMik> The only thing left to solve in my setup is the deployment strategy for 1 container per node
[2017-07-04 19:38:22] <JnMik> and I'll solve it with labels.
[2017-07-04 19:38:30] <JnMik> sysadmin convinced... !
[2017-07-04 19:38:42] <JnMik> Well, not really but he gave me the "go" to test it in our developement environement lol
[2017-07-04 19:39:02] <JinnaBalu> Currently I am running Single node cluster, in one machine
[2017-07-04 19:39:38] <JinnaBalu> I want to run with multinode in three different machine, One node will be the contact point for my application \\
[2017-07-04 19:40:02] <JinnaBalu> i need to configure this on three different machines what is the right way to achieve this
[2017-07-04 19:40:56] <JnMik> One node will be the contact point for your application ? By saying that, I suspect your are running 3 docker nodes, but not in cluster, correct ?
[2017-07-04 19:41:12] <JnMik> Because with Docker swarm, or kubernetes, your contact points would be the Service name / service IP
[2017-07-04 19:41:42] <JnMik> Which kinda have the "load balancer" role for your 3 replicas behind it
[2017-07-04 19:43:42] <JnMik> Well, I might be wrong on this. The service name might only be good using internally
[2017-07-04 19:44:16] <JnMik> But if you have a load balancer in front on your cluster, you could add the 3 nodes entry in it , they should all exposed the same port
[2017-07-04 19:44:36] <JinnaBalu> i have three servers is that possible to join these servers in docker swarm
[2017-07-04 19:44:56] <JnMik> Yup probably should, swarm is easy to use
[2017-07-04 19:45:01] <JinnaBalu> Service Ip wil be the contact point
[2017-07-04 19:45:23] <JnMik> Look for the "Swarm init" and "swarm join" command
[2017-07-04 19:45:24] <JinnaBalu> Can you please give me the docker commands to run run on different machine
[2017-07-04 19:45:45] <JnMik> You should go through the documentation anyway
[2017-07-04 19:45:47] <JinnaBalu> Will that join the server or only it joins the VMs?
[2017-07-04 19:45:48] <JnMik> To have the big picture
[2017-07-04 19:46:11] <JnMik> What'S the difference between your servers and yours VMs?
[2017-07-04 19:46:17] <JnMik> Not sure I picture them clearly lol
[2017-07-04 19:46:43] <JinnaBalu> VM and host are different right
[2017-07-04 19:46:59] <JnMik> lol it depends :P
[2017-07-04 19:47:12] <JnMik> Your docker nodes runs in VM ? Or directly on the machines/host ?
[2017-07-04 19:47:39] <JinnaBalu> I have three different host machines, is it possible to joint host together to work with swwarm
[2017-07-04 19:48:19] <JnMik> You want to run VMs AND Containers on the same host ?
[2017-07-04 19:48:34] <JnMik> I don't think you should
[2017-07-04 19:48:38] <JnMik> lol
[2017-07-04 19:48:49] <JinnaBalu> do run docker sarm we creates docker machines right, in my case machines are not created by docker they are preinstalled with ubuntu and ready to use for deployment
[2017-07-04 19:49:09] <JinnaBalu> I want them to run in swarm mode will that be a possibl case?
[2017-07-04 19:49:12] <SISheogorath> JinnaBalu: got with it step by step, learn how docker engine and docker swarm-mode work
[2017-07-04 19:49:16] <SISheogorath> then create one
[2017-07-04 19:49:50] <SISheogorath> check out the guides at [<-LINK->] 
[2017-07-04 19:50:24] <JnMik> Well, if it can help,   In your situation I would have 3 machines/hosts with centos as OS and docker-engine installed directly on the host (No docker machines VMs at all)
[2017-07-04 19:50:29] <JnMik> But that's me lol
[2017-07-04 19:50:37] <SISheogorath> Once you know how to use it and how it works (which includes some additional research in the docker docs and linux kernel manuals), you should go for it
[2017-07-04 19:50:44] <JinnaBalu> I have worked with creqating docker machines and worked with the swarm too, there i have created VMs with some drivers. but the case is different. I have servers ready, which are not VMs.
[2017-07-04 19:51:26] <SISheogorath> if you don't know how docker and docker-swarm-mode work you will run in more trouble than you solve with it
[2017-07-04 19:51:35] <JinnaBalu> JnMik: can you tell me and give me the docker commands how you configured, if you have time
[2017-07-04 19:52:07] <JnMik> Well you could install Docker directly on the host, no need for docker machines VMs
[2017-07-04 19:52:27] <JnMik> On ubuntu, I guess that would be apt-get install docker-engine
[2017-07-04 19:52:31] <JinnaBalu> Yes
[2017-07-04 19:52:44] <JnMik> then, check the swarm doc :P
[2017-07-04 19:53:03] <JnMik> But mostly your main target is to achieve "swarm init" and "swarm join"
[2017-07-04 19:53:19] <SISheogorath> JnMik: no longerdocker-engine:D it'sdocker-ceif you go for something more up-to-date
[2017-07-04 19:53:32] <JnMik> oh :) Sorry about that then lol
[2017-07-04 19:53:45] <JinnaBalu> that i can do, how to configure Cassandra, on three machines and give one machine as the contact point, if one machines fails I have other node in two machines
[2017-07-04 19:54:06] <JnMik> One of your 3 nodes will be a scheduler, 2 others will have containers (I don't recommand having containers on your scheduler, so maybe you would need 4 docker nodes)
[2017-07-04 19:54:36] <JnMik> Then once you have the scheduler ready, you\'ll start playing with docker commands like "docker service ls",  "docker service create"  etc
[2017-07-04 19:54:46] <JnMik> Then you'll discover the magic of docker swarm
[2017-07-04 19:54:50] <JnMik> lol
[2017-07-04 19:55:22] <JinnaBalu> Do you have any documentation on running cassandra? with multi node cluster on different machines?
[2017-07-04 19:56:14] <SISheogorath> JinnaBalu: there is no "use these 3 commands and a cassandra cluster without problems will appear on your machines"-documentation
[2017-07-04 19:56:21] <JnMik> ahaha
[2017-07-04 19:56:56] <SISheogorath> You have to K N O W docker, as well as cassandra, etc. otherwise you'll shoot yourself
[2017-07-04 19:57:10] <JnMik> Yeah, and you'll have some issues on the way
[2017-07-04 19:57:13] <JnMik> like
[2017-07-04 19:57:19] <JnMik>  [<-LINK->] 
[2017-07-04 19:57:23] <JnMik> and
[2017-07-04 19:57:23] <JnMik>  [<-LINK->] 
[2017-07-04 19:57:38] <JinnaBalu> @JinnaBalu there is no "use these 3 commands and a cassandra cluster without problems will appear on your machines"-documentation I know this
[2017-07-04 19:57:46] <JnMik> To be able to have your cassandra node rejoin the cluster automatically on failure :P
[2017-07-04 19:58:47] <JinnaBalu> Currently i am running in one node cluster. But want to replicate it on differnet machines whoch is different case, we need to hav link between the nodes in a cluster right, how do we do that was my question.
[2017-07-04 19:59:24] <SISheogorath> JinnaBalu: as always: First ask the question, how you would do it without docker
[2017-07-04 20:00:34] <SISheogorath> when you know how to do outside of docker, then you can do it inside docker as well. Docker is only the automated way to do it.
[2017-07-04 20:00:53] <JinnaBalu> SISheogorath: do you have the answer? with docker or without docker both are not so different, instead of installing cassnadra on hst we run on docker
[2017-07-04 20:00:53] <SISheogorath> the knowledge about how to do things must still exist in your head
[2017-07-04 20:01:20] <JinnaBalu> the knowledge about how to do things must still exist in your head Yes this is missing
[2017-07-04 20:01:37] <JinnaBalu> If you have answer pplease let me know
[2017-07-04 20:02:18] <SISheogorath>  [<-LINK->] <-- here you go
[2017-07-04 20:02:36] <SISheogorath> but actually I'm not a cassandra user so not sure if it's still up-to-date :D
[2017-07-04 20:02:49] <JnMik> jbalu and if you setup cassandra with 3 nodes, I suggest you might want to use Quorum of 2
[2017-07-04 20:03:02] <JnMik> And if you don't store too much data.. replication factor of 3 might be good for your case
[2017-07-04 20:03:18] <JnMik> Would allow you to have 2 nodes down without losing data.
[2017-07-04 20:03:20] <SISheogorath> Maybe it's better to go here: [<-LINK->] 
[2017-07-04 20:05:08] <SISheogorath> Since it's java I try to stay away from it as far as possible
[2017-07-04 20:05:44] <JnMik> xD
[2017-07-04 20:05:47] <JnMik> Greedy on ressources
[2017-07-04 20:05:53] <JnMik> minimum specs for a dev node : 4GB
[2017-07-04 20:06:01] <JnMik> insane
[2017-07-04 20:06:07] <JinnaBalu> JnMik: points to benoted. Quorum is new to me. If you have any docker commands or docker compose for cassnadra please send the configuration
[2017-07-04 20:07:31] <JinnaBalu> I have currently having 32 gb 3 server, i'll run elastic search and cassandra in two machines , application and cassnadra on one machine, I will run application with docker stack deploy or docker compose.
[2017-07-04 20:07:46] <JnMik> Well it's complicated to share, I have business stuff in it I might not want to share, and anyway I don't use docker-compose.yml for swarm, I generate .yml file for Docker swarm service through ansible
[2017-07-04 20:07:51] <JnMik> This might not be what you're looking for.
[2017-07-04 20:08:00] <JnMik> Why don'T you experiment
[2017-07-04 20:08:04] <JnMik> and ask specific questions anyway ?
[2017-07-04 20:08:23] <SISheogorath> take the official cassandra images' long description about building a cluster [<-LINK->] 
[2017-07-04 20:08:41] <SISheogorath> but as I mentioned if you don't know cassandra and docker really good you'll only shoot yourself
[2017-07-04 20:09:14] <JinnaBalu> I want to experiment, but if you have so that would save my day. Anyways I go nice inputs to work on from@JnMikand@SISheogorath
[2017-07-04 20:10:01] <JnMik> Well as said earlier, try to make your swarm cluster work first,then try to deploy a cassandra in it
[2017-07-04 20:10:07] <JinnaBalu> but as I mentioned if you don't know cassandra and docker really good you'll only shoot yourselfI have deployed my application with single node cluster using docker with Jenkins pipeline.
[2017-07-04 20:10:11] <JnMik> Questions will come along the way lol
[2017-07-04 20:11:20] <JinnaBalu> I need to find out the solution on connecting two nodes, seed ip/ contact point . I need to get clarity here
[2017-07-04 20:12:16] <JnMik> You can pass environment variables to cassandra containers
[2017-07-04 20:12:43] <JnMik> Exemple environment variable for cassandra container 1CASSANDRA_SEEDS: cassandra-peer1, cassandra-peer2,cassandra-peer3CASSANDRA_BROADCAST_ADDRESS: cassandra-peer1CASSANDRA_ENDPOINT_SNITCH: GossipingPropertyFileSnitch
[2017-07-04 20:14:29] <JnMik> Replication factor and consistency would be defined during migration (schema creation) / on the application level
[2017-07-04 20:21:40] <JnMik> cassandra-peerX would be my swarm internal service name, it's usable like an hostname/ IP address inside the containers which share the same docker network
[2017-07-05 02:26:20] <sabrehagen> Hi all, whenever I rebuild my container, it always build from scratch even though I only change a file that's ADDed in the last step. I believe it's theRUN apk updatecommand I use that stops the cached image version from being used. Does RUN invalidate the cache? How can I make it so I don't have to rebuild from scratch?
[2017-07-05 02:26:29] <sabrehagen> here's my Dockerfile [<-LINK->] 
[2017-07-05 02:38:35] <jordan-green> I think it will always check for updates
[2017-07-05 02:38:56] <jordan-green> And as a result will rebuild the image from there@sabrehagen
[2017-07-05 02:39:34] <jordan-green> If your other commands aren't reliant on a system update try moving it toward the end of your file to speed up your iterative builds
[2017-07-05 07:21:01] <SISheogorath> sabrehagen: It shouldn't invalidate that caching layer if you haven't changed that line. What docker version are you running and what command do you use to build your image?
[2017-07-06 07:51:33] <mikeleg> is possible to export in a package a docker_compose result
[2017-07-06 12:33:53] <basz> Hi I’m struggling a bit to ask the correct questions: given a swarm ready to accept stacks. I see a stack as a collection of services an application needs. But some services like ngix are required by multiple applications and that would mean multiple running ngix services, which doesn’t seem al that efficient… How do you handle this?
[2017-07-06 14:17:02] <gdeverlant> greetings agaain dockrians
[2017-07-06 14:17:35] <gdeverlant> I would like to know if it is possible to trigger the execution of a script outside of the dockerization proces
[2017-07-06 14:17:49] <gdeverlant> during the dockerization of a Dockerfile
[2017-07-06 14:18:43] <JinnaBalu> how to create angular-cli application docker image?
[2017-07-06 14:24:36] <gdeverlant> any clue ?
[2017-07-06 15:08:41] <gdeverlant> is there a way for a stack deploy before a service gets deployed
[2017-07-06 15:09:04] <gdeverlant> that a script is runned and then after the service is created ?
[2017-07-06 15:15:50] <JnMik> gdeverlant: You want the script to run on the hosts?
[2017-07-06 15:18:21] <JnMik> Maybe you should check Ansible.Ansible would be able to do your pre-docker tasks, launch your docker stack, and do your post-docker tasks (All of that in a proper way, and you'll be able to use versionning for your ansible playbooks etc).
[2017-07-06 15:39:41] <gdeverlant> Yes I want to run the  script on each nodes of the swarm@JnMik
[2017-07-06 15:40:00] <gdeverlant> but I don't want to use external tools
[2017-07-06 15:49:37] <JnMik> Well, I don't think the Docker commands are meant to run external scripts on hosts,  I don't think it's possible, and anyway it seems to me like it's not the right tool for the job (my opinion tho !)
[2017-07-06 15:50:12] <JnMik> That would be different if your script would run inside a container, but on the hosts.. meh !
[2017-07-06 15:50:32] <JnMik> Write a shell script and do "myshellscript.sh && docker stack deploy" :P
[2017-07-06 16:08:10] <gdeverlant> I need the script to do some stuffs on each node to prepare a static config file for each instance
[2017-07-06 16:08:44] <gdeverlant> all independently from one another
[2017-07-06 17:00:45] <SISheogorath> gdeverlant: the answer is no. There is no clean and easy way to achieve this. If you can generate the config file in one or another way do this inside your container, but it\'s currently not possible with docker and docker swarm mode. I know that RedHat\'s Atomic has a "setup" label per image which is (maybe) executed (never really got into this) .
[2017-07-06 17:01:12] <SISheogorath> Otherwise@JnMikis right, docker isn't the right tool for that
[2017-07-06 17:02:28] <SISheogorath> JinnaBalu: take a look at this example of mine: [<-ISSUE->] 
[2017-07-06 17:08:57] <SISheogorath> basz: if you serve your application with static files, that are served by nginx you need nginx in this setup to have the complete application. In this case the basic idea is: isolation(security) is more important than Ressource usage. And actually when you add a little bit of magic into your setup the ressource usage of another nginx instance isn't a problem. All in all you win, because when some weird issue causes the nginx instance of application A to crash every 2 seconds, the nginx instance of application B can continue work without a problem. I personally dislike it when stacks come with mapped ports. They should be written there but commented (but that's my personal opinion) because you usually have more than one application on your system (as you already pointed out) and this way you maybe run a reverse proxy like Traefik which handles all the port related things
[2017-07-06 17:10:27] <SISheogorath> mikeleg: if you cab explain it a bit more detailed, maybe we can help you. If you think about exporting a docker-compose file with all needed images which is automatically importable, no, doesn't exist right now
[2017-07-06 17:10:28] <JnMik> gdeverlant: "I need the script to do some stuffs on each node to prepare a static config file for each instance" I\'ve been doing that for years with ansible, but nowadays with Docker I think the best way is to pass the configs via environment variables
[2017-07-06 17:13:58] <JnMik> And if you don't want to expose crucial informations in your web server env variables, you can always transpose Container OS environment variables to a file base config inside  the container,  at startup
[2017-07-06 17:14:13] <JnMik> Depending on your language, there is some component out there that will do a clean job
[2017-07-06 17:14:15] <JnMik> like : [<-LINK->] 
[2017-07-06 17:15:15] <basz> SISheogorath: thanks. clarifies. indeed proxy, i use docker-flow-proxy in my swarm before any application
[2017-07-06 17:29:00] <gdeverlant> thanx yall
[2017-07-06 17:29:05] <gdeverlant> I will check into that
[2017-07-06 18:14:27] <SISheogorath> basz: yes, that's the typical way to go. The proxy containers are often included in published Dockerfiles to make sure they work out of the box
[2017-07-06 22:33:49] <juliocanares> hi guys
[2017-07-06 22:34:04] <juliocanares> I’ve got a question using docker swarm mode
[2017-07-06 22:34:22] <juliocanares> I am currently trying to deploy my swarm with 2 managers
[2017-07-06 22:34:41] <juliocanares> I am placing a load balancer in front of those 2 managers
[2017-07-06 22:34:49] <juliocanares> production.riqra.comis the dns name of the load balancer
[2017-07-06 22:35:17] <juliocanares> Now I need to access these managers from my CI server to deploy services in the swarm cluster
[2017-07-06 22:36:34] <juliocanares> so what I will do is to change the host of the docker client to something likedocker -H production.riqra.com:2376
[2017-07-06 22:39:50] <juliocanares> when it reachs the hostname the load balancer make its job and select one of the managers and try connect to its daemon through the port2376
[2017-07-06 22:40:10] <juliocanares> but I am not getting it working, am I missing something?
[2017-07-06 22:40:26] <juliocanares> should I generate differente certificates for each manager?
[2017-07-06 22:40:37] <juliocanares> o I can share the same certificate for both of them?
[2017-07-06 23:00:50] <gdeverlant> greetings again
[2017-07-06 23:01:05] <gdeverlant> why does this bash for loop doesn't work
[2017-07-06 23:01:10] <gdeverlant>  [<-CODE->] 
[2017-07-06 23:01:37] <gdeverlant> I get
[2017-07-06 23:01:39] <gdeverlant>  [<-CODE->] 
[2017-07-06 23:01:56] <gdeverlant> line 137 is if [ $i < $LAST_SERVER_NUMBER ]; then
[2017-07-07 06:54:18] <SISheogorath> gdeverlant: basics in shell programming: put your variables in quotes
[2017-07-07 06:59:40] <SISheogorath> juliocanares: first of all: swarm with only 2 managers breaks. Swarm mode uses raft consensus to keep state which needs n+1 nodes where n % 2 = 0
[2017-07-07 06:59:46] <SISheogorath> See [<-LINK->] 
[2017-07-07 07:22:19] <orhuncirakli> i tried many times to understand what docker is. please tell me if i am wrong
[2017-07-07 07:33:55] <orhuncirakli> we are using images as environments like .net or something else and put our app in .net image, so our app runs on every machine same way?
[2017-07-07 07:41:52] <SISheogorath> orhuncirakli: what we basically do, we provide filesystems for an application to run and isolate it. That's an image. To isolate them we use kernel features andmagica working application appears
[2017-07-07 07:42:25] <SISheogorath> The image is basically a tared filesystem for your application
[2017-07-07 08:16:34] <comeUpWithItLater>  [<-LINK->] 
[2017-07-07 08:17:16] <orhuncirakli> SISheogorath: so when we run our app on another machine, it runs on same filesystem and settings right? to my understanding, when we run our app in container, docker creates virtual filesystem and arrange settings for this container.
[2017-07-07 09:27:34] <SISheogorath> orhuncirakli: ever worked in a chroot?
[2017-07-07 09:54:28] <orhuncirakli> SISheogorath: no, i have limited experience with unix and linux
[2017-07-07 13:10:16] <brjadams> having an issue on ubuntu 16.04 where pip won't connect to a local pypi.running RUN pip install -r runtime.txt --trusted-host igarh7inscribebuild.iga.local
[2017-07-07 13:11:15] <brjadams> RUN pip install -r runtime.txt --trusted-host igarh7inscribebuild.iga.localin the Dockerfilei keep getting [<-CODE->] 
[2017-07-07 17:03:33] <imaia> Hello folks
[2017-07-07 17:03:55] <imaia> Folks, when does the container gain access to write to a volume?
[2017-07-07 17:04:09] <imaia> only after build?
[2017-07-07 17:04:25] <MaxGoh> Hey guys! I’m trying to connect my application to PSQL. Using flask
[2017-07-07 17:04:32] <MaxGoh> But I’m getting this error
[2017-07-07 17:04:32] <MaxGoh> sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not connect to server: Connection refusedIs the server running on host "localhost" (127.0.0.1) and acceptingTCP/IP connections on port 5432?could not connect to server: Cannot assign requested addressIs the server running on host "localhost" (::1) and acceptingTCP/IP connections on port 5432?
[2017-07-07 17:04:42] <MaxGoh> Do I not use localhost when I connect?
[2017-07-07 17:04:52] <imaia> MaxGoh: link your db container into your flask container
[2017-07-07 17:05:00] <MaxGoh> how do I do that?
[2017-07-07 17:05:03] <imaia> and reference your db host as the db container name
[2017-07-07 17:05:10] <imaia> are you using docker-compose?
[2017-07-07 17:05:12] <MaxGoh> yes
[2017-07-07 17:05:20] <MaxGoh> Oh my postgres service is called postgres
[2017-07-07 17:05:23] <MaxGoh> do I use thatj?
[2017-07-07 17:05:26] <imaia> just add a links section in your flask service
[2017-07-07 17:05:32] <imaia> yes
[2017-07-07 17:05:33] <MaxGoh> links:
[2017-07-07 17:05:36] <imaia> I usually call it db
[2017-07-07 17:05:37] <MaxGoh> postgres:postgres?
[2017-07-07 17:05:47] <imaia> links:postgres
[2017-07-07 17:05:53] <MaxGoh> cool!
[2017-07-07 17:06:07] <MaxGoh> I’m gonna give it a try now
[2017-07-07 17:06:08] <MaxGoh> thanks
[2017-07-07 17:06:10] <imaia> I'm writing a repo with a docker + flask setup
[2017-07-07 17:06:21] <imaia> when it's done, I'll advertise it here
[2017-07-07 17:12:56] <MaxGoh> imaia: hey!
[2017-07-07 17:13:04] <MaxGoh> I did a links: - db
[2017-07-07 17:13:25] <MaxGoh> and i tried connecting to it, but it said name or service not known
[2017-07-07 17:13:38] <MaxGoh> here’s my docker-compose
[2017-07-07 17:14:43] <MaxGoh>  [<-LINK->] 
[2017-07-07 17:42:05] <imaia> You don't need to use depends_on and links; just links will do
[2017-07-07 17:42:42] <imaia> ports:'5423:5423' <= I think you don't need to use ports here
[2017-07-07 17:43:15] <imaia> show me the flask database configuration
[2017-07-07 17:43:25] <MaxGoh> okay one sec
[2017-07-07 17:43:51] <MaxGoh> SQLALCHEMY_DATABASE_URI = "postgresql://maxgoh:passw0rd@db/blog"
[2017-07-07 17:43:53] <MaxGoh> mkumatag: 
[2017-07-07 17:44:47] <MaxGoh> oops tag wrong
[2017-07-07 17:44:50] <MaxGoh> imaia: 
[2017-07-07 17:45:31] <MaxGoh> i removed port and it still is the same error
[2017-07-07 17:45:50] <MaxGoh> sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name “db" to address: Name or service not known
[2017-07-07 17:47:39] <imaia> postgresql://scott:tiger@localhost:5432/mydatabase <= this is the correct format
[2017-07-07 17:47:59] <imaia> postgresql://maxgoh:passw0rd@db:5432/blog
[2017-07-07 17:48:02] <MaxGoh> so i’m lacking the port?
[2017-07-07 17:48:03] <MaxGoh> hm
[2017-07-07 17:48:37] <MaxGoh> so i add back the port ya
[2017-07-07 17:49:34] <MaxGoh> I just did it, but i’m getitng sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name “db" to address: Name or service not known
[2017-07-07 17:49:34] <MaxGoh> lol
[2017-07-07 17:53:24] <imaia> fez build?
[2017-07-07 17:53:33] <MaxGoh> fez?
[2017-07-07 17:54:56] <imaia> did you build?
[2017-07-07 17:55:01] <MaxGoh> yup
[2017-07-07 17:55:09] <imaia> fez -> "did you" in portuguese
[2017-07-07 17:55:11] <MaxGoh> i’m purely doing docker-compose build right now
[2017-07-07 17:55:15] <MaxGoh> ohh cool
[2017-07-07 17:55:18] <imaia> docker-compose up --build
[2017-07-07 17:55:30] <MaxGoh> i did docker-compose build
[2017-07-07 17:55:32] <MaxGoh> is that wrong?
[2017-07-07 17:56:03] <imaia> not wrong; up --build does both things; builds and runs your services
[2017-07-07 17:56:08] <imaia> just a shortcut
[2017-07-07 17:56:11] <MaxGoh> anyway
[2017-07-07 17:56:14] <MaxGoh> it didn’t work :(
[2017-07-07 17:56:21] <MaxGoh> is it because it’s not connected?
[2017-07-07 17:56:25] <MaxGoh> that’s why it’s not found?
[2017-07-07 17:56:31] <MaxGoh> should i have some kind of network key value
[2017-07-07 17:56:44] <mahenrique94> Is there someone that set up a node container by connecting mongo on main host ?
[2017-07-07 17:56:44] <imaia> your  (psycopg2.OperationalError) states that your app cannot see your database
[2017-07-07 17:56:53] <MaxGoh> yeah man
[2017-07-07 17:56:57] <imaia> which is not right, as you have linked them both
[2017-07-07 17:57:17] <MaxGoh> this is my latest
[2017-07-07 17:57:20] <MaxGoh> version: '2'services:nginx: [<-CODE->] - flask:flaskflask:    restart: always    build: ./maxgoh.io-backend    ports: [<-CODE->] data: [<-CODE->] command: 'true'postgres:    restart: always    image: postgres:latest [<-CODE->] 
[2017-07-07 17:57:23] <MaxGoh> shit
[2017-07-07 17:57:27] <MaxGoh> sorry, should have gist it
[2017-07-07 17:57:28] <MaxGoh> sec
[2017-07-07 17:57:33] <imaia> please, use dpaste
[2017-07-07 17:57:38] <imaia> or pastebin
[2017-07-07 17:58:00] <MaxGoh>  [<-LINK->] 
[2017-07-07 17:58:52] <MaxGoh> is it because of my psql port?
[2017-07-07 17:58:55] <MaxGoh> is it supposed to be 5432?
[2017-07-07 18:01:37] <imaia>  [<-LINK->] 
[2017-07-07 18:05:42] <MaxGoh> is it possible to do exec -it in docker-compose?
[2017-07-07 18:05:46] <MaxGoh> like i wanna access the shell
[2017-07-07 18:08:04] <kbespalov> MaxGoh: you still can use docker exec -it, whether you use compose or not, what a problem?
[2017-07-07 18:08:34] <MaxGoh> kbespalov: but i can’t be running any commands when i use exec am i right?
[2017-07-07 18:10:42] <kbespalov>  [<-CODE->] 
[2017-07-07 18:11:05] <MaxGoh> oh
[2017-07-07 18:11:06] <MaxGoh> i use run
[2017-07-07 18:11:07] <MaxGoh> haha
[2017-07-07 18:11:12] <MaxGoh> thanks!
[2017-07-07 18:11:17] <kbespalov> ok)
[2017-07-07 20:50:11] <basz> why is it I can’t connect when running 17.06.0-ce on ubuntu 16.04 and why is it that 17.05.0-ce isn’t available anymore? I can only go back to 17.03.0-ce
[2017-07-07 20:53:05] <basz> fo. docker stats wont work, not on the node nor local
[2017-07-08 02:31:44] <matrixbot> YvesHi. How can I specify a DNS entry with docker-compose 3? All v3 documentation I've seen show v2 examples.
[2017-07-08 03:46:53] <matrixbot> Yves- Found it: [<-LINK->] 
[2017-07-08 04:39:14] <WillSkates> I have a container on a bridge network that times out when you curl the domain of the host machine. Is there a way to find out why and fix it?
[2017-07-08 08:20:50] <Niko-La> can you inspect into a  remote container (something like ssh).  If not how are many companies running webterminal into docker systems ..
[2017-07-08 08:21:38] <thasmo> Hey everyone! How can I define an IP to bind to, when using the new docker-compose v3 syntax for port mappings?
[2017-07-08 10:05:33] <gdeverlant> Hi dockrians
[2017-07-08 12:59:49] <SISheogorath> gdeverlant: you have to make it executable >.>
[2017-07-08 13:00:00] <SISheogorath> means:chmod +xit
[2017-07-08 13:02:37] <SISheogorath> :/ sometimes I'm a bit demotivated to help people who don't even know the UNIX basics... These knowledge and typical mistakes are around for around 50 years (maybe longer) and super well documented on the internet. With and without the docker context. When ever an error appears please simply mark, copy  and paste it to the input line of the search engine of your trust. You will get an answer in 9 out of 10 cases
[2017-07-08 13:05:16] <gdeverlant> RUN chmod +x /usr/local/bin/dockerd-entrypoint.sh
[2017-07-08 13:05:27] <gdeverlant> this is what is inside of the docker image
[2017-07-08 13:05:40] <gdeverlant> I know that and I tried but it didn't work already
[2017-07-08 13:06:05] <SISheogorath> @thasmo you mean the long version? https://docs.docker.com/compose/compose-file/#long-syntax-1I\'m not completely sure, but IP and port number should be placed under "published". Notice: You can\'t specify an ip if you use it for docker stack deploy
[2017-07-08 13:06:06] <gdeverlant> I know chmod that's not a problem
[2017-07-08 13:06:25] <SISheogorath> gdeverlant: then check what executable you use in the entrypoint script (in you shebang line)
[2017-07-08 13:06:34] <SISheogorath> and make sure this is executable
[2017-07-08 13:06:36] <SISheogorath> and exists
[2017-07-08 13:06:53] <SISheogorath> still nothing really new
[2017-07-08 13:07:00] <SISheogorath> basics of shell programming :/
[2017-07-08 13:10:27] <SISheogorath> basz: What is the thing you can't connect with 17.06.0-ce?
[2017-07-08 13:18:20] <SISheogorath> what base image do you use?
[2017-07-08 13:18:22] <gdeverlant> this is supposed to run inside of an Alpine image
[2017-07-08 13:18:54] <gdeverlant> arm64-alpine
[2017-07-08 13:19:27] <SISheogorath> do you run the image privileged?
[2017-07-08 13:19:45] <gdeverlant> check there [<-LINK->] 
[2017-07-08 13:19:52] <gdeverlant> I have the whole listing the last threads
[2017-07-08 13:21:35] <SISheogorath> well, as I already asked, do you run the image/container of the image privileged?
[2017-07-08 13:21:52] <SISheogorath> since you try to run dind, that's important
[2017-07-08 13:23:12] <gdeverlant> but I don't execute this myself
[2017-07-08 13:23:30] <gdeverlant> drone is triggering docker
[2017-07-08 13:24:09] <gdeverlant> I found this link [<-ISSUE->] 
[2017-07-08 13:24:13] <SISheogorath> and drone runs in docker, too?
[2017-07-08 13:24:18] <gdeverlant> yes
[2017-07-08 13:25:19] <SISheogorath> in this case this is more a drone problem than it is a docker problem. The solution is easy: run it in privileaged mode, since this is a basic requirement of dind
[2017-07-08 13:26:07] <gdeverlant> Do I need dind
[2017-07-08 13:26:17] <gdeverlant> how Do I know that my version is greater than 1.8
[2017-07-08 13:26:31] <SISheogorath> I don't know, you are the one who currently tries to run dind
[2017-07-08 13:27:08] <SISheogorath> >.>-> 17.03 is greater than 1.8
[2017-07-08 13:27:27] <SISheogorath> and yes, before 17.03 it was 1.13
[2017-07-08 13:27:44] <SISheogorath> so yes, it's greater even after the versioning changed
[2017-07-08 13:28:04] <gdeverlant> It means that I don't need dind because of [<-ISSUE->] 
[2017-07-08 13:30:00] <gdeverlant> how can I adapt my docker-arm64 image [<-CODE->] 
[2017-07-08 13:30:05] <gdeverlant> without dind
[2017-07-08 13:31:25] <SISheogorath> What do you want to do?
[2017-07-08 13:32:05] <SISheogorath> and the issue you linked is about something completely different
[2017-07-08 13:32:13] <gdeverlant> I checked in my drone compose.yml and there is
[2017-07-08 13:32:13] <gdeverlant> DRONE_PLUGIN_PRIVILEGED=ergu/drone-docker-arm64,ergu/drone-git-arm64
[2017-07-08 13:32:42] <SISheogorath> can you please check that the container is privileged by inspecting it?
[2017-07-08 13:33:03] <gdeverlant> I don't control it actually
[2017-07-08 13:33:10] <gdeverlant> drone is connected to my gogs
[2017-07-08 13:33:18] <gdeverlant> and is triggered when I push
[2017-07-08 13:33:50] <SISheogorath> well,  you should still be able to do everything that drone does to reproduce/debug possible issues
[2017-07-08 13:34:05] <SISheogorath> check it out on the machine
[2017-07-08 13:34:09] <SISheogorath> maybe the container still exists
[2017-07-08 13:35:19] <SISheogorath> EHHHH question: have you made sure, that bash is installed?
[2017-07-08 13:35:26] <SISheogorath> alpines default shell isash/busybox
[2017-07-08 13:37:50] <gdeverlant> is it necessary the script has [<-CODE->] 
[2017-07-08 13:38:38] <SISheogorath> the set -e only says: stop when ever a non-zero exitcode appears
[2017-07-08 13:38:59] <SISheogorath> but that doesn't answer about bash
[2017-07-08 13:39:01] <gdeverlant>  [<-CODE->] 
[2017-07-08 13:39:05] <gdeverlant> there is no bash
[2017-07-08 13:39:13] <SISheogorath> try adding it
[2017-07-08 13:39:15] <gdeverlant> ok
[2017-07-08 13:39:21] <SISheogorath> maybe that's already the solution
[2017-07-08 13:41:33] <gdeverlant> I'm rebuilding the images
[2017-07-08 13:41:38] <gdeverlant> give me a sec I try
[2017-07-08 13:42:00] <gdeverlant> normally it has to be #!/bin/bash
[2017-07-08 13:42:11] <gdeverlant> so that I need to install bash isn't it ?
[2017-07-08 13:42:37] <gdeverlant> isn't #!/bin/sh recognized by default by alpine ?
[2017-07-08 13:43:23] <SISheogorath> the problem isn't your script
[2017-07-08 13:43:28] <SISheogorath> it's dind
[2017-07-08 13:43:37] <SISheogorath> dind is a shellscript that uses bash
[2017-07-08 13:43:58] <SISheogorath> could end up in  a weird issue
[2017-07-08 13:44:14] <SISheogorath> the#!/bin/shis fine
[2017-07-08 13:46:31] <gdeverlant> it makes sense ! men you are really insightful
[2017-07-08 13:46:37] <gdeverlant> that's pretty impressive
[2017-07-08 13:51:52] <gdeverlant> still get : ERROR: Error response from daemon: oci runtime error: container_linux.go:247: starting container process caused "exec: \\"/usr/local/bin/dockerd-entrypoint.sh\\": permission denied"
[2017-07-08 13:58:35] <SISheogorath> anything from SELinux or AppArmor? Maybe you run into limits there? and as already mentioned, you should verify that the container is actually running in privileged mode
[2017-07-08 14:03:23] <SISheogorath> Also verify that the binaries in your image work and are not for another architecture /o\\ that would be the worst case
[2017-07-08 14:07:08] <gdeverlant> the drone-git plugin and drone-docker plugin I have adapted to arm64 actually are built from Alpine within
[2017-07-08 14:07:20] <gdeverlant> the drone-git seems to work well
[2017-07-08 14:07:33] <gdeverlant> the clone is achieved successfully by drone
[2017-07-08 14:07:39] <gdeverlant> only the docker part is not passing
[2017-07-08 14:15:34] <SISheogorath> Do you know how to work withstrace?
[2017-07-08 14:16:29] <gdeverlant> no
[2017-07-08 14:16:48] <gdeverlant> drone server and drone client are running on my arm64 board
[2017-07-08 14:17:20] <gdeverlant> and the agent triggers the ergu/drone-docker-arm64
[2017-07-08 14:18:14] <gdeverlant> what is strace
[2017-07-08 14:18:34] <SISheogorath> a debugging tool to trace syscalls
[2017-07-08 14:18:42] <SISheogorath> which would you directly lead to the problem
[2017-07-08 14:18:54] <SISheogorath> but it's alittle bitverbose
[2017-07-08 14:18:55] <gdeverlant> how can I debug on my arm64 board  what is going on
[2017-07-08 14:19:06] <gdeverlant> with drone agent ?
[2017-07-08 14:20:01] <SISheogorath> that's a problem of your setup .-. I can't solve everything for you, you should try to get any way into such a machine by SSH
[2017-07-08 14:20:06] <SISheogorath> when you can debug
[2017-07-08 14:22:40] <kbespalov> Hi foks! Does anyone know companies who provides kubernetes as the service?Somethning like heroku, but with ability to use k8s DSL to define containers infrastracture.
[2017-07-08 14:25:14] <SISheogorath> kbespalov: techtonic, Google itself and iirc Amazon, too
[2017-07-08 14:25:34] <SISheogorath> that's the one I know out of my head, there are maybe even more
[2017-07-08 14:27:29] <SISheogorath> gdeverlant: I'm sorry but it will go way to time consuming to completely debug this in a peer session. Search for a good tutorial how to find the reasons for permission denied withstrace. There should be some out in the world.
[2017-07-08 15:14:02] <justinhj> kbespalov: there are a few on kubernetes partners page. Platform 9 for example. [<-LINK->] 
[2017-07-08 15:20:14] <gdeverlant> SISheogorath: Thanx you did so much like everytime
[2017-07-08 15:20:29] <gdeverlant> I will do my due diligence on my side
[2017-07-08 15:50:52] <basz> gdeverlant: i’ve created an issue for it [<-LINK->] 
[2017-07-08 15:52:45] <gdeverlant> It doesn't seem to be related with my problem@basz
[2017-07-08 15:53:36] <basz> gdeverlant: oh, sorry that was for@SISheogorath
[2017-07-08 15:56:59] <gdeverlant> You can edit your last post for SISheogorath
[2017-07-08 16:30:50] <WillSkates> Could someone please help me? I can't curl into the host when I run the container on a new bridge network.
[2017-07-08 16:30:54] <WillSkates> docker run --rm appropriate/curl https://host.domainworks
[2017-07-08 16:31:08] <WillSkates> docker network create testnetanddocker run --rm --net=testnet appropriate/curl https://host.domaindont.
[2017-07-08 16:31:23] <WillSkates> I'm not sure where to start looking.
[2017-07-08 16:45:28] <gdeverlant> when I run it it says : [<-CODE->] 
[2017-07-08 18:12:43] <italomaia> guys, just made myself a cli boilerplate creator for flask+semantic-ui+vuejs+nginx+dockersource code [<-LINK->] install: pip3 install --user fvsd
[2017-07-08 21:02:54] <gdeverlant> SISheogorath: I was able to fix the images
[2017-07-08 21:03:09] <gdeverlant> you can check the update [<-LINK->] 
[2017-07-09 03:57:13] <matrixbot> YvesI need to be able to setndots:1in/etc/resolv.confbut Docker appendsndots:0to anything I set as dns options. Any suggestion? I'm usingDocker version 17.06.0-ce, build 02c1d87
[2017-07-09 04:32:58] <MaxGoh> Hey  guys, how can I enable live-reload in my docker-container?
[2017-07-09 04:43:54] <matrixbot> Yvesinotify maybe?
[2017-07-09 04:46:14] <matrixbot> YvesMax Goh (Gitter): Are you looking for something like this: [<-LINK->] What do you want to reload?
[2017-07-09 04:52:09] <jordan-green> Hi all, has anyone successfully loaded a keras model into mxnet? We've built a keras moded and want to use mxnet for inference but are having issues with the mxnet keras fork being v1.2
[2017-07-09 09:38:33] <SISheogorath> Yves: did you set--dns-searchwhen you start your image? Not sure if it will really alter it, but it should. In general the question, why you need to do so
[2017-07-09 09:40:48] <SISheogorath> WillSkates: can you provide the error message?
[2017-07-09 09:41:17] <SISheogorath> Also check that the network is not isolated by usingdocker inspect
[2017-07-09 09:43:11] <SISheogorath> Yves: I just thought a bit about your problem: docker has to setndots:0because this is the only way how docker internal networking works
[2017-07-09 11:26:23] <gdeverlant> Greetings again dockrians
[2017-07-09 11:26:57] <gdeverlant> I would like to know if it is possible after having build an image to extract one file from it without running a container instance?
[2017-07-09 11:34:16] <gdeverlant> right now I do this [<-CODE->] 
[2017-07-09 11:35:22] <gdeverlant> but it might be incorrect I think
[2017-07-09 11:41:06] <SISheogorath> gdeverlant: You can usedocker saveto export it as tar file and then export the data using your favorite tar client. But I'm not sure what is easier to do
[2017-07-09 11:41:36] <MaxGoh> Hey@SISheogorathwonder if you know how can I docker-compose my flask application, and have it —watch the folder for any changes?
[2017-07-09 11:41:43] <MaxGoh> Wanting to use docker for development purpose
[2017-07-09 12:37:43] <SISheogorath> MaxGoh: Checked [<-LINK->] ?
[2017-07-09 17:24:56] <Vynlar> Howdy folks, I'm having some troubles. I'm attempting to use a docker swarm to host some static content using nginx containers. I've created a swarm over two physical servers, one manager and one worker. I can successfully launch a replica 2 nginx service across these two nodes and their appropriate docker containers show up indocker psanddocker service ps nginx. I created this service using--publish 80:80and adocker inspect --pretty nginxconfirms that the port is exposed. I've checked that dockerd is listening on port 80 using netstat; however, when I open my manager's public ip in the browser, I get aConnection refusederror. What steps should I take to figure out what is wrong? Thanks!
[2017-07-09 19:20:39] <matrixbot> Yves@Sheogorath(Gitter) I have set the dns_search, I see it in the container/etc/resolv.confbut I also seeoptions ndots:15 ndots:0. The first is inserted through/etc/docker/daemon.jsonand is what I want. The 2nd is appended by docker (libnetwork) and prevents proper usage. The container DNS at 127.0.0.11 tries figuring out a name on the host network, fails and stops there.Removing thendots:0setting allow proper operation and 127.0.0.11 answers properly on container names and host network names. [<-CODE->] 
[2017-07-09 20:30:13] <SISheogorath> Yves: I would suggest you to file a bug on github so you get an explanation why it is needed or someone will fix it. If you don't want to fix it this way I would suggest to simply add an sed statement to your entrypoint script that strips it out. Isn't nice, but works
[2017-07-09 21:20:17] <MaxGoh> Hey guys, how can I host 2 docker container in 1 server?
[2017-07-09 21:20:27] <MaxGoh> one would be example.com and another would be api.example.com
[2017-07-09 21:21:01] <MaxGoh> is it docker swarm?
[2017-07-09 21:51:20] <matrixbot> YvesSheogorath (Gitter): Bug already filed.I am not using an entrypoint, I use USER & CMD, that container is intended to run without intervention. Now if I fix resolv in the Dockerfile, it get overwritten at runtime and if I try at runtime, the selected user isn't root so edit fails.
[2017-07-09 22:11:23] <SISheogorath> MaxGoh: No, as outside of docker, it's called reverse proxy.
[2017-07-09 22:12:00] <SISheogorath> Yves: Well, in this case you actually run out of options. Using an entrypoint is the only way right now
[2017-07-09 22:15:44] <SISheogorath> Vynlar: Are all needed ports open? [<-LINK->] 
[2017-07-10 01:47:52] <matrixbot>  [<-CODE->]  [<-CODE->] the gateway isn't set. How does one sets the gateway with docker-compose v3?
[2017-07-10 02:29:29] <rcjsuen>  [<-CODE->]  [<-CODE->] Given the above Dockerfile, why is no error outputted? Is it exposing 80? 8081? 801? I'm having troubles understanding how escape characters are being parsed/handled.
[2017-07-10 03:04:45] <rcjsuen> Looks like 8081 is exposed.
[2017-07-10 03:10:08] <FrankYu> Hi there, Is it possible to rsync images on hub.docker.com to my local repos?
[2017-07-10 06:11:35] <coding-yogi> Hi, What should I be using to link external containers from my Docker Compose? Should it be links or external_links?
[2017-07-10 06:15:41] <coding-yogi> I am trying to use mongo db external container
[2017-07-10 06:16:06] <coding-yogi> which is started with command --> docker run --name some-mongo -p 27017:27017 mongo
[2017-07-10 06:16:29] <coding-yogi> I am trying to use it with external_link in my docker compose with below config
[2017-07-10 06:16:48] <coding-yogi>  [<-CODE->] 
[2017-07-10 06:52:27] <SISheogorath> FrankYu: not that I know, but check out [<-LINK->] 
[2017-07-10 06:54:30] <SISheogorath> coding-yogi: links are deprecated, so the suggestion is to use normal networking.
[2017-07-10 07:11:39] <coding-yogi> SISheogorath: , links are deprecated not the external_links right?
[2017-07-10 07:57:30] <SISheogorath> coding-yogi: since links a deprecated on the engine base andexternal_linksare a docker-compose construct that uses thelinkson container base,external_linksare deprecated, too
[2017-07-10 08:21:09] <coding-yogi> SISheogorath: , thanks for the info , appreciate it. ..any pointers for using network?
[2017-07-10 08:23:23] <coding-yogi> I have a mongodb container and I need to use it in my docker-compose
[2017-07-10 08:36:03] <SISheogorath> Create a network, start your container with it, then add the network in your compose file as external
[2017-07-10 10:00:14] <coding-yogi> I created a newtork, I started my mongodb container within that network with --network flag
[2017-07-10 10:00:21] <coding-yogi> so far so good
[2017-07-10 10:00:42] <coding-yogi> I also added network in compose file with tag networks:
[2017-07-10 10:00:46] <coding-yogi> is that correct
[2017-07-10 10:14:08] <SISheogorath> coding-yogi: here you go: [<-LINK->] 
[2017-07-10 10:18:04] <gdeverlant> Sheogorath: If I'm running DinD does the host docker need to be the same version as the one in the container ?
[2017-07-10 10:19:46] <SISheogorath> gdeverlant: good question, I don't really know. From my first understanding I would say no, since the docker instances aren't really talking to each other, but since both maybe modify various kernel parameter it could may cause conflicts if they aren't.
[2017-07-10 10:21:04] <gdeverlant> yesterday you suggest me to run the container locally first before I'm able to debug
[2017-07-10 10:21:18] <gdeverlant> DinD with strace
[2017-07-10 10:22:26] <gdeverlant> This is what I got : [<-CODE->] 
[2017-07-10 10:22:46] <gdeverlant> When I run with privileged : [<-CODE->] 
[2017-07-10 10:23:06] <gdeverlant> Does it seem to be running without problem ?
[2017-07-10 10:26:25] <gdeverlant> Do you see any problem with this DinD Container ?
[2017-07-10 11:15:29] <gdeverlant> how can I install docker-engine on aarch64 system ?
[2017-07-10 11:15:38] <gdeverlant> is there no official binaries ?
[2017-07-10 11:21:35] <SISheogorath> I think not
[2017-07-10 11:23:11] <SISheogorath>  [<-LINK->] 
[2017-07-10 11:23:42] <SISheogorath> And [<-ISSUE->] 
[2017-07-10 11:25:19] <SISheogorath> The only problem I see in this "big paste" is that you try to build a docker file in a directory that has no
[2017-07-10 11:26:30] <SISheogorath> /Dockerfile: no such file or directory<-- Should be fixable. But it's not really a docker problem
[2017-07-10 11:28:41] <gdeverlant> normally this is passed by drone
[2017-07-10 11:43:59] <gdeverlant> does someone know why I keep getting those huge logs when I do something on the bash ????? [<-CODE->] 
[2017-07-10 11:44:20] <imaia> Hey guys, I made this docker setup for python; I believe it could benefit with some hardening or, maybe, deploy friendly setup. Pull Requests and suggestions are very much welcomed [<-LINK->] 
[2017-07-10 14:05:15] <ahmetyasary_twitter> Hello everyone, I'll use the docker for the first time. How and where should I start? or Would you recommend a book to get started? Thanks.
[2017-07-10 14:06:05] <pjetr> without being a smart ass: [<-LINK->] 
[2017-07-10 14:06:12] <pjetr> :-)
[2017-07-10 14:06:43] <pjetr> and also: [<-LINK->] 
[2017-07-10 14:07:48] <pjetr> also, I'm still very much a beginner in docker ans devops in general so I can't really help you much more
[2017-07-10 14:08:22] <pjetr> I have a book, that was part of the now completed humblebundle booksale, and I have read nearly nothing from it yet
[2017-07-10 14:09:51] <ahmetyasary_twitter> Thanks for the great info you gave me.I'll look.
[2017-07-10 14:13:01] <pjetr> I read the docs, and did the examples
[2017-07-10 14:13:05] <pjetr> and posted questions here and on reddit
[2017-07-10 18:02:26] <mahenrique94> Guys, i've an app deployed on a node container, but my mongo it's installed on at main host, how can i establish a connection between both ?
[2017-07-10 18:05:52] <brjadams> anyone use docker on Ubuntu 16.04?
[2017-07-10 18:09:29] <brjadams> I cannot get pip to see a local domain when attempting to install packages in my container.
[2017-07-10 18:09:35] <ahmetyasary_twitter> OK. I will try. Thanks@pjetr
[2017-07-10 19:32:56] <brjadams> nothing that I run via docker-compose seems to be able to talk to the network. yum updates, etc, anything on the container seems to fail.
[2017-07-10 19:33:15] <brjadams> What are some steps I should take? Ubuntu 16.04, it's a centos image
[2017-07-10 20:00:22] <SISheogorath> mahenrique94: The same way, you would connect your mongodb from another computer
[2017-07-10 20:00:39] <SISheogorath> ahmetyasary_twitter: Check [<-LINK->] 
[2017-07-10 20:01:34] <SISheogorath> brjadams: check the dns server during build. possible they are set to8.8.8.8, 8.8.4.4
[2017-07-10 20:06:05] <SISheogorath> if you use direct IPs, check that they don't collide with the docker IP scopes on your local machine
[2017-07-10 20:16:07] <brjadams> SISheogorath: ,  during build?
[2017-07-10 20:17:07] <SISheogorath> yes, builds run in inside a container and  use the default network
[2017-07-10 20:17:16] <SISheogorath> if you don't specify another network
[2017-07-10 20:17:37] <brjadams> how do I check the dns udring build I guess is what I'm asking
[2017-07-10 20:18:50] <SISheogorath> runcat /etc/resolve.confduring build process should work
[2017-07-10 20:19:04] <brjadams> so, in the Dockerfile have it do that?
[2017-07-10 20:20:49] <brjadams> in my personal resolve.conf i have: [<-CODE->] 
[2017-07-10 20:24:39] <SISheogorath> yes, in the Dockerfilemaybe simply define an short one: [<-CODE->] 
[2017-07-10 20:27:41] <brjadams>  [<-CODE->] 
[2017-07-10 20:29:54] <brjadams> while perusing SO for a solution, one suggested: [<-CODE->] in the docker.service file.
[2017-07-10 20:30:13] <brjadams> So I think that's  where the 253 range is coming from
[2017-07-10 20:47:48] <SISheogorath> what? so your  local DNS servers are10.252.252.252and10.253.253.253or did you blindly copy?
[2017-07-10 21:03:59] <brjadams> 10.252.252.252 was there
[2017-07-10 21:04:02] <brjadams> i copied 253 into it
[2017-07-10 21:22:33] <SISheogorath> >.>you know that you have to use real DNS servers?
[2017-07-11 07:44:16] <ahmetyasary_twitter> Thanks@SISheogorath
[2017-07-11 08:00:34] <ninogomez> hi quick question... so I have an app and a selenium hub and chrome. I can access the app locally by localhost:port however, when I run my test using localhost:port, it says it can't be reached
[2017-07-11 08:00:40] <ninogomez> any ideas ?
[2017-07-11 10:53:52] <matrixbot> YvesA firewall maybe? I was having the same problem until I told UFW to allow from and to 172.16.0.0/12
[2017-07-11 12:48:27] <Richard87> Hi guys! I'm completley new to docker, but was hoping some of you could guide me to a comprehensive tutorial ( /book maybe?) My goal is to run my symfony application in docker, but have a specific docker container to build and test the application, thencopythe build into a readonly container, and when that is online, switch the old version over to the new version...
[2017-07-11 12:49:51] <Richard87> What I'm doing now is copying the new application to a folder on my server, installing it, andmigratingthe database schema (without it, the tests won't run), then when the tests complete, activate the new folder... The problem is if the tests fails, then the database might already be migrated if there was any changes, and the old version would also fail since the database is out of sync :/
[2017-07-11 12:51:08] <Richard87> I have managed to get the first part up and running with BitBucket pipeline (launching a new container, installing everything,copyingthe old db and testing the migrations, and then running tests)
[2017-07-11 12:51:50] <Richard87> But I don't know how to do the next 2 steps properly, create a new production instance, build it, migrate db, and then activate it :/
[2017-07-11 13:29:09] <oleic> hey, I run docker in docker. the first docker instance is linked with an another container. is it possible for the containers running in the second docker instance to communicate with the linked container from the first docker instance?
[2017-07-11 13:32:28] <pjetr> Richard87: that sounds like a cool project. I don't use docker that intensive yet. Only for development, so nothing crucial. I started out with the docker docs, which went quite some ways. And the second resource I used was [<-LINK->] and, you know [<-LINK->] 
[2017-07-11 13:32:43] <pjetr> and last, this channel
[2017-07-11 13:33:23] <pjetr> I think I've gotten quite a robust well dockerized development environment out of it.
[2017-07-11 13:33:53] <pjetr> oleic: [real question] why would you do that?
[2017-07-11 13:36:48] <pjetr> oleic: I mean, why would you run docker in docker? What is to be gained from it?
[2017-07-11 13:38:10] <oleic> pjetr: i am currently working on my bachelorthesis. I have write a cloud service, that  manages docker containers. portability is the only thing that i will gain from this i think. its just a prototype, so i havent put so much thought in it
[2017-07-11 13:40:00] <SISheogorath> @Richard87 running symphony in docker is easy -> check the official php container, install all additional dependencies in there, put your app in there and add a entrypoint script to generate the configs by env vars and/or docker secrets or simply use the newly introduced config management.Anyways:I don't see the need to create two separated images for testing and production. You should be able to run unit tests outside of docker and the integration and smoke tests should run against the image you want to use in production to get reliable results. So if you want, you can actually build your container with unittests as build step in multi-staged builds, but be aware that you need docker 17.06 for this to work.The switch problem is something you always run into. The typical way to solve it: Run the upgrade database on startup. and if you may want to fall back, you need to write migration steps in both ways or test your application completely. If you want it completely 0-downtime it becomes really difficult and you may need an additional layer, with allows to write to multiple backend versions. also not nice, but works. But if you are not at the scale of google or facebook, I would trow this idea away
[2017-07-11 13:41:41] <SISheogorath> oleic: when you say linked you mean--link?
[2017-07-11 13:42:29] <SISheogorath> pjetr: Hint: There is also the docker community ecosystem. [<-LINK->] 
[2017-07-11 13:42:32] <Richard87> SISheogorath: ,@pjetrThanks guys! Yeah, I think maybe testing and building could be the same container but I have to switch database link, I have to see how that works...
[2017-07-11 13:42:37] <oleic> SISheogorath: yeah that's what i mean
[2017-07-11 13:42:59] <SISheogorath> oleic: you shouldn't do this. It's deprecated for multiple reasons
[2017-07-11 13:43:07] <SISheogorath> use networking instead
[2017-07-11 13:43:48] <oleic> SISheogorath: i used the link from docker-compose. isnt it the same?
[2017-07-11 13:44:06] <SISheogorath> Richard87: check [<-LINK->] 
[2017-07-11 13:44:19] <pjetr> actually the database seems quite easy as well? Simply provide a nightly dump, and spawn a new mysql-container. It doesn't even need to persist any data. Simply install the database, run migrations and run tests. When the tests are completed, simply clean up the container.@Richard87&@SISheogorath
[2017-07-11 13:44:21] <SISheogorath> oleic: it is, and it is also deprecated in compose
[2017-07-11 13:44:52] <oleic> SISheogorath: ah okay, good to know. but it will not solve my problem :)
[2017-07-11 13:45:31] <SISheogorath> pjetr: yes... that works for a 20MB wordpress database :D but when you think about production databases with terrabytes of data... (or already more than 10 GB are enough to kill a container) it doesn't scale :D
[2017-07-11 13:45:55] <Richard87> pjetr: I'm not sure, anyhow I have to copy the running db to test migrations and unit tests/integration tests, but if I just replace prod with the test container, I might loose data if the process takes 5minutes to complete...
[2017-07-11 13:46:28] <pjetr> ah, yes, our application is long from anywhere in that size, hence why there is no need for docker in production yet :D
[2017-07-11 13:47:01] <pjetr> we simply have a cron running to create a nightly mysqldump
[2017-07-11 13:48:03] <pjetr> since the use of our app is strictly local bussiness hours
[2017-07-11 13:48:14] <pjetr> no worries there
[2017-07-11 13:48:29] <Richard87> I wonder if I can speed the process up alot if I can take a snapshot of the mysql database, and load it in a new instance for testing, then if it works just replace prod with test, then it would finish in 60seconds which would be acceptable :))
[2017-07-11 13:49:16] <pjetr> that's how I would do it, connect to a different database container for testing
[2017-07-11 13:49:20] <Richard87> that sounds nice ;)  It's not ahugedeal, but I'm working on a learning management system, with students in at all times working on stuff :(
[2017-07-11 13:49:59] <oleic> my situation looks like this: [<-LINK->] 
[2017-07-11 13:50:08] <Richard87> what's Dind?
[2017-07-11 13:50:21] <pjetr> I'd say Docker in Docker
[2017-07-11 13:50:29] <oleic> i want c3 communicating to c1
[2017-07-11 13:50:34] <Richard87> huh? interresting :)
[2017-07-11 13:50:41] <SISheogorath> oleic: links have weird effects, you can try to reach out for the ip of the container linked to the dind container to communicate or try to reach out to it's name. if one thing of both works, it's fine, otherwise, no
[2017-07-11 13:50:43] <oleic> yeah, docker in docker
[2017-07-11 13:51:17] <SISheogorath> Richard87: yes, it's a weird way to setup docker, but it's possible. [<-LINK->] is based on it.
[2017-07-11 13:51:51] <oleic> SISheogorath: i didnt want to fiddle directly with ip adresses, because ip adresses can change
[2017-07-11 13:52:13] <oleic> i thought, there would be a mechanism or something in docker
[2017-07-11 13:52:33] <SISheogorath> I know, in this case it's more about general possiblity of communucation
[2017-07-11 13:53:54] <SISheogorath> if it  works by ip, you start hacking the dns discovery
[2017-07-11 13:54:19] <SISheogorath> otherwise you don't need to try it
[2017-07-11 13:55:13] <SISheogorath> the current docker way would be usage of a network instead of--link
[2017-07-11 13:55:25] <SISheogorath> which is by the way something you would do, when you reach out for the IP
[2017-07-11 14:00:35] <pjetr> SISheogorath: more on links being deprecated :) [<-LINK->] this is how I link my containers on the virtual network. You're saying that I shouldn't do this? [<-CODE->] 
[2017-07-11 14:01:00] <pjetr> wowzers, that turned out bigger than I anticipated :D
[2017-07-11 14:01:49] <SISheogorath> you already have them on networks, what do you need thelinksfor?
[2017-07-11 14:03:10] <pjetr> I thought it was the links that created the dns records or hosts or whatever :)
[2017-07-11 14:04:03] <pjetr> so without links I should still be able to link tophpfrom myweb?
[2017-07-11 14:04:49] <SISheogorath> yes
[2017-07-11 14:05:03] <pjetr> good to know :D
[2017-07-11 14:05:26] <SISheogorath> links do weird things, they map networks ports and share environment variables (think about possible secrets) and other things you may don't want to do
[2017-07-11 14:06:40] <SISheogorath> See [<-LINK->] 
[2017-07-11 14:07:46] <oleic> with --network="host" i was able to let C3 to communicate with C1 via http
[2017-07-11 14:08:07] <SISheogorath> yes, that's true, but that also breaks the whole network isolation
[2017-07-11 14:08:20] <SISheogorath> you should keep that in mind@oleic
[2017-07-11 14:08:35] <oleic> yeah i know... but i think thats okay for my project
[2017-07-11 14:08:54] <oleic> but now i dont know, how to let C1 communicate with C3
[2017-07-11 14:09:20] <SISheogorath> if you run both with--network=hostit works identical
[2017-07-11 14:09:37] <SISheogorath> since both operate on the hosts network stack
[2017-07-11 14:47:33] <oleic> SISheogorath: thanks. its working now :)
[2017-07-11 15:49:53] <WillSkates> Is there anyway to let custom bridge networks through the firewall on centos?
[2017-07-11 15:50:18] <WillSkates> Everything using docker0 as the interface is fine to query the host at [<-LINK->] 
[2017-07-11 15:50:27] <WillSkates> everything on a bridge network times out.
[2017-07-11 15:50:38] <WillSkates> I'm using firewalld
[2017-07-11 21:27:22] <ketchupmonkey> Hi Everyone! I have a question. Has anyone used oracle database on docker? I am just wondering about the licensing. Is it allowed to be used in a corporate environment or only for personal use?
[2017-07-12 07:25:57] <jeserkin> Hello guys. I have read, that it is best practice to have a separate container for database if few containers are using database of same type, but I am having trouble of finding any good example on how to implement it. It seems there are few options. One of them islink. Any good articles on how to combine? I did read version 3 of docker documentation, but real world example woulbe much appreciated. I would like to define as much as possible indocker-compose
[2017-07-12 08:59:35] <FrankYu> Hi guys, I wanna setup a private docker gegistry, which one should I chose? anyone has used harbor/vmware?
[2017-07-12 09:10:53] <BenjamWhite> Hi guys,Im loading a sklearn Modell within a container using python3 and getting the 'IO Error out of memory' has anybody experienced the same problem and got a solution? The programm is just fine running on my local machine.
[2017-07-12 13:18:43] <carlosjgp> jeserkin: You have a basic example on [<-LINK->] 
[2017-07-12 13:32:49] <pjetr> jeserkin: also scroll up a bit, link is deprecated, as@SISheogorathexplained to me yesterday :D
[2017-07-12 16:38:31] <jeserkin> carlosjgp: will check out WordPress example for sure.
[2017-07-12 16:39:30] <jeserkin> pjetr: what should be used instead of links? What is the other way to expose containers to each other?
[2017-07-12 17:06:00] <SISheogorath> jeserkin: networks
[2017-07-12 17:06:05] <SISheogorath> Simply use networks
[2017-07-12 17:43:38] <jeserkin> You mean directly use IP provided to required container?
[2017-07-12 19:12:25] <SISheogorath> jeserkin:  [<-LINK->] 
[2017-07-13 07:39:46] <gdeverlant> greetings@SISheogorath
[2017-07-13 07:39:58] <gdeverlant> I'm back with another foolish question :D
[2017-07-13 07:40:47] <gdeverlant> I wanted to know if it is possible inside of a Dockerfile to do a for loop for dynamic list of exposed ports ?
[2017-07-13 07:46:48] <dv29> Hello, i have an issue with docker and nodejs, we are using volumes to mount node_modules, we haveprehooklibrary for runninglinterbefore we commit, but the issue is the library is insidenode_modulesand we dont have permission to execute it, any idea how to make it work
[2017-07-13 07:48:41] <airtonix> why don't you have permission?docker run --rm -it -v $PWD:/somewhere/in/the/container yourimagename node ./node_modules/.bin/linterdoesn't work?
[2017-07-13 07:49:37] <dv29> the hooks are fired from host os, because that where we commit from
[2017-07-13 07:49:46] <airtonix> yeah?
[2017-07-13 07:50:06] <airtonix> I mean why would that stop you? just mount$PWD/.git:/app/.git
[2017-07-13 07:50:27] <dv29> Let me give it a try
[2017-07-13 07:50:34] <dv29> havent tried that
[2017-07-13 07:50:37] <airtonix> wait git has nothing to do with it.
[2017-07-13 07:51:08] <airtonix> dv29: does your library provide something in./node_modules/.bin/?
[2017-07-13 07:51:20] <dv29> i think it does, as the hooks are fired by git, which is on host os
[2017-07-13 07:51:22] <dv29> yes it does
[2017-07-13 07:51:47] <airtonix> dv29: can you edit the.git/hooks?
[2017-07-13 07:51:57] <dv29> yes
[2017-07-13 07:52:03] <dv29> thats on host btw
[2017-07-13 07:52:43] <airtonix> dv29: then i'd be looking at modifying them to do rundocker run --rm -it blah blah blah
[2017-07-13 07:53:17] <airtonix> dv29: i assume it only needs to look at source code and doesnt require access to the local git repo
[2017-07-13 07:54:14] <airtonix> dv29: btw using docker-compose will make your commands cross platform across unix and windows
[2017-07-13 07:57:07] <dv29> we are using docker-compose
[2017-07-13 07:57:35] <dv29> the hook that we wrote requires access to local git repo
[2017-07-13 07:57:59] <klierik>  [<-CODE->]  [<-CODE->] 
[2017-07-13 09:02:13] <gdeverlant> To yall I wanted to know if it is possible inside of a Dockerfile to do a for loop in an array for to output a dynamic list of exposed ports give to an ENV variable?
[2017-07-13 09:06:30] <SISheogorath> gdeverlant: nope, you can't do any compute magic outside ofRUN. But when you want random ports, why not simply use the-Pparameter of swarm or the-p <port number>for the run statement, which will expose your ports to a random port on your machine
[2017-07-13 09:08:55] <SISheogorath> MaybeARGs work forEXPOSE
[2017-07-13 09:10:23] <gdeverlant> I have a build script which generates server settings based on params entered by user
[2017-07-13 09:11:01] <gdeverlant> I need to compile nginx with the ports that the user decided in the script
[2017-07-13 09:11:55] <gdeverlant> The best would be to just generate the Dockerfile for nginx based on the entries of the script
[2017-07-13 09:12:01] <gdeverlant> and then build the Dockerfile
[2017-07-13 09:13:13] <gdeverlant> would be amazing that someone confirms if exposed ports can be given by ENV variable
[2017-07-13 09:51:01] <gdeverlant> with multiple values
[2017-07-13 12:39:08] <comeUpWithItLater>  [<-LINK->] 
[2017-07-13 12:39:43] <comeUpWithItLater> what\'s the  context for the  "./httpd.conf"  in the config node?
[2017-07-13 12:48:45] <comeUpWithItLater> the config node cause erro Error response from daemon: page not found
[2017-07-13 12:49:20] <comeUpWithItLater> anyone have this issue b4 ?
[2017-07-13 15:23:10] <SISheogorath> comeUpWithItLater: What docker version are you running?
[2017-07-13 15:23:30] <SISheogorath> and what compose file version do you use?
[2017-07-13 23:40:56] <comeUpWithItLater> docker version :
[2017-07-13 23:40:58] <comeUpWithItLater> Docker version 17.06.0-ce, build 02c1d87
[2017-07-13 23:42:10] <comeUpWithItLater> compose file version :
[2017-07-13 23:42:11] <comeUpWithItLater> version: "3.3"
[2017-07-13 23:46:55] <comeUpWithItLater> on my local  machine [<-CODE->] 
[2017-07-13 23:47:31] <comeUpWithItLater> if I ssh into the one of the swarm  mode server:
[2017-07-13 23:48:49] <comeUpWithItLater>  [<-CODE->] 
[2017-07-14 00:26:27] <SISheogorath> docker version 17.03 doesn't supportconfig-> That's why you get the error
[2017-07-14 00:26:57] <SISheogorath> and that's why that can't work
[2017-07-14 00:27:19] <SISheogorath> you have to upgrade your swarm to 17.06 to use these features
[2017-07-14 00:40:19] <SISheogorath> All details: [<-LINK->] 
[2017-07-14 01:07:10] <comeUpWithItLater> got itmany  thanks
[2017-07-14 02:23:40] <w9n> hi, is there a tool to reverse engineer the changes i do on a container and create a Dockerfile from it?
[2017-07-14 06:33:49] <WillCup> how do you set storage driver for prd env?
[2017-07-14 06:34:57] <WillCup> docker: failed to register layer: devmapper: Error activating devmapper device for '24ea1e709520627a2862d2b9130b6aff77dde03fef39cc0169568cde5883b013': devicemapper: Can't set cookie dm_task_set_cookie failed.
[2017-07-14 06:35:50] <WillCup> And what's the meaning of above msg, whenever I run a container, I got this error
[2017-07-14 08:07:42] <SISheogorath> w9n: docker history
[2017-07-14 10:35:13] <jeserkin> SISheogorath: I read about networking as you suggested. But I do not understand how containers can communicate with each other in user-defined network.
[2017-07-14 10:35:44] <jeserkin> Can I reference by name?
[2017-07-14 10:37:18] <jeserkin> So if I have container1 and container2 in user-defined network, then this should work? Attach to container1 andping container2?
[2017-07-14 11:25:29] <SISheogorath> Yes. Simply use the container name
[2017-07-14 13:25:49] <daniel-halito> What versioning method do you guys apply when working with Dockerfiles? And do you use that method to create automated buils in Docker?
[2017-07-14 18:00:45] <vodnanmaga_twitter> has anyone installed google chrome  inside docker container (mac machine)
[2017-07-14 18:23:47] <MadMub> Hello. I’m developing a very unique application and it involves starting and stopping hundred of containers. So far on my Mac I’m only able to get 1.8 containers/sec (containerCreate + containerStart) using the golang sdk (which to my knowledge just invokes the http api)
[2017-07-14 18:24:34] <MadMub> does anyone know what kind of throughput docker can support? Does that number seem normal (about 1~2 container starts per second). I could not find much documentation on that kind of benchmark online
[2017-07-14 18:25:35] <MadMub> I’ve given my docker for mac 7 cores and 14gb of memory, and switched to the overlay2 storage driver, is there anything else I could try to get maximum startup performance, I am just running an alpine container that performssleep 600
[2017-07-14 18:43:46] <megamindbrian> vodnanmaga_twitter: SeleniumHQ/docker on GitHub has images with working chrome install.
[2017-07-14 18:44:46] <megamindbrian> vodnanmaga_twitter: it's painful the traditional way so use their commands from the Base/Dockerfile. Just a simple bash script with wget.
[2017-07-14 18:52:05] <vodnanmaga_twitter> megamindbrian: thanks! . will try that
[2017-07-14 19:15:36] <vodnanmaga_twitter> megamindbrian: Any example code that i can look into. kinda new to this
[2017-07-14 19:36:44] <megamindbrian> vodnanmaga_twitter:  [<-LINK->] 
[2017-07-14 19:38:56] <megamindbrian> vodnanmaga_twitter: The FROM statement is like inheritance so you may get have to do these steps first
[2017-07-14 19:39:24] <megamindbrian> vodnanmaga_twitter:  [<-LINK->] 
[2017-07-14 20:39:21] <lalib> here: hey there, is it possible to tag an image with multiple tags and push it to docker hub?
[2017-07-14 21:24:34] <SISheogorath> lalib: yes, it's possible. If you want to use automated builds it becomes a bit more difficult: [<-LINK->] 
[2017-07-15 11:47:15] <SISheogorath> vodnanmaga_twitter: this will become super hard, because doxker on mac runs inside a virtual machine and you have to bring the xsession outside which the again needs some kind of remote connection. So it doesn't really makes sense. For chrome in headless mode, I'm not aure about the details, but there was a problem with missing kernel capabilities last time I talked about/tried it.
[2017-07-15 11:52:07] <SISheogorath> MadMub: not running on macos possibly improves the number since you are outside of virtualization then. Also you can try to use ContainerLinux or CoreOS as base OS which may applies low level improvements to docker by optimizing the linux kernel.
[2017-07-15 15:22:04] <gdeverlant> Greetings@SISheogorath
[2017-07-15 15:22:11] <gdeverlant> hope you are having a good weekend
[2017-07-15 15:25:55] <gdeverlant> I have a question related with networking: I have a private registry and I'm trying to build another Dockerfile which reference to my private registry like FROM myprivateregistry:5000/danny/nginx:1.11. When drone tries to run the drone-docker-arm64 plugin in the background inside of its container I get this log : Get [<-LINK->] : dial tcp: lookup myprivateregistry on 127.0.0.11:53: no such hostWhat do I need to do so that my private repo which is a node in my cluster be recognized by its hostname?I don't want to endup with static ip addresses in my Dockerfile like : FROM 192.168.1.3:5000/danny/nginx:1.11
[2017-07-15 15:27:37] <gdeverlant> So basically drone agent which is a docker container running is running another DinD container on one of the nodes of the cluster
[2017-07-15 15:31:27] <gdeverlant> The sequence is shown like that
[2017-07-15 15:31:29] <gdeverlant>  [<-LINK->] 
[2017-07-15 15:41:42] <gdeverlant> all those containers are running on the same node in the cluster
[2017-07-15 15:41:59] <gdeverlant> the registry is in another node between the 12 nodes
[2017-07-15 17:49:37] <gdeverlant> my router is 192.168.1.1
[2017-07-15 17:49:45] <gdeverlant> the registry is on 192.168.1.2
[2017-07-15 17:50:04] <gdeverlant> and the CI server is on 192.168.1.13
[2017-07-15 17:50:19] <gdeverlant> they all have server1 to serverX as names
[2017-07-15 17:50:56] <gdeverlant> Like this diagram
[2017-07-15 17:51:18] <gdeverlant>  [<-LINK->] 
[2017-07-15 18:44:39] <kerbymart> Hello
[2017-07-15 20:00:23] <SISheogorath> gdverlant: Well, what you need then is to use an public DNS Server and reference the IP of your host service the registry. If you run it in swarm, then any swarm member. Or if you don't want to go for an public DNS server you have to provide a default DNS Server to your DinD instance which knows the needed DNS names.
[2017-07-15 20:00:51] <SISheogorath> kerbymart: Hi 
[2017-07-15 21:13:11] <iamvfl_twitter> Hey all! Anybody have any experience with Dokku?
[2017-07-15 21:13:52] <iamvfl_twitter> Having a really tough time getting my app to work with dokku and mongodb
[2017-07-16 04:10:45] <ninogomez> hi all. question.. so I have an app and selenium standalone containers, I can access the app by appContainerName:port, however there are parts of the app that redirects to localhost:port/session (ex), now since it's a test in selenium, the localhost:port/session doesn't exist in selenium container, I would like to know if there is a way to redirect localhost (in selenium container) to the app IP? Thanks a lot!
[2017-07-16 07:38:43] <SISheogorath> ninogomez: not really, and it doesn't make a lot of sense because in dockerlocalhostis broken. So it's better to fix the software
[2017-07-16 08:17:40] <gdeverlant> SISheogorath: Thanx for the answer
[2017-07-16 08:18:39] <gdeverlant> I was thinking about the private registry solution but I cannot imagine where do I need to set the DNS Server
[2017-07-16 08:19:06] <gdeverlant> and how can I provide to my DinD instance the custom dns address
[2017-07-16 08:52:34] <SISheogorath> Simply use the--dnsoption of the deamon
[2017-07-16 11:09:33] <Nublust> When using docker-compose (I'm running a webpack dev server in a container), is there a way to see what files are inside the volume IthinkI'm sharing my local files into?
[2017-07-16 11:11:24] <Nublust>  [<-CODE->] That is how I'm creating the volume in my docker-compose.yml file
[2017-07-16 11:12:02] <Nublust> (The config file is above my react app)
[2017-07-16 11:20:48] <SISheogorath> Simply usels ./react-appfrom the directory your docker-compose.yml is in.
[2017-07-16 11:22:58] <SISheogorath> If you want to have the "in container" view, usedocker exec -it $(docker-compose ps -q <servicename>) /bin/bashthen run ls for the path you specified
[2017-07-16 11:53:32] <w9n> hi im using docker via the remote api and some services require to mount single config files as volume. is there an easy way to upload a local config file or even adir to the remote server and mount it as volume via the docker api?
[2017-07-16 12:13:31] <SISheogorath> w9n: if you are using latest swarm mode, checkout the newdocker configsection. Otherwise, no.
[2017-07-16 12:17:48] <w9n> hm, i really miss such a feature... i can manually create a named volume and then scp the content into it but that feels very hacky
[2017-07-16 12:21:29] <MaxGoh> Hi guys. I currently have two repository for frontend and backend using Docker, along with a database. How can I deploy them to a server (preferably AWS) and map my frontend to example.com and my backend to api.example.com all on the same server. This is because it's a small application and there's no point getting 3 servers to host each layer separately.
[2017-07-16 19:39:30] <SISheogorath> MaxGoh: The word you are searching for is: Reverse Proxy
[2017-07-16 19:39:36] <SISheogorath> checkout Traefik.io
[2017-07-17 07:10:21] <airtonix> here: Co-worker is running docker  for windows (10 pro) inside parallels on a mac. parrallels has nested virtualisation on. He has host drive shared through parrallels into windows 10 as drive Y:. docker requests sharing drive Y when usingdocker compose run --rm --service-ports box npm run dev. but it fails shortly thereafter citing "failure with shared drive". additionally we can\'t add drive Y: through the settings interface with "docker for windows".
[2017-07-17 08:03:35] <jeserkin> Guys, isbuildproperty mandatory in docker-compose? Can I replace it withimageproperty completely?
[2017-07-17 08:14:05] <jeserkin> I am gettingERROR: build path XXX either does not exist, is not accessible, or is not a valid URL.
[2017-07-17 08:23:17] <janishorsts> Hi, what does "go version" mean in docker version?
[2017-07-17 10:22:52] <SISheogorath> janishorsts: since docker is written in golang, what do you think ;)
[2017-07-17 10:45:44] <jeserkin> SISheogorath: are you using docker on windows? Did you come across the message I provided above?
[2017-07-17 13:25:55] <yeryomenkom_twitter> Hello!Could your help me with docker-compose? How I can wait until my postgres docker image will be ready and only then start my another docker image.I read a lot about this subject but can not figure out how to achieve this.In this article ( [<-LINK->] ) mentioned script "wait-for-it.sh", but I can not understand where I should place this script.I`m pretty new in docker.
[2017-07-17 13:27:45] <pjetr>  [<-LINK->] 
[2017-07-17 13:28:37] <pjetr> all services listed underdepends_onmust run before the service you supplied them in can start
[2017-07-17 13:29:01] <yeryomenkom_twitter> pjetr: I do this already, but this is not actualy wait for postgres to start. Just for postgres container to start.
[2017-07-17 13:29:46] <pjetr> In that case, I'm out :-D
[2017-07-17 13:30:33] <yeryomenkom_twitter> pjetr: ))
[2017-07-17 14:48:39] <SISheogorath> jeserkin: sry, no windows over here anymore :/ even my Surface runs linux
[2017-07-17 14:50:22] <SISheogorath> yeryomenkom_twitter: place it in an entrypoint script for your image
[2017-07-17 14:50:56] <indigogoo> jeserkin: Even more here, even new windows runs linux
[2017-07-17 14:52:14] <jeserkin> indigogoo: what do you mean by that?
[2017-07-17 14:52:54] <indigogoo>  [<-LINK->] 
[2017-07-17 14:57:09] <jeserkin> LOL
[2017-07-17 14:58:17] <jeserkin> So windows more and more tells that do not use windows and use Ubuntu/Linux.
[2017-07-17 14:59:15] <creyke> Yes. Basically, if you\'re a .NET dev and want a job in 5 years time that isn\'t "keeping the lights on" it\'s time to learn Linux and bash :)
[2017-07-17 15:42:20] <SISheogorath> Or skip the .NET part :X
[2017-07-17 16:52:46] <jeserkin> I see. Well I might switch to unix system in future, but not with 1 day notice. Would love to solve this error though as soon as possible.ERROR: build path XXX either does not exist, is not accessible, or is not a valid URL.
[2017-07-17 17:03:26] <jeserkin> Okay. So as it turned out I am slow at thinking :D Tried to usedocker-composeon logical drive, that wasn't shared with docker.
[2017-07-17 17:05:38] <jeserkin> But for some reason containers still do not start. This is mydocker-compose.yml [<-CODE->] 
[2017-07-17 18:08:27] <vodnanmaga_twitter> @\\all has anyone integrated chrome with webdriverio . I usedwdio-chromedriver-serviceinpackage.jsonbut i am not sure of what will go inside dockerfile
[2017-07-17 19:14:16] <laytoneverson> Is it okay to combine services build from different parents? i.e. If I use the official Nginx service with a web service build from ubuntu? I'm just trying to maintain package versions equal to the versions installed on this vagrant box...
[2017-07-17 21:56:51] <SISheogorath> laytoneverson: what are you trying to build? In a image you can only have oneFROM. But since we have multi-staged builds, you can have oneFROMper build stage and then copy all needed files. But you have to make sure that your libraries are in place, if you use dynamic linked ones
[2017-07-17 22:39:21] <jeserkin> If my X containers are using user-defined network from docker-compose.yml, then how can inspect my user-defined network? I tried:docker network inspect backend, but it only givesError: No such network: backend
[2017-07-17 22:43:09] <SISheogorath> the point is that docker-compose names everything using a project prefix.
[2017-07-17 22:43:26] <SISheogorath> if you don't specify one, it's the directory name, where you started docker-compose
[2017-07-17 22:43:58] <SISheogorath> if you are not sure, usedocker network ls
[2017-07-17 22:53:37] <jeserkin> Yep. Sorry. Just realized it myself
[2017-07-17 22:53:54] <jeserkin> Nice
[2017-07-17 22:54:14] <jeserkin> Pretty sweet
[2017-07-17 22:54:23] <jeserkin> Thank you@SISheogorath
[2017-07-18 07:25:17] <FrankYu> Hi,  If I have install some package on host, should I install it in docker, or just use those on host?
[2017-07-18 12:21:16] <MaxGoh> Hi guys, I’m trying to deploy my app to AWS ECS
[2017-07-18 12:21:29] <MaxGoh> I’m just wondering, can I push all docker image to one instance?
[2017-07-18 12:21:39] <MaxGoh> Instead of running 3 instance for a simple web app
[2017-07-18 12:21:50] <MaxGoh> DB / Backend / Frontend
[2017-07-18 12:27:38] <stephencornelius> @MaxGoh yes you can run all on 1 instance. you can use the ecs-cli compose (http://docs.aws.amazon.com/AmazonECS/latest/developerguide/cmd-ecs-cli-compose.html)put all your containers in a single compose file as described above and use the cli to bring them up on your ECS instance. It will add all containers to the same instance
[2017-07-18 12:28:32] <stephencornelius> For the DB though you should either use RDS or a mounted volume otherwise you will lose your data if the instance goes down
[2017-07-18 13:42:19] <MaxGoh> Hey. Thanks for that! Just an add on question, how should I design my application then? As in like my backend and frontend are in seperate repository. And I normally start them by turning on backend and frontend separately with their own docker-compose.By having just one docker compose file for everything, does that mean that I have to merge everything into one repository? Thanks for the help too!
[2017-07-18 13:43:00] <MaxGoh> Because I want to use travis ci to automate all my pushes further on as well.
[2017-07-18 13:49:32] <stephencornelius> In that case the way you could do it is keep it as two separate compose files and run as two separate apps and link them through dns. If youre using ECS would recommend using an Application Load Balancer that can direct traffic based on host header. If you only run 1 instance in for ECS then it will still load both apps onto the same instance as thats all thats available
[2017-07-18 14:03:35] <MaxGoh> stephencornelius: , I see. but with regards to the cost, would it be the same, or would it be twice as much?
[2017-07-18 14:03:42] <MaxGoh> Because I would be running 2 instance instead of 1
[2017-07-18 14:05:30] <stephencornelius> No you would be running 1 instance but with 2 containers on it so would be the cost of the 1 instance
[2017-07-18 14:13:07] <MaxGoh> Oh, so I will set up everything in the cluster
[2017-07-18 14:13:14] <MaxGoh> And set up just one instance for it yeah.
[2017-07-18 14:13:15] <MaxGoh> Cool.
[2017-07-18 17:30:21] <w9n> hey, i would like to define my networks in seperate docker-compose files but it only returnsAttaching towhen i docker-compose -f  docker-compose.network.yml up with contentversion: '2'\nnetworks:\n  some-net:\n    driver: bridgeany idea why?
[2017-07-19 12:45:27] <MaxGoh> Unable to find image 'hello-world:latest' locally\ndocker: Error response from daemon: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers).
[2017-07-19 12:45:37] <MaxGoh> Anyone know why I’m getting this error?
[2017-07-19 12:45:41] <MaxGoh> I can’t seem to fix this?
[2017-07-19 12:45:49] <MaxGoh> Uninstalled, set to no proxy, etc
[2017-07-19 12:45:52] <MaxGoh> Nothing works
[2017-07-19 21:20:37] <SISheogorath> MaxGoh: are you sure your machine is allowed to access registry-1.docker.com? To test, maybe trywget
[2017-07-20 02:09:51] <tankdeper> hi? does anyone use wnameless/oracle-xe-11g image?
[2017-07-20 12:06:53] <rralf> Hi, I'm conducting a (really short) survey on classification of commits in software repos. Your expert insights are helpful for finding established categories. I'd appreciate if some of you could help me and spend 5 minutes on [<-LINK->] . Thanks!
[2017-07-20 13:27:07] <vodnanmaga_twitter> when trying to install google chrome from SeleniumHQ/docker-selenium on my mac machine running docker, I get/bin/sh: apt-key: command not found.  Anybody have any idea on how to resolve this?
[2017-07-20 14:48:02] <MaxGoh> Hi guys! Anyone familiar with serving flask w/ nginx & uwsgi in Docker?
[2017-07-20 15:27:13] <SISheogorath> MaxGoh: I would suggest you to read this guide: [<-LINK->] 
[2017-07-20 15:28:06] <SISheogorath> vodnanmaga_twitter: can you provide a bit more context? What image did you used, where did you get the error message, ...
[2017-07-20 15:40:10] <MaxGoh> SISheogorath: Sorry, I have been googling all over,  and I’m still stuck on the issue. I’m not even sure where to begin with, if I should have a single Dockerfile or use docker-compose. I’m trying to use this for production.
[2017-07-20 15:40:25] <MaxGoh> So I’m checking if there’s anyone who is experienced in this area who could give me some guidance.
[2017-07-20 15:41:02] <vodnanmaga_twitter> SISheogorath: I resolved it. It appears that the base image i was using was centOS 7. cent apparently usesyumnotapt-get. So i had to install chrome usingyum.
[2017-07-20 15:44:18] <SISheogorath> @vodnanmaga_twitter
[2017-07-20 15:47:34] <SISheogorath> MaxGoh: Go the regular way: First of all check for other flask applications and how they do it. Docker hub is a good place to start. Check for minimal images, but use a base image you know. If you are not good with alpine, search for something debian based instead. Then check their repositories, the less additional files you need, the better it is. Last but not least, start building something. Play around to get a working version. Once it works, share it and you will get suggestions
[2017-07-20 18:18:16] <fny> Hey all, we have a bunch of Debian containers we're looking to deploy on RHEL. If both environments use the same Linux kernel, are there any other compatibility issues we might run into?
[2017-07-20 22:02:29] <SISheogorath> fny: if you don't do very low level related this, there are usually no problems
[2017-07-21 02:07:25] <MaxGoh> SISheogorath: Thanks for that, I have finally managed to got uwsgi working with my Flask this morning before I crashed.
[2017-07-21 02:07:42] <MaxGoh> I’ll try to point out the exact gist of the problem next time :)
[2017-07-21 02:08:16] <MaxGoh> Now I’ll just have to finish up serving uwsgi+flask with nginx in my Dockerfile tonight.
[2017-07-21 04:45:09] <alaverty> Anyone have a solution for encrypting a docker containers mounted volume when I don't have access to change things on the underlying host? Was looking at LUKs but seems that changes the docker engine config and would apply to all containers, i only want to change one.
[2017-07-21 07:22:33] <SISheogorath> alaverty: how would you do it without docker?
[2017-07-21 19:09:04] <basz> having little trouble to log into a private registry behind a proxy. which port would this command try to connect todocker login registry.example.com? 5000 or 443?
[2017-07-21 22:40:07] <SISheogorath> If you don't add a port it would try to use HTTPS default port -> 443
[2017-07-22 00:48:34] <alaverty> SISheogorath: I think running something from within the container that encrypts the disk would be how i would want to approach it
[2017-07-22 04:59:38] <SISheogorath> alaverty: that wasn't really the question, the point is that you can do nearly everything within Doxker as you do it outside. The notation maybe differs. So if you know what file system you would use with what parameter, you can create suxh a volume, that writes data encrypted
[2017-07-22 05:01:47] <SISheogorath> But keep in mind if you don't set it up in a way, where you always recreate the volume on startup of the right container, you can simply attach another container to this volune and read it.
[2017-07-23 02:16:43] <sabrehagen> Hi all, I've always usedEXPOSEin my Dockerfiles, however other than informing the user, I can't see a technical/functional purpose for it. Is there any use includingEXPOSEin my Dockerfiles?
[2017-07-23 05:34:28] <SISheogorath> sabrehagen: the technical "details" ofEXPOSEare here: [<-LINK->] 
[2017-07-23 05:35:27] <SISheogorath> So, yes,EXPOSEis mainly used to inform users. But if you want to use-Pit can be useful.
[2017-07-23 05:37:11] <SISheogorath> For example when you have an external reverse proxy that interacts with the docker API you can use -P to create your container and expose the ports to a random port which is then again recognized by the external load balancer and allows redirecting traffic to the right places
[2017-07-23 23:30:36] <pydo> How do I reuse the same docker container with the run command? I run my container like thisdocker run -ti --name <container_name>but it always creates a new container. I don't believe the docker getting started tutorial covers this [<-LINK->] 
[2017-07-23 23:36:52] <pydo> Seems like I have to start the containers in detached mode and then I can reattach my shell after
[2017-07-24 00:00:26] <pydo> What's the point of persisting container data to a volume on the host os? I restarted a container that didn't  have any volumes mounted  and after it restarted all the original data was still there.
[2017-07-24 11:19:03] <HendrikRoth> pydo: when you recreate the container, the data is lost.
[2017-07-24 13:46:59] <basz> Hio! using a docker machine to provision nodes. The manager node has TLS setup automaticly. However those certificates are only valid when used from localhost (which makes sort of sense). However I’m trying to do a deployment from a gitlab ci build. I created a certificate that is valid for my domain and 127.0.0.1 but now I am unsure where to install those locally? Would be nice if docker-machie could allow for additional comman names…error during connect: Get https://docker-swarm.example.com:2376/v1.30/version: x509: certificate is valid for localhost, not docker-swarm.example.com
[2017-07-24 14:37:58] <basz>  [<-ISSUE->] 
[2017-07-24 15:01:14] <SunChero> hi guys .. im trying to build a new image  from a dockerfile .. but the build process is still using an old RUN statement which is causing errors .. even when the dockerfile is updating .. the build process keep using the old command
[2017-07-24 15:01:22] <SunChero> am i missing something here ?
[2017-07-24 15:02:23] <tudvari-nng> SunChero: Could you try the -no-cache option for the build command please?
[2017-07-24 15:02:42] <SunChero> already did ..
[2017-07-24 15:03:29] <SunChero> this is a simple change from adduser to usedadd  .. the build keep giving me errors related to adduser statement .. event if the dockerfile  now is using useradd
[2017-07-24 15:04:07] <SunChero> is there a way to clean up things and start from scratch ?
[2017-07-24 15:42:40] <matrixbot> YvesHow do we control Docker memory in a version 3 compose file? mem_limit is now allowed anymore and deploy only works with swarms
[2017-07-24 15:48:54] <SISheogorath> Yves: if you don't usedocker stackthere is no real reason to use version 3.
[2017-07-24 15:52:51] <SISheogorath> And you can maybe limit it using ulimits. But you should maybe file a bug report about it
[2017-07-24 15:55:51] <SISheogorath> SunChero: as@tudvari-nngpointed out, build it with--no-cacheas parameter. And be if there is an error message during build, ir would be useful to provide it along with the Dockerfile you have the problem with.
[2017-07-24 17:39:06] <elclanrs> How do I set--build-argindocker-composefor multiple services? I can set it for one service like:docker-compose build --build-arg http_proxy="http://my.proxy:8080" my-service
[2017-07-24 21:49:57] <imaia> Anyone managed to setup [<-LINK->] 
[2017-07-24 21:50:08] <imaia> I'm getting a 502 error : /
[2017-07-25 01:47:43] <jwilson8767> imaia: , I've failed to get that working on two separate occasions. If you figure it out please tell me.
[2017-07-25 07:29:40] <SISheogorath> elclanrs:  [<-LINK->] 
[2017-07-25 07:31:54] <SISheogorath> imaia: I would suggest you to use a reverse proxy with these feature built-in, like Traefik
[2017-07-25 07:32:26] <SISheogorath> But if you really want to use this image, you should maybe file a bug and see how maintained it is?
[2017-07-25 07:32:58] <SISheogorath> Oh just saw you already did
[2017-07-25 12:55:43] <donnib> If i have a container running with a folder /data that is not mounted as a volume, what happens to the data that's in that folder if i restart the container now with mounting the data folder to local host folder data ?
[2017-07-25 13:05:59] <SISheogorath> donnib: Well, that's a question you can ask more general: What happens to the data that is placed below a mount point?
[2017-07-25 13:06:56] <SISheogorath> But to answer your question specific: You can't simply mount a volume on restart. You can only recreate the container which vanishes the old one so the data is gone, too.
[2017-07-25 13:29:03] <donnib> SISheogorath: gotha....so i'll just have to get my data out then recreate the container with the volume mounted, how do i copy recursive from the container my data out ? I tried docker cp -a but i get an error that -a not defined
[2017-07-25 13:29:31] <SISheogorath> why-a?
[2017-07-25 13:30:00] <SISheogorath> docker cp <containerid>:/data ./datashould be enough
[2017-07-25 13:30:58] <donnib> thank you, i misread the doc where it was stated that cp = cp -a
[2017-07-25 18:36:25] <elclanrs> is there a way to pointcommandindocker-compose.ymlto a file in the host?
[2017-07-25 18:36:48] <elclanrs> likecommand: bash /file/in/host
[2017-07-25 18:36:58] <elclanrs> or do I need to add a volume?
[2017-07-25 18:44:15] <carlosjgp> elclanrs: You need a volume or copy the file on your image during build
[2017-07-25 18:56:57] <elclanrs> carlosjgp: thanks I think i'm gonna use a volume
[2017-07-26 07:39:13] <cavapoo2_twitter> been using docker toolbox on windows everything ok. now i've changed to ubuntu. it says for ubuntu server, i can still use this on ubuntu desktop can i ?
[2017-07-26 07:41:39] <cavapoo2_twitter> this is for docker ce, i can't get docker toolbox for linux
[2017-07-26 07:43:05] <tudvari-nng> cavapoo2_twitter: : you’re right, it isn’t exists a docker toolbox for linux, you can use docker itself from the ubuntu apt repository.
[2017-07-26 07:44:18] <cavapoo2_twitter> do you know what difference between docker ce and docker toolbox
[2017-07-26 07:48:04] <cavapoo2_twitter> seems like docker ce need 64bit cpu.
[2017-07-26 07:48:22] <tudvari-nng> docker ce is the community edition for linux systems, and docker toolbox is utility to use docker on windows and osx
[2017-07-26 10:59:46] <SISheogorath> Docker toolbox more precisely provides a tooling around a Linux VM with docker-ce installed
[2017-07-26 11:00:09] <tudvari-nng> +1
[2017-07-26 11:01:39] <SISheogorath> So simply install docker-ce and it works. Easiest way to install it: open a terminal and typewget -O- https://get.docker.com/ | sh
[2017-07-26 15:26:07] <cavapoo2_twitter> SISheogorath: thanks. i will give that a try
[2017-07-26 18:18:21] <elclanrs> How can I set the proxy vars in Docker for macOS through the terminal,withoutusing the GUI?
[2017-07-26 18:20:52] <rhyek> while doingdocker-compose up --build, why are cached images used for my application container where apackage.jsonhas changed during development? this makes it so I keep gettingmodule x not founderrors unless I wipe them withrmi....
[2017-07-26 18:20:56] <elclanrs> Or is there a way I can read the variables set through the GUI in my terminal? I need to use these vars for--build-arg http_proxy
[2017-07-26 18:21:20] <elclanrs> Currently I have to set them twice, once in the Docker GUI, and once in the docker-compose args
[2017-07-26 18:21:35] <elclanrs> the Docker GUI proxy vars is for downloading images, and the build args are for the container
[2017-07-26 18:21:42] <elclanrs> I want to reuse the same exact variables in some way...
[2017-07-26 21:06:00] <oanapat> Hi everyone, is this the correct room to ask advice about an error I am getting? (don't want to spam :) )
[2017-07-26 21:48:11] <SISheogorath> oanapat: feel free to ask, we will see if we can help
[2017-07-26 21:53:02] <oanapat> Ok, great!I am trying to dockerize an Angular2 app following the main steps in this doc (https://scotch.io/tutorials/create-a-mean-app-with-angular-2-and-docker-compose)Once everything is configured, I do a docker build (it builds my image succesfully)The error appears after I run the last command: [<-CODE->]  [<-CODE->] 
[2017-07-26 21:55:39] <SISheogorath> What did you try to call? What did you set asCMD
[2017-07-26 21:55:56] <oanapat> CMD npm start
[2017-07-26 21:56:10] <oanapat> I found a suggestion on stackoverflow
[2017-07-26 21:56:33] <oanapat> not sure I missread it or not...
[2017-07-26 22:08:45] <SISheogorath> What is your base image?
[2017-07-26 22:41:56] <oanapat> node 8
[2017-07-27 14:20:18] <devedse> Hey all, I\'m running into this error message when building a docker image:Error parsing reference: "microsoft/dotnet:2.0.0-preview2-sdk-stretch AS builder" is not a valid repository/tag: invalid reference format
[2017-07-27 14:20:55] <devedse> (This is on a remote server, locally building docker docker image works)
[2017-07-27 17:49:22] <basz> Hi, I would like to use [<-CODE->]  [<-CODE->] 
[2017-07-27 21:46:44] <luchillo17> Hi, i'm trying to make a docker file with a volume, trying to useARGlike this:
[2017-07-27 21:48:44] <luchillo17>  [<-CODE->] However the output goes like this:
[2017-07-27 21:48:49] <luchillo17>  [<-LINK->] 
[2017-07-27 21:50:45] <luchillo17> Note that first ADD succeeds, but second one seems to be executed from within the docker image temp folder.
[2017-07-28 07:17:05] <crazygit>  [<-LINK->] 
[2017-07-28 07:17:38] <crazygit> Hello, Can any body help me, env $JAVA_OPTS  not work, when docker run output isError: Could not find or load main class ${JAVA_OPTS}
[2017-07-28 08:32:35] <SISheogorath> basz: no, docker isn't using port 22. That's a host thing where may or may not an SSHd is running
[2017-07-28 08:33:52] <crazygit> I firgout , env var not work in ENTRYPOINT or CMD when use exec format
[2017-07-28 08:33:54] <basz> SISheogorath: thanks, i took the gamble. All I needed to do is change port in .docker/machine/machines/node-*/config on my local box and all was fine
[2017-07-28 08:38:09] <SISheogorath> luchillo17: doxker uses a so called build-context which is usually your repository you use to build your image. The build context directory is specified by as the unnamed parameter of thedocker buildcommand. So for exampledocker build reposets the build context to therepodirectory. Notice: Since docker build the entire thing in using the docker daemon it sends the entire directory to the daemon to build your container. That's why you can only use paths relative to the context abd why you shouldn't and can't add files from outside
[2017-07-28 08:39:01] <SISheogorath> crazygit: yes. That's normal.
[2017-07-28 10:37:32] <luchillo17> I see, so i have opted for making a copy of such files in a folder inside the repo, then tell the dockerfile where to paste when installing, is that better?
[2017-07-28 11:45:50] <SISheogorath> I would simply use an entrypoint script
[2017-07-28 11:46:12] <SISheogorath> Means write it to an.shfile
[2017-07-28 12:52:03] <cavapoo2_twitter> amd64  also applies to intel64 ?
[2017-07-28 12:53:11] <cavapoo2_twitter>  [<-LINK->] 
[2017-07-28 12:53:35] <cavapoo2_twitter> installing on ubuntu 64 bit, i have intel
[2017-07-28 12:53:55] <tudvari-nng> cavapoo2_twitter: it's fine for you
[2017-07-28 12:54:33] <cavapoo2_twitter> ok confusing saying amd though is it :)
[2017-07-28 13:15:28] <luchillo17> I'm having a different issue, i'm trying to source the.bash_profilei copy to the/root/folder but both the docker commandRUN source /root/.bash_profileand the source command in ainstall.shscript returnssource: not found.
[2017-07-28 13:17:23] <luchillo17> Oh ok, if i put this#!/bin/bashon top of theinstall.shit sources now, however the source of such file fails telling me that an alias is not found, which is actually defined 3 lines up in the same.bash_profile.
[2017-07-28 13:19:52] <luchillo17> Same file works in my Mac and another Ubuntu i have in home, why wouldn't in the container? isubuntu-serverthat different?
[2017-07-28 13:28:48] <cavapoo2_twitter> im also seeing difference, some scala code worked fine on windows. The command is run issbt clean docker:publishLocal. Error is permissions[error] Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock:`
[2017-07-28 13:30:31] <cavapoo2_twitter> seems like on ubuntu i need to usesudo docker
[2017-07-28 13:31:39] <cavapoo2_twitter> is there a way of baking the sudo into sbt
[2017-07-28 13:32:03] <cavapoo2_twitter> at com.typesafe.sbt.packager.docker.DockerPlugin$.publishLocalDocker(DockerPlugin.scala:302)
[2017-07-28 14:03:55] <cavapoo2_twitter> there's also the linux post install section i've not read yet. i'll read this and then try again .
[2017-07-28 14:18:44] <cavapoo2_twitter> yes updatingsudo usermod -aG docker $USERfixed first problem. next problem is running thedocker-composecommand which previously worked on windows toolbox, docker does not recognise on ubuntu-server
[2017-07-28 14:26:39] <cavapoo2_twitter> so docker-compose i have to download seprately for ubuntu
[2017-07-29 01:30:50] <rbalicki2> hi folks, I am new to using docker and I have a chicken-and-egg problem. Mydocker build -t myproject .command requires access to postgres, because I am generating code based on postgres schemas
[2017-07-29 01:31:29] <rbalicki2> however, it looks like if I set that up usingdocker-compose.yml, it needs to be published. For it to be published, it needs to be built
[2017-07-29 01:31:37] <rbalicki2> What am I missing here?
[2017-07-29 01:33:14] <karanhiremath> rbalicki2: build yourself an image doing everything up until you need to generate the code for all your dependencies up to that point. then set up your docker-compose with postgres and build a new dockerfile which builds from the first image you created that now handles all the code generation
[2017-07-29 01:33:44] <karanhiremath> you can also make a dockerfile to setup the schema in postgres for you
[2017-07-29 01:34:08] <karanhiremath> unless you are handling that in your application dockerfile at some point
[2017-07-29 01:34:30] <rbalicki2> ah
[2017-07-29 01:34:59] <rbalicki2> I think I can't do the latter, because the schema is managed via migrations and is subject to change
[2017-07-29 01:35:57] <rbalicki2> could you clarify the first sentence?@karanhiremath
[2017-07-29 01:37:09] <karanhiremath> sure - happy to help as much as i can let’s go to direct messaging
[2017-07-29 01:37:15] <rbalicki2> thank you
[2017-07-29 02:17:00] <srkadiyala> Hi All,We have to use Oracle JDK 8 and saw lot of vulnerability with Docker image scanning. When we are using open JDK 8 better. But we are still seeing vulnerability.what is the oracle JDK 8 image to include that can pass Docker image scan?Thanks
[2017-07-29 07:10:00] <Jackiegm> Hello guys,I want to build an image like nvidia/cuda,which can make use of physical host's gpu.how?thks
[2017-07-29 07:21:59] <cavapoo2_twitter> is there a way to test if docker-compose is installed correctly ?
[2017-07-29 07:22:17] <cavapoo2_twitter> like docker-compose --help
[2017-07-29 07:24:16] <karanhiremath> cavapoo2_twitter: what are you looking for? just running it without a .yml file for me returns the help instructions, you could try-vif you just want to verify that its installed and get the version or run a simpledocker-compose.ymlfile in—verboseif you aren’t seeing enough output and want to debug further
[2017-07-29 07:24:35] <karanhiremath> Jackiegm: interested as well would love to learn more
[2017-07-29 07:25:10] <cavapoo2_twitter> i think its broke sincedocker-compose --versionreturns noting.
[2017-07-29 07:25:27] <cavapoo2_twitter> proably explain why things not working
[2017-07-29 07:25:36] <karanhiremath> docker-compose is a seperate install from main docker
[2017-07-29 07:25:40] <karanhiremath>  [<-LINK->] 
[2017-07-29 07:25:50] <cavapoo2_twitter> yes i followed those
[2017-07-29 07:26:04] <karanhiremath> what OS are you using?
[2017-07-29 07:26:16] <cavapoo2_twitter> ubuntu 1604 64bit
[2017-07-29 07:26:18] <karanhiremath> and which installation method did you choose?
[2017-07-29 07:27:05] <cavapoo2_twitter>  [<-LINK->] 
[2017-07-29 07:28:08] <karanhiremath> hmmm ok never tried to install on ubuntu so not sure if there are any pitfalls to avoid but its definitely possible we have devs on our team using it on ubuntu
[2017-07-29 07:28:46] <cavapoo2_twitter> going try again.
[2017-07-29 07:29:06] <cavapoo2_twitter> total breeze on windows :)
[2017-07-29 07:29:19] <cavapoo2_twitter> with the toolbox
[2017-07-29 07:29:31] <karanhiremath> could be documetation problem, maybe try a different guide [<-LINK->] 
[2017-07-29 07:30:13] <karanhiremath> looks like that might be the case actually in the brief run through of the docker-ce guide i ran through
[2017-07-29 07:30:43] <karanhiremath> looks like the docker-compose instructions for ubuntu just redirect to docker-ce but those don’t specify how to actually install docker-compose on ubuntu
[2017-07-29 07:30:52] <cavapoo2_twitter> ok 'ill try this other guide
[2017-07-29 07:47:48] <cavapoo2_twitter> thanks at least nowdocker-compose -vcome sback with something
[2017-07-29 07:57:25] <cavapoo2_twitter> sudo wget https://github.com/docker/compose/releases/download/1.15.0/docker-compose-uname -s-uname -m> /usr/local/bin/docker-composethis never worked from these instructions [<-LINK->] 
[2017-07-29 09:35:18] <karanhiremath> when you rununame -swhat’s your output
[2017-07-29 09:35:24] <karanhiremath> could be related to that
[2017-07-29 10:09:16] <cavapoo2_twitter> comes back with Linux
[2017-07-29 10:09:53] <karanhiremath> and what aboutuname -m?
[2017-07-29 10:10:45] <cavapoo2_twitter> x_86_64
[2017-07-29 10:10:52] <karanhiremath> ahhh theres the issue
[2017-07-29 10:11:09] <karanhiremath> was there actualy an underscore between x and 8 when you ran it?
[2017-07-29 10:11:25] <karanhiremath> the github release is named x86_64
[2017-07-29 10:11:30] <karanhiremath> so its possible thats the issue
[2017-07-29 10:11:32] <cavapoo2_twitter> sory i meanx86_64
[2017-07-29 10:11:35] <karanhiremath> hmmm
[2017-07-29 10:12:21] <cavapoo2_twitter> also curl would not let me install, permission issue. wget was ok though
[2017-07-29 10:13:06] <cavapoo2_twitter> mybe issue with 1.15.0
[2017-07-29 10:13:33] <cavapoo2_twitter> is that ok to use with 16.04 ubuntu
[2017-07-29 10:15:39] <cavapoo2_twitter> its working now, but i'll try again with 1.15.0 since that is newer  / fewer bugs version supposedly ?
[2017-07-29 10:23:08] <karanhiremath> hmmmwget https://github.com/docker/compose/releases/download/1.15.0/docker-compose-\\uname -s`-`uname -m``
[2017-07-29 10:23:52] <karanhiremath> damn does markdown now use standard escape chars?
[2017-07-29 10:23:59] <karanhiremath> ``wget https://github.com/docker/compose/releases/download/1.15.0/docker-compose-uname -s-uname -m````
[2017-07-29 10:24:27] <karanhiremath>  [<-CODE->] 
[2017-07-29 10:24:38] <karanhiremath> works for me
[2017-07-29 10:25:23] <karanhiremath> granted on an ubuntu image lol but maybe the issue is in the permissions? what does this give you?
[2017-07-29 10:25:48] <karanhiremath>  [<-CODE->] 
[2017-07-29 10:26:07] <karanhiremath> it looks likecurltries to download the redirect file
[2017-07-29 10:28:20] <karanhiremath> -L flag fixes that though
[2017-07-29 10:28:42] <karanhiremath> def looks like a permissions thing - may need to add that step to the documentation
[2017-07-29 10:29:17] <karanhiremath> chmod +xshould fix it
[2017-07-29 10:29:38] <karanhiremath> oh its in there already
[2017-07-29 10:30:32] <karanhiremath> hmmm not sure try again maybe and let me know directly how it goes happy to help suggest a change to the documentation
[2017-07-29 10:47:44] <cavapoo2_twitter>  [<-CODE->] 
[2017-07-29 10:48:15] <cavapoo2_twitter> then achmod + xafter
[2017-07-29 10:55:45] <cavapoo2_twitter> is there also a way to clean up what docker did with the network (ifconfig). after stopping the containers and remove images, ifconfig still has some network mappings
[2017-07-29 11:11:22] <cavapoo2_twitter> other thansudo ip link delete name
[2017-07-29 15:04:39] <rbalicki2> hi folks, is there a way to view all the logs of a call todocker stack deploy? The pertinent information I want is on the top of the logs, but those seem to be gone by the time I get todocker pscopy-paste the iddocker logs -f <id>... edit: running&& docker logs -f $(docker ps | head -n 2 | tail -n 1 | awk '{print $1}')is not fast enough :(
[2017-07-29 15:05:33] <rbalicki2> I'm writing out theawkcode now to extract the id, but I figure there might be a simpler way?. Edit: NVM, just put the relevant part in my dockerfile instead of in the compose
[2017-07-29 15:05:56] <srkadiyala> Hi All, repeat post We have to use Oracle JDK 8 and saw lot of vulnerability with Docker image scanning. When we are using open JDK 8 better. But we are still seeing vulnerability.what is the oracle JDK 8 image to include that can pass Docker image scan?Thx
[2017-07-30 14:55:46] <MaxGoh> Hi guys, I’m currently running Amazon Web Service ECS service. I’m using a docker-compose reverse proxy architecture. So everything is pretty neat right now which have all my services set up on one server. So right now, I’m trying to enable SSL for my web application, I tried using the Application Load Balancer with Amazon Certificate Manager to no avail. Anyone here can guide me on how you got it up?
[2017-07-30 18:21:43] <johnrizzo1> Hey guys… I’ve been looking for information about what can go into the docker config file and I just can’t find it. This doesn’t seem to have the info I’m looking for [<-LINK->] 
[2017-07-30 18:22:06] <johnrizzo1> I am trying to figure out how to set a default docker repo.
[2017-07-30 20:27:24] <stephencornelius> MaxGoh: what isses did you run into? you need to use an application load balancer. create a listener on that for port 443. you then create a target group which you point at your service. You also need to create a rule for you to route requests to your ALB to the correct target group, this is created within the listner on  the ALB. I use host based routing so have a rule for api.example.com pointing to api target group. Something to note about the target group is it has a health check associated with it. if that check is failing it will kill your service so need to ensure that passes, the status is displayed within the target group info. Also if using host based routing you will need to setup dns for the host url cnamed to your ALB url. Theres also the alternative of path based routing on the ALB
[2017-07-30 20:40:22] <SISheogorath> johnrizzo1: docker configisNOTfor the configuration of the docker daemon. It's for config objects in swarmmode. Don't mix this up. I know that RedHat uses multiple default registries but I'm not sure if they used did that by changing the source code. May you can find something useful here: [<-LINK->] by changing the default mirror registry
[2017-07-31 00:57:37] <johnrizzo1> Thanks
[2017-07-31 00:58:13] <johnrizzo1> I see so we configure the daemon to use the registry not the command line…. :)
[2017-07-31 03:07:21] <MaxGoh> stephencornelius: Hi, yeah I’m pretty sure I did that, created a ALB with ACM issued certificate, then I created a target group and added my running instance in it. I then added the ALB DNS to my Cloudflare, and right now it’s showing "400 Bad Request The plain HTTP request was sent to HTTPS port”, If it helps, my nginx conf.d files only listens to port 80 with no ssl configured, But I read that using the ALB, everything should be configured on there and not on nginx itself.
[2017-07-31 10:37:13] <stephencornelius> MaxGoh: did you set your target group up as http protocol and on port 80? looks like that error is being returned from the nginx container. sounds like youre sending it a https request whereas its only serving on port 80. you could test your alb with a listener on port 80 to make sure that works
[2017-07-31 10:40:14] <MaxGoh> Yes, I did set it up on a target group, and yes to the error on nginx as well. Okay, I'll try to twitch around it. One quick question, right now I'm using cloudflare to point to my ec2 instance. So I have 2 sub domains to it. And using ALB, I have to point cloudflare to ALB DNS. It would probably show my frontend fine. But how can I access my backend say api.example.com?
[2017-07-31 11:51:41] <stephencornelius> MaxGoh: im not sure i understand. your backend is running on ECS as well? every app that runs on ECS give it a separate sub domain and cname to the ALB DNS
[2017-07-31 11:56:25] <MaxGoh> Hm. as in like I'm running a reverse-proxy Docker-compose architecture. Meaning I have a nginx that then calls my internal services (frontend and backend). So, my external nginx listens for different URL. api.example.com and example.com. They are all running on a single instance.
[2017-07-31 11:57:05] <MaxGoh> So do I have to create multiple ALB to map to different subdomain?
[2017-07-31 12:27:32] <stephencornelius> ok. no you just need to create separate rules. so you would have 2 sub domains. on your alb you create 2 rules. 1 for api.example.com and 1 for example.com both of which could go to the same target group which presumably is nginx and then that handles routing to the correct service based on the url
[2017-07-31 15:22:54] <ehernandez-xk> Hello all!I have read about Docker installation, Since the Docker daemon runs only with sudo, I understand that users can mount filesystem directories and do things like sudo, is there a way to prevent this? for example I would like to restrict the user only to mount directories in his $HOME scope.Thanks for the help
[2017-07-31 17:44:57] <DWSR> Hey everyone, I'm curious how others solve this: I am running a Swarm in AWS defined by Terraform. The worker nodes are in an ASG so that we can automatically scale out. When a scale-out occurs, the works are successfully added to the swarm via User Data. When a scale-in operation occurs, the node is drained, but also left in a state where the swarm lists it. Is there a way to clean this up, as I can easily see a scenario where, after a few dozen scale-out and scale-ins, the list of nodes is ~90% nodes that no longer exist.
[2017-08-01 00:28:20] <SISheogorath> Nope, Eddy, that's not possible. Sonce the docker daemon has to run as root to work. Maybe you can write or find an auth-plugin that provides such a customizablity but my guess is you want to use docker for desktop apps which is something docker isn't made for. I would suggest you to look for appimage, flat packages or snap apps. They are made for desktop applications and non-admin work
[2017-08-01 07:53:27] <Speechkey_twitter> Hi folks. What happends if I’m using a syslog driver and the syslog-host goes down for a minute?
[2017-08-01 09:31:26] <SISheogorath> Speechkey_twitter: what happens when you use syslog logging in any other software and the syslogd is not available?
[2017-08-01 09:35:08] <SISheogorath> DWSR: checkdocker node lsanddocker node rmon your manager nodes. The swarm can't know if the node is down or dead. You have to remove them. Or (and I'm not completely sure about this right now)doxker swarm leavemaybe works, too
[2017-08-01 10:06:07] <rohitcelestial> Hi all,Can someone please share code reloading example for docker dev env with Node JS (nodemon)Have searched many links on Google but most are not reloading code. Seen examples with copying package.json and the npm install but most are not working.I have been trying this for 2 days. Please share anything working if possible.Any help would be appreciated.
[2017-08-01 13:04:39] <imaia> jwilson8767: I managed to make it work. The problem is that it won't couple with a underlying nginx server; I'll probably have to mess with the template to make it work. Great project, but still needs some tunning (which is perfectly natural)
[2017-08-01 13:10:27] <imaia> rbalicki2: two containers, then?
[2017-08-01 13:33:26] <ehernandez-xk> Thanks@SISheogorath, I'm using docker in dev servers also
[2017-08-01 13:34:57] <SISheogorath> ehernandez-xk: then maybe consider to use dind or a kvm based virtualisation to provide everybody an own machine. for dind maybe this is interesting for you: [<-LINK->] 
[2017-08-01 15:42:48] <jwilson8767> Just finished [<-LINK->] . Would someone please test it and provide feedback? I'm really curious how well it works.
[2017-08-01 15:44:02] <jwilson8767> imaia: The tuning was where I stalled out and decided to revert to my previous approach.
[2017-08-01 17:18:50] <imaia> jwilson8767: the fellows are replying in the issues tab; maybe something good will come out of it
[2017-08-01 17:28:23] <DWSR> SISheogorath: docker swarm leavedoes not clean up the nodes either. You mustdocker node rmthem manually. I'm wondering how this is done in a large swarm deployment where nodes may be added or removed based on demand.
[2017-08-01 17:28:48] <SISheogorath> DWSR: Thanks for the info. I wasn't sure about that ^^
[2017-08-01 17:29:33] <SISheogorath> you simply run write a script that makes sure only the existing nodes exist.
[2017-08-01 17:29:50] <SISheogorath> every usual provisioning software should be able to do that
[2017-08-01 17:30:03] <SISheogorath> you have an HTTP API, so use it ^^
[2017-08-01 18:04:58] <DWSR> SISheogorath: Yeah, I was hoping that that cleanup would be built into Docker, but not to worry if it's not.
[2017-08-01 18:05:20] <DWSR> SISheogorath: Another interesting question: Is it possible to automate the registration of a Swarm into Docker Cloud (using BYOS)?
[2017-08-01 18:06:27] <SISheogorath> Tbh I have no idea. I'm not a Docker Cloud user.
[2017-08-01 18:30:25] <DWSR> Ok, no worries. I think manual registration will probably be OK for now.
[2017-08-02 15:23:39] <Barrakkuda> hello everybody
[2017-08-02 21:48:35] <SISheogorath> Hi
[2017-08-03 01:49:44] <Yusadolat> Hello@DWSR
[2017-08-03 01:49:53] <Yusadolat> Hope you are fine
[2017-08-03 11:39:06] <chaouiy> when I run docker-compose up and run it again after restarting machine I notice that modificates persist without making any commit how do you explain this ?
[2017-08-03 14:31:43] <vodnanmaga_twitter> how can i check if chrome is installed in docker container?
[2017-08-03 16:55:14] <SISheogorath> amineparis: what kind of modifiactions are you talking about?
[2017-08-03 16:57:15] <SISheogorath> vodnanmaga_twitter: how do you check that on your local machine by using the shell? simply check if it appeared at the place where you installed the binary. If you used a package, check the package specs or simply check if it's in path
[2017-08-03 17:07:06] <Karthi-SRV> hi
[2017-08-03 17:07:12] <Karthi-SRV> cf ic init
[2017-08-03 17:07:23] <Karthi-SRV>  [<-CODE->] 
[2017-08-03 17:08:45] <Karthi-SRV> what kind of issue?
[2017-08-03 17:51:47] <SISheogorath> sounds like something that is part of the software that is running inside the container
[2017-08-03 17:52:08] <SISheogorath> As far as I know docker doesn't provide such an error message
[2017-08-04 04:45:33] <Niko-La> how do you  ru  two commands using dockerfile?
[2017-08-04 04:45:46] <Niko-La> i been using tmux but is there a bettee way?
[2017-08-04 07:26:29] <SISheogorath> Niko-La: use and entrypoint script?
[2017-08-04 17:22:34] <vodnanmaga_twitter> SISheogorath: I was able to install chrome and chromedriver in my docker container. but when i try to run my tests I get an errorERROR: An unknown server-side error occurred while processing the command. (UnknownError:13)with additional messageLauncher => failed to spawn chrome. I checked both chrome and chromedriver(latest 2.31) installation and its installed . Any idea on what this error might be. I am not even able to debug it as its failing to open chrome
[2017-08-05 21:10:29] <Caroga> hi all.
[2017-08-05 21:11:43] <Caroga> Currently thinking about moving my sites/applications to a containerized solution, and I find myself having some implementation questions. Stuff like: should I include this in a container or not. Is this the right place to ask those kind of implementation questions?
[2017-08-05 21:13:51] <Caroga> One being: Would it be better to host php-fpm in a different container from my application\'s source code and "mount it in"?
[2017-08-05 22:02:32] <yuriy-yarosh> @Carogait be better to host php-fpm in a different container from my application\'s source code and "mount it in"?Yup, in general you should use immutable containers for your target platform and mount volumes with your code, data and logs ... code should be immutable too for obvious reasons.Storing any valuable data inside the env vars is not a good idea, even if it\'s a common practice... small vulnerability and a getenv() syscall will expose everything. Make sure you\'re clearing your env in the entrypoint script.Volume management changed a lot at recent docker releases, and there\'s multi-stage container builds which are preventing any need in docker-in-docker (dind).In general dind for building and CI tends to be very faulty, because stacking multiple CoW filesystems breaks consistency and your data becomes corrupted after a while.I\'d suggest go for lvm based storage driver instead of the stock OverlayFS and for Cisco\'s Contiv instead of Overlay network driver. If Contiv is too hard for you feel free to start with macvlan instead.
[2017-08-06 04:48:53] <rbalicki2> hi folks
[2017-08-06 04:49:05] <rbalicki2> I'm having trouble using docker compose v2 with ecs
[2017-08-06 04:49:53] <rbalicki2> is there something different I need to do differently to connect my web to my db?
[2017-08-06 04:51:21] <rbalicki2> my docker compose is at [<-LINK->] 
[2017-08-06 04:52:12] <rbalicki2> i've been trying different permutations, e.g. thenetworkkey I assume is not correct, but /shrug
[2017-08-06 05:09:39] <rbalicki2> ah! looks like I neededlinks: - dbinstead oflinks: "db". or something. but i got it working!
[2017-08-06 09:16:38] <yuriy-yarosh> rbalicki2: links are deprecated, I'd suggest you get some understanding how things work without the compose... it's just a yaml config parser which executes the respective docker engine commands. It's better just to read the docs and use plain bash instead nowadays.
[2017-08-06 13:16:55] <rbalicki2> yuriy-yarosh: I think it's an issue with the compatibility with amazon's ECS. I'm not sure. I had very few issues getting this to work with docker (and compose v3), but didn't want to bother with downgrading docker globally to support v2 :)
[2017-08-06 15:50:33] <swapnilsm> How can I check if a capability was enabled for a container from inside the container?
[2017-08-07 00:54:25] <SISheogorath> swapnilsm: capsh --printis what you search. [<-LINK->] 
[2017-08-07 06:47:15] <iSanjayAchar> When can we except GCP support for docker swarm?
[2017-08-07 10:06:13] <SISheogorath> iSanjayAchar: That's probably a better question for the Google support.
[2017-08-07 10:35:48] <cuznerdexter> Hi all, I am testing out Docker for first time - getting a bit stuck.I have a digitalOcean server with Docker setup, I have a local dev env pushing to GitHub that then auto updates my DockerHub (for now it is a single instance swarm - so manager only) repo — all working good.Now I want to auto deploy the changes to my DigitalOcean Server - How do I do this?  I don’t want to login to ssh everytime I change GitAny ideas or guides most welcome.
[2017-08-07 14:00:28] <carlosjgp> cuznerdexter: You should use a CD server to "ssh" and do the work for youJenkins\nGitlab\nGoCD\nBitbucket.... and othersNot related with Docker
[2017-08-07 17:12:27] <jbelmont> I am trying to get headless chrome installed on alpine-node and then run npm tests [<-CODE->] 
[2017-08-07 17:13:22] <jbelmont> I want this dockerfile at the moment, but I would like to get npm tests to run as well, any issues with this that anybody sees
[2017-08-08 10:03:21] <carlosjgp> jbelmont: You can make everything during buildnpm install,npm testandgoogle...... you don't need to create a contianer from that image... do you need to run this multiple time with the same code?
[2017-08-08 12:27:03] <huiqiangyang> 在mac中安装docker如何解决ping不通容器的问题?
[2017-08-08 12:27:58] <huiqiangyang>  [<-LINK->] 
[2017-08-08 12:28:21] <huiqiangyang> some one have resolve this question method?
[2017-08-08 12:31:56] <huiqiangyang> On Mac os docker container can`t  communicate
[2017-08-08 21:01:25] <NickJames-minted> Anyone got a sec to help me out with an environment variables question for docker containers? I'm having issues setting variables using a bash_profile based approach
[2017-08-08 21:02:35] <NickJames-minted> basically I want the .bash_profile from the parent environment to propagate down to the container environment. I'm attempting to do this by using COPY in the dockerfile. The files get there, but when I enter the container none of the variables are available.
[2017-08-08 21:03:34] <NickJames-minted> I've tried commands likesource /path/to/.bash_profilein various places (e.g. the dockerfile itself, the entrypoint script) without any success
[2017-08-08 21:04:17] <NickJames-minted> also have tried setting the env var in the dockerfile usingENV BASH_ENV /path/to/.bash_profile
[2017-08-09 08:46:14] <elcolie> Hi
[2017-08-09 08:46:24] <elcolie> I am usingdocker-composeversion 3
[2017-08-09 08:46:38] <elcolie> Andpostgresdoes not use my username and password
[2017-08-09 08:46:45] <elcolie> Here is myymlfile
[2017-08-09 08:46:53] <elcolie>  [<-CODE->] 
[2017-08-09 09:01:37] <elcolie>  [<-CODE->] 
[2017-08-09 09:01:39] <elcolie> Is it a bug?
[2017-08-09 09:02:17] <elcolie> Here is inside the container [<-CODE->] 
[2017-08-09 09:30:27] <josemaia> hey guys. I want to build a containerized application that has a web app (port 80), an api gateway (port 81), and a bunch of microservices. If I never want people to communicate directly with port 81 to access the API gateway what should I be running on the port 80 web app? should I just have an NGINX container in port 80 redirect requests like [<-LINK->] to [<-LINK->] ?
[2017-08-09 09:44:55] <toftware> josemaia: I think you should run your api gateway on port 80
[2017-08-09 09:46:32] <josemaia> have the api gw on 80 and the web app on a non-standard port?
[2017-08-09 09:47:00] <toftware> No your web app should be hosted behind the api gateway as well
[2017-08-09 09:48:57] <josemaia> hmm, that's an interesting idea. I'm gonna place this as a question on StackOverflow to get more feedback, so if you want karma there feel free to post this there :) [<-LINK->] 
[2017-08-09 09:50:19] <toftware> I would argue that your webapp is a service as well :)
[2017-08-09 09:52:05] <toftware> Another solution would be to have your web app on port 80 and then your api on api.example.com
[2017-08-09 09:54:13] <josemaia> how would I go about doing that within the context of a docker/docker-compose architecture?
[2017-08-09 09:57:21] <toftware> With your gateway as you were already doing
[2017-08-09 11:15:28] <ndpratas> Hi guys, HOW do you manage VOLUMES?I have gitlab as a docker stack in order to any of it's container to be able to run in whatever node is available.For it to work, i need to persist data that is accessible from ANY nodewhat is the correct way to do this?I'm thinking about mounting a shared storage in every node (NFS in fstab) and then just use mapping host_folder:container_folderis this a correct way to do it? I can't seam to wonder that there is probably a better way to do this
[2017-08-09 11:19:10] <basz> ndpratas: glusterfs, infinity.sh would probably be more dockerish (aquired by docker) but still alpha. or just bound gitlab to same host. which is what I did, cause my swarm exposes several ssh services (such as git) and ssh cannot be forwarded to the correct host by the overlay network.
[2017-08-09 11:26:49] <ndpratas> basz: First of all thanks for answering. I'm not concerned about ssh forwarding but still that info might come in handy in the future. What i'm trying to do is to use gitlab as a Prove of Concept to test the waters out. One of the things I would like to test is shared persisted storage between nodes in order to have container agnostic of the node they are running on. I don't know if I'm having this docker paradigm wrong or something, please tell me from your experience if am I being naive indeed. Also, I didn't want to have stuff in alfa supporting production services but I will check it out (thank for pointing me in the right direction).Still do you see a real problem with my simple solution?
[2017-08-09 11:27:13] <ndpratas> (the NFS mount on FSTAB in every worker/manager node)
[2017-08-09 11:37:09] <basz> ndpratas: yes it is a real problem. there are lots of use cases where you would want data to follow a container that runs on a random node (hence the docker acquisition of infinit). I believe there are others solutions out there then the one I have described but it’s an area that I am not too familiar with yet. research Data Volumes, or Flocker (but now deceased) like solutions.
[2017-08-09 11:38:38] <basz> ndpratas: docker containers are supposed to be stateless : [<-LINK->] 
[2017-08-09 12:25:20] <kamilorzelek> Hi. I have some problem. I try to start mysql on docker but i'm getting this error: [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2017-08-09 12:26:14] <basz> ndpratas: you’ve got me doing reading up : [<-LINK->] 
[2017-08-09 12:28:01] <basz> kamilorzelek: you must ensure it (db-data) exists on the host. (you’ll might also need to use an absolute path, not sure)
[2017-08-09 12:28:34] <kamilorzelek> basz: Thx. I will check
[2017-08-09 12:30:03] <Caroga> yuriy-yarosh: thank you for your explanation the other day. I did not got to see it until now. I was thinking, a container, only housing my code, does this has a valid reason to exist?
[2017-08-09 12:30:39] <basz> kamilorzelek: if the dir doesn’t exist the mount will fail and thus mysqld won’t start as it is missing its data dir
[2017-08-09 12:42:10] <kamilorzelek> basz: Solved. Directory existed, but old files from previous mysql image was blocked new one
[2017-08-09 12:42:40] <kamilorzelek> Thx again :)
[2017-08-09 13:22:20] <ndpratas> basz: Yes, docker container are supposed to be stateless but they do indeed need some data persistence (in some cases at least like running a DB in a container). I've read everything you pointed me out to but as the post's say it's all still in development and there is nothing worth relying. Do you happen to know if I can mount an NFS volume directly into the container using the volume flag (like --volume nsf_server:/data:container_data)?
[2017-08-09 13:25:42] <SISheogorath> ndpratas: you can do so (with iirc 17.05+): [<-LINK->] 
[2017-08-09 13:25:48] <SISheogorath> Check the last example
[2017-08-09 13:26:36] <ndpratas> SISheogorath: Thank you. Let me check that really quick
[2017-08-09 13:28:38] <ndpratas> SISheogorath: This was actually what I was asking for. Worth knowing! Thank you. Related, have you read why I\'m asking all of this? Can you please read my last posts (beginning at post "Hi guys, HOW do you manage VOLUMES?") and give me your opinion?
[2017-08-09 13:36:42] <SISheogorath> Well, currently the only official ways to get this is by volume drivers. And the only officially supported or recommended drivers (as in "is production ready and well tested") are for Amazon\'s, Google\'s, and Microsoft\'s container cloud storage backends. So I guess that\'s not what you want. There are also some other storage providers like netapp who provide volume drivers but usually you need on of their proprietary storage backends to work. So for a FOSS storage solution there is no official or well proven way. I personally go for GlusterFS + Hostmounts but that\'s far from perfect. And you shouldn\'t do that when it comes to databases or something. Also I currently experiment right now with glusterfs and native mounting in docker (like in the NFS example). But not enough tested to recommend it. So all in all, I can\'t recommend anything right now for an on-prem solution. What you should keep in mind in case of NFS is that you have locking problems if multiple containers use the same file.
[2017-08-09 13:36:53] <SISheogorath> ndpratas: see above
[2017-08-09 13:38:29] <basz> ndpratas: no I don’t.
[2017-08-09 14:14:01] <ndpratas> SISheogorath: Thank you for your great insight. I\'m new to all of this so experience from other users is all I can rely on, thank you again for taking the time. Now, I don\'t think I would have a problem with locking because I only run one instance at the time. What I want to be able to do is having a replicated container (1 replica) that changes nodes on the fly and have no problems accessing data that is persisted somehow. Think a DB for example. In my POC case I\'m running a docker stack with gitlab-ce that depends on 3 other containers (DB, redis, postfix relay) aside from the gitlab container itself.So far I have it running and configured just like I want it to be aside from having just 1 node in the swarm (I actually have two but one is in "drain" mode). All I want is to be able to have the two nodes running and making sure that even if one host machine dies it will just restart itself in the other node no problems. All and all, I want all containers FROM THE SAME STACK to be decoupled from the host they are running at. What would you recommend, or is really NFS the better way to to this for now until better drivers support come? I\'m also considering passing the NFS along with the volumes flag instead of mounting the NFS share in all host machines and then mounting a "local" path in volumes flag.
[2017-08-09 14:19:24] <SISheogorath> Well, I wouldn\'t wait for "better plugins". Right now the persistence problem is addresses by the infinite team that docker acquired a few months ago (last year?). and they currently consider an experimental solution and of this or beginning of the next year. which means until it\'s stable there will be more than 1 year. Many people simply wrote their own volume plugins (it\'s not rocket science). All in all I would go for NFS if you already have a storage backend that is replicated. Otherwise my personal preference is (as already mentioned) glusterfs. And yes, I would go for volume flags in case you want to run stack-deploy.
[2017-08-09 14:20:13] <SISheogorath> One hint: If your postfix container switches the host and is not using a smarthost you run into a problem. otherwise it sounds fine
[2017-08-09 14:22:44] <kamilorzelek> Another problem [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2017-08-09 14:26:26] <ndpratas> SISheogorath: smarthost? I'm not familiarized with this term. What do you mean by that?
[2017-08-09 14:27:04] <thomas-oo> Hi, I have a question regarding network to network DNS resolving. Currently my set up involves 2 redis containers running in the default bridge network, and registrator and consul running in the host network. Registrator automatically registers containers started into consul as services. Then on the host network, I could dns look up <service>.service.consul and it'll resolve correctly. However, I want to start another service in the default bridge network that can also use the same consul dns server in the host network. How do I connect kind of, the bridge and the host network so that dns lookups resolve? Let me know if I'm not making sense
[2017-08-09 14:28:29] <SISheogorath> kamilorzelek: first of all please don't uselinks. They are dead and deprecated for multiple months now. Then add adepends_onstatement. After you done this, please usePMA_HOST=mysqlas environment variables for the phpmyadmin container
[2017-08-09 14:28:34] <SISheogorath> Then check again
[2017-08-09 14:28:51] <SISheogorath> ndpratas:  [<-LINK->] here you go
[2017-08-09 14:29:31] <SISheogorath> you usually use it for setup in dynamic IP ranges which are widely blacklisted
[2017-08-09 14:33:17] <SISheogorath> thomas-oo: you should be able to address your hostmachine from an internal docker network by using it's external hostname. So use it like an external host. In case of DNS this means you have to use the public address of your machine or (if you are lucky, I'm not sure about that) the first IP address of your subnet. But for the latter I'm neither sure how to configure it, nor if it actually works.
[2017-08-09 14:36:14] <ndpratas> SISheogorath: I'm using an open relay, no auth, no restrictions from the sender's ip. Since every runs on the same docker network I thought that would be the easier solution.BTW I'm also using links but since this is my first docker compose /stack file I just mirrored stuff I saw online. What should I do with links? Remove them? I read the warning docker page on links but didn't understand how should I adapt my file ( [<-LINK->] )
[2017-08-09 14:37:50] <SISheogorath> iirc in v3 links are ignored. So you should be able to delete them without a problem :X
[2017-08-09 14:39:08] <ndpratas> cool
[2017-08-09 14:39:23] <kamilorzelek> SISheogorath: Thx a lot. Solved. 
[2017-08-09 14:41:36] <SISheogorath> ndpratas: as long as you don't expose 25 that's fine but doesn't solve the real problem. Mailserver require correct forward and reverse dns. which are usually bound to hosts and also advertised by your mailserver on connect while HELO. So your postfix instance needs to be aware of it's current hostname and your hostnames need to be configured correctly. (possible to do by mounting the right files, but something you have to be aware of, if you want to send mails to the internet)
[2017-08-09 14:47:44] <ndpratas> SISheogorath: I'm actually only using postfix as a relay to exchange because gitlab doesn't support SMTP with NTLM auth out of the box. Thus, I do the auth with postfix and just have an open relay for gitlab to send e-mail through... Yes, I do NOT expose 25, I use (used lol) links like you saw on my file and it is working... From the outside of the container I can't use that relay because there isn't a 25 port exposed on the nodes.
[2017-08-09 14:48:07] <SISheogorath> Ah in this case it's fine ^^
[2017-08-09 14:48:13] <ndpratas> I don't know if i am missing something or not, but I was happy because it is runnig
[2017-08-09 15:08:23] <megamindbrian> SISheogorath: you're a genius.
[2017-08-09 15:08:46] <SISheogorath> .-. Am I?
[2017-08-09 15:10:10] <SISheogorath> How do I come to this very special title? :D
[2017-08-09 15:25:01] <ndpratas> SISheogorath: Helping other I guess lol
[2017-08-09 19:40:48] <yuriy-yarosh> Caroga: you could create a runtime immutable container using multi-stage builds etc and mount few volumes with your code, data and logs ...
[2017-08-09 20:45:53] <frankiehayward> Hello all
[2017-08-09 20:47:15] <astericky> Hello everyone I was wondering if I could get help with a problem
[2017-08-09 20:47:54] <astericky> for some reason when I run my web app outside the docker container everything works just fine but when I run it inside the container the database is inaccessible
[2017-08-09 20:49:05] <thomas-oo> Could u supply the command u used to run ur web app in the container
[2017-08-09 20:50:15] <astericky> docker-compose up
[2017-08-09 20:52:20] <astericky>  [<-CODE->] 
[2017-08-09 20:56:38] <thomas-oo> I'm not an expert on docker myself but containers have an internal ip
[2017-08-09 20:56:52] <thomas-oo> my guess is that your app might be looking at the wrong ip
[2017-08-09 20:57:03] <thomas-oo> if you do docker network inspect localhost
[2017-08-09 20:57:14] <thomas-oo> you should see your two containers there with their ips
[2017-08-09 20:58:44] <thomas-oo> alternatively, try running both containers on the network "host"
[2017-08-09 20:59:10] <thomas-oo> I think that should allow you to call localhost just fine from your app
[2017-08-09 20:59:26] <astericky> ok cool beans will try that
[2017-08-09 21:19:07] <billiam13s> astericky: with docker-compose, you can reference the db service in app just by it name.
[2017-08-09 21:39:58] <Niko-La> docker run -d -v /src/work:/home/jovyan/work -p 8888:8888 jupyter/datascience-notebook start-notebook.sh --NotebookApp.token=''I am running the docker command from the location where work folder exits.  I am unable to find the files in the docker jupyter notebook... any one familiar with the volume flag.fyi this running on Windows using Docker toolbox
[2017-08-09 21:56:29] <astericky> oohhh so by db
[2017-08-09 22:00:57] <astericky> holly Molly that worked!!!
[2017-08-09 22:01:04] <astericky> Thanks so much!
[2017-08-09 22:01:07] <astericky> :D
[2017-08-09 22:46:16] <billiam13s> Niko-La: Have you try-v /home/jovyan/work:/src/work? At least on mac, and linux the left side is local machine and right side is the docker instance.
[2017-08-10 06:36:48] <atsushi-ishibashi> I’d like to activate tcp fast open. I executedecho 1 >/proc/sys/net/ipv4/tcp_fastopenbut not found file error occured. When I use host as networking mode by--network=host, I can. tcp_fastopen is config on tcp layer so I want to configure in container via CI. Is it possible?
[2017-08-10 08:04:03] <cuznerdexter> carlosjgp: Thanks for advice :) - it helped me get a bit further. I am currently looking at circleCi - looks promising, might try Bitbucket as well (if I can ever sort out my Bitbucket account issues!)
[2017-08-10 09:19:17] <SISheogorath> atsushi-ishibashi: use the--sysctlflag for the container
[2017-08-10 09:33:26] <atsushi-ishibashi> SISheogorath: I can find--sysctloption in docs. Butdocker run --sysctl net.ipv4.tcp_fastopen=1 -it ubuntu /bin/bashshows the same errorno such file or directory
[2017-08-10 10:18:15] <przemolb> Hello all,
[2017-08-10 10:19:22] <przemolb> my question is more about design of docker  ecosystem  in companies.
[2017-08-10 10:19:59] <przemolb> How do you organise internal registry in case when you:
[2017-08-10 10:20:51] <przemolb> need to provide access to some external images internally but also restrict  what docker images can be installed internally
[2017-08-10 10:21:22] <przemolb> have a lot in-house built images which also can be installed on particular hosts
[2017-08-10 10:21:54] <przemolb> (by particular users so not everybody could run docker run ...)
[2017-08-10 10:23:05] <przemolb> Do you guys use docker registry  with builtin proxy  for this kind of  tasks ? If not how do you (in general) manage access to thousands of internal and external docker images ?
[2017-08-10 11:38:47] <basz> Hi,docker-machine createquestion. Is it possible to define the used storage-driver with the generic create driver? Turns out it chooses aufs which isn’t supported on my system. Manually changing to--storage-driver overlay2in/etc/systemd/system/docker.service.d/10-machine.confworks, but…
[2017-08-10 12:33:41] <kamilorzelek> Hi. How can i ensure if process in container successfully started, cuzdepends_oncheck only in container, not proccess in container?
[2017-08-10 12:45:17] <spences10> Hello docker/docker
[2017-08-10 12:46:10] <spences10> I'm trying to follow the docs
[2017-08-10 12:46:26] <spences10>  [<-LINK->] 
[2017-08-10 12:46:42] <spences10> I get todocker run hello-world
[2017-08-10 12:47:52] <spences10> And get this: [<-CODE->] 
[2017-08-10 12:48:09] <spences10> How to even?
[2017-08-10 12:49:33] <spences10> Ok, apologies, this time I have docker running!
[2017-08-10 12:49:38] <spences10> Oh!
[2017-08-10 12:49:58] <spences10>  [<-CODE->] 
[2017-08-10 12:50:14] <spences10> Apologies to all!
[2017-08-10 13:49:29] <thomas-oo> Hi guys, I'm planning to use envconsul to watch KV entries in consul and use these to inject env variables into my containers
[2017-08-10 13:50:05] <thomas-oo> Only problem is, is there a way to share or pass certain env variables from one container to another? For now, assume they are both in the same network and the envconsul container can discover any other container
[2017-08-10 15:28:47] <basz> to have docker swarm use a private network should I init a swarm like sodocker swarm init --advertise-addr={{ public_ip }} --listen-addr {{ private_ip }}:2377
[2017-08-11 01:49:04] <GavinHsueh> 11
[2017-08-11 03:11:00] <SISheogorath> basz: the advertise-address should only differ from the listen-address when you use some kind of floating IP like you use in OpenStack setups
[2017-08-11 03:12:16] <SISheogorath> thomas-oo: well there is, but this way is deqd and should no longer be used. It waslinks. It would be better to talk to the docker engine API and gather the facts there
[2017-08-11 03:12:58] <SISheogorath> spences10: welcome to the docker side of life ;)
[2017-08-11 03:15:03] <SISheogorath> kamilorzelek: see [<-LINK->] 
[2017-08-11 03:15:46] <SISheogorath> Also you can useHEALTHCHECKs to wait for a container to be up.
[2017-08-11 03:22:23] <SISheogorath> przemolb: right now I would say the easiest way to control what images come in and what images are allowed the best way to achieve this is building a simple CI process for these images on a machine that has full access to both registries and then pulls them from the public one, test them, and push them then again to the private one, where they go the usual way of staging and production.
[2017-08-11 03:23:15] <SISheogorath> I can't say it for our company, since we have full access to public registry, but that sounds like a good way to me.
[2017-08-11 03:24:25] <SISheogorath> atsushi-ishibashi: does it exist on the host/does it work to set it on the host with sysctl? If so I have to think about it a bit more
[2017-08-11 03:24:57] <SISheogorath> .-. I think I did my part for today :D time to rest a bit
[2017-08-11 06:38:14] <atsushi-ishibashi> SISheogorath: I work on macOS. I can set bysysctl -w net.inet.tcp.fastopen=1. And when I ran docker container with--network=host, sysctl worked well.Btw thank you for help and have a nice day 
[2017-08-11 08:23:34] <basz> SISheogorath: should I use the private address for both then? (swarm is in same datacenter). ps thanks again!
[2017-08-11 09:46:40] <SISheogorath> basz: yes, you should
[2017-08-11 09:50:51] <SISheogorath> atsushi-ishibashi: so what was the command you used to start your container? Something likedocker run --sysctl net.inet.tcp.fastopen=1 someimage?
[2017-08-11 11:25:10] <atsushi-ishibashi> SISheogorath: Yes. I trieddocker run --sysctl net.inet.tcp.fastopen=1 -it ubuntuanddocker run --sysctl net.ipv4.tcp_fastopen=1 -it ubuntubut these two showed the same errordocker: Error response from daemon: oci runtime error: container_linux.go:262: starting container process caused "process_linux.go:339: container init caused \\"open /proc/sys/net/ipv4/tcp_fastopen: no such file or directory\\"".
[2017-08-11 13:09:52] <SISheogorath> atsushi-ishibashi: I'm not completely sure about it, but it sounds reasonable that not all options are available in a namespace. for example when they are global and affect other namespaces as well when you change them. So tcp_fastopen is maybe one of them (I didn't find a source to verify this theory by a quick research but I sounds reasonable)
[2017-08-11 14:27:37] <atsushi-ishibashi> @SISheogorath Docker docs also saysNote: Not all sysctls are namespaced. Docker does not support changing sysctls inside of a container that also modify the host system. As the kernel evolves we expect to see more sysctls become namespaced.So what you're saying is right. I'm not familiar with namespaced so I'm researching how these configs like tcp_fastopen affect other process.Thank you very much, Sheogorath!
[2017-08-11 14:28:27] <SISheogorath> You're welcome
[2017-08-11 15:01:47] <thomas-oo> quick question, I want one of my docker containers in the bridge network to know the ip of my host
[2017-08-11 15:01:50] <thomas-oo> any tips?
[2017-08-11 15:02:04] <thomas-oo> do I have to pass in an env variable to the docker container
[2017-08-11 15:07:32] <SISheogorath> thomas-oo: I would say, yes. as long as you don't want to break the network isolation, you should use an env var
[2017-08-11 15:08:55] <thomas-oo> makes sense, thanks
[2017-08-11 15:09:04] <thomas-oo> and yea i do not want to break network isolation
[2017-08-11 15:09:22] <thomas-oo> I just need the ip address of the host as the host is the dns server for the container
[2017-08-11 15:10:05] <atsushi-ishibashi> thomas-oo: How aboutcurl ifconfig.co?
[2017-08-11 15:12:45] <thomas-oo> gets some ip, but i can't ping to it
[2017-08-11 15:13:23] <thomas-oo> i have some private network as well so
[2017-08-11 15:13:38] <thomas-oo> for now I'll just pass an env variable, one wont hurt
[2017-08-11 18:44:19] <vito-c> is it possible for docker to handle your host machine dns entries? for example let's say I have a service foo.bar mapping to port 8108 (so I can access it at 127.0.0.1:8108) and I want to be able to access it via my browser by going to [<-LINK->] 
[2017-08-11 19:15:44] <atsushi-ishibashi> vito-c: In macOS, it's possible by changing/private/etc/hosts. I don't know about other os..
[2017-08-11 19:21:40] <vito-c> yah was trying to get around that requirement
[2017-08-11 19:25:09] <thomas-oo> vito-c:  [<-LINK->] 
[2017-08-11 19:25:24] <thomas-oo> might be applicable
[2017-08-11 19:25:39] <thomas-oo> I believe in in the end, it does just add entries into your /etc/hosts
[2017-08-11 19:49:19] <vito-c> thomas-oo: I think it modifies /etc/resolv.conf on the host
[2017-08-11 19:54:01] <spences10> Hello Docker people
[2017-08-11 19:54:03] <vito-c> thomas-oo: so I just need to run that resolvable container?
[2017-08-11 19:54:11] <spences10> I am struggle
[2017-08-11 19:54:17] <spences10> Here: [<-LINK->] 
[2017-08-11 19:54:45] <spences10> I get this@
[2017-08-11 19:54:55] <spences10>  [<-LINK->] 
[2017-08-11 20:01:38] <thomas-oo> I think so.. i ran it a while ago
[2017-08-11 20:01:44] <thomas-oo> i dont quite remember sorry
[2017-08-11 20:01:53] <thomas-oo> I think you would run that container on ur host network
[2017-08-11 20:14:40] <vito-c> yah I ran the container and then went to foo.bar
[2017-08-11 20:14:42] <vito-c> but no dice
[2017-08-11 20:15:08] <vito-c> thomas-oo: were you doing this on osx?
[2017-08-11 20:15:16] <vito-c> did you use the systemd one or the first one?
[2017-08-11 20:18:52] <vito-c> I think with mac osx you can't mount directories inside /etc
[2017-08-11 20:21:31] <thomas-oo> vito-c: no, on rhel7
[2017-08-11 20:22:22] <thomas-oo> oh i didnt know you can't mount /etc dirs in mac
[2017-08-11 20:52:54] <vito-c> i think you can
[2017-08-11 20:53:02] <vito-c> you have to add it i guess
[2017-08-11 20:58:38] <vito-c>  [<-CODE->] 
[2017-08-11 20:58:45] <vito-c> thomas-oo: I get those errors
[2017-08-11 21:12:33] <vito-c> thomas-oo: I also get errors when using docker-compose [<-CODE->] 
[2017-08-12 02:05:38] <Niko-La> is there any good examples of how to mount volume on linux ubuntu
[2017-08-12 02:06:19] <Niko-La> docker run -d -v ~/src/work:/home/jovyan/work -p 8888:8888 jupyter/datascience-notebook start-notebook.sh --NotebookApp.token=''this was working nicely on windows quickstart docker but not working on linux.
[2017-08-12 06:19:14] <przemolb> SISheogorath: Thanks for hint   So CI solution acts as a kind of limited proxy ?
[2017-08-12 09:12:09] <SISheogorath> przemolb: not only proxy, I would add a real validation of the images functionalities, so I know it does what I need. (So some kind of integration test
[2017-08-13 15:02:57] <arunma> Is there a way to restrict opening up the ports only for containers within the same network?Apologies if this question has been asked earlier and answered.  I have a docker compose.yml wrapping a Elastic and a Squid proxy container.  This is to simulate a corporate environment where I would be able to access Elastic only through a proxy. [<-CODE->] 
[2017-08-13 15:04:36] <arunma> This works fine. When I configure the Squid proxy in my browser, I am able to access the ES IP (172.*) and execute queries.  However, when I don’t use my proxy, I am still able to access the ES container through the 9200 port (obviously, because I have exposed the port).
[2017-08-13 15:05:04] <arunma> Is there a way to open up the port only to the default network - which I see isesnetin this case?
[2017-08-13 18:03:33] <SISheogorath> arunma: check theinternalparameter for your docker network
[2017-08-13 18:19:37] <renegoretzka> hello, i am having issue with wordpress and mysql connection
[2017-08-13 18:20:02] <renegoretzka> MySQL Connection Error: (1045) Access denied for user 'root'@'10.42.43.123' (using password: YES)
[2017-08-13 18:20:27] <renegoretzka> how can this be solved? i have set mysql_root_password to the same for the mysql and wordpress
[2017-08-13 18:49:20] <renegoretzka> hmm seems like the mounted volume of mysql is bugged
[2017-08-13 19:34:53] <renegoretzka> damn it.. seems like the schema is not the same since mysql update.. how can i solve this? cant login as root... when i start a fresh database it works, but i want to use my old one.. how to do that?
[2017-08-14 03:38:15] <arunma> SISheogorath: Thanks a lot !!
[2017-08-14 05:20:38] <SISheogorath> renegoretzka: how would you do it outside of docker? Docker is not magic that makes the inside project work. When you put a shitty software in docker it stays a shitty software. To update your MySQL schema it's maybe useful to not skip any major version while updating. And your error message sounds like there is a config mistake with your start parameter
[2017-08-14 05:20:54] <SISheogorath> arunma: You're welcome
[2017-08-14 11:47:53] <ulyssessouza> Someone using docker SDK here? I have a doubt about how to get Environment variables from a running container...
[2017-08-15 05:22:59] <lostllama> Hi, does anyone know if there's a fix for this?: Error response from daemon: Get [<-LINK->] : dial tcp: lookup registry-1.docker.io on [::1]:53: read udp [::1]:55308->[::1]:53: read: connection refused
[2017-08-15 05:27:34] <lostllama> Anyone?
[2017-08-15 05:29:48] <lostllama> I've tried two ISPs, two different DNS servers (Google, and 4.4.2.2), and nothing helps.
[2017-08-15 05:57:42] <lostllama> Apparently uninstalling Docker, wiping away any traces of existence, and reinstalling it resolved my issue.
[2017-08-15 08:21:08] <codeRuth> how do i edit the startup command when i run, docker run <image> ?
[2017-08-15 08:33:48] <lostllama> If you don't have an [entrypoint...] defined in your docker file, then it will run the command you specify after the image name
[2017-08-15 08:34:31] <codeRuth> lostllama: thanks..
[2017-08-15 16:40:58] <NickJames-minted> I'm trying to run bash scripts for etl in a container. The scripts require mysql and postgres clients among others, and I'm having issues getting all the requirements installed into one container using the official docker images. Would be grateful for advice on getting everything I need into the environment.
[2017-08-15 17:23:20] <NickJames-minted> i know you're generally meant to split services up across containers but in this case they can't be decoupled because of job dependencies
[2017-08-15 17:34:35] <thomas-oo> I'm trying to build an image from centos, in this image, I am also running RUN yum install -y unzip and RUN yum install -y curl
[2017-08-15 17:34:45] <thomas-oo> both of which timeout
[2017-08-15 17:35:04] <thomas-oo> I suspect that at build time, it cannot access the internet? How do I fix this
[2017-08-15 17:35:20] <thomas-oo> On my host machine I can reach the yum repos just fine
[2017-08-15 17:35:48] <thomas-oo> This is not only a problem on the centos image but also on alpine, so I do not think it is due to the OS choice
[2017-08-15 17:37:15] <thomas-oo> NickJames-minted:  [<-LINK->] 
[2017-08-15 17:37:45] <thomas-oo> You should create your own Docker image, choose a base OS image, then install specific dependencies
[2017-08-15 17:45:14] <NickJames-minted> thomas-oo: I have created my own Docker image. But installing the specific dependencies has been far more difficult than expected. Appending my base OS image with the lines from the mysql dockerfile isn't working.
[2017-08-15 18:00:05] <thomas-oo> unfortunately so am I, for me my machine sits behind a proxy server isn't able to do apt-get or apk add etc
[2017-08-15 19:04:07] <thomas-oo> I'm still not able to do any yum install commands in my Dockerfile at build time.. I've looked into added in ENV http_proxy and https_proxy as per [<-ISSUE->] but it is still not working
[2017-08-15 19:04:26] <thomas-oo> Could not retrieve mirrorlist [<-LINK->] error was12: Timeout on [<-LINK->] : (28, 'Resolving timed out after 30546 milliseconds')
[2017-08-15 21:06:30] <thomas-oo> in docker-compose
[2017-08-15 21:06:43] <thomas-oo> what is the equivalent of running docker run -P option
[2017-08-15 21:07:04] <thomas-oo> the publish all ports to random host ports, how do I do this in docker-compose
[2017-08-15 22:50:41] <NickJames-minted> Anyone know how to install python-apt module? I am using hte official python dockerfile for 2.7.13 and debian keeps installing python-apt to the system python 2.7.9
[2017-08-15 22:50:55] <NickJames-minted> this one is killing
[2017-08-15 22:53:17] <NickJames-minted> looks like it's not supported on pypi- so is there just no way of getting python-apt to a newer distro of python without changing the system install?
[2017-08-15 23:44:37] <SISheogorath> thomas-oo: simply use [<-CODE->] 
[2017-08-15 23:44:58] <SISheogorath> don't specify what port should be used
[2017-08-15 23:48:39] <SISheogorath> NickJames-minted: the official python image doesn't use apt to install python and that's why apt installs python as a dependency for a package as it doesn't know anything about the self-compiled python version. I would suggest you to usepipto install the package of your choice or usedebianinstead ofpythonas base image
[2017-08-16 02:39:29] <NickJames-minted> SISheogorath: Thanks, I went with using the debian base image. I didn't realize thatdebian:stretchships with 2.7.13
[2017-08-16 02:40:19] <NickJames-minted> pipis a not a supported distribution of thepython-aptpackage and fails relentlessly due to dependencies. The creator of the package firmly directs people to usingapt
[2017-08-16 03:14:02] <DWSR> Anyone in here that can guide me in the right direction with this? I'm trying to run a Docker Registry (usingdistribution/registry:master) as a service. When I run the container as standalone, it runs no problem and I can upload images to it. When I try to run it as a service, I getNo such imagewhenever the service tries to spin up a container. I have cleaned out all the images on the manager that I'm connected to viadocker rmi $(docker images -a -q) --force
[2017-08-16 04:17:13] <vecchp> is there any way to have a command trigger on every docker push?
[2017-08-16 14:54:59] <carere> Hello everyone :)
[2017-08-16 14:59:08] <carere>  [<-CODE->] I can post some code too if needed :)
[2017-08-16 18:14:30] <thomas-oo> carere: why is the host directory removing contents? I also use volumes and there's no removal of the contents
[2017-08-16 18:14:56] <thomas-oo> and yea, post the command for starting your service
[2017-08-16 21:50:34] <ctlajoie> I have two containers (call them 'web' and 'redis') running on a host using the default bridge network mode. The redis container was run with-p 12345:6379. From the web container I amunableto connect to redis using<ip of host>:12345and I cannot figure out why. It seems to have something to do with iptables because if I stop iptables then it works fine. But docker is supposed to manage iptables rules so I still don't understand why this doesn't work...
[2017-08-16 22:40:29] <thomas-oo> Chris it is to do with iptables, I had the same issue, what I did was flush my iptable records and accept them all then I restarted docker service
[2017-08-16 22:41:41] <thomas-oo> But the better approach might be to connect the web container to the redis container using the internal ip of the redis container:6379
[2017-08-16 22:42:44] <thomas-oo> Docker network inspect bridge will show u the containers internal ip
[2017-08-16 23:04:24] <ctlajoie> thomas-oo: flushing all iptables rules and restarting docker worked. I just wish I could figure out why...I guess I will reset them and try removing rules one-by-one until I find the one that's blocking it.
[2017-08-16 23:56:44] <ctlajoie> thomas-oo: I was able to solve the problem by inserting a rule in the INPUT chain.iptables -I INPUT -i docker0 -j ACCEPT
[2017-08-17 06:23:21] <Karthi-SRV> hi
[2017-08-17 13:15:17] <thomas-oo> ctlajoie: thanks! I'll keep that in mind
[2017-08-17 16:40:56] <doc-tongue> My docker swarm crashed and is stuck.  I lost a node and had too large a load on remaining node.  I cannot run a command it does not respond.  How can a restart docker without it auto deploying the stack that causes it to become unresponsive?
[2017-08-17 16:47:17] <AnthonyWC> restart the docker daemon on that node?
[2017-08-17 16:47:52] <doc-tongue> AnthonyWC: thanks.  I tried but it loads the stack it previously had
[2017-08-17 16:48:02] <doc-tongue> I had to leave swarm
[2017-08-17 16:48:11] <doc-tongue> then init a new one.
[2017-08-17 16:54:24] <doc-tongue> Sorry for the poor writing trying to get systems back on line.  Was in a rush
[2017-08-17 22:23:57] <vito-c> is it possible to log to stdout and to splunk??
[2017-08-17 22:24:12] <vito-c> i want docker logs <foo> to work as well as using splunk
[2017-08-18 16:00:33] <SISheogorath> vito-c: when there is a logging driver for splunk that allows it, yes
[2017-08-18 18:50:19] <vito-c> SISheogorath: so right now it's not possible? by default?
[2017-08-18 18:58:31] <thomas-oo> Similar to this question: [<-LINK->] , I am using consul as well but I am trying to start a docker stack where I start a consul agent globally. However, consul needs an IP to advertise to other nodes, I want to use the container's host ip. How should I do this
[2017-08-18 20:37:06] <RothIOP> Hey guys, I'm having issues connecting to a second registry on the same host that's listening on a different port from the first registry
[2017-08-18 20:37:09] <RothIOP> first registry works perfectly
[2017-08-18 20:37:34] <RothIOP> But when I try to connect into the second registry I'm getting backWarning: failed to get default registry endpoint from daemon (Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.27/info: dial unix /var/run/docker.sock: connect: permission denied). Using system default: https://index.docker.io/v1/
[2017-08-18 20:38:30] <RothIOP> I can't even tell what it's trying to connect to when I'm trying to create that connection
[2017-08-20 00:02:44] <hyperking> when Using docker compose file how can I define a custom domain name for local development? i.e myapp.dev instead of localhost
[2017-08-20 10:02:13] <vinifala> Hi, I'm trying to start a mongoDB container using 'wiredTiger' as engine, to which, the docs say I should run$ docker run --name some-mongo -d mongo --storageEngine wiredTiger. However, I'd like --storageEngine wiredTiger to be part of my Dockerfile for this particular container. How can I tell Docker to run with additional config from a Dockerfile?
[2017-08-20 11:50:27] <vinifala> answer: command: --storageEngine wiredTiger
[2017-08-20 17:13:09] <4doge> Hello,Can anyone explain me the best practice for my project.I'm using docker cloud.I need to run node.js project and nginx for serving that project.I want to do that in two separated containers, but since i'm newbie with docker i don't understand how can i define in docker-cloud.yml how to build each (which commands to run) container. Or maybe i need to use the docker-compose.yml?
[2017-08-21 06:06:49] <rsegecin> Does anyone knows where to find good information on how to deploy a  asp net core rest api over TLS on docker?
[2017-08-21 06:09:47] <rsegecin> I've my API using Kestrel with a self signed certificate that I generated  that's working but unable to make it work on docker
[2017-08-21 06:14:03] <rsegecin> I've heard that I should have a proxy server just to make TLS and have my Rest API behind it does this information follow?
[2017-08-21 07:17:36] <jihegra> rsegecin: hi! I have been installing net framework/core apps on Docker EE and WS2016 recently. I'm using Kong (nginx-based) like an API Gateway in front of all my microservices, Kong has TLS out-of-box. Also, Kong has a REST API for management and monitoring... and some others plugins like CORS, Auth, etc.
[2017-08-21 07:24:16] <rsegecin> jihegra: that sounds really cool
[2017-08-21 07:28:17] <rsegecin> jihegra: I will start [<-LINK->] 
[2017-08-21 07:30:23] <rsegecin> jihegra: Thank you
[2017-08-21 14:34:43] <thomas-oo> 4doge: I'm not too familiar with docker cloud but as for running these two containers, just run them on your local machine using docker-compose. docker-compose.yml documentation is here: [<-LINK->] In your case, you'd have two services, your node.js project and an nginx image.
[2017-08-21 16:10:42] <matiasmagni> I would like to use this medium to promote the survey that I'm doing that will be included as statistical data in my final thesis work. If you would be kind enough to fill it and broadcast it among your contacts would help me a lot. Thanks!Link: [<-LINK->] 
[2017-08-21 22:03:43] <8Gitbrix> hi
[2017-08-21 22:05:06] <8Gitbrix> I'm new to docker, and I'm trying to run a local python file inside a docker container. How would I do that? When I call: docker run Imagename python3 localpathtofilename.py, it says [Errno 2] No such file or directory
[2017-08-21 22:28:32] <8Gitbrix> never mind I got it working, but it doesn't recognize any of the modules which i installed in the requirements.txt when creating the image
[2017-08-22 07:28:08] <andela-cwekesa> 8Gitbrix: can you share your Dockerfile?
[2017-08-22 10:19:14] <carlosjgp> try something likedocker -w /myapp -v /host/folder/:/myapp/ python:3 python xxxx.pyIn this way you define the folder where you map your app as theworking folder inside the container
[2017-08-22 10:20:40] <carlosjgp> Actually there is an example quite similar on the docker hub website [<-LINK->] 
[2017-08-22 11:59:57] <webertrlz> anyone experienced problems of communication between containers? I have this weird problem that always happens and no one knows anything about it
[2017-08-22 12:02:04] <webertrlz> I have an Overlay network (using consul, not swarm but I've seen this happen in swarm mode too).Container A tries to connect to container B, no response. Ping from A to B, no response.Then I  Ping from B to A, I get the ping responses, so the other connections from A to B starts working
[2017-08-22 12:02:30] <webertrlz> it happens in different datacenters, different overlay networks, different containers. Same problem.
[2017-08-22 12:05:23] <SISheogorath> Usually it's a firewall issue
[2017-08-22 12:05:41] <SISheogorath> I saw similar things happen while using digital oceans cloud firewall and swarm-mode
[2017-08-22 12:07:59] <webertrlz> I thought of that, but we have disabled iptables on the clusters that this happens, and its still the same
[2017-08-22 12:12:13] <InTheCloudDan> webertrlz: normally with something like that I would think ARP table, but I'm not familiar enough with docker networking
[2017-08-22 12:14:15] <webertrlz> InTheCloudDan: Could be. It's quite difficult to debug this. It looks like the sent packages don't reach the destination container so Arp is a good guess. I'll look into that.
[2017-08-22 12:15:32] <InTheCloudDan> yeah in the case of A->B an invalid entry, then B arps for A when it's going to ping and refreshes everything, is a possibility
[2017-08-22 12:16:19] <webertrlz> Thanks for the fresh thought@InTheCloudDan, i'll try to reproduce it (it happens kind of random)
[2017-08-22 14:00:34] <SISheogorath> disabling iptables isn't a good idea. iirc docker requires iptables
[2017-08-22 14:01:04] <SISheogorath> for things like NAT and internal rewrites
[2017-08-22 14:01:13] <webertrlz> SISheogorath: Sorry I meant we have removed all custom rules. The iptables service is still present, but only docker is managing it.
[2017-08-22 14:02:05] <webertrlz> We set up a new cluster from with fresh new installs and we didn't even touch iptables to be sure it's not any custom rules.
[2017-08-22 14:04:03] <SISheogorath> Mhm if it still happens then, I would suggest to open an issue on github and hope to find more help there
[2017-08-22 14:05:59] <webertrlz> SISheogorath: I tried IRC and Docker forums, no success. I have found many similar issues on github and all of them without solution.I think they won't look into it as long as it's not reproducible. It happens a lot in production but not when I want it to happen.
[2017-08-22 14:07:17] <SISheogorath> I see. I guess as long as you don't have an EE subscription there won't happen much with a non-reproducible problem :/
[2017-08-22 14:08:27] <SISheogorath> I'm neither a docker official, nor a docker developer, so I guess I can't help you a lot here
[2017-08-22 14:09:35] <webertrlz> Yeah, I guess so. Until I can reproduce it I\'ll keep on "warming the wire" by pinging back when this happens.
[2017-08-22 19:25:06] <NickJames-minted> I'm having an issue with volume access in a container. I'm my entrypoint script runs an ansible playbook and I'm seeing some odd behavior. Anyone got a sec?
[2017-08-22 19:25:37] <NickJames-minted> My docker compose file sets volumes to share between the host and the container, and everything runs fine on my local, but not on my ubuntu ec2 instance
[2017-08-22 19:28:30] <NickJames-minted> one thing the container has to do is write a file for ansible to be able to sudo, which docker is trying unsuccessfully. I can add this file manually, but still see some weird behavior when Ansible tries to find files. This may be a question for Ansible people, but I figured someone here may have run into this since the only difference appears to be the docker-compose version (1.15 on my ec2, 1.14 on my mac)
[2017-08-22 19:59:15] <SISheogorath> NickJames-minted: I'm not sure what you try, can you share your Dockerfile and entrypoint script and explain a bit more detailed, what you try and what doesn't work?
[2017-08-22 20:01:44] <NickJames-minted> here's my docker-compose block:
[2017-08-22 20:02:17] <NickJames-minted>  [<-CODE->] 
[2017-08-22 20:03:31] <NickJames-minted> the python module I want to install lives in the/usr/local/airflow/bivolume
[2017-08-22 20:05:24] <NickJames-minted> myentrypoint.shscript tries to run a few pip installs like this:
[2017-08-22 20:05:47] <NickJames-minted> pip install -e $DEPLOY_PATH/bi/m_jobs/sake/ --user
[2017-08-22 20:06:16] <SISheogorath> Is$DEPLOY_PATH/bi/writable to for the user you use in the container?
[2017-08-22 20:07:24] <NickJames-minted> so the question i have is about those permissions actually
[2017-08-22 20:07:42] <NickJames-minted> when I dols -lafrom inside the container the owner isusers
[2017-08-22 20:08:29] <SISheogorath> usually it is a question of permissions ^^
[2017-08-22 20:08:34] <NickJames-minted> yea I agree with you
[2017-08-22 20:08:51] <NickJames-minted> but i've never see ownership show up asusers:rootbefore
[2017-08-22 20:08:58] <NickJames-minted> i run a non-root user in my container
[2017-08-22 20:09:06] <NickJames-minted> so in my dockerfile I've added that user to the grouproot
[2017-08-22 20:09:13] <NickJames-minted> and am hoping that it gains write permissions
[2017-08-22 20:09:36] <SISheogorath> can you run it withls -ln?
[2017-08-22 20:10:04] <SISheogorath> And then check that the uid is the same when you runid -u
[2017-08-22 20:10:30] <NickJames-minted> yea it's the only non-root user so it's 1000
[2017-08-22 20:10:45] <NickJames-minted> but for that directory it's 1010!
[2017-08-22 20:10:47] <NickJames-minted> hmmm
[2017-08-22 20:11:02] <NickJames-minted> 1010:0
[2017-08-22 20:11:05] <SISheogorath> there is your problem :D
[2017-08-22 20:11:49] <NickJames-minted> so where is the best way to set htese permissions? The volume isn't actually mounted until after the image is built, so I can't do it in the dockerfile, and by the time I'm in my entrypoint script I'm running as non-root user
[2017-08-22 20:12:02] <NickJames-minted> this worked natively on my local
[2017-08-22 20:13:43] <SISheogorath> the official images solve these problems by starting as root, chown the directories and then drop the permissions usinggosu(notsudoorsubecausesudoandsucreate issues with signals)
[2017-08-22 20:15:03] <SISheogorath> I personally set the uid for my images to a fixed value and chown the directories on the machine before running them
[2017-08-22 20:15:12] <SISheogorath> that's a question of your choice
[2017-08-22 20:18:36] <NickJames-minted> i see. I'd like to try that approach. The only issue is that these files are actually being used by the host at the moment
[2017-08-22 20:18:48] <NickJames-minted> an unprivileged user
[2017-08-22 20:19:06] <NickJames-minted> so chowning them would break the processes running on the host
[2017-08-22 20:19:41] <SISheogorath> that's unperfect .-.
[2017-08-22 20:19:53] <NickJames-minted> hah yes I fully admit that.
[2017-08-22 20:20:10] <NickJames-minted> I'm basically transitioning an environment into a docker container in piecemeal fashion
[2017-08-22 21:03:26] <SISheogorath> you can use gids to map them together
[2017-08-22 21:09:38] <NickJames-minted> i think the easiest thing to do is get those pip packages out of the repo altogether
[2017-08-22 21:10:18] <NickJames-minted> while it's frustrating, i tend to agree with the idea that hte container should not be editing files in the host filesystem
[2017-08-22 21:10:52] <NickJames-minted> and I'm not explicitly trying to write anything. I'm just trying topip install -e /path/to/python/package --user
[2017-08-22 21:12:12] <NickJames-minted> writing requirements to minted_etl.egg-info/requires.txt\n    error: [Errno 13] Permission denied: 'minted_etl.egg-info/requires.txt'
[2017-08-23 05:07:38] <VQuery> Hi all
[2017-08-23 05:08:07] <VQuery> i am going to create docker slave in my jenkins
[2017-08-23 05:08:28] <VQuery> please guild me how to create docker slave
[2017-08-23 05:09:05] <VQuery> i am using windows 8.1 machine and installed docker tool box
[2017-08-23 05:29:20] <VQuery> please any one guild me the steps
[2017-08-23 07:10:10] <SISheogorath> VQuery: I think that's more a Jenkins thing than docker:
[2017-08-23 07:10:15] <SISheogorath>  [<-LINK->] 
[2017-08-23 07:17:08] <sabrehagen> I'm having trouble with an exposed port that is getting connection refused. It responds inside the container, but not outside. Can somebody review this log to help me debug please? [<-LINK->] 
[2017-08-23 09:13:37] <VQuery> how to find docker host IP in my machine ?
[2017-08-23 09:13:50] <VQuery> please suggest
[2017-08-23 09:23:15] <SISheogorath> VQuery: when you use docker toolbox you'll find it in the virtual box interface, iirc
[2017-08-23 09:23:20] <SISheogorath> (I'm not a windows user)
[2017-08-23 09:24:47] <SISheogorath> sabrehagen: can you please provide the output ofnetstat -ln | grep :9229from inside your container?
[2017-08-23 09:27:20] <VQuery>  [<-LINK->] 
[2017-08-23 09:27:28] <VQuery> SISheogorath: ,facing this issue ,pls help me
[2017-08-23 09:30:03] <SISheogorath> replacehttpwithtcpin your URL
[2017-08-23 09:30:46] <SISheogorath> But I don't know how usable it is with windows base system
[2017-08-23 10:00:33] <ndpratas> QUESTIONCan I specify which node I want a container (or the entire stack) to run in a "docker stack" deploy?
[2017-08-23 10:16:19] <gluxix> Всем привет! Делаем микросервис на Docker. Нужно чтобы один контейнер (FROM alpine) коннектился к AP Wi-Fi другого устройства. Как это из под контейнера сделать? Испольщуем Node.js и для управления wi-fi - npm модуль node-wifi, с реальной машины проблем нет.
[2017-08-23 10:17:10] <gluxix> Ups
[2017-08-23 10:20:23] <gluxix> Sry :D Hello all! We are doing microservice with Docker. The docker container (FROM alpine) need connect to other device Wi-Fi. We use node.js (node-wifi for network managment). How we can do it from docker container? (It’s work fine on real machine).
[2017-08-23 10:56:21] <SISheogorath> Wifi in a docker container? I would go for changing network/network_mode to host and add CAP_NET_ADMIN (which makes the container like privileged mode) and see what happens. Should work then like outside a container
[2017-08-23 10:56:32] <SISheogorath> But doesn't make a lot of sense to me
[2017-08-23 11:10:35] <gluxix> Actually, we need get access to wireless interface of host machine. Docker must be able to manage host wifi iface. For examle: this microservice receive http request (within REST) from user (or other microservice) and the container must connect to other WiFi AP.
[2017-08-23 11:11:51] <gluxix> … and the container must connect to other WiFi AP within HOST’S wireless iface
[2017-08-23 11:15:05] <SISheogorath> Sounds crazy :D I like it ^^
[2017-08-23 11:15:31] <gluxix> SISheogorath: :D
[2017-08-23 11:30:32] <comeUpWithItLater>  [<-LINK->] 
[2017-08-23 11:30:49] <comeUpWithItLater> so how to view service log ?
[2017-08-23 11:42:05] <SISheogorath> docker service logs <servicename>if you run an up-to-date docker version
[2017-08-23 11:42:43] <SISheogorath> otherwise:docker service ps <servicename>and thendocker logs <taskname>on the machine where it was deployed
[2017-08-23 13:51:01] <comeUpWithItLater>  [<-LINK->] 
[2017-08-23 13:51:15] <comeUpWithItLater> how to find taskname ?
[2017-08-23 13:51:23] <comeUpWithItLater> which col?
[2017-08-23 13:55:24] <InTheCloudDan> webertrlz: any luck with the networking?
[2017-08-23 14:13:27] <ndpratas> QUESTIONCan I specify which node I want a container (or the entire stack) to run in a "docker stack" deploy?
[2017-08-23 14:18:38] <SISheogorath> ndpratas: here you go: [<-LINK->] 
[2017-08-23 14:19:10] <SISheogorath> comeUpWithItLater: You should switch to the node where it's running and run docker ps. the task id is then part of the name
[2017-08-23 14:22:23] <ndpratas> SISheogorath: Hey THANKS. Now... Can I say "hey docker, run thisentire stackin whatever node"?
[2017-08-23 14:22:54] <SISheogorath> when you use an environment variable, iirc yes
[2017-08-23 14:23:07] <ndpratas> because I don't really want to specify the node this time around. I just want every container to run on the same node
[2017-08-23 14:23:58] <ndpratas> do you happen to know how can I do that?
[2017-08-23 14:24:11] <ndpratas> SISheogorath: 
[2017-08-23 14:25:29] <SISheogorath> the schema you search for is called "sidekick-container" in K8s and if they didn\'t changed it in 17.07 or 17.08 not possible right now
[2017-08-23 14:26:10] <ndpratas> aren't we in 17.06? :S
[2017-08-23 14:26:12] <SISheogorath> at least not without explicit deploying the containers to a specific node
[2017-08-23 14:26:21] <SISheogorath> 17.06 is current stable, yes
[2017-08-23 14:26:26] <ndpratas> ok
[2017-08-23 14:27:18] <ndpratas> Well thank you@SISheogorath
[2017-08-23 14:27:34] <SISheogorath> You're welcome
[2017-08-23 14:29:10] <ndpratas> SISheogorath: BTW, it's the same if ... say... I wanted two of the 4 containers in my stack to run on the same node but the others have no specific restriction... right?
[2017-08-23 14:29:33] <SISheogorath> yep
[2017-08-23 14:29:55] <ndpratas> "same node" like Whatever node as long as they are deployed together lol
[2017-08-23 14:30:34] <ndpratas> SISheogorath: Ok, thank you so much. you're very kind. I believe it's not the 1st time you helped me.
[2017-08-23 20:41:35] <jpreese> Question: How can I mount the current directory to a directory in the container? I've tried running docker run -v /${PWD}:/tmp --rm -it --name my-container myimage bash   as well as some alternatives, but no luck. My goal is to set up a development environment, so the host location isn't always going to be known (unless we're forced to state one)
[2017-08-23 20:42:33] <jpreese> So I'd like to be able to share the host current directory with a directory in the container so the files are accessible by both. This way I could say.. create source code on the host machine and compile it in the docker container
[2017-08-23 21:33:21] <jpreese> Answer: "%cd%"
[2017-08-23 21:46:48] <johndoeneu_twitter> Can docker swarm scale to more than 1000 nodes?
[2017-08-23 21:47:02] <johndoeneu_twitter> I see many articles referring to 1000 as the max
[2017-08-23 21:47:50] <johndoeneu_twitter> Thus does it imply it shouldn't be used for a production website?
[2017-08-24 05:55:24] <sabrehagen> johndoeneu_twitter: that's a large size swarm. I don't know if 1000 is the cap. However I'm interested in your workload that requires 1000 nodes. Could you share?
[2017-08-24 05:55:32] <sabrehagen> I'm really stuck on a problem. I've put my repro steps here. Can anyone figure this out? [<-LINK->] 
[2017-08-24 09:03:58] <SISheogorath> johndoeneu_twitter: if you referring to [<-LINK->] it simply an example size. There is no technical reason why docker swarm should be limited to 1000 nodes
[2017-08-24 13:21:56] <w9n> hi, im currently using custom containers that i manually have to attach to volumes to create and restore backups. Is there any integration i didnt see? something like docker volume backup/restore <name> <path> via remote api would be fantastic....
[2017-08-24 13:27:15] <SISheogorath> You can usedocker cp containerid:/path/in/container /local/path
[2017-08-24 13:30:00] <w9n> thats a nice one i didnt see, thanks!
[2017-08-24 14:44:22] <brunorpinho> Is [<-LINK->] returning a database error for anyone else?
[2017-08-24 14:44:56] <amanagarwal2189> yep
[2017-08-24 14:45:33] <brunorpinho> They should containerize it
[2017-08-24 14:45:39] <amanagarwal2189> lol
[2017-08-24 14:45:47] <brunorpinho> hahaha
[2017-08-24 14:46:16] <amanagarwal2189> or the whole thing would have gone down!! they will fix it in a jiffy
[2017-08-24 14:47:11] <brunorpinho> the docs are fine, it is just the main page
[2017-08-24 14:47:54] <amanagarwal2189> yeah.. even hub is doing fine
[2017-08-24 15:06:39] <sabrehagen> Is this a docker issue, or some other part of my stack? [<-LINK->] 
[2017-08-24 15:26:10] <jpreese> If we have a recommended way that we'd like the consumers of our docker images to run our image, is it just common practice to put it up on dockerhub? Or is there a way to provide a run script so all they need to do is docker run image, where run would actually have a lot more parameters to it.. or some other process?
[2017-08-24 15:26:37] <jpreese> For example, if I wanted a dotnet environment and mount the current directory so they could work on code on the host machine then build it in the container, I\'m doing.. docker run -v "%cd%":/root/dev -it --name dev-dotnet-docker microsoft/dotnet:latest bash
[2017-08-24 15:29:53] <amanagarwal2189> jpreese: i guess bith the ways should be fine... but that would be really helpful if other community members can comment
[2017-08-24 15:38:20] <SISheogorath> jpreese: docker runisdocker run. Not more.atomicprovides such a functionality using an install and run label, but native docker ignores it.
[2017-08-24 15:38:59] <SISheogorath> In general you should avoid these things or provide a docker-compose file to stay transparent
[2017-08-24 15:40:10] <jpreese> I was under the impression that compose was mostly for multiple services
[2017-08-24 18:08:57] <8Gitbrix> andela-cwekesa: I fixed it. To run a local file in a docker image I useddocker run -it --rm -v $(pwd):/workdir dockerimagename python filename.py
[2017-08-24 18:09:08] <8Gitbrix> and got it working
[2017-08-24 18:25:24] <webertrlz> InTheCloudDan: haven't been able to reproduce it yet
[2017-08-24 21:18:14] <MarkoShiva> guys I have a local registry that is running in swarm mode at the moment it is not on my local machine but on one of the vm's. how to access it? Is there a way to force a service to stay on one node in swarm mode? Also specifying 127.0.0.1:5000 doesn't really make sense if the service is replicated and need to access the image in local repository from VM. Can someone help with this?
[2017-08-25 00:06:23] <amanagarwal2189> jpreese: yes it can also run multiple services. but it is a cleaner and straight-forward way to start a container
[2017-08-25 00:06:59] <amanagarwal2189> your customers do not need to go through thedocker runcommand.
[2017-08-25 00:56:17] <DWSR> Hey all, I'm trying to get a Docker Swarm stood up in AWS via Terraform using some steps from this guide: [<-LINK->] . I'm having an issue, however, with usingdocker -Hto retrieve the token from the manager on the prospective worker nodes. I just receivemalformed HTTP request. The docker versions on each of these is exactly the same (they're spun up from the same AMI). How can I remotely retrieve the worker token?
[2017-08-25 14:06:21] <hinell> Hello guys. In case you are experiencing problems with latest docker updates of the edge version on the windows (or others) here is the issue I have opened requesting the old docker versions to be published: [<-ISSUE->] Your help is appreciated so please comment. Thanks.
[2017-08-26 02:31:07] <vinifala>  [<-CODE->] Having trouble trying to set this volume for mongo to work with my data. Above is my docker-compose.yml and this is what I get in the terminal [<-CODE->] I'm running windows
[2017-08-26 02:46:51] <vinifala> Been struggling with it for days,  tried many methods, this seems to be the closer.
[2017-08-26 12:19:18] <w9n> vinifala: it says operation not permitted, probably because of the file permissions
[2017-08-26 19:01:44] <hinell> vinifala: Have you specified your/data/dbfolder to--dbpathoption of themongodinstance  ?
[2017-08-26 19:58:14] <hinell> vinifala: Well, just rendered your problem and got the same error. If you specify/data/instead of/data/dbthen it works well.
[2017-08-26 20:12:05] <AwelEshetu> vinifala: what is docker ?
[2017-08-26 20:13:33] <hinell> lol
[2017-08-26 20:14:20] <AwelEshetu> hinell: what is docker ?
[2017-08-26 23:17:50] <SISheogorath> AwelEshetu: bot? If not, here you go: [<-LINK->] 
[2017-08-27 00:45:53] <buhman> is there an easier way to do secure docker authentication on CI than TLS client auth?
[2017-08-27 00:46:21] <buhman> it seems like getting the client cert files in ~/.docker is a bit ugly
[2017-08-27 01:29:11] <vinifala> hinell: I now get "Can\'t create lock file in read only directory error"
[2017-08-27 01:29:57] <vinifala> I decided to just go with named volumes. Does someone know where such volumes sit in the host machine in Windows?
[2017-08-27 15:22:31] <Karl-EdwardFPJeanMehu> vinifala: Try changing the permissions for the directory you're trying to create the volume in. If you're running on Mac / Linux you can use the chmod command
[2017-08-27 15:40:13] <bkawk> Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)Anyone else getting this?
[2017-08-27 16:17:13] <hinell> vinifala: The named volumes  are volumes created bydocker volumeright?
[2017-08-27 18:01:06] <SISheogorath> bkawk: happens sometimes when docker hub isn't working perfect, but usually happens when there is a local network issue like missing firewall rules for your host or broken proxy config
[2017-08-27 18:01:38] <SISheogorath> hinell: yes.
[2017-08-27 19:02:03] <MarkoShiva> guys any idea how to setup EndPoint in dnsrr I get this errorport published with ingress mode can't be used with dnsrr modewhe try to deploy my stack.
[2017-08-27 19:32:56] <SISheogorath> in1t3r: can you share your stack file?
[2017-08-27 20:36:25] <MarkoShiva>  [<-CODE->] 
[2017-08-27 20:36:51] <MarkoShiva> at the moment I have turned off dnsrr
[2017-08-27 21:51:09] <SISheogorath> My guess: you can't combine published ports with the dnsrr setting
[2017-08-27 22:50:40] <vinifala> hinell: I'd assume so. I'm using docker-compose to spin a nodejs and mongo container.
[2017-08-27 23:15:16] <vinifala> @hinell my docker-compose file looks like this [<-CODE->] mongodb's Dockerfile: [<-CODE->]  [<-CODE->] 
[2017-08-28 08:32:13] <hanchenyi> Hi, guys. Have you experienced a problem like  no space left on device ? I have removed some logs and there is 16G space left. But after that I can not pull docker images from docker hub, it comes out that Error response from daemon: EOF. Is there anyone has similar problems ?
[2017-08-28 10:40:54] <DeshdeepDivakar> hanchenyi: delete the Docker.qcow2 and restart docker
[2017-08-28 11:06:04] <elcolie> hanchenyi:  [<-LINK->] Try remove your images.
[2017-08-28 12:18:35] <UniFreak> Hi, I’m trying to set up a lemp stack, I decided to build a nginx image, a php-fpm image, but one question remained: say I have three project: api.sample.com, erp.sample.com and fin.sample.com, should these three project have their own image?
[2017-08-28 12:19:08] <UniFreak> And how can I configure docker so that they all can access other project by domain name?
[2017-08-28 12:20:09] <adaliszk> proxy_pass?
[2017-08-28 12:21:17] <UniFreak> adaliszk: I read lots of tutorial on docker, they all seems to access project in docker via ip
[2017-08-28 12:21:33] <UniFreak> can I access them in my host by domain name?
[2017-08-28 12:21:54] <adaliszk> sure, if you use some server likenginxwhat you mentioned before the containers
[2017-08-28 12:22:41] <adaliszk> so you should have a "proxy" which will handle the domain itself and will forward the requests to the desired container
[2017-08-28 12:23:09] <adaliszk> also with this proxy you could show a nice "in maintenance" page when your container is down for some reason
[2017-08-28 12:23:45] <UniFreak> So, basicly I will have those container: nginx, php-fpm, my three project and a proxy?
[2017-08-28 12:24:54] <adaliszk> you can use nginx as your proxy
[2017-08-28 12:25:38] <adaliszk> btw I recommend to use php with litespeed in your containers, literally about 2x as fast than fpm
[2017-08-28 12:25:52] <adaliszk> (phpearth/php:litespeed)
[2017-08-28 12:26:28] <UniFreak> Thanks but for now I’m just trying to get a enviroment mirroring my company’s production env
[2017-08-28 12:26:44] <adaliszk> sure
[2017-08-28 12:30:11] <amanagarwal2189> i guess even container name/ service name is sufficient for establishing a network (all containers should be in the same network)
[2017-08-28 12:30:15] <UniFreak> adaliszk: what should I do to let that nginx proxy forward request made by my host machine? forward all 80 port request to it?
[2017-08-28 12:32:59] <adaliszk> UniFreak: somethink like this: [<-CODE->] 
[2017-08-28 12:34:28] <adaliszk> ofc you can use your local container ip address like172.17.0.1:80
[2017-08-28 12:35:05] <adaliszk> then your container should take over and handle the request by himself with whatever server you build into it
[2017-08-28 12:37:35] <adaliszk> also if you search for you can find automatic scripts which will generate this vhost config for you using ENV varables
[2017-08-28 12:39:29] <adaliszk> and@amanagarwal2189yes, they should be on the same network or they output has to be published on the hosts
[2017-08-28 12:39:44] <UniFreak> I’m not sure you understand my problem: I want to access the php projects using their domain name likeerp.sample.comin myhost machine. your paste seems like a typical nginx site configuration
[2017-08-28 12:40:33] <adaliszk> change theserver_nametoerp.sample.comand you are good to go
[2017-08-28 12:41:17] <UniFreak> do I need to edit my host machine’s host file, to point those domain name to that proxy’s ip?
[2017-08-28 12:41:51] <adaliszk> it depends on where the domains are pointed, if they are pointed nowhere or somewhere else you should override them to your localhost
[2017-08-28 12:42:21] <adaliszk> then your local server can resolve the domain names which will eventually pass you to your containers
[2017-08-28 19:57:16] <tudvari-nng> Hi Guys, I would like to prevent copy files from my container, are there any possibility to achive this ?
[2017-08-29 00:24:47] <DeshdeepDivakar> Hey guys, have anyone tried to setup proxy access to docker stack service from a container outside the stack?
[2017-08-29 03:00:25] <DeshdeepDivakar> ?? any ideas are highly appreciated
[2017-08-29 04:16:10] <VQuery> Hi folks
[2017-08-29 04:16:44] <VQuery>  [<-LINK->] 
[2017-08-29 04:16:52] <VQuery> How to find docker Url ?
[2017-08-29 04:17:22] <VQuery> i have used this image [<-LINK->] 
[2017-08-29 04:18:22] <VQuery> and created container with below commentsdocker run -d -p 80:80 bibinwilson/jenkins-slave
[2017-08-29 05:10:21] <VQuery> please update any docker user!! 
[2017-08-29 15:43:21] <cheenamalhotra> The URL to use to access your Docker server API (e.g: [<-LINK->] )
[2017-08-29 15:44:07] <cheenamalhotra> Refer here [<-LINK->] 
[2017-08-29 15:46:51] <amanagarwal2189> VQuery: you mean the network details?
[2017-08-29 15:48:37] <amanagarwal2189> something likedocker network inspect <network-name>
[2017-08-29 16:57:42] <MarkoShiva> what is a proper way to start a swarm. I usedocker swarm init --advertise-addr my-laptop-lan-address-on-wifiI have a pretty tedious project to work on. The services work correctly one with each other in the stack deploy also tests work properly in drone.yml. However if I'm targeting my own lan address with curl to test the bashserver it hangs sometime.
[2017-08-29 16:57:46] <MarkoShiva>  [<-LINK->] 
[2017-08-29 17:02:13] <MarkoShiva> maybe to post it as a snipet: [<-CODE->] The compose runs without problem and deploy mode too just I'm not sure why it hangs sometime. It uses overlay network should I specify VIP or DNSSR as endpoint mode? Also I read somewhere that for dnsrr I need to not have explicitly exposed ports in compose file maybe that is wrong I'm still learning advanced docker topics.
[2017-08-30 01:48:56] <geejay1225> this link above explained a little to me. "what is docker? [<-LINK->] 
[2017-08-30 01:49:42] <geejay1225> but i still never got past the login screen. So i dont know much about it
[2017-08-31 00:34:18] <hanchenyi> hi guys. Does anyone know how to fix port conflict. When I docker run these two rest containers, I set --endpoint equals to localhost:10003 and localhost:10004. Currently these two can not run together. After I start one of them, I try to start the other container, the error in logs metions that port 8080 already in use.
[2017-08-31 00:59:01] <echiphn> hanchenyi: I think that you get wrong port mapping. it should be -p 10003:8080 -p 10004:8080
[2017-08-31 08:30:42] <umrashrf> Hey, why would dockerfile "ADD filename.txt /dirname" won\'t work?
[2017-08-31 08:30:57] <umrashrf> "ADD . /dirname" works well though
[2017-08-31 08:42:09] <umrashrf> Nevermind, I was doing it wrong
[2017-09-01 09:24:42] <sandys> hey guys - all the containers on my server with docker swarm 17.06 are getting restarted every 30 minutes. im not sure what is going on. anyone else have similar issues ?
[2017-09-01 09:25:39] <withlin> do you use overlay network、
[2017-09-01 09:25:40] <withlin> ？
[2017-09-01 09:25:50] <sandys> yes
[2017-09-01 09:27:06] <sandys>  [<-CODE->] 
[2017-09-01 09:28:06] <withlin> oh, i have a meeting. ...
[2017-09-01 09:29:00] <sandys> i also have this set in daemon.json
[2017-09-01 09:29:08] <sandys>  [<-CODE->] 
[2017-09-01 13:44:35] <lrcorrea> Hi guys. I installed docker on windows 10 and when rebooted windows does not start anymore, someone has already seen this problem?
[2017-09-01 16:36:12] <brentarias> lrcorrea: Not heard of this.  Try starting in safe mode?
[2017-09-01 16:48:39] <brentarias> I\'m reading "Docker on Windows" (Elton Stoneman). The book suggests that I use a Docker image, containing IIS, to launch multiple ASP.NET web sites each in its own container;  therefore each web site would not share an app pool (full isolation) even though all of them are in the IIS default app pool.  This sounds great from a simplicity POV, but this sounds like a memory liability.  It sounds like I would be running several instances of IIS in memory simultaneously (each within its own container), rather than running IIS as a single process.  From a memory-efficiency POV, isn\'t that a bad thing?
[2017-09-01 18:36:33] <lrcorrea> brentarias: I did a restore and started it again. Really not good.  thanks Brent
[2017-09-02 08:00:52] <comeUpWithItLater> how to  ssh into a windows container(mssql)  ?
[2017-09-02 08:01:17] <comeUpWithItLater> docker exec -it  <container>   /bin/bash  # <- no bash  in  windows
[2017-09-02 10:26:24] <SISheogorath> should work with powershell
[2017-09-02 10:26:29] <SISheogorath> instead of bash
[2017-09-02 10:49:13] <SISheogorath> comeUpWithItLater: ^
[2017-09-02 11:03:01] <comeUpWithItLater> downloading  a  2016-sp1-windowsservercore-10.0.14393.1480 6 GBWindows - x86-64  and trying
[2017-09-02 11:03:49] <comeUpWithItLater> docker exec -it <container>   powershell   #<- something like this
[2017-09-02 11:11:36] <SISheogorath> I guess so, yes
[2017-09-02 11:40:12] <HussainMirahmadi> hi eveyone
[2017-09-02 11:40:30] <HussainMirahmadi> I have neo4j on laradock on docker
[2017-09-02 11:40:48] <HussainMirahmadi> laradock/laradock
[2017-09-02 11:41:16] <HussainMirahmadi> I can browse my neo4j via broswer linklocalhost:7474
[2017-09-02 11:41:58] <HussainMirahmadi> but when I try to access the neo4j via code
[2017-09-02 11:42:03] <HussainMirahmadi> I get this error :
[2017-09-02 11:42:25] <HussainMirahmadi> Http\\Client\\Exception\\NetworkException with message 'cURL error 7: Failed to connect to localhost port 7474: Connection refused (see http://curl.haxx.se/libcurl/c/libcurl-errors.html)'
[2017-09-02 11:42:44] <HussainMirahmadi> any comments ?
[2017-09-02 11:52:21] <SISheogorath> HussainMirahmadi: Sounds like a in-container error. Since docker itself doesn't use curl. You should contact the image vendor
[2017-09-02 12:29:24] <HussainMirahmadi> thanks@SISheogorath
[2017-09-02 12:29:59] <HussainMirahmadi> when I dodocker-compose ps
[2017-09-02 12:30:36] <HussainMirahmadi> theStateparameter of a container is set toExit_1
[2017-09-02 12:30:40] <HussainMirahmadi> what does it mean ?
[2017-09-02 12:43:37] <SISheogorath> that the container terminated itself
[2017-09-02 12:43:41] <SISheogorath> with exitcode 1
[2017-09-02 18:41:24] <HussainMirahmadi> could I have more than one volume in a docker file ?
[2017-09-02 19:48:00] <SISheogorath> HussainMirahmadi: See: [<-LINK->] 
[2017-09-02 19:48:11] <SISheogorath> simply put an array of volumes in your volume tag
[2017-09-02 19:49:00] <HussainMirahmadi> thanks
[2017-09-02 20:04:33] <HussainMirahmadi> like this ?
[2017-09-02 20:04:36] <HussainMirahmadi> VOLUME ['/var/lib/neo4j/data','/var/lib/neo4j/plugins']
[2017-09-02 20:04:51] <HussainMirahmadi> it didn't work
[2017-09-02 20:05:12] <HussainMirahmadi> I also edited thedocker-compose.ymlfile
[2017-09-02 20:05:24] <HussainMirahmadi> like this =
[2017-09-02 20:05:40] <HussainMirahmadi> `      volumes: [<-CODE->] 
[2017-09-02 20:05:51] <HussainMirahmadi> yet it didn't work
[2017-09-03 08:38:32] <fleed> hi allI'm trying to create a composer file for Wordpress using an external volume that I've created: [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] thank you for support
[2017-09-04 07:23:09] <VQuery> any one using windows docker slave agent in jenkins ?
[2017-09-04 09:41:22] <VQuery> is this possible ?
[2017-09-04 12:00:45] <igor-ramazanov> Hi, everyone!
[2017-09-04 12:00:47] <igor-ramazanov> Is there some ready tool for supervising and upgrading of docker containers.It should upgrade container by polling for commands from remote server with ability to specify its CLI arguments.And also it should restart container in case if it failed, and if it failed several times, it should run an old version of container with old arguments.
[2017-09-04 12:34:04] <igor-ramazanov> And another question - is it possible - update a docker container from inside itself?
[2017-09-04 22:47:13] <denizs> themirrortruth: the optimal solution would be to use some orchestration tool like cloudformation or kubernetes to roll out immutable updates, whenever you introduce major changes
[2017-09-04 22:50:43] <danieldram> Anyone avail to help troubleshoot an issue? I am all out of ideas
[2017-09-04 23:09:36] <neetjn> Hey doods
[2017-09-04 23:10:11] <neetjn> I know this isn't necessarily the correct room, but seeing as to I can't find any NGINX discussions:
[2017-09-04 23:10:24] <neetjn> I'm having some trouble running NGINX dockerized.
[2017-09-04 23:10:44] <neetjn> It's reading my config fine, volume linking is gravy.
[2017-09-04 23:10:50] <neetjn> But it's not actually working.
[2017-09-04 23:11:05] <neetjn> I have another dockerized application running on my server, that's forwarded to port 5000. Should I link the containers, or should it not matter (I'm assuming it shouldn't).
[2017-09-04 23:11:26] <danieldram> I have an issue where when I try to build with docker-compose it says the Dockerfile is empty but it is in the same directory
[2017-09-04 23:12:12] <neetjn> danieldram: is this in version control?
[2017-09-04 23:13:16] <danieldram> Not sure what you mean, my docker version is 17.06 and docker-compose is 1.16
[2017-09-04 23:13:38] <neetjn> I'm saying is this on GH or on Bitbucket so I can pull it down and check it out?
[2017-09-04 23:14:29] <danieldram> ah unfortunately, I can't upload the code
[2017-09-04 23:14:36] <danieldram> IP..
[2017-09-04 23:14:43] <danieldram> not my project
[2017-09-04 23:15:06] <danieldram> But when I installed docker and docker-compose, it won't build it. I can attach the files though
[2017-09-04 23:15:16] <danieldram> for docker-compose and dockerfile if that helps?
[2017-09-04 23:31:43] <danieldram> I have no idea what to do
[2017-09-04 23:32:08] <danieldram> I installed a new docker, I see both files, they are legit. I run docker-compose build and it says the Dockerfile is empty. I'm on mac osx
[2017-09-04 23:48:18] <danieldram> Is anyone having this issue?
[2017-09-05 04:03:11] <amanagarwal2189> hey people... is there a docker-compose.yml equivalent ofdocker run --user=demo_user:group1 <image_name> <command>
[2017-09-05 04:04:07] <amanagarwal2189> the aim is to allow only a specific user to access the container running for that particular service
[2017-09-05 07:16:20] <SISheogorath> amanagarwal2189:  [<-LINK->] 
[2017-09-05 07:16:40] <SISheogorath> It's simplyuser:
[2017-09-05 08:46:36] <elcolie> Hi
[2017-09-05 08:47:03] <elcolie> I want to letrootuser executeshell_scritp.sh
[2017-09-05 08:47:43] <elcolie> But my container ispostgres.  Then I have to put my initialization script in/docker-entrypoint-initdb.d
[2017-09-05 08:48:06] <elcolie> Everything in this directory will be execute by userpostgres. It is just fine.
[2017-09-05 08:48:16] <elcolie> The problem raises when I have to do tunnelling
[2017-09-05 08:49:05] <elcolie> The container has no/home/postgres/.ssh
[2017-09-05 08:49:45] <elcolie> And that script involvesshtunnelling. To get production database to container itself.
[2017-09-05 08:50:55] <elcolie> Right now I have to manually execute thescriptby jump into the container and do it myself
[2017-09-05 10:24:40] <SamwiseUP> hello. docker noob here. Trying to setup reverse proxy with nginx-proxy to host multiple sites on a single host running docker.nginx-proxy is running fine. created two containers of wordpress sites to test.I’m able to access test1.dev but test2.dev gives me 502 bad gateway. Not sure what the problem is.I made sure to give differnet names for the wp container as well as the database containers. Virtual Host is setup correctly I think. Do the containers have to be exposing different ports? they are both exposing port 80
[2017-09-05 13:01:13] <elcolie> Hi. I need your opinion on my question. [<-LINK->] 
[2017-09-05 14:29:27] <SISheogorath> elcolie: check the value of$HOMEinside the container when running as postgres user. There should be one
[2017-09-05 14:34:08] <SISheogorath> themirrortruth: Maybe a bit late, but restarting a container can be done by--restart=alwaysor--restart=on-failureparameter and it's equivalent in docker-compose. Also when you deploy it as docker service (swarm-mode) It'll be provided automatically. When it comes to automated updates, the general advice is to do it by version control or similar, but if you go for mutable tags: [<-LINK->] This is what I used in some previous projects
[2017-09-05 15:52:06] <amanagarwal2189> SISheogorath: : when i am trying to bring up the container, the starts and then exits with code 1
[2017-09-05 18:21:31] <SISheogorath> amanagarwal2189: Check the logs. Sounds like a permission issue. The often appear when you run container with bind volumes
[2017-09-05 19:08:05] <rightisleft> Howdy - im trying to figure out why my docker instnace does not contain my pg_hba.conf files when extending the postgres  image
[2017-09-05 19:09:01] <rightisleft>  [<-CODE->] 
[2017-09-05 19:09:27] <rightisleft> when i exec into the container - /var/lib/postgresql/data/pg_hba.conf shows the default config
[2017-09-05 19:42:15] <SISheogorath> simple reason:/var/lib/postgresql/data/is a volume. volumes can't be modified after they are defined
[2017-09-05 19:43:00] <SISheogorath> rightisleft: See [<-LINK->] 
[2017-09-05 21:23:25] <avierax> why knows why does launching a container with a mounted directory does not populates this directory with what's already in that mount point in the image?
[2017-09-05 21:24:10] <avierax>  [<-CODE->] issuesfile not found /usr/local/apache2/conf/httpd.conf
[2017-09-05 22:00:29] <SISheogorath> Because that are bindmounts, which have various pros and cons. You should avoid them in general
[2017-09-05 22:03:50] <avierax> ok thanks, any place where those differences are listed?
[2017-09-05 22:33:30] <dch999> 好
[2017-09-05 22:42:02] <SISheogorath> 你好@dch999  你说英語？
[2017-09-05 22:43:39] <SISheogorath> avierax: See [<-LINK->] and [<-LINK->] 
[2017-09-05 22:44:07] <avierax> thanks@SISheogorath
[2017-09-05 22:44:37] <SISheogorath> You're welcome
[2017-09-05 23:59:55] <avierax> If I have two containers in different networks both with the same name
[2017-09-06 00:00:04] <avierax> and I have a container connected to those two networks
[2017-09-06 00:00:27] <avierax> how do I refer to one or another?
[2017-09-06 00:01:20] <avierax> backend @ network abackend @ network bfrontend @ networks a, and b
[2017-09-06 00:01:46] <avierax> is there a way to quality the container by prepending or appending their network name
[2017-09-06 00:01:49] <avierax> ?
[2017-09-06 00:13:45] <SISheogorath> Not that I know. But usually you can't use a name twice. So this situation only appears ehen you use the alias function of a network
[2017-09-06 00:14:12] <avierax> well let me explain myself better
[2017-09-06 00:14:22] <avierax> I have two instances of the same compose
[2017-09-06 00:14:30] <avierax> each is isolated from each other
[2017-09-06 00:15:11] <avierax> and I want to proxy those two compose from an external container, the only one that is exposed to the internet
[2017-09-06 00:16:01] <avierax> I need to connect those the proxy to those two networks
[2017-09-06 00:16:14] <avierax> and then refer to each of these containers by a name
[2017-09-06 00:16:40] <avierax> what name would that be?
[2017-09-06 00:16:51] <avierax> they have the same name in their private network
[2017-09-06 00:17:31] <avierax> but when I connect a third container to those two networks, how to make that third container refer to each one of them separately
[2017-09-06 03:39:07] <shyam334> Question: Is there a way to access the labels of a parent image, during the build time.
[2017-09-06 11:52:37] <elcolie> SISheogorath: Thanks. I will give it a try. Right now I solves it byparallel. Expensive solution takes my RAM nah
[2017-09-06 14:18:56] <SISheogorath> shyam334: Labels are outside of the image scope. You can't access them inside your container
[2017-09-06 14:20:09] <SISheogorath> avierax: compose assigns to every deployed version a prefix. Usually it's the name of the directory, but you can specify it by using the-pflag
[2017-09-06 14:25:19] <lenixlobo> Is there a way to limit specifically only the stack and data segment memory inside the docker image? I tried -m , ulimits and cgroups ,they restrict the entire memory access but the stack and data segment cannot be specifically restricted.
[2017-09-06 14:40:54] <avierax> is there a way to express in compose that a port should be published and specify its interface but not its destination port?
[2017-09-06 14:41:38] <avierax> something like can be done using docker command line when issuing docker run -p 127.0.0.1::80, for example
[2017-09-06 15:38:08] <SISheogorath> lenixlobo: you mean set a general limit for a stack and then set a more specific limit for services inside this stack? That's currently not possible, no. (okay, in theory you could run dind but that's nothing you should do in production)
[2017-09-06 15:40:35] <SISheogorath> avierax: I would say no, but the best way to do so is trying it. Also an option it maybe works with a compose file using long syntax for ports. See [<-LINK->] 
[2017-09-06 15:40:40] <SISheogorath> maybe it works ^^
[2017-09-06 15:40:46] <lenixlobo> Actually,I meant to run a container inside which I want to run an operation but with limited stack and data segment memory allocation.@
[2017-09-06 15:40:50] <lenixlobo> @SISheogorath
[2017-09-06 15:42:17] <SISheogorath> lenixlobo: right now you can only specify limits for specific containers, not for an entire stack.
[2017-09-06 16:40:28] <14mar1983> Hello everyone
[2017-09-06 16:41:21] <14mar1983> I need some help on docker orchestration for blue-green deployments for ruby and rails application...any help is appreciated...thanks in advance.
[2017-09-06 18:44:33] <monksy> I've got a question about letsencrypt with the private docker registry
[2017-09-06 18:44:46] <monksy> I'm not using the cachefile option, because I'm not recieving a cachefile from letsencrypt
[2017-09-06 18:44:59] <monksy> What I do have is a cron job that auto renews a cert
[2017-09-06 18:45:39] <monksy> I'm using the instructions from: [<-LINK->] to generate a domain.crt file
[2017-09-06 18:46:00] <monksy> When trying to pull I get: x509: certificate signed by unknown authorityBut in the browser it doesn't complain about the cert
[2017-09-06 22:29:39] <swamifalgun> Hy guys ! Any suggestions for learning docker from a beginner point of view ?
[2017-09-06 23:55:56] <shyam334> SISheogorath: thanks
[2017-09-07 01:09:43] <elishnevsky> Guys, when I upgrade Docker for Windows, the new version always fails to start. Every single time. I have to completely uninstall and install it again. It's extremely annoying. Any idea why this could be happening?
[2017-09-07 01:55:23] <lenixlobo> SISheogorath: is there no other way? Using ulimts ,cgroups? Or something else?
[2017-09-07 01:56:03] <SISheogorath> swamifalgun: check [<-LINK->] and of course [<-LINK->] 
[2017-09-07 02:00:24] <SISheogorath> lenixlobo: you have to keep in mind that on a machine level the stack are simply a few containers that may or may not share a directory or a network stack. How will you set limits this way? Besides network and volumes, which are both optional, they share nothing, they don't even have to run on the same machine
[2017-09-07 02:02:10] <SISheogorath> Keep in mind that these limits work on kernel level and not as part of docker, which could may know what container is assigned to a stack
[2017-09-07 02:03:06] <SISheogorath> monksy: sounds like missing ca-certifices
[2017-09-07 02:24:27] <14mar1983> Hello All --I need some help on docker orchestration for blue-green deployments for ruby and rails application...any help is appreciated...thanks in advance.
[2017-09-07 03:41:20] <comeUpWithItLater>  [<-LINK->] 
[2017-09-07 03:41:37] <comeUpWithItLater> ports:   - "30000-30009:30000-30009"
[2017-09-07 03:41:45] <comeUpWithItLater> is this ok ?
[2017-09-07 03:50:24] <14mar1983> it should work
[2017-09-07 03:50:31] <14mar1983> Hello All --I need some help on docker orchestration for blue-green deployments for ruby and rails application...any help is appreciated...thanks in advance.
[2017-09-07 07:06:44] <VQuery> We have installed Docker for windows toolbox and pulled docker container hello-world-nginx from Kitematic (Alpha) tool .Now we need to configure docker plugin in jenkins and we are facing below connectivity issue while using docker url test connection stepDOCKER_HOST=tcp://192.168.99.100:2376shaded.org.apache.http.ProtocolException: The server failed to respond with a valid HTTP responseWhat are things we need to done ?Jenkins and Docker Tool box are both running in same machine.MY Operating system configuration:Windows 8.1 - X64bit
[2017-09-07 07:11:17] <VQuery> we are working for this issue nearly 2 days 
[2017-09-07 07:11:34] <VQuery> please guide me on this
[2017-09-07 07:31:27] <comeUpWithItLater>  [<-LINK->] 
[2017-09-07 08:32:58] <VQuery> comeUpWithItLater: ,did you try docker container as jenkins slave?
[2017-09-07 08:57:17] <comeUpWithItLater> no
[2017-09-07 08:57:27] <comeUpWithItLater> solved by [<-LINK->] 
[2017-09-07 09:07:36] <VQuery> Thanks for the reply
[2017-09-07 09:17:20] <SISheogorath> VQuery: I would suggest you to go to forums.docker.com with that question. Possibly there will be more Windows users
[2017-09-07 09:26:28] <VQuery> SISheogorath: Posted 
[2017-09-07 09:29:30] <VQuery>  [<-LINK->] 
[2017-09-07 11:02:35] <huangyanxiong01> How can i run docker command in dockerfile?
[2017-09-07 11:06:48] <huangyanxiong01> The docker from host ,example [<-CODE->] 
[2017-09-07 12:02:36] <SISheogorath> huangyanxiong01: you shouldn't run docker commands inside a Dockerfile. It's not made for this. If you want to use multiple images for your application please have a look at multi-staged builds [<-LINK->] 
[2017-09-07 15:20:59] <monksy> SISheogorath: I'm running an up to date copy of Archlinux on the client
[2017-09-07 15:21:12] <monksy> is there anyway to verify what cert is being returned?
[2017-09-07 17:08:08] <SISheogorath> Ah@monksyI had to checkout your link >.> Their instructions are not correct. They tell you to copy the cert.pem, use the fullchain.pem. If you want to verify useopenssl s_client -connect host:portbut as I already see: They provide an incomplete certificate chain which breaks the trust
[2017-09-07 17:08:30] <SISheogorath> Use the fullchain.pem and the problem should be solved
[2017-09-07 17:21:41] <JavaMonkey_twitter> when setting up my local docker environment I want to establish the correct hostname for each container so that ssl traffic is handled properly. It seems that container_name in my docker-compose file dictates my docker network dns name. So, what is the hostname property for, if not to map the correct dns name?
[2017-09-07 17:42:55] <SISheogorath> JavaMonkey_twitter: what hostname property?
[2017-09-07 18:17:31] <JavaMonkey_twitter> After more reading, I think what I need to do is setup an alias on a pre-existing network.
[2017-09-07 18:19:56] <JavaMonkey_twitter>  [<-CODE->] 
[2017-09-07 18:20:05] <JavaMonkey_twitter> but that doesnt seem to work
[2017-09-07 18:20:54] <JavaMonkey_twitter> I getuses an undefined network "myprexistingnetwork"
[2017-09-07 18:21:16] <monksy> that fixed the issue! thank you
[2017-09-07 18:21:22] <JavaMonkey_twitter> even though I have declared my network in my compose file
[2017-09-07 18:21:24] <monksy> SISheogorath: 
[2017-09-07 18:24:52] <JavaMonkey_twitter> Is it possible to setup an alias for my container on a pre-existing network in my docker-compose file?
[2017-09-07 18:26:45] <SISheogorath> you can add it under network and mark it as external
[2017-09-07 18:27:14] <SISheogorath> See [<-LINK->] 
[2017-09-07 18:28:42] <JavaMonkey_twitter> SISheogorath: , so, I have done that. And have been using the external network for some time. Now I want to create a container alias on that network in my services description. Thats what Im struggling with.
[2017-09-07 18:30:13] <JavaMonkey_twitter> Is that possible? If so, whats the right syntax in my container description?
[2017-09-07 18:31:32] <SISheogorath> it should work like that the error message "undefined network" indicates it\'s more likely a typo
[2017-09-07 20:47:14] <tasuki> Hi guys, what could be the reason thatdocker run -it someimagetakes ~10 seconds to start the web server on my laptop and 15 minutes (and counting!) to create a container from the same image on AWS ECS (anm4.largewhich is sitting with idle cpu and empty memory)?
[2017-09-07 20:48:04] <tasuki> ah, fwiw, on my laptop the speed of this is 100% cpu limited
[2017-09-07 20:55:49] <tasuki> docker statsdoes not help...
[2017-09-07 22:08:13] <SISheogorath> Well, it depends on the filessystem, storagedriver, image size, number of layers, entrypoint script, volumes, …
[2017-09-08 05:36:47] <huangyanxiong01> SISheogorath: thank you,hat's what I want
[2017-09-08 06:24:11] <lostllama> Can anyone tell me how to map a local folder into docker in the latest version? I used to do something likedocker run -it -v C:/work/web-dashboard:/opt/atlassian/pipelines/agent/build atlassian-docker, and while that option allows persistent changes between container launches, it doesn't map to the folder like it did in the previous version.
[2017-09-08 06:40:54] <lostllama>  [<-ISSUE->] I've come to believe it's a bug, so I've registered it as an issue.
[2017-09-08 07:24:03] <huangyanxiong01> lostllama: you need share C drives  to   virtual machine
[2017-09-08 07:24:25] <lostllama> It was already shared. The fact is, the same command that works with 17.06.1 doesn\'t work with 17.06.2. The drive shows up in the settings as "shared" in both cases. Unless the update to 17.06.2 somehow broke that sharing but didn\'t reflect it in the UI.
[2017-09-08 07:27:36] <huangyanxiong01> oh,You can ssh to virtual machine  then  check  C drives  is mount to Linux
[2017-09-08 07:28:14] <lostllama> What virtual machine? I'm running docker on my Windows machine.
[2017-09-08 07:28:59] <lostllama> I'm fairly certain that it's a bug in Docker.
[2017-09-08 07:30:49] <huangyanxiong01> Docker run in  Hyper-v Linux virtual machine on windows 10
[2017-09-08 07:31:15] <huangyanxiong01>  [<-LINK->] 
[2017-09-08 07:32:39] <lostllama> OK, but regardless of that, running the command to map a folder doesn't work on 17.06.2, but uninstalling that and reinstalling 17.06.1 and running the same command worked flawlessly, as it had been before I installed the update for 17.06.2 today. Does that not strongly suggest that it's a bug with Docker?
[2017-09-08 07:33:18] <huangyanxiong01> I don't konw is bug, I generally work with Linux
[2017-09-08 07:34:12] <lostllama> I've never needed to configure anything regarding hyper-v, etc. other than granting Docker access to enable it. So I'm not sure how that stuff works. I think I'll just keep using 17.06.1 until they fix it.
[2017-09-08 07:34:25] <lostllama> Thanks anyway.
[2017-09-08 07:34:31] <huangyanxiong01> mybe,You can create issue on github
[2017-09-08 07:34:46] <lostllama> The issue I linked above is the issue I created on github :-)
[2017-09-08 07:36:00] <huangyanxiong01> well good
[2017-09-08 08:10:52] <comeUpWithItLater>  [<-LINK->] 
[2017-09-08 08:10:53] <comeUpWithItLater> how to   verify this ?
[2017-09-08 08:18:09] <huangyanxiong01> sudo systemctl status dockerin  local  or remote host
[2017-09-08 09:26:37] <comeUpWithItLater> solved  by [<-LINK->] 
[2017-09-08 09:26:48] <comeUpWithItLater> now got new problem:
[2017-09-08 09:27:40] <comeUpWithItLater>  [<-LINK->] 
[2017-09-08 09:28:57] <lostllama> What happens if you run:wget http://mirrors.163.comon the host machine?
[2017-09-08 09:29:06] <lostllama> does it download an html file or fail? It works for me so I'd hope it would work for you.
[2017-09-08 09:30:29] <comeUpWithItLater>  [<-LINK->] 
[2017-09-08 09:30:36] <comeUpWithItLater> super fast
[2017-09-08 09:39:51] <huangyanxiong01> you  can choose othen mirrors
[2017-09-08 09:40:04] <huangyanxiong01> othen == other
[2017-09-08 09:48:10] <comeUpWithItLater>  [<-LINK->] 
[2017-09-08 09:48:37] <comeUpWithItLater> none of them works
[2017-09-08 09:49:08] <14mar1983> I need some help on docker orchestration for blue-green deployments for ruby and rails application...any help is appreciated...thanks in advance.
[2017-09-08 09:49:46] <comeUpWithItLater> not the mirrors' problem , the container can not resolved any DNS
[2017-09-08 09:55:50] <SISheogorath> 14mar1983: Maybe #ci-cd in the docker community Slack is the better place for this question. See [<-LINK->] 
[2017-09-08 10:07:10] <zhongdj> Hey Guys, can I use “Template Variables” in docker-compose?
[2017-09-08 10:07:52] <zhongdj> such as: [<-CODE->] 
[2017-09-08 10:25:45] <huangyanxiong01> You can use env Variables
[2017-09-08 10:28:02] <huangyanxiong01>  [<-CODE->] 
[2017-09-08 10:53:40] <SISheogorath> zhongdj: I'm not sure. Why not simply try it? If it works fine, if ti doesn't you have your answer
[2017-09-08 11:21:49] <orionprateek> How can I make sure the code inside one docker container is able to access mongodb inside another container??
[2017-09-08 12:29:19] <anshulpatel25> Hi, Is there any tool to unit-test Dockerfile.For Eg: I wrote Dockerfile [<-CODE->] I need to run unit test to verify whether nginx was installed or not?
[2017-09-08 13:08:41] <SISheogorath> orionprateek: networking. Use the other container like a remote computer and use the containername as hostname.
[2017-09-08 13:12:55] <SISheogorath> anshulpatel25: Depends on how much you trust in ubuntu's apt-get. It's not an official tool by docker, but [<-LINK->] basically works. I personally don't use it, since I do integration testing which is from my perspective enough for the docker image itself
[2017-09-08 13:13:53] <anshulpatel25> thanks@SISheogorath, If I may ask, how do you perform integration testing, are you using any kind of framework, for eg: BATS ?
[2017-09-08 13:14:39] <anshulpatel25> or the image is deployed on integration environment, and then test-cases are executed?
[2017-09-08 13:15:47] <SISheogorath> Well, for my private projects I use just a bunch of Bashscripts to test basic functionalities (so basically smoketests) :D For a professional environment I use the same test cases I use for the software usually and run them against the image.
[2017-09-08 13:16:20] <SISheogorath> so yes, the image is deployed to test environment
[2017-09-08 13:16:54] <SISheogorath> this is one of my private projects: [<-LINK->] 
[2017-09-08 13:17:09] <SISheogorath> very easy but enough to work with it
[2017-09-08 13:17:20] <SISheogorath> You notice it when the service doesn't work ^^
[2017-09-08 13:19:03] <anshulpatel25> Thanks@SISheogorathfor helping out!
[2017-09-08 13:23:08] <SISheogorath> You're welcome
[2017-09-08 13:56:04] <danbopes> What\'s the best practice for building apps to be deployed to docker? The app needs to be built first, so I\'m thinking "npm install --dev && npm build" locally, run "npm install" via the RUN command? Or should I build the app directly on the docker image?
[2017-09-08 14:07:11] <elcolie> danbopes: I build thebuild.js and build.js.mapin the image. Then instantiate thecontainermyentrypoint.shcopy asset to volume.
[2017-09-08 14:07:57] <danbopes> What do you mean instantiate the container?
[2017-09-08 14:08:18] <elcolie> start the container
[2017-09-08 14:08:37] <elcolie> I use term instantiate because single image and has many containers
[2017-09-08 14:09:04] <danbopes> I'm confused at the second sentence
[2017-09-08 14:09:20] <danbopes> Your entrypoint will do what exactly?
[2017-09-08 14:12:06] <elcolie> Do anything withrootpermission. Normally it is initialization
[2017-09-08 14:17:22] <danbopes> elcolie: Shot you a PM
[2017-09-08 14:30:51] <elcolie> ok
[2017-09-08 15:11:51] <danbopes> Do you not see it@elcolie?
[2017-09-08 15:12:02] <elcolie> yes
[2017-09-08 15:12:20] <danbopes> I hate gitter :(
[2017-09-08 15:43:51] <elcolie> danbopes: I answer to your private already.
[2017-09-08 15:43:55] <elcolie> Hope this help
[2017-09-08 18:49:46] <amanagarwal2189> trying to run DockerEE in the production...I get this error when I have modified /etc/docker/daemon.json to run for direct-lvm [<-CODE->] 
[2017-09-08 18:52:12] <amanagarwal2189>  [<-CODE->] 
[2017-09-08 23:23:19] <comeUpWithItLater>  [<-LINK->] 
[2017-09-08 23:23:52] <comeUpWithItLater> how to convert this to  docker-compose.yml format?
[2017-09-09 04:00:01] <SISheogorath> comeUpWithItLater: simply usecommand: "--flag
[2017-09-09 04:00:53] <SISheogorath> Where--flagis replaced with the marked string
[2017-09-09 06:19:22] <comeUpWithItLater> works  , thank you
[2017-09-09 07:11:30] <zhongdj> SISheogorath: I tried, it does not work
[2017-09-09 18:06:30] <matthewharwood> How can I watch my package.json and npm install my image when it's been update?
[2017-09-09 18:07:10] <matthewharwood>  [<-CODE->] docker build . -t testImagedocker run -p 8191:8191 -v $(pwd)/server/src:/var/www/src testImage
[2017-09-09 18:23:38] <SISheogorath> matthewharwood: how would you do it outside of a container?
[2017-09-09 18:23:56] <matthewharwood> SISheogorath:  [<-LINK->] 
[2017-09-09 18:24:03] <matthewharwood> I made a more formal question
[2017-09-09 18:24:19] <matthewharwood> Sorry for these seemingly noob questions this is like day 2 of using docker
[2017-09-09 18:25:05] <SISheogorath> the question is still: How would you do it outside of docker? Because there is actually no difference in handling it
[2017-09-09 18:25:45] <matthewharwood> npm install cors --save
[2017-09-09 18:25:57] <matthewharwood> is how I do it outside
[2017-09-09 18:26:12] <matthewharwood> the problem is the npm install is running only when I make the image
[2017-09-09 18:27:06] <matthewharwood> do I need to keep my node_modules local in the volume for development?
[2017-09-09 18:27:15] <matthewharwood> that the only way?
[2017-09-09 18:27:27] <matthewharwood> or can i run them from the container?
[2017-09-09 18:27:48] <matthewharwood> right now I'm runnig them from the container but I cannot update them.
[2017-09-09 18:28:02] <SISheogorath> well, you install it this way, but you don't monitor the package.json for changes. Which is another usecase. anyways: When you want to run npm install, simple prefix it with:docker exec -it <containerid>so you can something likedocker exec -it mycontainer npm install cors --save
[2017-09-09 18:28:35] <matthewharwood> ahh I see
[2017-09-09 18:28:36] <matthewharwood> hmm
[2017-09-09 18:29:14] <matthewharwood> I don't want the developer to have to interact too much with the docker container.  is there anyway to watch the package.json ?
[2017-09-09 18:29:25] <matthewharwood> so they can do it local but it will trigger in the container also?
[2017-09-09 18:29:31] <SISheogorath> you can search for ionotify
[2017-09-09 18:29:48] <SISheogorath> But that's nothing docker specific
[2017-09-09 18:31:06] <matthewharwood> I can come up with a solution.  the exec -it command helpped a lot.  it's simple
[2017-09-09 18:31:28] <SISheogorath> nice :)
[2017-09-09 18:32:01] <SISheogorath> when you solved it feel free to blog about it so others can learn from it ^^
[2017-09-09 18:36:01] <matthewharwood> SISheogorath: in npm install theres a postinstall scriptinstall, postinstall: Run AFTER the package is installed.maybe kind of lame but I could right a script to godocker exec -it <containerid>and npm install also lol
[2017-09-09 19:12:52] <jsfour> Does anyone have a good recommendation on a service monitoring system for docker?
[2017-09-09 19:13:32] <jsfour> basically we want to track the uptime of containers that are run by rancher.
[2017-09-09 19:18:05] <anshulpatel25> jsmootiv: , Prometheus?
[2017-09-09 19:21:23] <jsfour> yeah ive been reading that
[2017-09-10 00:17:31] <neetjn> Hey guys, I'm trying to deploy a secure docker registry.
[2017-09-10 00:18:54] <neetjn> Is there any way to restrict a docker user to pull/push access?
[2017-09-10 00:19:21] <neetjn> I was also looking atdocker_auth, but the setup seems to be quite vague.
[2017-09-10 01:49:58] <SISheogorath> neetVeritas: iirc not within the registry problem, but you can use a reverse proxy that blocks some actions in front
[2017-09-10 02:27:13] <matthewharwood> how can I rewrite this command into docker-compose file [<-CODE->] All I got so far is [<-CODE->] 
[2017-09-10 02:29:45] <matthewharwood> still missing (and maybe not needing)-it,--rm,'-w /app,ng server --host 0.0.0.0
[2017-09-10 02:44:05] <matthewharwood> oh yay I did it by myself
[2017-09-10 02:44:07] <matthewharwood> ! lol
[2017-09-10 07:00:54] <Miniexchange> Hello everyone, does anyone has experience with docker swarm mode and can give me a hand? I've setup swarm of 8 nodes (3 managers, 5 workers), i've spinned up 2 containers in the same overlay network but seperate nodes. For some reason when i'm trying to connect between them it's not working - seems like  resolved IP is not  up to date
[2017-09-10 07:02:11] <Miniexchange> query from service magento-mag-589: [<-CODE->] 
[2017-09-10 07:03:00] <Miniexchange> but when i check Virtual IP of this service it's different: [<-CODE->]  [<-CODE->] 
[2017-09-10 07:05:22] <Miniexchange> docker network inspect also  shows different ip:docker network inspect magento-web [<-CODE->] 
[2017-09-10 07:06:22] <Miniexchange> Any idea from where I can start to solve this issue?
[2017-09-10 08:53:53] <Miniexchange> ok, removed all services, removed overlay network and recreated whole stack, seems like now is ok
[2017-09-11 13:44:43] <crebuh> Hello Guys, I want to make the build process of my docker container more efficient. Instead of always executing the npm install, I just want to execute the npm install command when actually the package.json file changes. I adjust the the part in the dockerfile but still npm install is executed always. Here is my dockerfile [<-CODE->] 
[2017-09-11 14:54:09] <j0rdn> Hello! I am looking for a way to keep the python:alpine container running idle in the background (similar to a vm). Suggestions?
[2017-09-11 15:40:21] <hmatt1> How do you flush the dns in a container?
[2017-09-11 16:44:36] <amanagarwal2189> hey. I just installed Docker EE and i am getting the error/warningWARNING: COMMAND_FAILED: \'/usr/sbin/iptables -w2 -twhen i check "firewalld" status
[2017-09-11 18:41:45] <hmatt1> amanagarwal2189: try running the container in priviledged mode
[2017-09-11 18:41:57] <hmatt1> that helped when iptables was failing for me
[2017-09-11 23:56:32] <prasenjithaty> Hi all
[2017-09-11 23:57:41] <prasenjithaty> Anybody using the official maven image to build their Java project? I'm specifically stuck at resolving dependencies from a private Nexus repertory
[2017-09-12 00:09:11] <prasenjithaty> Repository*
[2017-09-12 00:55:04] <DWSR> Hello everyone, I'm curious if anyone here has some advice for how to handle using Swarm secrets in conjunction with configuring a Docker registry with an S3 backend.
[2017-09-12 02:13:03] <AyushyaChitransh> prasenjithaty: What problem are you facing. I had used maven:3.5 in [<-LINK->] which worked good
[2017-09-12 02:14:30] <AyushyaChitransh> j0rdn: You could start the python with a bash command
[2017-09-12 02:14:45] <prasenjithaty> AyushyaChitransh: here is the link to an issue I have opened [<-ISSUE->] 
[2017-09-12 02:19:07] <AyushyaChitransh> It says thatcontent-core.jarwas missing some dependencies. I think that content-core.jar was not prepared properly
[2017-09-12 02:20:06] <prasenjithaty> AyushyaChitransh: the issue here is authorization while downloading that jar from our private Nexus repository
[2017-09-12 02:21:12] <prasenjithaty> That jar is defined as a dependency in pom.xml
[2017-09-12 02:31:06] <AyushyaChitransh> prasenjithaty: I haven't used authorization hence hadn't came across this issue. I am not sure if there is something wrong with the maven image or something else.
[2017-09-12 02:33:52] <AyushyaChitransh> Check if this helps.. [<-LINK->] 
[2017-09-12 02:39:55] <AyushyaChitransh> And most probably you need to copysecurity-setting.xmltoo. As said at [<-LINK->] 
[2017-09-12 02:50:11] <prasenjithaty> AyushyaChitransh: thanks. I’m not using encrypted password. So I don’t necessarily need thesecurity-settings.xml
[2017-09-12 02:52:54] <prasenjithaty> I’m also not using proxies so I wonder if the other solution will help. But let me give it a shot and thanks for helping
[2017-09-12 04:33:34] <kapilpipaliya> Hello
[2017-09-12 06:39:52] <comeUpWithItLater> when starting a  new project , how can I keep a node.js container up and running  when a  index.js file isn't ready to benode index.js?
[2017-09-12 06:40:43] <comeUpWithItLater> so I can go through the set up commands here : [<-LINK->] 
[2017-09-12 14:29:44] <JnMik> Hey guys, the max_attempts  restart policy on docker stack deploy, does it affect the service or the containers ?
[2017-09-12 14:30:12] <JnMik> If I set max_attempts:50 with 3 replicas, do I have a total of 150 retries, or only 50
[2017-09-12 15:15:17] <rightisleft> Hi Folks - im trying to figure out why my dockerhub is showing all my tags as being updated -
[2017-09-12 15:15:24] <rightisleft>  [<-LINK->] 
[2017-09-12 15:16:18] <rightisleft> im building using the following ci script
[2017-09-12 15:16:29] <rightisleft>  [<-CODE->] 
[2017-09-13 06:31:22] <marcuzy> Hi, guys! Did somebody face a problem which is running stateful replicas? I have a microservice which consumes RabbitMQ queue and sends messages to Slack through http API, this miscroservice is something like "gateway". Messages contain teamId, the microservice keeps all tokens, it gets a token by teamId and sends a message to Slack using a correspond token. It works great while there is one instance of the microservice. To scale the microservice I can change the replicas number and use "round-robin" feature of RabbitMQ, but the order of messages isn\'t strict anymore for each particular user because queues in different replicas are independent.Maybe somebody has some experience with such a problem-solving. Thank you.
[2017-09-13 16:12:26] <DWSR> marcuzy: RabbitMQ doesn't ensure consistency in message delivery order.
[2017-09-13 16:13:07] <DWSR> marcuzy:  [<-LINK->] 
[2017-09-13 16:13:19] <DWSR> marcuzy: You may want to look at Kafka for this
[2017-09-13 18:29:26] <vodnanmaga_twitter> @/allDoes anyone have command to install geckodriver in a centos 7 docker container?
[2017-09-13 20:28:57] <DWSR> Hey everyone, I'm having trouble with the Docker Swarm Overlay network when deploying a Stack using a Compose file. When I have all my containers on one worker node (setting all other nodes to Drain), I can talk between containers no problem. When I set all nodes to active and redeploy the same stack (so that containers end up on different nodes), the containers can no longer talk to each other. The DNS does not seem to work correctly. Is there something I should be doing here?
[2017-09-14 00:29:06] <zhongdj> Hey Guys, I have a single docker-compose.yaml file but more .env files for different physical machines, how can I specify .env file at docker-compose cli
[2017-09-14 00:35:43] <AyushyaChitransh> zhongdj: You can specify env file for specific service also. Would that help?
[2017-09-14 05:36:18] <TRMIKO> Hey guys , i am new un docker and have a question  , i has install a prestas
[2017-09-14 09:08:45] <Everspace> I am trying to compose a directory inside a container from 2 directories on the host machine [<-CODE->] Is it possible to do something like the above? I keep running into problems where it's a directory or something like that
[2017-09-14 09:26:08] <SISheogorath> you shouldn't do bind mounts for files, but yes, should be possible.
[2017-09-14 09:27:38] <Everspace> Is there a reason against that practice?
[2017-09-14 09:48:27] <SISheogorath> One is because docker by default creates a directory if the file doesn't exist (if you use docker run, in swarm mode it's a bit different) and iirc it was also some kind of permission related but not sure about that in detail
[2017-09-14 10:47:40] <VQuery> Any one here using docker plugin ?
[2017-09-14 16:26:17] <onerealfunnyguy> any one point me in the right direction to determine why an instanse running with only ports expsed can not access a instanse running on the host network, please & thank you in advnace
[2017-09-14 17:14:21] <SISheogorath> onerealfunnyguy: you need to address the services on the host machine like an external host. The network stacks isolated so for your container everything on the host's network stack is another machine
[2017-09-14 17:15:40] <onerealfunnyguy> SISheogorath: , belive my problem is something else, as when I put both instances on host network still have same problem, ty
[2017-09-14 17:16:31] <SISheogorath> onerealfunnyguy: how do you address them and how do you put them on host networks?
[2017-09-14 17:18:48] <onerealfunnyguy>  [<-LINK->] 
[2017-09-14 17:18:51] <onerealfunnyguy> working on adding tts to my home-assistant set-up, everything else is in docker, so goal is to keep it that way, have mopidy running, work with tune in and local music, yet when I send a tts from the HA instanse to the mopidy one I get the following,
[2017-09-14 17:19:46] <onerealfunnyguy> i can wget the mp3 from the cli inside the mopidy instanse so I know it can see it yet, not finding away around mad not beable to find it
[2017-09-14 17:21:06] <onerealfunnyguy> SISheogorath: and just using --net=host \\
[2017-09-14 18:30:18] <ags799> i have a git repo that defines multiple microservices. these microservices are deployed as docker images. the images are built following the builder pattern. i would like to move to a multi-stage build. how can i have a Dockerfile for each microservice, where each Dockerfile references the same builder image?
[2017-09-14 19:21:30] <crdil> I'm running a node api in a docker container, but when I try to log the ip of client which connects to it i'm getting the docker gateway ip, how can i solve this so i get the realy ip instead?
[2017-09-15 16:12:41] <rightisleft> Any ideas on this?
[2017-09-15 16:12:41] <rightisleft>  [<-LINK->] 
[2017-09-15 23:53:14] <liangyuanpeng> sudo docker inspect containerID
[2017-09-15 23:53:35] <liangyuanpeng> crdil: 
[2017-09-16 03:31:24] <brania_93_twitter> I am working with multiple clients from Australia, mostly based in Sydney.If you would be interested in a new position working across DevOps, AWS cloud and infractructure architecture, CI/CD, Security, Infrastructure as a Code, Automation, Python scripting,Linux environment, Anisble, CloudFormation, Microservices & Docker?Please contact me at anna.baran.60@gmail.com
[2017-09-16 15:47:43] <marcuzy> @DWSR thank you for your answer, but I mean a little different and Kafka solves another problem (I didn\'t know about it). The problem is I want a strict order for particular team\'s user and to save universality of replicas that RabbitMQ gives messages using "round-robin" strategy and any of the replicas can handle it. But if I send two messages simultaneity to the same user, one of them will be gotten by one replica, second of them will be gotten by another replica and the second replica can send the second message earlier than the first that is a bad behavior.One of the solutions is creating separate queues for each team. Unfortunately, this solution generates a lot of queues (thousands in my case) and I don\'t sure this is a good idea. However, I tested the solution with 10k queues and a performance is quite good but a control via web plugin isn\'t friendly. I wonder to keep a small amount of queues and keep replica\'s universality (there is solving that gives each replica a range of teams to handling). If I don\'t find a solution I going to use this one.
[2017-09-17 02:08:52] <DWSR> marcuzy: But Kafka actually specializes in this. You are able to ensure delivery order in Kafka because of its architecture, while RabbitMQ does not always guarantee this (as you're finding out). I would highly recommend that you look further into how the architectures between the two differ. You will find that Kafka is actually much more suited to your scale than RabbitMQ.
[2017-09-17 02:09:28] <DWSR> We are looking at RabbitMQ for things, but it's single provider multiple consumer, so we need the cursor support more than anything else.
[2017-09-17 13:17:06] <karthikeyanpa90> Hi all
[2017-09-18 13:55:31] <srkadiyala> We started using using overlay2 and experienced issues. Any one tried overlay2? Thx
[2017-09-18 16:32:18] <SISheogorath> srkadiyala: it would be useful when you explain your issue a bit more detailed.
[2017-09-18 16:48:59] <pzaj2> hello everyone :) I started playing around with docker just yesterday and it seems quite nice and easy (almost too easy :D). I\'m wondering how configurable are docker images? I currently work on Symfony 2 app and would like to "dockerize" it, but my app requires few php modules not usually included in PHP & also few other things, for instance imagemagick. How would one handle such things? Should I be building my own custom images?
[2017-09-18 17:49:56] <sircinnamon> pzaj2: Yes, you can build custom images using what you have currently as a starting point and bringing in more files and modules
[2017-09-18 19:13:30] <pzaj2> sircinnamon: thanks :) I\'m reading more on docker now, it seems, well... nice & easy and confusing at the same time  I\'ve seen people having separate "gulp build assets" containers.. well :) we will see how it works out :P
[2017-09-19 00:29:55] <killtheliterate> having some issues with a mongo container set up with compose like: ```    image: mongo    container_name: gudfites_mongo    environment: [<-CODE->]  [<-CODE->] 
[2017-09-19 00:31:48] <killtheliterate> not sure this is the right place to ask, so will ask in the docker slack as well
[2017-09-19 04:50:25] <VQuery> Hi docker users
[2017-09-19 04:50:35] <VQuery> any one using docker plugin?
[2017-09-20 10:55:30] <tuan3w> Hi everyone,I\'m using Docker API to retrieve service logs. However, I get invalid character  in the begining of every lines.  I try to replace 0x0 with \'\\n\'  and still get some invalid characters, something like this: "Error grabbing logs:".  Does anyone has experienced this problem ?
[2017-09-20 14:30:11] <tuan3w> I found the reason for that weird characters. First 8 bytes belong to header  of stream ( [<-LINK->] ).
[2017-09-21 07:52:32] <singhalpk> Is there any platform for chatting data . I need random data for my application
[2017-09-21 08:28:18] <SISheogorath> singhalpk: freenode? :D
[2017-09-21 08:28:34] <lostllama> :-D
[2017-09-21 08:28:56] <SISheogorath> Keep in mind you have to inform the channel owners when you start logging
[2017-09-21 08:29:45] <SISheogorath> Otherwise check the tons of slack archives or public IRC logs
[2017-09-21 08:52:14] <crebuh> Hi Guys, I'm running my docker environment behind an nginx reverse proxy which is servering the container applications to the outside world. In case I'm updating my containers, they are not accessible from the outside on port 80 or 443 for let's say one minute. Is there a way within docker to avoid this short downtime or should I just redirect all request via nginx to a maintenance page or something similar? What is best practice in this case?
[2017-09-21 08:53:31] <airtonix> crebuh: you want to research load-balancing and green/blue deployments
[2017-09-21 08:54:10] <crebuh> airtonix: thanks!
[2017-09-21 08:54:42] <airtonix> crebuh: as i see it, you'd have things running at foo.com, and then uploading a new container it needs to run alongside old container at uat.foo.com, confirm all is good and switch nginx pointers to new container.
[2017-09-21 08:55:07] <airtonix> crebuh: i'm sure there are tools around to automate this
[2017-09-21 08:57:00] <crebuh> yes this is the idea
[2017-09-21 08:57:04] <crebuh> I will check  it out
[2017-09-21 08:57:19] <crebuh> the idea having two environments on production sounds reasonable
[2017-09-21 08:57:28] <airtonix> crebuh:  [<-LINK->] 
[2017-09-21 08:58:14] <airtonix> crebuh: join the rancher slack channel and ask the guys there
[2017-09-21 08:59:30] <crebuh> awesome thanks
[2017-09-21 09:12:13] <crebuh> is there a way to file the contents of an image for example when it is stored in the gitlab registry?
[2017-09-21 09:12:45] <crebuh> during build I'm copying some config files, but it seems that there s a problem but I cannot check the content of the image
[2017-09-21 09:13:36] <crebuh> the issue is that the container/app is  crashing on start because a config file is not in place
[2017-09-21 09:13:56] <crebuh> when I use docker ps I can see the process shortly and then it dissapears
[2017-09-21 09:14:21] <lostllama> have you tried manually starting it using the -i flag (i.e. accessing it interactively)?
[2017-09-21 09:15:25] <crebuh> no how can I do this?
[2017-09-21 09:15:54] <lostllama> What command do you usually use to launch your docker image?
[2017-09-21 09:16:36] <crebuh> yeah this is a bit complex, I have a make file which is doing this here: [<-CODE->] 
[2017-09-21 09:17:15] <crebuh> on the staging environment I'm just pulling to ready to go images from the gitlab registry
[2017-09-21 09:19:14] <lostllama> Hmm, I'd recommend just pulling the image locally (if possible) and then running it with something likedocker run -it IMAGENAME(and any other relevant startup flags).
[2017-09-21 09:19:32] <crebuh> mmhm I see
[2017-09-21 09:19:42] <lostllama> Doing so will connect you to the standard input / output from the container, so you should then be able to look around once it crashes.
[2017-09-21 09:20:00] <crebuh> at least I have access to the log of the container
[2017-09-21 09:20:17] <crebuh> so It is throwing this: [<-CODE->] 
[2017-09-21 09:20:37] <crebuh> so the problem is the config file which seems somehow corrupt or not in place
[2017-09-21 09:21:10] <lostllama> Is the config file part of the container, or on a mapped volume?
[2017-09-21 09:22:29] <crebuh> it is part of the container and will be copied during build from src/ to the bin/ folder
[2017-09-21 09:23:23] <crebuh> depending on the environment the application then will choose the correct file, on development every thing is working fine (there I'm building the images always from scratch) on staging where I just want to pull the images from gitlab it is not working
[2017-09-21 09:25:45] <lostllama> Have you confirmed that the "writing configuration" step has succeeded? It looks like it should be working, so I\'m a little confused by it
[2017-09-21 09:28:06] <crebuh> Yes I think I have found the isse in my staging.env file I was storing the environment values with additional "" which then will break my staging.json
[2017-09-21 09:28:09] <crebuh> sorry for bothering you
[2017-09-21 09:28:41] <lostllama> No worries :-) It took me away from my growing rage at Microsoft's design decisions for a few moments.
[2017-09-21 09:40:55] <crebuh> haha at least that :D
[2017-09-21 10:24:29] <VQuery> VQuery: Hi guys,Facing below error in while connecting docker linux slave to windows masterINFO: [JNLP4-connect connection to 172.16.102.234/172.16.102.234:4000] Local headers refused by remote: docker-slave-584a5b1ec73c is not a JNLP agentat org.jenkinsci.remoting.protocol.impl.ConnectionHeadersFilterLayer.newAbortCause(ConnectionHeadersFilterLayer.java:375)at org.jenkinsci.remoting.protocol.impl.ConnectionHeadersFilterLayer.onRecvClosed(ConnectionHeadersFilterLayer.java:432)at org.jenkinsci.remoting.protocol.ProtocolStack$Ptr.onRecvClosed(ProtocolStack.java:832)at org.jenkinsci.remoting.protocol.FilterLayer.onRecvClosed(FilterLayer.java:287)at org.jenkinsci.remoting.protocol.impl.SSLEngineFilterLayer.onRecvClosed(SSLEngineFilterLayer.java:172)at org.jenkinsci.remoting.protocol.ProtocolStack$Ptr.onRecvClosed(ProtocolStack.java:832)at org.jenkinsci.remoting.protocol.NetworkLayer.onRecvClosed(NetworkLayer.java:154)at org.jenkinsci.remoting.protocol.impl.BIONetworkLayer.access$1500(BIONetworkLayer.java:48)at org.jenkinsci.remoting.protocol.impl.BIONetworkLayer$Reader.run(BIONetworkLayer.java:247)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)at hudson.remoting.Engine$1$1.run(Engine.java:94)at java.lang.Thread.run(Thread.java:748)Suppressed: java.nio.channels.ClosedChannelException
[2017-09-21 10:37:34] <SISheogorath> VQuery: Sounds like a jenkins problem to me, not like a docker problem. Maybe contect them? I don't see where docker is involved here besides providing the container for the application.
[2017-09-21 10:39:40] <VQuery> SISheogorath: little bit confusion on this error ,  docker-slave-584a5b1ec73c is not a JNLP agentDue to this ,should  we change any configuration in docker container ?
[2017-09-21 10:41:32] <SISheogorath> I don't know, I'm not a Jenkins user. But to me it looks likedocker-slave-584a5b1ec73cis the container name -> hostname inside the container which breaks. You should contact someone from the Jenkins community/support
[2017-09-21 10:42:43] <VQuery> SISheogorath: yes posted there too
[2017-09-21 12:51:22] <jclagache> Hello ! Is it the right place to share docker for windows issues ?
[2017-09-21 15:36:46] <jclagache> I'll give a try ! ;-)My docker client and server versions are 17.06.1-ee-2 on a Windows Server 2016I want to populate data in volume.  So, in powershell : [<-CODE->]  [<-CODE->]  [<-CODE->] Should I post an issue or this bug is allready know ?
[2017-09-22 06:20:24] <VQuery>  [<-LINK->] 
[2017-09-22 06:20:44] <VQuery> any one explain clearly what they mentions
[2017-09-22 06:20:46] <VQuery> ?
[2017-09-22 10:20:32] <saidiahd> hi folk, Is it necessary to use thin pool LVM with Docker? can I replace a normal LVM partition for storing images layers?
[2017-09-22 19:10:35] <razlupercio_twitter> hello everyone! I'm trying to setup a docker-repo containing loowid along with a php app, both have ssl certs but I'm having issues setting up a reverse proxy which can cover both app, any links on suggestions on this?
[2017-09-23 03:50:14] <hanct> Is it possible to dockerize internet explorer and window nano server, and then use X-forwarding to open the IE graphically inside the docker container?
[2017-09-23 12:38:33] <SISheogorath> hanct: you can't run Windows containers on Linux
[2017-09-23 12:38:58] <hanct> I running windows containers on Window
[2017-09-23 12:39:18] <hanct> I using docker for windows
[2017-09-23 12:39:51] <hanct> So thinking of dockerize window nano server as base image, and then trying to install IE into the container...i wonder if there is possible
[2017-09-23 12:40:40] <SISheogorath> In this case you don't have regular x-forwarding but I can't say if this works or not. I'm not experienced with Docker on Windows
[2017-09-25 06:18:25] <Kibos>  [<-LINK->] 
[2017-09-25 06:18:34] <Kibos> how can I deal with this?
[2017-09-25 08:20:45] <SISheogorath> Iirc a restart of your docker daemon should fix the missing iptables chain
[2017-09-25 08:21:18] <SISheogorath> Kibos: ^
[2017-09-25 08:48:43] <Kibos> how
[2017-09-25 11:39:20] <crebuh> Hi Guys, I want to dockerize an php-application. Before I just worked with node-applications. So for the php-application my question is if I need also a web-server installed inside the container (preferable nginx) to make the application available to the outside world? On the main-system I have installed nginx also so not sure what is the best practice there. Any ideas or suggestions?
[2017-09-25 11:42:44] <thedrint> crebuh: IMHO, setup your host nginx as reverse-proxy to provide reqests from Internet to dockerized php
[2017-09-25 11:44:36] <crebuh> yes this is what I'm doing for the need apps as well
[2017-09-25 11:44:52] <crebuh> the node apps are started in the container and expose a specific port to the host system
[2017-09-25 11:45:43] <thedrint> dockerized php exposes 9000 port (if you use php-fpm). and host nginx must have fastcgi_pass localhost:9000 in nginx.conf file (or IP:9000 if you set up container with bridge network)
[2017-09-25 11:50:01] <crebuh> ok I got it, I was just not sure if I need a webserver (apache or nginx) inside the container to start the application or do what ever is necessary
[2017-09-25 11:50:27] <crebuh> so basically I dont even need a CMD command in my Dockerfile right?
[2017-09-25 13:33:02] <SISheogorath> crebuh: check the php-fpm container for [<-LINK->] They show how to do it ;)
[2017-09-25 13:33:55] <thedrint> crebuh: or [<-LINK->] 
[2017-09-25 13:43:28] <SISheogorath> I wouldn't completely recommend that, because it breaks the idea of containers and images of being immutable besides configurations
[2017-09-25 17:47:45] <hmatt1> how do I check how much memory/CPU is allocated to docker as a whole from the linux command line?
[2017-09-25 17:48:15] <thedrint> ctop ?
[2017-09-25 17:49:35] <hmatt1> if you were in the GUI, its under settings
[2017-09-25 17:49:53] <hmatt1> not how much it is using, but what the limit is in the docker settings
[2017-09-25 17:50:17] <hmatt1> I was looking atdocker statsbut that breaks it down by container
[2017-09-25 18:16:12] <hmatt1>  [<-LINK->] 
[2017-09-25 18:16:31] <hmatt1> just to clarify, looking to view these settings from the cli
[2017-09-25 18:19:29] <mcarpenterjr> igorbarkowsky: Hey whats the diff betweenctopandhtop?
[2017-09-25 18:20:55] <thedrint> mcarpenterjr: htop for host processes, ctop show info about containers in realtime (use docker stats)
[2017-09-25 18:21:46] <mcarpenterjr> ah I see
[2017-09-26 09:27:43] <rsegecin> Is not possible to automatically copy the required files to the source volume when I'm working with remote deployment?
[2017-09-26 09:33:40] <rsegecin> without the need of "docker-machine scp"
[2017-09-26 09:35:42] <ebcodes> anyone here used aws' cloudhsm before?
[2017-09-26 09:35:51] <ebcodes> question regarding connectivity from docker
[2017-09-26 09:59:52] <SISheogorath> rsegecin: source volume?
[2017-09-26 10:26:17] <VQuery> Hi Guys,INFO: Agent discovery successful\n  Agent address: 172.16.102.234\n  Agent port:    4000\n  Identity:      88:ed:5f:bf:01:a1:c9:aa:e1:1d:a3:50:44:a5:d4:af\nSep 26, 2017 10:25:05 AM hudson.remoting.jnlp.Main$CuiListener status\nINFO: Handshaking\nSep 26, 2017 10:25:05 AM hudson.remoting.jnlp.Main$CuiListener status\nINFO: Connecting to 172.16.102.234:4000\nSep 26, 2017 10:25:05 AM hudson.remoting.jnlp.Main$CuiListener status\nINFO: Trying protocol: JNLP4-connect\nSep 26, 2017 10:25:06 AM hudson.remoting.jnlp.Main$CuiListener status\nINFO: Remote identity confirmed: 88:ed:5f:bf:01:a1:c9:aa:e1:1d:a3:50:44:a5:d4:af\nSep 26, 2017 10:25:06 AM org.jenkinsci.remoting.protocol.impl.ConnectionHeadersFilterLayer onRecv\nINFO: [JNLP4-connect connection to 172.16.102.234/172.16.102.234:4000] Local headers refused by remote: vj-docker-3fb753bfde72 is not a JNLP agent\nSep 26, 2017 10:25:06 AM hudson.remoting.jnlp.Main$CuiListener status\nINFO: Protocol JNLP4-connect encountered an unexpected exception\njava.util.concurrent.ExecutionException: org.jenkinsci.remoting.protocol.impl.ConnectionRefusalException: vj-docker-3fb753bfde72 is not a JNLP agent\nat org.jenkinsci.remoting.util.SettableFuture.get(SettableFuture.java:223)\nat hudson.remoting.Engine.innerRun(Engine.java:583)\nat hudson.remoting.Engine.run(Engine.java:447)\nCaused by: org.jenkinsci.remoting.protocol.impl.ConnectionRefusalException: vj-docker-3fb753bfde72 is not a JNLP agent\nat org.jenkinsci.remoting.protocol.impl.ConnectionHeadersFilterLayer.newAbortCause(ConnectionHeadersFilterLayer.java:377)\nat org.jenkinsci.remoting.protocol.impl.ConnectionHeadersFilterLayer.onRecvClosed(ConnectionHeadersFilterLayer.java:432)\nat org.jenkinsci.remoting.protocol.ProtocolStack$Ptr.onRecvClosed(ProtocolStack.java:832)\nat org.jenkinsci.remoting.protocol.FilterLayer.onRecvClosed(FilterLayer.java:287)\nat org.jenkinsci.remoting.protocol.impl.SSLEngineFilterLayer.onRecvClosed(SSLEngineFilterLayer.java:172)\nat org.jenkinsci.remoting.protocol.ProtocolStack$Ptr.onRecvClosed(ProtocolStack.java:832)\nat org.jenkinsci.remoting.protocol.NetworkLayer.onRecvClosed(NetworkLayer.java:154)\nat org.jenkinsci.remoting.protocol.impl.BIONetworkLayer.access$1500(BIONetworkLayer.java:48)\nat org.jenkinsci.remoting.protocol.impl.BIONetworkLayer$Reader.run(BIONetworkLayer.java:247)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\nat hudson.remoting.Engine$1$1.run(Engine.java:98)\nat java.lang.Thread.run(Thread.java:745)\nSuppressed: java.nio.channels.ClosedChannelException\n... 7 more\nSep 26, 2017 10:25:06 AM hudson.remoting.jnlp.Main$CuiListener status\nINFO: Connecting to 172.16.102.234:4000\nSep 26, 2017 10:25:06 AM hudson.remoting.jnlp.Main$CuiListener status\nINFO: Server reports protocol JNLP4-plaintext not supported, skipping\nSep 26, 2017 10:25:06 AM hudson.remoting.jnlp.Main$CuiListener status\nINFO: Server reports protocol JNLP3-connect not supported, skipping\nSep 26, 2017 10:25:06 AM hudson.remoting.jnlp.Main$CuiListener status\nINFO: Trying protocol: JNLP2-connect\nSep 26, 2017 10:25:06 AM hudson.remoting.jnlp.Main$CuiListener status\nINFO: Protocol JNLP2-connect encountered an unexpected exception\njava.util.concurrent.ExecutionException: org.jenkinsci.remoting.protocol.impl.ConnectionRefusalException: Server didn't accept the handshake: \nat java.util.concurrent.FutureTask.report(FutureTask.java:122)\nat java.util.concurrent.FutureTask.get(FutureTask.java:188)\nat hudson.remoting.Engine.innerRun(Engine.java:583)\nat hudson.remoting.Engine.run(Engine.java:447)\nCaused by: org.jenkinsci.remoting.protocol.impl.ConnectionRefusalException: Server didn't accept the handshake: \nat org.jenkinsci.remoting.engine.JnlpProtocol2Handler.sendHandshake(JnlpProtocol2Handler.java:134)\nat org.jenkinsci.remoting.engine.LegacyJnlpProtocolHandler$2.call(LegacyJnlpProtocolHandler.java:162)\nat org.jenkinsci.remoting.engine.LegacyJnlpProtocolHandler$2.call(LegacyJnlpProtocolHandler.java:158)\nat java.util.concurrent.FutureTask.run(Future
[2017-09-26 10:26:41] <VQuery> please provide suggestion on this
[2017-09-26 11:01:35] <SISheogorath> VQuery: Still a jenkins/hudson error. Has nothing to do with Docker so we can't really help you.
[2017-09-26 13:01:49] <kdiogenes> Is there any boot2docker with XFS and quota support?
[2017-09-26 13:09:15] <rsegecin> yes@SISheogorath
[2017-09-26 13:11:09] <SISheogorath> rsegecin: what's a source volume?
[2017-09-26 13:13:57] <rsegecin> I mean when you have to configure the volume you need to write the mounting points source and destination
[2017-09-26 13:14:45] <rsegecin> actually "a volume" not "the volume"
[2017-09-26 13:18:43] <rsegecin> as in docker composeservices:[name of the container]:volumes: [<-CODE->] 
[2017-09-26 13:20:37] <SISheogorath> Well, you only need to do that for bindmounts, You can also use named volumes or unnamed volumes
[2017-09-26 13:21:48] <SISheogorath> And there is no way to automatically copy them, because the docker client only talks to the docker server. which then setups up all the paths and things. So the docker client isn't really aware of what the paths actually mean
[2017-09-26 14:40:49] <rsegecin> SISheogorath: so it's not possible to deploy on a remote machine specifying the volume source without having to copy the files to the node before hand?
[2017-09-26 14:42:48] <SISheogorath> well, since it's recommended to not use bind volumes, yes. The recommendation is to use named volumes with volume drivers which use an external storage backend like efs on Amazon or netapp on-prem.
[2017-09-26 14:43:36] <SISheogorath> bindmounts have various disadvantages compared with volumes
[2017-09-26 14:47:56] <karthikeyanpa90> Any help appreciated:
[2017-09-26 14:47:57] <karthikeyanpa90>  [<-LINK->] 
[2017-09-26 14:53:30] <rsegecin> SISheogorath: ok I understood. But even them with a efs configured I'd still need to copy the service files to that system wouldn't I?
[2017-09-26 14:56:17] <carlosjgp> rsegecin: You can use distributed storage, like S3, to mount a volume on your Docker container [<-LINK->] 
[2017-09-26 15:02:25] <SISheogorath> rsegecin: what "service files"?
[2017-09-26 15:03:23] <rsegecin> SISheogorath: the files that I need for the container to work with
[2017-09-26 15:05:55] <SISheogorath> You usually have your sourcecode on your GitHub/GitLab repository, let a CI pipeline build your images, deploy your images to the server instances and only the data is stored in volumes. In case of leagcy applications you maybe add some configs to the image or mount them by bindmount and copy them there using ansible, puppet or what ever CD system you use or even better, when you use docker swarm you can use config objects. When you run microservices following the 12factor.net rules, you simply use environment variables and docker secrets. So nothing else is needed ._.
[2017-09-26 15:06:20] <SISheogorath> I don't see where there is a need for the docker client to bring things over
[2017-09-26 15:20:23] <rsegecin> SISheogorath: that\'s what I needed but as I\'m doing a small project and I still don\'t know how to configure this "deployment pipeline" I came across this problem where I wanted to update something really small and if docker automatically update those files it would facilitate a lot. I guess this is a next step that I\'ll take in the future.
[2017-09-26 15:22:25] <SISheogorath> You can checkout this project of mine: [<-LINK->] We provide a basic configuration with the image and generate the remaining parameter from environment variables and defaults on startup
[2017-09-26 15:30:30] <rsegecin> it looks like a milestone from where I'm but thank you anyway =D
[2017-09-26 15:34:07] <rsegecin> Thank you@SISheogorath,  thank you@carlosjgpby the suggestion, I guess I'll just compile a new image with the change for now, when I try to create a pipeline I'be back here
[2017-09-26 15:34:13] <rsegecin> thank you guys
[2017-09-26 20:21:37] <thedrint> I have a question with named volumes
[2017-09-26 20:23:24] <thedrint> When create one with local-persist driver and map it to some directory in user home, app/ for example. app/ has permissions 775 and 1000:1000
[2017-09-26 20:26:02] <thedrint> Then i've run new container with nginx:latest with this new volume as /usr/share/nginx/html. Container change permissions of app/ to 755 0:0 (e.g. root)
[2017-09-26 20:27:38] <thedrint> I've change permissions to 775 1000:1000 again recursively. Copy my files inside. All good and works.
[2017-09-26 20:29:38] <thedrint> But when i re-create container (change nginx config for example) with docker stop-rm-run, permissions to app/ (only for app/ ) 755 0:0 again.
[2017-09-26 20:30:18] <thedrint> If i simply re-run container with docker stop-start, all fine.
[2017-09-26 20:33:44] <thedrint> With shared folders never see the same :(
[2017-09-26 21:54:21] <SISheogorath> igorbarkowsky: do you also recreate the volume?
[2017-09-26 21:55:06] <thedrint> SISheogorath: no, volume was untouched
[2017-09-26 21:57:00] <SISheogorath> Mhm do you have a link to the sources of your volume driver?
[2017-09-26 21:58:09] <thedrint> SISheogorath: i don't use compose, if you asked about it.
[2017-09-26 22:00:23] <thedrint> I've open issue at docker-nginx on github. But not sure that is nginx image bug
[2017-09-26 22:05:32] <SISheogorath> Well, when you use the alpine image for example?
[2017-09-26 22:06:05] <SISheogorath> does it appear there too?docker run --rm -it -v myvolume:/app alpine /bin/sh
[2017-09-26 22:09:46] <thedrint> No, with alpine image app/ mounted correctly, 775 1000:1000
[2017-09-26 22:11:55] <thedrint> Looks like nginx during install chown and chmod /usr/share/nginx/src (app/ on host)
[2017-09-26 22:57:08] <SISheogorath> that's possible, do you use the official nginx:latest image or an unofficial one?
[2017-09-26 22:59:23] <thedrint> SISheogorath: official.This is workaround for described situation [<-CODE->] 
[2017-09-26 23:09:55] <SISheogorath> yes,  seems to be an nginx image problem. They should be able to help when you open an issue :)
[2017-09-27 04:19:57] <ebcodes> is there a way with supervisord to promote a subprocess' shell to the foreground?
[2017-09-27 04:20:20] <ebcodes> within a docker container of course
[2017-09-27 10:31:32] <SISheogorath> ebcodes: acording to [<-LINK->] there issupervisorctl fg <process>
[2017-09-27 10:32:22] <SISheogorath> it's the same as outside of a docker container. Keep in mind the container only provides the environment for your software. Not more, not less. No magic involved
[2017-09-27 13:47:30] <rsoeldner> I receive strange  errors inside a docker container. My jvm application writes files to disk and directly call another process with a system call. Is it possible that filesystem isn't synchronized and subprocess tries to read a not flushed file ?
[2017-09-27 14:20:55] <SISheogorath> rsoeldner: do they run in different containers?
[2017-09-27 14:23:16] <rsoeldner> SISheogorath: no, same but found the failure. Sorry for not getting back its not realted to docker.
[2017-09-27 17:35:50] <ebcodes> SISheogorath: : seems like I'm getting aunix:///tmp/supervisor.sock no such fileerror
[2017-09-27 17:36:05] <ebcodes> entrypoint in docker file:ENTRYPOINT ["supervisorctl", "-c", "/src/docker/supervisord.conf", "fg app"]
[2017-09-27 17:41:48] <SISheogorath> Well, this can't really work because you need to run supervisord first before you can attach the application
[2017-09-27 17:42:03] <SISheogorath> in general it's not a good idea to do this
[2017-09-27 17:42:16] <SISheogorath> but it's possible
[2017-09-27 17:44:44] <ebcodes> what would be a better approach?
[2017-09-27 18:40:49] <ebcodes> pretty sure supervisord is not the right answer here
[2017-09-27 19:18:50] <thedrint>  [<-CODE->]  [<-CODE->] This info reference to what i set up in docker settings GUI.
[2017-09-27 19:22:25] <thedrint> @hmatt1 and on one of my linux host [<-CODE->] I not set up these settings on linux, think it set up automatically from whole memory and cpus at host.
[2017-09-27 19:24:18] <SISheogorath> ebcodes: depends on your setup. You should usually try to split up all your process into own containers. If that's not possible use supervisord
[2017-09-27 20:31:17] <ebcodes> figured out a solution :)
[2017-09-28 05:59:14] <ebcodes> another question
[2017-09-28 05:59:38] <ebcodes> I want to run an openvpn client inside my container and allow it to have a public routable ip address separate from the host ip address (mac os x)
[2017-09-28 05:59:43] <ebcodes> is there a way to achieve this?
[2017-09-28 06:52:24] <orangelynx> it certainly is possible, see here: [<-LINK->] . I cannot tell you however to configure your Mac for multiple ips.
[2017-09-28 10:02:46] <comeUpWithItLater> any suggestion  on writing    docker app Deployment Diagram?  how to describe  swarm cluster,   manager ,  node , service ,  container  all these things ?
[2017-09-28 10:07:41] <comeUpWithItLater> I  mean  uml
[2017-09-28 10:30:22] <VQuery>  [<-LINK->] 
[2017-09-28 10:30:33] <VQuery> how to install java in our boot2docker machine ?
[2017-09-28 10:30:48] <VQuery> please suggest
[2017-09-28 11:34:12] <Richard87> Hi guys! I'm running Nginx+PHP-FPM these days on my vps, but I'm thinking about migrating our apps to docker/kubernetes... Is there any recommandations on using php-apache vs php-fpm+nginx? Any benchmark-tests or best-practises?  (I feel that php-apache would be easier to setup, but I prefer nginx' config files...)
[2017-09-28 12:28:08] <saviour123> Is there a way to set password on a docker deployment?
[2017-09-28 14:24:11] <thedrint> Richard87: with nginx you must reload it all times you chage config. For example when you add some rewrite rules. With apache you can add rewrite to hraccess and it works immediatelly without restart apache
[2017-09-28 14:54:49] <thedrint> Richard87: php-apache containter has bigger image and it slower than php-fpm. And all hates apache:)
[2017-09-28 15:26:50] <Richard87> that makes me even more torn :/ I never update my config, so that's no problem, and I'll stopp all containers and launch new ones whenever I refresh the app anyway... BUT I was planning on copying in all my files into my container... But I don't know if nginx can access the files if they are inside the php-fpm container?
[2017-09-28 15:27:20] <SISheogorath> VQuery: you shouldn't install java on a boot2docker instance. it's a minimal OS and comes iirc even without a package manager. If you want to use java on such a machine, put it in a container
[2017-09-28 15:29:46] <SISheogorath> Richard87: as@igorbarkowskyalready pointed out. Both work. If you are already familiar with nginx and php-fpm that's the better way to go for you. If not, I would suggest to use the Apache combo. If you know neither Apache, nor nginx, apache is easier to start, nginx better to master :D
[2017-09-28 15:31:28] <Richard87> hehe, thanks@SISheogorath! I know both... But I'm not familiar with Docker, so I wonder what is mostly used in docker php-apps :)
[2017-09-28 15:32:06] <SISheogorath> I would say php-fpm.
[2017-09-28 15:32:29] <Richard87> Alright, thanks mate!
[2017-09-28 15:32:57] <SISheogorath> when you look at the official images, that's mainly used. Simply because it's more microserviced :D
[2017-09-28 16:38:06] <thedrint> @Richard87But I don't know if nginx can access the files if they are inside the php-fpm container?Maybe, volumes_from: directive in docker-compose.yml helps you. [<-CODE->] 
[2017-09-29 02:46:50] <JoinBugs> hello, i'm starting in docker and i have a project in python, i manage its dependencies with virtualenv, so reading many tutorials the recommendation is install virtualenv inside the docker image, but if i have my virtualenv in the host machine, why do not just copy using copy or add commands and not build a new virtualenv?
[2017-09-29 03:02:12] <AyushyaChitransh> JoinBugs: The point of using a docker container is to create a virtual environment. I mean you don't need a virtualenv. Do you?
[2017-09-29 03:03:34] <AyushyaChitransh> And if you do then you can simply mount an existing virtualenv inside container. That would be much easier. Because copy will create two instances, and every file will get copied individually.
[2017-09-29 03:31:07] <JoinBugs> Oo, I was not in perspective, Thanks so much@AyushyaChitransh
[2017-09-29 03:32:40] <comeUpWithItLater>  [<-LINK->] 
[2017-09-29 03:33:04] <comeUpWithItLater> is it possible to use "external"   like this?
[2017-09-29 04:20:13] <VQuery> SISheogorath: Thank you so much !! .i am new to docker for windows .please suggest docker image names to create docker node as using as slave in jenkins
[2017-09-29 04:20:40] <VQuery> previously we are using java web start  method
[2017-09-29 04:21:02] <VQuery> now we need to implement Docker JNLP implementation
[2017-09-29 04:22:20] <VQuery>  [<-LINK->] 
[2017-09-29 04:22:41] <VQuery> please find my docker plugin configuration above
[2017-09-29 04:24:14] <VQuery> my docker containers (evarga/jenkins-slave) log while running job`+ catchmod +x /tmp/init.sh\nexec /tmp/init.sh\nexport CONFIG=/tmp/config.sh\nCONFIG=/tmp/config.sh\n'[' '!' -f /tmp/config.sh ']'\necho 'No config, sleeping for 1 second'No config, sleeping for 1 second\nsleep 1\n'[' '!' -f /tmp/config.sh ']'\necho 'No config, sleeping for 1 second'No config, sleeping for 1 second\nsleep 1\n'[' '!' -f /tmp/config.sh ']'\necho 'No config, sleeping for 1 second'No config, sleeping for 1 second\nsleep 1\n'[' '!' -f /tmp/config.sh ']'\necho 'No config, sleeping for 1 second'No config, sleeping for 1 second\nsleep 1\n'[' '!' -f /tmp/config.sh ']'\necho 'No config, sleeping for 1 second'No config, sleeping for 1 second\nsleep 1\n'[' '!' -f /tmp/config.sh ']'\necho 'No config, sleeping for 1 second'No config, sleeping for 1 second\nsleep 1\n'[' '!' -f /tmp/config.sh ']'\necho 'No config, sleeping for 1 second'No config, sleeping for 1 second\nsleep 1\n'[' '!' -f /tmp/config.sh ']'\necho 'No config, sleeping for 1 second'No config, sleeping for 1 second\nsleep 1\n'[' '!' -f /tmp/config.sh ']'\necho 'No config, sleeping for 1 second'No config, sleeping for 1 second\nsleep 1\n'[' '!' -f /tmp/config.sh ']'\necho 'No config, sleeping for 1 second'No config, sleeping for 1 second\nsleep 1\n'[' '!' -f /tmp/config.sh ']'\necho 'Found config file'Found config file\nsource /tmp/config.sh++ JENKINS_URL=http://172.16.108.119:8080/++ JENKINS_USER=++ JENKINS_HOME=/home/jenkins++ COMPUTER_URL=computer/vj-docker-033193ecec5b/++ COMPUTER_SECRET=d2ad8bb48147339c14e2afd7abc847c460748b396440b1a338f3c3792557e902\n'[' -z http://172.16.108.119:8080/ ']'\n'[' -z computer/vj-docker-033193ecec5b/ ']'\n'[' '!' -d /home/jenkins ']'\n'[' -z /home/jenkins ']'++ command -v curl\n'[' -x '' ']'\nwget http://172.16.108.119:8080//jnlpJars/slave.jar -O /home/jenkins/slave.jar/tmp/init.sh: line 42: wget: command not found`
[2017-09-29 04:24:38] <VQuery> what we need to do?
[2017-09-29 05:55:28] <SISheogorath> comeUpWithItLater: I wouldn't suggest to do so, no.
[2017-09-29 05:57:56] <SISheogorath> VQuery: there are tons of Jenkins Slave slave images on docker hub, please checkout one of these. I'm neither a Jenkins, nor a java fan/expert.
[2017-09-29 06:47:00] <matrixbot> B3NGo/ Hey Guys, I'm not sure if I'm here in the right channel... I have a question about docker swarm and network-/ port-binding behaviours.
[2017-09-29 11:46:26] <SISheogorath> B3NG: feel free to ask your question. Maybe someone can help you with it :)
[2017-09-29 11:49:35] <matrixbot> B3NG@Sheogorathperfect! :)
[2017-09-29 11:52:37] <matrixbot> B3NGwhen I'm setting up a swarn serivce with the -p Argument , the ports are bind to every interface / network. Is there a way to bind ports of a services  to specific interface?
[2017-09-29 11:53:18] <matrixbot>  [<-CODE->] <IP>:<EXPOSED-PORT>:<CONTAINER-PORT>```does not work. :(
[2017-09-29 11:58:31] <SISheogorath> Nope, for Swarm-mode this is not possible right now.
[2017-09-29 12:01:18] <matrixbot> B3NGis this planned for the future?
[2017-09-29 14:06:05] <SISheogorath> I guess there are issues about that on GitHub. [<-ISSUE->] 
[2017-09-29 14:58:39] <rightisleft> Any good resources on how to manage persistence layers in docker swarm?
[2017-09-29 14:59:06] <rightisleft> we're scaling out our app and i need to read up on best practices for docker database architecture s
[2017-09-29 15:02:31] <matrixbot> B3NG@Sheogorath: thx
[2017-09-29 17:51:18] <SISheogorath> rightisleft: that's not such an easy question. Highly depends on your environment.
[2017-09-29 18:07:20] <rightisleft> right - thats what im researching ;)
[2017-09-29 18:57:22] <rightisleft> basically trying to decide between a monolithic database or service specific database
[2017-09-29 18:57:48] <rightisleft> and the pros and cons on scaling them using docker swarm
[2017-09-29 19:56:11] <chris453> hi there I am trying to remote run a docker container but whenever i try to run it i keep on getting this errorError response from daemon: invalid header field value "oci runtime error: container_linux.go:247: starting container process caused \\"process_linux.go:339: running prestart hook 1 caused \\"error running hook: exit status 1, stdout: , stderr
[2017-09-29 19:57:29] <chris453> the command i use is docker -h tcp://ipaddress:2376 run -it [<-LINK->] 
[2017-09-30 09:42:40] <Richard87> Hi guys! Are there any proxies (nginx, kube-proxy, ingress?) that have "retry logic" on specific responses from the container?
[2017-09-30 10:12:34] <comeUpWithItLater>  [<-LINK->] 
[2017-09-30 10:13:22] <comeUpWithItLater> doesdocker stack deploy * ***impose " SIGTERM" ?
[2017-09-30 10:39:01] <gusseleet> Hi Guys! Just trying to understand docker, I'm reading [<-LINK->] , when I change app.py the page does not update. I have no clue where to start debugging. Any tips?
[2017-09-30 14:30:28] <SISheogorath> comeUpWithItLater: yes, it sends a SIGTERM and after 30 secods (by default, but can be changed) it kills the process. Notice: It only sends the SIGTERM to the PID 1 in the container. So you have to take care of the rest. This often causes problems when people don't use the right tools in theirENTRYPOINTstatements.
[2017-10-01 02:11:51] <thedrint> @Richard87Hi guys! Are there any proxies (nginx, kube-proxy, ingress?) that have "retry logic" on specific responses from the container?I\'ve read yesturday on nginx.org about upstream options. In commercial subscribe nginx has some useful options like resolve. In upstream {} section (under http{} section) you can define pool of servers to response. And then you define at location{} section defined upstream. For example, you can set [<-CODE->] And in location [<-CODE->] Docker service in compose.yml has option "restart" too, if you want proxy try to up after fails.
[2017-10-01 15:52:14] <AyushyaChitransh> jeud: Naah, If you don't need the older image too, then you can simply rebuild the newer image with the same tag
[2017-10-01 18:09:51] <SISheogorath> jeud: depends on where you store your source code.VOLUMEis probably not what you search for. It only persist the data that is inside the container at the mentioned path
[2017-10-01 18:11:59] <SISheogorath> Usually you useCOPYor  get/clone it from you version control. If you talk about a local development environment, you may want to bind-mount it into a running container using the-vparameter withdocker run
[2017-10-02 06:42:59] <rsoeldner> Good morning. While running my application inside a docker container I sometimes receiveIllegal Instruction, exit code 132. I compiled my application on the same machine running debian.  If I understand correct my docker cpu instructions doesn't match to compiled ones. But it run's locally perfect. Can someone provide help ?
[2017-10-02 09:24:41] <Richard87> Hi guys! I need some more advice :/ My "Build context" is 1.25gbs, even though my source-code is around 50mb (including images/assets etc), I\'m using .dockerignore to remove all logs and vendorfiles etc, what else can I do to limit the size?
[2017-10-02 09:28:27] <AyushyaChitransh> Richard87: Are there any hidden files that could have gone in context?
[2017-10-02 09:29:07] <Richard87> no, there is only .git and .idera, and they are both added to .dockerignore
[2017-10-02 09:31:45] <Richard87> (I have also used Disk analytics to look for big files, there are none..
[2017-10-02 09:38:06] <Richard87> well, it makes perfect sense :(docker build .ignores .dockerignore ..
[2017-10-02 09:38:28] <Richard87> checking/var/lib/docker/tmp/docker-builder156883376and all my files are there..
[2017-10-02 09:46:52] <SISheogorath> rsoeldner: looks like the your architecture your application is compiled for doesn't match the one your run underneath. Usually happens in ARM environment because there are various ARM versions out there (it's a nightmare) if your image runs and fails after a while you probably have added a binary for a different architecture.
[2017-10-02 10:19:32] <Richard87> AyushyaChitransh: Thanks for helping! Leading/messed up everything, I removed those and now it worksalotbetter ;)
[2017-10-02 10:20:59] <Richard87> wow, this actually works _alot faster :O
[2017-10-02 10:36:43] <rsoeldner> SISheogorath: thank you! To fix this the workflow must be an entryscript which pulls sources and build it ?
[2017-10-02 10:37:49] <SISheogorath> usually it's better to simply build the docker image on your architecture. Keep in mind you need an base image that supports the architecture
[2017-10-02 11:00:15] <rsoeldner> SISheogorath: oh sry, but my image was build & run locally. I have no idea why this happens, I use some SSE instructions in my application binary. But they are available inside docker (checked by proc/cpuinfo)
[2017-10-02 12:24:48] <SISheogorath> Are you on a non-x86_64 CPU? and if so, what base image are you using?@rsoeldner
[2017-10-02 12:25:10] <SISheogorath> Also check back that your process doesn't fail because of missing permissions
[2017-10-02 12:49:28] <rsoeldner> SISheogorath: no its x86_64 its gcc-6 base image. The process exits with error code 132
[2017-10-02 12:51:00] <rsoeldner> But it only fails inside my docker container on the same machine i build it. If i run it outside the docker image, it works perfectly. I don't get it. Maybe there is some memory corruption that causes this problem ?
[2017-10-02 13:04:18] <SISheogorath> As I said, probably missing permissions. check what capabilities your process has outside of docker and inside of docker
[2017-10-02 13:11:25] <SISheogorath> See: [<-LINK->] 
[2017-10-02 13:12:14] <SISheogorath> use--privilegedonly for testing
[2017-10-02 15:17:18] <ndpratas> Does anyone here have experience running Tibco bwce in docker locally?
[2017-10-02 15:17:19] <ndpratas> I'm lost
[2017-10-02 18:26:49] <mahenrique94> Good afternon guys, How do to proxy a DOMAIN for ports ? e.g: mysql.domain.com.br redirect to server_mysql:3306 or ssh.domain.com.br redirect to server_ssh:22, any sugestions ?
[2017-10-02 19:35:03] <SISheogorath> mahenrique94: what you search is a SRV record. But that has nothing to do with docker
[2017-10-02 19:36:47] <SISheogorath> Also you have to check that the software you want to use with these "Domains" know how to use SRV records
[2017-10-02 20:03:04] <imaia> question folks: is there any good practices around nfs vs volume?
[2017-10-02 22:02:03] <SISheogorath> since the "local" volume driver has a type field now, simply mount it, using it. Keep in mind that you probably run into problems with local caching and missing ability of Lockfiles
[2017-10-03 00:15:38] <karneaud> Hey guys can anyone help me understand how the volumes of docker-compose work? I have the following problem [<-LINK->] and not sure how to solve it
[2017-10-03 02:48:10] <jeud> i'm using node.js and expect to config docker compose, should i install npm packages locally and map entire path to the container or somehow install npm packages when loading the container ? please guide
[2017-10-03 08:14:53] <PhoenixMage> How can I check to see what storage drivers my particular instance of docker supports?
[2017-10-03 10:07:37] <SISheogorath> PhoenixMage: it's listed bydocker info
[2017-10-03 10:10:15] <SISheogorath> jeud: depends on your environment. If it's a development environment, maybe. If it's a production environment: Everything that is not data should be part of the image. Take a look at [<-LINK->] as reference
[2017-10-03 10:10:25] <PhoenixMage> SISheogorath: I thought that only listed the active one
[2017-10-03 10:11:21] <SISheogorath> There should be an array
[2017-10-03 10:14:11] <SISheogorath> Mhm okay  no longer there
[2017-10-03 10:20:06] <PhoenixMage> SISheogorath: Docker with aufs doesnt support POSIX ACLs does it? according to the aufs website they do but maybe Docker or the version I am on with ResinOS doesnt...
[2017-10-03 10:59:30] <SISheogorath> I can't say, I'm using overlay2
[2017-10-03 17:08:23] <kdiogenes> someone knows about any script to detect underused running docker containers?
[2017-10-03 17:11:01] <kdiogenes> I'm thinking in writing a script to parsedocker statsand implement rules to decide if a container is underused or not
[2017-10-03 19:47:03] <SISheogorath> underused like using less memory than allowed?
[2017-10-03 21:30:20] <kdiogenes> Not using CPU or network for a long time
[2017-10-03 21:42:55] <SISheogorath> I don't think that a script is the right way to do that. That's what monitoring is for
[2017-10-03 21:43:10] <SISheogorath> Get the metrics and set a threshold
[2017-10-03 21:44:13] <kdiogenes> Do you recommend any monitoring solution for this?
[2017-10-03 22:00:54] <SISheogorath> depends on where you run it. If it's about selfhosting a prometheus stack is probably the way you want to go. (But I don't run it myself so can't say for sure) Otherwise I would also recommend Datadog as Cloud-based solution, but it's pretty expensive. Everything else I can think of right now is more improvised or also cloud based and nothing I used until now
[2017-10-04 08:01:03] <hazim1093> Hi, does anyone know what's the difference betweenactionandstatusindocker events?
[2017-10-04 08:01:24] <hazim1093> they both seem to have the same values
[2017-10-04 14:40:30] <ndpratas> I set up my private registry
[2017-10-04 14:40:33] <ndpratas> net/http: request canceled (Client.Timeout exceeded while awaiting headers)
[2017-10-04 14:40:40] <ndpratas> does anyone have a clue?
[2017-10-04 14:42:33] <ndpratas> I get that error trying to pull an image (which I pushed to the registry fromanotherhost) FROM THE SAME HOST where the registry is running
[2017-10-04 14:44:33] <ndpratas> so, the registry is running, cool.i can push an image from a random host across the network, coolI can't pull the image from the same host where the registry that is running on,notcool
[2017-10-04 14:49:39] <SISheogorath> how do you try to pull?
[2017-10-04 14:51:14] <ndpratas> docker pull hostname:5000/blabla:latest
[2017-10-04 14:51:34] <ndpratas> the same as I do with push but with pull
[2017-10-04 14:51:40] <ndpratas> same command
[2017-10-04 14:54:50] <SISheogorath> What does the registry logs say?
[2017-10-04 15:06:41] <ndpratas> SISheogorath: Good question. Let me see
[2017-10-04 15:09:29] <ndpratas> SISheogorath: nothing on the logs. btw I can pull the image from the registry on the remote host
[2017-10-04 15:09:53] <ndpratas> I just changed the hostname to localhost
[2017-10-04 15:09:56] <ndpratas> worked... wtf
[2017-10-04 15:10:08] <ndpratas> pinging the server works as well
[2017-10-04 15:10:21] <ndpratas> I don't know what the issue is
[2017-10-04 15:14:09] <SISheogorath> sounds like a routing problem. A possible solution is to correct your hostname mapping in/etc/hosts
[2017-10-04 15:52:46] <ndpratas> SISheogorath: the thing is.... it is correct lol
[2017-10-04 15:53:11] <SISheogorath> you mapped the hostname to localhost on that machine?
[2017-10-04 16:02:23] <ndpratas> SISheogorath: no. I just checked and the /etc/hosts is the default one,nothing is added. Therefore when I ping the hostname it must be using the DNS
[2017-10-04 16:05:55] <SISheogorath> is your fqdn in there?
[2017-10-04 16:06:22] <SISheogorath> or what ever you used as "host" in your pull?
[2017-10-04 16:22:06] <ndpratas> SISheogorath: how so?
[2017-10-04 16:23:04] <ndpratas> I used: docker pull example.domain.com:5000/bla/blabla:latest
[2017-10-04 16:23:08] <SISheogorath> usually the fqdn of a machine should be place inside its/etc/hostsfile
[2017-10-04 16:23:19] <ndpratas> you're right
[2017-10-04 16:23:25] <ndpratas> I don't manage these machines
[2017-10-04 16:23:45] <ndpratas> but It should work nonetheless because it can indeed ping itself
[2017-10-04 16:23:50] <ndpratas> (DNS)
[2017-10-04 16:25:31] <ndpratas> SISheogorath: Like I said, I just edit the /etc/hosts file and nothing changed
[2017-10-04 16:26:01] <ndpratas> [DONT WORK] docker pull example.domain.com:5000/bla/blabla:latest[WORK] docker pull localhost:5000/bla/blabla:latest
[2017-10-04 16:48:33] <SISheogorath> it's not that easy because routing with networknamespaces is a bit more complicated
[2017-10-05 07:32:22] <rkdls> is there any project integration docker and machine learning  ?
[2017-10-05 07:39:54] <racinmat> yes, for some machine learning projects, there is docker image, but mostly, as far as I know, docker haven't penetrated machine learning field as heavily as software development.
[2017-10-05 07:40:35] <racinmat> When I use docker for machine learning,I mostly use some python image with jupyter, numpy,scipy, matplotlib.
[2017-10-05 07:42:41] <racinmat> but Kaggle image should be good starting point for looking for integration of docker and machine learning [<-LINK->] 
[2017-10-05 07:46:09] <rkdls> ah that repo is very usefull i think
[2017-10-05 07:55:17] <rkdls> but I'm finding project  integrated docker-py and machine-learning
[2017-10-05 07:58:36] <racinmat> you mean project in machine learning utilizing docker? I do not think I get your question. In machine learning, people do not care much about docker, it is used only to more easily run the machine learning source code, nothing more.
[2017-10-05 08:07:03] <rkdls> aha Ok. I just looking for anyproject. thanks
[2017-10-05 19:33:14] <sherryhw> hello everyone. is there anyone who use "dockerfile-maven-plugin"?
[2017-10-05 19:34:19] <sherryhw> I use this maven plugin to build and push image to a reposotory. however, on the first step to build the image, it fails for "Caused by: java.util.concurrent.ExecutionException: com.spotify.docker.client.shaded.javax.ws.rs.ProcessingException: javax.net.ssl.SSLException: Unrecognized SSL message, plaintext connection?" Anyone has any ideas? Thanks!
[2017-10-06 07:47:47] <littlefuntik> Hi guys! [<-CODE->] Why???
[2017-10-06 11:46:22] <Fuco1> Is there some way to list all the files matched by.dockerignore?  I'm building a filtering utility and I would like to have a filter to hide all files ignored bydocker build
[2017-10-06 11:46:47] <Fuco1> in git we can do something likegit ls-files --others -i --exclude-from=.gitignore | awk -F "/" \'{print $1}\' | sort | uniqto get the toplevel ignored files/directories... I\'m looking for something similar
[2017-10-06 14:34:25] <brandonawells> Does anyone here do any sort of container security cans on their docker containers? If so, how are you doing, what service(s), how does it integrate with your CI progress, etc..? Any help is appreciated.
[2017-10-06 14:34:38] <brandonawells> Part 2 to that, has anyone ever worked with Twistlock?
[2017-10-06 15:46:31] <aios> littlefuntik: beacause containers runing in own network
[2017-10-06 15:46:53] <aios> littlefuntik: you need to expose ports to use host machine for connect to db
[2017-10-06 15:48:54] <littlefuntik> aios: docker-compose exec php sh -c "php /var/www/testdb.php"- connect successcurl http://localhost/testdb.php- failed
[2017-10-06 15:49:39] <littlefuntik> One and the same container
[2017-10-06 15:50:20] <littlefuntik> but php-fpm process works poorly with dns
[2017-10-06 15:50:43] <aios> what content in testdb.php?
[2017-10-06 15:51:03] <aios> littlefuntik: В личку пиши затрахали на инглише)
[2017-10-06 15:51:50] <maxpaint> aios: (((((
[2017-10-06 15:52:23] <maxpaint> party hard
[2017-10-07 16:51:26] <JonasHedEng> Hello! Is it possible to have some form of recursive dependency on replicas? I want to start a bunch of replicas of the same image on my docker subnet and when they start they try to register to another replica on a "smaller" IP address.
[2017-10-07 17:18:18] <littlefuntik>  [<-CODE->] answer: [<-CODE->]  [<-CODE->] 
[2017-10-09 01:17:15] <ebcodes> question
[2017-10-09 01:17:29] <ebcodes> I'm using Synology Diskstation and Docker
[2017-10-09 01:17:42] <ebcodes> unfortunately, /var/run/docker.sock only allows access via root
[2017-10-09 01:18:24] <ebcodes> 1) is this by design?2) if it isn't, is there a global config somewhere on Synology (maybe /var/packages/Docker/...) where I can ensure this sock file doesn't prohibit access by non-root users?
[2017-10-09 02:51:25] <SISheogorath> ebcodes: Yes, that's by default the case. Only root and docker users should have access to this socket. Simply because who ever has write access to this socket has root privileges.
[2017-10-09 08:46:16] <MonXBZH> Hello there ! o/
[2017-10-09 08:46:52] <MonXBZH> There is a way to add a distant worker on a swarm over internet ?
[2017-10-09 09:11:45] <VQuery> Hi guys ,i just now installed docker for windows and switched to windows containers .Now  i want to create docker-machine ,how to do this ?
[2017-10-09 17:38:34] <mcarpenterjr> Question, I have a docker container running, it has a port exposed at:3030I have apache running on the same server as docker. I would like to configure a relative url to point to:3030. Is this possible? and if so what terminology would I be searching for. I googled a couple different terms and I either get results that describe if apache is running as a container or some other unexpected result.
[2017-10-09 18:36:19] <SISheogorath> mcarpenterjr: I guess what you are searching for is the term "reverse proxy" ;)
[2017-10-09 18:39:37] <SISheogorath> MonXBZH: yes, as always. Simply put thedocker swarm joinstatement in your console on your remote worker. But you have to make sure, that your manager is accessible (means routed alias "doesn\'t use a private IP space in a different network").
[2017-10-10 02:19:28] <DWSR> MonXBZH: This is highly discouraged as the Docker socket provides root access to the box.
[2017-10-10 03:57:46] <VQuery> i am using jenkinsci/slave image in minimax linux boot2docker ,but our organization has only windows platform build operation like Msbuild compilations ,bat files execute,visual studio supporting tools .How to create windows machine slave in docker ?
[2017-10-10 04:46:22] <comeUpWithItLater> I  just send an image to the  manager machine in a swarm cluster :
[2017-10-10 04:46:35] <comeUpWithItLater>  [<-LINK->] 
[2017-10-10 04:47:52] <comeUpWithItLater> do I need to send it to every  worker  worker machine b4 I candocker stack deploy ***?
[2017-10-10 08:25:54] <SISheogorath> comeUpWithItLater: you should use a private registry for swarm. Since swarm automatically uses the fingerprint of an image to identify it and make sure it's the same image for this service no matter if the tag got overwritten or not. There is no functionality built-in to send your images to the workers
[2017-10-10 08:29:52] <MonXBZH> Thx@SISheogorathand@BrandonAndrews
[2017-10-10 08:31:42] <comeUpWithItLater> Thank you@SISheogorath
[2017-10-10 08:32:03] <comeUpWithItLater> one more:
[2017-10-10 08:33:05] <comeUpWithItLater> network_mode: "host"config option is not supported in stack.yml  ?
[2017-10-10 08:33:27] <comeUpWithItLater>  [<-LINK->] 
[2017-10-10 08:38:28] <comeUpWithItLater> if so ,  how to  proxy pass ( nginx )  to an other  stack service's container port?
[2017-10-10 09:55:49] <rsoeldner> comeUpWithItLater: I needed this too [<-CODE->] 
[2017-10-10 09:57:59] <comeUpWithItLater> but  I need to proxy  it  to  container(s)  in an other stack services
[2017-10-10 09:59:13] <comeUpWithItLater> i   knewbackendrefer to   an other service name  in the current  stack  in your example
[2017-10-10 09:59:16] <rsoeldner> Hm, I'm not sure if I understand this, I use alinksflag in my docker compose
[2017-10-10 10:01:37] <SISheogorath> rsoeldner: you shouldn't.linkshave ugly side effects
[2017-10-10 10:03:31] <comeUpWithItLater> so how to refer to  service  in   other  stack  ?
[2017-10-10 10:04:07] <SISheogorath> comeUpWithItLater: nope, network_most: "host" currently doesn\'t work in swarm mode so also not in stack deploy. The answer to how to pass the stuff is networking. The recommendation from my side is use an API based reverse proxy like traefik. If you are form "bug I need nginx" fraction, take a look at jwilders dynamic nginx reverse proxy image
[2017-10-10 10:04:33] <SISheogorath> when you are inside a stack you can simply use the service name on the stack's network
[2017-10-10 10:04:37] <rsoeldner> ^^ ok thanks i will check this too
[2017-10-10 10:05:14] <SISheogorath> rsoeldner: Check [<-LINK->] 
[2017-10-10 11:35:54] <masaeedu> Probably the least lawyery person on the planet, would appreciate help with a licensing question.
[2017-10-10 11:36:29] <masaeedu> If I generate a client for the Docker API using the swagger API definition, can this client be licensed/published under MIT?
[2017-10-10 11:36:37] <masaeedu> See [<-LINK->] 
[2017-10-10 12:09:45] <SISheogorath> Yes. Since it's your code (even when it's generated) you can license it as you wish. You only have to make sure that your DEPENDENCIES don't conflict with your license. Check for license compatibility in this case.
[2017-10-10 12:12:14] <masaeedu> Thanks
[2017-10-10 12:12:54] <SISheogorath> You're welcome. 
[2017-10-10 12:28:46] <comeUpWithItLater> SISheogorath: thaks for recommending
[2017-10-10 12:29:15] <comeUpWithItLater> but :
[2017-10-10 12:29:27] <comeUpWithItLater>  [<-LINK->] 
[2017-10-10 12:30:37] <comeUpWithItLater> the  emilevauge/whoami   image works ,  but my  nginx   image doesn't
[2017-10-10 12:31:17] <comeUpWithItLater>  [<-LINK->] 
[2017-10-10 12:31:19] <SISheogorath> comeUpWithItLater: try to run traefik with the--weband expose port 8080
[2017-10-10 12:31:31] <comeUpWithItLater> this is the dockerfile
[2017-10-10 12:31:46] <SISheogorath> then check this webinterface for what rules are applied to what container
[2017-10-10 12:32:05] <SISheogorath> also check your traefik settings for the default domain suffix for containers
[2017-10-10 12:32:37] <comeUpWithItLater>  [<-LINK->] 
[2017-10-10 12:32:42] <SISheogorath> If you don't want to change the default settings or want to use multiple domains, consider to use ahostrule
[2017-10-10 12:34:04] <comeUpWithItLater> this is the stack.yml file for  traefik
[2017-10-10 12:34:11] <comeUpWithItLater>  [<-LINK->] 
[2017-10-10 12:36:04] <comeUpWithItLater> could  be some nginx  config  workroud?
[2017-10-10 12:38:35] <SISheogorath> maybe, you do a prefix strip there, which is probably not what you want
[2017-10-10 12:45:23] <comeUpWithItLater> comment out the- "traefik.frontend.rule=PathPrefixStrip:/http/", still doesn\'t work
[2017-10-10 13:08:57] <Aaaaaa11804835_twitter> hi i have problem with linking nginx and php-fpm containers in docker-compose.yml [<-CODE->] 
[2017-10-10 13:10:18] <Aaaaaa11804835_twitter> i use laravel in web container and if it's route from code - works fine. But if it's static file (like js, css,image) - 404 error.
[2017-10-10 13:10:40] <Aaaaaa11804835_twitter> probably nginx doesn't see those static files
[2017-10-10 13:13:38] <comeUpWithItLater> docker service logs --tail=10  traefik_proxyshows :msg="Validation of load balancer method for backend backend-www failed: invalid load-balancing method \'\'. Using default method wrr."
[2017-10-10 13:22:49] <rsoeldner> Is it possible, without modifications to runaws ecr composelike a localdocker-composewitha private registry ?Currently I build all needed images by hand and expect them. Now i want to create a small script to push them - but afaik for AWS ECR I need to tag them special and then docker-compose service names change.
[2017-10-10 13:39:56] <karthikeyanpa90> hi, how to get spark-assembly-x.x.x-hadoopx.x.x.jar ?
[2017-10-10 14:07:09] <Aaaaaa11804835_twitter> Hi. What is the best practice to get source code from repository? Using 'git pull' in Dockerfile or first pull repository and then run docker?
[2017-10-10 17:23:10] <littlefuntik> девиз "Хочешь с чего-то начать - начни с докера" :D
[2017-10-10 17:29:41] <SISheogorath> Aaaaaa11804835_twitter: depends on your needs. In general I would go for docker inside the repository, when it's a project that runs inside a company. Docker split up into an own repository, then build the image and test the image for software you are about to publish, because you probably need different tests, additional documentation and an own CI process for docker. Besides your usual way of setting the software up natively
[2017-10-10 17:30:50] <SISheogorath> So while in the first case for internal projects I would go forCOPY . /srcin the latter version in an own repository you will clone the latest stable release
[2017-10-10 17:33:12] <SISheogorath> For official best practices: [<-LINK->] 
[2017-10-10 22:16:29] <nafg> Hi, I'm having a really weird issue.docker inspectshows my environment variables are set correctly, and if Idocker-compose execin I can see them, however the actual process running inside docker does not see them
[2017-10-10 22:23:17] <nafg> Ok it's dropping the ones with dots in the name
[2017-10-10 22:33:19] <nafg> cuz this [<-LINK->] 
[2017-10-11 04:33:35] <VQuery> please any one clarify my doubts in docker ?I switched to windows containers but how to create windows slave node in jenkinsi could not find any documentation for this . 
[2017-10-11 04:36:23] <VQuery> but i have implemented linux slave in jenkins by using jenkinsci/slave image .
[2017-10-11 04:36:49] <VQuery> all things configured in yet another plugin
[2017-10-11 05:41:16] <fouadroumieh> I need help install docker-compose via yml command for TeamCity agent. Can anyone help please with an example?
[2017-10-11 07:24:30] <rsoeldner> fouadroumieh: Couldn't you build a new image like this [<-LINK->] 
[2017-10-11 08:14:26] <comeUpWithItLater>  [<-LINK->] 
[2017-10-11 08:15:27] <comeUpWithItLater> how to allow multi networks?  adding adefaultnetwork break thetraefik_public
[2017-10-11 08:18:14] <comeUpWithItLater> but if  i don't add  it , the  adminx01 will not be able to refer to the db1 service
[2017-10-11 08:20:13] <comeUpWithItLater> config thedb1to use  thetraefik_publicmay be help, bu t  not sure if it's a good    practice  or ?
[2017-10-11 08:56:19] <SISheogorath> comeUpWithItLater: what I use in production: Create a network for traefik. then rundocker-compose upfor your traefik instance with an network that is marked as external. Everything else, you want to publish on HTTP or HTTPS should use this network as external network
[2017-10-11 08:56:59] <SISheogorath> If you are familiar with ansible: [<-LINK->] 
[2017-10-11 08:57:20] <VQuery> SISheogorath: ,please give me any suggestion for below queryI switched to windows containers but how to create windows slave node in jenkins ?i could not find any documentation for this . but i have implemented linux slave in jenkins by usingjenkinsci/slaveimage .all things configured in yet another plugin
[2017-10-11 08:58:59] <SISheogorath> VQuery: I can't say anything about windows containers or jenkins. I touched my last jenkins over a year ago and for windows the time scale is similar
[2017-10-11 08:59:49] <SISheogorath> Maybe check the docker Community Slack. There is an entire channel about windows containers
[2017-10-11 09:00:02] <SISheogorath> And also one for CI/CD
[2017-10-11 09:02:23] <VQuery> SISheogorath:  is  windows container users count very low globally ?
[2017-10-11 09:06:45] <SISheogorath> The whole container thing is a bit new to Windows, so I would say there is a large gap between the number of Windows containers and the number of Linux containers. Especially when it comes to the usage in production. But that doesn't mean that the windows containers count is very low. It's not as popular right now, but a fastly growing market
[2017-10-11 09:10:25] <yiv> how do I solve this problem
[2017-10-11 09:10:49] <VQuery> SISheogorath: Thanks for your valuable comments 
[2017-10-11 09:11:03] <yiv>  [<-CODE->] 
[2017-10-11 09:11:04] <yiv> how do I solve this problem
[2017-10-11 09:13:28] <SISheogorath> yiv: does it work withdocker stop compose_cockroach2_1  && docker rm compose_cockroach2_1?
[2017-10-11 09:14:37] <SISheogorath> If so, trydocker-compose stop cockroach2 && docker-compose rm cockroach2(yes, in one row) to verify if it's a time or a general problem
[2017-10-11 09:17:24] <yiv>  [<-CODE->] 
[2017-10-11 09:18:53] <yiv>  [<-CODE->] 
[2017-10-11 09:19:05] <SISheogorath> What's the output ofdocker version?
[2017-10-11 09:20:04] <yiv>  [<-CODE->] 
[2017-10-11 09:22:05] <SISheogorath> Did you setup some kind of automated restart with systemd or upstart?
[2017-10-11 09:23:36] <yiv>  [<-LINK->] 
[2017-10-11 09:24:16] <yiv> I installed the docker as what this document say
[2017-10-11 09:24:44] <yiv> then didn't setup any kind of automated
[2017-10-11 09:25:20] <yiv>  [<-CODE->] 
[2017-10-11 09:26:01] <yiv> I do use 'restart: always' option
[2017-10-11 09:32:10] <SISheogorath> That should be fine. I would recommend to open an issue in [<-LINK->] 
[2017-10-11 09:33:16] <SISheogorath> When you are sure there is only docker involved, that's the way to go
[2017-10-11 09:34:26] <yiv> thanks, I'll do it
[2017-10-11 10:09:35] <sabrehagen> Is there a way to use CloudFormation'sdependsOnin a serverless cloudformation config?
[2017-10-11 10:32:05] <crebuh> Hy Guys, had anyobdy a similar issue with a node-application. When I'm building the container locally all dependencies are installed correctly (with the right version). When I build the container on my remote server, a wrong version of the peerDependency is installed. Not sure how this could happen. I then always have to login into the container remove the module and install it with npm installpackage@correct-versionagain. Which is pretty annoying
[2017-10-11 10:34:50] <SISheogorath> crebuh: Usually this happens by not locked dependencies. yarn hasyarn install --pure-lockfileto prevent this. NPM 5 also uses some kind of lock file, maybe you want to check this out
[2017-10-11 10:35:39] <SISheogorath> when you have something likepackage@^1.0in your package.json
[2017-10-11 13:29:06] <IceS2> Hey guys, anyone here uses the Docker Python SDK? I'm having some trouble connecting to an external Docker Swarm
[2017-10-11 14:09:39] <crebuh> SISheogorath: yes I know this, this is the reason why on our projects we are always locking the dependencies by using a fixed version number and now ^ or ~ in front. but it seems that one of the dependencies (let's say express) has also a dependency and this peer-dependency is installed with the wrong version
[2017-10-11 14:13:22] <SISheogorath> You useyarnornpm?
[2017-10-11 14:14:48] <SISheogorath>  [<-LINK->] <-- is this included in your source repository you add to your container?
[2017-10-11 14:17:48] <SISheogorath> I see. Right now, the install from lock is missing in npm right now [<-ISSUE->] 
[2017-10-11 14:18:09] <SISheogorath> try to useyarnand check if the issue perists
[2017-10-11 14:18:27] <SISheogorath> crebuh: ^
[2017-10-11 14:18:56] <SISheogorath> IceS2: Feel free to share you error message, maybe someone can help
[2017-10-11 14:59:56] <fouadroumieh> rsoeldner: yes one of the ways is to use RUN command insde Dockerfile, but I want to do it through yml file.
[2017-10-11 16:27:37] <IceS2>  [<-CODE->] When trying to connect via CLI I get the following error: [<-CODE->] But I'm not using a TLS-enabled daemon ;x
[2017-10-11 16:55:01] <crebuh> SISheogorath: thx i will check it
[2017-10-11 17:53:44] <IceS2> I managed to overcome that problem guys, It took a while because of some configuration issues. Now I'm looking to start a bunch of services based on a docker-compose file  on Swarm using the Python SDK (=
[2017-10-11 18:01:15] <SISheogorath> cool@IceS2so it was no SDK issue?
[2017-10-11 18:20:58] <IceS2>  [<-CODE->] I was messing around with the SDK to develop an Ansible module for docker swarm... But I think I'll just use the shell module and call it a day
[2017-10-11 19:53:50] <johnsonw> Hello, quick question regarding disk creation in docker. In vagrant, we have been able to create a disk by doing something like this: [<-CODE->] I can then see the disk by running lvmdiskscan: [<-CODE->] Is it possible to create a disk like this in a docker container?
[2017-10-11 20:22:43] <Scapal> What would be the best pattern to publish docker service?I was thinking about having only the manager nodes with a public IP.Put a pair of haproxy with a failover VIP in front of that.
[2017-10-11 20:23:46] <Scapal> Is this considered the best practice or should I just put a failover VIP on the manager nodes without an additional layer of haproxy outside the swarm ?
[2017-10-11 20:24:24] <SISheogorath> The regular setup is more that the manager nodes are hidden in a private network and a few worker nodes are exposed
[2017-10-11 20:25:01] <SISheogorath> But it highly depends on what you are about to do and how familiar you are with these setups
[2017-10-11 20:33:31] <Scapal> My setup is:3 Proxmox servers, on each one: 1 manager node for fault tolerance + worker nodes.I was going to put 3 small VM with HaProxy (with corosync and pacemaker for VIP failover) and load-balancer to the 3 manager nodes with health check.I this setup, even the manager nodes don’t need a public IP.
[2017-10-11 20:34:59] <Scapal> The other possibility I can think about is to have the HaProxy on the manager nodes (or 3 other workers) with pacemaker on those 3 swarm nodes to assign the VIP to one of them
[2017-10-11 21:02:09] <killerspaz>  [<-CODE->]  [<-CODE->] I forget how to work around this...
[2017-10-11 21:02:30] <killerspaz> notice it statesnuleven though I provide/dev/null
[2017-10-11 22:35:14] <Miguelacosta90> hi I just started using docker and I want to make a simple wordpress plugin can any guide me to some guides so I can learn?
[2017-10-11 22:40:09] <SISheogorath> A wordpress plugin? That's something that is not really related to docker.If you talk about an wordpress image, have a look at http://training.play-with-docker.com
[2017-10-11 23:03:45] <Miguelacosta90> ya I want to learn how to run the plugin file in the docker imgae
[2017-10-11 23:38:06] <SISheogorath> Iirc the official WordPress images have a WordPress instance inside. But I know that a
[2017-10-11 23:41:22] <SISheogorath> friend of mine built this one: [<-LINK->] very awesome
[2017-10-11 23:41:45] <SISheogorath> And should be able to use the regular install mechanisms
[2017-10-12 02:55:02] <rkdls> Is it possible to mount the docker engine in Windows? like linux  "docker run -v /var/run/docker.sock:/var/run/docker.sock"
[2017-10-12 03:49:03] <killerspaz> My google-fu is failing, is there a way to verbosely show the files being copied with a COPY statement?--verbosedoesn't seem to do it
[2017-10-12 03:56:16] <comeUpWithItLater> @SISheogorath   I   have  :-1. a traefik    service-2.  an api  service-3 . a MySQL db service [<-CODE->]  [<-CODE->] 
[2017-10-12 03:58:06] <comeUpWithItLater> since the MySQL  db service only is running onconstraints: [node.role == manager]
[2017-10-12 04:40:26] <VQuery> Hi Guys,i am using docker toolbox windowsconfigured docker and jenkins in same local machine and its working fine in below manner.in jenkins implemented yet another plugin and added docker api url tcp://192.168.99.100:2376 and usedjenkinsci/slave.docker slave is creating every time job triggering in jenkins .Now we moved jenkins server to cloud but docker in local machine .How to access docker in this case?how to create docker public API url ?
[2017-10-12 04:54:59] <killerspaz> I have a web server hosting a react app, and another service hosting an API.... I'm on windows, how would i go about building the react assets to point to the API without hardcoding the IP?
[2017-10-12 05:51:23] <MonXBZH> Hey there ! o/
[2017-10-12 05:52:06] <MonXBZH> There is a way to use TLS/SSL between workers and manager on Docker Swarm?
[2017-10-12 06:25:16] <SISheogorath> MonXBZH: for the management traffic thats the default case (iirc there is no way to disable it) to encrypt your overlay network traffic, add the `--encrypt* option during creation
[2017-10-12 06:29:13] <SISheogorath> comeUpWithItLater: you should have two networks. One for your proxy and one for your API/backend stuff of the service. Both should be overlay networks. The API service should be in both, the database only in the backend network
[2017-10-12 06:36:06] <masaeedu> killerspaz: Use an env var
[2017-10-12 06:52:22] <killerspaz> well, thing is, that is only for run time, not build time
[2017-10-12 06:52:36] <killerspaz> i ended up using an arg, and having windows-only build instructions
[2017-10-12 08:20:56] <carlosjgp> killerspaz: Use--build-argthat maps to anENVvariable inside theDockerfiledocker build --build-arg MY_IP=10.0.0.1 [<-CODE->] 
[2017-10-12 08:21:13] <killerspaz> that's what i did
[2017-10-12 09:14:17] <bjonen> Hey guys, quick question. When it says milestone1.13.0in this issue ( [<-ISSUE->] ). How does that relate to the current version 17.09 of the commuinity edition? I would love to know when this PR is expected to be contained in a release ( [<-LINK->] because we are seeing a lot ofdriver "devicemapper" failed to remove root filesystem.
[2017-10-12 20:45:06] <ju2wheels> hi all, is there a way to figure out what the default command was for an image (I didnt make it and dont have access to the Dockerfile). It wont start but I can get in by explicitly running bash. I want to know what it would normally run.
[2017-10-12 20:45:52] <ju2wheels> i dont see anything in the inspect output either
[2017-10-12 20:49:51] <SISheogorath> ju2wheels: docker history <image>
[2017-10-12 20:52:06] <ju2wheels> im good, was reading too quickly, it is in the inspect
[2017-10-13 07:17:17] <comeUpWithItLater> Hi Sheogorath,  are you there@SISheogorath
[2017-10-13 07:17:22] <comeUpWithItLater> help
[2017-10-13 07:17:34] <comeUpWithItLater>  [<-LINK->] 
[2017-10-13 07:18:45] <comeUpWithItLater> adding theadminnetwork to   adminx01 service   will    cause  Gateway Timeout.
[2017-10-13 07:21:32] <comeUpWithItLater> why?
[2017-10-13 08:01:51] <SISheogorath> Check the traefik logs, usually it points out why. Also try to ping the traefik container from inside your admin Container
[2017-10-13 08:01:52] <comeUpWithItLater> dig the docs and found :
[2017-10-13 08:02:01] <comeUpWithItLater>  [<-LINK->] 
[2017-10-13 08:02:29] <SISheogorath> Ah yes, this setting should help
[2017-10-13 08:05:41] <comeUpWithItLater> it works . thank you for your help all these days
[2017-10-13 08:24:16] <SISheogorath> You're welcome
[2017-10-13 21:38:22] <Scapal> What is the best way to update a service image using a tag like latest ?Currently I do a pull on a manager node, get the image digest and do the service update --image with that digest as tag.Is there a better, more direct approach to do the same ?
[2017-10-13 21:49:02] <basz> I have the same question as Pascal
[2017-10-13 22:01:21] <Scapal> basz: I'm considering doing a tag rotation when doing continuous deployment:push my_image:latest\nssh on the swarm manager:\ndocker tag my_image:previous-1 my_image:previous-2\ndocker tag my_image:latest my_image:previous-1\ndocker pull my_image:latest\nfetch digest of my_image:latest\ndocker service update --image my_image@digest --with-registry-auth my-service
[2017-10-13 22:01:58] <Scapal> Doing so would enable me to do a rollback easily
[2017-10-14 19:21:16] <clem109> Hi, I am new to docker and was wondering if someone could help me? I\'m trying to run an express app in a docker container for development. I\'ve tried with various nodejs projects and I can get it to build and run. However, when it comes to editing code the changes are not reflected when I do "docker exec container bash" I can see that the files are not matching those in my directory when I make additional changes. Here is a simple version of what I\'m trying to do (feel free to clone): [<-LINK->] 
[2017-10-14 19:22:16] <clem109> When I do this on a php project it works fine and I can make changes and they are reflected, for example this project: [<-LINK->] 
[2017-10-14 19:22:56] <clem109> I'm running the latest versions of docker on a mac 10.12.6
[2017-10-14 19:32:44] <clem109> actually figured it out
[2017-10-14 19:33:00] <clem109> nodemon is needed for watching filechanges
[2017-10-15 11:59:14] <SISheogorath> Yes
[2017-10-15 12:00:47] <SISheogorath> On any other binary that watches for file changes and restarts the node process or re-require the changed files
[2017-10-15 12:01:05] <SISheogorath> Usually nodemon is used for this because it brings in some additional features for debugging
[2017-10-16 08:48:34] <comeUpWithItLater>  [<-LINK->] 
[2017-10-16 08:49:47] <comeUpWithItLater> looks like the ports marked in green wasn't used by the config in red. so why map the green ports to host machine?
[2017-10-16 13:41:40] <MonXBZH> Hello ! o/
[2017-10-16 13:41:46] <MonXBZH> I've got a question
[2017-10-16 13:42:46] <MonXBZH> When I use swarm on Docker, what happen when I deploy an application as service with his own embeded database?
[2017-10-16 13:42:57] <MonXBZH> I'm thinking about TeamSpeak 3 server
[2017-10-16 13:43:54] <MonXBZH> If I deploy a TS3 server as service on a swarm with 1 manager and 2 workers. The database gonna be synch between workers and managers? Or I must copy manualy database between each instanc ?
[2017-10-16 13:43:59] <MonXBZH> instance*
[2017-10-16 13:44:02] <MonXBZH> Thx!
[2017-10-17 01:13:03] <zhongdj> AyushyaChitransh: that would help. but I do not know how via docker-compose cli
[2017-10-17 01:59:32] <AyushyaChitransh> zhongdj: Have you tried things described in [<-LINK->] ?
[2017-10-17 04:26:18] <comeUpWithItLater>  [<-LINK->] 
[2017-10-17 04:26:53] <comeUpWithItLater> following  the  docs at [<-LINK->] , but  doesn't seems to work
[2017-10-17 04:27:09] <comeUpWithItLater> Y  ?
[2017-10-17 07:51:38] <SISheogorath> comeUpWithItLater: this is nothing docker supports officially. According to the article you shared that\'s a feature of "DCHQ".
[2017-10-17 09:01:18] <VQuery> Hi Guys,i am using docker toolbox windowsconfigured docker and jenkins in same local machine and its working fine in below manner.in jenkins implemented yet another plugin and added docker api url tcp://192.168.99.100:2376 and usedjenkinsci/slave.docker slave is creating every time job triggering in jenkins .Now we moved jenkins server to cloud but docker in local machine .How to access docker in this case?how to create docker public API url ?
[2017-10-17 17:32:41] <IceS2> Hey guys, is there a way to usedocker service createto create a service if it isn't present or do nothing if the service is already active?
[2017-10-17 18:47:18] <imaia> Hey folks; Just found this syntax for docker-compose the other day: <<: *webapp
[2017-10-17 18:47:30] <imaia> it allows me to reuse a service build inside docker-compose
[2017-10-17 18:47:44] <imaia> (webapp is a service in my docker-compose, by the way)
[2017-10-17 18:47:48] <imaia> is this documented somewhere?
[2017-10-17 19:01:31] <SISheogorath> imaia: I'm not sure what kind of syntax you are talking about
[2017-10-17 19:03:34] <imaia> SISheogorath: you make a alias for your service, like this: myservice: &somename
[2017-10-17 19:03:50] <imaia> theh, references it like this: <<: *somename
[2017-10-17 19:04:07] <imaia> you can see a full example at [<-LINK->] 
[2017-10-17 19:10:27] <SISheogorath> There is: [<-ISSUE->] 
[2017-10-17 19:11:33] <SISheogorath> It says it's nothing docker specific. It's yaml reference syntax
[2017-10-17 19:12:18] <SISheogorath>  [<-LINK->] 
[2017-10-17 20:00:43] <imaia> Thanks
[2017-10-17 20:01:00] <imaia> Also, some people are saying swarm has its days counted
[2017-10-17 20:01:05] <imaia> anyone heard of that?
[2017-10-17 20:54:50] <masaeedu> who are "some people"
[2017-10-17 22:30:25] <SISheogorath> On the DockerCon EU there was K8s introduced as natively supported alternative to Swarm. But I don't think it means that swarm dies.
[2017-10-17 22:30:41] <SISheogorath> K8s is way to hard for small companies
[2017-10-17 22:31:13] <necrose99> quemu in docker extensions native would be a bleeeping godsend
[2017-10-18 02:28:48] <AyushyaChitransh> Some [<-LINK->] indicate that docker-compose would be deprecated over stack on docker swarm.
[2017-10-18 07:09:00] <SISheogorath> Right now docker-compose is not deprecated and as far as I know there are no plans for this. And even when it would be deprecated, if it's deprecated likelinksit's supported for more than a year afterwards
[2017-10-18 07:10:30] <SISheogorath> Also keep in mind that there are alternatives that use it as library like Ansible'sdocker_servicemodule, so we don't need to be worried that something will stop working
[2017-10-18 07:15:58] <AyushyaChitransh> a docker run command gives error.docker: Error response from daemon: authorization denied
[2017-10-18 08:09:49] <comeUpWithItLater>  [<-LINK->] 
[2017-10-18 08:10:42] <comeUpWithItLater> both  image & build here!  what's that used for ?
[2017-10-18 08:10:46] <comeUpWithItLater>  [<-LINK->] 
[2017-10-18 08:17:41] <SISheogorath> comeUpWithItLater: the build statement says that the image will be build if not exist
[2017-10-18 08:18:23] <SISheogorath> The image statement specifies the tagging for the image that is the result of the build process or used in general when it already exists
[2017-10-18 08:33:10] <comeUpWithItLater> got it , thanks
[2017-10-18 08:33:19] <comeUpWithItLater>  [<-LINK->] 
[2017-10-18 08:33:40] <comeUpWithItLater> following the docs : [<-LINK->] 
[2017-10-18 08:34:40] <comeUpWithItLater> I remember  you told me about the use ofcommand, but it doesn't seems to work this time
[2017-10-18 08:34:51] <comeUpWithItLater> SISheogorath: 
[2017-10-18 09:30:23] <SISheogorath> When I check their script I see this line: [<-LINK->] 
[2017-10-18 09:31:43] <SISheogorath> It breaks the wholecommand:part since it uses"$@"instead of$@and this way pass all arguments that were passed to the script, as one argument to their tool. That again, breaks the whole argument parsing
[2017-10-18 09:38:57] <comeUpWithItLater> so what's the  quickest way to get it work?
[2017-10-18 09:39:02] <comeUpWithItLater> though I can create an issue later
[2017-10-18 09:39:34] <SISheogorath> fix it?
[2017-10-18 09:41:06] <comeUpWithItLater> fork -> modify entry script  ->build  an new image ?
[2017-10-18 10:25:02] <SISheogorath> xes and consider to create a pull request
[2017-10-18 11:43:55] <SISheogorath> *yes
[2017-10-18 13:52:21] <BrianAsher> I have a project environment that is setup using docker and docker-compose.  It works great for the dev team.  I am trying to deploy it to AWS ECS using their ecs-cli tool.  AWS has a limit of 10 task definitions, which correlates to 10 containers in docker.  We have more than that because we are using event sourcing and have a container for each projection.  Has anyone ran into this problem? Do you have any suggestions for a way to get around this?
[2017-10-19 00:36:16] <ShionAt> Please support my attempt to change the world of the project, spread it, baptize it [<-LINK->] 
[2017-10-19 03:09:27] <tuan3w>  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2017-10-19 03:13:23] <ShionAt> Who can help me unlock the next push, my account has just been frozen. I can not use my phone to unlock, because our country visit Twitter is illegal.
[2017-10-19 03:14:21] <ShionAt> help
[2017-10-19 10:10:00] <claudiotx7_twitter> Hello guys. Which tool (saas) do you usually use to share credentials and sensitive  within your team? Thanks
[2017-10-19 10:45:26] <ovelindstrom> claudiotx7_twitter: Keepass or LastPass most often. If shared between applications, mostly Zookeeper.
[2017-10-19 10:46:27] <ovelindstrom> claudiotx7_twitter: Some say that Thycotic Secret Server is good, but I have never tried it.
[2017-10-19 15:07:12] <matrixbot> YvesI need container A to be up and running to build container B (A is a caching proxy). Must I really need to put that into 2docker-compose.ymlor can I have that properly done in only one, to keep common definitions at the same place (network, for example)
[2017-10-20 09:29:28] <carlosjgp> matrixbot: You don't have to usedocker-compose. You can run them with justdockerI will recommend to use and external volume (docker volume --help) for the caching in case you want to change the proxy container
[2017-10-20 15:25:51] <ndpratas> Hi, this is a quick one (for those more knowledge than me): Is docker stack the only way to deploy services through an yaml file?
[2017-10-20 15:26:41] <ndpratas> my understanding was that stack was more for like... well... a stack of individual services and not for ONE service itself
[2017-10-20 15:26:56] <ndpratas> say I only want to deploy 1 service (1 container)
[2017-10-20 15:27:10] <ndpratas> do I still have to use docker stack?
[2017-10-20 20:32:46] <imaia> ndpratas:  [<-LINK->] 
[2017-10-20 20:34:52] <imaia> Hey guys, I'm having trouble with the containers ips
[2017-10-20 20:35:06] <imaia> they're conflicting with my network
[2017-10-20 20:35:20] <imaia> whenever my container is up, my network goes down
[2017-10-20 20:35:48] <imaia> I tried editing daemon.json to mend things (make docker-compose create containers in another network, but it is not working)
[2017-10-20 20:35:59] <imaia> did anyone go through that?
[2017-10-20 20:51:22] <dylanscott> not sure if this is a reasonable place to ask this but is there any way with the registry API ( [<-LINK->] ) to retrieve tags for a specific image (identified by digest)?
[2017-10-20 20:51:33] <dylanscott> i only see a way to get all tags for a repo
[2017-10-23 09:24:14] <ndpratas> imaia: Thank you for the link. However I had already checked that and didn't find the answer I was looking for. Fortunately someone over on IRC channel pointed me in the right direction. Turns out stack is the way to go if you want to start services via yaml. I already suspected this, I just wanted someone more knowledge than I am to confirm that. Thank you anyway.
[2017-10-23 11:58:30] <ndpratas> QUICK QUESTION: I'm noticing that whenever i start a new stack (only 1 service) each container gets two ips, one that is common to the service (all containers of the same service have it) and 1 unique to each container itself. Is this by design? Where can I read more about this? How can I change this behavior
[2017-10-23 11:58:32] <ndpratas> ?
[2017-10-23 12:21:36] <carlosjgp> ndpratas:  [<-LINK->] 
[2017-10-23 13:03:50] <Kunepro> Hi, I already have several Docker images in my projects, all working and nice with their dockerfile. My problem is that maintaining the version number is a pain. Is there a UI build on top of the bash or something that can integrate with git repository to help building keeping track of version and desired build environment (pointing to a different dockerfile)?
[2017-10-23 13:05:08] <Kunepro> I would build a simple script, but with million of docker users I can't believe that there isn't already something out there that I just didn't manage to find out
[2017-10-23 13:21:38] <saidiahd> Hi folk ,I installed docker-1.12.6-55.gitc4618fb.el7.x86_64 for  RHEL 7 in a nfs volume, when I try to do docker-compoe up –d i get this error:Cannot create container for service sol_container: SELinux relabeling of /mntnfs/SOL_NAME/docker/volumes/SOL_NAME-data/_data is not allowed: "operation not supported"any help plz
[2017-10-23 13:32:11] <ndpratas> saidiahd: trysudo setenforce 0
[2017-10-23 13:32:33] <ndpratas> your selinux is somehow blocking
[2017-10-23 13:33:44] <ndpratas> you should however keep selinux on, so if it works, then makesudo setenforce 1and read journalctl to see how you can add the exception to selinux
[2017-10-23 13:34:23] <saidiahd> sestatusSELinux status:                 enabledSELinuxfs mount:                /sys/fs/selinuxSELinux root directory:         /etc/selinuxLoaded policy name:             targetedCurrent mode:                   permissiveMode from config file:          permissivePolicy MLS status:              enabledPolicy deny_unknown status:     allowedMax kernel policy version:      28
[2017-10-23 13:48:35] <saidiahd> it's permissive my SeLinux
[2017-10-24 05:56:22] <akshay951228> how to add Expose in existing Dockerfile
[2017-10-24 08:14:02] <ndpratas> akshay951228: edit Dockerfile and addEXPOSE 8080no?
[2017-10-24 08:50:22] <akshay951228> ndpratas: I want write DockerFile from existing docker .
[2017-10-24 08:52:06] <akshay951228> In that existing DockerFile there IsExpose.So I want add new port In new Extended DockerFile.How can I do that?
[2017-10-24 10:23:40] <ndpratas> @akshay951228 I believe you can just pass a -p ####:#### to publish a new port in run time without the need to expose it...however if you want to buid a new image from that original image you can just do something like: [<-CODE->] Then you can just pass a -P (capital p) to publish on the host every port that is being exposed by the container
[2017-10-24 11:20:11] <LY3DM> that's amazing
[2017-10-24 11:20:18] <LY3DM> thank u boddy
[2017-10-24 12:23:09] <Fl317> Hey, I'm quite a docker and linux noob and have some stupid questions. anyone bored and is willing to help me?
[2017-10-24 13:25:06] <ndpratas> Fl317: go ahead
[2017-10-24 13:31:42] <Fl317> ndpratas: i found the solution, my error came from my distribution
[2017-10-24 14:31:21] <akshay951228> what is the use of EXPOSE in Dockerfile
[2017-10-24 14:38:45] <ndpratas>  [<-CODE->] 
[2017-10-24 14:38:59] <ndpratas>  [<-LINK->] 
[2017-10-24 14:41:01] <akshay951228> ndpratas: thanks 
[2017-10-24 14:47:34] <akshay951228> ndpratas: If I started the container with some port like 30303 but I didn't expose the port. will I'm able to publish the port in host or not?
[2017-10-24 15:16:48] <sujaypillai> if you are on linux try the iptables command -iptables -t nat -A DOCKER -p tcp --dport 30300 -j DNAT --to-destination <yourContainerIP>:30303
[2017-10-24 15:45:21] <ndpratas> akshay951228: YES. I'm pretty sure you will as long as you pass the -p (lower capital) ####:####
[2017-10-24 16:42:23] <akshay951228> ndpratas: thanks once again.
[2017-10-25 01:31:32] <MacroLove> Hi all, I build an image with exist name in my docker, will this new image overwrite the old one?
[2017-10-25 08:35:22] <ndpratas> @MacroLoveImages in Docker don\'t have a name, they have tags.A tag is a reference to an image. Multiple tags may refer to the same image.If you reassign a tag that is already used, then the original image will lose the tag, but will continue to exist (it will still be accessible by its image ID, and other tags might refer to it). https://stackoverflow.com/questions/26401649/building-a-new-docker-image-with-the-same-name-as-an-existing-onesSo when you do "docker build -t my_image" the image will not be overwritten BUT your tag "my_image" will to the newly created image. So when you do "docker run my_image" your new image will be spun up.
[2017-10-25 08:36:12] <aldarund> Hi all. Can someone help me with port sharing on windows for mongodb? Basically the problem is that port sharing works if i use docker run but doesnt work if i use same settings via docker-compose. And it confuse me as hell and i even dont know where to look at anymore.  Here is all details [<-LINK->] 
[2017-10-25 08:46:50] <ndpratas> aldarund: can you show us your yaml? are you publishing the port in yaml?
[2017-10-25 08:47:37] <aldarund> ndpratas: it is on that post on SO. But here it is too: [<-CODE->] 
[2017-10-25 08:55:43] <ndpratas> aldarund: Oh I didn\'t realize the port on SO was yours, sorry. Your yaml is fine I guess. I think (not sure) the problem is you\'re trying to connect to the localhost (127.0.0.1) and not the interface of the host itself. Try doing a "netstat -aon" on windows command line with the container up and see if the 27017 port it listening and at which ip
[2017-10-25 08:56:33] <ndpratas> My guess is if you do a "telnet yourhostname 27017" instead of "telnet localhost 27017" it will work
[2017-10-25 08:59:18] <carlosjgp> aldarund: Port sharing? you mean port mapping? Which error reportsdocker-compose? Do you have any other container running with a port mapped to the same port (27017)? as@ndpratassuggested usenetstatto find it out ordocker ps
[2017-10-25 08:59:27] <aldarund> ndpratas: my host for docker is localhost e.g. 127.0.0.1 . Other port sharing works fine e.g. nginx, postgresql. It only doesnt work for mongo-db via docker-compose. It works for mongodb via docker. And it works for everything else via docker-compose. netstat show as expected e.g.TCP    0.0.0.0:27017          0.0.0.0:0              LISTENING       25132
[2017-10-25 09:00:20] <aldarund> carlosjgp: yes port mapping. No i dont have any other containers and i tried to map to different host port same result. No error in docker-compose
[2017-10-25 09:00:46] <ndpratas> well yeah, if it's 0.0.0.0 it should work on localhost as well as your hostname...
[2017-10-25 09:01:07] <carlosjgp> aldarund: So why do you think/know it's not working ondocker-compose?
[2017-10-25 09:01:48] <carlosjgp> Can you post how do you run Mongo withdocker run?
[2017-10-25 09:02:08] <aldarund> carlosjgp: because of error when i connect to it [<-CODE->] 
[2017-10-25 09:02:36] <aldarund> carlosjgp: docker run --name my_mongox6 -d -p 27017:27017 mongo
[2017-10-25 09:04:11] <carlosjgp> So it's not that you can't connect to Mongo, it's that an error is throw after connecting (sorry I'm not a Mongo user)
[2017-10-25 09:05:00] <aldarund> but it doesnt throw any errors when i run it via docker without compose. same image. same settings
[2017-10-25 09:05:07] <aldarund> connect works fine
[2017-10-25 09:15:53] <ndpratas> aldarund: can you please do a telnet to that port and see if you can indeed connect to it?
[2017-10-25 09:16:02] <ndpratas> because if you can, the problem must be something else
[2017-10-25 09:18:57] <aldarund> ndpratas: it writes Connecting To localhost... and then clear screen and in command line again and thats it.
[2017-10-25 09:19:24] <ndpratas> if it clears it means it connected
[2017-10-25 09:19:43] <aldarund> ndpratas: its in windows command line again
[2017-10-25 09:20:51] <ndpratas> cat you do "docker exec your_container_running cat /var/log/mongodb/mongod.log" ?
[2017-10-25 09:21:30] <ndpratas> can*
[2017-10-25 09:22:20] <aldarund> ndpratas: cat: /var/log/mongodb/mongod.log: No such file or directorythe logs are outputted into docker logs .  But there nothing in it. Last record is waiting for connections on port 27017
[2017-10-25 09:25:07] <aldarund> even if i set db.setLogLevel(5) there nothing in mongo logs
[2017-10-25 09:25:23] <aldarund> *nothing about failed connect attempts.
[2017-10-25 10:06:14] <aldarund> I see a difference in docker ps when run via compose vs when run via docker. [<-LINK->] ( 27017/tcp, 0.0.0.0:27017->21017/tcp ) vs [<-LINK->] (0.0.0.0:27017->21017/tcp)I guess that the cause of error. But no idea why this happens.
[2017-10-25 12:03:43] <aldarund> and this behavior is exactly same on linux host and its reproducible.
[2017-10-25 12:13:31] <carlosjgp> aldarund: Could be an error related to the container, or thedocker-composeordockeryou are using.I'll recommend updating both and if it doesn't work raise a GitHub ticket for the Mongo image, I use lots of other containers withdocker runanddocker-composeand they behave in the same wayTry to update your Mongo image toodocker pull mongo:latest
[2017-10-25 12:14:39] <aldarund> carlosjgp: its latest version. and i asked my friend on linux try it. And he have same behaviour with his docker and docker-compose
[2017-10-25 12:20:09] <carlosjgp> aldarund: So, in my opinion, that container is "broken" try an older version and see how it works
[2017-10-25 12:21:57] <LY3DM> i see u need to download latest version of the container
[2017-10-25 12:24:29] <aldarund> carlosjgp: oldest version ( 3.0 ) - same behaviour
[2017-10-25 12:24:36] <aldarund> LY3DM: it is latest version
[2017-10-25 12:30:54] <carlosjgp> aldarund: Maybe this will help? [<-LINK->] I don't think this is a Docker issue. Mongo may need special configuration to run on containers :/
[2017-10-25 12:31:38] <aldarund> carlosjgp: doesnt help. and it work if run via docker itself without compose.
[2017-10-25 15:28:45] <amanagarwal2189> Hello folks.. has anyone ecountered a problem while backing up RHEL when docker is installed on it?
[2017-10-25 16:23:17] <SISheogorath> RHEL ships an own docker version. Do you use it or the one by Docker Inc.?
[2017-10-26 02:46:42] <power-man> hi,I have a question . Started EurekaApplication in 314.2 seconds (JVM running for 321.902) when I use docker
[2017-10-26 02:47:35] <power-man> It is too slow
[2017-10-26 04:18:03] <SISheogorath> There is no question
[2017-10-26 05:16:32] <power-man> :: Spring Boot ::        (v1.5.6.RELEASE)2017-10-26 02:40:46.003  INFO 1 --- [           main] c.c.s.SpringbootGradleDemoApplication    : Starting SpringbootGradleDemoApplication on faab00b7d111 with PID 1 (/webdemo-0.0.1.jar started by root in /)2017-10-26 02:40:46.114  INFO 1 --- [           main] c.c.s.SpringbootGradleDemoApplication    : No active profile set, falling back to default profiles: default2017-10-26 02:40:48.891  INFO 1 --- [           main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4ee285c6: startup date [Thu Oct 26 02:40:48 UTC 2017]; root of context hierarchy2017-10-26 02:41:31.604  INFO 1 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!2017-10-26 02:42:48.262  INFO 1 --- [           main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)2017-10-26 02:42:52.510  INFO 1 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]2017-10-26 02:42:52.628  INFO 1 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.162017-10-26 02:42:59.189  INFO 1 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext2017-10-26 02:42:59.284  INFO 1 --- [ost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 130393 ms2017-10-26 02:43:04.351  INFO 1 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: \'dispatcherServlet\' to [/]2017-10-26 02:43:04.660  INFO 1 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: \'characterEncodingFilter\' to: [/]2017-10-26 02:43:04.740  INFO 1 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: \'hiddenHttpMethodFilter\' to: [/]2017-10-26 02:43:04.740  INFO 1 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: \'httpPutFormContentFilter\' to: [/]2017-10-26 02:43:04.741  INFO 1 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: \'requestContextFilter\' to: [/]2017-10-26 02:43:24.745  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4ee285c6: startup date [Thu Oct 26 02:40:48 UTC 2017]; root of context hierarchy2017-10-26 02:44:11.954  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/user],methods=[POST],produces=[application/json;charset=utf-8]}" onto public java.lang.String com.css.springbootgradledemo.user.UserController.addUser(java.lang.String)2017-10-26 02:44:12.164  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/user/{id}],methods=[GET],produces=[application/json;charset=utf-8]}" onto public java.lang.Object com.css.springbootgradledemo.user.UserController.getUser(java.lang.Long)2017-10-26 02:44:12.509  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)2017-10-26 02:44:12.566  INFO 1 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)2017-10-26 02:44:14.289  INFO 1 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2017-10-26 02:44:14.290
[2017-10-26 05:17:02] <power-man> look at this :  2017-10-26 02:42:59.284 INFO 1 --- [ost-startStop-1] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 130393 ms
[2017-10-26 05:17:14] <power-man> 130393 ms
[2017-10-26 05:18:18] <power-man> my another srping boot   use the same docker
[2017-10-26 05:18:25] <power-man> 2017-10-26 02:21:00.566  INFO 15 --- [           main] c.c.k.Kylincloud2WebApplication          : Starting Kylincloud2WebApplication on 8451bc8ebea7 with PID 15 (/opt/kylincloud2/kylincloud2-web-0.0.10.jar started by root in /)2017-10-26 02:21:00.574  INFO 15 --- [           main] c.c.k.Kylincloud2WebApplication          : The following profiles are active: docker2017-10-26 02:21:00.971  INFO 15 --- [           main] ationConfigEmbeddedWebApplicationContext : Refreshingorg.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@ee7d9f1: startup date [Thu Oct 26 02:21:00 UTC 2017]; root of context hierarchy2017-10-26 02:21:05.596  INFO 15 --- [           main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8020 (http)2017-10-26 02:21:05.679  INFO 15 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]2017-10-26 02:21:05.682  INFO 15 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.162017-10-26 02:21:06.009  INFO 15 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext2017-10-26 02:21:06.010  INFO 15 --- [ost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 5047 ms
[2017-10-26 05:18:44] <power-man> it just takes 5047 ms
[2017-10-26 05:19:36] <power-man> I don't konw why this result shows so different
[2017-10-26 05:21:07] <power-man> Does someone know  how  to fix that ?
[2017-10-26 05:25:27] <power-man> I use springboot ,but my service shows different when start ,some fast ,some slow ,the slowest takes 5 mins
[2017-10-26 05:26:07] <power-man> when my the slowest service run without docker ,it just takes 30 seconds
[2017-10-26 05:29:49] <power-man> Docker version 1.10.3, build 20f81dd
[2017-10-26 05:40:10] <power-man> Containers: 47Running: 2Paused: 0Stopped: 45Images: 383Server Version: 1.10.3Storage Driver: aufsRoot Dir: /var/lib/docker/aufsBacking Filesystem: extfsDirs: 463Dirperm1 Supported: trueExecution Driver: native-0.2Logging Driver: json-filePlugins:Volume: localNetwork: bridge null hostKernel Version: 4.4.13-20170224.kylin.5.YUN+Operating System: Kylin 4.0-2SP1OSType: linuxArchitecture: aarch64CPUs: 16Total Memory: 31.4 GiBName: master1ID: GVWM:BVSZ:4QZL:B2U4:NVCJ:ORLB:7GJA:ZPDY:HMRO:YI7O:CMR2:4YIZWARNING: No swap limit support
[2017-10-26 06:41:11] <SISheogorath> power-man: Hint: Docker version 1.10 is outdated as hell. Please update to the current stable.
[2017-10-26 12:24:08] <Chris-Devine> hi, i am trying to use docker-compose up but find i can not connect to the exposed port using "hostname:port" like i could when i used docker run.  I cant find on google what am doing wrong, can sombody advise me please. I am using windows containers [<-CODE->] 
[2017-10-26 12:54:52] <przemolb> Hello all,
[2017-10-26 12:55:14] <przemolb> on ubuntu with docker installed I am trying to build the docker image (docker build ...)
[2017-10-26 12:55:32] <przemolb> as non-root user and get the following error:
[2017-10-26 12:55:42] <przemolb>  [<-CODE->] 
[2017-10-26 12:56:48] <przemolb> indeed /var/lib/docker is owned by root:
[2017-10-26 12:57:00] <przemolb>  [<-CODE->] 
[2017-10-26 12:57:25] <przemolb> should I build it as root user (would like to avoid it ...) ?
[2017-10-26 13:00:18] <przemolb> Docker Version:      17.10.0-ce
[2017-10-26 13:13:43] <przemolb> sorry - my fault - it was something else (missing additional file).
[2017-10-26 18:08:41] <skarred14> anyone who can answer this will be immensely helpful
[2017-10-26 18:12:07] <skarred14> tried stopping & removing containers, rebuilding the images but i cant seem to get rid of the following error:Error response from daemon: driver failed programming external connectivity on endpoint nginx-proxy (669659d666e6b6164716c6009cc1f1b413f2130e8d6238db341769bce23620fa): Error starting userland proxy
[2017-10-26 18:12:11] <skarred14> any suggestions?
[2017-10-26 19:43:05] <creyke> Chris-Devine: i am seeing the same
[2017-10-26 19:43:15] <creyke> what version of docker for win are you using?
[2017-10-26 19:43:42] <creyke> <--- Version 17.10.0-ce-win36 (13788)    ... using linux containers
[2017-10-27 07:43:12] <wormen> tell mehow in the container to get the data of the host machine? (cpu, memory, network traffic)
[2017-10-27 09:22:16] <SISheogorath> wormen: by default you don't get them. But if you really need them you can mount the /proc directory as read only and read them there
[2017-10-27 09:22:58] <SISheogorath> Keep in mind that this will expose other things, too
[2017-10-27 10:02:49] <vwyuheng> 北京 有换工作的吗
[2017-10-27 10:03:36] <comeUpWithItLater> 哦， 这里不说中文的吧 ！
[2017-10-27 11:02:20] <przemolb> Did anyone deployed ELK stack as docker containers ? How about its stability ? Do you like the way it work ?
[2017-10-27 20:26:42] <chris453> hi i am running a docker remotely using tcp on port  2376
[2017-10-27 20:27:32] <chris453> but i can't seem to get my host to see the remote host at 2376 what port is it trying to reach the remote docker host at? i set the firewall to let port 2376 to be let in
[2017-10-27 20:27:41] <chris453> but doesn't seem to work . . this will for sure work if i turn off the firewall though
[2017-10-27 20:30:25] <chris453> what port would i have to open ?this is the docker c ommand im usingdocker -H tcp://10.10.26.62:2376 run hello-world
[2017-10-28 10:45:43] <chris453> i seem to be getting this errordocker0: iptables: No chain/target/match by that name on my host
[2017-10-29 12:22:26] <dykyi-roman> hi
[2017-10-29 12:22:55] <dykyi-roman> how create DB after run mysql container in docker-compose. I can add*.sh script or  *.sql scriptfor run in docker-compose.yaml or I must create new image inherited from base mysql container and write my code inside container
[2017-10-29 14:14:15] <jimschubert> dykyi-roman: you'd have to add scripts into a derived Dockerfile.  For an example check out [<-LINK->] 
[2017-10-29 14:18:21] <jimschubert> The database environment variable ensures the DB is created. That and the user/pass could be moved to docker-compose.yaml. You could forgo the custom file by mapping a local volume with structured scripts to the appropriate location in the container. Just remember that scripts execute in bash glob order, which is alph
[2017-10-29 14:18:47] <jimschubert> ... ascending. so I like to prefix with numbers.
[2017-10-29 14:27:29] <dykyi-roman> jimschubert: thanks and if i dont want write Dockerfile and use docker-compose.yml, Did you know docker-compose have command for copy and run sql script like in you github example
[2017-10-29 14:28:13] <jimschubert> d
[2017-10-29 14:29:11] <jimschubert> dykyi-roman: you can use the volume command and mount your scripts to /docker-entrypoint-initdb.d
[2017-10-29 14:29:41] <dykyi-roman> i am done, but script not automatic run
[2017-10-29 14:30:11] <dykyi-roman> volumes: [<-CODE->] 
[2017-10-29 14:30:25] <dykyi-roman> data -> mysql.sql
[2017-10-29 14:32:46] <jimschubert> Hm. Check your .dockerignore to make sure "data" isn\'t ignored. You can exec into the container and inspect the directory (easiest via Kitematic).
[2017-10-29 14:34:13] <jimschubert> Also, you may want to check the base image you're using to make sure the directory is correct. my base, I think it's 5.7.
[2017-10-29 14:36:18] <jimschubert> I just verified the 8.0 image is the same location.
[2017-10-29 14:37:02] <dykyi-roman> i am not have dockerignore file
[2017-10-29 14:37:25] <dykyi-roman> i am check file is copy and exist in the folder
[2017-10-29 14:37:38] <dykyi-roman> strange (
[2017-10-29 14:38:04] <jimschubert> Maybe kill that container and recreate it?
[2017-10-29 14:39:25] <dykyi-roman> ok i try
[2017-10-29 14:39:46] <jimschubert> I used that method from a compose file almost a year ago, but my team moved to using flywaydb and running different scripts per  "environment"
[2017-10-29 14:40:22] <dykyi-roman> understand)
[2017-10-29 14:42:10] <jimschubert> docker logs should show echo statements when it attempts to run your script. Good luck, I hope I helped a bit. ;)
[2017-10-29 14:46:13] <dykyi-roman> jimschubert: yes thanks
[2017-10-29 14:46:42] <dykyi-roman> logs is clear. Not found information about start run my script
[2017-10-29 15:45:20] <dykyi-roman> jimschubert: kill all container ad images and run again - and work)))) fuck
[2017-10-29 15:45:50] <dykyi-roman> cash ?
[2017-10-29 15:48:18] <jimschubert> probably. docker-compose doesn't rebuild by default. I think there's a --recreate option or something. If you kill the running container via Kitematic, it'll often resolve issues. I created a startup script for my composed network that traps EXIT and tears down the created network. That seems to work pretty nicely for my team.
[2017-10-30 08:50:27] <dykyi-roman> jimschubert: ok thnaks
[2017-10-30 08:53:08] <dykyi-roman> somebody works with nginx-proxy? now i have one site him work on the nging, How I can add multi-website config to my docker-compose.yml
[2017-10-30 10:03:30] <BouchaaraAdil> Hey roman, can you please delete all you containers, volumes, networks .. using 'docker system prune --volumes -f'
[2017-10-30 10:03:46] <BouchaaraAdil> then run again
[2017-10-30 14:54:11] <morpheyesh> I am having an issue with docker networking when I am trying to access my cassandra container from my application container.this is my compose file [<-CODE->] 
[2017-10-30 14:56:36] <morpheyesh> The issue is, if i run cassandra with--network testnetworkand then specify thenetworks:default:externalin compose, change the environment in app fromcassandrato the inspected ip. It works.
[2017-10-30 14:57:02] <morpheyesh> Not sure  why the networking isnt getting picked up in compose?
[2017-10-30 19:10:19] <rightisleft> Is docker's TLS support only for the docker engine, or is it designed to also be utilized by app-land code ?
[2017-10-30 19:11:43] <rightisleft> IE: If i have 2 containers in my swarm, can i access the certs from docker to verify identities?
[2017-10-30 21:16:52] <SISheogorath> rightisleft: no, you can't access the certificates from docker. But you can use encrypted networking in swarm to make sure it's nothing weird around
[2017-10-31 10:39:59] <sovtechshaun> Good day dockernauts - I’m getting auth errors whenever I try to pull an image from the store. I’m singed in on docker and Kitematic, and keep being told to go forth and multiply :(
[2017-10-31 10:40:27] <sovtechshaun> I’m not sure if this is the right room to ask this question in.
[2017-10-31 11:15:24] <SISheogorath> can you provide the command you used?
[2017-10-31 11:20:02] <papaiatis> Hi guys. Duringdocker buildI'm creating an image that runs an Angular application.  During the build process, I run the unit tests as well which creates a report (XML file) inside the container. How can I extract this file afterdocker buildfinishes?
[2017-10-31 11:33:02] <SISheogorath> papaiatis: you don't. the unit tests should run outside of docker build and show if you application is broken or not. Testing during a docker build isn't very useful
[2017-10-31 11:50:15] <papaiatis> SISheogorath: Yeah, I didn\'t feel right at the first place. So what do you mean by "run outside" ?
[2017-10-31 11:51:48] <SISheogorath> You should either have a base image and run the unit tests usingdocker runor you should run them in general outside of docker. I would recommend running them usingdocker runduring your CI process
[2017-10-31 11:58:49] <papaiatis> thank you
[2017-10-31 12:00:55] <papaiatis> ... and if I use your suggestion then I can attach a volume to the container where the report is generated, which I can access outside of the container
[2017-10-31 12:25:13] <SISheogorath> exactly
[2017-10-31 12:27:06] <SISheogorath> I currently use a 3 image setup for these things. A base image with the production dependencies, A dev image which includes all build and testing tools and the production image which uses multi-staged builds and the dev image to build the production setup based on the base image
[2017-10-31 12:35:11] <papaiatis> that sounds complicated
[2017-10-31 12:40:35] <SISheogorath> depending on what you are doing it's needed
[2017-11-01 05:26:02] <VQuery> initially docker machine creating with this 192.168.99.100:2376 API url but i want to access this globally ,do we need to generate any unique IP for our docker machine?
[2017-11-01 05:27:43] <VQuery> how to create remote docker API URL?
[2017-11-01 08:09:31] <PixellUp> Let's say I have docker image with version 1.0 pulled into the machine and I update that image with 1.1 version and push it into docker hub.  Does next time I start docker container with docker run will automatically check and download newly 1.1 version of the image or I must pull the latest version of the image manually?
[2017-11-01 08:19:07] <comeUpWithItLater> anyone using traefik ?
[2017-11-01 08:19:30] <comeUpWithItLater>  [<-LINK->] 
[2017-11-01 08:20:02] <comeUpWithItLater> how to convert config options in * .toml into  docker command option?
[2017-11-01 09:41:32] <comeUpWithItLater>  [<-LINK->] 
[2017-11-01 09:41:40] <comeUpWithItLater> this doesn't seem to work
[2017-11-01 10:16:27] <radojesrb> hey people can anyone assist me with this error
[2017-11-01 10:16:38] <radojesrb>  [<-LINK->] 
[2017-11-01 10:17:43] <radojesrb> this is how my docker-compose.yml looks like
[2017-11-01 10:17:52] <radojesrb>  [<-LINK->] 
[2017-11-01 10:26:24] <jdelStrother> docker-compose appears to use a different build cache that just regulardocker build.  Is that expected?  I'm struggling to find much about it on google
[2017-11-01 10:27:54] <jdelStrother> It's partly irritating due to building things twice, but also I was surprised thatdocker build; docker-compose updidn't boot up the newly built image, but instead booted the version thatdocker-compose up --buildlast built
[2017-11-01 11:15:00] <carlosjgp> jdelStrother: it shouldn't since, as far as I know,docker-composeis a python library that comunicates with your docker client (see [<-LINK->] )
[2017-11-01 11:16:41] <jdelStrother> hm. [<-ISSUE->] 
[2017-11-01 11:19:45] <carlosjgp> They are using a really old version of docker and docker-compose. And bear in mind that there are commands that can't be cached likeCOPYorADD [<-LINK->] 
[2017-11-01 11:28:30] <jdelStrother> Yeah, it's not that.  Here's the start of my Dockerfile - [<-LINK->] .    If I rundocker buildthendocker-compose up --build, it goes through the whole apt-get process twice
[2017-11-01 11:39:03] <carlosjgp> jdelStrother: but that makes sense (for me)... the packages may have changed. If you want to cache theapt-get installcommand I will suggest you to build your own ubuntu\\debian base image and then install ruby in another image
[2017-11-01 11:40:52] <jdelStrother> carlosjgp: I don't think that's the way docker caching works.   It assumes that the results of a given command are idempotent, it doesn't know anything about whether packages may have changed.
[2017-11-01 11:41:24] <jdelStrother> Otherwisedocker build && docker buildwould run apt-get twice, but instead the second version uses the cache from the first
[2017-11-01 11:43:58] <carlosjgp> You are right... docker cache looks only to theRUNcommand string... I will suggest to investigate a little bit more aboutdocker-composeand the--no-cache. You can rundocker-compose --verboseto see which commands are been sent to your docker client
[2017-11-01 11:54:53] <jdelStrother> thanks, I'll take a look
[2017-11-01 17:40:14] <rightisleft> when you are defining ports in docker-compose - its usually host:container - whtat does it mean when it just a single value?
[2017-11-01 17:42:33] <rightisleft> is that just the container port - but not exposed to the host?
[2017-11-01 17:48:16] <przemolb> Hi, is there any way to deploy bunch of docker images but each with different parameters ?
[2017-11-01 18:14:54] <rightisleft> Hrmm - still having a weird issue with haproxy
[2017-11-01 18:14:56] <rightisleft>  [<-LINK->] 
[2017-11-02 06:55:23] <SISheogorath> rightisleft: only the port will expose the port to a random port on the host
[2017-11-02 06:55:43] <SISheogorath> przemolb: docker-compose?
[2017-11-02 11:03:13] <PixellUp> Let's say I have docker image with version 1.0 pulled into the machine and I update that image with 1.1 version and push it into docker hub.  Does next time I start docker container with docker run will automatically check and download newly 1.1 version of the image or I must pull the latest version of the image manually?
[2017-11-02 11:13:21] <SISheogorath> It doesn\'t check for updates this way.latestis simply the default tag. if you want to "update" the online version you have to tag your container as 1.1 and latest and push both
[2017-11-02 11:14:22] <SISheogorath> then you can pull them. But the docker daemon itself won't pull a newer image if an image with the defined name is already in the local image store
[2017-11-02 11:15:00] <SISheogorath> PixellUp: ^
[2017-11-02 11:23:25] <PixellUp> Good to know. Thanks@SISheogorath
[2017-11-02 12:09:25] <SISheogorath> PixellUp: You can have a look at [<-LINK->] which automatically updates and respawns containers
[2017-11-02 13:02:41] <comeUpWithItLater> i have a tomcat  app  depends_on  zoo1:
[2017-11-02 13:02:49] <comeUpWithItLater>  [<-LINK->] 
[2017-11-02 13:03:46] <comeUpWithItLater> but when i deploy it with swarm , depends_on doesn't work  swarm
[2017-11-02 13:03:55] <comeUpWithItLater> any solution ?
[2017-11-02 13:14:03] <comeUpWithItLater> SISheogorath: any  ideas?
[2017-11-02 14:00:27] <InTheCloudDan> is there anyway to get more verbose output on a docker build COPY? It starts running the COPY then I'm gettingunexpected EOF
[2017-11-02 15:28:19] <ImFlog> Hi all, do you know if it is possible to bind a --config to an env var in docker swarm ?
[2017-11-02 15:28:48] <ndpratas> comeUpWithItLater: that yaml sounds good to me... you don't need links anymore though. Are you usingversion: '2'?
[2017-11-02 15:29:04] <ImFlog> The doc statesConfigs can be added or removed from a service at any time, and services can share a config. You can even use configs in conjunction with environment variables or labels, for maximum flexibility.
[2017-11-02 15:30:08] <ImFlog> But I did not found any information about how to do this. Thank you in advance.
[2017-11-02 15:30:36] <ndpratas> ImFlog: What do you mean by "bind a --config to an env var"?
[2017-11-02 15:31:24] <ImFlog> I would like to put my config content in a env var like--config source=my-config,env=MY_ENV
[2017-11-02 15:37:15] <ImFlog> I understand that it is not acceptable for secrets for security reasons but don't understand for config...
[2017-11-02 15:37:33] <ImFlog> any idea about this@ndpratas?
[2017-11-02 15:39:16] <ndpratas> @ImFlog I actually never used config. I was just reading into it. Maybe I'm not the best person to help you. Nonetheless, when you sayput my config content in a env var likeDo you mean an env var of the HOST machine or the container?
[2017-11-02 15:59:05] <ImFlog> Container
[2017-11-02 17:12:14] <carlosjgp> ImFlog: What about Docker secrets? [<-LINK->] 
[2017-11-02 17:26:11] <ImFlog> Well the use case is not about sensitive information, this is just a common configuration and I found it easier to use config than secret (the interesting part for us was environment vars)
[2017-11-02 17:28:32] <SISheogorath> comeUpWithItLater: There is exactly one valid solution: Make your image aware of the possibility that a service is not there and it has to wait for it's depedency
[2017-11-05 00:47:41] <jelmerk> Hi a project I am looking at  is using--ulimit cpu=10:10to make sure that a docker container gets killed after 10 seconds but by default each container’s access to the host machine’s CPU cycles is unlimited so often it will get killed before the 10 second mark
[2017-11-05 00:47:58] <jelmerk> is there a more elegant way to accomplish this in docker ?
[2017-11-05 00:57:27] <danieldram> Hello when I try to build a windows docker-machine with hyper-v, it says the file is not digitally signed so it never runs. I tried for 2 hours to find a solution, even creating a vm in hyper v itself will not run. is there a solution?
[2017-11-05 14:55:26] <siassaj> I've been copying compiled assets and dependencies into my docker builds via ADD, doing my app's build tasks (which may create, reuse and delete some assets/dependencies) and after the image is create I copy those compiled assets and dependencies into a cache using docker cp.It speeds up builds significantly, but it makes it hard to use things like aws' ECS or any other docker build & deploy service because of the need for a custom bash script.
[2017-11-05 14:56:23] <siassaj> when I builththis there was no better way that seemed to exist. Have there been any changes to improve this, and get all thes 'caching' steps into the Dockerfile
[2017-11-05 14:58:34] <maximkrusina> Hi there! Plz any best practices, when I would like to connect from Docker container to another network via L2TP/IPSec? Add L2TP/IPSec into container, or add one more container just for handling the VPN?
[2017-11-05 16:08:40] <DGrass> Is anyone here familiar with Laradock? I need to upgrade from PHP 7.1.4 to (i think) 7.1.9, as I'm using MySQL 8 and it's not working
[2017-11-06 05:06:03] <dpnova> I've found that restarting a container in compose when I'm connected to my wifi kills my wifi connection... I have to reconnect wifi every time...
[2017-11-06 05:10:30] <dpnova> actually nm i think this is my issue [<-LINK->] 
[2017-11-06 07:14:50] <comeUpWithItLater>  [<-LINK->] 
[2017-11-06 07:15:02] <comeUpWithItLater> so what's wrong with this config ?
[2017-11-06 09:22:26] <comeUpWithItLater> oh my bad
[2017-11-06 09:22:30] <comeUpWithItLater> forget it
[2017-11-06 10:00:36] <EDDYMENS> so I have an app in a container and I just want to add SSL to that
[2017-11-06 10:00:44] <EDDYMENS> any idea how I do that
[2017-11-06 11:36:12] <SachinKSingh28> here: 
[2017-11-06 11:38:41] <SachinKSingh28> I have docker engines configured to forward logs to splunk and we had an issue when splunk service was unavailable and containers stopped working. We were wondering if someone had this issue before or if there is a fix so that container would work even if the remote logging server is not available?
[2017-11-06 11:39:17] <SachinKSingh28> docker engine version is 1.12.6
[2017-11-06 16:42:06] <brandonawells> Hey all, i\'m running to the follow error in my django project when using docker: django.db.utils.OperationalError: could not translate host name "postgres" to address: Name does not resolvemy docker-compose: [<-CODE->] My host in my django db config: DB_HOST=postgresIs there something I\'m missing?
[2017-11-06 18:04:53] <jlai403>  [<-CODE->]  [<-CODE->] 
[2017-11-07 02:31:29] <Shirakiina> Is someone here?
[2017-11-07 02:32:14] <Shirakiina> Im deploy piwik on  docker ,now I want update piwik to the newlast
[2017-11-07 02:32:41] <Shirakiina> How can i do that ...
[2017-11-07 07:18:35] <86-toyobaru> hi. do anybody know about adding docker --cap-add and --device options to swarm mode?
[2017-11-07 07:19:31] <86-toyobaru> as I read in issues it's at least in WIP status
[2017-11-07 07:45:17] <anshulpatel25> Hey,  What is way to check the status of docker engines of manager and worker? Does docker provide any HTTP/TCP status for the same?I am writing a monitoring client which will check whether the engine is healthy and part of swarm? What parameters should I be looking for?
[2017-11-07 09:02:40] <pjetr> Hey guys, I've a question, that I posted on reddit as well: [<-LINK->] 
[2017-11-07 09:04:38] <pjetr> in short I need to create a staging system, and need to be able to build each branch, and test each branch manually of every application in our eco-system. IE test a specific ticket of application A against the master of application B, development of application C and perhaps even another ticket of app D...
[2017-11-07 09:05:17] <pjetr> My idea is to create docker containers in our CI of each branch, and simply choose which container to run
[2017-11-07 09:06:04] <pjetr> but this would require my containers to contain more than one technology, ie nginx + php-fpm + mariadb + redis + elastic
[2017-11-07 09:06:22] <pjetr> or node + redis + mongo
[2017-11-07 09:06:30] <pjetr> or ...
[2017-11-07 09:07:09] <pjetr> The reason why I would try to keep it all in a single container is to make switching between branches as smooth as possible
[2017-11-07 09:07:40] <pjetr> and, more importantly, to have migrations ran during build
[2017-11-07 18:51:07] <zcregan> I have a quick question. In my dockerfile, how do I COPY a directory and a file to WORKDIR in a single layer? I currently have this:COPY src/ tsconfig.json ./but that copies the contents of src, not the src directory itself.
[2017-11-07 20:12:57] <djfusco> I'm looking to run a script of SQL commands against my mariadb AFTER it has been brought up and started.  the script can be run from the same container or another - it doesn't matter.  I've tried this, but it tells me mysql isn't ready yet.
[2017-11-07 20:12:58] <djfusco> FROM mariadbCOPY /shell/MySQL.sh /usr/local/bin/MySQL.shRUN chmod +x /usr/local/bin/MySQL.shCMD ["/usr/local/bin/MySQL.sh"]
[2017-11-07 20:13:32] <djfusco> When I do just 'FROM mariadb' I can connect to the container and issue mysql and it works
[2017-11-07 20:16:45] <arunkumar-patange>  [<-LINK->] there is a /docker-entrypoint-initdb.d where you should copy MySQL.sh during docker run
[2017-11-07 20:16:51] <arunkumar-patange> djfusco: ^^
[2017-11-07 20:21:56] <djfusco> arunkumar-patange: Thanks - am trying it now
[2017-11-07 20:52:06] <djfusco> arunkumar-patange: I have this
[2017-11-07 20:52:08] <djfusco> FROM mariadbADD init.sql /docker-entrypoint-initdb.d/init.sql
[2017-11-07 20:52:10] <djfusco> and this
[2017-11-07 20:52:17] <djfusco> CREATE USER djf;CREATE DATABASE dockerdjf;GRANT ALL PRIVILEGES ON DATABASE dockerdjf TO djf;
[2017-11-07 20:52:21] <djfusco> in init.sql
[2017-11-07 20:52:28] <djfusco> but it doesn't seem to be running the SQL script
[2017-11-07 20:55:11] <djfusco> might be a permission issue - looking at that now
[2017-11-07 20:56:16] <pjetr> you can simply use ENV stuff to do that@djfusco
[2017-11-07 20:59:20] <djfusco> pjetr: thanks.  I'm learning.  I appreciate your help
[2017-11-07 21:00:23] <pjetr> no worries, I'm no devops myself, but I did that using docker-compose, which made getting a development environment quite easy to set up
[2017-11-07 21:01:11] <djfusco> Trying to migrate from VM/server environment to learning this way of doing things
[2017-11-07 21:02:14] <pjetr>  [<-LINK->] If you scroll down toEnvironment Variablesyou'll see that yu can addMYSQL_DATABASE,MYSQL_USERandMYSQL_PASSWORDwhen creating a container
[2017-11-07 21:03:30] <pjetr> also mounting to/docker-entrypoint-initdb.dshould be done when creating a container using a volume
[2017-11-07 21:06:12] <pjetr> docker run -d -v "$pwd/init.sql:/docker-entrypoint-initdb.d/init.sql" -e MYSQL_DATABASE=djf -e MYSQL_USER=dockerdjf -e MYSQL_PASSWORD=password mariabd:10
[2017-11-07 21:06:19] <pjetr> or something like that
[2017-11-07 21:06:27] <pjetr> (if I recall correctly)
[2017-11-07 21:06:55] <pjetr> Are you trying this for production, or for development?
[2017-11-07 21:07:31] <pjetr> Because for production a whole new layer comes in to play where I can't tell you anything about :-D
[2017-11-07 21:08:09] <djfusco> Currently dev, but want to make a yaml file for people to use in production.  Am building an app using this and several other services.  I have those working with shell scripts, but this one is stumping me.  Can't get it to wait for mysql to be ready to issue it commands
[2017-11-07 21:10:09] <djfusco> Thanks@pjetr!
[2017-11-07 21:12:52] <pjetr> no worries :)
[2017-11-07 21:13:22] <pjetr> you should check out  docker-compose though, it'll make your life that much easier :D
[2017-11-07 21:14:25] <djfusco> I'm using it (docker-compose) for build/up with a yaml file for 'the whole app', which is working, except for this script that I want to run to customize some things
[2017-11-07 21:15:22] <djfusco> I'm enjoying the ride and learning.
[2017-11-07 21:17:19] <pjetr> I use the default images for mariadb, php-fpm and nginx. they are all on the same network, and can talk to each oter using their container-names. To add the database, I simply mount a dump-file in the/docker-entrypoint.dand use ENV to have the correct user / database and other stuff
[2017-11-07 21:18:25] <djfusco> cool - will check it out in a bit
[2017-11-08 02:45:26] <praveensams> Has anyone have document/url  for installing kubernate on vagrant
[2017-11-08 05:56:04] <anshulpatel25> Hey,  What is way to check the status of docker engines of manager and worker? Does docker provide any HTTP/TCP status for the same?I am writing a monitoring client which will check whether the engine is healthy and part of swarm? What parameters should I be looking for?
[2017-11-08 15:52:47] <PixellUp> Can someone help out - [<-LINK->] 
[2017-11-08 17:50:58] <bitsofinfo> with the announcement of k8 orchestration support and that docker stack compose files can be used when targeting deployment on k8 as the backend, how will the secret functionality of the compose format be handled/translated for k8? Will that be supported?
[2017-11-08 18:52:02] <bitsofinfo> We are developing some new containers and would like to pick the best approach for CLI deployment and management policies that will be compatible w/ the future Docker orchestration direction (i.e. k8 or swarm). From this video ( [<-LINK->] ) it sounded like we should just go w/ using compose files and docker stack deploy… then if I understand correctly we could swap out orchestration targets (k8/swarm) with little effort
[2017-11-08 18:52:32] <bitsofinfo> So… if I am correct… will this abstraction pertain to secrets as well?
[2017-11-08 19:55:49] <AnderssonPeter> im trying to build a docker container but when i add --no-cache i get the following errorunknown shorthand flag: '' in -–no-cache
[2017-11-09 00:52:52] <djfusco> I'm looking to run a script when I start my Ubuntu container, which includes doing things like chmod a .sh to be executable, modifiy files, etc. and I'm getting an 'operation not permitted'.  I'm sure it's obviously something with the 'container root' account not having access to the files I've copied over OR the volume I've mapped.  Do I change permissions to the files locally (my Mac) OR change them inside the container?
[2017-11-09 00:56:09] <airtonix> djfusco: things to check for: line endings (should be LF not CRLF), is it executable (chmod +x), does it have#!/bin/THE-ENGINE-YOU-WANT?
[2017-11-09 00:58:11] <airtonix> djfusco: also, an example of what you're trying to do is helpfule, beacuse your case is fairly vague and generic. so make a gist, show a directory listing of the project on the host, the docker-compose file (if any), the dockerfile, theentrypoint.shfile (if any)
[2017-11-09 00:58:17] <djfusco> the command I\'m using is \'chmod +x somescript.sh\' and what I get is "changing permissions" "Operation not permitted"
[2017-11-09 00:59:06] <djfusco> BUT - when I chmod BEFORE I run docker-compose (e.g. chmod 777) it works.  I know I can't just open it to the world,
[2017-11-09 01:03:59] <djfusco>  [<-LINK->] 
[2017-11-09 01:04:33] <djfusco> dfusco-pro:dockerscript dfusco$ ls -altotal 24drwxr-xr-x    6 dfusco  426003623   204 Nov  8 18:47 .drwxr-xr-x+ 138 dfusco  426003623  4692 Nov  8 20:03 ..-rw-r--r--    1 dfusco  426003623   560 Nov  8 20:03 Dockerfile-rw-r--r--    1 dfusco  426003623   197 Nov  8 18:46 docker-compose.ymldrwxr-xr-x   26 root    426003623   884 Nov  8 18:50 elmsln-rwxr-xr-x    1 dfusco  426003623   409 Nov  8 20:03 entrypoint.sh
[2017-11-09 01:06:08] <djfusco> The 'ls -al > out.txt' was just a test to make sure the script was running, which it is.
[2017-11-09 01:07:57] <airtonix> djfusco: is the phusion a ubuntu thing? does ubuntu have selinux on it?
[2017-11-09 01:08:37] <airtonix> djfusco: do you get the same problem if you based your dockerfile on an alpine based image?
[2017-11-09 01:09:11] <djfusco> yes it's ubuntu.  not sure if this version has selinux on it
[2017-11-09 01:09:56] <djfusco> haven't tried alpine yet, but will try full version of Ubuntu
[2017-11-09 01:12:04] <airtonix> does phusion do some funky stuff with users in the container?
[2017-11-09 01:12:31] <djfusco> good question.  I do not know.  I was trying to use a smaller version of Ubuntu
[2017-11-09 01:13:00] <airtonix> if you want smaller, then i'd use alpine. but then it looks like you're heavily locked into ubuntu with your provisioning
[2017-11-09 01:13:40] <djfusco> Yeah, all of my scripts from this full blown server version is wrapped around apt-get vs apk (which I could change if I had to)
[2017-11-09 01:13:51] <airtonix> things i'd do at this point: try a generic ubuntu base image with just the entrypoint and the provisioning script. does your chmod work there?
[2017-11-09 01:14:15] <airtonix> no docker-compose, no project source code...
[2017-11-09 01:15:20] <djfusco> will try.  thanks.
[2017-11-09 05:53:45] <HarshaliRaka> I\'m trying to set the value of sysctl params when running my docker image. I\'m able to set net.core.somaxconn parameter, but I get an error for net.core.netdev_max_backlog param, which says - "/proc/sys/net/core/netdev_max_backlog: no such file or directory."What will be the correct way to set the parameter?
[2017-11-09 15:05:08] <alculquicondor> Hello. How can I determine a .Task.Slot before hand? I'm trying to use that variable to generate a volume for each of my global tasks for a particular service.
[2017-11-10 05:07:00] <MacroLove> ndpratas: thx. gotta
[2017-11-10 14:11:36] <pjetr> I'm clueless. I'm creating an image, in it I copy mycomposer.jsonand mycomposer-lock.json. I runcomposer installand then add the rest of my files. Everything worked
[2017-11-10 14:12:16] <pjetr> but I've been restructuring my image to be split up in multiple images, because of inherritage
[2017-11-10 14:12:41] <pjetr> and now suddenly my composer install doesn't add my vendor-folder anymore?
[2017-11-10 14:12:51] <pjetr> like WTF?
[2017-11-10 14:14:31] <pjetr> but the log states it installed everything as it should...
[2017-11-10 16:13:32] <pjetr> I think I found my answer guys. It seems to be because I marked my /var/www folder as a volume in one of my parent images. [<-LINK->] 
[2017-11-10 16:54:53] <ekelvin> ekelvin: I am trying to persist a postgres docker on a windows machine. is working with a named volume but not with a volume mapping, can anyone help me on this ? [<-CODE->] 
[2017-11-10 19:08:49] <btamayo> SachinKSingh28: Did you figure out a solution for this? We actually did run to this and I’m not sure what the team’s solution was other than to not use the splunk driver since the container (at least with compose) will fail to instantiate if the logging driver doesn’t work. We’re just going to log to a different level (not directly docker driver) and then forward to splunk. For mine, I moved them to application level. I think others moved it to syslog level.
[2017-11-12 00:41:37] <romainbr2004_twitter> i can't comment out the h1 element
[2017-11-12 18:42:51] <JakubA3informatics> Hello, I'm Jakub new here. I have a question about an app I'm building in my office. I have to build an app which use RoR, PostgreSQL and Nwo4j. I would like to know how to build a Docker container for this as I cannot find any good reference. My app has to use 2 different DB technologies and that is mandatory. I need to find a solution how to make this. Thank you for help :)
[2017-11-13 07:55:07] <thibremy> Hello there !May be somebody can help me because I'm stuck :(I try to bind tcp connection between two services, to share the same event_bus.I use this docker-compose [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2017-11-13 09:45:57] <MichaelBui> project_defaultis your network name, not container or service name
[2017-11-13 09:47:10] <MichaelBui> I don’t know what you are trying to archive but usually services communicte one another by service names or IP
[2017-11-13 09:57:31] <ekelvin>  [<-CODE->] 
[2017-11-13 10:00:02] <MichaelBui> thibremy: Maybe it’s easier if you can explain a bit what is EVENT_BUS_URL and how it will be used
[2017-11-13 17:26:53] <AshokRajuDevops> hi all
[2017-11-13 17:27:15] <AshokRajuDevops> i am running docker on ubuntu 14.04lts
[2017-11-13 17:27:23] <AshokRajuDevops> and it showing WARNING: No swap limit support
[2017-11-13 17:27:52] <AshokRajuDevops> i want to create a container with swap mem limit
[2017-11-13 17:30:02] <AshokRajuDevops> i updated GRUB_CMDLINE_LINUX_DEFAULT and GRUB_CMDLINE_LINUX with cgroup_enable=memory swapaccount=1 and ran update-grub
[2017-11-13 17:30:08] <AshokRajuDevops> but no luck
[2017-11-13 17:30:15] <AshokRajuDevops> still i am getting same warning
[2017-11-13 17:30:23] <AshokRajuDevops> any idea??
[2017-11-13 20:18:30] <jeychan12> channel: , is there way we can install windows exe under docker and on top of it can we install any .exe app and use that docker any linux machine
[2017-11-13 22:47:18] <JosephLeon> I'm struggling with something that seems very simple but nothing is working. I have a symfony project on docker and I want to hook up sequel pro to the mysql db running in docker
[2017-11-13 22:47:25] <JosephLeon>  [<-LINK->] 
[2017-11-13 22:47:30] <JosephLeon> that's what im getting
[2017-11-13 22:47:54] <JosephLeon> everything I've googled assumes you know what you are doing with docker and im a nub at it
[2017-11-13 22:48:33] <airtonix> JosephLeon: gist all your files. then someone can start giving you a realistic idea about where you can change thigns
[2017-11-13 22:54:43] <JosephLeon> airtonix: so the issue is I suck so bad I dont even know what files you are talking about
[2017-11-13 22:55:20] <JosephLeon> I dont do docker, I just got a project dropped in my lap with docker
[2017-11-13 22:55:37] <JosephLeon> like getting thrown in water without knowing how to swim
[2017-11-13 22:56:12] <JosephLeon> its an OS project [<-LINK->] 
[2017-11-13 22:56:17] <airtonix> JosephLeon: ahh, but you have some idea that Docker is involed?
[2017-11-13 22:56:43] <JosephLeon> Yea I know kind of what docker does
[2017-11-13 22:57:22] <JosephLeon> but having to say fetch data from somewhere to hookup to sequel pro im lost, ive poured through file after file and cannot make sense of anything
[2017-11-13 22:58:28] <airtonix> i like how they use the word "easily" then proceed to make you run anything other thandocker-compose upordocker run ...
[2017-11-13 22:58:38] <airtonix> looks fun!
[2017-11-13 22:58:39] <JosephLeon> hhaha
[2017-11-13 23:00:32] <airtonix> I'd start with any chat/forum channel that project has.
[2017-11-13 23:03:00] <thedrint> Hi, can't mount named volume correctly. Any ideas? [<-CODE->] After run container, /var/www/html permissions from it copied to my host directory ~/test/app (which bind to myvol early).So, php can't create new files in myvol. And me from host can't create in /home/user/test/app too:(
[2017-11-13 23:06:51] <thedrint> But if i map host dir to container: [<-CODE->] I have correct permissions inside and outside: [<-CODE->] 
[2017-11-13 23:09:14] <thedrint> Maybe I forgot some bind options or something else?Stuck on this:)
[2017-11-14 00:06:03] <thedrint> I try to get answer in Internet, spent 7 evenings of my life, but no success:)Issued it on github [<-ISSUE->] 
[2017-11-14 02:10:31] <Khoa_Truong_twitter> hey guys. trying out lcow on windows 10. been trying to figure out the new location for docker.sock
[2017-11-14 02:11:02] <Khoa_Truong_twitter> been running a proxy container and that's a required link.docker run -d --restart=always \\\n  -v /var/run/docker.sock:/tmp/docker.sock:ro \\\n  -v ~/.dinghy/certs:/etc/nginx/certs \\\n  -p 80:80 -p 443:443 -p 19322:19322/udp \\\n  -e DNS_IP=127.0.0.1 -e CONTAINER_NAME=http-proxy \\\n  --name http-proxy \\\n  codekitchen/dinghy-http-proxy
[2017-11-14 08:57:26] <VQuery> Hi Guys,I Want to save my docker build -t  command execution logs to text file or any other format .Is this possible?
[2017-11-14 13:24:58] <lanwin> Hi. Does Docker has any way to set default constraints in swarm mode?
[2017-11-14 13:26:07] <lanwin> I want to exclude some nodes for special purposes and want to ensure that that nobody deploys to them simply cause he forgot to provide that constraint
[2017-11-14 16:32:49] <alexc101> Can anyone check this out? Can't connect to docker instance usings windows 7 professional. [<-LINK->] 
[2017-11-14 20:10:18] <arunkumar-patange>  [<-ISSUE->] @lanwin
[2017-11-15 18:48:54] <fouadroumieh> What is the best practice when it come to handling images for dev, staging and prod environments?
[2017-11-15 22:19:05] <SISheogorath> build a dev image, later build the staging image. Instead of building a prod image, relabel the staging image since it's proven to work
[2017-11-15 22:48:46] <rightisleft> is there a field in docker-compose to limit the number of service replicas on the same host?
[2017-11-15 22:48:58] <rightisleft> IE if i only wantfooto run 1 instance per host - so a host can never have foo.1 foo.2
[2017-11-16 08:26:23] <ppLorins>  [<-LINK->] 
[2017-11-16 08:27:49] <ppLorins> Hey guys, I run the example from the official site, but the http request will cost me more than 20+ seconds , have no idea why , who ever encounter this ?
[2017-11-16 08:29:09] <elcolie> ppLorins: Do you usedocker-compose?
[2017-11-16 08:29:16] <ppLorins> Yes
[2017-11-16 08:29:38] <elcolie> Then please show me in here. If somebody is free they would troubleshoot for you.
[2017-11-16 08:29:59] <elcolie> docker-composehas many version. Single wrong indent would get you hair off
[2017-11-16 08:30:55] <ppLorins> `version: "3"services:  web: [<-CODE->] networks:  webnet:`this is my docker-compose yml file , it\'s very simple .
[2017-11-16 08:31:15] <ppLorins> copy from office site and modify the image to my own one.
[2017-11-16 08:32:27] <ppLorins> expose port 7000 on my host machine, and the port 7000 can be telnet okay from outside. Buy the http request will take very long to complete.
[2017-11-16 08:36:26] <ppLorins> I believe it's because the app logic inside the container, it's a flask instance and do connect to redis which is not  present actually.
[2017-11-16 09:19:00] <elcolie> Yes
[2017-11-16 09:19:53] <elcolie> ppLorins:  [<-LINK->] 
[2017-11-16 13:10:20] <djfusco> I\'ve tried numerous versions of Alpine and can\'t seem to find one that support these packages - php-mysql php-mysqli php-pdo_mysql    I continually get "ERROR: unsatisfiable constraints:php-mysqli (missing):required by: world[php-mysqli]"
[2017-11-16 13:32:30] <grofit> Anyone here using docker with windows containers?
[2017-11-16 13:33:07] <grofit> as I am losing the will to live trying to extract a gzip file using nanoserver and almost every avenue ends in failure
[2017-11-17 08:20:29] <jemliF> hi
[2017-11-17 08:22:07] <jemliF> I have aDockerfilein which I was trying to run.binfile (a server installer)
[2017-11-17 08:24:53] <jemliF> it runs as expected, but it looks like it doesn't respond when it displayPRESS ENTER TO CONTINUE
[2017-11-17 08:25:34] <jemliF> I pressENTERbut it behaves like I didn't
[2017-11-17 09:40:35] <SISheogorath> jemliF: because in docker during the build processeverythinghas to run unattended
[2017-11-17 09:40:46] <SISheogorath> means without human interaction
[2017-11-17 09:41:15] <SISheogorath> so there is no stdin which results in the behaviour you noticed
[2017-11-17 09:44:04] <sureshpareek> i do not understand where docker will data stored  if i use gitlab docker in system
[2017-11-17 13:03:22] <davidkarlsen> in compose, is there any way do initialize a data volume with contents from the host filesystem?
[2017-11-17 14:05:15] <grofit> Is there any definitive article about how to do string interpolation in a dockerfile? i.e if I set: [<-CODE->] Then somewhere else I want to do something like [<-CODE->]  [<-CODE->] 
[2017-11-17 14:05:56] <grofit> as it seems you CAN do interpolation in certain places but some things just use$varnameothers use${varname}and there is little info online about this, which I thought would be a super common use case
[2017-11-17 14:25:43] <jemliF> SISheogorath: How can interact with server installation process, it needs my confirmation for some options
[2017-11-17 14:26:49] <SISheogorath> jemliF: As mentioned before, you can't. If it's your setup script/binary provide a way to pass all needed options by arguments or a config file. If it's not yours, write a wrapper
[2017-11-17 14:43:43] <jemliF> SISheogorath: maybe it provides--silentinstallation option
[2017-11-17 14:44:05] <jemliF> SISheogorath: I will check
[2017-11-17 14:45:31] <SISheogorath> sounds like Windows
[2017-11-17 14:46:58] <SISheogorath> grofit: Since docker usually uses/bin/shalmost everything you can do with/bin/shis also possible inRUN
[2017-11-17 14:52:46] <hazim1093> Hi,I'm trying to have access to docker inside the docker container,according to the official dind (docker inside docker) image, (https://hub.docker.com/_/docker/) [<-CODE->] should run and show me the list of running docker containers, but it doesn't work for me until i map the docker socker as well like: [<-CODE->] Am I doing it the right way?
[2017-11-17 15:08:43] <grofit> AH but here is the kicker
[2017-11-17 15:08:45] <grofit> I am in windows
[2017-11-17 15:08:49] <grofit> using windows containers
[2017-11-17 15:09:05] <grofit> just raised a SO on the subject
[2017-11-17 15:09:11] <grofit>  [<-LINK->] 
[2017-11-17 15:10:12] <grofit> I assumed behaviour would just be the same between both platforms but I assume (like with most things) linux command lines are a lot more intelligent and flexible than windows ones
[2017-11-17 18:51:17] <SISheogorath> grofit: well, then you have to check the whole powershell things
[2017-11-17 18:57:59] <grofit> Ah right one mo as this may be the crux of my issue
[2017-11-17 18:59:08] <grofit> My understanding was that the docker file kinda pre processed the RUN and other commands in there, but are you saying that it just passes the content through to ps/cmd without processing it in any way?
[2017-11-17 19:07:02] <fouadroumieh> Is it a better practice to create separate images for application and database? What are the consequences if the application is running in a docker container and the database not?
[2017-11-17 20:06:36] <SISheogorath> fouadroumieh: think about what happens when your application gets too much load and you need a second instance of it
[2017-11-17 20:06:51] <SISheogorath> do you want a second DB? Usually not
[2017-11-17 20:07:15] <SISheogorath> grofit: On Windows I'm not sure, but on Linux it simply sets the encironment and runs the command
[2017-11-17 20:07:33] <SISheogorath> you can see this when you usedocker historyon an image
[2017-11-17 20:18:12] <tomiwaadey_twitter> Hi guys, I have some networking related questions.
[2017-11-17 20:18:38] <tomiwaadey_twitter> Basically, if someone says my ip was rate limited which ip will that be?
[2017-11-17 20:19:18] <tomiwaadey_twitter> If i run nslookup domain.com i get an ip address
[2017-11-17 20:19:48] <tomiwaadey_twitter> if i docker inspect product container for the app, I get another ip address
[2017-11-17 20:20:12] <tomiwaadey_twitter> and the host server (digital ocean droplet) is another address.
[2017-11-17 20:20:36] <tomiwaadey_twitter> I know it's a newb question, but which ip is what?
[2017-11-17 20:21:00] <tomiwaadey_twitter> If i want to change the ip that was rate limited. Which one would be changed?
[2017-11-18 02:53:09] <comeUpWithItLater> anyone  using  traefik ?
[2017-11-18 02:53:17] <comeUpWithItLater>  [<-LINK->] 
[2017-11-18 02:53:45] <comeUpWithItLater> i want host this service with test.api01.diantouapp.com and [<-LINK->] .
[2017-11-18 02:54:01] <comeUpWithItLater> how to config it ?
[2017-11-18 09:09:40] <karachainproj_twitter> We are soon going to release Blockchain Tutorial  using GOlang for Developers on our Gitter and telegram group - you can join our groups
[2017-11-18 09:09:41] <karachainproj_twitter> karachainproj_twitter: Gitter : [<-LINK->] Telegram: [<-LINK->] 
[2017-11-19 14:47:32] <ekelvin> anyone can help me on this windows problem? [<-LINK->] 
[2017-11-19 19:16:41] <kunalbhatia87> Hey guys, need some help around mounting a volume for logstash using docker stack deploy in swarm, as I get an error while doing the same
[2017-11-19 19:16:57] <kunalbhatia87> "invalid bind mount source, must be an absolute path: C:\\projects\\docker-tests\\swarm-logging\\logstash\\logstash.conf"
[2017-11-19 19:17:19] <kunalbhatia87>  [<-CODE->] 
[2017-11-20 06:28:55] <ppLorins>  [<-LINK->] 
[2017-11-20 06:29:35] <ppLorins> why my docker-machines on win7 often times out ?  Who ever encounter this issue?
[2017-11-20 15:25:37] <iosven>  [<-CODE->] Background: I just had a Kafka container of size 80GB where this huge size increase was apparently due to log statements (the actual Kafka data is mapped to a volume so resides outside of the container), and I want to find out if this is Docker default behavior, or if I need to look for a logging configuration that also persists log statements to a file instead of just logging to console.Also, is there a way to cutoff or otherwise configure Docker container logs?
[2017-11-20 15:33:51] <iosven> We did not configure anything, so our containers use logging driver json-file with default settings, which would come without constraints regarding size or number of files?
[2017-11-21 10:56:20] <scippio> hi all ...
[2017-11-21 10:56:39] <scippio> Is somewhere a documentation for docker-machine driver?
[2017-11-21 10:56:55] <scippio> I want create my own machine driver...
[2017-11-21 11:10:11] <scippio> hmm I found something... [<-LINK->] 
[2017-11-21 11:12:19] <scippio> hmm it's for Docker ... :( not for docker-machine ..
[2017-11-21 16:07:54] <pjetr>  [<-LINK->] 
[2017-11-21 16:08:00] <pjetr> how cool is this!
[2017-11-21 16:08:08] <pjetr>  [<-LINK->] 
[2017-11-21 16:08:12] <pjetr> direct link
[2017-11-21 16:08:43] <pjetr> Someone created a docker image that emulates the original unix
[2017-11-21 19:24:11] <rightisleft> is there a way to remove all volume instances on a host that are assosciated with an image?
[2017-11-21 19:24:54] <rightisleft> right now when i start a service - the container instantiates a dynamic volume - i can see that running docker inspect foo and looking at the mouints
[2017-11-21 19:25:18] <rightisleft>  [<-CODE->] 
[2017-11-21 19:25:41] <rightisleft> i want to be able to tell my team how to nuke the volume assosciated with a service
[2017-11-21 19:26:09] <rightisleft> without runnong docker inspect blah blah and finding the mount - then deleting manually
[2017-11-21 21:12:49] <SISheogorath> rightisleft: when you use docker-compose then usedocker-compose down -v
[2017-11-21 21:13:15] <SISheogorath> otherwise there is no way right now
[2017-11-21 21:13:40] <rightisleft> if -v does the trick - thats fine
[2017-11-21 23:10:23] <thedrint> @igorbarkowsky cpuguy83 give me answer to my question:Hi, can't mount named volume correctly. Any ideas?If use :nocopy option - it works. [<-CODE->] 
[2017-11-22 07:24:55] <tomiwaadey_twitter> Guys, what's the easiest way to deploy docker?
[2017-11-22 07:42:42] <airtonix> Use an os with it preinstalled. Or use docker machine
[2017-11-22 07:50:57] <tomiwaadey_twitter> In production?
[2017-11-22 08:10:37] <tomiwaadey_twitter> Basically, I want to deploy a mini app that scrapes the web for backlink data.
[2017-11-22 08:15:08] <tomiwaadey_twitter> I'll need the flexibility to spin up another version of the app with a different ip quickly in case the previous one is rate limited.
[2017-11-22 08:15:21] <tomiwaadey_twitter> So I was wondering if anyone know the best solution for this use case with docker.
[2017-11-22 08:18:34] <airtonix> It's not
[2017-11-22 08:18:55] <airtonix> Your containers will all have the same wan ip address
[2017-11-22 08:20:17] <airtonix> Your solution is going to be more complicated thanrun container > so magic from New ip
[2017-11-22 08:22:07] <tomiwaadey_twitter> Thanks  Zenobius. I just learnt something new. So the wan ip address will be the host ip address?
[2017-11-22 08:22:14] <tomiwaadey_twitter> Interesting.
[2017-11-22 08:22:42] <tomiwaadey_twitter> And each container has a different ip address right. What's the term for the container ip address?
[2017-11-22 08:23:38] <airtonix> Yes it will, but they'll be lan IP addresses. You could do something with docker events and Amazon Elastic ip if it had an api
[2017-11-22 08:27:33] <tomiwaadey_twitter> Interesting! I'll look up these terms to learn more about them. Thanks :)
[2017-11-22 08:27:59] <tomiwaadey_twitter> How does docker events and Amazon Elastic ip solve this?
[2017-11-22 08:33:12] <tomiwaadey_twitter> Also is there a way to quickly look up both the lan and wan ip adresses from the command line?
[2017-11-22 08:56:09] <airtonix> docker inspect
[2017-11-22 08:56:57] <airtonix> Your wan IP address isn't handled by docker.
[2017-11-22 08:59:57] <comeUpWithItLater>  [<-LINK->] 
[2017-11-22 09:00:06] <comeUpWithItLater> what's wrong with this ?
[2017-11-22 09:00:30] <comeUpWithItLater> docker  ce 17.*
[2017-11-22 09:00:38] <comeUpWithItLater> os: windows 10 latest
[2017-11-22 09:30:49] <tomiwaadey_twitter> Got you. Thanks for your help@airtonix.  These terms I've learnt will allow me to refine my search better.
[2017-11-22 11:11:10] <JasonShin> hey guys
[2017-11-22 11:11:24] <JasonShin> how do you use kubernetes in development?
[2017-11-22 11:11:39] <JasonShin> and would you recommend it? I want to run docker/faas locally so I can develop microservices
[2017-11-22 11:11:58] <JasonShin> and want to run exactly same setup in production
[2017-11-22 13:40:17] <pjetr>  [<-LINK->] 
[2017-11-22 13:40:37] <pjetr> Hi guys, I could use some help mapping a domain to a specific container
[2017-11-22 13:41:14] <pjetr> or isn't that a thing?
[2017-11-23 08:19:23] <fouadroumieh> Is it possible to install Docker for windows through the command in docker-compose file? also Hyper-V?
[2017-11-23 08:42:31] <kunalbhatia87> Hello, Is there a way to create docker-machines on "Bash on Ubuntu on Windows", looking to create multiple hosts as done using hyperv driver in windows
[2017-11-23 09:26:44] <airtonix> Docker machine works in powershell.
[2017-11-23 09:27:43] <airtonix> Like... We all know Microsoft is about software as layers of Band-Aids... Bash on on Ubuntu on Windows... Just ugh.
[2017-11-23 09:29:31] <kunalbhatia87> airtonix: I agree on that, but the reason I\'m using the WSL(Windows Subsystem for Linux) to solve other issues of mounting volumes like"Err": "invalid mount config for type \\"bind\\": bind source path does not exist"
[2017-11-23 09:29:58] <airtonix> What does your volume directive actually look like?
[2017-11-23 09:30:35] <kunalbhatia87> when using docker-machines on windows shell, it is unable to find the  source path for bind type.
[2017-11-23 09:31:02] <airtonix> Depends on which shell.
[2017-11-23 09:31:34] <kunalbhatia87>  [<-CODE->] 
[2017-11-23 09:32:08] <airtonix> But with docker machine all your mounts are going to be in the Virtual machine... This isn't docker-for-windows and moby
[2017-11-23 09:32:46] <airtonix> There is no windows workstation:docker host sharing
[2017-11-23 09:33:47] <kunalbhatia87> the code run with docker-compose as it natively uses the shared drives as configured in docker settings.
[2017-11-23 09:34:14] <airtonix> In docker for Windows?
[2017-11-23 09:34:50] <kunalbhatia87> Yes
[2017-11-23 09:36:42] <kunalbhatia87> but fails to run in docker-machine, as the file is not present in the VM
[2017-11-23 09:38:18] <airtonix> yeah like I said. docker for windows creates a mobylinux docker server in the hyperv hypervisor
[2017-11-23 09:39:08] <airtonix> docker-machine also creates a virtual machine that is a docker host. but you don't get to share the hypervisor host drives into the virtualmachine
[2017-11-23 09:40:04] <airtonix> so in your docker-machine virtual machine, there is no path/c/Users/Prometheus
[2017-11-23 09:53:28] <kunalbhatia87> yes, there is no path as/c/Users/Prometheus
[2017-11-23 09:54:57] <kunalbhatia87>  [<-CODE->] 
[2017-11-23 09:55:25] <kunalbhatia87> this works on WSL, but not sure if I do the same in docker-machine, it will work or not..
[2017-11-23 21:05:02] <VeeTeeDev> I have this weird problem:I have an image   registry.gitlab.com/username/my-image:predevand I want to retag it to registry.gitlab.com/username/my-image:devby means of the remote API (http) [<-CODE->] I\'m always getting `{"message":"invalid reference format"}``
[2017-11-23 22:19:16] <rzhovnirchyk> what is a better option for a simple PHP/nginx application?1) mount source code as a volume in compose; use git for deployment (push to git repo, pull on server and run compose up)2) copy source code to images; push images to registry, run images from the registry on server
[2017-11-23 22:47:50] <Sankarshan-Mudkavi> Is there a docker for Mac release planned to address the high Sierra crashes? I didn't find much in the repo discussion
[2017-11-24 07:29:15] <fouadroumieh> When the Hyper-v is needed for docker? for example is it needed when running windows containers on a windows machine?
[2017-11-24 07:32:00] <acepsaepudin> Hyper-v will running by default. but we can start it manually
[2017-11-24 07:34:22] <fouadroumieh> acepsaepudin: that doesn't answer my question. Is it required to be running for win containers?
[2017-11-24 07:35:02] <acepsaepudin> yes
[2017-11-24 10:27:45] <ppLorins>  [<-LINK->] 
[2017-11-24 10:29:11] <VeeTeeDev> No one a solution for my remote API tag problem ?
[2017-11-24 10:29:54] <ppLorins> Hi all , above is the example of getting started tutorial from docker official website.My question is : How could app.py find the right ip address of redis service in a docker container ?  I attached to the container inside which app.py runs , but found nothing that indicating the redis service's ip address.
[2017-11-24 15:39:56] <miriam-z> hi, I am running a rails app using docker
[2017-11-24 15:40:49] <denel-manilov> miriam-z: Congratulations!
[2017-11-24 15:40:52] <miriam-z> after hittingdocker-compose up
[2017-11-24 15:41:08] <miriam-z> denel-manilov: 
[2017-11-24 15:41:30] <miriam-z> The app starts to build
[2017-11-24 15:43:04] <miriam-z> I get the following [<-CODE->] 
[2017-11-24 15:43:51] <miriam-z> I also get the following in the terminal:Redirected to http://localhost:3000/p/sign_in
[2017-11-24 15:44:43] <miriam-z> when usingtcp://0.0.0.0:3000I get redirected to google and when usinghttp://localhost:3000/p/sign_inI can see the app
[2017-11-24 15:45:59] <miriam-z> I need to know if this is correct or if I should be using thetcp://0.0.0.0:3000?
[2017-11-24 15:49:39] <denel-manilov> miriam-z: tcp - Internet protocol suite, http - is an application protocolIf you want to use your application as a web service, you need HTTP
[2017-11-24 15:51:03] <denel-manilov> the problem is probably that you have not published the port
[2017-11-24 15:51:34] <denel-manilov> show your docker-compose.yml
[2017-11-24 15:54:44] <denel-manilov> the problem is probably that you have not published the portmy mistake
[2017-11-24 15:54:53] <denel-manilov> all right, use to access the application [<-LINK->] 
[2017-11-24 15:55:15] <miriam-z> ok
[2017-11-24 15:55:44] <miriam-z> just wanted to make sure that my build was successful with docker as I missed a set yet the app is still running
[2017-11-24 15:56:03] <miriam-z> after the first stepbundle install
[2017-11-24 15:56:25] <miriam-z> I should runbundle exec rake db:migrate
[2017-11-24 15:56:40] <miriam-z> howeverbundle exec rake db:migrateis not responding
[2017-11-24 15:57:01] <denel-manilov> just wanted to make sure that my build was successful with docker as I missed a set yet the app is still runningThe application works, do not worry
[2017-11-24 15:57:42] <miriam-z> I get the following error message:
[2017-11-24 15:57:51] <miriam-z> rake aborted!\nPG::ConnectionBad: could not connect to server: Connection refused\n        Is the server running on host "127.0.0.1" and accepting\n        TCP/IP connections on port 5432?
[2017-11-24 16:03:25] <denel-manilov>  [<-LINK->] 
[2017-11-24 16:07:06] <denel-manilov> ppLorins:  [<-LINK->] 
[2017-11-24 16:15:13] <miriam-z> is networking the only solution here
[2017-11-24 16:15:18] <miriam-z> Thanks
[2017-11-24 16:15:28] <miriam-z> I will take a look
[2017-11-24 16:20:14] <denel-manilov> glad to help
[2017-11-24 16:30:19] <jemliF> hi
[2017-11-24 16:31:12] <jemliF> I just started using Docker on Windows
[2017-11-24 16:31:47] <jemliF> I ran my first hello world container fine
[2017-11-24 16:33:11] <jemliF> but when I tried to build a Dockerfile
[2017-11-24 16:40:29] <jemliF> I got an endless symbols printed on my terminal
[2017-11-24 16:41:53] <denel-manilov> jemliF: can I see a screenshot?
[2017-11-24 17:01:17] <jemliF> denel-manilov:  [<-LINK->] 
[2017-11-24 17:01:39] <jemliF> I am using Linux containers by the way
[2017-11-24 17:13:12] <denel-manilov> Try change terminal encoding to utf-8
[2017-11-24 17:22:43] <denel-manilov> here is a similar problem, try to find a solution by this link: [<-ISSUE->] 
[2017-11-24 19:26:42] <gkatsanos> hey guys.
[2017-11-24 19:26:53] <gkatsanos> Problem withAutoteston cloud.docker, described there: [<-LINK->] 
[2017-11-24 19:27:26] <gkatsanos> Essentially I wonder if docker-compose.test.yml is run without docker-compose.yml so the thing doesn't work?
[2017-11-24 19:27:36] <gkatsanos>  [<-CODE->] ^ docker-compose.test.yml
[2017-11-24 19:28:17] <gkatsanos>  [<-CODE->] ^docker-compose.yml
[2017-11-24 19:49:11] <denel-manilov>  [<-LINK->] 
[2017-11-24 20:11:36] <denel-manilov> And this [<-LINK->] 
[2017-11-24 21:44:36] <gkatsanos> I read part1-6 already
[2017-11-24 21:45:05] <gkatsanos> do you mind being a bit more specific ?
[2017-11-24 21:46:44] <gkatsanos> my files are not "stack files" I guess?
[2017-11-24 21:47:18] <gkatsanos> I dont understand, do I have to make a different compose file for docker cloud?
[2017-11-25 06:12:25] <denel-manilov> Stack file is a compose file without
[2017-11-25 06:13:02] <denel-manilov> buildexternal_linksenv_file
[2017-11-25 06:13:14] <denel-manilov> Sections
[2017-11-25 06:15:33] <denel-manilov> You need build Dev version
[2017-11-25 06:16:31] <denel-manilov> gkatsanos/server image
[2017-11-25 06:20:31] <denel-manilov>  [<-LINK->] 
[2017-11-25 09:16:17] <gkatsanos> sorry I dont understand. if you could make complete sentences..
[2017-11-25 17:17:48] <edmondo1984> Hello guys, how do I find the docker-host ip on my macos?
[2017-11-27 04:44:49] <stevecordrey> Is it possible to clone the data from an existing volume to a new one?
[2017-11-27 05:16:48] <denel-manilov> gkatsanos: Hi!About environment variables (question from stackoverflow):Add to Dockerfile: RUN echo "NODE_ENV var is: $NODE_ENV"This will allow you to see the variable when building the image (if problem is in the environment variables)
[2017-11-27 05:24:45] <denel-manilov> docker-compose.test.yml and docker-compose.ymlWhat's the problem with running these configurations?
[2017-11-27 05:30:35] <denel-manilov> stevecordrey:  [<-LINK->]  [<-CODE->] 
[2017-11-27 05:31:04] <stevecordrey> Awesome. Thanks@denel-manilov
[2017-11-27 05:35:27] <denel-manilov> edmondo1984:  [<-LINK->] 
[2017-11-27 10:47:59] <ofri84> hey, i'm trying to make amazonlinux to start sshd on startup
[2017-11-27 10:48:02] <ofri84> no luck so far
[2017-11-27 11:52:03] <mpathy> Hi There.. I have an docker with an old installation of PHP5.3 because I need it for transition of a project.. I link the web directory into the docker.. But now I dont have the right User and Group inside Docker to make the files run with Apache.. Can I tell Docker to rewrite the user and group he gets to another, inside the container
[2017-11-27 11:55:49] <YoannMa> mpathy: I don't know if you can do it directly with Docker. If you can't,  you can use this : [<-LINK->] 
[2017-11-27 13:44:54] <papaiatis> Hi guys. In a Dockerfile, how can I run some command if, and only if a given environment variable exists and has a specific value?So ifENVIRONMENT=productionthen callRUN "...."
[2017-11-27 13:56:10] <denel-manilov> papaiatis: Use build args: [<-LINK->] 
[2017-11-27 14:07:25] <papaiatis> denel-manilov: and how should I use ARG in a control statement?
[2017-11-27 14:19:27] <denel-manilov> Dockerfile [<-CODE->] Build: [<-CODE->] 
[2017-11-27 14:21:01] <papaiatis> Thanks!
[2017-11-27 17:05:02] <outkaj> if i declare two volumes for two separate containers in docker-compose which have different names, but the same filepath, is the containers' data stored separately or is it shared? i'd like the former use case (separate data) but with the convenience of not having to specify a different filepath for each container. I am happy to clarify if my explanation is unclear
[2017-11-27 17:27:40] <outkaj> update: looks like i can do this (data will be stored separately as long as the names are different, even if filepath the same). thanks!
[2017-11-27 18:02:35] <rightisleft> If i need to give a secondary user access to the docker daemon using the official docker-dind image - whats the proper group requirements?
[2017-11-27 18:02:37] <rightisleft>  [<-LINK->] 
[2017-11-27 18:04:54] <denel-manilov>  [<-LINK->] 
[2017-11-27 18:07:03] <rightisleft> will that work for dind? i didnt see a def docker group
[2017-11-27 18:07:32] <rightisleft> only dockremap
[2017-11-27 18:09:24] <denel-manilov> Create group and add to user
[2017-11-27 18:44:44] <leviyehonatan> i'm trying to get some environment variables to the running docker so i can use it in scripts. i thought that ENV will do the trick but apparently it doesnt
[2017-11-27 18:45:36] <rightisleft> i'm still getting permission denied
[2017-11-27 18:46:05] <rightisleft> /etc/group has -> docker1001:go
[2017-11-27 18:48:54] <rightisleft> so when i look at the group who owns the sock file, inside the go container, it saysroot        993
[2017-11-27 18:49:06] <rightisleft> what is group 993?
[2017-11-27 18:49:21] <rightisleft> is that the host machines group?
[2017-11-27 18:49:48] <rightisleft> do they have to match?
[2017-11-27 19:08:24] <leviyehonatan> environment variables anyone?
[2017-11-27 19:51:47] <denel-manilov> leviyehonatan: see above, the message at 18:19
[2017-11-27 19:52:10] <denel-manilov> rightisleft: 
[2017-11-27 19:53:01] <denel-manilov> Inside container?
[2017-11-27 19:53:31] <denel-manilov> $ cat /etc
[2017-11-27 19:53:39] <leviyehonatan> i have a container which must accept git commits over ssh, i am not sure yet if this is the best practice or way
[2017-11-27 19:53:46] <leviyehonatan> its a machine to receive code, build and deploy it
[2017-11-27 19:55:05] <leviyehonatan> and i now see in the dockerized sshd example they say that the env commands wikl be discarded because the way the sshd is run(using CMD)
[2017-11-27 19:58:09] <leviyehonatan> so@denel-manilovi guess i can do the echo "export VAR=X" >> /etc/profile trick
[2017-11-27 19:58:32] <leviyehonatan> but then i repeat some lines in my Dockerfile since i need them for the build process as well
[2017-11-27 20:15:16] <denel-manilov> leviyehonatan: problem solved?
[2017-11-27 20:15:30] <leviyehonatan> ya
[2017-11-27 20:15:35] <denel-manilov> Ok
[2017-11-27 20:15:49] <leviyehonatan> the whole ssh and docker thing is pretty tricky to grasp
[2017-11-27 20:18:28] <denel-manilov> Do you want to build an image based on the code that is in the repository?
[2017-11-27 20:18:40] <leviyehonatan> yes
[2017-11-27 20:18:53] <leviyehonatan> and i want it to keep running and be update on post-receive
[2017-11-27 20:20:08] <denel-manilov> wow
[2017-11-27 20:37:13] <leviyehonatan> wow
[2017-11-27 20:37:18] <leviyehonatan> denel-manilov: 
[2017-11-27 20:37:21] <leviyehonatan> ?
[2017-11-27 20:37:41] <leviyehonatan> what does your wow refer to
[2017-11-27 20:44:27] <denel-manilov> an image is usually contains a specific version of the application
[2017-11-27 20:44:58] <leviyehonatan> yes, i know but what if you want to update
[2017-11-27 20:45:38] <leviyehonatan> for dev its very helpful
[2017-11-27 20:46:16] <leviyehonatan> and i have another question, how is docker is intended to use for deployment?
[2017-11-27 20:46:41] <leviyehonatan> how do i get amazon to run my dockerfile/image?
[2017-11-27 20:51:55] <denel-manilov> For dev use volumes, to see instantly the code change
[2017-11-27 21:00:31] <denel-manilov> The deployment of applications depends on the infrastructure and the instrument of orchestration
[2017-11-27 21:00:58] <leviyehonatan> volumes? is that docker?
[2017-11-27 21:01:35] <leviyehonatan> infrastructure? could that be amazon ec2 in my case?
[2017-11-27 21:03:35] <leviyehonatan> can you give an example?
[2017-11-27 21:03:42] <denel-manilov>  [<-LINK->] 
[2017-11-27 21:05:13] <leviyehonatan> i understand, but where does volumes come in handy in my case?
[2017-11-27 21:05:25] <leviyehonatan> how do i instantly see code change using volumes
[2017-11-27 21:09:38] <leviyehonatan> that
[2017-11-27 21:09:51] <leviyehonatan> that's pretty close maybe to my aim: [<-LINK->] 
[2017-11-27 21:16:16] <denel-manilov> for example, you are developing a site on the PHP so as not to build an image for each code change you mount the volume with the directory of your code inside the container
[2017-11-27 21:18:41] <leviyehonatan> so you can change the code outside the container?
[2017-11-27 21:19:08] <leviyehonatan> thats useful but what i am trying to do is to be able to push code to update a remote server
[2017-11-27 21:19:15] <leviyehonatan> no need for volumes for that
[2017-11-27 21:19:32] <leviyehonatan> is docker meant to be used in production this way at all?
[2017-11-27 21:19:46] <leviyehonatan> i am sort of using docker as a configuration tool, aren't everybody?
[2017-11-27 21:21:52] <leviyehonatan> while we are at it. how would you go about getting a git clone to happen once server starts? would you do it in the build? or after? how do i instruct something to be called on startup
[2017-11-27 21:25:30] <denel-manilov> I can not respond so quickly from the mobile version Gitter)
[2017-11-27 21:25:46] <leviyehonatan> oh sorry
[2017-11-27 21:26:05] <leviyehonatan> if you answer later i will appreciate
[2017-11-27 21:29:44] <denel-manilov> I will try to show the simplest example of a working process with Docker.
[2017-11-27 21:31:59] <denel-manilov> local dev - git push - ci/cd build image and push to registry and update service
[2017-11-27 21:32:04] <denel-manilov> Done)
[2017-11-27 21:32:37] <leviyehonatan> update service?
[2017-11-27 21:34:06] <denel-manilov> Yes, remove old and run new
[2017-11-27 21:34:17] <leviyehonatan> how is that done?
[2017-11-27 21:34:23] <leviyehonatan> on amazon for example
[2017-11-27 21:50:21] <denel-manilov> I can not give an example for Amazon, because I use bare metal
[2017-11-27 21:50:37] <leviyehonatan> if i used amazon?
[2017-11-27 21:50:52] <leviyehonatan> i must run my production server on some remote server
[2017-11-27 21:51:17] <denel-manilov>  [<-LINK->] 
[2017-11-27 21:58:26] <denel-manilov> try using a docker swarm on docker-machine locally
[2017-11-27 21:58:45] <denel-manilov> for experiments
[2017-11-27 21:59:12] <leviyehonatan> and for production?
[2017-11-27 22:01:15] <leviyehonatan> in the link you sent they state amzon ecs
[2017-11-27 22:06:22] <denel-manilov> Look at the Amazon website that they offer for orchestrating containers
[2017-11-28 05:25:49] <b1alpha> Good evening, I have a configuration question of the php-fpm/nginx/xdebug variety does anyone happen to know this
[2017-11-28 05:26:21] <b1alpha> I keep getting a [<-CODE->] 
[2017-11-28 05:27:19] <b1alpha> and the breakpoint is not respected, its like the chrome:ext just does not pass it to phpstorm
[2017-11-28 05:28:34] <b1alpha>  [<-CODE->] 
[2017-11-28 05:29:47] <b1alpha> thanks in advance, cpt. ace (rimmer)
[2017-11-28 05:30:24] <b1alpha> I spent a 9hr day on it so anything helps and im 35
[2017-11-28 06:22:40] <anshulpatel25> Hey I am using Docker 17.09 on CentOS - 7 systemCurrenly (by default) it is using journald for engine logsIs there any way I can change or log to syslog?
[2017-11-28 10:17:02] <jemliF> hi
[2017-11-28 10:17:24] <jemliF> I am unable to share a drive with docker in windows 10
[2017-11-28 13:54:27] <anshulpatel25> Hey I am currently using 17.09 with CentOS 7.4. I created custom nameserver entry in/etc/resolv.confon CentOS. I am able to resolve the domains on OS but when I try to resolve in container it is not doing so any idea?
[2017-11-28 15:53:39] <spences10> I can't uninstalldocker.iofrom my WSL
[2017-11-28 15:53:46] <spences10> I have tried all sorts
[2017-11-28 15:54:05] <spences10> Considering uninstalling WSL and starting over
[2017-11-28 15:54:17] <spences10> Anyone else have this?
[2017-11-28 15:54:41] <spences10> I used Linux brew to install docker I think not sure about docker.io
[2017-11-28 16:00:05] <denel-manilov> anshulpatel25:  [<-LINK->] 
[2017-11-28 16:01:18] <denel-manilov> anshulpatel25:  [<-LINK->] 
[2017-11-29 10:15:43] <jemliF> hi
[2017-11-29 10:16:01] <jemliF> I have this instruction in a Dockerfile:RUN wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.6/install.sh | bash && export NVM_DIR="$HOME/.nvm" && [ -s "$NVM_DIR/nvm.sh" ] && . "$NVM_DIR/nvm.sh" && nvm install v6.10.2
[2017-11-29 10:16:51] <jemliF> It works good excepting that in the next instructionRUN npm -v
[2017-11-29 10:17:06] <jemliF> I gotnpm undefined
[2017-11-29 10:17:57] <jemliF> when I dive into the built container andnpm -vI get 6.10.2
[2017-11-29 10:19:00] <jemliF> its like it installs node but when running npm just after the installation in the Dockerfile it returnsundefined
[2017-11-29 10:20:05] <jemliF> Who knows a solution? my goal is to install node version6.10.2and npm version4.1.2after all
[2017-11-29 11:01:16] <SISheogorath> why do you run nvm inside a docker container? O.o
[2017-11-29 11:17:49] <jemliF> SISheogorath: I need to install a specific version of node
[2017-11-29 11:22:14] <SISheogorath> Isn't that version available on docker hub?
[2017-11-29 12:42:13] <jemliF> SISheogorath: I don't need the image, I need to install node in a Dockerfile
[2017-11-29 12:44:13] <jemliF> SISheogorath: I keep getting this error:ERROR: Service '...' failed to build: The command '/bin/sh -c npm -v' returned a non-zero code: 127
[2017-11-29 14:55:30] <sudorobot> basic question, I’m new: I have pulled an image from docker hub, how do I turn this image into a working directory? How do I edit the files and work with them? I can’t even find them
[2017-11-29 15:06:58] <SISheogorath> sudorobot: That's not how docker works. Docker is not git. In docker you download an image which is ready to use. Sometimes you need to use a bindmount to add or edit some config files, but the better way is to either extend an image if you need to add configs or make it configurable by environment variables
[2017-11-29 15:07:53] <sudorobot> I see, thanks!
[2017-11-29 15:16:05] <mathematics0> Hi, can I ask a question about rabbitmq on docker container here
[2017-11-29 15:20:06] <mathematics0>  [<-LINK->] 
[2017-11-29 15:20:10] <mathematics0> hangs here forever
[2017-11-29 19:37:14] <relwell> Hi there, is it possible to attach a particular port on localhost to a build context so that I can make HTTP requests to that port during the build phase?
[2017-11-30 12:17:54] <plagov> Hello. Does anyone manage to connect USB/Serial peripheral devices to containers on Windows?
[2017-11-30 12:19:23] <plagov> I heard it was not supported with Windows Containers. Was reading today news about LCOW, but didn't find any mentions of that...
[2017-11-30 12:35:43] <siassaj> okies
[2017-11-30 12:36:39] <siassaj> so i need to be able to mount the host machines' git app dir into the 'web' docker compose container. But this git app  path differs from developer to developer
[2017-11-30 12:37:01] <siassaj> is there a way to docker-compose up and specify this mount path?
[2017-11-30 16:02:26] <outkaj> Hello, is it possible to have "EXPOSE" point to an environment variable?
[2017-11-30 18:19:37] <outkaj> fixed in case anyone was curious by using expose in docker-compose instead
[2017-11-30 21:01:33] <Cosbgn> Hello, is anyone online who can help me a bit? I'm trying to figure out this whole docker thing, moving from virtual environments, I use django but I guess that's not so important at this stage
[2017-11-30 21:02:02] <Cosbgn> I've read the documentation and my app is now happily running on 0.0.0.0
[2017-11-30 21:02:21] <Cosbgn> I'm having troubles figuring out the database and environments
[2017-11-30 21:03:12] <Cosbgn> I'm trying to connect to a local postgresql database, but I'm having troubles since docker obviously can't find it as it's not in the container
[2017-11-30 21:04:28] <Cosbgn> 2nd I also have troubles figuring out the.envfiles, should I just through in a prod.env file all my production variables  and when deploying to production add the --env-file:prod.env flag?
[2017-12-01 03:24:26] <xxLogicxx> Hey guys, I am applying for a software development job in Golang, but I need help with building the project that they want me to present. If someone could please help me that would be greatly appreciated.
[2017-12-01 05:06:44] <jyprksh001> Can I share data to a container using bash
[2017-12-01 05:08:22] <jyprksh001> I am running the compilers in containers and the nodejs application needs to share data with compilers
[2017-12-01 05:09:23] <denel-manilov> jyprksh001: Use Volumes: [<-LINK->] 
[2017-12-01 05:35:04] <denel-manilov> @Cosbgn Use "host" network. Connect to a host IPI\'m trying to connect to a local postgresql database, but I\'m having troubles since docker obviously can\'t find it as it\'s not in the containerhttps://docs.docker.com/engine/userguide/networking/
[2017-12-01 05:41:20] <denel-manilov> @Cosbgn [<-CODE->] I would use the ENV file for development, and in the Dockerfile variables for production, to reduce the dependencies
[2017-12-01 06:00:04] <denel-manilov> @relwell Use "host" network. Connect to a host IP https://docs.docker.com/engine/userguide/networking/Dockerfile: [<-CODE->] Build image: docker build --network host --build-arg HOST_IP=<HOST IP> --tag myimage:latest .
[2017-12-01 08:04:00] <lanwin> Hi, I am having a swarm mode cluster running between a linux and a windows host and trying to deploy a steck between them. Everything deployes fine but my problem is that both containers can not reach each other. How can I debug the problem?
[2017-12-01 08:05:14] <lanwin> What I can see is that both machines have created that overlay network but on both machines only the container which is running on that machine is listed in the network
[2017-12-01 08:08:02] <lanwin> Both machines list each other under peers but they can not ping each other
[2017-12-01 09:17:57] <grofit> Anyone here have any expericence with windows containers and nanoserver?
[2017-12-01 09:18:11] <grofit> (or other windows images)
[2017-12-01 09:19:02] <Cosbgn> denel-manilov: thanks for helping out
[2017-12-01 09:20:05] <Cosbgn> so you would use hardcoded database username & password for production in the Dockerfile and a dev.env file which overwrites those variables while local?
[2017-12-01 09:20:50] <Cosbgn> and then I use something like .dockerignore to skip uploading compleately my dev.env so docker picks up directly the vars in the docker file
[2017-12-01 09:20:57] <Cosbgn> right?
[2017-12-01 09:34:33] <siassaj> so yeah
[2017-12-01 09:35:01] <siassaj> is it possible to run docker-compose and specify the host mount directory ?
[2017-12-01 09:36:14] <siassaj> I'm making this up, but maybe something along the lines of 'docker-compose up --mount <name> /path/to/app/git/dir'
[2017-12-01 12:15:40] <Cosbgn> Hello everyone, it's again me with all my  problems..
[2017-12-01 12:15:49] <Cosbgn> I get docker to run my app
[2017-12-01 12:16:14] <Cosbgn> it tells me that [2017-12-01 12:05:53 +0000] [14] [INFO] Listening at: [<-LINK->] (14)
[2017-12-01 12:16:27] <Cosbgn> however nothing loads on 0.0.0.0:8000
[2017-12-01 12:16:49] <Cosbgn> I'm not sure where to find my app. I looked up the IP for nginx, and for the django app
[2017-12-01 12:17:02] <Cosbgn> i.e. [<-LINK->] and [<-LINK->] 
[2017-12-01 12:17:13] <Cosbgn> but also there nothing...
[2017-12-01 12:17:20] <Cosbgn> where it's running>
[2017-12-01 12:17:22] <Cosbgn> ??
[2017-12-01 13:18:22] <grofit> your local docker container may be running at 8000 but you need to expose that port right?
[2017-12-01 13:18:37] <grofit> so you may map that port from the container (8000) to the host (23456)
[2017-12-01 13:18:51] <grofit> so then it would be localhost:23456
[2017-12-01 15:59:07] <denel-manilov> @siassaj Command  "docker-compose up" does not have the option: --mountI\'m making this up, but maybe something along the lines of \'docker-compose up --mount <name> /path/to/app/git/dir\'
[2017-12-01 16:01:14] <denel-manilov> @siassaj https://docs.docker.com/compose/compose-file/#volumesis it possible to run docker-compose and specify the host mount directory ?
[2017-12-01 16:04:13] <denel-manilov> @Cosbgn if port 8000 is exposed that: http://localhost:8000where it's running?
[2017-12-01 16:06:45] <denel-manilov> docker ps [<-CODE->] 
[2017-12-01 16:09:04] <Cosbgn> denel-manilov: I manage to get it to work changing the conf on nginx.conf
[2017-12-01 16:09:54] <Cosbgn> however I'm still confused by one thing. I have a backend in python and a frontend in Vue.js, should I dockerize only my backend as vue once built it's just a js file
[2017-12-01 16:10:14] <Cosbgn> or I should run a node image with webpack and everything in it
[2017-12-01 16:10:25] <Cosbgn> how do people usually do it?
[2017-12-01 16:14:33] <denel-manilov> you should get two containers: Frontend (nginx with static files css, js, 404.html, etc) and Backend (python application)
[2017-12-01 16:16:15] <Cosbgn> at the moment I have 4 images: [<-CODE->] 
[2017-12-01 16:16:26] <Cosbgn> does it makes sense?
[2017-12-01 16:17:32] <Cosbgn> and 2 dockefiles
[2017-12-01 16:18:30] <denel-manilov> does it makes sense?yes, you just wrote about Vue.js and Python. I did not know that you have more services )
[2017-12-01 16:21:21] <denel-manilov> why do you have a prefix: ANALYTICME_ ?The docker-compose creates it automatically from the name of the directory in which the docker-compose.yml file
[2017-12-01 16:22:15] <Cosbgn> oh I see
[2017-12-01 16:22:26] <Cosbgn> I just read that it needs to be a unique name, that's why
[2017-12-01 16:22:37] <Cosbgn> better if I can remove it
[2017-12-01 16:23:05] <Cosbgn> however it keeps failing telling me that/bin/sh: 1: npm: not found
[2017-12-01 16:23:19] <Cosbgn> my DockerfileNode is super simple
[2017-12-01 16:23:50] <Cosbgn>  [<-CODE->] 
[2017-12-01 16:31:47] <denel-manilov>  [<-CODE->] it's strange, I do not see an error
[2017-12-01 16:32:38] <Cosbgn> I've deleted everything and rebuilt
[2017-12-01 16:33:47] <denel-manilov> did it fix the error?
[2017-12-01 16:34:42] <Cosbgn> yes but I get [<-CODE->] 
[2017-12-01 16:35:30] <Cosbgn>  [<-LINK->] 
[2017-12-01 16:35:38] <Cosbgn> my path looks like this
[2017-12-01 16:42:02] <denel-manilov> check the Webpack configuration
[2017-12-01 16:42:12] <denel-manilov> Sorry, but I do not know much about webpack
[2017-12-01 16:43:03] <Cosbgn> But I think it's docker not finding the file no?
[2017-12-01 16:44:30] <denel-manilov> These errors occurred when:npm run dev
[2017-12-01 16:45:42] <denel-manilov> Showpackage.json
[2017-12-01 16:47:47] <Cosbgn>  [<-CODE->] 
[2017-12-01 18:09:46] <denel-manilov>  [<-LINK->] 
[2017-12-03 05:55:35] <koolay> How can I get the mac/hardware id of host in container ?
[2017-12-03 05:56:04] <JasonShin> yo guys
[2017-12-03 05:56:14] <JasonShin> can I ask about kubernetes here?
[2017-12-03 06:18:52] <PRIMETSS> koolay Linux or Windows container?
[2017-12-03 06:19:11] <PRIMETSS> Found this from Docker CLI \'docker inspect <container name or id> |grep MacAddress|tr -d \' ,"\'|sort -u\'
[2017-12-03 06:22:08] <koolay> I want to license my app binding with the host,  and my app deployed with container.
[2017-12-03 06:23:35] <koolay> So,  need to get host id(MAC/host name etc.) on runtime.
[2017-12-03 06:23:51] <PRIMETSS> what language?
[2017-12-03 06:24:18] <koolay> cython
[2017-12-03 06:25:16] <PRIMETSS> ok, not sure about cython, but have you just tried obtaining MAC from its API? assuming it has that. Guess you will get back the hosts MAC address, interesting
[2017-12-03 06:29:11] <PRIMETSS> can you just call python [<-LINK->] 
[2017-12-03 06:29:19] <koolay> obtained only container’s MAC in container
[2017-12-03 06:37:58] <PRIMETSS> which is different to the host's?
[2017-12-03 06:38:04] <koolay> Maybe I’ll using anther solution. Running a license server in host, then the app verify license  with license server, since license server can obtain id of host.
[2017-12-03 06:39:36] <PRIMETSS> yeah thats what I was thinking... seems a bit cluncky to have to call another service outside of container, but then again if it works that way, why not
[2017-12-03 06:40:09] <koolay> MAC of container is changed
[2017-12-03 06:41:39] <PRIMETSS> interesting to know its another MAC? was wondering what you would see... MACs are partly bound to Manufacture of NIC, so was the container MAC a 'psuedo' MAC or still had the hardware owners identifier in it?
[2017-12-03 06:44:44] <koolay> sudo docker run --rm --mac-address"=12:34b0:6b:61" ubuntu ifconfig | grep HWaddreth0      Link encap:Ethernet  HWaddr 12:34b0:6b:61
[2017-12-03 06:44:49] <koolay>  [<-LINK->] 
[2017-12-03 06:47:14] <PRIMETSS> hmmm, but doesnt that mean someone can just spoof the MAC address and bypass what your planing. IF im following
[2017-12-03 06:52:49] <koolay> oh. I need to license my app bound the host.
[2017-12-03 06:59:52] <PRIMETSS> sure but from above, are you know just spoofing an address any way?
[2017-12-03 07:00:02] <PRIMETSS> know aka not
[2017-12-03 13:22:50] <bluemmb> Hi everyone
[2017-12-03 13:23:33] <bluemmb> Can we ask about the opinion of members on the architecture of dockerizing our app ?
[2017-12-03 15:21:26] <Cosbgn> hey everyone, I have docker running fine on my localhost
[2017-12-03 15:22:04] <Cosbgn> however when I change some code I need to run againdocker-compose up --buildso that it's reflected
[2017-12-03 15:22:25] <Cosbgn> I'm trying to understand how to avoid that in development
[2017-12-03 15:22:42] <Cosbgn> I think that I understood that using volumes is the way to go
[2017-12-03 15:23:31] <Cosbgn> is that right?
[2017-12-03 15:24:05] <Cosbgn> on my nginx image I have these volumes: [<-CODE->] 
[2017-12-03 15:24:40] <Cosbgn> while on my web I have: [<-CODE->] 
[2017-12-03 15:25:32] <Cosbgn> does this.:/codemeans: the local folders in this path (.) represent the folders in the container under the path/code?
[2017-12-03 15:26:23] <Cosbgn> if this is the case, why it doesn't work?
[2017-12-04 18:09:44] <przemolb> Guys, do you have an idea how to manage hundreds or thousands of docker containers each with volume mounted on a host(s) ? Any tools helping with it ?
[2017-12-04 18:21:17] <gaborvecsei> How can I switch between training on CPU and GPU?I need 2 different environments with the different tensorflow versions?
[2017-12-04 19:10:34] <collin5> przemolb: I think you can usedocker composefor that, unless you need anything in particular.
[2017-12-04 22:25:00] <niklas-sm> Hey there! I\'m trying to write a Jenkins pipeline job to do a simple CI loop (building a few dockerfiles, pushing images, and then running some tests on downstream code that uses these images). To have everything scripted and visible for reviewers, I\'d like to run this CI loop from within a container on a jenkins slave. I\'ve found a few useful resources talking about this model. Can anyone help me with a few quick questions? First, is this a reasonable use-case (running one container from which to build and push a few other containers), or should I use some other tool to script my CI build environment (maybe using Packer to make a suitable AMI for my worker), and then just rundocker build ...anddocker push ...from a plain linux environment? Second, assuming this is a reasonable use case, is there an authoritative resource I should refer to for this type of configuration? I am bind mounting the docker socket into the "outer" container, but I\'m not sure how to start the docker daemon inside that container (attempting a simple minded approach of just doingsystemctl start dockerin the container  fails with "Failed to get D-Bus connection: Operation not permitted")
[2017-12-04 23:40:01] <przemolb> collin5: sorry but I think I haven't described my scenario precisely enough - all the containers (100s, or 1000s) use volumes. But because the containers are disposable they can be started again on another host. What happens with the volumes ? How to do track them ?
[2017-12-05 00:24:02] <cheenamalhotra> przemolb: When you create a volume, it is stored within a directory on the Docker host. When you mount the volume into a container, this directory is what is mounted into the container. This is similar to the way that bind mounts work, except that volumes are managed by Docker and are isolated from the core functionality of the host machine.A given volume can be mounted into multiple containers simultaneously. When no running container is using a volume, the volume is still available to Docker and is not removed automatically. You can remove unused volumes using docker volume prune.
[2017-12-05 00:30:16] <cheenamalhotra> Cosbgn:  [<-ISSUE->] have a look!
[2017-12-05 14:55:17] <crebuh> Hey guys, anybody here who is docker in combination with frontend apps, for example build with angular?
[2017-12-05 17:09:57] <outkaj> Hey all, probably something simple I'm missing, but I'm trying to restore data from a backup like this:docker run --rm \\\n --volume VOLUME_NAME:/tmp/data \\\n --volume $(pwd):/tmp/backup \\\n alpine:latest \\\n tar xvf BACKUP_ARCHIVE -C /tmp/data --strip 1\ndocker cp /tmp/data CONTAINER_NAME:VOLUME_DIRECTORY_ON_CONTAINER. However, when I stop and start CONTAINER_NAME, I still see the old data, rather than the restored volume. What else should I do to make this work (or is there a better way I'm missing?)
[2017-12-05 17:14:09] <outkaj> przemolb: I wonder if something like this would be helpful to you as a volume management tool? ( [<-LINK->] ). Rancher in general will probably help as well since you have so many containers
[2017-12-06 08:55:58] <lanwin> Hi. What options do I have to discover service endpoints (from outside of the cluster) in a Swarm Mode cluster when Ingress is not available?
[2017-12-06 14:46:48] <grofit> When I do adocker build .what is actually happening at a high level? I assumed it would create a container for this but not run it, but it does appear to run the container too, so is a docker build basically doing a run as well?
[2017-12-06 14:56:52] <OnamChilwan> Hi all, is this the place for docker windows too or is there a seperate channel for this?
[2017-12-06 14:59:21] <grofit> I am using docker for windows (with windows containers) currently
[2017-12-06 14:59:27] <grofit> but its often quite dead in here
[2017-12-06 14:59:34] <OnamChilwan> lol OK
[2017-12-06 14:59:35] <grofit> but know of no better place to ask questions
[2017-12-06 14:59:48] <OnamChilwan> would you mind if I pick your brain please :)
[2017-12-06 15:02:02] <pjetr> I tend to create a post on [<-LINK->] and try to get a discussion on the roll here :-D
[2017-12-06 15:03:59] <OnamChilwan> I am having issues with configuring a dockerfile using aspcore
[2017-12-06 15:04:44] <OnamChilwan> simple setup works fine (single project file) but when I have a project file referencing another project file I am having issues
[2017-12-06 15:06:54] <jclagache> OnamChilwan: What issues ?
[2017-12-06 15:11:19] <OnamChilwan> so I have a setup which is like this:.slnProject1/Project1.csproj\nProject1/Dockerfile\nProject2/Project2.csprojProject1 references Project2
[2017-12-06 15:11:32] <OnamChilwan> Docker file looks like [<-CODE->] 
[2017-12-06 15:12:32] <OnamChilwan> However, it fails suggesting an error: CS5001 no suitable entry point for /app/Project1.csproj.
[2017-12-06 15:13:00] <OnamChilwan> But I definately have aprogam.csand an entry pointstatic void main
[2017-12-06 15:14:53] <jclagache> S5001 no suitable entry point for /app/Project1.dllright ?
[2017-12-06 15:15:11] <OnamChilwan> yeah
[2017-12-06 15:15:16] <OnamChilwan> sorry no
[2017-12-06 15:15:40] <OnamChilwan> it actually says no suitable entrypoint for the/app/Project1.csproj
[2017-12-06 15:15:46] <OnamChilwan> I know that is weird
[2017-12-06 15:16:30] <OnamChilwan> don't know why its got a hold of the.csprojas opposed to thedll
[2017-12-06 15:17:39] <OnamChilwan> it looks like the publish fails
[2017-12-06 15:17:47] <OnamChilwan> however if I run that on my machine it works fine
[2017-12-06 15:18:10] <OnamChilwan> I have tried running the container in an interactive terminal and get the same issue
[2017-12-06 15:18:43] <OnamChilwan> as in via the terminal rundotnet publishand it can't detect an entry point
[2017-12-06 15:24:33] <grofit> hmm not done that yet, we just copy out build output directly over to an iis running container
[2017-12-06 15:24:41] <grofit> so dont do the actual build on the container (Atm)
[2017-12-06 15:24:49] <grofit> hardest bit is trying to get clamav runnign on windows :(
[2017-12-06 15:25:15] <grofit> I have a docker container that does it, but it seems to RUN it when it build so it never finishes the build
[2017-12-06 15:25:24] <grofit> as its just running .... so not sure what to do there
[2017-12-06 15:27:30] <jclagache> Project1 is a console application ?
[2017-12-06 15:27:49] <OnamChilwan> web api app
[2017-12-06 15:28:21] <OnamChilwan> I have replicated this. Just added a new Web Application project and hitdocker buildsame thing [<-CODE->] 
[2017-12-06 15:31:08] <grofit> OH....
[2017-12-06 15:31:11] <OnamChilwan> jclagache: I guess everything in core is a console application
[2017-12-06 15:31:24] <grofit> IsEntryPointmeant to be the starting RUN to do?
[2017-12-06 15:31:29] <grofit> I think thats where I am going wrong :)
[2017-12-06 15:36:40] <OnamChilwan> grofit: not sure what you mean :)
[2017-12-06 15:37:46] <jclagache> COPY . ./before publish
[2017-12-06 15:43:16] <jclagache> you only have copied the project files
[2017-12-06 15:50:42] <OnamChilwan> Thats the only thing thats required right?
[2017-12-06 15:51:25] <OnamChilwan> as the restore and publish will resolve everything else it needs
[2017-12-06 15:54:13] <jclagache> that's what I see missing
[2017-12-06 15:54:22] <grofit>  [<-LINK->] 
[2017-12-06 15:54:33] <grofit> Originally I didnt have the entry point and was wondering why the docker build was just running forever
[2017-12-06 15:54:48] <grofit> but then once I saw your bit I realised I needed to have the last commandclamdto be an entry point
[2017-12-06 15:58:49] <OnamChilwan> this is me just trying to get it to run locally
[2017-12-06 16:01:45] <grofit> yeah yeah, but thanks to seeing your stuff, it helped me solve my own
[2017-12-06 16:01:47] <grofit> so as you were soldier
[2017-12-06 16:01:49] <grofit> nothing to see here
[2017-12-06 16:03:26] <OnamChilwan> lol OK :)
[2017-12-06 16:48:12] <jclagache> OnamChilwan: I've reproduced your pb and successfully resolved it withCOPY . ./
[2017-12-06 16:58:37] <OnamChilwan> Oh
[2017-12-06 16:58:49] <OnamChilwan> can you post your dockerfile please@jclagache
[2017-12-06 17:00:24] <OnamChilwan> oh my dear lord!
[2017-12-06 17:24:42] <OnamChilwan> That worked.
[2017-12-07 08:27:23] <echiphn> Hi guys, last time I've tried to run docker on Mac Os and got a big issue with mount point between host machine and container. I've tried to share a java working directory but the IO speed in container is extreme slow. The web application can not run inside container. I've found some doc in docker page talked about this issue. But I haven't found any good solution from Docker for this issue ...
[2017-12-07 08:34:02] <rkitover> you could try SMB or something, or just copy the directory if you can do that
[2017-12-07 09:27:57] <grofit> I have a windows container which runs fine locally
[2017-12-07 09:28:10] <grofit> but when I pushed it up to docker hub it doesnt work, no errors
[2017-12-07 09:28:25] <grofit> DockerHub does support windows images from what I can tell
[2017-12-07 09:28:30] <grofit> so is there anything magic I need to do?
[2017-12-07 09:28:52] <grofit> the output from the push was: [<-CODE->] 
[2017-12-07 09:31:14] <grofit> and if I dodocker run myimageit runs fine, no problems
[2017-12-07 09:31:28] <grofit> if I get the version from docker hub and run it, just hangs
[2017-12-07 09:32:18] <echiphn> rkitover: actually that is what I don't want. I want to synchronize between theses folders. I'm trying to implement Vagant concept using Docker. Developer can use any Idea ,editors he want to edit the code, but to test and run app he has to have same infrastructure like other guys
[2017-12-07 10:30:54] <grofit> hmm think it may be something to do with Kitematic as it works fine if I do a command line run, just when doing it through kitematic it falls over
[2017-12-07 16:41:47] <miriam-z> Hi I have a ruby and docker set up for application in ruby I have changed my file name and in docker drone in the pipelines my test failed it says that it cannot find the previous file name his go fix this
[2017-12-07 16:48:22] <hinell> Hi guys. Any ideas how to force docker vm machine to use convenient ip4 address version?
[2017-12-07 16:48:45] <hinell> I'm getting only ip6 address: [<-CODE->] 
[2017-12-07 16:58:10] <denel-manilov> hinell: HyperV vm?
[2017-12-07 17:10:31] <denel-manilov> miriam-z: where the file name is changed?
[2017-12-07 18:39:13] <miriam-z> denel-manilov: I have changed the file locally in my feature branch
[2017-12-07 18:44:55] <hinell> denel-manilov: Yep, hyper-v. Already solved by setting --hyperv-virtual-switch explicitly. Now it works properly. IP6 address above is emerging from docker nat internal network. Now it is ok.
[2017-12-07 19:02:08] <denel-manilov> miriam-z: insufficient information about the problem. Perhaps you need to rebuild the image or configure the tests with a new file name
[2017-12-07 23:17:45] <xenoterracide> if I have this [<-CODE->] does that mean I can use overlay but only on xfs?
[2017-12-07 23:19:42] <rkitover> I wanted to commit an exited container, but it told me that it ran out of space, yet I have plenty of space on my drive, what does that mean.
[2017-12-07 23:46:52] <xenoterracide> rkitover: could mean you're out of inodes, I require more evidence
[2017-12-08 01:13:48] <rkitover> well df -h says the overlay is 63G and I used 54G
[2017-12-08 01:14:08] <rkitover> that's not configurable is it
[2017-12-08 03:08:37] <airtonix>  [<-CODE->] the task is : [<-CODE->] 
[2017-12-08 03:12:18] <airtonix> maybe i should also be using the [<-CODE->] flag of git.
[2017-12-08 03:59:17] <airtonix> ugh, wrong channel
[2017-12-08 10:11:21] <fiture> Hi, guys. Is anyway to access the virtual machine in docker for win. Hyper-v
[2017-12-08 10:26:22] <grofit> Hmm tried askign on Kitematic but seems to be dead in there, does anyone know why when running locally this image works, but when I run it in Kitematic from docker hub it doesnt?https://github.com/grofit/docker-s3rver-windows/blob/master/dockerfile [<-CODE->] 
[2017-12-08 12:36:09] <Cosbgn> hello, I can't output my bundle.js in any possible way inside docker. I tried everything, can you please have a quick look here and help me out? [<-LINK->] 
[2017-12-08 12:36:39] <Cosbgn> some help would be reeeeeeeeeeeeeeeeeeeealy appreciated
[2017-12-08 12:58:33] <jsbot> Hello. Guys maybe stupid question but. Where is better place to run MEAN app with docker?
[2017-12-08 13:00:46] <grofit> you just mean a host for your docker image?
[2017-12-08 13:01:01] <grofit> if you want it on the cheap with SSL support look at openshift
[2017-12-08 13:01:11] <grofit> if you want more control over things look at AWS
[2017-12-08 13:02:30] <jsbot> can't find good tutorial how to deploy and run MEAN dockers on AWS
[2017-12-08 13:03:30] <grofit> well just tackle each problem
[2017-12-08 13:03:55] <jsbot> ok.
[2017-12-08 13:04:05] <grofit> you need to run Mongo, Node
[2017-12-08 13:04:22] <jsbot> i need run angular, node and probably mongo
[2017-12-08 13:04:32] <grofit> So thats gonna be a docker compose (I think) which pulls in both a mongo instance (whichever one you want) and a node instance
[2017-12-08 13:04:47] <grofit> Then you need your app container
[2017-12-08 13:04:48] <jsbot> yep locally i'm using it
[2017-12-08 13:04:58] <jsbot> but can't figure out how to do it on aws
[2017-12-08 13:05:01] <grofit> So that would contain the NPM guff for express, ng etc
[2017-12-08 13:05:05] <grofit> forget AWS atm
[2017-12-08 13:05:09] <grofit> just get it running locally
[2017-12-08 13:05:33] <grofit> then just google "docker compose to aws"
[2017-12-08 13:05:38] <jsbot> it's running locally
[2017-12-08 13:05:50] <grofit> oh well you have a docker compose right which marries everything up?
[2017-12-08 13:05:51] <jsbot> but i want deploy it on AWS
[2017-12-08 13:05:56] <jsbot> yep
[2017-12-08 13:06:24] <jsbot> deploy AWS or any other service where i can point to
[2017-12-08 13:06:29] <jsbot> and have it live
[2017-12-08 13:06:30] <grofit>  [<-LINK->] 
[2017-12-08 13:06:36] <grofit> thats the first link on google
[2017-12-08 13:06:43] <grofit> that explains basics
[2017-12-08 13:07:03] <grofit> as the amazon CLI supports the docker compose file
[2017-12-08 13:07:19] <grofit> so you basically just find out the AWS commands and give it your compose file
[2017-12-08 13:07:58] <grofit> you could technically do it all without compose as just a single image which pulls in node and mongo on same container, but I would probably do it as a compose for flexibility and scaleability
[2017-12-08 13:15:42] <jsbot> what if  deploy each container as separate instance?
[2017-12-08 13:15:57] <jsbot> and based on load add new instance?
[2017-12-08 13:18:50] <grofit> this gets onto a more complex debate on how you control individual instances
[2017-12-08 13:18:54] <grofit> and I cannot really help you there
[2017-12-08 13:19:43] <grofit> my understanding is you tell AWS (in this example) what types of instances to provision then give it the compose for the cluster and it provisions the right stuff for you, but I dont know enough about AWS specifically in this scenario to advise further
[2017-12-08 13:23:58] <jsbot> i see
[2017-12-08 13:24:03] <jsbot> thank you
[2017-12-08 13:24:17] <jsbot> will dig more
[2017-12-08 15:58:47] <Richard87> Hi guys! I need some advice :/ I am starting 4 services with docker compose (apache+php, redis, mysql and mailhog), apache is available on port 80, mysql on port 3307 and mailhog on port 8025
[2017-12-08 15:59:09] <Richard87> BUT I can't reach mailhog :/ Everything else works as expected, but I can't open it.. any idea?
[2017-12-08 15:59:30] <Richard87> mailhog log:
[2017-12-08 15:59:31] <Richard87>  [<-LINK->] 
[2017-12-08 16:00:12] <Richard87> Docker-compose: [<-LINK->] 
[2017-12-08 16:07:11] <denel-manilov> Mailhog exposed to host 8085 port
[2017-12-08 16:07:37] <Richard87> yup, I just noticed 
[2017-12-08 16:07:39] <Richard87> thanks :)
[2017-12-08 16:13:05] <xenoterracide>  [<-CODE->] does this mean I can only use xfs for overlay and not ext4?
[2017-12-08 18:05:30] <edmondo1984> Hello, we are running an OpenVPN client locally, and when I tried to reach from inside a docker container on mac running on --net=host the ip of the VPN
[2017-12-08 18:05:32] <edmondo1984> it just takes forever
[2017-12-08 21:16:10] <xenoterracide> can a docker container access it's host network daemon via tcp? instead of socket?
[2017-12-08 21:43:39] <denel-manilov> Yes. The Docker daemon can listen for Docker Engine API requests via three different types of Socket: unix, tcp, and fd.
[2017-12-08 21:45:57] <denel-manilov>  [<-LINK->] 
[2017-12-08 22:34:14] <smashingx1> build a swarm do I have to install docker engine in all the nodes including the master?
[2017-12-09 07:59:12] <denel-manilov> smashingx1: yes
[2017-12-09 16:17:29] <nelson54> What is the recommended way to install docker on Mac? Should I use brew? The "Docker Store"?
[2017-12-10 09:47:35] <SISheogorath> nelson54:  [<-LINK->] 
[2017-12-10 16:43:01] <bluemmb> Hi ... Can docker services load balance such that at each time only one request work on each container ?
[2017-12-10 16:43:14] <bluemmb> and the extra requests are queued for processing
[2017-12-10 18:01:08] <bluemmb> Thanks in advance
[2017-12-11 01:52:43] <SISheogorath> Since docker itself only does L4 load balancing, no. But with the right reverse Proxy it probably possible
[2017-12-11 05:26:40] <bluemmb> SISheogorath: thanks ... reverse proxy inside the container or outside ?
[2017-12-11 05:34:06] <bluemmb> more precisely (if it helps), I am under pressure of my manager to remove RabbitMQ that is serving the workers inside a service and config the Docker Service such that it does the same thing
[2017-12-11 05:34:35] <bluemmb> workers should do only one job at a time
[2017-12-11 10:42:25] <OussamaElgoumri> Hello everyone
[2017-12-11 10:42:32] <OussamaElgoumri> i'am trying to write
[2017-12-11 10:42:42] <OussamaElgoumri> docker cp $container:$file /tmp
[2017-12-11 10:43:36] <OussamaElgoumri> but i get this error Error response from daemon: lstat /var/lib/docker/aufs/mnt/c
[2017-12-11 10:43:49] <OussamaElgoumri> : no such file or directory0d4d14cd/home/test.txt
[2017-12-11 10:44:03] <OussamaElgoumri> and i'am 100% sure the rfile exists?
[2017-12-11 10:44:10] <OussamaElgoumri> anyone know why?
[2017-12-11 14:43:35] <Richard87> Hi guys, I have an application container (php+apache) where all the code etc is inside the docker image... but It's incredibly slow! (again, the container have no volume mounts), it takes about 3-4sec pr request (testet with [<-LINK->] ) while the regular linux host processes a request in 200-300ms... What can I do?
[2017-12-11 16:30:02] <SISheogorath> Richard87: Check the storage driver indocker info
[2017-12-11 16:30:13] <SISheogorath> should beoverlay2oraufs
[2017-12-11 16:43:21] <smashingx1> Does a replica on a swarm mean on how many workers I want my service running?
[2017-12-11 16:44:57] <smashingx1> What I would like to do is to start a service on a swarm (postgresql for example) and then if a worker for a reason fails it has a failover to another server (I currently have 1 manager and 2 workers) so my question is how many replicas do I need?
[2017-12-11 17:05:56] <SISheogorath> A replica is actually only the number of instances of a service should run. This can result in multiple instances run on the same machine. So be aware of that when you deploy something. Also keep in mind you have to take care of replication when you for example run multiple Postgres instances. Or in general how you push the data to your instances.
[2017-12-11 17:06:56] <SISheogorath> So you need some kind of shared and/or replicated storage for your Postgres instance even when you only run one replica but want to to automatically fail over
[2017-12-11 17:07:05] <SISheogorath> smashingx1: ^
[2017-12-11 17:08:53] <smashingx1> SISheogorath: So I can have 1 replica spread along my 2 workers and 1 manager correct?
[2017-12-11 17:10:14] <SISheogorath> yes, but as I said, you have to take care about replicating your persistant data on these hosts
[2017-12-11 17:22:10] <smashingx1> SISheogorath: Does docker take care of this?
[2017-12-11 17:41:23] <SISheogorath> nope
[2017-12-11 18:25:01] <bdaler> hello there. pls help. why i can't access from php container to postgres container ?
[2017-12-11 18:54:07] <roman-1983> hi all!
[2017-12-11 18:54:21] <roman-1983> bdaler: did youlinkthe containers?
[2017-12-11 18:57:52] <roman-1983>  [<-CODE->] What is the best way to this? Should i use networks?
[2017-12-11 19:07:52] <Richard87> Guys, I have a new problem, on Fedora27 this time, suddenly docker didn't list any images or containers, after rebooting, it doesn't start
[2017-12-11 19:07:55] <Richard87> Failed to start Docker Application Container Engine.
[2017-12-11 19:08:19] <Richard87> (I have tried disabling selinux, downgrading/upgrading docker etc, no change :S )
[2017-12-11 20:37:19] <xenoterracide> can you expose the docker api to a container? on a reliable ip?
[2017-12-11 20:39:46] <xenoterracide> Richard87: I saw something recently about Fedora making some recent change to SELinux, and essentially waiting for bug reports to come in
[2017-12-11 20:40:18] <Richard87> Hi, its not a container issue, I can't start Docker at all on the host :/
[2017-12-11 20:40:28] <Richard87> (I have disabled selinux for the time beeing
[2017-12-11 20:41:00] <xenoterracide> Richard87: you might want to go look up that change I was talking about, even if you've disabled SELinux
[2017-12-11 20:41:18] <xenoterracide> and your errors as given aren't actually helpful
[2017-12-11 20:41:42] <Richard87> hehe, thanks, I'll look into it, but what do you mean expose docker api to a container?
[2017-12-11 20:42:40] <Richard87>  [<-LINK->] 
[2017-12-11 20:43:13] <xenoterracide> docker has an api you can connect to over tcp? maybe http? that you can communicate with, and I'm trying to figure out if there's a simple way to expose it to a container app, so that app can communicate with that instead of a volume bound /var/run/docker.sock (or whatever)
[2017-12-11 20:43:16] <Richard87> systemctl start dockerjust hangs (and never completes),,, running it manually dropscontainerd health check returned error: rpc error: code = 14 desc = grpc: the connection is unavailable
[2017-12-11 20:43:47] <Richard87> as I said, I can't run any containers, I can't run docker info or docker ps :/
[2017-12-11 20:43:54] <Richard87> (maybe I'm misunderstanding)
[2017-12-11 20:43:59] <xenoterracide> well that's because your daemon doesn't start
[2017-12-11 20:44:08] <xenoterracide> I'd check your system logs
[2017-12-11 20:44:15] <xenoterracide> journalctl
[2017-12-11 20:44:28] <Richard87> yeah, because I get an error from containerd, grpc: the connection is unavailable
[2017-12-11 20:45:35] <Richard87> I have no idea how to move forward :(
[2017-12-11 20:45:56] <xenoterracide> check your seystem logs
[2017-12-11 20:46:07] <xenoterracide> or is that all the errors in those too?
[2017-12-11 20:46:55] <Richard87> I have some weird erros in the firewall log
[2017-12-11 20:46:59] <Richard87>  [<-LINK->] 
[2017-12-11 20:47:24] <xenoterracide> indeed that looks weird
[2017-12-11 20:47:32] <xenoterracide> but what doesjournalctlsay
[2017-12-11 20:47:59] <xenoterracide> and to investigate those errors I'd start looking at iptables, 'cause it could be your problem
[2017-12-11 20:48:18] <Richard87> nothing at all... systemctl start docker never completes, and never fails
[2017-12-11 20:50:59] <xenoterracide> journalctldidn't log anything? weird
[2017-12-11 20:51:15] <xenoterracide> so yeah, I'd investigate your firewall issues
[2017-12-11 20:51:28] <xenoterracide> could be you're blocking the port
[2017-12-11 20:53:25] <Richard87> thanks, I'll investigate... btw, any idea aboutdocker-containerd?
[2017-12-11 20:53:31] <Richard87>  [<-LINK->] 
[2017-12-11 20:54:36] <xenoterracide> well I see an error in those logs about volume stuff
[2017-12-11 20:54:41] <xenoterracide> so...
[2017-12-11 20:55:04] <xenoterracide> maybe your volume storage is set up wrong?
[2017-12-11 20:55:19] <xenoterracide> and by the way, those logs would have been visible injournalctl
[2017-12-11 20:55:33] <xenoterracide> maybe tryjournalctl -u docker
[2017-12-11 20:55:54] <Richard87> thanks..
[2017-12-11 20:56:06] <Richard87> well that's different!
[2017-12-11 20:56:48] <Richard87>  [<-LINK->] 
[2017-12-11 20:56:49] <Richard87> or maybe not so different :/
[2017-12-11 20:57:30] <SISheogorath> Richard87: Do you run docker-ce from docker.io or from Fedora repos?
[2017-12-11 20:57:53] <Richard87> I have tried both, also a downgraded version from fedora repos
[2017-12-11 20:58:16] <Richard87> I'm running F27, so no updated repos yet, but I installed the F26  package manually
[2017-12-11 20:58:32] <SISheogorath> That's why I'm asking ^^
[2017-12-11 20:58:54] <Richard87>  [<-LINK->] 
[2017-12-11 20:59:20] <Richard87> hehe,  I have been wrestling with this for the last 3 hours without gettinganywhere:/
[2017-12-11 21:01:04] <Richard87> Any clue how to fix this error?FATA[0000] open /run/containerd/io.containerd.runtime.v1.linux/state.json: no such file or directory
[2017-12-11 21:08:33] <Richard87> I deleted the folder/run/containerd/io.containerd....anddocker-containerdstarted
[2017-12-11 21:11:32] <Richard87> and dockerd fails:'(
[2017-12-11 21:12:03] <ShawnAbshire> Greetings all, so I'm struggling to find any resources about using a windows 10 virtual machine to create docker images.  Is this possible?
[2017-12-11 21:17:44] <SISheogorath> Richard87: could you please uninstalldocker-ceand/ordocker, delete/var/lib/docker, rundnf update --refresh, reboot and reinstalldocker?
[2017-12-11 21:17:53] <SISheogorath> then try again what ever you are working on :D
[2017-12-11 21:21:38] <SISheogorath> ShawnAbshire: What host OS are you using?
[2017-12-11 21:23:45] <Richard87> haha, yeah, I'll give it a try ;) Thanks for all your advices ;)
[2017-12-11 21:39:49] <SISheogorath> Richard87: Sry for not coming up with a better solution, but from my perspective it looks like you broke your setup :D
[2017-12-11 21:39:53] <xenoterracide> if you're using overlay, does that mean that your volumes are actually stored in/var/lib/docker/overlay?
[2017-12-11 21:40:03] <Richard87> yeah
[2017-12-11 21:40:08] <Richard87> It seems like it :/
[2017-12-11 21:40:19] <Richard87> Don't realy understand how those drivers work
[2017-12-11 21:40:32] <Richard87> but It seems the data is in the volumes folder
[2017-12-11 21:40:54] <SISheogorath> xenoterracide: storage driver is not volume driver. So no.
[2017-12-11 21:41:15] <xenoterracide> but don't volumes use the storage driver?
[2017-12-11 21:41:15] <Richard87> hmm, I have created a named volume, where all the data is stored?
[2017-12-11 21:41:24] <xenoterracide> just trying to understand how that works
[2017-12-11 21:41:25] <Richard87> which is in ./volume folder?
[2017-12-11 21:41:51] <xenoterracide> since drivers are somewhat newer than my initial understanding of volumes
[2017-12-11 21:42:33] <Richard87> hehe
[2017-12-11 21:42:44] <Richard87> I have no f**clue
[2017-12-11 21:43:00] <xenoterracide> I thought maybe the mad god@SISheogorathdid
[2017-12-11 21:45:18] <SISheogorath> xenoterracide: guess what, volumes use volume-drivers ;)
[2017-12-11 21:45:48] <xenoterracide> so what's a storage driver for then? why should I care about that?
[2017-12-11 21:46:48] <xenoterracide> just trying to ensure that whatever I\'m doing to ensure my "EBS" volume survives instance termination works right and is perfomant
[2017-12-11 21:46:54] <SISheogorath> xenoterracide: storage drivers are for images. Since you use a layered filesystem for images
[2017-12-11 21:47:56] <SISheogorath> xenoterracide: sounds like you are looking for docker for aws
[2017-12-11 21:48:16] <xenoterracide> well, yes, but I'm implementing it
[2017-12-11 21:48:18] <SISheogorath>  [<-LINK->] 
[2017-12-11 21:48:41] <xenoterracide> oh interesting
[2017-12-11 21:48:43] <xenoterracide> thanks
[2017-12-11 21:48:54] <SISheogorath> you're welcome ^^
[2017-12-11 21:50:48] <xenoterracide> SISheogorath: I admit to skimming, is thiscloudstorjust generally available as part of Docker CE?
[2017-12-11 21:51:32] <SISheogorath> iirc you can get it as docker plugin, so yes
[2017-12-11 21:52:03] <xenoterracide> ah it's a plugin hmm... now how do I get that on centos
[2017-12-11 21:56:15] <SISheogorath> I'm not totally sure forcloudstorbut docker4x has it available. Maybe check that out or trydocker plugin install cloudstor:aws
[2017-12-11 21:56:29] <SISheogorath> but keep in mind you need an up to date docker version for that
[2017-12-11 21:58:53] <xenoterracide> yeah I'm using the latest LTS CE
[2017-12-11 21:59:05] <xenoterracide> at least on this refactor away from ECS
[2017-12-11 21:59:09] <xenoterracide> which is all that matters
[2017-12-11 22:23:04] <xenoterracide>  [<-CODE->] hmm
[2017-12-11 22:25:29] <SISheogorath> docker plugin install docker4x/cloudstor:17.09.0-ce-aws1
[2017-12-11 22:44:18] <xenoterracide> hmm
[2017-12-11 22:44:26] <xenoterracide>  [<-CODE->] 
[2017-12-11 22:53:41] <xenoterracide> SISheogorath: seems that this solution requires me to run all the things it wants, like cloudformation
[2017-12-11 22:54:18] <SISheogorath> I never used it
[2017-12-11 22:54:32] <SISheogorath> Can't say anything about it in detail
[2017-12-11 22:54:36] <SISheogorath> only know it exists
[2017-12-11 22:54:49] <SISheogorath> The recommended way is to use docker for AWS
[2017-12-11 23:25:29] <xenoterracide> yeah, from the looks of it, it's too holistic for me, and the one reference I found to that error generally criticizes the stability
[2017-12-11 23:25:43] <xenoterracide> I'd love to have the volume support
[2017-12-11 23:25:53] <xenoterracide> because it would solve headaches
[2017-12-12 08:32:07] <przemolb> I would like to build a docker image with my application running inside. I don\'t want my application  to run as root so I can use "USER user1" for that. But is there any way I can add (in dockerfile) the whole folder with my application and keep it owned by "user1" but without using \'chown\' after ? I read somehow that chown in dockerfile is not the best way to do that ...
[2017-12-12 13:51:28] <SISheogorath> przemolb: why chown the application?
[2017-12-12 13:52:12] <SISheogorath> only chown what you really need writeable
[2017-12-12 13:52:24] <SISheogorath> this improves your image's security
[2017-12-12 15:05:57] <przemolb> SISheogorath: chown the whole whole folder where the application resides. It needs the folder to function properly.
[2017-12-13 08:30:45] <grofit> Does anyone know if there is a reason why docker images would work fine locally, but when the same image is pushed to docker hub then run via kitematic it fails to start
[2017-12-13 08:38:13] <SISheogorath> different config? what happens when you delete the image locally, pull it and try to run it with the same command?
[2017-12-13 08:47:13] <grofit> let me try that, I assumed the local image I tagged was same as the one on docker hub
[2017-12-13 08:47:20] <grofit> so didnt bother pulling it
[2017-12-13 08:49:05] <grofit>  [<-CODE->]  [<-CODE->] 
[2017-12-13 08:49:15] <grofit> So that works fine
[2017-12-13 08:49:25] <grofit> let me just check how to delete image locally
[2017-12-13 08:51:36] <truthadjustr> grofit: mounted volunes is one of the reasons ..show us your Dockerfile content instead
[2017-12-13 08:51:40] <grofit> kk
[2017-12-13 08:52:00] <grofit>  [<-LINK->] 
[2017-12-13 08:52:57] <grofit> (its a windows container btw)
[2017-12-13 08:53:08] <grofit>  [<-CODE->] 
[2017-12-13 08:54:00] <grofit> I have 2 windows containers that work fine locally but when using via kitematic they just seem to exit after starting, but other images work fine on there
[2017-12-13 08:54:06] <truthadjustr> grofit: im not into windows but do u think the base image exist in hub.docker.com?
[2017-12-13 08:54:39] <grofit> yeah it does one mo
[2017-12-13 08:55:22] <grofit> So there is mine:https://hub.docker.com/r/grofit/s3rver-windows/Here is the base image:https://hub.docker.com/r/microsoft/nanoserver/
[2017-12-13 08:56:59] <grofit> Problem I have is that they have a .net code base they would like to run within docker, which depends upon 3rd party bits, but as windows containers cannot run WITH linux ones without swarms etc its a pain, so just making windows compatible versions of the 3rd party libs so devs can just use these to host the relevant bits (as its not using .net core, just the old .net, so cant get away with hosting it in linux containers)
[2017-12-13 10:16:00] <grofit> Any ideas?
[2017-12-13 10:51:49] <SISheogorath> grofit: there is probably no solution than "fixing" the application.
[2017-12-13 10:51:53] <SISheogorath> or replace it
[2017-12-13 10:52:26] <grofit> when you say the application what do you mean?
[2017-12-13 10:52:32] <grofit> kitematic, my image?
[2017-12-13 11:30:10] <zhang-dre> How to use KubernetesCommand-line Tools Reference?There are many kinds of tools here: [<-LINK->] How to use them? Run them on master but not found.
[2017-12-13 11:42:39] <grofit> Isnt there a Kubernetes room somewhere?
[2017-12-13 11:43:50] <grofit> SISheogorath: Sorry to ping you, but when you said "The application" what did you actually mean? Kitematic or the image I was trying to deploy (or something else)?
[2017-12-13 12:36:02] <SISheogorath> zhang-dre: For K8s please check their Slack community
[2017-12-13 14:58:45] <grofit> Any chance of a confirmation of what you meant by "application"
[2017-12-13 14:59:30] <grofit> as if this is possibly just a bug in kitematic (the kitematic room is dead, already asked there) I will just leave it as that (other windows containers run in there fine and seem same sort of dockerfile stuff as myself)
[2017-12-13 15:12:20] <SISheogorath> When it works fine by CLI, throw kitematic away
[2017-12-13 15:13:14] <grofit> thats easy enough to say but most people here are are not that used to docker, I am still a novice and Kitematic is an easier way for them to visually see in the windows eco system whats running and manage things from there
[2017-12-13 15:14:02] <truthadjustr> the CLI, is the easist way to work with docker and not the kitematic gui
[2017-12-13 15:14:24] <grofit> Sure for creating images and power users
[2017-12-13 15:14:44] <grofit> but for people who dont really care much about docker and just want to consume the code run a gulp/build script and then click something in a gui not so much
[2017-12-13 15:14:47] <truthadjustr> with GUIs, a lot is hidden, so it is harder to understand
[2017-12-13 15:15:04] <grofit> yeah but in an existing team, I am not here to teach them the ins and outs of docker
[2017-12-13 15:15:18] <grofit> I am looking for path of least resistence to get them using their stuff with docker
[2017-12-13 15:16:00] <grofit> so if I can say to them "just run the build script, go to your images in kitematic and press play" thats a lot better than trying to teach them how to pull, build, run etc
[2017-12-13 15:16:17] <truthadjustr> agree
[2017-12-13 15:16:54] <grofit> So ideal world I would like to understand why CLI works fine with images (as I am authoring them for the others here) but Kitematic doesnt, but only seemingly with my images as like I say other windows/linux containers work fine
[2017-12-13 15:17:14] <truthadjustr> i just learn today, that a lot of microsoft docker images is already around.. very interesting, these were not here just a year ago
[2017-12-13 15:17:36] <grofit> yeah, this is why now I am trying to get some traction on moving to docker based images for environments
[2017-12-13 15:17:48] <grofit> as with docker compose it makes a lot of stuff easier to just "run"
[2017-12-13 15:18:23] <grofit> but its more baby steps with the team adoption of it, if I can just show them a simple thing that works, I can build off that and get them more involved in CLI when they want to start authoring or altering stuff
[2017-12-13 15:18:48] <grofit> and like I say I only know basics of images and compose, not used swarm or other stuff yet
[2017-12-13 15:19:15] <grofit> but anyway this hurdle seems difficult to analyse as Kitematic just fails and the kitematic room is dead
[2017-12-13 15:19:51] <truthadjustr> ok, so.. from the CLI it works and runs but in kitematic it is not working?
[2017-12-13 15:19:55] <grofit> so if the problem is kitematic, I can just leave it as that and try to chase it up with kitematic people somewhere, or look for other GUI tools, if there are none then looks like I will need to get people involved with CLI from day one, which may cause issues with adoption
[2017-12-13 15:20:04] <grofit> yeah, as shown above with my CLI use
[2017-12-13 15:20:15] <grofit> if I remove the image, download it, run it locally it runs fine
[2017-12-13 15:20:35] <grofit> if I use kitematic and download it from docker hub via that and run it, it falls over
[2017-12-13 15:20:43] <truthadjustr> i can definitely say, .. the issue is with kitematic then
[2017-12-13 15:21:11] <grofit> kk thanks
[2017-12-13 15:21:20] <truthadjustr> there are better GUI you may try to check..
[2017-12-13 15:21:22] <grofit> just baffles me why other stuff works and mine doesnt, I assumed I was just doing something silly somewhere
[2017-12-13 15:21:25] <grofit> oh right
[2017-12-13 15:21:33] <grofit> what would you recommend (this is windows environment)
[2017-12-13 15:21:40] <truthadjustr> for example, my favorite isportainer
[2017-12-13 15:22:04] <grofit> kk will give it a look, kitematic support is built into Docker-For-Windows
[2017-12-13 15:22:11] <grofit> so it just seemed path of least resistance
[2017-12-13 15:22:14] <truthadjustr> then, you gave to your team the http console, and from there they will be swimming into containers via the web GUI
[2017-12-13 15:22:43] <truthadjustr> kitiematic is a personalized GUI in ones laptop...
[2017-12-13 15:23:10] <truthadjustr> portaineris a centralized way.. then your team create and run containers via web console
[2017-12-13 15:23:46] <grofit> ah right so its setup on one server and everyone uses that one for docker stuff?
[2017-12-13 15:23:55] <truthadjustr> correct
[2017-12-13 15:23:56] <grofit> that may not fly here as we want each dev machine to be its own environment
[2017-12-13 15:24:18] <grofit> rather than having a shared environment, as automated tests will be tearing down DBs and other related data
[2017-12-13 15:24:41] <grofit> so want devs to be able to spin up environments locally in docker, do their stuff then turn it off (via compose)
[2017-12-13 15:24:54] <truthadjustr> it is.. each machine to be its own dev yes. But then, when deploying to production.. you push the container/images to the the central place
[2017-12-13 15:25:16] <grofit> atm we would expect TeamCity to output the image as an artifact
[2017-12-13 15:25:29] <grofit> then that can be used to deploy to prod (be it AWS/Azure/Wherever)
[2017-12-13 15:26:09] <truthadjustr> i can see, that you are using hub.docker.com for collaborative deployment. You may, choose to have a local intranet docker registry and used that instead to exchange images and not hub.docker.com
[2017-12-13 15:26:28] <grofit> hmm maybe, atm the stuff I have put on docker hub is not unique to this project
[2017-12-13 15:27:04] <grofit> so its just generic bits we would need but not project specific, like we use ClamAV and S3 (via emulator for local use) so have just made OS windows containers for them to be consumed via the apps
[2017-12-13 15:27:17] <grofit> our "business" apps would as you say be in a private repo or exposed via TC or something
[2017-12-13 15:27:45] <grofit> still not entirely sure of best practice here, as the CI server exposes current builds etc, with Octo deploy for releasing, so just seems like moving the releasing part to a docker-esque handler
[2017-12-13 15:28:05] <truthadjustr> also, you can export a container.. it becomes a tar file.. copy it via USB and import it into another dev's machine...
[2017-12-13 15:29:03] <grofit> hmm I was planning on having the devs "env setup" build script would do the docker build etc locally, but again until we have this up and running across the team I cannot evaluate it
[2017-12-13 15:29:09] <grofit> but good to know you can do things that way
[2017-12-13 15:30:26] <truthadjustr> just drop the kitiematic roadblock that's hindering you.. kitematic is a very very small icing on the cake comparing to what is possible with docker ...
[2017-12-13 15:30:57] <grofit> well its not hindering me exactly, its just I can see it being easier for people to get their heads around it with a GUI tool for now
[2017-12-13 15:31:05] <grofit> but it is something I would like to solve
[2017-12-13 15:31:14] <grofit> as I could be doing something "wrong" that just works locally
[2017-12-13 15:31:41] <grofit> so its a worry that it may work fine on devs machines, but then when we went to a QA or Prod env etc it may fall over because of this issue, but like I say could just be kitematic, but I dont know why
[2017-12-13 15:32:11] <grofit> so its more of a niggling thing I would like to solve, but I can continue with my work without worrying about it
[2017-12-13 16:21:24] <drewboardman> hey, I'd like to have log output show when Idocker run. Is that possible?
[2017-12-13 16:21:37] <drewboardman> and have ittailthem so i can keep seeing output?
[2017-12-13 16:24:40] <truthadjustr> yes..docker logs -f containernamehere
[2017-12-13 16:26:29] <truthadjustr> but u can't use that if the container crashes (exited)...so u have do it fast to see the logs b4 it crashes...
[2017-12-13 16:27:09] <drewboardman> ok so like usingdocker run | awk '{docker logs -f $1}'
[2017-12-13 16:27:20] <drewboardman> or is there a docker way to do this?
[2017-12-13 16:27:22] <drewboardman> withoutawk
[2017-12-13 16:28:56] <truthadjustr> to each his own...i think u can see more realtime logs from the unix socket docker uses ..but its not for normal use
[2017-12-13 16:29:29] <drewboardman> what do you mean by that?
[2017-12-13 16:30:46] <drewboardman> my awk command is working btw
[2017-12-13 17:33:33] <drewboardman> i ended up using xargs
[2017-12-13 17:44:27] <truthadjustr> does it capture anything if the container crashes or won't start?
[2017-12-13 17:59:55] <drewboardman> not sure
[2017-12-13 18:00:06] <drewboardman> it's messed up right now, but hasn't failed to start yet
[2017-12-13 18:17:28] <SISheogorath> truthadjustr: it logs all std:out and std:err from your container.
[2017-12-13 18:17:46] <SISheogorath> Which means as long as 1 process starts in your container, yes. it's entire output is captured
[2017-12-13 18:18:54] <SISheogorath> if no process is started because you want to start a program in a path that doesn't exist, for example, it won't can't capture the output since there is no process. But it'll iirc tell you indocker ps -a
[2017-12-13 18:33:48] <truthadjustr> SISheogorath: yes. Most often i am puzzled why a container won't run anddocker logs -fis too late to see the crash logs. Any tips for that?
[2017-12-13 18:34:40] <SISheogorath> simply dodocker logson it. Logs persist as long as the container exists. So when you don't start it with--rmyou are fine
[2017-12-13 18:35:04] <SISheogorath> checkdocker ps -aif you need the container id, but names work withdocker logs, too
[2017-12-13 18:35:13] <SISheogorath> even when they are killed
[2017-12-13 18:37:34] <truthadjustr> aha..thanks. Halted containers only retain the  very last lines of the log...
[2017-12-13 19:28:38] <SISheogorath> don't use the -f flag for them
[2017-12-14 09:52:01] <grofit> Hello again, so a new question for today
[2017-12-14 09:53:21] <grofit> so lets say I have a web app which depends upon 2 other apis, so the web app by default is looking for localhost:3456 for one api and localhost:4567 for the other api. When writing my docker compose file the docs are not to clear on if/how you can tell the containers to have some sort of virtual network which has  these ports setup where expected
[2017-12-14 09:54:23] <grofit> Given each container is really gonna be its own "machine" in a way I am not sure if this will work and I will need to instead look at using some sort of network link so rather than it beinglocalhost:3456itsapi1or something, but its not clear on if you can setup the internal network hostnames and ports
[2017-12-14 09:54:35] <grofit> as most docs seem to detail setting up ports for the host to relay from the container
[2017-12-14 09:59:26] <grofit> so is there a way to let the web app just use localhost:3456/4567 without having to reference by the service name, and not externally exposing the ports on the host machine (just within the web container)
[2017-12-14 10:00:10] <grofit> as my understanding is that the EXPOSE command will automatically expose the ports inside the containers, so the ports are already exposed its just how you can reference lets sayapi1:3456aslocalhost:3456on the web machine
[2017-12-14 10:00:13] <grofit> any of this make sense?
[2017-12-14 10:41:44] <MohamedShawky85> I facing an issue now i running the akka actor inside a docker container but when the container deleted the actor postStop() method not run
[2017-12-14 13:31:08] <Cosbgn> hey everyone, when usingdocker-composeisdocker-compose buildthe equivalent ofdocker build?
[2017-12-14 13:31:32] <Cosbgn> as after that I would just usedocker pushetc
[2017-12-14 13:42:33] <grofit> I dont think you push your composes anywhere
[2017-12-14 13:42:47] <grofit> as they are not images, more network setups
[2017-12-14 15:15:16] <yosefrow> Docker compose is a fancy tool that builds and runs so yes you can push an image built with docker compose
[2017-12-14 15:51:06] <drewboardman> hey, so I've noticed that when idocker runeverything goes fine - but when I actually visit the webserver on my host browser the container exits after the first page load
[2017-12-14 15:51:10] <drewboardman> is this expected?
[2017-12-14 15:51:17] <drewboardman> I'd like the container to be persistent
[2017-12-14 15:58:12] <drewboardman>  [<-CODE->] 
[2017-12-14 15:58:40] <drewboardman> I'm running with
[2017-12-14 15:59:00] <drewboardman>  [<-CODE->] 
[2017-12-14 16:14:50] <yosefrow> Your app is failing in some waydocker logs containernameorid
[2017-12-14 16:17:40] <drewboardman> it's not failing
[2017-12-14 16:17:46] <drewboardman> I can hit the app in the browser
[2017-12-14 16:17:48] <drewboardman> once
[2017-12-14 16:17:51] <drewboardman> and then the container exits
[2017-12-14 16:18:23] <drewboardman> it's like the script finishes, and then docker decides that the container can exit
[2017-12-14 16:20:58] <drewboardman>  [<-CODE->] 
[2017-12-14 16:24:59] <yosefrow> Sorry misread ur issue
[2017-12-14 16:25:58] <yosefrow> Docker container depends on process to run when no process is left it exits
[2017-12-14 16:27:05] <yosefrow> There are ways to force it to stay alive like for example running sleep
[2017-12-14 16:27:50] <yosefrow> In your case your script
[2017-12-14 16:28:05] <yosefrow> Is finishing or failing
[2017-12-14 16:29:41] <yosefrow> When script stops no process is left alive so container exits
[2017-12-14 16:32:47] <yosefrow> grofit: EXPOSE in a dockerfile only documents ports to publish. Then to open them u have to publish at docker run with -p hostport:containerport
[2017-12-14 16:33:25] <yosefrow> EXPOSE doesnt open ports
[2017-12-14 16:40:09] <yosefrow> drewboardman: by default docker run will show u logs and b attached to the process so that if u interrupt the container will die. With -d you can detach and view the logs whenever u want with  'docker logs'
[2017-12-14 16:40:10] <grofit> In compose doesn't it auto expose them to linked images?
[2017-12-14 16:40:48] <grofit> I thought you only needed ports specified on images in docker compose if you want them externally exposed to the host
[2017-12-14 16:41:54] <yosefrow> Docker compose is orchestration 4 docker. You can docker run and set port to publish manually or specify in compose
[2017-12-14 16:42:22] <yosefrow> Dockerfile doesnt control ports
[2017-12-14 16:43:05] <yosefrow> Only docker run or orchestrators like compose that use docker run
[2017-12-14 16:44:20] <yosefrow> Expose means expose port requirement 4 all to see. Publish means publish port on host machine by adding rule to ur firewall
[2017-12-14 16:46:29] <yosefrow> Docker compose can link containers internally within docker by using docker virtual network features
[2017-12-14 16:53:32] <grofit> Yeah that must be the bit I meant as no examples set ports in compose files but they work, like you say with run you need explicit -p
[2017-12-14 16:59:34] <yosefrow> Not so. Compose letz you publish ports to host. But from container 2 container not needed
[2017-12-15 00:42:20] <zhang-dre> SISheogorath: Okay:)
[2017-12-15 04:06:46] <huangyanxiong01>  [<-CODE->] template [<-CODE->] how to render raw html to template?
[2017-12-15 07:50:39] <yosefrow> huangyanxiong01: you can add any file to an image by putting 'COPY sourcepathoffile pathofileincontainer' inside the Dockerfile
[2017-12-15 07:53:34] <yosefrow> With 'RUN somecommand' you can run any command inside the image. Other than that im not sure what u are asking as it relates 2 docker
[2017-12-15 08:05:39] <maxime1992> hi :) is there any way to cut internet for a given container?
[2017-12-15 08:06:47] <yosefrow> Docker networks i think
[2017-12-15 08:11:08] <maxime1992> Ok I found it thanks@yosefrowdocker network disconnect bridge e3bb7ed2aea2
[2017-12-15 08:13:07] <yosefrow> Restrict Internet Access - Docker Container - Stack Overflow [<-LINK->] questions  r...
[2017-12-15 08:13:27] <yosefrow> Woops one sec
[2017-12-15 08:13:58] <yosefrow>  [<-LINK->] 
[2017-12-15 08:15:00] <yosefrow> Ok third timez the charm [<-LINK->] 
[2017-12-15 08:16:44] <yosefrow> Network creation for block internet accessdocker network create --internal --subnet 10.1.1.0/24 no-internetIf you want to connect docker container into internetdocker network connect internet container-nameIf you want to block internet accessdocker network connect no-internet container-name
[2017-12-15 08:19:43] <maxime1992> Ok thanks! :) And do you think I could do something like that from a Dockerfile?
[2017-12-15 10:24:18] <pjetr> unsure if this has been posted here yet: [<-LINK->] If you have issues that your.devdomain gets redirected tohttpsread the link, and change your domains to.test
[2017-12-15 16:58:23] <susannamartinelli> Hi at all, has anyone ever faced with this problem yet (aws_cloudwatch_event_target) [<-ISSUE->] 
[2017-12-15 17:00:18] <susannamartinelli> Sorry wrong room :D
[2017-12-15 17:52:37] <miriam-z> Hi I am having many issues runningdocker-compose upin a rails application
[2017-12-15 17:53:00] <miriam-z> the commands are hanging in the terminal and no connection to the server is being made
[2017-12-15 17:53:06] <miriam-z> I am also using postgres as well
[2017-12-15 17:53:22] <miriam-z> not sure what is happnening can anyone help with this?
[2017-12-15 19:29:45] <patwalt> Hi, everyone
[2017-12-15 19:30:20] <patwalt> I have what is likely a very basic issue with docker
[2017-12-15 19:31:11] <patwalt> When I tried to build a basic docker file, I get an error that states: 'can't stat '/home/developer/.dbus''.  Is this a common problem?
[2017-12-15 22:39:48] <jgolubenko> patwalt: check permissions
[2017-12-15 22:40:07] <jgolubenko> could be root vs non-root owned
[2017-12-15 22:41:26] <jgolubenko> ifsudo docker buildworks for sure permissions on the dir/file is restrictive
[2017-12-16 17:23:01] <kevincaradant> HiI'm trying to have Kodi inside a container with Docker. And I wish to mount my home partition as volume in the container. [<-CODE->]  [<-CODE->] Snippet of my docker-compose.yml: [<-CODE->] My repository is here if this can help: https://github.com/kevincaradant/kodi-docker-gui/tree/V3Thank you :)
[2017-12-16 21:22:35] <yosefrow> maxime1992: docker image commands go in dockerfile. Docker run commands are represented by docker compose, so for networks use docker compose. Though im not sure u can exactly configure the network w compose perhaps u can configure the net properties manually then add the networj name to compose
[2017-12-16 21:25:00] <yosefrow> patwalt: i had trouble to copy or add files in dockerfile unless they were in the same  or child of the same directory that the dockerfile is in
[2017-12-16 21:26:00] <yosefrow> Try copying the files or dir  into the dockerfile dir if its not a permissions issue
[2017-12-16 21:28:53] <yosefrow> kevincaradant: docker compose reads env variables from the .env file. So put USER=something in .env or try write a build script that does export USER=something b4 docker compose up. This might work too
[2017-12-16 22:11:13] <kevincaradant> yosefrow: , you right ! it's works thank you
[2017-12-17 07:07:26] <yosefrow> Glad i could help :)
[2017-12-17 08:43:45] <truthadjustr> what's the real use ofEXPOSEin Dockerfule it seems that I can still use p
[2017-12-17 08:45:00] <truthadjustr> ports without having them pre-declared in Dockerfile?!
[2017-12-17 10:07:21] <yosefrow> Expose is documentation only
[2017-12-17 10:07:28] <yosefrow> truthadjustr: 
[2017-12-17 10:07:50] <yosefrow> As far as i know
[2017-12-17 10:17:16] <truthadjustr> In docker-compose.yml, is there an init ordering such as which container should be up first bcoz other containers depend on it?
[2017-12-17 11:06:20] <SISheogorath> truthadjustr: you should make sure that your containers don't care about the order they are started in
[2017-12-17 11:06:37] <SISheogorath> Check: [<-LINK->] 
[2017-12-17 23:19:56] <zebralight> hello. I was wondering if anyone here uses docker not just for deployment but also for development
[2017-12-18 01:01:18] <NikIvan> zebralight: Yes, actively using docker for development to run for example redis and mysql instances. Works pretty well and usefull. Allows to be more flexible if you are working on lots of projects. You don't need to install for ex. mysql or redis to your local machine if you are using them only on one project and to be consistent with production environment
[2017-12-18 09:45:41] <ppLorins> Hi all , I want to specify different storage-drivers for the different containers, is there a way to do this ?
[2017-12-18 11:17:30] <SISheogorath> ppLorins: no. Storage drivers are global
[2017-12-18 11:17:54] <SISheogorath> But please recheck you don't mixup storage and volume drivers
[2017-12-18 11:35:04] <ppLorins> SISheogorath: Yes , I didn't mixup them .  I tried add the the following to /etc/docker/daemon.json , but docker told me it doesn't supportoverlay2, how to make docker support that kind of storage driver?
[2017-12-18 11:35:32] <ppLorins> {"storage-driver": "overlay"\n}
[2017-12-18 11:35:32] <SISheogorath> What kernel version are you running?
[2017-12-18 11:35:53] <ppLorins> 17.09.1-ce  running on centos7
[2017-12-18 11:36:05] <SISheogorath> Kernel version ->uname -a
[2017-12-18 11:36:18] <ppLorins> {"storage-driver": "overlay2"\n}
[2017-12-18 11:36:29] <ppLorins> Linux localhost.localdomain 3.10.0-693.11.1.el7.x86_64 [<-ISSUE->] SMP Mon Dec 4 23:52:40 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
[2017-12-18 11:36:38] <SISheogorath> well there is your answer :D
[2017-12-18 11:36:54] <SISheogorath> overlay2 is only available in kernel version >4
[2017-12-18 11:37:12] <ppLorins> you mean linux kernel version ?
[2017-12-18 11:38:07] <SISheogorath> See: [<-LINK->] 
[2017-12-18 11:38:11] <ppLorins> alright.  actually I want limit disk space usage of containers , and found--storage-opt size=120Gis a solution .
[2017-12-18 11:38:12] <SISheogorath> yes, linux kernel version
[2017-12-18 11:38:29] <ppLorins> Got it .Thanks@SISheogorath
[2017-12-18 11:38:36] <SISheogorath> You're welcome ^^
[2017-12-18 11:39:38] <MateuszGrab> Hi guys, Anyone knows how to expose engine remote API on moby based images?
[2017-12-18 11:43:15] <MateuszGrab> Alpine linux, deployed by default docker CloudFormation template.
[2017-12-18 14:42:48] <maxime1992> Hi! I'm using 2 dockerfile within the same folder (which is possible since 1.8) thanks to this syntax:Dockerfile.dbDockerfile.webetc...Now I'd like to build/run them from a docker compose.Can I do that? I don't see how...
[2017-12-18 19:34:11] <danielarnason> Hi all....new to Docker and I have a question......is there a way to add an empty environment variable in my docker-compose or .env file?
[2017-12-18 19:37:05] <mab122> Why would you need an empty variable? Can't you just set it ... empty string or sth
[2017-12-18 20:38:54] <danielarnason> I'm using an .env file to make some environment variables, such as DB_PASS and there is no password to the test database I am using (in the postgres.app on mac)
[2017-12-18 20:39:13] <danielarnason> this appearantly causes some issues
[2017-12-18 20:39:17] <mab122> In that case you can literally do what I suggested.
[2017-12-18 20:39:43] <danielarnason> if that's the case, then the problem lies elsewhere
[2017-12-18 20:40:02] <danielarnason> I'm just getting some wierd connection problems
[2017-12-19 02:15:33] <jk-jx> Hi. I've create docker image as backup for my file everyday. Why I'm not even using the file, it still increase its size everyday? Not large but still increase.
[2017-12-19 03:13:55] <SISheogorath> Docker is neither a version control, nor a backup system .-. I neither understand why you did that, nor what for
[2017-12-19 07:29:02] <mohanzeal> hi all. Is there anything like docker-compose commit... I have a docker-compose.yml in the root folder that spin up 5 different services with 5 different images. I made modifications for all the images.. now I want to commit those images... How can I do that
[2017-12-19 07:41:13] <athifrank> hii all
[2017-12-19 09:34:12] <SISheogorath> mohanzeal: don't commit these changes directly. Use a Dockerfile to make them reproducible and put it into a git repository
[2017-12-19 09:37:11] <mohanzeal> i did the same, created a Dockfile but the problem is that i have many dependency instructions listed in the dockerfile. It's taking a lot of time to build the image.
[2017-12-19 09:37:18] <mohanzeal> SISheogorath: 
[2017-12-19 11:43:04] <DJFliX> Hi! Assuming I was stupid enough to think "Oh, the docker UI for Mac has the option to manage my swarm from the cloud, let\'s enable it". Am I able to revert this? Apparently my existing client certificate in my docker machine does not work anymore. I ssh\'d into the server and saw that the ca.pem is still in place. But runningdocker-machine lsyields:docker-manager-01         -        azure     Running   tcp://<redacted-ip>:2376                                  docker-manager (master)   Unknown   Unable to query docker version: Get https://<redacted-ip>:2376/v1.15/version: x509: cannot validate certificate for <redacted-ip> because it doesn\'t contain any IP SANs
[2017-12-19 11:58:06] <rkitover> Are services down right now? I'm getting:Error response from daemon: Get https://registry-1.docker.io/v2/: dial tcp: lookup registry-1.docker.io on [::1]:53: read udp [::1]:45660->[::1]:53: read: connection refused
[2017-12-19 12:05:18] <rkitover> oh it looks like a DNS lookup on localhost, but why is it doing that (this is docker for windows)
[2017-12-19 12:36:13] <rkitover> turning off ipv6 fixed it
[2017-12-19 12:57:06] <SISheogorath> mohanzeal: And?
[2017-12-19 17:18:26] <yosefrow> mohanzeal: use a docker registry or  to dockerhub w docker push my
[2017-12-19 17:18:55] <yosefrow> Docker image tag myrepo/myimage
[2017-12-19 17:19:25] <yosefrow> Docker login / requires signup
[2017-12-19 17:19:44] <yosefrow> Docker push myrepo/myimage
[2017-12-19 17:20:30] <yosefrow> Then u dont have 2 build image everywhere. Just docker pull
[2017-12-19 17:24:22] <truthadjustr> u can also save (in tar) an image, copy to usb drive and load it to another system..
[2017-12-19 17:25:45] <yosefrow> True but if ur saving u should use use docker save not docker export since it is lossy
[2017-12-19 17:26:10] <yosefrow> Make sure 2 use save and load
[2017-12-19 23:40:55] <liangyuanpeng> hello guys,i have a problem,i try to create first admin user in docker-jenkins . but i get the msg : First user was already created
[2017-12-19 23:49:37] <liangyuanpeng> should be Hit the URL localhost:8080, and you shall see the screen.
[2017-12-19 23:49:39] <liangyuanpeng> cool
[2017-12-20 05:57:06] <yosefrow> Just a small distinction of docker export vs save: save will save an image or the image a container is based on and its metadata and layers. Export makes a copy of the filesystem of a running container.
[2017-12-20 06:32:20] <aldencolerain> Hi all.  I\'m having some trouble understanding service discovery.  I have two stacks on the same overlay network and I\'m confused that I can ping "service" "service_stack" but not "service_stack.stack".  Does anyone have any insight?
[2017-12-20 08:28:06] <maxime1992>  [<-CODE->] Can I access the -h parameter at runtime? I guess not but in case...
[2017-12-20 08:28:21] <maxime1992> or is there any way from the container to find it somewhere?
[2017-12-20 09:56:15] <truthadjustr> use environ var -e
[2017-12-20 19:41:13] <smashingx1> Does docker swarm could provide automated failover in a case of a postgresql replication server?
[2017-12-20 22:24:14] <skarred14> hi all - i have been facing a strange issue with mounting volumes using the following command:docker run -d -v ~/.temp/dir:/etc/some/dir/ c1 <image>. i am unable to see the files i have in./temp/diron the container. i am using docker 1.17ce on mac osx. any suggestions?
[2017-12-20 22:29:21] <skarred14> i have also checked the file sharing tab on docker preferences and i see /Users as a directory that can be bind mounted..any suggestions would be immensely helpful, as this is causing a lot of hold up
[2017-12-20 23:37:57] <skarred14> ^^correction: docker version: 17.09.1-ce.mac42
[2017-12-21 03:03:13] <truthadjustr> is there no COPY command inside docker-compose.yml?
[2017-12-21 03:32:14] <siassaj> man
[2017-12-21 03:32:28] <siassaj> i just can't get nginx:alpine to accept a basic_auth directive
[2017-12-21 03:32:50] <siassaj> nginx: [emerg] invalid number of arguments in "auth_basic" directive in /etc/nginx/nginx.conf:30  ... every time
[2017-12-21 03:32:54] <siassaj> so werid
[2017-12-21 03:36:08] <Nessex> You're passing in a realm name?
[2017-12-21 03:38:06] <siassaj> ... no
[2017-12-21 03:38:23] <siassaj> appartenly " is not the same as “
[2017-12-21 03:38:29] <siassaj> siassaj: stabs someone
[2017-12-21 03:38:53] <Nessex> "Smart" quotes 
[2017-12-21 03:39:50] <siassaj> hurts my brain
[2017-12-21 03:40:01] <siassaj> that's 2 hours wasted i could have been billing
[2017-12-21 05:55:10] <yosefrow> siassaj: i think same problem with single quotes sometimes. Been there too
[2017-12-21 05:55:19] <yosefrow> Also dashes
[2017-12-21 05:59:33] <yosefrow> skarred14: sounds like could b a problem specific to mac os. On linux -v hostdir:dockerdir works fine. Make sure u are going to the right dir though. ~/.temp is not the same as  ./temp
[2017-12-21 09:10:17] <ppLorins> Hi all , I have a symbolic link lost issue: [<-CODE->] I don't understand why , and want to keep the symbolic link stay even I do the mount operaiton.Can anyone help ?
[2017-12-21 09:12:04] <SISheogorath> simply recreate the link in your entrypoint script
[2017-12-21 09:12:30] <SISheogorath> when you mount a directory from outside the original content of this path is gone
[2017-12-21 09:12:55] <ppLorins> You mean the original content inside the container will gone ?
[2017-12-21 09:14:31] <SISheogorath> when you bindmount a directory inside a container, the path inside the container is replaced with the outside one. Not merged
[2017-12-21 09:15:12] <ppLorins> Got it , thanks .
[2017-12-21 09:16:59] <SISheogorath> You're welcome
[2017-12-21 14:24:38] <ndpratas> I guys, I need a really quick answer. How is the best way to ship stdout and stderr logs from docker container to ELK agnostic of the Cloud I'm using? Suppose I'm using azure/bluemix/ kubernetes PaaS. How it's the best way to do this?
[2017-12-21 17:01:12] <rightisleft> in docker swarm - what methodology does the mesh network use when load balancing? I know you can turn on DNS-Round-Robin, but whats the order of operations ?
[2017-12-21 17:01:45] <rightisleft> IE if service: fish has a replica count of 10 on an overlay network - how does docker discern which instance to send data to?
[2017-12-21 17:21:05] <rightisleft>  [<-LINK->] 
[2017-12-21 17:42:42] <ldacey> What is the simplest set up to remotely deploy some ETL / reporting stuff on a windows machine? 1) PostgreSQL image with the tables created, 2) Python image (maybe Airflow) to run scripts, 3) a volume for raw files or scripts to be saved?
[2017-12-21 17:43:48] <ldacey> This all needs to be a self contained thing operating on a single computer, and I want to avoid installing much software (other than docker for windows)
[2017-12-21 17:46:47] <ndpratas> rightisleft: I believe you can't choose order: [<-LINK->] 
[2017-12-21 17:49:40] <ndpratas> unless you use DNSRR and leave it to the client to choose one of many dns query results
[2017-12-21 17:50:23] <ndpratas>  [<-CODE->] 
[2017-12-21 17:50:51] <drewboardman> Hi. So I have 2 containers running on a VM. One is a web app on port 9000. The other is atestercontainer that needs to hit localhost:9000 to visit the web app
[2017-12-21 17:51:00] <drewboardman> what's the smartest way to go about this?
[2017-12-21 17:51:27] <drewboardman> for the web app, I'm just doingdocker run -p 9000:9000 <etc> <etc>
[2017-12-21 17:51:45] <drewboardman> but I'm having network errors trying to request it from thetestercontainer
[2017-12-21 17:57:40] <drewboardman> does--linkexist to do this?
[2017-12-21 17:58:22] <ndpratas> drewboardman: Use docker compose. --link is already deprecated I believe. They will be always linked when joined to the same network
[2017-12-21 17:58:40] <ndpratas> inside tester if you ping "webapp" it will resolve the dns to the ip address
[2017-12-21 17:58:59] <ndpratas> (if they are in the same network which they will in compose)
[2017-12-21 18:05:13] <drewboardman> damn, i really would like to avoid writing a docker compose file
[2017-12-21 18:07:02] <drewboardman> i really need the output of docker logs
[2017-12-21 18:07:17] <drewboardman> and the web app needs to be running before the CMD of the tester is executed
[2017-12-21 18:24:59] <ammario> Anyone know how to find the ZFS filesystem associated w/ a container? I'm using docker 1.13.1. In later versions of Docker there's a usefulGraphdriverfield when getting a container, but I can't upgrade for other compatibility reasons.
[2017-12-21 18:33:14] <drewboardman> ndpratas: do the containers actually need to be linked to achieve what I'm trying to do?
[2017-12-21 18:33:32] <drewboardman> essentially tester really just needs to know about port 9000 on host
[2017-12-21 18:43:52] <ammario> Offering $10 PayPal/ETH to anyone that solve my problem :)
[2017-12-21 19:11:29] <ammario> Figured it out:/var/lib/docker/image/zfs/layerdb/mounts/<container-id>/mount-id
[2017-12-21 20:20:05] <SISheogorath> ndpratas: not only for compose. It's deprecated in general.
[2017-12-21 20:21:04] <SISheogorath> drewboardman: Why does it need to be localhost?
[2017-12-22 00:32:14] <smashingx1> docker service create —-mount \'type=bind,src=/tmp/postgres,dst=/var/lib/postgresql/data,readonly\' -—name dev -d -e contraint:node==/swarm1/  postgres\nError response from daemon: rpc error: code = InvalidArgument desc = ContainerSpec: "—-mount" is not a valid repository/tag
[2017-12-22 00:33:41] <smashingx1> any help on this please?
[2017-12-22 00:35:35] <SISheogorath> use real--mountinstead of a wrong-sign
[2017-12-22 00:35:52] <SISheogorath> just write it again yourself instead of coping ;)@smashingx1
[2017-12-22 00:38:23] <smashingx1> copying you mean?
[2017-12-22 00:38:53] <smashingx1> heh. What I did is I constructed the command in notepad and then copy it to the command line, that was the problem
[2017-12-22 00:39:03] <smashingx1> thank you@SISheogorath
[2017-12-22 00:40:28] <smashingx1> would that be the translation of a non-swarm command like this: [<-CODE->] 
[2017-12-22 00:40:51] <smashingx1> because it seems like swarm can't handle -v
[2017-12-22 00:46:26] <SISheogorath> Swarm can handle the mount command, but you have to handle the data
[2017-12-22 00:46:45] <SISheogorath> and yes, this should work
[2017-12-22 00:57:01] <smashingx1> and also, can I mount it from another server? e.g. nfs?
[2017-12-22 02:07:16] <SISheogorath> smashingx1: yes, check [<-LINK->] 
[2017-12-22 09:19:57] <ndpratas> @drewboardman You can always publish the port on the host with -p <hostPort>:<containerPort> and from there on, you can access the webapp on the <dockerHostIP>:<hostPort>.i really need the output of docker logs [<-CODE->] and the web app needs to be running before the CMD of the tester is executedThis is exactly why you need compose. You can use depends_on flag in docker compose file in order to set dependencies. Docker will make sure to initiate your container in order. It's pretty cool actually.
[2017-12-22 09:22:20] <jemliF> hi
[2017-12-22 09:22:32] <jemliF> is it possible to launch an android emulator from docker container?
[2017-12-22 12:28:24] <SISheogorath> jemliF: As far as I know some people do, but I wouldn't recommend it
[2017-12-22 13:41:15] <AyushyaChitransh> Hello, a question here: [<-CODE->] 
[2017-12-22 13:42:10] <AyushyaChitransh> there is a server running on port3000which I verified by going inside container and usingcurl localhost:3000
[2017-12-22 14:02:04] <AyushyaChitransh> If I specify these ports in a docker-compose file, everything works well, but when starting container  alone, I think ports are not being forwarded
[2017-12-22 14:05:15] <SISheogorath> AyushyaChitransh: It's because you put the parameters behind the image name
[2017-12-22 14:07:06] <AyushyaChitransh> My goodness! What a silly mistake! thanks a lot@SISheogorathI wouldn't have been able to figure this out. Its working fine now 
[2017-12-22 14:07:26] <SISheogorath> This way they are send as arg to the process inside the image. You need to put them before the image name so they are processed by docker
[2017-12-22 14:07:39] <SISheogorath> AyushyaChitransh: You're welcome
[2017-12-22 14:54:00] <akkayatr> Hi
[2017-12-22 18:09:51] <ldacey> So it is preferred to use a volume compared to linking a host folder? This volume would contain and persist the raw data files, for example, which I download from an SFTP site?
[2017-12-22 18:10:36] <ldacey> I don’t want to lose the raw data, they will be downloaded to this location, then processed by a python container, then loaded into PostgreSQL container
[2017-12-22 18:59:15] <SISheogorath> ldacey: It highly depends on the size of your setup. I would go myself for host directories, but the main reason is that it's easier to control and Backup when you run on a single host. When you run a Storage backend or an orchestrator you probably don't want to manage tons of directories across all hosts and that's where volumes are what you really love. Also when you go for a setup on AWS, Azure, or GCE. They have nicely integrated volume drivers that makes it way easier to manage volumes instead of syncing host directories between your machines
[2017-12-22 19:28:35] <andersonkyle> I'm curious if anyone knows the ETA for Kubernetes support within Docker CE/EE?  And if there's a good issue in GitHub to watch for this feature.
[2017-12-22 21:27:39] <smashingx1> what would be the ip address of a container in a swarm using the Overlay Network Driver?
[2017-12-22 21:27:56] <smashingx1> would that be the ip inside of "docker inspect"?
[2017-12-22 23:18:54] <SISheogorath> smashingx1: yes
[2017-12-23 01:23:05] <ldacey> SISheogorath: thanks. So in this case, management wants everything to work in a silo (separate database and reporting all on-premise and not a part of our data warehouse). I actually would prefer that the files remained on the host machine as a normal folder which my python ETL stuff could read and write to
[2017-12-23 01:24:01] <ldacey> This would be a windows pro machine, so I’d just have a folder on it which is linked to the container?
[2017-12-23 05:05:27] <ldacey> Got it. Mounted my dags folder (python ETL scripts) and a folder for files and it worked just fine
[2017-12-23 08:42:30] <truthadjustr> is coreos the best docker platform?
[2017-12-23 16:55:16] <markych96> i prefered rancheros
[2017-12-23 19:23:52] <SISheogorath> truthadjustr: it highly depends on what you are doing. For hosting K8s CoreOS is pretty good. For docker swarm or minimal docker setups in general linuxkit is the way to go. For single or a few boxes using a usual OS is way easier
[2017-12-24 03:20:49] <smashingx1> Now that I connected my swarm node to the overlay network I lost connectivity to it if I want to connect from another host, even though I'm exposing the ports by doing -p 5432:5432
[2017-12-24 03:21:16] <smashingx1> This is how I created the service:
[2017-12-24 03:21:29] <smashingx1>  [<-CODE->] 
[2017-12-24 04:23:42] <elcolie> Hi
[2017-12-24 04:24:14] <elcolie> I have problem, but it is not related todocker, but I think you guys withdockerexperince can help
[2017-12-24 04:24:38] <elcolie> I accidentally delete my 2TD USB HDD. And I have tontfsundeletethem back
[2017-12-24 04:24:40] <elcolie>  [<-LINK->] 
[2017-12-25 23:45:12] <briantopping> Hi all, happy Christmas to everyone!
[2017-12-25 23:45:35] <briantopping> Or happy Monday if you happen to be in the majority of people on earth that don’t celebrate it lol
[2017-12-25 23:47:41] <briantopping> Curious if anyone is using IntelliJ GoLand to work with Docker sources. I’m new to both (and GoLand looks to be pretty new), thought there might be some collected knowledge I could discover...
[2017-12-26 00:55:53] <ldacey> I have been running into permission issues with Docker for Windows using the postgres official image. My docker containers are linux though
[2017-12-26 00:56:15] <ldacey> I am trying to link the PGDATA folder to a normal folder I can view and edit
[2017-12-26 00:56:40] <ldacey> I have this working with my airflow python ETL scripts etc, but the PGDATA folder won't play nice
[2017-12-26 00:58:09] <ldacey> this is for a single machine and there is no need for data to be accessible elsewhere, so a host folder made sense compared to making a volume beforehand
[2017-12-26 08:07:31] <rsoeldner> briantopping: keep going with scala :P
[2017-12-26 08:07:53] <rsoeldner> briantopping: happy christmas
[2017-12-26 08:25:42] <briantopping> Hey Robert!! Happy Christmas to you too!
[2017-12-26 08:26:55] <briantopping> I have been trying to resolve why NFS mounts with the local storage driver are not working. The error messages are worthless! Lol
[2017-12-26 09:54:58] <rsoeldner> briantopping: hehe 
[2017-12-26 12:49:28] <ldacey> Has anyone tried to deploy some containers to a computer they don’t have direct or constant access to?
[2017-12-26 12:51:53] <ldacey> As an alternative to traveling there and setting up some pretty simple automated reporting (Salesforce and ftp files), I was considering just having Docker installed on a computer and running a few containers
[2017-12-26 12:53:39] <ldacey> I’d need to set it up through screen sharing tools or have someone set it up for me. Any changes I would make would have to be through the docker or compose files
[2017-12-26 13:08:27] <gorbierd> Hello all! I know it's probably a bit out of topic, but I'm trying to automate build and run of the java app with docker. I'm using docker-compose with depends_on directive for tomcat server, which depends on maven build container. The problem is, that web doesn't wait until maven package the app, just until it started. Any idea of how can I automate such pipline with a single docker-compose file?
[2017-12-26 13:44:07] <elcolie> Hi
[2017-12-26 13:44:21] <elcolie> Anybody here usinggitlab-ci?
[2017-12-26 13:44:34] <elcolie> MyDocker runnerdoes not run mypytest
[2017-12-26 13:44:34] <elcolie>  [<-LINK->] 
[2017-12-26 14:09:32] <SISheogorath> ldacey: check watchtower for docker. It automatically updates the containers when there is a new image available. I used it for CD purposes without the need of ssh into the machine. Works pretty well^^
[2017-12-26 14:10:48] <SISheogorath> gorbierd: why docker compose? Use a multi-staged build for that is way more effective. Other wise search for the builder-pattern in context of docker for similar set-ups
[2017-12-26 14:11:33] <SISheogorath> elcolie: sounds a bit more like a gitlab than an docker issue
[2017-12-26 14:12:08] <elcolie> SISheogorath: I found the solution now. Yeah you are right. It isGitlab-CI runner behavior
[2017-12-26 14:14:08] <SISheogorath> smashingx1: did you check your postgres instance is running correctly?
[2017-12-26 14:14:33] <elcolie> SISheogorath: Thank you :)
[2017-12-26 14:40:51] <imaia> does docker have a maximum number of networks?
[2017-12-26 16:06:31] <smashingx1> SISheogorath: is running
[2017-12-26 16:33:46] <briantopping> anyone debugging Docker itself withdelve?
[2017-12-26 16:48:13] <SISheogorath> imaia: for sure, but I never made it to hit that limit. And as there are tons of running instances out there and I never saw someone complaining, I think it's high enough to don't worry about it
[2017-12-26 16:48:54] <SISheogorath> smashingx1: so postgres is running but you can't connect from outside?
[2017-12-26 17:09:30] <smashingx1> SISheogorath: No when I connect it to an overlay network
[2017-12-26 17:12:36] <imaia> SISheogorath: A friend of mine just hit it; we're debugging what may have happened
[2017-12-26 18:30:52] <maxime1992> Is there a good alternative to raspberry pi for running docker but not limited to ARM images?
[2017-12-26 23:39:11] <emmairwin> Hello, I work at Mozilla , specifically on diversity and inclusion on open source participation.  Where is the best place/who is the best person to ask about sharing a survey on this topic with docker community?
[2017-12-27 00:36:11] <SISheogorath> emmairwin: please check the docker Community slack
[2017-12-27 00:38:19] <SISheogorath> Check for
[2017-12-27 00:38:20] <SISheogorath> karenbajza
[2017-12-27 01:50:54] <emmairwin> thank you!
[2017-12-27 02:28:02] <SISheogorath> You're welcome :) keep in mind that it's Christmas time so maybe they are not around
[2017-12-27 02:28:39] <SISheogorath> maxime1992: vservers are available everywhere and work pretty well
[2017-12-27 02:29:05] <SISheogorath> imaia: are you sure it's a docker limit abd not a kernel limit?
[2017-12-27 11:24:20] <elcolie> Hi
[2017-12-27 11:24:49] <elcolie> I am building theimageand my docker must use my ssh key to dopip install -r requirements.txt
[2017-12-27 11:25:12] <elcolie> WithgitlabI can usesecret_keyas a variable in the server
[2017-12-27 11:25:33] <elcolie> But when I build in my local pc. What is your people practical solution?
[2017-12-27 12:11:29] <elcolie> Hi
[2017-12-27 12:11:47] <elcolie>  [<-CODE->] 
[2017-12-27 12:12:20] <elcolie> I can executepytestnormally in my local machine. But when I instantiate thecontainer. It failed
[2017-12-27 12:12:38] <elcolie> I have put.dockerignorein the directory already
[2017-12-27 12:13:00] <elcolie> In.dockerignore. It has single line of__pycache__
[2017-12-27 13:04:02] <elcolie> I solves it!. I misconfigure inDockerFile. I forgot toCOPY ./pytest.ini .
[2017-12-27 17:59:23] <sovanmishra451_twitter> hi
[2017-12-27 19:54:04] <CaptainYarb> Does anyone know if they've created any changelog or release notes for Docker CE 17.12 yet?
[2017-12-27 19:54:40] <CaptainYarb> We had to update to fix an edge-case bug. Now our container tests never come back, resulting in the containers never being healthy.
[2017-12-27 19:57:06] <CaptainYarb> took 15+ mins of Google-foo but I finally found it
[2017-12-28 12:33:20] <pkbharath> Hi
[2017-12-28 12:33:34] <pkbharath> unable to build dockerfile
[2017-12-28 12:34:01] <pkbharath> get error The command '/bin/sh -c systemctl start mongod' returned a non-zero code: 1
[2017-12-28 12:34:22] <pkbharath> anyone could help me make mongodb as service and start it from dockerfile
[2017-12-28 12:35:48] <pkbharath> have the mongod file under /usr/bin/
[2017-12-28 12:52:49] <avaika> pkbharath: are you trying to build own mondo docker from scratch?
[2017-12-28 12:53:09] <avaika> you can check Docker file ( [<-LINK->] ) from official [<-LINK->] 
[2017-12-28 12:53:15] <avaika> or just use it
[2017-12-28 12:54:48] <pkbharath> Noticed that
[2017-12-28 12:54:51] <pkbharath> The command '/bin/sh -c systemctl start mongodb' returned a non-zero code: 1
[2017-12-28 12:55:01] <pkbharath> still get the same error
[2017-12-28 12:55:16] <pkbharath> if i ssh and run these commands it works
[2017-12-28 12:55:36] <pkbharath> not able to create and start it as service from the dockerfile
[2017-12-28 12:56:11] <pkbharath> its for me to learn
[2017-12-28 12:56:24] <pkbharath> so did not want to use mongo image
[2017-12-28 12:56:46] <pkbharath> tried RUN service start mongod
[2017-12-28 12:56:56] <pkbharath> and RUN service start mongodb
[2017-12-28 12:57:07] <pkbharath> and RUN service mongod start
[2017-12-28 12:57:20] <pkbharath> and  RUN service mongodb start
[2017-12-28 12:57:26] <pkbharath> all are giving me errors
[2017-12-28 12:58:13] <pkbharath> using ubuntu base image
[2017-12-28 12:58:33] <pkbharath> planning to have multiple containers talking to each other
[2017-12-28 12:58:54] <pkbharath> anyone help would be appreciated
[2017-12-28 12:59:03] <pkbharath> lol typoo
[2017-12-28 13:13:52] <pkbharath> Fixed it ty all
[2017-12-28 13:14:03] <imaia> SISheogorath: actually, it was a mask misconfiguration problem
[2017-12-28 13:14:06] <imaia> = ]
[2017-12-28 16:20:34] <przemolb> I'd like to run a container/docker image but be able to modify its (container) configuration files from the host. And be able to save the modifications between restarts. Is it possible in docker ?
[2017-12-28 16:23:15] <yosefrow> przemolb: Yes via volume bind mount for live files or Dockerfile COPY for files that live in the container only
[2017-12-28 16:32:44] <przemolb> yosefrow: Thanks for the hint. So what is actually the best practice for storing data between containers restart but still be able to modify the data (whatever it is: configuration data, database data, etc) from the host ?
[2017-12-28 16:43:54] <SISheogorath> The best practice is to provide configuration for your application by environment variables (if possible) and save your persistent data in volumes.
[2017-12-28 16:44:15] <SISheogorath> But I personally prefer to bind mount most things outside
[2017-12-29 09:41:32] <przemolb> SISheogorath: why do you prefer to use bind mount ? I am assuming this is based on your personal experience. So what made you to use bind mount ?
[2017-12-29 11:07:14] <elcolie> Hi
[2017-12-29 11:07:41] <elcolie> I need to getMS SQLcontainer andPHP5+ webserver.
[2017-12-29 11:07:51] <elcolie> I am reading this. [<-LINK->] 
[2017-12-29 11:08:08] <elcolie> But I am confusing. How can I implement my code with it?
[2017-12-29 11:08:39] <elcolie> I havephp5code already, but it needsphp5MSSQLandwebserver
[2017-12-29 11:46:34] <SISheogorath> przemolb: I don't have a big enough setup to really get into volume management. At least in my home setup. So it's way easier to use bind mounts.
[2017-12-29 11:47:28] <SISheogorath> For setup on AWS, Azure or GCE I would recommend to use volumes
[2017-12-29 11:49:06] <SISheogorath> elcolie: to be honest I wouldn't use their setup .-.
[2017-12-29 11:49:43] <elcolie> SISheogorath: By that. If you were me what would you do?
[2017-12-29 11:49:55] <SISheogorath> Check the official docker images and develop it using them
[2017-12-29 11:50:27] <elcolie> SISheogorath: Sorry. What does itthemin your context?
[2017-12-29 11:52:41] <elcolie> I think you mean theofficialdocker image from scratch
[2017-12-29 11:53:18] <elcolie> Sorry for inaccurate answer. It is 10 hours for me by now
[2017-12-29 13:25:35] <SISheogorath> I mean the official images for mssql and php -> [<-LINK->] 
[2017-12-30 03:20:22] <elcolie> SISheogorath: Got it.I have to use  2 official images [<-CODE->] 
[2017-12-30 14:46:06] <duikb00t> Hi, I am pretty new in docker and I have used a dockerfile and all my container are created by running docker compose up -d
[2017-12-30 14:46:37] <duikb00t> But I made now a filechange in a docker-compose file. Can I re-init that file w/o re-initializing all my containers?
[2017-12-30 14:47:03] <duikb00t> I have changed a domain in a docker-compose.yml file.
[2017-12-30 21:33:30] <SISheogorath> duikb00t: docker-compose up -dwill recreate and restart all containers that have to changed or depend on one that needs to be changed. It'll automatically detect the changes and then do its job
[2018-01-02 03:30:08] <comeUpWithItLater> my app writes log to  files. how to config it to log to logstash [<-LINK->] with min modify?
[2018-01-02 08:00:33] <bravekjh> Hi everyone.  I joined this room first time today,  nice to meet you all
[2018-01-02 10:09:55] <jemliF> SISheogorath: can I emulate to device by mapping the/dev/bus/usbfolder? I mean a cordova app running in my container can see devices plugged to my machine ?
[2018-01-02 10:10:45] <jemliF> I am facing a weirdcontainer exited with code 0error with docker compose
[2018-01-02 11:52:34] <SISheogorath> I think there is a--deviceparameter. never used it myself but that's probably the better way to map it
[2018-01-02 13:17:03] <ghost~57cbaf6040f3a6eec0634f49> What is the use of docker?
[2018-01-02 13:19:38] <ghost~57cbaf6040f3a6eec0634f49> Can anyone explain about it in a very simple lang?
[2018-01-02 13:50:51] <SISheogorath> dpnashsh: Docker is an container engine (means it isolates applications) and orchestration system (means it places applications on various hosts and makes sure there is a fail over when a host dies). It provides all tooling to create such containers. Means you can download images of applications and/or build them yourself in a reproducable way using Dockerfiles. This way docker allows you to manage the entire workflow of a application building to deployment.
[2018-01-02 13:53:53] <jemliF> SISheogorath: how can I list/know the devices to map? do they represents devices plugged using USB?
[2018-01-02 13:56:01] <ghost~57cbaf6040f3a6eec0634f49> SISheogorath: Thanks. How can I use it if I am working on project in which I am using nodejs and angular js?
[2018-01-02 13:56:58] <SISheogorath> jemliF:  [<-LINK->] 
[2018-01-02 13:59:44] <SISheogorath> dpnashsh: depends on what you want to do. Docker is simply a tool that helps to abstract environments
[2018-01-02 14:01:35] <SISheogorath> if it's only an angularJS app, than you may want to have a look at this: [<-LINK->] 
[2018-01-02 14:01:52] <SISheogorath> it was an example I once build to add docker support for an angularJS application
[2018-01-02 14:01:55] <jemliF> SISheogorath: Do you think--devicecan help me to access my USB plugged android smartphone ?
[2018-01-02 14:02:40] <SISheogorath> jemliF: To be honest, I have no idea. Never was in the need to do that, since I usually only deploy docker containers on server. I don't use them for development or debugging.
[2018-01-02 14:02:51] <SISheogorath> Maybe it works, maybe not
[2018-01-02 14:05:32] <briantopping> dpnashsh: another way to look at Docker is that of library and deployment isolation. Linux package managers do a good job of avoiding system bit rot by making sure installed libraries are compatible, but they can get stuck. Docker images encapsulate these libraries are isolated to the specific deployment that needs them so the host is not overloaded with installations for every service on the machine.
[2018-01-02 14:08:52] <briantopping> Natively, Docker is not a virtualization environment, it's an encapsulation environment like chroot once was. It uses cgroups, which are a more powerful version of that.
[2018-01-02 14:10:21] <briantopping> That said, running Docker containers on non-Linux OSes generally requires emulation of a Linux environment with lightweight virtualization running behind the scenes.
[2018-01-02 14:13:23] <briantopping> Does that make sense?
[2018-01-02 14:16:31] <jemliF> SISheogorath: thank you, I will try it
[2018-01-02 14:17:40] <jemliF> SISheogorath: I am facing acontainer exited with code 0with docker compose
[2018-01-02 14:17:43] <SISheogorath> briantopping: for Windows containers that's not 100% correct :D
[2018-01-02 14:17:59] <SISheogorath> jemliF: well, what does the logs say?
[2018-01-02 14:18:35] <briantopping> SISheogorath: please do feel free to correct that! 
[2018-01-02 14:18:51] <jemliF> SISheogorath: it printsdockerizedmfp_devbox_1 exited with code 0
[2018-01-02 14:18:55] <jemliF> nothing else
[2018-01-02 14:19:23] <jemliF> It's weird because I am able to build and run my container separately
[2018-01-02 14:19:44] <briantopping> SISheogorath: oh you mean for containers that have Windows contents, yes?
[2018-01-02 14:21:34] <SISheogorath> briantopping: exactly. Can't say much about that myself because I got rid of Windows a while ago
[2018-01-02 14:21:36] <briantopping> I did think of that briefly but decided against polluting the explanation for someone just getting started
[2018-01-02 14:21:50] <jemliF> SISheogorath: here is myDockerfile [<-LINK->] 
[2018-01-02 14:21:51] <SISheogorath> Completely fine with that ^^
[2018-01-02 14:22:07] <briantopping> I feel sorry for anyone that needs to run Windows in a server room.
[2018-01-02 14:23:00] <jemliF> briantopping: me too 
[2018-01-02 14:23:03] <SISheogorath> briantopping:  Same over here :D
[2018-01-02 14:23:28] <SISheogorath> jemliF: Looks fine. How do you start your container?
[2018-01-02 14:23:52] <jemliF> sudo docker-compose up
[2018-01-02 14:24:01] <SISheogorath> that explains it :D
[2018-01-02 14:24:31] <jemliF> SISheogorath: what's wrong?
[2018-01-02 14:24:42] <SISheogorath> you call bash as entrypoint and CMD which is pointless, but let's get to the real problem: bash itself doesn't get any instruction and doesn't run interactively. So it exists with 0
[2018-01-02 14:25:32] <SISheogorath> so you either call your container with the application you really want to run or you run it interactively and open the program you need with the shell itself
[2018-01-02 14:25:51] <SISheogorath> the latter doesn't work with docker-compose
[2018-01-02 14:25:54] <jemliF> SISheogorath: I notice that so I added theseENTRYPOINTandCMDin Dockerfile
[2018-01-02 14:26:00] <SISheogorath> at least not without a bit hacking :D
[2018-01-02 14:27:15] <jemliF> SISheogorath: I don't have a specific program to run on startup
[2018-01-02 14:27:29] <jemliF> how can I keep my container up and running?
[2018-01-02 14:28:14] <SISheogorath> there are various ways. Pretty popular is to justtail -f /dev/nulland then jump into it usingdocker exec
[2018-01-02 14:29:13] <jemliF> SISheogorath: where to put thistail -f /dev/null?
[2018-01-02 14:31:45] <SISheogorath> simplest way is to remove the entrypoint and use it as CMD
[2018-01-02 14:32:10] <SISheogorath> not completely sure for the java image, but I guess it should work
[2018-01-02 14:37:23] <jemliF> SISheogorath: apparently it's working
[2018-01-02 14:37:40] <SISheogorath> you're welcome :)
[2018-01-02 14:55:29] <jemliF> SISheogorath: 
[2018-01-03 04:16:46] <elcolie> Hi
[2018-01-03 04:17:05] <elcolie> I am usingphp:5because my customer is usingphp5.6
[2018-01-03 04:17:17] <elcolie> And production server isAmazon Linux
[2018-01-03 04:17:41] <elcolie> MyDockerFilefailed because it can not find the package. But it does released in the official repo
[2018-01-03 04:17:47] <elcolie>  [<-CODE->] 
[2018-01-03 04:18:00] <elcolie>  [<-CODE->] 
[2018-01-03 04:25:46] <comeUpWithItLater>  [<-LINK->] 
[2018-01-03 04:25:59] <comeUpWithItLater> no 'php5-sybase'  found!!
[2018-01-03 04:26:20] <elcolie>  [<-LINK->] 
[2018-01-03 04:26:44] <elcolie> It isJessie. [<-LINK->] 
[2018-01-03 04:26:51] <elcolie>  [<-LINK->] 
[2018-01-03 04:27:33] <elcolie> I am now reading. How can I addDebianrepo toDockerFile?
[2018-01-03 04:28:08] <elcolie> I want thishttps://packages.debian.org/jessie/amd64/php5-sybase/download
[2018-01-03 04:28:12] <elcolie> comeUpWithItLater: 
[2018-01-03 04:29:42] <comeUpWithItLater> then use the   source : [<-LINK->] 
[2018-01-03 04:30:36] <SISheogorath> elcolie: keep in mind that the php image doesn't use the packaged version of php
[2018-01-03 04:32:03] <elcolie> SISheogorath: I don't understand. What am I suppose to do.My goal isApache2\nphp5.6\nBe able to connect to MS SQL
[2018-01-03 04:32:23] <elcolie> I am stuck atphp5-mssqldriver
[2018-01-03 04:33:14] <SISheogorath> I just wanted to mention that because you may run into a problem like: Mhm, why is php twice in that image
[2018-01-03 04:33:37] <elcolie> SISheogorath: !
[2018-01-03 04:34:11] <SISheogorath> When the driver depends on the php package and the php package is not installed by default… I guess you understand ^^
[2018-01-03 04:34:39] <elcolie> SISheogorath: Than you are telling me that. I have to prepare everything from plainUbuntu/Debianimage?
[2018-01-03 04:35:14] <SISheogorath> Maybe check the "add more extensions" section [<-LINK->] 
[2018-01-03 04:35:27] <SISheogorath> If that doesn't work, then maybe
[2018-01-03 04:35:48] <SISheogorath> And you should maybe usephp:5-apache
[2018-01-03 04:36:42] <elcolie> SISheogorath: OK. One moment.
[2018-01-03 04:37:13] <elcolie> Let me try5.6-apache
[2018-01-03 04:37:43] <elcolie> SISheogorath:  [<-CODE->] 
[2018-01-03 04:39:00] <elcolie>  [<-CODE->] 
[2018-01-03 04:39:11] <elcolie> I will try adding repo to it
[2018-01-03 04:39:50] <SISheogorath> As mentioned, follow the instructions for extending the image, not blindly use package management. It'll fool you in this case
[2018-01-03 04:40:51] <SISheogorath> Since it'll install a php version you don't want
[2018-01-03 04:41:58] <elcolie> SISheogorath: Opss. Sorry. Forgot
[2018-01-03 07:02:11] <elcolie>  [<-LINK->] 
[2018-01-03 08:13:29] <ghost~57cbaf6040f3a6eec0634f49> SISheogorath: Thanks
[2018-01-03 08:14:37] <ghost~57cbaf6040f3a6eec0634f49> briantopping: thanks
[2018-01-03 08:18:41] <comeUpWithItLater>  [<-LINK->] 
[2018-01-03 08:19:08] <comeUpWithItLater> elasticsearch   not  running , but no logs
[2018-01-03 08:19:27] <comeUpWithItLater> any idea?@SISheogorath
[2018-01-03 08:20:45] <SISheogorath> check how the container exited
[2018-01-03 08:21:40] <SISheogorath> when it's 127 (or 128?) then you have to check where the binary is. Otherwise I suggest to exec into the container and start a regular debugging
[2018-01-03 08:22:34] <SISheogorath> and by exec into the contianer I mean doing something likedocker run <your parameters> -it --entrypoint /bin/bash <yourimage>and then run your commands manually with debug flags etc
[2018-01-03 08:22:53] <SISheogorath> the 101 linux admin job ^^
[2018-01-03 08:26:08] <comeUpWithItLater> ok
[2018-01-03 08:26:12] <comeUpWithItLater> thx
[2018-01-03 08:26:17] <comeUpWithItLater> let me try
[2018-01-03 09:19:05] <elcolie> Hi
[2018-01-03 09:19:20] <elcolie> How can I let container running?
[2018-01-03 09:19:48] <elcolie>  [<-CODE->] 
[2018-01-03 09:19:56] <elcolie>  [<-CODE->] 
[2018-01-03 09:20:13] <elcolie> docker-compose upbut it exit later on
[2018-01-03 09:20:22] <elcolie> How can I keep it running?
[2018-01-03 09:20:31] <safiulm_twitter> What is start
[2018-01-03 09:20:36] <safiulm_twitter> ?
[2018-01-03 09:21:04] <safiulm_twitter> Can you do docker logs container
[2018-01-03 09:32:24] <SISheogorath> elcolie: that's exactly why people shouldn't use packages in docker images. The container exits when the process with PID 1 exits. Which is in this case an init script which exists after doing a double fork to demonize apache… Check: [<-LINK->] 
[2018-01-03 09:33:52] <SISheogorath> So you not only don't really make it to start the httpd, you also happily create a lot of little zombie processes on your system in worst case
[2018-01-03 09:37:44] <SISheogorath> If you really want to use the packaged version you should at least copy the apache foreground script and run it as entrypoint
[2018-01-03 10:16:03] <elcolie> SISheogorath: Here is ground up to the current problem
[2018-01-03 10:16:05] <elcolie>  [<-CODE->] 
[2018-01-03 10:16:38] <elcolie>  [<-CODE->] I am stuck atCodeIgniter. It does not execute the/api
[2018-01-03 11:58:42] <comeUpWithItLater>  [<-LINK->] 
[2018-01-03 12:00:02] <comeUpWithItLater> anyone  know where to find the documentation for elastic  images?
[2018-01-03 13:21:34] <elcolie> Hi
[2018-01-03 13:21:49] <elcolie> I am new toPHP.
[2018-01-03 13:21:56] <elcolie>  [<-LINK->] 
[2018-01-03 13:22:19] <elcolie> I had installed everything it needs. But I could not figure out whyphpdoes not run?
[2018-01-03 13:22:58] <joschua011> this does not answer your question but why not us an official php image?
[2018-01-03 13:23:27] <joschua011>  [<-LINK->] 
[2018-01-03 13:24:23] <joschua011> also what do you mean php does not run at all? in command line or if open -php files via apache?
[2018-01-03 13:25:47] <elcolie> joschua011: Yeah. I had. But@SISheogorathor somebody here suggest me to build from the ground.
[2018-01-03 13:49:17] <jarodrigues> I need help
[2018-01-03 14:55:31] <SISheogorath> comeUpWithItLater:  [<-LINK->] 
[2018-01-03 14:56:42] <SISheogorath> elcolie: I told use to use the php:5-apache image and extend it as in the image documentation
[2018-01-03 14:57:25] <SISheogorath> jarodrigues: if you need help, we need help to help you ;) a good start would be telling us what you need help with
[2018-01-03 18:05:56] <jayczech23> Hi Everyone, is it possible to run Xcode and Xcode Simulator inside a Docker container using Docker for Mac?
[2018-01-03 18:06:15] <jayczech23> ^^ Docker beginner
[2018-01-03 22:24:24] <briantopping> jayczech23: no, D4M runs Linux binaries.
[2018-01-04 01:57:45] <comeUpWithItLater> thx@SISheogorath
[2018-01-04 02:15:26] <elcolie> SISheogorath: Thanks. I managed to survive any way now.
[2018-01-04 06:04:29] <achillesimo> Hi allI'm trying to build a docker image from jenkins? I'm runing a windows OP
[2018-01-04 06:05:26] <achillesimo> I'm trying to build a docker image from jenkinsdocker build -t fc12c2a5edc227f992c7f117588c5d24be9752bc -f Dockerfile .always give me this error script.sh: docker: not foundi installed this pluginCloudBees Docker Build and Publish pluginplease what am i missing
[2018-01-04 07:16:33] <SISheogorath> achillesimo: I would suggest you to check the CI-CD and/or Windows channels in the docker community slack -> [<-LINK->] 
[2018-01-04 18:40:42] <shahbazn> If i am building FROM a base docker image and that base image starts an nginx process with its entrypoint script. Now I add an entrypoint script to fill a few config files from env variables and before the base image calls its entrypoint script. So my question does adding a new entrypoint script override the base image's entrypoint script or does it add another layer on the docker image and execute both layer first the new layer and then base images?
[2018-01-05 03:49:57] <SISheogorath> it'll overwrite the ENTRYPOINT script of the base image, yes
[2018-01-05 03:50:28] <SISheogorath> if you want to extend it, just source the original entrypoint script :) make sure you use the same shell interpreter so it works fine
[2018-01-05 03:50:33] <SISheogorath> shahbazn: ^
[2018-01-05 09:49:34] <comeUpWithItLater> docker.elastic.co/kibana/kibana:6.1.1 wouldn't startno erro msgno idea what's wrong
[2018-01-05 09:49:49] <comeUpWithItLater>  [<-LINK->] 
[2018-01-05 09:50:01] <comeUpWithItLater> any idea?
[2018-01-05 09:50:27] <shahbazn> SISheogorath: thanks that helps
[2018-01-05 10:03:52] <comeUpWithItLater> SISheogorath: any ideas?
[2018-01-05 14:22:07] <hamon-e> Hello, I was wondering if there was a way to run a docker container on a unsafe host ? I don't want the host to be able to explore or change my container  (Maybe there is another software for that ?) Any suggestion ? Thanks
[2018-01-05 14:28:38] <techberlin> Background: I have installed WSL and running Ubuntu 16.04. Due to organizational policy, I don\'t have Windows Fall Creators update but the Ubuntu is working fine. I have installed docker and able to communicate via DOCKER_HOST without TLS.Issue: When I try to mount /mnt/c to /c, I don\'t get any error but the mount doesn\'t seem to do anything. "ls -l /c" doesn\'t show the output I see when "ls -l /mnt/c".Question: How to ensure that volume mount works seamlessly and I don\'t have to specify weird filepath in Dockerfile.
[2018-01-05 14:28:58] <techberlin> Please help, I wasted two days figuring out but could not find the solution
[2018-01-05 14:30:09] <techberlin> For mounting I tried: "sudo mkdir /c" and then "sudo mount --bind /mnt/c /c" but it doesn\'t work
[2018-01-05 14:36:17] <techberlin> Anybody any idea?
[2018-01-05 14:36:24] <aftemark> hello, i have a problem setting up xdebug working with docker container on windows, anyone has working it or experienced setting it up?
[2018-01-05 15:22:31] <aftemark> docker.for.win.localhost as a xdebug.remote_host worked for me, just letting know
[2018-01-05 21:51:30] <smashingx1> Thisdocker service create --volume postgres:/var/lib/postgresql/datagives me an error:unknown flag: --volume
[2018-01-05 21:51:47] <smashingx1> Does anybody know what's the flag to mount volumes in services?
[2018-01-05 21:52:21] <ramonberrutti> smashingx1: use -v
[2018-01-05 21:52:35] <smashingx1> it also gives me an error@ramonberrutti
[2018-01-05 21:54:20] <smashingx1> unknown shorthand flag: 'v' in -v
[2018-01-05 21:54:33] <smashingx1> ramonberrutti: can you tell me how?
[2018-01-05 21:54:36] <ramonberrutti> smashingx1: try with: --mount
[2018-01-05 21:54:51] <ramonberrutti>  [<-CODE->] 
[2018-01-05 21:55:06] <smashingx1> ok let me do it
[2018-01-05 21:55:24] <smashingx1> because I already created the volume
[2018-01-05 21:55:33] <smashingx1> I just need to mount it
[2018-01-05 21:56:13] <smashingx1> no,
[2018-01-05 21:56:29] <smashingx1> it seems like mount is just for mounting binds, etc but not for volumes
[2018-01-05 21:56:43] <ramonberrutti> smashingx1: read this: [<-LINK->] 
[2018-01-05 21:58:18] <ramonberrutti> if you dont want to read all: --mount type=volume,source=my-volume,destination=/path/in/container
[2018-01-05 22:03:11] <smashingx1> I found it  that part in the do
[2018-01-05 22:03:12] <smashingx1> doc
[2018-01-05 22:03:14] <smashingx1> thank you
[2018-01-05 22:37:06] <smashingx1> ok I fixed that
[2018-01-05 22:37:33] <smashingx1> how can I send a command e.g. "ls -l" to a running service?
[2018-01-05 22:37:40] <smashingx1> since I can't attach it
[2018-01-05 23:15:10] <smashingx1> how can I find out what service/container is using a specific volume?
[2018-01-06 00:37:35] <smashingx1> I have a weird problem, services inside of the same network can't communicate, I see the following error:
[2018-01-06 00:37:45] <smashingx1> could not translate host name "dev_db" to address: Temporary failure in name resolution
[2018-01-06 00:38:22] <smashingx1> but they are both in the same network as I can see in the inspect Network overlay: [<-LINK->] 
[2018-01-06 00:39:34] <smashingx1> or even when I try their VIPs
[2018-01-06 04:23:18] <comeUpWithItLater>  [<-LINK->] how manyCURREN STATEs  could a  service be？
[2018-01-06 04:23:30] <comeUpWithItLater> not listed in the doc
[2018-01-07 06:55:54] <smashingx1> So I just debugged the problem I have in my docker swarm. My swarm consists of a manager node and a worker node. I created my first service inside of my overlay network (called mynetwork) and constrained on the manager node. Then, I created another service that all it does is to ping the service in the manager node, so I constrained it in the worker node and also joined to the overlay network. The problem I have is the following, when I ping the service in the manager node from the worker node I get the following:helloworld.1.r5i6truptf61@swarm02    | ping: bad address 'dev_db'and when I ping the service from the manager node (so the same node as the service I'm trying to ping I don't get any errors)helloworld.1.bcay6ht12bs8@swarm02    | 64 bytes from 10.0.0.4: seq=0 ttl=64 time=0.027 ms
[2018-01-07 07:01:58] <smashingx1> I thought at first it could be the firewall the problem so what I did is to flush iptables in both hosts
[2018-01-07 07:02:03] <smashingx1> but still nothing
[2018-01-07 07:06:20] <smashingx1> nevermind, I just restarted the service in both hosts and now it works.
[2018-01-07 07:06:33] <smashingx1> I think there's a bug with docker overlay network
[2018-01-07 14:54:53] <JohnyWaynen_twitter> Hello, very quick question: is docker handling service healt inside container. For example do i need to setup a systemd script inside container for the health of service ?
[2018-01-07 20:42:24] <FrederikBrinckTruelsen> JohnyWaynen_twitter: If you want container health / orchestration you can add kubernetes on top of your docker these two work perfectly in sync with each other
[2018-01-07 20:43:03] <FrederikBrinckTruelsen> You would need to add some kind of health check inside your container that kubernetes can react upon
[2018-01-07 21:34:17] <JohnyWaynen_twitter> Thanks Frederik, obviously first time I hear kubernetes, will look at. Systemd look necessity for the purpose. Since I had run 8-9 months of nonstop containers never faced with a process stop issue, but it pinned to my head nowadays.
[2018-01-07 22:36:43] <FrederikBrinckTruelsen> It depends on what your container cotains, but Systemd is defiantly one road you can take
[2018-01-07 22:37:35] <FrederikBrinckTruelsen> if its a web or a java application with Spring Boot there is web interface you can use to do health checks
[2018-01-07 22:43:03] <jamesalbert> Not sure if this is the right place to ask docker-py questions, but I'm using python to pull, run a detached container of, and run 1 command on a python:3.6 image. It pulls and runs the image, but when trying to run the command with: [<-CODE->] it just logs the default python prompt. I'm assuming this has something to do with the default entrypoint, but I tried overriding it and still no luck. Would anyone know by looking at this what I'm doing wrong?
[2018-01-07 22:45:19] <jamesalbert> For more info, I'm trying to run the equivalent:docker exec -t <container> pip install -r requirements.txt
[2018-01-07 22:45:43] <jamesalbert> but all I'm seeing in logs (ran from python) is: [<-CODE->] 
[2018-01-07 22:46:04] <jamesalbert> but it works as expected on the command line, just not in python
[2018-01-08 03:40:53] <6ewis> hi
[2018-01-08 03:41:29] <6ewis> why does docker suggest to do this: eval "$(docker-machine env default)" as opposed to only docker-machine env default
[2018-01-08 03:41:34] <6ewis> what is the difference?
[2018-01-08 08:59:04] <comeUpWithItLater>  [<-LINK->] 
[2018-01-08 08:59:20] <comeUpWithItLater> what can we do in this case
[2018-01-08 09:24:22] <ethicalmohit> Guys, I just want to know about the behaviour of the docker container when any of the app running inside the container stops.
[2018-01-08 09:25:29] <ethicalmohit> I have monitored my one of the nodejs app which is running on docker container which stop responding after sometime due to the worker died inside container but the container doesn't stops.
[2018-01-08 09:25:47] <ethicalmohit> I want to know if its the normal behaviour or is there anything i have to look upon.
[2018-01-08 16:05:31] <6ewis> this channel is so active it's amazing
[2018-01-08 16:05:38] <6ewis> I love the conversation we're having
[2018-01-08 17:01:51] <yosefrow> 6ewis: man eval
[2018-01-08 17:02:26] <yosefrow> Eval evaluates some text and excecutes it
[2018-01-08 17:02:51] <yosefrow> Dollar parentheses does that too
[2018-01-08 17:05:36] <yosefrow> So ur command says evaluate the output of  the evaluated command
[2018-01-08 17:07:01] <yosefrow> Try 'docker-machine env default'
[2018-01-08 17:07:15] <yosefrow> And observe the output
[2018-01-08 17:07:48] <yosefrow> That output is then evaluated w eval
[2018-01-08 18:36:45] <6ewis> yosefrow: exactly so why is it recomman ded
[2018-01-08 18:36:52] <6ewis> doesnt make sense to me
[2018-01-08 18:40:36] <yosefrow> .docker-machine env default. alone outputs commands as text. It doesnt run them. Try it  . Eval takes that output and runs it
[2018-01-08 18:40:48] <yosefrow> 6ewis: 
[2018-01-08 18:42:01] <6ewis> thanjs yosefrow
[2018-01-08 18:42:21] <6ewis> so in theory i could have done eval(eval(docker-machine..))
[2018-01-08 18:42:24] <yosefrow> ethicalmohit: docker containers require a running process to live. When there are no processes left in a container it exits
[2018-01-08 18:43:04] <yosefrow> Run ps waux inside the container 2 see processes inside it
[2018-01-09 08:49:28] <ethicalmohit> yosefrow: Thank you for your response. Yes, It was weird. In the logs I can see that the worker was died but there were some SQL queries running inside the container. I got to know about this by docker logs. I haven't seen if the node process is running inside the container or not. As It was under production so I didn't get the chance to dig deep.  I will check it next time.
[2018-01-09 12:40:21] <ke1echi> hi guys
[2018-01-09 12:41:39] <ke1echi> am new to docker...i installed it and ran the quick start but get boot2docker.iso not found locally, pls how do i fix it
[2018-01-09 14:57:42] <ke1echi> pls help
[2018-01-09 17:15:42] <RoryShively> Hey does anyone know what gitbub repo hosts the actual docker engine
[2018-01-09 17:17:26] <RoryShively> And whats up with this Moby stuff? I'm trying to see how docker actually works and need pointers on which repos to look at
[2018-01-09 17:19:30] <FrederikBrinckTruelsen> RoryShively:  [<-LINK->] 
[2018-01-09 17:19:48] <FrederikBrinckTruelsen> only public docker repo I know off
[2018-01-09 17:20:30] <RoryShively> FrederikBrinckTruelsen: Awesome! Exactly what I'm looking for
[2018-01-09 17:42:46] <FrederikBrinckTruelsen> np
[2018-01-09 21:14:16] <mcarpenterjr> Can I direct a docker contaier to use the server's MySQL server?
[2018-01-09 22:19:35] <jgolubenko> yes
[2018-01-10 05:39:26] <siassaj> so
[2018-01-10 05:39:32] <siassaj> turns out docker can be ok useful
[2018-01-10 07:11:54] <truthadjustr> docker is the new drug
[2018-01-10 22:41:01] <nathvi> why would a person use docker on windows?
[2018-01-10 23:32:22] <roychri> Maybe because their on premise machines are running windows and they hope to be able to reuse what they already have...
[2018-01-11 09:45:32] <Scapal> When using multiple secrets in a compose file, the docker stack deploy seems to only bind the first, I have to manually add the others.ex. [<-CODE->] Do you experience the same problem (v17.09 and v17.12) ?
[2018-01-11 10:52:31] <Scapal> nevermind, my bad
[2018-01-11 11:18:58] <pernilsalat> hello guys! a new guy here with the following question: how can i get the same funcionality as-links: [<-CODE->] with depends_on ?
[2018-01-11 11:52:25] <ChazUK> Hey, got a quick question about logging in viadocker loginwith an organisation. Do I just use a specific users account, or is there a way to get an api-key from the org
[2018-01-11 12:59:30] <mikeleg> hi i have a question i use a docker compose with 3 container one of this is mvc .net core api  i need to call another service is into another container.I recived thi error message System.Net.Http.HttpRequestException: An error occurred while sending the request. ---> System.Net.Http.CurlException: Couldn't connect to server
[2018-01-11 16:18:48] <smashingx1> Is there any way to create swarm services with dockerfiles?
[2018-01-12 07:55:18] <ganeshgunaki_twitter> please  join my new chat room for devop learning : [<-LINK->] 
[2018-01-12 11:52:50] <erip> Hi folks. I recently upgraded docker for mac to 17.12.0-ce-mac47. My company has self-signed certs, so we used to add corporate certs to the docker daemon's store by attaching to a screen session and appending certs to the store... I find that this isn't possible anymore.
[2018-01-12 11:53:25] <erip> Interestingly, the daemon tells me if knows of no certs for our corporate registries in my UI. Is there a way to add them from the daemon UI?
[2018-01-12 11:56:50] <erip>  [<-CODE->] 
[2018-01-12 13:22:06] <NurullahCaliskan> hi
[2018-01-12 13:22:21] <NurullahCaliskan> how to EXPOSE port on running container?
[2018-01-12 16:08:55] <roychri> Once its running you mean? Without restarting it?
[2018-01-12 16:09:30] <roychri> I dont think you can, if there's a way, I never found out how
[2018-01-12 16:10:20] <mcarpenterjr> I want to agree, I don't think it's possible while the container is running.
[2018-01-12 16:11:58] <erip> seems like it would be a big security problem if you could
[2018-01-12 22:52:36] <aeos> Does anyone have any insights on why docker for windows throws up "Docker doesn\'t support your windows version." after an update?
[2018-01-12 22:54:04] <autoferrit> does anyone have any good examples on using Docker multi-stage builds to handle differences between local and production environments? In my case, I am using node.js
[2018-01-13 15:02:20] <ke1echi>  [<-LINK->] 
[2018-01-13 15:02:59] <ke1echi> i get that errors after close to an hour of download and it stops downloading.. i need help, what could be wrong?
[2018-01-14 23:06:42] <fayep> Is there any chance that version tags will see a resurgence under moby/moby?
[2018-01-14 23:08:53] <fayep> Right now if you build, you can't run on a 17.12 docker server (latest release) because the API has been bumped to 1.36 which is newer than the 1.35 supported by the docker server without either a) going back to find the Bump API version commit and reverting to the previous commit or b) lying to the server and telling it you're using an older client.
[2018-01-14 23:09:30] <fayep> normally you'd just checkout v1.35 or 17.12 or whatever and be done, but version tags haven't been maintained since 17.05
[2018-01-15 02:45:15] <iDVB> Weird Volume Mounting: Docker for Windows is “sharing” all the host’s drives (c, d,e,f,h) then in the container (docker-compose.yml) I’m mounting them like this… [<-CODE->]  [<-CODE->] 
[2018-01-15 14:03:59] <ganeshgunaki_twitter> Join my community Learn DevOps and Guide the beginners for understanding the DevOps [<-LINK->] via@gitchat
[2018-01-15 14:04:36] <ganeshgunaki_twitter> Join my community Learn DevOps and Guide the beginners for understanding the DevOps   https://gitter.im/DevOps-Getting-Started via @gitchat
[2018-01-15 14:14:23] <bjornamr> Is there any easy solution to split up a build in docker?I want to be able to build something. Then reference that build into another DockerFile to build the rest of the solution
[2018-01-15 14:17:18] <bjornamr> The problem is that I do not want to do pip install -r requirements for the python part every time I build.
[2018-01-15 14:21:58] <bjornamr> So the Ideal would be that I would end up with two DockerFiles. The first one to install dependecies and the other file to reference the image from made from the first dockerfile.
[2018-01-15 15:44:45] <bjornamr> If anyone is wondering how to do it. I solved it using this process described here. It was quite easy: [<-LINK->] 
[2018-01-15 17:43:01] <yosefrow> F
[2018-01-15 20:13:56] <earthquakesan> bjornamr:  [<-LINK->] 
[2018-01-15 22:01:42] <przemolb> If I run the same docker image X times at once on the same server does it allocate memory for each separately or does it work like COW ?
[2018-01-16 02:05:53] <comeUpWithItLater> how to config linux crontab  in  swarm cluster?
[2018-01-16 02:05:56] <comeUpWithItLater> any idea
[2018-01-16 02:47:43] <comeUpWithItLater> the original  crontab :* * * * * /usr/local/php/bin/php /home/wwwroot/default/laravel/artisan schedule:run >> /dev/null 2>&1
[2018-01-16 03:00:16] <comeUpWithItLater> i found this post [<-LINK->] , but what if we run multi replicas of that service ?
[2018-01-16 05:36:08] <SISheogorath> comeUpWithItLater: build an own image for your cronjob and run it as a separate task. Keep in mind it's an unperfect solution because the container may dies before the job was running and comes up again after the job should have run which results in missing the cronjob being done once. If you are using CoreOS/ContainerLinux they have an distributed systemd build in, which is probably capable of doing systemd.timers as well
[2018-01-16 05:38:35] <SISheogorath>  [<-LINK->] 
[2018-01-16 07:48:28] <comeUpWithItLater>  [<-CODE->] using entrypoint now,  seems to work
[2018-01-16 09:57:41] <cuznerdexter> having Karma - Docker - Jenkins issues
[2018-01-16 09:57:43] <cuznerdexter> Anyone know how to pass test results from Karma (in Docker container) back to Jenkins (Jenkins pipeline)??Keep getting “No report files were found” no matter what I try [<-CODE->] 
[2018-01-16 11:43:44] <jmls> so, I started an xterm session, and connected to a background container withdocker exec -it <container> bash: all well and good. The my x session crashed .However, the docker container and bash session inside are still running.Is it possible to reconnect to the existing, running bash session inside this container. Another exec starts a new bash session
[2018-01-16 11:54:23] <cuznerdexter> jmls: I am not docker expert but have you trieddocker attach? [<-LINK->] 
[2018-01-16 11:57:04] <jmls> yes, thanks - but that connects to the entrypoint process
[2018-01-16 11:57:29] <jmls> I need / want to reconnect to the bash session I created before but thanks for helping
[2018-01-16 16:35:01] <yosefrow> jmls: Theres probably a way but why do it? Trying to recover data?
[2018-01-16 16:36:49] <jmls> no - just didn't want to stop a process that I had started in the shell ;)
[2018-01-16 16:40:36] <yosefrow> jmls: tty command should show all tty on system though maybe u need to nsenter to enter namespace of container or run tty from iniside a new tty connection 2 ur container
[2018-01-16 22:29:59] <autoferrit> on my host machine, in my/etc/hostsfile i have a named host for a DB connection. when using compose, is it possible for an app in a container, to get to the db hostname from the host machine? I can tell it to look for the hostname say 'my-remote-db' but should resolve that, or find that hostname on my host machine. on my host machine I can just domysql -uUser -h my-remote-db -pand I can connect.
[2018-01-16 22:30:36] <autoferrit> we need to be able to do this while we transition from using docker for local development and still talk to an existing database that is not dockerized.
[2018-01-16 22:31:33] <autoferrit> sorry i just saw this was for contributors.
[2018-01-17 06:54:57] <SISheogorath> autoferrit:  [<-LINK->] 
[2018-01-17 07:54:54] <staffanselander> Hello everyone.Im ending up with a ~/.docker/machine/machines/default file with the size of 100 gb. I think this size is a little bit big. But i don’t know how to debug this?
[2018-01-17 08:38:54] <bjornamr> earthquakesan: Well it seems like the only way to split it is "temporary" images?
[2018-01-17 08:44:12] <bjornamr>  [<-CODE->] This is the thing i have now. I would love to be able to split this so I can build first part, second part or third part. It seems like the only way here is if I split it on "temp" images using FROM?
[2018-01-17 09:17:26] <comeUpWithItLater>  [<-LINK->] 
[2018-01-17 09:18:27] <comeUpWithItLater> i have config: [<-CODE->] but doesn't seems to work ?
[2018-01-17 09:18:44] <comeUpWithItLater> any ideas ?
[2018-01-17 14:01:33] <mikeleg> i have a problem with my docker-composer, i can't call the api url [<-CODE->] I don't understand way
[2018-01-17 19:47:59] <egucciar> hi all
[2018-01-17 19:48:06] <egucciar> im having difficulty with the install on windows 10
[2018-01-17 19:48:20] <egucciar> would there be any issue with installing Docker on a Windows 10 Virtual Machine?
[2018-01-17 19:48:47] <egucciar> also, my issue is that VMBox is not installed? but it is not listed on the install page that this is required to be pre-installed.
[2018-01-17 19:49:07] <egucciar> I almost installed it manually, but it freaked me out that it would need to disable networking
[2018-01-17 19:49:24] <egucciar> since im using a VM on windows 10 im not sure the impacts to disable networking even temporarily
[2018-01-17 19:49:30] <egucciar> someones help, would be much appreciated.
[2018-01-17 22:46:53] <jason-timios> Hello everyone, I am trying to use a docker container to contain a wordpress install, but I can only see the site if i do-p 80:80vs-p 1024:80any ideas as to what might be happening?
[2018-01-17 23:30:13] <NicoTexas> Did you try [<-LINK->] 
[2018-01-17 23:32:01] <jason-timios> yup, but it keeps getting re-written to localhost:80
[2018-01-17 23:32:10] <jason-timios> that is the crux of the problem
[2018-01-17 23:32:53] <jason-timios> Just wondering if there is anything on the docker side that I can do to prevent that, but probably not
[2018-01-17 23:33:05] <jason-timios> seems more like a wordpress thing than a docker one
[2018-01-18 03:27:01] <NuiStrawBerry> Hi all，I use docker to run a spring boot application.When run the follow cmds docker run --rm -it downloadcode:v1 java -Dsun.jnu.encoding=UTF-8 -jar download.jar . It gives out a IOException cloud not rename the file.But when I enter the container and run java -Dsun.jnu.encoding=UTF-8 -jar download.jar ,it just runs without any exception. Why?
[2018-01-18 03:31:38] <lpwang> -rm means Automatically remove the container when it exits,did you exit you container??
[2018-01-18 03:35:14] <NuiStrawBerry> 没有退出，正常的运行报异常
[2018-01-18 03:37:53] <lpwang> 我觉得应该先stop正在运行的container再执行带rm参数的命令。
[2018-01-18 03:43:33] <NuiStrawBerry> 不是的，其实可以不考虑那个 --rm参数的，有没有它都是一样的结果。
[2018-01-18 06:17:47] <comeUpWithItLater> some  oriental guys ...
[2018-01-18 12:20:55] <nielspedersen> How do you provide a config argument to a postgres image in adocker-compose.yml?
[2018-01-18 13:19:46] <matrixbot> MortyWith environments
[2018-01-18 13:21:03] <matrixbot> Mortyservices:\n    postgresql:\n        image: postgres:9.6\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB}\n            POSTGRES_USER: ${POSTGRES_USER}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n        healthcheck:\n            test: ["CMD-SHELL", "pg_isready"]\n            interval: 10s\n            timeout: 10s\n            retries: 6
[2018-01-18 13:21:12] <matrixbot> MortySomething like this
[2018-01-18 13:30:17] <matrixbot> Mortymaybe you want to change de default cmd ?
[2018-01-18 14:36:48] <darrist> I have a Dockerfile which looks like below, and I'm having issue where if docker-compose is run by user it cannot seem to find/usr/share/app/entrypoint.shor/usr/..../manage.py. If I runsudo docker-compose build && sudo docker-compose ... up -das sudo it will run. [<-CODE->] 
[2018-01-18 15:10:42] <matrixbot> MortyCan you share the failing ouput ? binary (Gitter)
[2018-01-18 16:13:44] <darrist>  [<-CODE->] 
[2018-01-18 17:03:47] <nielspedersen> matrixbot: thanks, I ended up creating environment variables as well :)
[2018-01-18 21:10:56] <slim-hmidi> Hi, I created a job which allows to populate the tables with data when the service was created. Is it possible to relaunch the same or a new job to backup the data of some table to be considered for the population of the next creation of services?
[2018-01-18 21:33:10] <janega> anyone a keycloak expert here?
[2018-01-18 22:32:08] <rmagnum2002> Hi everyone, new to docker, when running docker build . it fails at this step [<-CODE->] where exactly this path should be created? not on my computer I assume
[2018-01-19 06:28:43] <SISheogorath> rmagnum2002: when you rundocker build .(maybe with more parameter) the entire content of the directory represented in the last argument is sent to the docker service which that again places this directory structure in this tmp dir. depending on where you dockerd (docker service) runs, it's placed there. And it looks like there is a file missing in your directory.
[2018-01-19 07:56:20] <claudio-viola> hello everybody does anyone know how to fix "WARNING: no logs are available with the \'syslog\' log driver” when running docker-compose? container exits immediately after going up
[2018-01-19 08:16:19] <SISheogorath> claudio-viola: well, what does your syslog say?
[2018-01-19 08:40:14] <claudio-viola> hi christoph, i am not sure how to check that as the container exits immediately
[2018-01-19 08:46:32] <claudio-viola> SISheogorath: /var/log/docker.log within docker-machine
[2018-01-19 08:46:35] <claudio-viola> time="2018-01-19T08:45:15Z" level=debug msg="event published" module="containerd/containers" ns=moby topic="/containers/delete" type=containerd.events.ContainerDelete\ntime="2018-01-19T08:45:15.996890606Z" level=debug msg="Calling GET /v1.30/containers/json?all=0&limit=-1&trunc_cmd=0&size=0"\ntime="2018-01-19T08:45:16.001936164Z" level=debug msg="Calling GET /v1.30/containers/99cfaeb1194f3175a1eef1df7ac52589ad8e8051b9dd0549bf53c0260628336a/json"\ntime="2018-01-19T08:45:16Z" level=debug msg="event published" module="containerd/events" ns=moby topic="/tasks/exit" type=containerd.events.TaskExit\ntime="2018-01-19T08:45:16.075778934Z" level=debug msg=event module=libcontainerd namespace=moby topic=/tasks/exit\ntime="2018-01-19T08:45:16Z" level=debug msg="received signal" module=containerd signal=child exited\ntime="2018-01-19T08:45:16Z" level=info msg="shim reaped" id=99cfaeb1194f3175a1eef1df7ac52589ad8e8051b9dd0549bf53c0260628336a module="containerd/tasks"\ntime="2018-01-19T08:45:16Z" level=debug msg="event published" module="containerd/tasks" ns=moby topic="/tasks/delete" type=containerd.events.TaskDelete
[2018-01-19 09:14:54] <SISheogorath> well, you configured your container to use syslog. syslog is not docker.log
[2018-01-19 09:16:49] <claudio-viola> i didnt configure anything its all defaulted
[2018-01-19 09:16:58] <claudio-viola> docker-machine create default docker-machine start
[2018-01-19 09:17:25] <claudio-viola> the compose file is also not being set to use any specific logging driver
[2018-01-19 09:20:05] <claudio-viola> at least thats what i see :(
[2018-01-19 09:37:07] <allienna> Hi,I try to connect a personal liquibase container to a Postgres one. But I faced with some weird problem.I use this [<-CODE->] But, liquidabase start when Postgres restart. [<-CODE->] 
[2018-01-19 09:46:50] <rmagnum2002> SISheogorath: thank you, found the issue, there was indeed a missing folder and files in it required
[2018-01-19 13:54:33] <SISheogorath> rmagnum2002: You're welcome
[2018-01-19 13:58:19] <ShionAt> I shamelessly show ShionKeys to everyone [<-LINK->] 
[2018-01-19 13:58:53] <SISheogorath> allienna: first of all, don't use links, they will die in future versions. Also please check [<-LINK->] 
[2018-01-19 14:00:49] <SISheogorath> claudio-viola: interesting, what system are you running on? Windows, Linux, MacOS?
[2018-01-19 14:00:58] <claudio-viola> MacOS
[2018-01-19 14:23:37] <claudio-viola> I fixed …. upgraded docker-machine to latest
[2018-01-19 14:23:44] <claudio-viola> I was on 0.10
[2018-01-19 14:46:52] <SISheogorath> Sounds good :D
[2018-01-19 14:57:19] <grofit> Anyone here hosting docker images in AWS?
[2018-01-19 14:58:11] <grofit> as I am having a nightmare trying to get a non HTTP based container running there and the docs on AWS are useless if you are wanting to be non HTTP
[2018-01-19 15:11:32] <bossmankudz_twitter> hi am developing an enterprise angular 4 application which is run a secure server with several proxies. i have a get request which downloads documents from the server . but the problem is users are getting an error downloading the documents. there is no way for me to see the error in developer tools since the users dont have access to developer tool. this application is a government application which runs on a very secure network. some of these request never make it to the server. the main problem is when angular receives and error it treats it like a progress event instead of a serialised json response
[2018-01-19 15:12:30] <bossmankudz_twitter>  [<-LINK->] 
[2018-01-19 15:56:47] <josecolella> hello everyone, I'm trying to use docker compose to have a expressjs application talk to a redis container, but the problem is that the nodejs won't connect to the redis instance. [<-CODE->] Any suggestions?  This is my node redis connection [<-CODE->] 
[2018-01-20 07:30:04] <comeUpWithItLater> how to   retrieve the real client ip in docker swarm mode  ？  issue : [<-LINK->] 
[2018-01-20 07:30:11] <comeUpWithItLater> any idea ?
[2018-01-21 00:00:27] <rcjsuen> I want to build an image and then tag it. So I dodocker build -t x/y .and then will rundocker tag. If I then performdocker push x/yis it pushing a)latest, b) the tag, or c) bothlatestand the tag?
[2018-01-21 00:15:11] <rcjsuen> I guess I'll just usedocker pushtwo times withlatestand then tag, nothing wrong with that.
[2018-01-21 10:12:27] <SISheogorath> rcjsuen: I noticed that the easiest way to push all taggs to docker hub is this: [<-LINK->] 
[2018-01-21 11:19:37] <rcjsuen> Thanks for the tip
[2018-01-21 21:22:13] <nirtal85> i am using windows 10
[2018-01-21 21:22:17] <nirtal85> how do i fix this error
[2018-01-21 21:22:39] <nirtal85> error during connect: Get      http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.33/info: open //./pipe/docker_engine: The system cannot find the file specified. In the default daemon configuration on Windows, the docker client must be run elevated to connect. This error may also indicate that the docker daemon is not running.
[2018-01-21 21:23:34] <nirtal85> searched the internet but did not find any good explanation
[2018-01-21 21:33:05] <mberndt123> I\'m running an application I\'ve written in a docker container. It listens on 9000/tcp and 9011/tcp. When I run it withdocker run -p9000:9000 -p9011:9011, it starts fine and I can connect and communicate through port 9000. However it doesn\'t work with port 9011, I keep getting "Connection reset by peer."
[2018-01-21 21:36:21] <mberndt123> Same if I map it onto another port, like-p 1234:9011
[2018-01-21 21:36:59] <mberndt123> and my Dockerfile does have anEXPOSE 9000 9011line
[2018-01-21 21:37:27] <mberndt123> I don't think it's the application's fault because it works just fine outside the container
[2018-01-21 21:39:08] <rcjsuen>  [<-CODE->] Publish all exposed ports to the host interfaces
[2018-01-21 21:42:26] <mberndt123> that publishes ports on random ports
[2018-01-21 21:42:56] <mberndt123> OK, tried it anyway. same issue
[2018-01-21 21:45:09] <nirtal85> Can anyone help?
[2018-01-21 21:55:42] <rcjsuen> If you only expose9011does that work?
[2018-01-22 00:59:25] <mberndt123> No
[2018-01-22 01:07:09] <mberndt123> ugh, I think I've figured it out.
[2018-01-22 01:07:25] <mberndt123> The application binds on 127.0.0.1, I guess it should bind on 0.0.0.0 instead.
[2018-01-22 03:16:55] <sgronblo> Is there currently some workaround available for --net=host referring to the xhyve VM on Macos? In other words, can I access an ssh tunnel on the Macox host from a docker container somehow?
[2018-01-22 04:42:26] <sgronblo> Ok, I found that you can use net bridge with the DNS namedocker.for.mac.localhost
[2018-01-22 21:25:03] <stephenchu> is there a way filterdocker imagesresults with "not equal" (e.g.docker images --all <repo> --filter "label=foo!=42")?
[2018-01-23 00:06:55] <ArStah> Hi guys, help me please
[2018-01-23 00:08:57] <ArStah> I have a project in git repo,  it contains several submodules. I use docker-compose to create containers, and each submodule is a service in docker-compose
[2018-01-23 00:11:49] <ArStah> One of services - node application, and when i runnpm installin container - the error is caused: [<-CODE->] 
[2018-01-23 00:13:30] <ArStah> That causes because there is.gitfile in that folder, that specify where the actually git repository located, but i have no ideas how to solve it
[2018-01-23 02:48:19] <ppLorins>  [<-CODE->]  [<-CODE->]  [<-CODE->] Environment:Docker CE 17.09.1 build 19e2cf6Centos 7
[2018-01-23 02:48:58] <ppLorins> ---dir-root--- dir-sub1--- dir-sub2
[2018-01-23 02:49:46] <ppLorins> dir-rootis the parent directory ,and  thedir-sub1anddir-sub2are all direct child ofdir-root
[2018-01-23 06:29:47] <devd16689> Has anyone worked on kubernetes here?
[2018-01-23 06:43:18] <matrixbot> rarkDevD (Gitter): yes
[2018-01-23 09:26:58] <CharlLescott_twitter> Hey all, anyone here looking for a new opportunity in London to join a tech start up as co-founder. Competitive salary + equity given.
[2018-01-23 10:44:13] <GiddeonWyeth> Hello everyone!
[2018-01-23 10:45:17] <GiddeonWyeth> Can someone explain me how can I create data volume which i will be able to share with containers via docker-compose file
[2018-01-23 10:45:49] <GiddeonWyeth> volumes:data-volume:
[2018-01-23 10:47:12] <GiddeonWyeth> I found that I can make it like this in compose file but I can't undestant how to configure the data which will be inside that volume and also can I use Dockerfile for volume as well
[2018-01-23 10:47:16] <GiddeonWyeth> thank you!
[2018-01-23 10:57:11] <cebor> hi, is it possible to run docker 4 mac, as systemuser when no user is logged in?
[2018-01-23 11:04:39] <Bhushan001> is it possible to provide running mongodb instance while building a docker image?
[2018-01-23 13:02:00] <ifelsemonkey_twitter> GiddeonWyeth: u can attach the volume into a container and see contents
[2018-01-23 13:36:13] <GiddeonWyeth> ifelsemonkey_twitter: How can I do this?
[2018-01-23 18:23:11] <nirtal85> --add-host localhost:8080 fail - how can this be performed?
[2018-01-23 22:41:46] <kobvel> Guys, I am struggling to get environment variables in the Dockerfile process from Docker-compose
[2018-01-23 22:45:29] <yosefrow> mikki pls be specific. where do u want env to come from and where do u want it to go
[2018-01-23 22:45:57] <kobvel> yosefrow:  [<-LINK->] 
[2018-01-23 22:46:14] <kobvel> in the root of the project there is docker compose
[2018-01-23 22:46:37] <kobvel> I am trying to pass     - PEERS= [<-LINK->] 
[2018-01-23 22:46:45] <kobvel> 48 Line of Code
[2018-01-23 22:47:00] <yosefrow> to inside container?
[2018-01-23 22:47:45] <kobvel> yes, inside of the nested Dockerfile
[2018-01-23 22:47:48] <kobvel> forwalletnode
[2018-01-23 22:47:57] <kobvel> I am running a script
[2018-01-23 22:47:59] <kobvel>  [<-LINK->] 
[2018-01-23 22:48:18] <kobvel> which relies on theprocess.env.PEERSvariable
[2018-01-23 22:48:23] <kobvel> which is undefined for some reason
[2018-01-23 22:48:41] <yosefrow> use docker compose environment or env_file
[2018-01-23 22:49:06] <kobvel> I do use environment
[2018-01-23 22:49:11] <yosefrow> or in Dockerfile use ENV
[2018-01-23 22:49:17] <yosefrow> your choice
[2018-01-23 22:49:25] <kobvel> environment does not work
[2018-01-23 22:49:33] <kobvel> what was the last option?
[2018-01-23 22:49:38] <kobvel> ENV?
[2018-01-23 22:49:50] <yosefrow> docker compose environment does work
[2018-01-23 22:50:18] <yosefrow> if its not working 4 u it may be misconfigured
[2018-01-23 22:50:46] <yosefrow> ENV in Dockerfile makes it part of the image
[2018-01-23 22:51:19] <yosefrow> it will then appear in any container run from that image
[2018-01-23 22:51:56] <kobvel> environment works for my server nodes, but not during the run of the Dockerfile
[2018-01-23 22:52:00] <yosefrow> docker compose environment adds it after container already running
[2018-01-23 22:52:08] <kobvel> aaaa
[2018-01-23 22:52:10] <kobvel> I see
[2018-01-23 22:52:14] <yosefrow> I mean at run time
[2018-01-23 22:52:39] <kobvel> that is an answer
[2018-01-23 22:53:01] <yosefrow> choose a method that is best 4 u
[2018-01-23 22:53:04] <kobvel> so .env file should solve the issue probably
[2018-01-23 22:53:27] <yosefrow> .env file... not sure Dockerfile reads that
[2018-01-23 22:53:36] <yosefrow> haven't tried
[2018-01-23 22:53:49] <yosefrow> I know compose reads it
[2018-01-23 22:54:19] <kobvel> I will try
[2018-01-23 22:54:24] <kobvel> thank you very much
[2018-01-23 22:54:28] <kobvel> you made my day!
[2018-01-23 22:54:47] <yosefrow> worst case use dockerfile ARG
[2018-01-23 22:55:03] <yosefrow> to pass it at command line
[2018-01-23 22:55:09] <yosefrow> np
[2018-01-24 00:35:25] <ArStah> kobvel: you can use ARG as@yosefrowsaid, but you don't have to specify it only while launching via command line, you can use [<-LINK->] of yourdocker-composefile
[2018-01-24 00:46:54] <kobvel> Is there a way to find a host address of the docker container inside of Applicaiton?
[2018-01-24 00:47:30] <kobvel> right now I am passing a DOCKER_HOST as an variable to the Node.js server, but I believe there should be a better way to do that
[2018-01-24 00:47:31] <kobvel> ArStah: 
[2018-01-24 00:48:07] <ArStah> Really don't know
[2018-01-24 00:49:09] <ArStah> You can mount/etc/hostnamefrom host to container, for example
[2018-01-24 00:49:55] <ArStah> But you'll have it only after launch, not while build
[2018-01-24 02:27:21] <jacarrichan> [root@localhost~]# docker-compose -version-bash: /usr/local/bin/docker-compose: Permission denied
[2018-01-24 02:27:28] <jacarrichan> How  to  fix it ？
[2018-01-24 02:36:35] <jacarrichan> FIXed
[2018-01-24 02:37:07] <jacarrichan> because  docker-compose    has not  executeable  permission
[2018-01-24 02:37:21] <jacarrichan> chmod  755  docke-compose  。
[2018-01-24 02:37:22] <jacarrichan> done
[2018-01-24 12:02:04] <ddd07009655_twitter> Hello, is it possible to connect 2 sockets at the same time?
[2018-01-24 12:02:51] <ddd07009655_twitter> smth like: "docker -H tcp://host1:2375,tcp://host2:2375 ps"?
[2018-01-24 12:03:10] <ddd07009655_twitter> from docker --help it's not clean if it's possible
[2018-01-24 12:03:48] <ddd07009655_twitter> -H, --host list          Daemon socket(s) to connect to (default [])
[2018-01-24 12:04:23] <ddd07009655_twitter> it sounds like we can use more then 1 sockets/docker hosts at the same time, but how to do that not clear
[2018-01-24 12:04:28] <ddd07009655_twitter> Thanks in advance
[2018-01-24 12:29:05] <zigzagzoozoo_twitter> hi guys. can anyone help with this proxy problem? i\'m trying to build an image from a dockerfile, base image is node:9-alpine. in this file i run "npm install ..." and i get "FetchError: request to [<-LINK->] failed, reason: connect ECONNREFUSED 151.101.112.162:443". i have set the proxy for npm, and the proxy is also set in the env. if i specifiy the proxy in the Dockerfile in this manner: "ENV http_proxy= [<-LINK->] " the build completes succesfully. but i don\'t want to set the proxy for the conainer itself. so i tried to use call "docker build" command with the argument "--build-arg HTTP_PROXY= [<-LINK->] " but sadly this does not work and i get the ECONNREFUSED error described above. any ideas on this? or is it npm specific?
[2018-01-24 13:34:35] <jemliF> hi guys
[2018-01-24 13:34:52] <jemliF> I have an issue with Docker volumes
[2018-01-24 13:36:19] <jemliF> I cannot delete a file inside of a sharedvolumefromDocker host
[2018-01-24 13:36:55] <jemliF> I started the container like this:
[2018-01-24 13:37:28] <jemliF> docker run -d --name container --env-file=./.env -v ${PWD}/:/opt/project image tail -f /dev/null
[2018-01-24 13:38:18] <jemliF> now, I found myself unable to delete any file in the current folder (PWD)
[2018-01-24 13:40:50] <jemliF> **To be specific I am using Docker in Gitlab-CI, first of all I start this container and  I usedocker execto run later jobs inside of it
[2018-01-24 13:41:41] <jemliF> From job to job I get this warning
[2018-01-24 13:41:55] <jemliF> warning: failed to remove apps/.scannerwork/report-task.txtwarning: failed to remove apps/.scannerwork/class-mapping.csvwarning: failed to remove apps/.scannerwork/.sonar_lock
[2018-01-24 13:42:06] <jemliF> and my job fails
[2018-01-24 13:42:18] <jemliF> ERROR: Job failed: exit status 1
[2018-01-24 13:45:30] <ArStah> jemliF: had the same issue, and didnt figure it out, i think thatgitlab-runnerdoesn't  supose to launch docker images, maybe i'm wrong
[2018-01-24 13:49:13] <jemliF> ArStah: I know that it's not the recommended way of using Docker with Gitlab CI but I have some limits that forced me to do it this way
[2018-01-24 13:50:57] <ArStah> jemliF: hope you'll find a solution, because i need it too)
[2018-01-24 13:59:23] <jemliF> ArStah: okay, no problem
[2018-01-24 23:47:02] <bshankar_dude_twitter> have a question..i am using this template to deploy docker swarm onto our aws
[2018-01-24 23:47:21] <bshankar_dude_twitter>  [<-LINK->] 
[2018-01-24 23:47:38] <bshankar_dude_twitter> looks like its exposing all the services through external ELB
[2018-01-24 23:47:59] <bshankar_dude_twitter> i am working on this so it creats internal LB and all instances registers to it
[2018-01-24 23:48:15] <bshankar_dude_twitter> question , i have is how do i register with internal LB
[2018-01-24 23:48:37] <bshankar_dude_twitter> i see in user-data section., its adding externallb to /var/lib/docker/editions/elb.config
[2018-01-24 23:48:52] <bshankar_dude_twitter> anyone has experience of adding one more load balancer to it ?
[2018-01-24 23:49:20] <bshankar_dude_twitter> do i need to modify the same file..there is not much docs around this ..and this is using Moby Linux 17.12.0-ce-aws1 stable (ami-42f3f322)
[2018-01-25 01:02:21] <bshankar_dude_twitter> any assistance ?
[2018-01-25 23:18:52] <igrayson> Has anyone figured out how to make log lines larger than 16Kb to play nicely with syslog (specifically, syslog-ng)? I'd like syslog-ng to be able to stitch those chunks back together, but it seems like docker is just taking my original string, and splitting it with indistinguishable\\ns before shipping it off to my syslog-ng service.
[2018-01-26 14:51:44] <fdisp> hi guys
[2018-01-26 14:52:01] <fdisp> im a complete noob in docker
[2018-01-26 14:53:59] <SISheogorath> Hi@fdispthen feel free to change it :) ask questions and try to find solutions^^ The docs are a wonderful place to start and if you want something more interactive, go for [<-LINK->] 
[2018-01-26 14:56:50] <hullsean> fdisp: all gotta start somewhere :)
[2018-01-26 14:57:09] <fdisp> i need to understand the basic concepts of what it is and what can be done with it. if someone knows a book, source, docs or anything adapt for this purpose please give me a mention
[2018-01-26 14:58:08] <SISheogorath> fdisp: Here you go: [<-LINK->] 
[2018-01-26 14:58:34] <SISheogorath> For everything else: [<-LINK->] 
[2018-01-26 14:58:52] <SISheogorath> Also maybe visit one of the local Meetups close to you :)
[2018-01-26 14:59:08] <SISheogorath>  [<-LINK->] 
[2018-01-26 17:12:23] <cuznerdexter> Hi anyone, how do you save karma junit xml file in a docker container and then report to jenkins?? I have tried over 300 times in jenkins pipeline and always no xml file found!
[2018-01-26 19:40:48] <hullsean> cuznerdexter: Are you sure you've tested as the user jenkins runs as?  I would guess it is either writing to the wrong path or doesn't have permissions on the path you specify.  Perhaps there is an error somewhere that jenkins has logged
[2018-01-27 05:53:56] <fouadroumieh> is it possible to set the interactive mode of a container inside dockerfile? This is not working CMD [ "-D", "FOREGROUND" ]
[2018-01-28 12:10:33] <AnorakTech_twitter> Hi there. I have a 2 docker containers running. Is it possible to move one image/container to another partition? I want to keep the first container in the default /var/lib/docker folder, but move the 2nd one to another place.
[2018-01-28 12:57:49] <SISheogorath> fouadroumieh: no, but you can check the official apache image, they use a script for this. [<-LINK->] 
[2018-01-28 12:59:32] <SISheogorath> AnorakTech_twitter: no. Container always run stateless in your docker directory which is when you don't do fundamental changes in/var/lib/docker. What you can change is the location of your volumes. But only when you use bind mounts or a non-default volume driver
[2018-01-28 13:46:17] <AnorakTech_twitter> Cool, thanks.
[2018-01-29 09:01:04] <comeUpWithItLater> anyone using [<-LINK->] 
[2018-01-29 09:02:25] <comeUpWithItLater> what's the advantages / disadvantages comparing  with the build-in docker config？
[2018-01-29 13:37:58] <elbsurfer> Hello, I have 20gb free space on my HDD, but my docker mysql image tells me this: "Got error 28 from storage engine" which says that there is not enough space left. How can I fix that?
[2018-01-29 18:28:21] <FrederikBrinckTruelsen> which image are you using?
[2018-01-30 01:49:19] <outkaj> Hello! What is the most straightforward method/utility to back up a running container with its volume directory? (I'd like to avoid something like:docker commit, create an intermediate container, copy the volume into the intermediate container and tar it, untar it into the committed version, etc, if possible), as I have to do this a number of times.
[2018-01-30 06:41:50] <comeUpWithItLater>  [<-LINK->] 
[2018-01-30 06:43:00] <comeUpWithItLater> how to access  my workstation machine((192.168.1.32))  from inside docker container ?
[2018-01-30 06:43:29] <comeUpWithItLater> SISheogorath: any idea ?
[2018-01-30 10:34:19] <SISheogorath> outkaj: you shouldn't need to backup the container itself. Only the volumes. There it highly depends on your filesystem underneath. If you go for a storage system, snapshot the filesystem but make sure you don't have some caching in-between as NFS does. If you run on a local filesystem or a NAS you sadly have to stop the container, make a copy, start it again. At least when you want it reliable. If you have less stateful data you can also copy it on the fly, but it's risky. Given the luck that you run btrfs or zfs underneath you can also simply use their snapshot featues.
[2018-01-30 10:35:24] <SISheogorath> elbsurfer: keep in mind that docker searches space in /var/lib/docker not in the location you run the command
[2018-01-30 10:36:45] <SISheogorath> comeUpWithItLater: keep in mind there is maybe a firewall doing ugly things. Also this doesn't work when you run it on a VM that does NAT on the network device. Otherwise I have not really an idea .-.
[2018-01-30 14:39:50] <ghost~56fc9ded85d51f252abbbbad> Hello
[2018-01-30 14:40:38] <ghost~56fc9ded85d51f252abbbbad> I am trying to setup Jenkins in a docker container, now for my understanding if I run it with port exposure 8080:8080 then connecting to the host ip:8080 I should see the jenkins instance running in the container right?
[2018-01-30 15:32:03] <LanderU> cisco87: you're right
[2018-01-30 15:32:27] <LanderU> is this port available in your system?
[2018-01-30 15:33:32] <LanderU> docker run -p 8080:8080 -p 50000:50000 -v /your/home:/var/jenkins_home jenkins
[2018-01-30 15:34:05] <LanderU> from: [<-LINK->] 
[2018-01-30 15:34:14] <ghost~56fc9ded85d51f252abbbbad> yeah@LanderUthis is how I am running it, but I can't even connect from the host using links 127.0.0.1:8080
[2018-01-30 15:34:29] <ghost~56fc9ded85d51f252abbbbad> if I go in the container I can links into it
[2018-01-30 15:37:09] <LanderU> I'm testing it , and it works perfectly for me
[2018-01-30 15:37:21] <LanderU>  [<-LINK->] 
[2018-01-30 15:37:28] <ghost~56fc9ded85d51f252abbbbad> shit
[2018-01-30 15:38:09] <ghost~56fc9ded85d51f252abbbbad> ok but that is another image
[2018-01-30 15:38:30] <ghost~56fc9ded85d51f252abbbbad> that says that that image is discontinued and to use jenkins/jenkins:lts
[2018-01-30 15:38:43] <LanderU> which one are you using?
[2018-01-30 15:38:53] <ghost~56fc9ded85d51f252abbbbad> jenkins/jenkins:lts
[2018-01-30 15:39:03] <LanderU> I'll try it as well
[2018-01-30 15:41:22] <LanderU> same result
[2018-01-30 15:42:15] <LanderU> could be a problem with your network configuration?
[2018-01-30 15:43:29] <ghost~56fc9ded85d51f252abbbbad> mh it's a digitalocean box
[2018-01-30 15:59:37] <ghost~56fc9ded85d51f252abbbbad> thanks@LanderUI will try to understand what's going on better
[2018-01-30 16:39:28] <outkaj> SISheogorath: thank you for the thorough answer! that is very helpful and it makes sense re: needing to stop the container, as well.
[2018-01-30 18:59:54] <oanapat> hello everyone, I am new to Docker and love it! I have a question, can anyone recommend some good articles regarding Why to use Docker? The benefits of Docker?  My arguments need a bit of polishing since I will present them to a room full of my fellow devs :) (I did Google the above but wanted some recommendations from the community) Thank you :)
[2018-01-30 22:19:11] <cuznerdexter> hullsean: Thanks for the advice. You were correct, ultimately it was to do with wrong paths being interpreted. Finally I got the karma tests passed back to Jenkins and reporting. Took me 395 attempts though!
[2018-01-30 22:27:04] <cuznerdexter> hullsean: Maybe you can advise -  What is best way to run a ci/cd pipeline with docker and jenkins pipeline?We want to run the tests in the dev code, then if they pass we build the prod code and deploy nginx prod server. I tried a docker multi build - seems like wrong approach. Maybe docker compose is better?
[2018-01-31 02:30:04] <AshokRajuDevops> helloall
[2018-01-31 02:31:17] <AshokRajuDevops> i am getting below exception after upgrading carbon stack to 1.1.1
[2018-01-31 02:32:24] <AshokRajuDevops> 2018-01-30,13:49:27.757 :: Exception encountered in <POST http://x.x.x.x:8888/render?from=-6h&until=19:01_20180130&maxDataPoints=323&format=json&preventCache=1517320164645>Traceback (most recent call last):File "/usr/local/lib/python2.7/dist-packages/django/core/handlers/base.py", line 132, in get_responseresponse = wrapped_callback(request,callback_args, *callback_kwargs)File "/opt/graphite/webapp/graphite/render/views.py", line 117, in renderViewdata.extend(evaluateTarget(requestContext, targets))File "/opt/graphite/webapp/graphite/render/evaluator.py", line 15, in evaluateTargetprefetchData(requestContext, pathExpressions)File "/opt/graphite/webapp/graphite/render/datalib.py", line 255, in prefetchDatafor result in STORE.fetch(pathExpressions, startTime, endTime, now, requestContext):File "/opt/graphite/webapp/graphite/storage.py", line 138, in fetchraise Exception(\'All fetches failed for %s\' % (str(patterns)))Exception: All fetches failed for
[2018-01-31 02:33:02] <AshokRajuDevops> any idea?
[2018-01-31 05:06:39] <yosefrow> cuznerdexter: your workflow seems perfect for gitlab-ci rather than jenkins
[2018-01-31 05:09:11] <yosefrow> cuznerdexter: for development/manual testing docker compose overrides/templates is a decent approach. it lets you override a base docker compose template with other env specific templates
[2018-01-31 05:10:19] <yosefrow> for true ci and unique env id go ultimately with kubernetes in addition to gitlab ci which I mentioned before. but there's a learning curve
[2018-01-31 05:34:59] <rumes> Hey their is anyway to make container command globally available?.
[2018-01-31 08:38:17] <cuznerdexter> yosefrow: Thanks for the great advice. Gitlab-ci sounds good.  All our pipelines are currently using Jenkins (in mind to move to Kubernetes). For now I have to find a solution using Docker ...
[2018-01-31 11:46:29] <felps> good day to all...May I join in and ask for some assistance? I am running a docker swarm and having this strange issue.Adding a network to a service will stop it from coming up and be stuck at "starting". Anyone have any idea on how to tackle this issue?
[2018-01-31 12:03:00] <cs-mahmoud-khateeb> is there a way to let a container (in bridge mode) use the host for dns queries without hardcoding the host ip address within the container ?
[2018-01-31 12:17:40] <felps> cs-mahmoud-khateeb: why would you do that?
[2018-01-31 12:18:02] <felps> the container already "inherits
[2018-01-31 12:18:13] <felps> " the resolv.conf file from the host
[2018-01-31 12:18:44] <felps> so, pretty much, any address the host can resolve the container could also no?
[2018-01-31 12:26:55] <DaniGuardiola> Hi, I have this.dockerignorefile: [<-CODE->] 
[2018-01-31 12:27:26] <DaniGuardiola> then my dockerfile doesCOPY . /app
[2018-01-31 12:28:13] <DaniGuardiola> it copies only the.jsfiles on the root (in this case themain.jsfile on my project)
[2018-01-31 12:28:30] <DaniGuardiola> however, it ignores.jsfiles in directories (in my case,src/)
[2018-01-31 12:28:46] <DaniGuardiola> if I add!src/*.jsit works
[2018-01-31 12:29:35] <DaniGuardiola> but**/*.jsis supposed to match any.jsfiles anywhere no matter the depth
[2018-01-31 12:29:48] <DaniGuardiola> so I don't think I'm doing anything wrong here, but it is not working
[2018-01-31 12:31:21] <cs-mahmoud-khateeb> felps: it doesn't work if the host's resolver lives on the hosts itself (in case of having a discovery service for example). I am using172.17.0.1but I feel it's a hack that will give me headache down the road.
[2018-01-31 12:34:42] <felps> @cs-mahmoud-khateeb I believe you can set the IP for the dns in the daemon.json (so, in your local docker daemon) instead of setting it in the container itself.It may not be as clean as you would hope but at least it keeps matter separated.https://docs.docker.com/engine/userguide/networking/default_network/custom-docker0/
[2018-01-31 12:35:18] <felps> then you can set the dns to be whatever the host's IP is
[2018-01-31 12:36:48] <cs-mahmoud-khateeb> I have thought about this, it's a bit messy if you have an ecs cluster with multiple ec2 instances each running its own instance of service discovery which is acting as a dns.
[2018-01-31 12:38:14] <matrixbot> MortyDo you know a tip or a command to find which container is using all my disc ?
[2018-01-31 12:38:15] <felps> I do believe, however, that the IP you are using will be fine for the foreseeable future
[2018-01-31 12:38:39] <matrixbot> MortyFiles are in /var/lib/docker/overlay2/XXXXXX and finding the attached container is not that simple
[2018-02-01 04:42:24] <comeUpWithItLater>  [<-LINK->] 
[2018-02-01 04:43:07] <comeUpWithItLater> how to config to allow my co-workers to access my local docker swarm ?
[2018-02-01 04:43:42] <comeUpWithItLater> my ip is 192.168.1.32
[2018-02-01 06:22:11] <sxpistols> can i used symlinks dir for docker data dir?
[2018-02-01 08:54:59] <hi1027> How Can docker for Mac find the physical files of the container
[2018-02-01 08:57:09] <hi1027> I want to modify a configuration file for a container that can not be started
[2018-02-01 09:17:49] <SISheogorath> sxpistols: I didn't test it, but I would say, don't
[2018-02-01 09:19:26] <brettminnie> zshzj: I'd launch the container by overriding the entry point to use your base shell, then modify the file, exit and use the docker commit command on the exited container
[2018-02-01 09:22:08] <hi1027> brettminnie: I'm a novice, can I have a little detail? Thanks
[2018-02-01 09:25:42] <brettminnie> something likedocker run --entrypoint "/bin/bash" my_containerwhich should drop you into the shell as root, then once you have made your changes, you can usedocker ps -ato list the exited containers
[2018-02-01 09:26:30] <brettminnie> ie09:26 $ docker ps -a\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                     PORTS               NAMES\n1cb825b61409        phusion/baseimage   "/sbin/my_init"     10 seconds ago      Exited (0) 3 seconds ago                       cranky_sinoussi
[2018-02-01 09:27:03] <brettminnie> then using that container id from there, you can use docker commit to save the exited container
[2018-02-01 09:27:11] <brettminnie>  [<-LINK->] 
[2018-02-01 09:28:25] <brettminnie> 09:26 $ docker commit 1cb825b61409 containersauce\nsha256:8bb3c1ca69ff08e87b3418c436b22c0004f6b1fe17230e3ff9560c2e02c06791\n09:27 $ docker images | grep container\ncontainersauce          latest              8bb3c1ca69ff        8 seconds ago       209M
[2018-02-01 09:29:01] <brettminnie> excuse the line bleed seems gitter doesn't respect the new lines :(
[2018-02-01 09:29:06] <comeUpWithItLater> SISheogorath: 
[2018-02-01 09:29:10] <comeUpWithItLater> how to config to allow my co-workers to access my local docker swarm ?my ip is 192.168.1.32
[2018-02-01 09:29:30] <comeUpWithItLater>  [<-LINK->] 
[2018-02-01 09:31:32] <hi1027> brettminnie: 
[2018-02-01 09:32:12] <hi1027> brettminnie: I'll try thank you.
[2018-02-01 09:35:05] <hi1027> brettminnie: But the bad container, there's the data I need.
[2018-02-01 09:41:17] <sxpistols> thank you@SISheogorath
[2018-02-01 09:48:35] <cydrickn> hi... i have a problem... my host has internet.... but my docker container dont have... how i can put internet to  docker container?
[2018-02-01 09:58:46] <brettminnie> @brettminnie But the bad container, there's the data I need.@zshzj that's why you start it up using the overridden entry point, if you use the shell it doesn't run any of the init scripts so you can change the config in there
[2018-02-01 16:30:34] <PabloReszczynski> Hello!
[2018-02-01 16:30:53] <PabloReszczynski> I have a docker question:Context: At work, we manage a whole lot of kiosks computers in our client locations. These kiosks are running docker containers with our software using docker-compose.The problem: In some situations, it is necessary to reset the system by usingdocker-compose downanddocker-compose up -d. But that requires sshing to the computer and doing the commands by hand, and some clients don’t even have ssh enabled. The numbers of kiosks we are managing are increasing each week and this kind of manual work is becoming too  much.
[2018-02-01 16:39:20] <RStrydom> Hi guys.I have recently started on a project that uses a Maven application for the backend + PostgreSQL DB and React frontend. I have tried to setup everything to run as docker containers except for the React frontend (for now) to no avail.I am sorry for just chucking a lot of code here but this is what I have: - I am able to spin up the containers and run the Maven project , but I am not able to access the project from my browser/react frontend.nginx.dockerfile [<-CODE->] postgres.dockerfile [<-CODE->] jdk.dockerfile [<-CODE->] .nginx.conf [<-CODE->] docker-compose.yaml [<-CODE->] doThings.sh [<-CODE->] /etc/hosts [<-CODE->] Please can someone point me in the right direction, I would be eternally grateful!
[2018-02-01 23:22:42] <Leeaandrob> hello :)
[2018-02-02 06:20:24] <lygoods> hello
[2018-02-02 06:20:47] <lygoods> ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: YES)
[2018-02-02 06:21:08] <lygoods> How to fixed this issue?
[2018-02-02 06:21:20] <lygoods> In docker container
[2018-02-02 06:36:46] <hullsean> hey guys what is the best way to troubleshoot localhost networking problems? i have a local mysql instance (non docker) and a webserver i want to talk to it. but it’s not seeing outside itself. i’m a beginner at troubleshooting these
[2018-02-02 06:36:56] <hullsean> use interactive mode?
[2018-02-02 06:37:28] <lygoods> yes
[2018-02-02 06:37:38] <lygoods> docker -it mysql bash
[2018-02-02 06:37:47] <lygoods> docker exec -it mysql bash
[2018-02-02 06:37:51] <hullsean> docker inspect | grep IPAddress?
[2018-02-02 06:37:52] <lygoods> like this
[2018-02-02 06:38:13] <hullsean> the mysql instance is outside
[2018-02-02 06:38:23] <hullsean> it’s just running on mac
[2018-02-02 06:38:43] <lygoods> on my MAC
[2018-02-02 06:39:04] <lygoods> "IPAddress": "172.17.0.2",
[2018-02-02 06:39:10] <lygoods> docker ip
[2018-02-02 06:40:21] <hullsean> in the apache container i tried mysql -h localhost -u but it fails
[2018-02-02 06:40:42] <hullsean> i think i also started mysql with —skip-networking
[2018-02-02 06:41:50] <lygoods> ah
[2018-02-02 06:41:53] <hullsean> so appears i can reach out of the container
[2018-02-02 06:42:45] <lygoods> I try to visit from local to docker
[2018-02-02 06:42:46] <lygoods> ERROR 2003 (HY000): Can't connect to MySQL server on '172.17.0.2' (60)
[2018-02-02 06:42:49] <lygoods> Show this
[2018-02-02 06:42:54] <hullsean> i looked through the docker settings dialog & tabs but only thing i found was a subnet
[2018-02-02 06:43:15] <hullsean> yep
[2018-02-02 06:43:21] <hullsean> looks like the error
[2018-02-02 06:43:27] <lygoods> yes
[2018-02-02 06:43:40] <lygoods> I don’t know how to fix
[2018-02-02 06:43:44] <lygoods> Like this
[2018-02-02 06:44:01] <hullsean> would it be better if i out mysql into its own container bc then it would be on 172.17 network
[2018-02-02 06:44:11] <hullsean> ok
[2018-02-02 06:44:20] <hullsean> networking always gets messy !
[2018-02-02 06:44:55] <lygoods> ah
[2018-02-02 06:46:10] <lygoods> hullsean: You know how to install a git local server?
[2018-02-02 06:46:22] <lygoods> on docker
[2018-02-02 07:49:01] <hullsean> i have not tried
[2018-02-02 07:49:08] <comeUpWithItLater>  [<-LINK->] 
[2018-02-02 07:49:14] <hullsean> should be like any other service
[2018-02-02 07:50:15] <comeUpWithItLater> docker daemon  doesn't seems to listen on 0.0.0.0:2375
[2018-02-02 07:50:22] <comeUpWithItLater> what am i missing ?
[2018-02-02 07:50:39] <hullsean> lygoods: is that what you’re working on
[2018-02-02 07:51:21] <lygoods> This is window?
[2018-02-02 07:51:34] <comeUpWithItLater> yes , windows
[2018-02-02 07:51:50] <lygoods> My MAC has not this option.
[2018-02-02 07:52:33] <lygoods>  [<-LINK->] 
[2018-02-02 08:49:49] <lygoods> hullsean: I found the cause
[2018-02-02 08:50:54] <lygoods> You need a  root permission
[2018-02-02 08:51:07] <lygoods> ‘’su’' command
[2018-02-02 23:50:02] <deekshasharma> Hi everyone , I have started fiddling around with Docker registry API [<-LINK->] I want to be able to download any docker image using this API. Can I only access images that belong to me via this API or any image from Docker hub?Also, there is no hostname on this documentation, so where can I send some example requests and see the results ?Just wanted to check if anyone has used this, your help is appreciated
[2018-02-03 18:41:37] <expertio_twitter> Hello community, wonder if anyone know what are the best practice and patterns for the following situation. I have a dynamically created docker containers, what is the best way to tail logs form them if the image id or name is unknown beforehand ?
[2018-02-03 23:15:35] <yosefrow> maybe ps and sort by created by date or use docker-compose to manage name or specify --name on docker run command
[2018-02-03 23:16:48] <yosefrow> lygoods: maybe mysql permissions error
[2018-02-03 23:17:48] <yosefrow> "
[2018-02-04 00:21:24] <EmpeRoar> Hi Guys
[2018-02-04 00:21:35] <EmpeRoar> I cannot swtich to linux containers on my Docker for Windows
[2018-02-04 00:50:31] <lygoods> yosefrow: just need a permission
[2018-02-05 05:21:39] <cheshirecode> are there alot of unfortunate people developing with Docker on Windows/Mac?
[2018-02-05 05:22:22] <ArStah> cheshirecode: me :c
[2018-02-05 05:29:59] <cheshirecode> oh good I'm not the only one
[2018-02-05 05:30:36] <cheshirecode> struggled to get 2-way sync working with volumes, even in Linux VM for Docker on Windows
[2018-02-05 05:31:30] <ArStah> cheshirecode: that is working for me
[2018-02-05 05:31:34] <cheshirecode> ArStah: have you found a better way than [<-LINK->] 
[2018-02-05 05:33:37] <cheshirecode> really? Did you get hot-reloading like Webpack HMR work too?
[2018-02-05 05:34:06] <ArStah> Don't think so, when i launched Docker container on my drive for the first time - windows asked me to share that drive, and after that almost all is working
[2018-02-05 05:34:29] <ArStah> No, hot-reloading, unfortunately, doesn't work
[2018-02-05 05:35:30] <ArStah> I've actually found a solution for it, hot-reloading is working, but it detect changes very-vey-very slowly
[2018-02-05 05:36:07] <ArStah>  [<-ISSUE->] 
[2018-02-05 05:36:25] <ArStah> Try to enable pooling in your webpack
[2018-02-05 05:36:33] <ArStah> Maybe for you it will work better)
[2018-02-05 05:50:15] <cheshirecode> ah yes I went down that path
[2018-02-05 05:50:54] <cheshirecode> it's really slow as you mentioned, like a few seconds delay
[2018-02-05 05:53:38] <cheshirecode> according to [<-ISSUE->] , seems like a OS-level limitation on webpack-dev-server itself :)
[2018-02-05 06:02:34] <ArStah> I got used to it and while developing i launch it directly in Windows
[2018-02-05 07:45:19] <cheshirecode> I used to do it as well, for 1 application. Developing multiple inter-dependent applications is too much for Windows, it seems
[2018-02-05 09:53:33] <gaydenko> Hi! How to modify already existing container as if it was created with given--dnsoption?
[2018-02-05 19:40:57] <SISheogorath> gaydenko: just recreate them
[2018-02-06 06:31:34] <shadow-cpp> hello!
[2018-02-06 06:34:19] <jamesalbert> EHLO!
[2018-02-06 08:12:29] <yosefrow> @gaydenko. -dns=IP_ADDRESS...Sets the IP addresses added as nameserver lines to the container's /etc/resolv.conf file. Processes in the container, when confronted with a hostname not in /etc/hosts, connect to these IP addresses on port 53 looking for name resolution services.
[2018-02-06 08:13:01] <yosefrow>  [<-LINK->] 
[2018-02-06 08:15:06] <yosefrow> theoretically without dns option docker mounts host resolv.conf so host changes appear in container.  but with dns option not sure if host changes appear in container. so may just need to edit container resolv.conf manualky
[2018-02-06 10:05:51] <ghost~54e3435715522ed4b3dc1b7a> Hey guys — is this the right place to make questions about Docker Official Images program?
[2018-02-06 11:51:48] <SISheogorath> XVincentX: You mean in general or for a special image?
[2018-02-06 12:58:09] <ghost~54e3435715522ed4b3dc1b7a> SISheogorath: Basically I am the mainteiner of Express-Gateway and I would like to apply to be part of the Docker Official Images program. I’ve gone thorugh all the requirements but there’s one I am not sure about. I’d like to know where I should ask for clarifications.
[2018-02-06 13:18:03] <SISheogorath> Feel free to ask here :D
[2018-02-06 13:19:33] <SISheogorath> XVincentX: As alternative you can go checkout this place: [<-LINK->] 
[2018-02-06 13:40:19] <ghost~54e3435715522ed4b3dc1b7a> So what I do not understand is whether it’s mandatory to have a separate repository just to store the Dockerfile definitions
[2018-02-06 13:40:31] <ghost~54e3435715522ed4b3dc1b7a> express-gateway-docker-image
[2018-02-06 13:41:11] <ghost~54e3435715522ed4b3dc1b7a> Or if I can have the “release” docker file within the same repository
[2018-02-06 14:30:08] <ghost~54e3435715522ed4b3dc1b7a> SISheogorath: 
[2018-02-06 14:31:33] <SISheogorath> I would say you need it because you may want to support multiple releases with the docker setup
[2018-02-06 14:32:16] <SISheogorath> I can't think of an official image that doesn't run as separated repo
[2018-02-06 14:40:15] <ghost~54e3435715522ed4b3dc1b7a> SISheogorath: I am not sure I’m following you — what do you mean?
[2018-02-06 14:42:48] <SISheogorath> When you check official images, you\'ll notice they usually provide the few latest stable versions of a software like nextcloud or nginx, as well as traefik. (For example they provide a alpine-based version as well as a "raw" one).
[2018-02-06 14:44:34] <ghost~54e3435715522ed4b3dc1b7a> Well the Official Docker Images are not generated using the source code — given it’s an npm package, I generate the docker image starting from there
[2018-02-06 14:44:40] <ghost~54e3435715522ed4b3dc1b7a> I’ll probably open a PR and we’ll go from there.
[2018-02-06 14:55:02] <SISheogorath> That's a good idea :)
[2018-02-06 14:55:06] <SISheogorath> Let things envolve
[2018-02-06 14:55:13] <ghost~54e3435715522ed4b3dc1b7a> Thank you. Let’s see how it goes.
[2018-02-07 03:19:10] <comeUpWithItLater> Hi@SISheogorath,  you are back
[2018-02-07 03:19:56] <comeUpWithItLater>  [<-LINK->] 
[2018-02-07 03:20:37] <comeUpWithItLater> docker for windows doesn't seems  to listen on  tcp://0.0.0.0:2372
[2018-02-07 03:20:49] <comeUpWithItLater> what am i missing ?
[2018-02-07 06:50:10] <SISheogorath> Well, I can't say much about Windows. Haven't used it for more than a year
[2018-02-07 07:15:23] <comeUpWithItLater> anyone has any idea?
[2018-02-07 09:28:10] <Hobbit44> comeUpWithItLater: depending on what version you are running try opening [<-LINK->] in a browser
[2018-02-07 09:30:51] <Hobbit44> I had this set up before as i switched it back to port 4243 but i think they disabled the config file on windows in favour or the daemon config in the settings so they could run validation on the config (i think, just my experience)
[2018-02-08 18:08:35] <pedroparraortega> Hi all, i have a problem with my mac. I've installed docker for mac community edition (stable). And i've configured my configuration.json with bip:192.168.99.1/24 to avoid collaiding with my office network. The problem is that when i run a docker-compose up/down connected to the office network it takes too long. Finally its run but take too long. if i do the same connected to any other network it is pretty fast
[2018-02-08 18:08:43] <pedroparraortega> do you have any ideas??
[2018-02-08 19:08:26] <fdisp> hello guys im trying to learn docker from online sources and at the moment there is a question i cant find an answer:can docker x64 (docker for debian x86-x64 in a 64 bit machine)RUNan image created from an ARM linux distro like raspbian, and vice-versa, could an arm architecture version of docker run an image created from a 64 bit linux distribution?
[2018-02-08 19:10:29] <yosefrow> id be interested to know this as well. as far as I understand the hardware doesn't matter as long as you have the right os kernel
[2018-02-08 19:10:51] <yosefrow> so linux images on linux kernel
[2018-02-08 19:10:58] <yosefrow> but I'm not sure
[2018-02-08 19:53:33] <oanapat> Hello everyone, I have a swarm set up which I used to learn how a swarm works, how machines are created and added to a swarm, etc. I want to delete that swarm and the machines in it but whenever I try to, I get the following errors:
[2018-02-08 19:53:43] <oanapat>  [<-LINK->] 
[2018-02-08 19:54:09] <oanapat> the question: how do I delete a non active swarm, non active manager, worker nodes?
[2018-02-08 20:18:18] <pedroparraortega> Try to leave the swarm before removing It
[2018-02-08 21:11:34] <oanapat> pedroparraortega: definetly an alternative but it did not work
[2018-02-08 21:12:26] <oanapat> found the solution (I am sure this is not the best one) went to my hyperv ->server manager and stopped all the machines from there manually, after that I was able to remobe all of them
[2018-02-08 23:45:31] <fdisp> i found the answer to my question above. the docker image must originate from an os with the same cpu architecture as the host os and docker that is going to run it. an x64 bit pc where an x64 bit version of docker is required to be installed, can NOT run any ARM based docker image or vice-versa.important discovery:the docker’s slogan “build here and run everywhere” is a lie
[2018-02-08 23:50:18] <SISheogorath> fdisp: .-. I wonder how you couldn't know this. It's basics of how compiling works when you work outside of a VM. Which you do on docker.
[2018-02-08 23:54:04] <SISheogorath> And it\'s not a lie, just incomplete. As you say to your child "When you are older, you can live everywhere" but don\'t include another planet
[2018-02-08 23:59:03] <fdisp> SISheogorath: instead of sayingI wonder how you couldn't know this; you could have been more helpful if you answered when the question was asked, because as i stated before i am a complete noob in docker, and yes an incomplete information could be as bad as misleading
[2018-02-09 00:03:49] <SISheogorath> well, first of all, I wasn't online, when you asked it, and second of all, this knowledge is only far docker related
[2018-02-09 00:20:16] <fdisp> i ask your pardon to everyone in this room. it was that my expectation based in the growing advertisement and rumor about docker was a little excessive. in the other hand expressions like “I wonder how you couldn't know this” can only yield a response of the same level of ignorance. thank you for understanding.
[2018-02-09 00:28:10] <SISheogorath> Well, I agree that it was maybe a bit ignorant to say this. Let's put it this way: Containers are not more than isolated places for processes on the same OS. So the same base rules apply to the processes inside a container, as the do outside. the main difference is that processes in containers are based on image, means they bring their own dependencies etc. with them. That means you don't have to care about the base OS's libs, setup, etc. All you need to care about is the kernel as this is the same for your application and the host. Kernel and of course everything below.
[2018-02-09 00:29:31] <SISheogorath> And for those who don't know: A docker image is a bit more complicated zip/tar file with multiple layers. Not more, not less. Just a zip/tar file for everything your container is made of. Means libs, configs, binaries, ….
[2018-02-09 00:39:02] <fdisp> thanks
[2018-02-09 01:13:41] <dlpatri> I am working with docker compose, and I am trying to have one of my services be in the default docker compose bridge network as well as the host network. Having trouble finding anything in docs..
[2018-02-09 01:18:30] <SISheogorath> dlpatri: not possible. Either bridge, or host network.
[2018-02-09 01:20:21] <ajpatri> Hm, so containers in a bridge network can't leverage external resources? Like a database running outside of docker?
[2018-02-09 08:34:24] <emilaasa> I'd like to see some logging output after runningdocker stack deployon a compose file. Where do I look for that?
[2018-02-09 08:48:39] <SISheogorath> ajpatri: you can use the public hostname of your system which (may) works. But it also requires your database to be accessible outside of 127.0.0.1
[2018-02-09 08:48:52] <SISheogorath> As an alternative you can use a unix socket and mount it.
[2018-02-09 13:16:28] <hmrc87_twitter> Hi, any idea how to set prevent inter-container traffic from using the HTTP_PROXY of the host?
[2018-02-09 13:52:57] <pedroparraortega> Just if any of you have the problem with docker-compose taking too long…. Adding a new entry inside the hosts file with127.0.0.1 localunixsocketsolved the issue
[2018-02-09 20:03:01] <oanapat> question: can anyone recommend a good tutorial where I can learn about the docker swarm self healing capability?
[2018-02-10 03:56:53] <ONE-Luffy> Hello world
[2018-02-10 05:41:01] <AshokRajuDevops> hello all..
[2018-02-10 05:42:00] <AshokRajuDevops> is there any way to check status codes(500,404) rather than simple command exit code (0,1) in docker health check commnad??
[2018-02-10 08:05:29] <FrederikBrinckTruelsen> AshokRajuDevops: health check really depends on what is running inside your container. If you for example have a webserver running with a mangement port and you expose that you can use that to do health checks
[2018-02-10 08:10:35] <FrederikBrinckTruelsen>  [<-LINK->] 
[2018-02-10 08:11:22] <FrederikBrinckTruelsen> Seems you do not even have to expose it you need to specify which command inside the container you want to run for the healthcheck
[2018-02-10 08:13:19] <AshokRajuDevops> FrederikBrinckTruelsen: i am using curl command to do health check.. curl --fail [<-LINK->] :<port>/<url> with time out of 5mins..  but problem is if deployment fails after 2mins, it will still checks status till timeout
[2018-02-10 08:14:36] <AshokRajuDevops> so is there any way to make container unhealthy if deployment fails before timeout??
[2018-02-10 08:14:45] <FrederikBrinckTruelsen> Which webserver are you using?
[2018-02-10 08:15:03] <AshokRajuDevops> i am using tomcat appication server
[2018-02-10 08:25:33] <FrederikBrinckTruelsen> tomcat has a mangement port on 8081 for healthchecks
[2018-02-10 08:27:24] <AshokRajuDevops> i am sure that docker is checking only exit codes of health check command  (0,1) to decide healthy or unhealthy.. curl command returns 1 while deploying and 1 if deployment fails and 0 if deployment success.
[2018-02-10 08:27:51] <AshokRajuDevops> so it is better  to do status check (400,501,500,200)
[2018-02-10 08:29:43] <AshokRajuDevops> if status code is 500,  container health check should be unhealthy immediately..
[2018-02-10 08:32:17] <FrederikBrinckTruelsen> that is not possible as docker health can only return 0,1,2
[2018-02-10 13:16:26] <develroo> Hey guys. is there way to link docker containers after creation? I have a web-proxy container which cannot resolve names of a guacamole container ?
[2018-02-10 13:17:49] <develroo> I used to just specify the ip but that keeps changing depending on restarts
[2018-02-11 08:31:09] <AshokRajuDevops> can we run multiple health check commands  for one container??
[2018-02-11 09:04:51] <SISheogorath> AshokRajuDevops: only one healthcheck line, but as long as you are capable of shell scripting, you should be able to run multiple healthchecks at once
[2018-02-11 11:37:44] <robbyoconnor> that is not possible as docker health can only return 0,1,2Not entirely true @FrederikBrinckTruelsen  -- You can write a bash function which returns 0,1 or 2 based on http status codes...
[2018-02-11 17:01:30] <mikeevstropov> Hi guys! Do i need to make a db instances for each an applications, or use a single db for it all?
[2018-02-11 17:41:13] <SISheogorath> mikeevstropov: I prefer to go for one per application because it's easier to backup file filesystem snapshots
[2018-02-11 17:47:12] <mikeevstropov> SISheogorath: Thank you for reply!
[2018-02-11 18:11:16] <AshokRajuDevops> robbyoconnor: deployment in progress and deployment failure both returns 1 and health check waits till timeout.. how we can exit before timeout if it deployment failure
[2018-02-12 11:04:37] <joel-bernard> Hi guys, have you feedback about high sierra OS X  APFS filesystem performance with docker for mac ? i use docker-sync alternative but it's just waiting for the performance to become an acceptable day
[2018-02-12 11:19:18] <pedroparraortega> i’m using docker under high sierra OS X APFS filesystem and i don’t have any performance issue
[2018-02-12 11:22:31] <joel-bernard> pedroparraortega: thx for your feedback... my performance problem is with big project with npm libs or composer vendor sync... Have you same project profile ?
[2018-02-12 11:23:30] <pedroparraortega> right now i’m using it with a project with a lot of php libraries, php7, apache, and a huge docker mysql database
[2018-02-12 11:23:41] <pedroparraortega> and it’s working fine
[2018-02-12 11:24:57] <pedroparraortega> and redis - memcached
[2018-02-12 11:26:52] <joel-bernard> pedroparraortega: thx, i will test that when MacOS upgrade will be finished and i will shared betchmark if ihave performance problem
[2018-02-12 11:50:38] <pedroparraortega>  if you need me to run any benchmarks… let me know
[2018-02-12 11:51:58] <ofabricio> guys, what is this image docker creates all the time here: [<-CODE->] 
[2018-02-12 12:52:10] <Martinnord> Hey guys!
[2018-02-12 13:18:19] <SISheogorath> Martinnord: hi 
[2018-02-12 13:33:37] <Martinnord> Have you used knex with docker@SISheogorath?
[2018-02-12 13:35:07] <SISheogorath> I don't, but ghost does: [<-LINK->] 
[2018-02-13 00:24:09] <zebralight> hello. I was wondering if anyone has any leads on how to run a docker linux container on a windows host that will persist all the changes made to it using package updates from the distro's repository
[2018-02-13 08:02:37] <hmrc87_twitter> hi, any idea how to mount a volume between containers (for logfiles) withouth root permissions? Within my containers there is no root available
[2018-02-13 08:18:45] <pedroparraortega> with a volume?
[2018-02-13 08:21:13] <hmrc87_twitter> yes I did that, it appears within the containers but it's permissions are root:root
[2018-02-13 08:21:30] <hmrc87_twitter> So that the user running (in my case Apache airflow) which is called airflow is not able to work with it
[2018-02-13 08:22:43] <hmrc87_twitter> I am trying out this way because somehow when Container:Webserver calls Container:Worker via HTTP in order to get logs it is always using the company proxy. I have to explicitly set NO_PROXY=thecontainerid in order to make it work. But how can I automate this?  I thought about adding the Docker-Subnet to NO_PROXY but the variable does not work with CIDR notation in my case
[2018-02-13 08:48:42] <hmrc87_twitter> So a trick would be to unset the HTTP_PROXY variable of the docker-container. I provided this variable during build-time. Then no traffic, including inter-container-traffic is routed via proxy. But then I cannot call the outside world (which is OK for now...).
[2018-02-13 09:03:09] <2anilkumar> Looking for help on -  "Recommendation for Airflow design/architecture" - [<-LINK->] 
[2018-02-13 09:17:07] <schafferer> Hey guys! Does anybody have some information on Docker in Azure, with regards to upload limits? I have set up a custom PyPi-server to host big python packages. It work perfect locally, but when uploading 1gb+ files to azure, i get error:<urlopen error [Errno 32] Broken pipe>. I'm running the image in an Azure Web App for Containers.
[2018-02-13 13:01:04] <rakeshbimra_twitter> We are new to docker container.We have created a docker image(with .net core) now we are looking for deploy this image on our dev environment. This is windows environment and we have already deployed some of the our .net applications. So we have following questions.Can we deploy our docker image(which is created with .net coreapplication) on our dev environment?\nand can we create different docker images for dev/ prod environment?
[2018-02-13 13:04:30] <hmrc87_twitter> Why dont you want to use the same image? I am using a linux docker container setup on Debian8 and the same one on Windows 10 using docker-machine and VirtualBox
[2018-02-13 13:05:19] <hmrc87_twitter> However it is not so easy regarding file permissions in volume mounts etc. But it is doable
[2018-02-13 13:06:07] <rakeshbimra_twitter> Hi@hmrc87_twitter, do we need to configure linux docker container or can we do with docker for windows?
[2018-02-13 13:06:27] <rakeshbimra_twitter> We are using windows OS and we installed docker for windows
[2018-02-13 21:20:23] <ledil_twitter> hello, ive got a docker with postfix and rsyslog installed, ive configured rsyslog within docker to log everything to /dev/stdout, whenever I start the docker with run ... and I write an email I would expect that the message in the "docker run" window, but there is nothing, what should I do ?
[2018-02-13 22:42:04] <yosefrow> try first to run it logging to regular syslog. problem might reveal itself if that doesn't work
[2018-02-13 22:54:58] <intellix> how can I bind to and get an object using ReactiveForms and a select?
[2018-02-13 22:55:19] <intellix> this seems not to work: [<-CODE->] 
[2018-02-13 22:55:40] <intellix> onFilterChange gets priceRange.label and not the value
[2018-02-13 22:56:40] <intellix> ngValue only works with ngModel? I've noticed it's not mentioned anywhere in the docs
[2018-02-13 23:52:22] <watsaqat> Hi all, is it possible to the os that the docker container is running in? For example: if I'm running a docker container on a mac, I would like to access that information from inside the docker container
[2018-02-14 06:09:16] <codesahil> Hey is there anybody from docker community who looks for students and local chapter applications
[2018-02-14 06:13:07] <bshankar_dude_twitter> hi..i am using [<-LINK->] to deploy on our AWSafter our deploying our docker stacks., i see the exposed ports are added onto load balancer as “TCP” port..is there anyway to make it as “HTTPS” porti cant find where to change in the template
[2018-02-14 07:17:35] <hmrc87_twitter> rakeshbimra_twitter: you can do this: [<-LINK->] or follow the official docker for windows documentation
[2018-02-14 08:07:43] <rakeshbimra_twitter> thanks@hmrc87_twitter
[2018-02-14 08:08:09] <rakeshbimra_twitter> Here is the default docker file generated when i create  .net core app with docker support for windows
[2018-02-14 08:08:15] <rakeshbimra_twitter>  [<-LINK->] 
[2018-02-14 08:09:08] <rakeshbimra_twitter> When i run the build command i got the following error message
[2018-02-14 08:09:14] <rakeshbimra_twitter>  [<-LINK->] 
[2018-02-14 08:09:38] <rakeshbimra_twitter> Step 6/17 : COPY *.sln ./COPY failed: no source files were specified
[2018-02-14 08:10:01] <rakeshbimra_twitter> Do i need to modify my dockerfile or need to do something else? Please suggest
[2018-02-14 11:25:40] <CiprianBeldean> Hello all, i have a VirtualBox VM on which i installed Docker. In docker i created a jenkins container and a  mariaDB container. I want to create a jenkins build to manipulate the data in my mariaDB using Groovy Script. I created a jenkins freestyle build and i imported groovy.sql.Sql and i created a Sql.newInstance("jdbc:mariadb://127.0.0.1:7702/first", "user", "password", "org.mariadb.jdbc.Driver") too. The problem is that i am not able to access groovy because i dont have groovy installed in my jenkins container. How and where should i install groovy to run the jenkins build correctly? Thank you very much for the support.import groovy.sql.Sql// define SQL statemendef sql_storeip = "select LastName from first.Persons"def selectStatement() {    return  """select * from Persons;"""}// create DB connections /instancedef sqlMaria = Sql.newInstance("jdbc:mariadb://127.0.0.1:7702/first", "serverUser", "ServerPass", "org.mariadb.jdbc.Driver")// run SQL statement in the SQL Instancetry {        sqlMaria.execute(selectStatement())    // catch error and print out} catch (Exception ex){    sqlMaria.rollback()    println("!! ERROR!! Transaction rollback -> ${ex}")} finally {    // close db connection -> always}    sqlMaria.close()}and this is the error i receivedBuilding in workspace /var/jenkins_home/workspace/MariaDBConnection[MariaDBConnection] $ groovy /var/jenkins_home/workspace/MariaDBConnection/hudson4277122594457720117.groovyFATAL: command execution failedjava.io.IOException: Cannot run program "groovy" (in directory "/var/jenkins_home/workspace/MariaDBConnection"): error=2, No such file or directory    at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)    at hudson.Proc$LocalProc.<init>(Proc.java:249)    at hudson.Proc$LocalProc.<init>(Proc.java:218)    at hudson.Launcher$LocalLauncher.launch(Launcher.java:930)    at hudson.Launcher$ProcStarter.start(Launcher.java:450)    at hudson.Launcher$ProcStarter.join(Launcher.java:461)    at hudson.plugins.groovy.Groovy.perform(Groovy.java:106)    at hudson.tasks.BuildStepMonitor$1.perform(BuildStepMonitor.java:20)    at hudson.model.AbstractBuild$AbstractBuildExecution.perform(AbstractBuild.java:744)    at hudson.model.Build$BuildExecution.build(Build.java:206)    at hudson.model.Build$BuildExecution.doRun(Build.java:163)    at hudson.model.AbstractBuild$AbstractBuildExecution.run(AbstractBuild.java:504)    at hudson.model.Run.execute(Run.java:1724)    at hudson.model.FreeStyleBuild.run(FreeStyleBuild.java:43)    at hudson.model.ResourceController.execute(ResourceController.java:97)    at hudson.model.Executor.run(Executor.java:421)Caused by: java.io.IOException: error=2, No such file or directory    at java.lang.UNIXProcess.forkAndExec(Native Method)    at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)    at java.lang.ProcessImpl.start(ProcessImpl.java:134)    at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)    ... 15 moreBuild step \'Execute Groovy script\' marked build as failureFinished: FAILURE
[2018-02-14 14:32:18] <ChazUK> Has anyone had any success with shared volumes on Windows? My container seems to be able to access the files, then starts to write files and hangs
[2018-02-14 15:10:29] <hmrc87_twitter> Yeah, it worked for me using docker-machine with VirtualBox and having the shared container under C:\\Users\\myusrname
[2018-02-14 15:11:01] <hmrc87_twitter> i mounted a git repository from the HOSt to the container (container running airflow with user airflow) and I saw pychache files written by the container in this volume
[2018-02-14 15:11:55] <hmrc87_twitter>  [<-LINK->] 
[2018-02-14 15:11:57] <hmrc87_twitter> VirtualBox somehow defines this shared volume (which you cannot change via GUI)
[2018-02-14 23:22:29] <farhanahmedsyed> Hi guys, I am new in docker. I installed docker in my machine now in my docker image I want to install windows, can anyone tell me how I can do that?
[2018-02-15 06:52:29] <asadrao11> farhanahmedsyed:  [<-LINK->] 
[2018-02-15 06:53:32] <asadrao11> farhanahmedsyed: Have you installed docker in windows or in Linux ? in what operating system did you installed it ?
[2018-02-15 09:46:44] <juboba> hey guys. I have a Dockerfile which downloads some source to a mounted volume. It seems I cannot do this (or at least it is shadowed by the volume specification, in the docker-compose file). What would be the correct way of doing this?I need the source (or part of it) to be available to the developer.It seems to me that the correct way would be to create a Makefile or a shell script to download the source and then run the docker-compose build, but if I did that it would be Host-OS dependant (either use wget, curl or none can be installed in host machine)
[2018-02-15 09:47:15] <juboba> I can pastebin both files if someone can help :D
[2018-02-15 10:02:32] <asadrao11> juboba: yeah sure share the Dockerfile here and also if you could summarize your question that will be helpfull for me too...
[2018-02-15 12:45:48] <juboba> I think the sane solution is to have the source files provided by the HOST
[2018-02-15 12:46:40] <juboba> because it doesn't sound very good to have a docker-contained image to manipulate the host's directory
[2018-02-15 12:47:22] <juboba> thanks for the interest in helping@asadrao11but I think what I had in mind is not possible (and if it was it would be not safe)
[2018-02-15 12:49:08] <juboba> I have a new question though, I have 2 containers defined in my docker-compose file. One is for a web server and the other one for database (mysql listening on port 3306).I don't know if I should connect both usinglinkorexposeing the port.
[2018-02-15 13:10:09] <go4cas>  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2018-02-15 13:17:45] <asadrao11> juboba: links: db  and expose the port
[2018-02-15 13:18:41] <asadrao11> go4cas: can you upload your docker-compose.yml here
[2018-02-15 13:18:54] <asadrao11> go4cas: let me check ..
[2018-02-15 13:26:26] <go4cas> asadrao11: ... here you go: [<-CODE->] 
[2018-02-15 13:40:04] <go4cas> So, if I rename thetraefik.envto.env, it works ...
[2018-02-15 13:58:16] <asadrao11> go4cas: the issue is for port.. are you already using that port ?
[2018-02-15 13:58:25] <go4cas> Nope
[2018-02-15 13:58:31] <go4cas> It's free
[2018-02-15 13:59:55] <asadrao11> can you check you port 80 is free ?
[2018-02-15 14:00:08] <asadrao11> ss -tunlp |grep 80
[2018-02-15 14:00:52] <asadrao11> because if you see traefik orignal dockerfile from scratch they have expose the port 80..
[2018-02-15 14:01:53] <asadrao11> version: '2'services:  proxy:    image: traefik    command: --api --docker --docker.domain=docker.localhost --logLevel=DEBUG    networks: [<-CODE->] networks:  webgateway:    driver: bridge
[2018-02-15 14:02:06] <asadrao11> have you tried this ?
[2018-02-15 14:02:48] <asadrao11> Check the documentation brother first.. all the configuration which you have to set into the directory.. [<-LINK->] 
[2018-02-15 14:05:00] <go4cas> asadrao11: ... it's not the port. When I change the name of thetraefik.envfile to.env, then it works 100%
[2018-02-15 14:08:02] <asadrao11> go4cas: Alright brother...
[2018-02-15 15:13:47] <ghost~56fc9ded85d51f252abbbbad> so guys
[2018-02-15 15:14:20] <ghost~56fc9ded85d51f252abbbbad> I have a docker swarm, with Teamcity on one node and mysql on another node, I can connect through Teamcity server via CLI to mysql, but I can't connect through Teamcity
[2018-02-15 15:14:31] <ghost~56fc9ded85d51f252abbbbad> is there any reason why?
[2018-02-15 15:14:42] <ghost~56fc9ded85d51f252abbbbad> I am using 127.0.0.1:3306
[2018-02-15 16:38:35] <pedroparraortega> Both of then are connected to the same Network? If so... Use the service name instead 127.0.0.1 or the internal MySQL ip
[2018-02-15 19:16:48] <bshankar_dude_twitter> hi..i am using [<-LINK->] to deploy on our AWSafter our deploying our docker stacks., i see the exposed ports are added onto load balancer as “TCP” port..is there anyway to make it as “HTTPS” port
[2018-02-15 19:17:34] <bshankar_dude_twitter> looks like in the userdata area., i see the instance is automatically getting added into external LB and whatever the ports are exposed., its getting added as a listener as TCP
[2018-02-15 19:17:40] <bshankar_dude_twitter> looking for some options to change it to https
[2018-02-15 19:17:45] <bshankar_dude_twitter> any directions ?
[2018-02-15 19:36:23] <codesahil> I wanted to ask if im running a application on docker swarm mode with multiple tests running in parallel on the same machine in containers, will thosecontainers will have the same IP addresses or would interferewith each other.
[2018-02-15 19:42:45] <asadrao11> Multihost Networking is the key feature of docker swarm.. you can specify an overlay network for your services. The swarm manager automatically assigns address to the containers on the overlay network.
[2018-02-15 19:43:10] <codesahil> thanks
[2018-02-15 19:43:29] <asadrao11> Wellcome khan sahib..
[2018-02-15 19:58:55] <farhanahmedsyed> Asad: Rao  I installed on my Mac now I wanted to install windows 10 on docker container
[2018-02-15 20:05:03] <asadrao11> Farhan, do you want to install windows on docker or do you want install docker on windows ??
[2018-02-15 21:26:07] <farhanahmedsyed> I want to InshaAllah windows on docker container
[2018-02-15 21:26:36] <farhanahmedsyed> I want to install *
[2018-02-15 21:29:45] <asadrao11> Yr urdu me bta do bhai.. ap ki baat he smjh ni arhi ha farhan
[2018-02-15 21:39:39] <szcc> Hello. I am running my first docker image and I can see it is running:
[2018-02-15 21:39:46] <szcc>  [<-LINK->] 
[2018-02-15 21:40:21] <szcc> but  I cannot connect it : sudo docker exec pg_rdkit_1 /bin/bash
[2018-02-15 21:40:41] <szcc> what did I do wrong?
[2018-02-15 21:52:16] <asadrao11> Sudo docker exec -it name /bin/bash
[2018-02-15 23:23:20] <farhanahmedsyed> Bhai I want to install windows in docker container
[2018-02-15 23:45:21] <kylegordon_twitter> farhanahmedsyed: that can't be done. Docker does not support GUI processes
[2018-02-15 23:57:55] <farhanahmedsyed> Thanks for clarification, I was googling alot and not getting my answer
[2018-02-16 03:17:42] <MadLittleMods> Heads-up (Gitter dev here), there was an XSS exploit in Gitter that allowed someone to embed a crypto mining script via chat message (this room was targeted). The exploit has been fixed and the messages removed but you could still be affected. You can check whether you are still affected by following the instructions in the blog post, [<-LINK->] 
[2018-02-16 08:33:00] <go4cas> Hey guys ... does theproject-nameargument, when using withdocker-compose up, have any side effects, besides name spacing?
[2018-02-16 08:40:45] <go4cas> I am seeing different behavior betweendocker-compose up -danddocker-compose --project-name mystack up -d
[2018-02-16 13:39:53] <szcc> asadrao11: Thank you! "pg_rdkit_1" is my docker image name.
[2018-02-16 13:40:23] <szcc>  [<-LINK->] 
[2018-02-16 13:43:00] <szcc> when I type the command and return there is no error message but the bash did not up.  I am thinking to check if my Linux box is listening this port ....
[2018-02-16 14:03:38] <asadrao11> szcc: yeah sure.. pleasure tell me if there is any help needed..
[2018-02-16 17:46:06] <chan_seeker_twitter> hey  hi  guys
[2018-02-16 17:47:45] <chan_seeker_twitter> can anyone help me or tel me how to see where a dotnet core application is running sucessfully on a conatiner bcoz i ran the conatiner but when i hit a api call request from postman to that application it gives me no response from the conatiner apllication how to see it
[2018-02-16 17:52:47] <asadrao11> Docker ps
[2018-02-16 17:52:56] <asadrao11> Docker ps -a
[2018-02-16 18:17:24] <chan_seeker_twitter> i have done that
[2018-02-16 18:17:42] <chan_seeker_twitter> in that hosted application it has api's
[2018-02-16 18:18:15] <chan_seeker_twitter> i want to check whether the api' s are working are not how to do that?
[2018-02-16 18:18:53] <asadrao11> Locate api
[2018-02-16 18:19:04] <asadrao11> In container.
[2018-02-16 18:19:15] <chan_seeker_twitter> how
[2018-02-16 18:19:23] <chan_seeker_twitter> i am quite new
[2018-02-16 18:19:28] <chan_seeker_twitter> can u help me
[2018-02-16 18:20:56] <asadrao11> Do you have skype ?
[2018-02-16 18:21:55] <asadrao11> You are new in docker or linux ?
[2018-02-16 18:22:28] <chan_seeker_twitter> docker
[2018-02-16 18:22:36] <chan_seeker_twitter> linux i am good at
[2018-02-16 18:23:21] <asadrao11> Can you show docker ps snap here
[2018-02-17 03:31:26] <albertkim> Hey guys, I'm really struggling to understand the best way to build docker containers in CI while running db integration tests against it
[2018-02-17 03:31:48] <albertkim> my idea was to try: npm run test as part of the Dockerfile build process - however, I ran into this issue: [<-LINK->] 
[2018-02-17 03:32:05] <albertkim> Where I cannot connect to the host's mysql service from my docker build
[2018-02-17 03:32:16] <albertkim> Are there resources where I can learn about this stuff?
[2018-02-17 10:15:47] <AnderssonPeter> I\'m trying to run bash inside a specific image to debug a few thing but nothing happens when i rundocker run -t -i microsoft/dotnet:2.0.0-runtime-stretch-arm32v7 bashbut nothing happens what am i doing wrong? if i writedocker ps -ait just exits with 139, the container should contain bash as one of the layers in it isCMD ["bash"]
[2018-02-17 10:17:10] <AnderssonPeter> also when writing my own containers where do i write logs, so that docker can pick it up with thedocker logscommand?
[2018-02-17 10:54:53] <dreiv> for example alpine usses ash
[2018-02-17 10:57:08] <dreiv> I am trying to rundocker run --rm -v $(pwd):/usr/src/app angular-dev:z npm test
[2018-02-17 10:57:17] <dreiv> and I am receiving "invalid reference format."
[2018-02-17 10:57:35] <dreiv> I am new to docker, does anyone notice a mistake in my command?
[2018-02-17 10:58:05] <dreiv> $(pwd)works for me, I am running it on a windows machine, but with enabled bash commands.
[2018-02-17 11:43:37] <dreiv> figured it out,$(pwd)has multiline output in powershell, and it messed up docker, which is understandable.
[2018-02-17 11:47:32] <chan_seeker_twitter> my task is i have been given a dotnetcore version 1.1 apllication which contains api's which i have to host it and check whether all api's are waorking properly by hitting tht url of the api through postman after hosting in docker
[2018-02-17 11:47:50] <chan_seeker_twitter>  [<-LINK->] 
[2018-02-17 11:47:56] <chan_seeker_twitter> help me anyone
[2018-02-17 11:48:01] <chan_seeker_twitter> how to do it
[2018-02-17 13:17:06] <AnderssonPeter> chan_seeker_twitter: have you started the container and exposed the correct port?
[2018-02-17 13:25:44] <chan_seeker_twitter> AnderssonPeter: I dono
[2018-02-17 13:25:52] <chan_seeker_twitter> my build failed
[2018-02-17 13:26:38] <chan_seeker_twitter>  [<-LINK->] 
[2018-02-17 13:38:36] <AnderssonPeter> can you build the project in visual studio? (i don't know if this issue is docker related)
[2018-02-17 18:03:24] <chan_seeker_twitter> AnderssonPeter: can u give dockerfile for dotnetcore 1.1 web api application
[2018-02-18 20:51:27] <shawnsmithdev> anyone awake in here?
[2018-02-18 21:47:24] <megamindbrian> shawnsmithdev: I'm awake.
[2018-02-18 22:11:05] <dansok> hi, i have a question --
[2018-02-18 22:11:17] <dansok>  [<-CODE->] 
[2018-02-18 22:12:16] <dansok> how do i run that container?
[2018-02-18 22:13:01] <dansok> I trieddocker run 66ebe848b7deanddocker run dockerfile:latest
[2018-02-18 22:13:25] <dansok> in both cases i get the same response
[2018-02-18 22:13:28] <dansok>  [<-CODE->] 
[2018-02-19 03:16:42] <brandonlee781> Hey everyone, just starting out learning docker. Got a node app running with postgres as a service. I'm wondering if there's a best practice for where to persist my db data? I should I mount a directory from my project folder to the postgres data storage folder in the instance or should I keep the local data outside my project folder?
[2018-02-19 06:09:19] <duyngha>  [<-CODE->]  [<-CODE->] everything seems work fine until I ran Wordpress configuration step 2. The error screen show me a message that I got a database connection error.https://screenshots.firefox.com/vG7rfJKnmwXhetrw/localhostIt seems my configuration of my mysql container was wrong. Anybody can help me? I'm very grateful.
[2018-02-19 09:04:35] <juboba> how can I make docker-compose launch the machine with a uid and gid?
[2018-02-19 09:05:07] <juboba> all the files created have root (or some other user) as owner so I can't make changes on those files
[2018-02-19 15:08:08] <crebuh> Hey Guys, how can I rotate the log files of my containers. I tried 2 different approaches:1) add this lines to my docker compose file [<-CODE->] 2) use logrotate to rotate files, which leads to the problem, that even when the file is renamed like node.log.1 the container is still logging into this file until the container is restared are newly generated.what is best practice in terms of log rotation?
[2018-02-19 17:38:16] <ghost~5928d90bd73408ce4f629b9e> anyone familiar with Go how do i setup GOPATH for custom path installation?go is installed at E:/Go
[2018-02-19 17:39:20] <ghost~5928d90bd73408ce4f629b9e> export GOROOT="E:\\Go"
[2018-02-19 17:42:02] <ghost~5928d90bd73408ce4f629b9e> everyone: 
[2018-02-19 17:42:35] <jpz> Why are you asking this in a Docker channel?
[2018-02-19 17:48:22] <ghost~5928d90bd73408ce4f629b9e> ues??
[2018-02-19 17:48:29] <ghost~5928d90bd73408ce4f629b9e> yes??
[2018-02-19 17:50:48] <ghost~5928d90bd73408ce4f629b9e> jpz: im using go help me brotherhood
[2018-02-19 19:22:05] <kc1116> anyone here ?
[2018-02-19 19:23:05] <kc1116> Using the docker sdk, how to I start a container and pass arguments to the entrypoint command defined in the docker file ?
[2018-02-20 03:54:42] <duyngha> no one can help?
[2018-02-20 04:03:49] <go4cas> duyngha: ... do you have a.envfile where the environment variables are declared?
[2018-02-20 14:57:11] <szcc> asadrao11: Thank you. '''sudo docker exec –it mydockerimagename /bin/bash ''' is correct. I miss -it
[2018-02-20 15:38:05] <yosefrow> kc1116: docker run image entrypoint.command
[2018-02-20 16:58:00] <asadrao11> szcc: Pleasure..
[2018-02-21 08:28:02] <codesahil> I wanted to test docker swam so intially wanna run 2 containers and check them using ping.Can anyone tell me how to do that.
[2018-02-21 08:28:27] <codesahil> No experience with docker swarm at all
[2018-02-21 19:00:44] <codesahil> Want to write a sample script that throws up two "west" and two"east" machines using docker swarm and give them two interfaces andtwo IPs and do some pings
[2018-02-21 21:28:29] <rgwozdz> I’m trying to run docker-compose on an Azure VM.  Keeps hanging on the extraction phase of one of my images and eventually my ssh session closes.  Anyone know why this may be happening?
[2018-02-21 21:28:48] <rgwozdz>  [<-LINK->] 
[2018-02-21 21:29:28] <rgwozdz> I should note that the VM is Ubuntu 16.04
[2018-02-22 13:30:43] <alonhar> Hi, I want to start use docker-compose, I use java app, Their is something that I dont understand. If I have 10 containers in the docker compose, and I want to develope one of them. what is the flow ?I stop the runnig container.\nrun the java app locallyhow does all the other services talk with this service?
[2018-02-22 16:26:53] <Arunkayathi> Hi Does any one know how to pick application properties from environment variables in docker-compose file.Here is the stack overflow link for the error that i am going throughhttps://stackoverflow.com/questions/48927342/how-to-make-application-properties-pick-from-environment-variables-in-docker-com
[2018-02-23 00:57:34] <hulkish> Hi... is there a way to dodocker export <img>:<version> | docker import -but filter only the files u want?
[2018-02-23 12:59:54] <basz> Hello, would anyone happen to know why a script run viadocker-compose -f docker-compose.yml run php bin/application.phpwould not be able to receive cntrl-c signals? (FROM php:7.1-cli-alpine)
[2018-02-23 13:01:43] <basz> if usedocker stop xxxxxxxxthe process does receive a signal for the same image
[2018-02-23 22:03:39] <hulkish> nevermind, i
[2018-02-23 22:03:41] <hulkish> guess
[2018-02-24 10:52:02] <comeUpWithItLater> any  GUI  tool to test remote rabbitmq connection?     i set up  an mq   server with [<-LINK->] .
[2018-02-24 10:53:03] <comeUpWithItLater> don't  know  if it's ready accept remote connection, and ready  to pass it to the develop  team or not
[2018-02-24 10:53:45] <comeUpWithItLater> need to  write some code to test it? like [<-LINK->] 
[2018-02-25 00:50:09] <charlesread> Hi all, I am hoping to get some clarification aboutDockerfiles and theVOLUMEinstruction.  What is the point of theVOLUMEinstruction if to really do any mounting you have to usedocker run ... --volume|mount ...?
[2018-02-25 07:09:54] <MakanTaghizadeh> Hi@charlesread,VOLUMEis just an instruction which instructsDocker Enginethat this docker image has a mount point. If you don’t bind it to a mount point in host or a volume when you’re running the image usingdocker run, theDocker Engineautomatically create a volume and binds it to the path you specified in your Dockerfile.
[2018-02-26 14:30:51] <jonstout> I've setup jenkins using the docker plugin. One thing I've noticed is that containers created by jenkins don't appear indocker ps -aordocker container ls -aafter they've stopped. Only if i start a container via cli do stopped containers appear in the list. Is that quirk of the docker api by any chance?
[2018-02-26 18:24:40] <mantoshelis> Hello, it is possible to rebuild only one image usingdocker-compose? I can't find anything documented.
[2018-02-26 18:25:23] <ripper2hl> yes its only rundocker-compose build example
[2018-02-26 18:25:34] <ripper2hl> my arom plugin helps whit this
[2018-02-26 18:26:01] <mantoshelis> ripper2hl: Should I be in directory whereDockerfileof that image placed?
[2018-02-26 18:26:02] <ripper2hl>  [<-LINK->] 
[2018-02-26 18:26:15] <ripper2hl> atom*
[2018-02-26 18:26:55] <mantoshelis> ripper2hl: , sorry, I'm using IntelliJ. Anyways, thanks for fast response
[2018-02-26 18:27:05] <ripper2hl> in the docker-compose you can specify the path to Dockerfile
[2018-02-26 18:27:31] <ripper2hl> i have intellij but i dont use for docker development
[2018-02-26 18:27:47] <ripper2hl> atom and old bash works fine, but i try use intellij
[2018-02-26 18:28:32] <mantoshelis> I will give a try for IntelliJ
[2018-02-26 18:49:45] <mantoshelis> ripper2hl: , did you try Portainer, a Docker UI tool?
[2018-02-26 18:51:22] <ripper2hl> no , but i try install now
[2018-02-26 18:51:25] <ripper2hl> thanks
[2018-02-26 21:32:11] <w1z4rd> Hello
[2018-02-26 21:32:45] <w1z4rd> I have some issues with the docker engine after upgrading my ubuntu kernel from 14.4 to 14.15.5
[2018-02-26 21:32:54] <w1z4rd> has anyone ran into similar issues?
[2018-02-26 21:34:28] <w1z4rd>  [<-CODE->] 
[2018-02-26 23:39:24] <w1z4rd> reverted to 4.13.0-36
[2018-02-26 23:39:39] <w1z4rd> got the docker service up
[2018-02-26 23:39:53] <w1z4rd>  [<-CODE->] 
[2018-02-26 23:41:25] <w1z4rd>  [<-CODE->] 
[2018-02-26 23:41:45] <w1z4rd>  [<-CODE->] 
[2018-02-26 23:44:06] <w1z4rd> looks like removingDOCKER_HOSTfrom/etc/environmentsolved it
[2018-02-26 23:44:26] <w1z4rd> thanks for being such an engaged audience
[2018-02-26 23:44:33] <w1z4rd> it's always a pleasure
[2018-02-27 08:34:37] <mjosef89> Hi,I have created two folders "Project-A" and "Project-B" for testing both of them contain a docker-compose.yml file.Project-A: (services: project-a: image: fauria/lamp / ports: 8080:80)Project-B: (services: project-b: image: fauria/lamp / ports: 80:80)When I first call "docker-compose up" in Project-A, the Container "docker_project-a_1" starts. After that i do the same inProject-B and container "docker_project-b_1" starts also.But I get the warning:"Found orphan containers (docker_project-a_1) for this project. [...]) that I don\'t understand.If the starting order is reversed, I get the message when starting Project-A with reference to docker_project-b_1.These two projects/containers should have no connection to each other.It\'s all working, but I\'d like to know why the report is coming.Thanks
[2018-02-27 11:32:29] <hiteshchaudhari-tudip> Hi,I am newbie in Docker.I am getting 'localhost didn't send any data' error while I use docker run image-name which is javascript project.
[2018-02-27 11:53:27] <MakanTaghizadeh> What is you OS?
[2018-02-27 11:53:40] <MakanTaghizadeh> Are you running any distro of linux?
[2018-02-27 14:27:25] <Leeaandrob> hello I need help :(
[2018-02-27 14:27:31] <Leeaandrob> I am trying to run this command
[2018-02-27 14:28:01] <Leeaandrob>  [<-LINK->] 
[2018-02-27 14:32:18] <Leeaandrob> but always I receive this error /bin/sh: 1: ./config: not found
[2018-02-27 14:33:02] <MakanTaghizadeh> You’re running commands in separate layers
[2018-02-27 14:33:11] <MakanTaghizadeh> You have two choices
[2018-02-27 14:34:46] <MakanTaghizadeh> 1- You can either run all in just oneRUNinstruction, like the following: [<-CODE->] 
[2018-02-27 14:35:19] <MakanTaghizadeh> Right?
[2018-02-27 14:35:45] <Leeaandrob> oh thanks@MakanTaghizadehI will try the first option :)
[2018-02-27 14:37:13] <MakanTaghizadeh> 2- You can instructDocker Enginethat I want to switch my working directory from one layer on, like the following: [<-CODE->] 
[2018-02-27 14:37:45] <Leeaandrob> interesting thing... for the .config works I need to do this?WORKDIR?
[2018-02-27 14:37:58] <MakanTaghizadeh> Second one is not good a practice.
[2018-02-27 14:38:06] <Leeaandrob> because on centos so I didn't need to do this..
[2018-02-27 14:38:16] <Leeaandrob> nice to know@MakanTaghizadeh
[2018-02-27 14:38:27] <MakanTaghizadeh> Yup, ;-) ur welcome mate 
[2018-02-27 14:38:40] <Leeaandrob> thanks very much :)
[2018-02-27 14:38:47] <MakanTaghizadeh> np mate 
[2018-02-27 14:45:11] <Leeaandrob> hey@MakanTaghizadehI have other problem with other package :p
[2018-02-27 14:45:22] <Leeaandrob> 32 RUN curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | apt-key add -33 RUN echo "deb https://dl.yarnpkg.com/debian/ stable main" | tee /etc/apt/sources.list.d/yarn.list && apt install yarn
[2018-02-27 14:45:52] <Leeaandrob> E: Unable to locate package yarn
[2018-02-27 14:45:57] <Leeaandrob> I receive this error
[2018-02-27 14:46:11] <Leeaandrob> but when I run inside on container the command works :s
[2018-02-27 14:47:35] <MakanTaghizadeh> I guess you’ve got to update apt package list once after adding new repo url. I mean the line 33 should be:RUN echo "deb https://dl.yarnpkg.com/debian/ stable main" | tee /etc/apt/sources.list.d/yarn.list && apt update && apt install yarn
[2018-02-27 14:48:30] <MakanTaghizadeh> But put this apart, as I said it’s highly recommended to run multiple related commands inoneRUNinstruction.
[2018-02-27 14:48:32] <Leeaandrob> very strange directly on container I didn't need to runapt update
[2018-02-27 14:48:35] <Leeaandrob> it works now :)
[2018-02-27 14:48:56] <Leeaandrob> nice tip brow!
[2018-02-27 14:49:08] <MakanTaghizadeh> I mean this  [<-LINK->] 
[2018-02-27 14:49:26] <MakanTaghizadeh> ;-) good luck 
[2018-02-27 14:49:32] <Leeaandrob> ok thanks again :)
[2018-02-27 20:51:39] <harshana5> Hey guys
[2018-02-27 20:52:57] <harshana5> we are farily new to docker, Iam trying to setup docker machine to deploy containers to my remote hosts. the documentation is bit unclear so i was wondering if one of you can help me out
[2018-02-27 22:56:25] <j0nathan_davies_twitter> Hi - new to docker, enjoying getting stuck in but a bit confused conceptually by something. Wonder if anyone can help out?
[2018-02-27 22:57:12] <j0nathan_davies_twitter> I’m running a jira instance using this image: [<-LINK->] 
[2018-02-27 22:58:20] <j0nathan_davies_twitter> By modifying the Volume part of the dockerfile toVOLUME ["~/jira-home:/var/atlassian/jira:rw", "~/jira-home:/opt/atlassian/jira/logs:rw”]I can get the data to persist
[2018-02-27 23:20:46] <j0nathan_davies_twitter> My question is, how do I share this instance with other people, so they sign in to my instance, but any modifications they make are also persisted for all other users?As it stands I assume anyone who runs my image (with the amended docker file) will be prompted to start a new instance, which will persist data on their computer only, as opposed to just logging into my instance.Can anyone give me any pointers  for solving this?
[2018-02-27 23:48:57] <Toxicable> Hey all, Anyone happen to know how to set a host in a image that will remain for any images deriving from it?I've only found --add-host and extra_host but i'd prefer to build it into the image rather than in the commands
[2018-02-28 03:43:15] <SISheogorath> Toxicable: No, not possible. Neither hostname nor changes on /etc/hosts will survive.
[2018-02-28 03:44:58] <SISheogorath> If you really want it, you can try to hack it into the entrypoint script, but that a ugly havk and only works as long as all derivates call this script.
[2018-02-28 03:47:35] <SISheogorath> j0nathan_davies_twitter: the way you use the Volume statement in your docker file makes no sense .-. you can't bindmount with this statement
[2018-02-28 03:48:42] <SISheogorath> harshana5: don't ask to ask, bring up your question and if someone can help they will.
[2018-02-28 03:58:50] <Toxicable> SISheogorath: yeah that's what I though, ohwell looks like I'll have to inline host file edit scripts when I need it
[2018-02-28 04:00:29] <SISheogorath> mjosef89: the warning appears because you use the same "project name" from docker-compose perspective. By default docker-compose uses the directory name as project name and prefix. (In your example docker) when it now finds a container with this prefix, which is not listed as a service in its compose file, it expects that it was deleted from it but the container was never stopped and this way became an orphan container
[2018-02-28 05:45:32] <yosefrow> you can override the default compose project name by defining the env var COMPOSE_PROJECT_NAME as a unique string on ur host machine [<-LINK->] 
[2018-02-28 07:06:54] <vito-c> I would like my containers to communicate to each other via host name. Let's say I have container foo running on port 9000 and I have container bar that would like to talk to foo via [<-LINK->] is there a config in docker-compose I can set to do this
[2018-02-28 07:19:37] <hiteshchaudhari-tudip> MakanTaghizadeh: I'am using OSX
[2018-02-28 10:50:14] <yosefrow> vito-c: I believe by services containers brought up by the same compose have the other service names added to their /etc/hosts by default and can be acessed like [<-LINK->] 
[2018-02-28 10:51:51] <yosefrow>  [<-LINK->] 
[2018-02-28 10:58:38] <mcordoba> yosefrow: yes it is just like@yosefrowsaid
[2018-02-28 16:11:32] <vito-c> mcordoba: @yosefrowyah I know I can hit [<-LINK->] 
[2018-02-28 16:11:58] <vito-c> but what I need is something that maps that to [<-LINK->] for example
[2018-02-28 17:45:39] <mcordoba> vito-c: so you are talking about production? you can use a reverse proxy like nginx
[2018-02-28 18:13:56] <vito-c> mcordoba: no it's for development
[2018-02-28 18:14:31] <vito-c> I'm using traefik for proxying but I'm not sure how to set it up to do internal host names for the containers
[2018-02-28 21:32:06] <CharityCompassionCoin-CCC> is there anyone that can clarify how much 420.000 stands for?
[2018-02-28 21:32:19] <CharityCompassionCoin-CCC> in actual coin volume
[2018-03-01 00:58:28] <rightisleft> Is there a way to use yum to install docker-compose? it looks like CentOS 7.4 has an epel release, but its an old version
[2018-03-01 00:58:42] <rightisleft> docker-compose version 1.9.0, build 2585387
[2018-03-01 00:59:23] <rightisleft> yum : docker-compose.noarch                     1.9.0-5.el7@epel
[2018-03-01 05:28:31] <hullsean> vito-c: check out -link in your docker-compose.yml file.  it allows the containers to “see” each other
[2018-03-01 05:48:51] <skarred14> hi all, i am using docker-compose v3 and running the following file: [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2018-03-01 07:09:44] <itwebsil> hi
[2018-03-01 07:12:00] <itwebsil> i'm trying to install xwiki on docker and i looked up on docker hub but the steps are not complete, i'm new to docker so any  article/post  or video that has step by step instruction would help me
[2018-03-01 07:12:17] <itwebsil> anyone here has done this before?
[2018-03-01 09:14:42] <vito-c> hullsean: are you able to map domain names to ip and port with links?
[2018-03-01 10:47:18] <mcordoba> vito-c: I don't see the point to use domains in dev... you will have extra complexity
[2018-03-01 13:54:08] <amrit3701> Hi,How to bypass the process running on specific port inside the docker space to system? For eg.I have entered to docker container (sudo docker-compose run --entrypoint bash api) and then runroot@c5240f3ab908:/app# python3.6 manage.py run_server --hostname 0.0.0.0 --port 3333command. The process running on3333port not reflects to the outer system. [<-CODE->] 
[2018-03-01 15:38:09] <mderdem> newbie question: I would like to build a docker image based on rhel 7.1, can I build this on ubuntu (I still plan to run on RHEL 7.1), I am only curious if I can build all the images on one distro.
[2018-03-01 15:57:40] <CharityCompassionCoin-CCC> may one kindly answer: What happens if i were to send ethereum directly to my contract address?
[2018-03-01 15:58:15] <CharityCompassionCoin-CCC> Will this begin to give valation to coin? how does a token coin establish a valuation per token?
[2018-03-01 22:41:20] <vito-c> Let's say I  have containers A, B, C in a bridged network and I want them to send all of their requests over port 80 to host D is there a way to do this?
[2018-03-02 07:31:14] <jdickey> Hey, folks. Really basic question, but I\'ve somehow missed this in the docs.I\'ve several (>10) images, ergo Dockerfiles, that I maintain that differ only by the image that they\'re based on. I\'d really love to DRY that up, so I have one "master" Dockerfile or template that I can use to spin off variations as needed. What\'s my best course of action?
[2018-03-02 07:55:29] <cheshirecode> jdickey: try [<-LINK->] 
[2018-03-02 07:55:35] <yuetianle> happy to here
[2018-03-02 08:31:01] <chan_seeker_twitter> How to dockerize a angular application
[2018-03-02 08:31:06] <chan_seeker_twitter> any dockerfile?
[2018-03-02 09:06:40] <jdickey> cheshirecode: Thanks; reading now
[2018-03-02 09:13:37] <jdickey> cheshirecode: Interesting, but different than what I'm asking about. If I understand multistage builds correctly, they're to clean up things that have often used multiple Dockerfiles to create a single product; the classic example (that they demonstrate) is probably dev vs prod builds. What I'm after is a bit different; I want to apply the same steps to each of a group of base images (e.g., Ruby version/base OS combinations such asruby:2.4.2-jessievsruby:2.5.0-alpine). Any other ideas?
[2018-03-02 09:15:38] <jdickey> IIUC, multistage builds are great if you want to apply a collection of different option paths to a common base image. I'm going the other way: applying a common set of actions to a collection of base images
[2018-03-02 09:28:38] <cheshirecode> If I understand correctly, you want to create containers based on your given base image as input? Maybe you need to generate Dockerfiles on the fly and consume them. Look into [<-LINK->] for more ideas. I haven't explored this problem in details yet so let me know if you come up with a working solution too. Would love to hear.
[2018-03-02 09:30:52] <jdickey> Thanks! That looksreallypromising
[2018-03-02 09:37:15] <jdickey> cheshirecode: …and I'm an idiot. I can apparently get what I want with simple build arguments. I missed [<-LINK->] on previous read-throughs of the docs; the second example isexactlywhat I'm looking for, and makes my lifesomuch easier. Thanks for your help and patience :)
[2018-03-02 10:40:38] <SISheogorath> vito-c: use network aliases and add the full domain name there, rhen it works. By default it's not planned to use full domain names
[2018-03-02 10:42:23] <SISheogorath> hullsean: please don't recommend links anymore they are deprecated and neither work in swarm setups nor should they be used anywhere else because they have some ugly side effects
[2018-03-02 10:44:18] <SISheogorath> mderdem: yes, when you can access the base image, you can build it without a problem as long as you cpu arch matches
[2018-03-02 10:49:34] <SISheogorath> chan_seeker_twitter: check my example PR [<-ISSUE->] 
[2018-03-02 11:00:46] <chan_seeker_twitter> SISheogorath: Will this dockerfile work for any angular application?
[2018-03-02 11:05:06] <cheshirecode> jdickey: good to save yourself an mini SI project :D
[2018-03-02 11:08:23] <chan_seeker_twitter> Hii am getting this error while connecting to a swarm registered on docker cloudC:\\Program Files\\Docker Toolbox\\docker.exe: error during connect: Post https://192.168.99.100:2376/v1.36/containers/create: x509: cannot validate certificate for 192.168.99.100 because it doesn't contain any IP SANs.
[2018-03-02 11:08:31] <chan_seeker_twitter> any one help me out
[2018-03-02 11:08:36] <chan_seeker_twitter> thanks in advance
[2018-03-02 11:10:01] <chan_seeker_twitter> I have a already ip in it still it gives on docker-toolbx for windows 7
[2018-03-02 19:33:14] <pgreisen> Hi all, I have a problem creating a virtual environment inside a docker container: python3 -m venv test but I keep getting this error: Command '['/home/pjug/test/bin/python3', '-Im', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.pjug@eb1749ce4748:~$
[2018-03-02 19:33:50] <pgreisen> could someone guide me how to fix this and why I get this problem it is inside a jupyterhub within in container
[2018-03-03 08:29:15] <EmpeRoar> Hi Guys
[2018-03-03 08:29:29] <EmpeRoar> I got this error
[2018-03-03 08:29:30] <EmpeRoar> Error starting userland proxy: Bind for 0.0.0.0:80: unexpected error Permission denied.
[2018-03-03 08:29:40] <EmpeRoar> how do I solve that?
[2018-03-03 08:29:48] <EmpeRoar> I stuck for 5 days already
[2018-03-03 08:30:04] <MakanTaghizadeh> Hi@EmpeRoar
[2018-03-03 08:30:22] <MakanTaghizadeh> Are you running this container as a non-root user?
[2018-03-03 08:30:27] <EmpeRoar> Hi@MakanTaghizadeh
[2018-03-03 08:30:37] <EmpeRoar> I am using Windows 10 Pro
[2018-03-03 08:30:58] <EmpeRoar> using powershell as administrator
[2018-03-03 08:30:59] <MakanTaghizadeh> Oh, I see.
[2018-03-03 08:31:32] <MakanTaghizadeh> Are you sure you’re not running IIS or similar service already on port 80?
[2018-03-03 08:31:44] <EmpeRoar> iis is off
[2018-03-03 08:32:00] <EmpeRoar> the build version for my windows pro is 17110
[2018-03-03 08:32:06] <EmpeRoar> and docker version is
[2018-03-03 08:32:27] <EmpeRoar> Client: Version:       18.03.0-ce-rc1 API version:   1.37 Go version:    go1.9.4 Git commit:    c160c73 Built: Thu Feb 22 02:34:04 2018 OS/Arch:       windows/amd64 Experimental:  true Orchestrator:  kubernetesServer: Engine:  Version:      18.03.0-ce-rc1  API version:  1.37 (minimum version 1.12)  Go version:   go1.9.4  Git commit:   c160c73  Built:        Thu Feb 22 02:42:37 2018  OS/Arch:      linux/amd64  Experimental: true
[2018-03-03 08:34:47] <MakanTaghizadeh> Um, I’m afraid I have little exprience with docker in windows. I’ll do a search for it and let you know if I found anything useful.
[2018-03-03 08:35:38] <MakanTaghizadeh> Are you running the container with run command in Powershell, or you’re using docker-compose?
[2018-03-03 08:36:17] <EmpeRoar> im using powershell
[2018-03-03 08:36:24] <EmpeRoar> im try to run
[2018-03-03 08:36:38] <EmpeRoar> 'docker container run --publish 80:80 nginx'
[2018-03-03 08:37:59] <MakanTaghizadeh> It seems flawless! Strange behaviour!
[2018-03-03 08:38:13] <EmpeRoar>  [<-LINK->] 
[2018-03-03 08:39:55] <EmpeRoar>  [<-LINK->] 
[2018-03-03 08:40:02] <MakanTaghizadeh> Unfortunately I have no idea. I’ll let you know if I found anything good.
[2018-03-03 08:40:16] <EmpeRoar> thanks Buddy@MakanTaghizadeh
[2018-03-03 21:50:15] <SISheogorath> chan_seeker_twitter: actually no idea, it's not like I'm a frontend dev. i judt automate things
[2018-03-04 17:19:03] <johannwagner> Hey Guys, I just have a small issue with the node container regarding cloning from a private repo with ssh keys. I generated a new pair of ssh keys and added them as user, which has access to the repo, I want to clone. I also managed to copy the keys into my docker container, but I am not sure, where I have to copy them, because the container seems to ignore .ssh folder.
[2018-03-05 09:20:55] <slim-hmidi> Hi, I'm using the official image of [<-LINK->] and I need to make the export based on [<-LINK->] . However the server always run and it's not possible to make the export and I got an error.Is it possible to launch a script when the docker container stop to make the export?
[2018-03-05 09:30:40] <SISheogorath> you can modify the entrypoint script handle signals, but when the container is killed by OOM or something, no
[2018-03-05 09:39:46] <serragnoli> Hi guys.My app stopped outputting to the console inside a container. The container is running a JVM app with Logback. Does anyone know if this is caused by some limitation of the container or do you think it’s likely to be logback?
[2018-03-05 11:56:24] <dkirrane> Hi, I had docker-for-win up and running and after rebooting my laptop I hit'MobyLinuxVM' failed to add device 'Virtual CD/DVD Disk'Full error [<-CODE->] 
[2018-03-05 15:15:27] <edmondo1984> hello, can one define a variable in a Dockerfile and use it in the various commands? I.e. I want to set the variable of a library and use it when downloading from a repository etc, when I update my library I just want to change it in one place
[2018-03-05 15:28:47] <SISheogorath> edmondo1984:  [<-LINK->] 
[2018-03-05 15:36:49] <MonXBZH> Hello everybody, just a little question, do dockers containers need to expose theirs ports to be reachable by anothers containers? Or they can be reachable if they are on the same network ? What I've understood it's, only exposed ports will be reachable from internet. But for an internal network use?
[2018-03-05 15:36:59] <MonXBZH> PS: excuse my EN... ^^"
[2018-03-05 16:00:09] <SISheogorath> MonXBZH: yes, when containers are on the same networks, they can access every port. No need to expose anyone. Exposed ports are only for external connections outside of docker
[2018-03-05 16:01:06] <MonXBZH> SISheogorath: Copy. Thx for reply ! o/
[2018-03-05 17:54:36] <Jahhein> might anyone be able to help me figure out why I cannot move docker's local diskimage on macos ? Through the app, after selecting an external hard disk I have, it will freeze and lock up. I've checked to see if it is moving things, but after several hours it was only about 500mb. I've reinstalled, I have no images downloaded. I've try symlinking but that isn't working for some reason either.
[2018-03-05 18:52:09] <lidderupk> can somebody help with thishttps://stackoverflow.com/questions/49116456/how-to-use-multiple-dockerfiles-for-single-application. I am new to docker. Learning as I go.
[2018-03-05 18:54:49] <ugorur>  [<-LINK->] @lidderupk
[2018-03-05 19:01:25] <lidderupk> Thanks@ugorur. I know how to run the files. The problem is that when I run the second file, it does not allow me toRUN chmodon my files. Seems like when the.tar.gzis extracted, it gives them an owner ofgamesand a groupid of501.
[2018-03-05 23:16:21] <killerspaz> I need to simulate 2 sets of services coming up that need to talk through a proxy (which is one of the services)... so essentially i'll have 2 http servers accessible via different ports... Is it best to create 2 separate docker-compose config files (one extending the other, and the 2nd one specifying the network to use?) or is there a more sophisticated way to accomplish this?
[2018-03-05 23:39:14] <killerspaz> Figured it out.. i'm running viadocker-compose -d -p group1 up && docker-compose -d -p group2 up
[2018-03-06 02:44:21] <cheshirecode> would it be possible to orchestrate 2 services and 1 proxy in the same docker-compose.yml file so you can run 1 command?
[2018-03-06 05:50:55] <killerspaz> probably, but i figure it's easier to let docker-compose deal with the networking segregation... works pretty well instead of having to instrument every service definition
[2018-03-06 07:10:12] <cheshirecode> same train of thought :D, since I could route from nginx like this [<-CODE->] with app1  as a defined service in the same compose file where nginx proxy is another server, I've been adding more services to the same network basically
[2018-03-06 09:25:09] <SISheogorath> lidderupk: Your problem is that you change the user in the first dockerfile. chown only works are root. when you are the userdsadminthis can't work
[2018-03-06 09:25:41] <SISheogorath> oh funny, someone already wrote this underneath ^^
[2018-03-06 09:54:39] <dimensi0n> Is there a Golang community on gitter ?
[2018-03-06 10:21:37] <duyngha> Hi there
[2018-03-06 10:22:03] <duyngha> I have adocker-compose.ymlfile as below [<-CODE->] 
[2018-03-06 10:22:27] <duyngha> and aDockerfile [<-CODE->] 
[2018-03-06 10:23:00] <duyngha> when I rundocker-compose upit works
[2018-03-06 10:23:21] <duyngha> docker psshows
[2018-03-06 10:23:54] <duyngha>  [<-CODE->] 
[2018-03-06 10:24:43] <duyngha> this0.0.0.0:5000->3001/tcpmean docker map the port successfully
[2018-03-06 10:25:28] <duyngha> but when I accesslocalhost:5000it saidThis page isn’t working
[2018-03-06 10:25:48] <duyngha> Did I make something wrong?
[2018-03-06 10:25:53] <duyngha> please help me!
[2018-03-06 10:25:59] <duyngha> thank you so much
[2018-03-06 11:08:59] <SISheogorath> duyngha: By "this page isn\'t working", can you provide a more technical error message?
[2018-03-06 14:14:47] <davidmichaelkarr> that error means it got to your app.check the logs of the app container.
[2018-03-06 15:22:25] <killerspaz> cheshirecode: oh, that's how you're meant to do it... Just that i need the same services up twice to simulate replicated cluster of services, so it's slightly a different problem... .But yes, I do the same thing, but also have a fallback for the deployment (using a proxy_pass to localhost) since docker isn't the deploy target
[2018-03-06 15:59:15] <killerspaz> duyngha: that all looks correct for the most part.... as stated, check the logs (docker-compose logs app), and if nothing jumps out, try going into the container (docker exec -it YOUR_CONTAINER_NAME bash) and do some investigation (ie,netstat -tanp)
[2018-03-06 21:28:07] <lidderupk> thank you@SISheogorath.
[2018-03-06 21:48:32] <SISheogorath> You're welcome
[2018-03-07 01:32:09] <duyngha> killerspaz: thanks for your respondingthis is logs that I got [<-CODE->] 
[2018-03-07 01:35:21] <duyngha> SISheogorath: It didnot show me anything else. btw inapp/folder I created stuff ofnodejsserver withexpressandnodemon
[2018-03-07 01:56:31] <duyngha> killerspaz: @SISheogorathI resolved my issue. it caused I expose wrong port in Dockerfile. the nodejs run in default port 3000. So docker works fine. I just need to change the port to 3000 and map it in todocker-compose.yml. Thank you so much for your responding guys
[2018-03-07 05:27:40] <fabiomolinaruol> Hello all! I just finished compiling a survey with more than 350 open source software project members which, together with some communication theory, we used to define a set ofbest practices and guidelines for using Gitter(in fact, it probably applies toany chat-like platform).If anybody would be interest on it, or in applying them in this community, or your other projects, there is a [<-LINK->] you can fill to get the guidelines. The survey takes something between just10 seconds to a maximum of 2 minutes to filland it is intended to help us validate the guidelines in the future.There is also a small [<-LINK->] I wrote with a really short description about the study; in case you would be curious about it.Of course, feel free to send the [<-LINK->] to anyone you would like to share these guidelines with.
[2018-03-07 14:47:32] <aroca> Hi guys! Is there a way in compose to replicate the behaviour of swarm deploy in services like defining N services: web: quantity: 3 ?
[2018-03-07 14:47:46] <aroca> like the deploy part in swarm
[2018-03-07 14:49:38] <SISheogorath> aroca:  [<-LINK->] <-- ?
[2018-03-07 14:51:43] <aroca> nice.. thanks@SISheogorath! though this is only for command line right?
[2018-03-07 14:52:03] <SISheogorath> yes, this is currently only for commandline
[2018-03-07 14:52:05] <aroca> i think i can manage with it. :)
[2018-03-07 14:52:14] <SISheogorath> for testing it should be enough
[2018-03-07 14:52:20] <Leeaandrob> hello :)
[2018-03-07 14:52:21] <aroca> yepss.. thanks!
[2018-03-07 14:52:29] <Leeaandrob> I am trying to use docker-compose to run node applications
[2018-03-07 14:52:37] <Leeaandrob> but it fails always :(
[2018-03-07 14:53:39] <Leeaandrob>  [<-CODE->] 
[2018-03-07 14:53:47] <Leeaandrob>  [<-CODE->] 
[2018-03-07 14:54:17] <Leeaandrob>  [<-CODE->] 
[2018-03-07 14:54:46] <Leeaandrob> what's the error on my recipes? :(
[2018-03-07 14:55:10] <SISheogorath> the more important question is: What error message do you get?
[2018-03-07 14:55:38] <Leeaandrob> hey@SISheogorathhow are you?
[2018-03-07 14:55:59] <SISheogorath> Leeaandrob: I'm fine, thanks, how about you?
[2018-03-07 14:56:01] <Leeaandrob>  [<-CODE->] 
[2018-03-07 14:56:12] <Leeaandrob> I'm fine too@SISheogoraththanks :)
[2018-03-07 14:59:20] <SISheogorath> I really suggest you to learn how to read error messages. It\'s very, very clearly stated why it fails: "Error: /build/node_modules/scrypt/build/Release/scrypt.node: invalid ELF header" -> the version of the module you are using in your container is not compiled against the right version
[2018-03-07 14:59:37] <SISheogorath> Why does this happen? Because you run a different OS on your host than in the container
[2018-03-07 14:59:56] <SISheogorath> How to resolve? Stop sharing the node_modules directory and install the dependencies inside the container
[2018-03-07 15:00:03] <Leeaandrob> you have right!
[2018-03-07 15:00:11] <Leeaandrob> but my idea is avoid this situation...
[2018-03-07 15:00:26] <SISheogorath> or rewrite everything to use the same OS as your host OS
[2018-03-07 15:00:43] <Leeaandrob> ok thanks@SISheogorathyou have right! sorry!
[2018-03-07 15:01:01] <SISheogorath> If you need a cached version of node_modules, use multi-staged builds
[2018-03-07 15:01:14] <Leeaandrob> how?
[2018-03-07 15:01:35] <SISheogorath>  [<-LINK->] 
[2018-03-07 15:02:32] <SISheogorath> Build one container that runs npm install and uses the same base image, then copy the node_modules directory from this image to the one you want to use and rebuild
[2018-03-07 15:03:12] <Leeaandrob> hm... ok thanks@SISheogorath
[2018-03-07 15:04:14] <SISheogorath> You're welcome
[2018-03-07 15:04:40] <Leeaandrob> sometimes the bad of programmer is not read the output ;)
[2018-03-07 15:07:59] <SISheogorath> No problem, that's why we are around ^^ Just as hint: Next time first read/post the error and the sources only on request :D because some people can tell you the problem without reading the source ;)
[2018-03-07 15:08:32] <Leeaandrob> sure!
[2018-03-07 15:09:45] <SISheogorath> In a forum you would go the other way around, but here space is limited :D
[2018-03-07 15:10:15] <Leeaandrob> yes you have absolutely right@SISheogorathsorry again!
[2018-03-07 15:10:30] <SISheogorath> No need to be sorry ;)
[2018-03-07 15:13:15] <Leeaandrob> I am following the tutorial :)
[2018-03-08 13:38:34] <ppLorins> Hi all , I'm stucking atpulling fs layerwhen building images  , it didn't help after restart the docker daemon serveral times, anyone who ever encoutered this ?
[2018-03-08 13:38:42] <ppLorins>  [<-LINK->] 
[2018-03-08 14:12:28] <SISheogorath> Do you run through any kind of proxy or VPN?
[2018-03-08 19:21:38] <dkirrane> Hi, is it possbile to configire docker-for-win with a config file rather than from the UI settings? And will the UI pick up the config file and display the settings?
[2018-03-08 20:30:22] <cebor> hi, is it possible to reset a local kubernetes cluster created with docker-ce edge?
[2018-03-08 20:32:08] <cebor> found it, RESET (little bomb) -> Reset Kubernetes
[2018-03-08 20:32:17] <cebor> in docker options
[2018-03-08 22:36:47] <Leeaandrob> hello guys!
[2018-03-08 22:43:39] <Leeaandrob> is it possible cache node_modules during the docker build images?
[2018-03-09 10:58:33] <maksimyugai> hi, everyone. Can someone say, how I can delete docker image with configuration? I run jenkins docker image, but when I delete it, jobs which I created earlier, appears again
[2018-03-09 10:59:36] <hamon-e> Hellosince this morning i have an error when i try to launch my docker compose with a custom network and ip settings [<-CODE->] the only change on my computer was the update [<-CODE->] Here is my docker compose: https://transfer.sh/hOiDY/docker-compose.ymlThx
[2018-03-09 11:56:42] <gokhankuyucak> maksimyugai: hi, are you mounting same value everytime like -v jenkins_home:/var/jenkins_home? If so you need to check your local jenkins_home folder while you're mapping.
[2018-03-09 12:05:49] <maksimyugai> gokhankuyucak: thnx for answer, I found out how to delete it. But I don\'t understand what does this line mean -v "$HOME":/home. I try run jenkins docker image from this guide [<-LINK->] 
[2018-03-09 12:16:08] <gokhankuyucak> maksimyugai: by using command -v(volume), you are sharing your local folder with container. In your example -v jenkins-data:/var/jenkins_home means that jenkins container will use your local env jenkins_data instead of container folder. we can assume that /var/jenkins_home is a shortcut in container which maps to local jenkins-data. So when you remove jenkins image it does not delete your jenkins-data. You can delete that folder after you remove image or you can give another name while running new jenkins image like -v jenkins-data_20180309:/var/jenkins_home
[2018-03-09 12:16:49] <ChazUK> Are there any Docker & Jenkins experts here?
[2018-03-09 12:37:48] <ChazUK> Or another question, does anyone know how to pass a variable between docker steps
[2018-03-09 14:37:45] <mohamedaittaleb> Maybe you Can use Env Vars I think
[2018-03-09 14:39:28] <mohamedaittaleb> The ARG instruction defines a variable that users can pass at build-time to the builder with the docker build command using the  --build-arg <varname>=<value> flag. If a user specifies a build argument that was not defined in the Dockerfile, the build outputs an error.
[2018-03-09 14:40:56] <mohamedaittaleb> this should help [<-LINK->] 
[2018-03-09 14:46:32] <ChazUK> Thanks@mohamedaittaleb
[2018-03-09 14:47:42] <mohamedaittaleb> welcome :)
[2018-03-10 08:41:07] <collink> Hi all.  I'm trying to go through the docs for setting up my own registry, and I'm running into this issue, which seems to have no resolution... docker/distribution#1652Does anyone have any suggestions? Thanks in advance.
[2018-03-10 08:47:19] <collink> If I runalpinewith the same volume bindings, I can see files from the host FS in/certsand/auth, so I don't think it's related to the issue that was referenced when it was closed...
[2018-03-10 20:30:57] <nan140114> Hi :)
[2018-03-10 20:31:42] <nan140114> i'm trying to set this variable
[2018-03-10 20:32:04] <nan140114> export LANG="C.UTF-8"
[2018-03-10 20:32:24] <nan140114>  [<-CODE->] 
[2018-03-10 20:33:09] <nan140114> `FROM rubyRUN export LANG="C.UTF-8" \\    && export LC_ALL="C.UTF-8" \\`
[2018-03-10 20:33:13] <nan140114> OMG
[2018-03-10 20:37:42] <nan140114> ok im trying to set LANG and LC_ALL on the Dockerfile, when i try to run the container via docker compose, the variables doesnt exists
[2018-03-10 20:39:22] <nan140114> this is my Dockerfile
[2018-03-10 20:39:23] <nan140114>  [<-LINK->] 
[2018-03-10 20:39:56] <nan140114> at the docker-compose i'm just bind ports and volumes
[2018-03-10 20:41:49] <nan140114> but whe i run printenv in container the LANG and LC_ALL doesnt exists
[2018-03-10 20:42:10] <nan140114> that's right?
[2018-03-10 20:49:35] <nan140114> sorry, i can set env var with docker compose
[2018-03-10 20:49:40] <nan140114> :D
[2018-03-10 20:49:43] <nan140114> :D
[2018-03-11 01:07:31] <prashant7july> Hi all, How am I able to run curl command in docker-composer.yml only or docker-composer.yml call shell file (.sh) where we can execute curl command? [<-CODE->] 
[2018-03-11 03:34:47] <jadametz> Hey everyone  [<-CODE->] I don't see any Special Interest Group (SIG) channels or anything related to contributing in the channels list.
[2018-03-11 03:35:22] <jadametz> I think I'm mainly looking for some initial guidance on if the issue should be opened undermoby/mobyordocker/cli.
[2018-03-11 03:35:36] <jadametz> Figure conversation can go on from there after the issue is filed :)
[2018-03-11 05:51:20] <jadametz> Wanted to get the ideaon paperso I went ahead and created a feature issue. Would love other's support / feedback as interested: [<-ISSUE->] 
[2018-03-12 05:21:54] <maksimyugai> Hi, guys. I want to run jenkins into docker container. In Jenkinsfile I specified in steps following command: sh "python -m py_compile source/add2vals.py source/calc.py" and error occures there: [simple-pipeline] Running shell scriptpython3 -m py_compile sources/add2vals.py sources/calc.py/var/jenkins_home/workspace/simple-pipeline@tmp/durable-d6785e67/script.sh: line 1: python3: not found
[2018-03-12 05:22:56] <maksimyugai> even though I have installed python3
[2018-03-12 05:23:20] <maksimyugai> What's problem?
[2018-03-12 07:59:56] <ovelindstrom> maksimyugai: , IMHO, you should run your Jenkins Server and the Jenkins Worker in separate Docker instances. I have used the python image ( [<-LINK->] ) as a base to our python builds. Influences can be found at [<-LINK->] and [<-LINK->] 
[2018-03-12 08:08:38] <ovelindstrom> However, it is kind of tricky to run both the Jenkins Server and the Jenkins Slaves in Docker.
[2018-03-12 09:32:33] <talus46> greetings,  is there a way to configure muliple docker-composite that share some containers?
[2018-03-12 10:13:15] <SISheogorath> jadametz: I recommend to visit the docker community slack for this, there you'll find devs, specific channels, and more
[2018-03-12 10:14:32] <SISheogorath> talus46: do you have an example?
[2018-03-12 10:45:38] <aliuk2012> Hi, I have an angular, django app which I've setup docker-compose.  Docker-compose is working great but is there a way I can change and then upload & restart just one image container from the docker compose file
[2018-03-12 11:40:17] <SISheogorath> by upload you mean push to a registry or do you mean pull to your machine?
[2018-03-12 11:40:32] <SISheogorath> and in general, yes, that's no problem
[2018-03-12 11:42:11] <SISheogorath> you can either use [<-LINK->] or [<-LINK->] with--no-depsflag
[2018-03-12 11:42:18] <SISheogorath> aliuk2012: ^
[2018-03-12 12:49:17] <aliuk2012> SISheogorath: Hi, thanks for you reply, 'upload' should of been update.  Heres an example of the docker-compose i have [<-LINK->] . I would like to be able to locally develop django container. The DockerFile for django does run a few things like gulp tasks to compile frontend assets etc so when I make a change locally i would like the django container to update
[2018-03-12 18:04:01] <tusharbudhe0302> bash: syntax error near unexpected token '('
[2018-03-12 18:04:26] <tusharbudhe0302> docker run -p 4200:4200 -v $(pwd): /var/power-bi -w "/var/power-bi-ui" node npm run start
[2018-03-12 18:04:44] <tusharbudhe0302> docker run -p 4200:4200 -v $(pwd): /var/power-bi -w "/var/power-bi" node npm run start
[2018-03-12 18:46:28] <SISheogorath> aliuk2012: This sounds more like a job for a bash script with a file notify on it to rebuild the container
[2018-03-12 18:46:41] <SISheogorath> that's nothing docker will do automatically for you
[2018-03-12 18:47:15] <SISheogorath> tusharbudhe0302: Sounds like you have a broken shellscript somewhere
[2018-03-12 22:23:44] <matjazmav> Anyone know how to setup ceph distibuted storage?
[2018-03-12 23:26:09] <SISheogorath> probably the ceph guys? I mean, they not only wrote the software, they also wrote a lot of documentation about how to set it up ;)
[2018-03-13 08:06:30] <farukhkhan21_twitter> Hello guys, I am new to docker. Trying to deploy a LAMP stack for a production server using docker-compose. What are the security measures we can take inside the docker container? Maybe some port blocking, selinux, no root ssh? inside the container? And after yum -y update can we reboot the container from the dockerfile and after the reboot continue executing rest of the commands?
[2018-03-13 10:01:10] <SISheogorath> farukhkhan21_twitter: 1st you can't boot a container. Containers have no kernel, no bootloader, they are just a subset of your OS
[2018-03-13 10:01:30] <SISheogorath> 2nd you don't run ssh inside a container if you want to run a lamp stack
[2018-03-13 10:02:03] <SISheogorath> 3rd docker isolates the network by default and only publishes the ports you explicitly expose when you start your container
[2018-03-13 10:02:19] <SISheogorath> Please get some basics at: [<-LINK->] 
[2018-03-13 11:52:47] <farukhkhan21_twitter> SISheogorath: I am going through the training videos gradually. Meanwhile I need some help regarding what some codes are doing.
[2018-03-13 11:53:04] <farukhkhan21_twitter>  [<-CODE->] 
[2018-03-13 11:54:28] <farukhkhan21_twitter> can anyone please explain what each of these lines are doing exactly.
[2018-03-13 12:07:35] <SISheogorath> @farukhkhan21_twitter [<-CODE->] ```
[2018-03-13 12:09:31] <farukhkhan21_twitter> Thanks a lot@SISheogorathAm I creating a new bridge type network here instead of using the default bridge0?
[2018-03-13 12:09:39] <farukhkhan21_twitter> with a different subnet address?
[2018-03-13 12:10:03] <SISheogorath> yes and yes
[2018-03-13 12:10:30] <farukhkhan21_twitter> ok. do I need to explicitly disable the ipv6? or by default it is disabled?
[2018-03-13 12:10:44] <farukhkhan21_twitter> on the driver_opts
[2018-03-13 12:10:54] <SISheogorath> depends on your setup ^^
[2018-03-13 12:11:15] <farukhkhan21_twitter> My host server has IPv6 configured and working. Running CoreOS
[2018-03-13 12:11:32] <farukhkhan21_twitter> but I dont want my containers to have any form of IPv6 functions
[2018-03-13 12:11:44] <SISheogorath> then probably it's not the worst idea to explicitly disable it
[2018-03-13 12:12:18] <farukhkhan21_twitter> alright. the app_net is just a name of the new network right? I can rename this to anything?
[2018-03-13 12:12:28] <SISheogorath> yes
[2018-03-13 12:13:11] <farukhkhan21_twitter> lastly, is there any other things, you think I should add for a LAMP stack networking in here? Or anything to secure the network further?
[2018-03-13 12:14:01] <farukhkhan21_twitter> trying to design a lamp stack for production usage
[2018-03-13 12:17:03] <SISheogorath> You shouldn't do this as long as you are not at least a bit into the docker concepts
[2018-03-13 12:17:18] <farukhkhan21_twitter> just trying to learn bit by bit
[2018-03-13 12:17:39] <farukhkhan21_twitter> on a practical (sort of testing) project.
[2018-03-13 12:17:43] <SISheogorath> That's totally fine, but may not go instantly in production with it
[2018-03-13 12:17:56] <farukhkhan21_twitter> no I won't
[2018-03-13 12:18:08] <farukhkhan21_twitter> I will test it out thoroughly before doing that
[2018-03-13 12:18:34] <farukhkhan21_twitter> any suggestions on making the network more robust?
[2018-03-13 12:23:03] <SISheogorath> There are no universal hints. it highly depends on what you want to do and what you want to use
[2018-03-13 12:23:27] <SISheogorath> apart from that for a local setup the network defaults are pretty good
[2018-03-13 12:23:43] <SISheogorath> but usually you don't use coreos without an orchestrator
[2018-03-13 12:23:55] <farukhkhan21_twitter> I see
[2018-03-13 12:24:14] <farukhkhan21_twitter> btw when to use \'\' instead of "" or when to use nothing at all for boolean or strings like false.
[2018-03-13 12:25:39] <SISheogorath> You can use\'\'as well as""everywhere. booleans are a native type. Just check the yaml specification
[2018-03-13 12:27:09] <farukhkhan21_twitter> alright
[2018-03-13 12:29:00] <farukhkhan21_twitter> why there is an - in the subnet when there is none at the com.docker.network line? what are the differences between these two?
[2018-03-13 12:29:40] <farukhkhan21_twitter> subnet: 173.25.5.0/24
[2018-03-13 12:29:47] <farukhkhan21_twitter> com.docker.network.enable_ipv6: "false"
[2018-03-13 12:29:58] <farukhkhan21_twitter> the subnet line has an extra - at the front
[2018-03-13 12:34:04] <farukhkhan21_twitter> is there no difference?
[2018-03-13 12:38:06] <farukhkhan21_twitter> and should I explicitly declare a gateway such as: gateway: 173.25.5.1?
[2018-03-13 13:08:55] <SISheogorath> everything stating with an - is an array element. otherwise it becomes and object. As I said, please read the yaml specification
[2018-03-13 13:09:15] <SISheogorath>  [<-LINK->] 
[2018-03-13 13:16:12] <farukhkhan21_twitter> alright
[2018-03-13 13:33:34] <farukhkhan21_twitter> btw what you guys think about alpine in production?
[2018-03-13 13:35:51] <SISheogorath> I build almost all my images on alpine
[2018-03-13 13:36:41] <SISheogorath> it makes deployments way faster and minimizes the footprint of your containers. But of course you need to know how to handle it, as it's musle based and this way not as the most distros
[2018-03-13 13:37:14] <farukhkhan21_twitter> does apps under musl libc behaving good?
[2018-03-13 13:37:38] <SISheogorath> Not all, but most, yes, once you made them build
[2018-03-13 13:38:16] <farukhkhan21_twitter> ow I see.
[2018-03-13 13:38:35] <farukhkhan21_twitter> did you ever try using bind under alpine?
[2018-03-13 13:39:25] <SISheogorath> nope
[2018-03-13 13:40:19] <farukhkhan21_twitter> in my end bind is behaving weird. not sure whether its a bind config problem or the alpine base
[2018-03-13 13:41:43] <farukhkhan21_twitter> when I dig any hostname from the php-fpm container which depends on bind it usually ends up giving me the bind dns wildcard ip
[2018-03-13 13:48:22] <farukhkhan21_twitter> should I explicitly declare gateway on the network?@SISheogorath
[2018-03-13 13:49:56] <ghost~59eab51fd73408ce4f7b031f> I want to install xwiki over tomcat and MySQL without pull,so,basically a dockerfile. To build image for xwiki as I don't have access to outside docker public repo..
[2018-03-13 13:50:55] <ghost~59eab51fd73408ce4f7b031f> I will create a image and upload it to private docker hub repo
[2018-03-13 13:51:15] <SISheogorath> praveensinghpokharia: Go for it, what's the problem?
[2018-03-13 13:53:00] <ghost~59eab51fd73408ce4f7b031f> I do not want to pull image, I hv tomcat mysql installed.. I have war of xwiki as well
[2018-03-13 13:53:13] <ghost~59eab51fd73408ce4f7b031f> Any sample for that
[2018-03-13 14:15:15] <SISheogorath> if you really want to build everything yourself, check out how to build base images. meansFROM scratchbut keep in mind, this is nothing for newbies. You should really be aware of how docker works when you want to build base images
[2018-03-13 14:29:54] <farukhkhan21_twitter> Hey@SISheogorathI will be re-writing a new dockerfile with alpine base for bind dns. I will post it here and please look into it if I am doing something wrong
[2018-03-13 15:49:33] <tusharbudhe0302> SISheogorath: Thanks. It help me.
[2018-03-13 17:49:03] <jdickey>  [<-CODE->]  [<-CODE->] and I'd love to be able to automate this in a Ruby script. Thanks!
[2018-03-13 18:26:25] <stephenchu>  [<-CODE->]  [<-CODE->] 
[2018-03-14 09:13:16] <mohamedaittaleb> Hi All,any docker certified guy here ?
[2018-03-14 09:26:50] <grofit> Apologies if this is a super simple question but I am struggling to find much info on the subject, so currently the main pathway to create a docker container and share it for other applications (i.e you have an api and a front end) is to add a dockerfile to each, then push that container to docker hub
[2018-03-14 09:28:56] <grofit> So I was wondering is there another way to basically share a docker container without using docker hub? i.e we would like to be able to somehow expose the containers from our build server in some fashion for our other apps to depend on rather than the docker hub, so is there some way to consume a docker container from a file or some other place other than docker hub?
[2018-03-14 09:29:30] <grofit> A bit like how with NPM you can output your stuff as tar files and just install that tar file rather than using npm repo
[2018-03-14 09:29:33] <mohamedaittaleb> you can work locally
[2018-03-14 09:29:44] <mohamedaittaleb> without pushing your images to docker hub
[2018-03-14 09:30:41] <grofit> but lets say we are all on different PCs
[2018-03-14 09:30:57] <grofit> so its not like we all have the same docker images cached (I appreciate I could clone them and build them manually)
[2018-03-14 09:31:22] <mohamedaittaleb> hum think about nexus locally registry
[2018-03-14 09:31:28] <grofit> but it would feel nicer having some sort of way to resolve containers on our network, like we have a custom npm repo and a custom nuget repo on the network
[2018-03-14 09:31:55] <mohamedaittaleb> you can Create a private nexus docker repo
[2018-03-14 09:32:16] <grofit> ah ok will look into that, but as it was raised by a co-worker here, is there a way to basically distribute a container as a single file which can be used on another computer to spin up an instance of that container?
[2018-03-14 09:32:30] <grofit> i.e amy-container.tar
[2018-03-14 09:33:38] <mohamedaittaleb> Actually a container is an instance of an image if I'm not wrong, so you can share the image with the dockerfile, your colleague can build the same image and run the same container
[2018-03-14 09:33:46] <mohamedaittaleb> based on your Dockerfile.
[2018-03-14 09:34:09] <mohamedaittaleb> my knowledge stops here lol; maybe someone else can help with other solution
[2018-03-14 09:35:02] <grofit> oh right, so I could literally just use the git repo (assuming a dockerfile in root) and it would just work like a container?
[2018-03-14 09:36:12] <grofit> there isnt much info on how its all packaged, its all just magic
[2018-03-14 09:37:21] <grofit> so like with npm it says all the formats it supports [<-LINK->] (I know NPM is a completely different tool to docker, but using it here as an example of a cli telling you how you can run the packages)
[2018-03-14 09:40:53] <grofit> but the docker documentation just seems to show you how to use local docker tags or docker hub tags
[2018-03-14 09:59:31] <mohamedaittaleb> yes you can write your own dockerfile and add it to your git repo so anyway else will just build the image and run the container. I don't know actually why you want to use docker so I can help you
[2018-03-14 10:03:59] <grofit> we use docker for a few things, mainly just wrapping up 3rd party services we want to consume, then just have a docker compose file which ties it all together
[2018-03-14 10:04:09] <grofit> but this is just done on devs pcs for easier environmental setup
[2018-03-14 10:04:30] <grofit> but in this case we are looking at how we can basically move it past the dev stage without relying on docker hub
[2018-03-14 10:05:22] <grofit> so we have an api (or many) which each have their own docker file (setup/expose ports etc), then we have a front end which would be setup with a web server as well, but would compose with the api parts (maybe some other bits)
[2018-03-14 10:05:39] <grofit> so would be nice to have all that configuration somewhere, but not need to consume it from docker hub
[2018-03-14 10:05:55] <grofit> this way we can keep it all private, but not need to worry about persisting it externally and the cost incurred for this
[2018-03-14 10:06:35] <grofit> its like with github, you can host it all on there and pay for it to be private, or setup your own onsite gitlab which gives pretty much same features we care about, but without any cost or external hosting
[2018-03-14 10:12:18] <SISheogorath> without any costJust saying, that's not true, as you usually pay the person that maintains it, but doesn't matter here.share a docker container without using docker hub?A self-hosted docker registry. Here you go: https://docs.docker.com/registry/
[2018-03-14 10:12:31] <SISheogorath> grofit: ^
[2018-03-14 10:13:25] <SISheogorath> And yes, you can also export docker images as file ->docker savebut it's not recommended as it breaks layering.
[2018-03-14 10:20:15] <grofit> sure sure, but they seem to want to keep more stuff on site and not have to pay external parties if possible (i.e custom nuget, npm repos etc), which is why I think they are steering away from hosting on docker hub
[2018-03-14 10:21:29] <SISheogorath> ?
[2018-03-14 10:21:31] <grofit> I will speak to them about costings, as they are hoping to do it on the cheap, hence why they were hoping they could just piggy back off Teamcity, or just host some open source repo or something
[2018-03-14 10:23:03] <grofit> by open source repo I mean like how you can use verdaccio as an open source private npm repo
[2018-03-14 10:23:43] <grofit> Really I am just caught in the cross fire here between a team who likes docker as an approach, but a business who doesnt really want to pay for anything they dont need to
[2018-03-14 10:24:38] <grofit> (and there seems to be some pressure to keep all source/builds etc internal, not external, for right or wrong)
[2018-03-14 10:25:42] <grofit> Anyway its probably all getting out of scope now, my main query I guess was "can I generate a single file and expose that somewhere for somewhere todocker run <my-file>and I guess as you mention there is thedocker savecommand which seems to do this, but by the looks of it you dont run those,  just import them then run
[2018-03-14 10:56:49] <farukhkhan21_twitter> Does CoreOS installation by default enables docker API?
[2018-03-14 11:04:10] <SISheogorath> grofit: yes, you have to import them before you can run. There is no way around this, without using a registry.
[2018-03-14 11:04:47] <SISheogorath> but if you want to run a registry internal, you can usedocker run internalrepo:port/imagename:tag
[2018-03-14 11:05:10] <SISheogorath> farukhkhan21_twitter: That's something you should ask in a CoreOS channel ^^
[2018-03-14 11:08:31] <grofit> Thanks@SISheogorath
[2018-03-14 11:08:47] <SISheogorath> You're welcome
[2018-03-14 11:09:31] <farukhkhan21_twitter> sorry my bad
[2018-03-14 13:29:43] <stherrienaspnet> Hello I'm new to docker and i have a question that will help me to decide if I can got with it or not
[2018-03-14 13:30:46] <stherrienaspnet> I have an electronic device like a Raspberry PI, actually this is an ODROID-C2 running Ubuntu 16.04 on Arm processor
[2018-03-14 13:31:06] <stherrienaspnet> I know there is a Docker CE for Arm I can install
[2018-03-14 13:31:58] <stherrienaspnet> I question my self if I would be able to use any linux container on docker hub?
[2018-03-14 13:35:35] <farukhkhan21_twitter> I think it depends on the ARM version of the board
[2018-03-14 13:36:24] <farukhkhan21_twitter> I think if your ARM processor is ARMv8 it can run almost every image from docker hub@stherrienaspnet
[2018-03-14 13:36:30] <farukhkhan21_twitter> but surely there are some exceptions
[2018-03-14 13:36:43] <stherrienaspnet> i will check now
[2018-03-14 13:37:07] <stherrienaspnet> Amlogic ARM Cortex-A53(ARMv8) 1.5Ghz quad core CPUs
[2018-03-14 13:37:55] <stherrienaspnet> example i will need to install mongodb, so i found a container for that on docker hub, will it work?
[2018-03-14 13:39:15] <stherrienaspnet> i mean the mongo official docker container
[2018-03-14 13:39:46] <farukhkhan21_twitter> I think it will work without any problem. docker engine will handle the underlying stuffs. That's the beauty of docker.
[2018-03-14 13:40:10] <stherrienaspnet> cool
[2018-03-14 13:40:34] <farukhkhan21_twitter> but on ARMv7 or ARMv6 docker engine seems to behave a bit weird. That's why I am not sure about those two. ARMv8 is new and I think docker will work here just fine.
[2018-03-14 13:40:57] <stherrienaspnet> Thanks@farukhkhan21_twitter
[2018-03-14 13:41:53] <stherrienaspnet> Do you have some experience with docker compose?
[2018-03-14 13:42:19] <farukhkhan21_twitter> No problem. Actually I did some research on this because I was planning to do a ARMv8 docker and kubernetes cluster with multiple SBC's as my CI server.
[2018-03-14 13:42:40] <farukhkhan21_twitter> I have some. But it's still very limited. I am also kinda new to docker
[2018-03-14 13:42:55] <farukhkhan21_twitter> what you trying to achieve with docker-compose?
[2018-03-14 13:43:08] <stherrienaspnet> if you want cheap and get performance, look at ODROID-C2
[2018-03-14 13:43:57] <farukhkhan21_twitter> I was about to choose this board but some people reported different overheads on the board's hardware. Not really that is really true or not. I haven't tested one
[2018-03-14 13:44:01] <stherrienaspnet> On my ODROID i need to run mongodb+mosquitto(mqtt broker) + nodejs + angular(web app)
[2018-03-14 13:44:43] <stherrienaspnet> so i wandering how i will setup and run all these container so they can work togetter?
[2018-03-14 13:44:44] <farukhkhan21_twitter> some type of IoT setup? pretty interesting.
[2018-03-14 13:44:50] <stherrienaspnet> Yes
[2018-03-14 13:45:10] <stherrienaspnet> really interesting
[2018-03-14 13:46:51] <stherrienaspnet> do we use docker compose to configure one large container container everything
[2018-03-14 13:47:25] <farukhkhan21_twitter> well, with my current knowledge I don't think I can guide you on this. I am still struggling to setup a LAMP stack for production usage. Some suggestions I can give you is that, proceed step by step. First try run the mongodb successfully. Then try nodejs and carry on like this. If everything works the way you want then just compile the whole thing in docker-compose file for fast deployments.
[2018-03-14 13:47:27] <stherrienaspnet> or we use it to make the link between multiple container running independently?
[2018-03-14 13:48:04] <stherrienaspnet> ok, thanks for your advice
[2018-03-14 13:48:16] <farukhkhan21_twitter> Actually it is a bad practice to use one container for multiple purpose or process. They say, one container one process which makes it more modular and manageable.
[2018-03-14 13:48:34] <farukhkhan21_twitter> docker-compose will help establishing the link and also it will make the deployment easy
[2018-03-14 13:49:50] <campbs> Hi i’m not sure if this is a docker question or a postregresql question but I am using Ory Hydra which is said to be best set up in a container. I want to connect it to a postgres DB i already have running. Am i able to connect these 2 even tho my DB isnt in a container? should I put it in a container ?
[2018-03-14 13:51:53] <farukhkhan21_twitter> not sure about what is the ory hydra. But just curious, where is your postgres DB?
[2018-03-14 13:52:04] <farukhkhan21_twitter> is it in another docker container?
[2018-03-14 13:52:12] <farukhkhan21_twitter> or is it in the host machine?
[2018-03-14 13:52:20] <farukhkhan21_twitter> or totally different server?
[2018-03-14 13:52:34] <campbs> i just have it locally
[2018-03-14 13:52:39] <campbs> it’s not in a container
[2018-03-14 13:54:04] <farukhkhan21_twitter> local as in your pc? or in the docker host machine?
[2018-03-14 13:54:19] <campbs> sorry local on my pc
[2018-03-14 13:55:29] <farukhkhan21_twitter> Well, then there's a lot of things to consider. Do you have a real ip which can be publicly accessible by anyone? and is your postgres allowing wildcard hosts?
[2018-03-14 13:57:20] <campbs> Im not really sure what you mean :( ( sorry im a learner) basically what i need to do is containerise the postgres db that i have now
[2018-03-14 13:58:24] <farukhkhan21_twitter> well then fire up a postgres container using docker with any official image
[2018-03-14 13:58:31] <farukhkhan21_twitter> and then export import your database
[2018-03-14 13:59:42] <farukhkhan21_twitter> When you will have the container running it will automatically connect to the bridge0 default network provided by docker. And see if oy hydra can connect to that bridge0 network to access the database. If oy hyndra is also using default brigde0 it will be able to connect to the postgres container
[2018-03-14 14:00:21] <mohamedaittaleb> hi all, Please Someone has certificat in Docker ?
[2018-03-14 14:00:33] <mohamedaittaleb> or someone who has ideas
[2018-03-14 14:00:39] <mohamedaittaleb> or somethings
[2018-03-14 14:01:20] <campbs> farukhkhan21_twitter: Thanks so much will try that now!
[2018-03-14 14:02:23] <mohamedaittaleb> hi all, Please Someone has certificat in Docker ?
[2018-03-14 14:02:39] <farukhkhan21_twitter> No problem@campbslet me know if it works.
[2018-03-14 17:14:28] <jdickey> Asking again, just in case the first time got buried in the flow... [<-CODE->]  [<-CODE->] and I'd love to be able to automate this in a Ruby script. Thanks!
[2018-03-14 18:38:39] <campbs> hey im using docker for mac and im trying to get a vue js container to be able to access on local host i have binded the ports and done everything that is supposed to be done but when i go to local host it says localhost didnt send any data ?  anyone had this problem ? have looked everywhere?
[2018-03-14 22:37:48] <Leeaandrob> hello :)
[2018-03-14 22:38:04] <Leeaandrob> i don't if is it possible... but let me ask for the expert on docker :)
[2018-03-14 22:38:27] <Leeaandrob> is it possible to avoid always that i am doingdocker-compose up --buildthe docker donpm install?
[2018-03-15 11:53:45] <Shine-neko> Hello  :)
[2018-03-15 11:56:38] <Shine-neko> I need help. I have a container (nginx official image) that produces no logs
[2018-03-15 13:23:58] <loicdescotte> Hi all
[2018-03-15 13:24:59] <loicdescotte> I have a "cluster" of docker images on a single physical machine
[2018-03-15 13:25:38] <loicdescotte> They are running inside a docker network
[2018-03-15 13:25:57] <loicdescotte> is it possible to make this work on several physical machines?
[2018-03-15 13:26:35] <loicdescotte> i.e. defining a docker network through several physical machine so all docker images can continue to communicate seamlessly?
[2018-03-15 13:29:05] <SISheogorath> loicdescotte: check docker swarm :)
[2018-03-15 13:29:15] <loicdescotte> thanks!
[2018-03-15 13:29:31] <loicdescotte> I was reading this [<-LINK->] 
[2018-03-15 13:29:52] <loicdescotte> I was not sure it was the right direction, so thanks :)
[2018-03-15 13:32:40] <SISheogorath> You're welcome :)
[2018-03-15 13:45:57] <Leeaandrob> SISheogorath: hello how are you?
[2018-03-15 13:46:24] <Leeaandrob> may i ask something for you? I am searching but I don't find anywhere how I can do this :(
[2018-03-15 13:46:33] <farukhkhan21_twitter> SISheogorath: does the official httpd docker image have mod_rewrite enabled by default?
[2018-03-15 13:48:52] <Leeaandrob> I am trying to find a better way to see output logs from applications running inside docker containers... do you have an idea?
[2018-03-15 13:49:14] <Leeaandrob>  [<-CODE->] 
[2018-03-15 13:49:29] <Leeaandrob> I have a docker-compose.yml like this
[2018-03-15 14:16:39] <SISheogorath> Leeaandrob: First hint: don't mount your tmpfs this exposes a lot of sensitive data to your container. Use this instead: [<-LINK->] 
[2018-03-15 14:16:57] <SISheogorath> or use any other directory
[2018-03-15 14:17:27] <SISheogorath> also just push all logs to stdout and stderr. These will be handle by docker
[2018-03-15 14:17:44] <Leeaandrob> do you mean in myvolumes?
[2018-03-15 14:18:09] <Leeaandrob>  [<-CODE->] 
[2018-03-15 14:18:20] <SISheogorath> yes
[2018-03-15 14:19:05] <Leeaandrob> is it can be better?
[2018-03-15 14:19:20] <SISheogorath> I already linked the docs
[2018-03-15 14:19:32] <Leeaandrob> I am reading about
[2018-03-15 14:19:33] <SISheogorath> farukhkhan21_twitter: Not really sure, but I guess so
[2018-03-15 14:19:47] <Leeaandrob> so I can to do like this:
[2018-03-15 14:20:42] <Leeaandrob>  [<-CODE->] 
[2018-03-15 14:20:49] <Leeaandrob> SISheogorath: ?
[2018-03-15 14:21:16] <SISheogorath> isn't the example clear?
[2018-03-15 14:21:37] <Leeaandrob> nope :(
[2018-03-15 14:21:58] <Leeaandrob> I need to mount a tempory directory and maps for it?
[2018-03-15 14:22:27] <SISheogorath>  [<-CODE->] 
[2018-03-15 14:22:59] <Leeaandrob> but i need to share the /tmp between the containers 
[2018-03-15 14:23:21] <Leeaandrob> because db and portal are seeing the /tmp/file.json made by parity
[2018-03-15 14:26:14] <Leeaandrob> when i set this on my docker-compose.yml all containers likend will see for the same /tmp?
[2018-03-15 14:32:39] <Leeaandrob> anyway thanks@SISheogorath
[2018-03-15 14:34:28] <SISheogorath> Leeaandrob: no, they won't see it. but if you really need to share a tmp dir between your containers, use something like /tmp/<somethingrandom> because root in your container is allowed to read EVERYTHING inside your container directories (by default) and this way can read all data in /tmp which are may sensitive
[2018-03-15 14:35:58] <Leeaandrob> hhhhhaaaa I'm seeing your point now.. you have absolutely right about this.. I will change to pointing a specifying folder thanks so much@SISheogorath
[2018-03-15 15:52:41] <SISheogorath> You're welcome
[2018-03-15 18:01:00] <tusharbudhe0302> Hi Guys,I am getting below exception while running container:require('update-notifier')( package ).notify() ^ syntaxerror unexpected tokenPlease check my docker-compose.yml file
[2018-03-15 18:01:06] <tusharbudhe0302> version: "3.1"services:      nginx:          container_name: dokernode_nginx          image: dockernode_nginx          build:            context: .            dockerfile: .docker/nginx.dockerfile          links: [<-CODE->] networks:    dockernode-network:      driver: bridge
[2018-03-15 18:26:15] <tusharbudhe0302> Hello Guys,Exception : host not found in upstream "node1:8080" in /etc/nginx/nginx.conf:9I am getting above exception on docker-compose up. I did share you a git hub link to access my code.It\'s very simple code. I would appreciate your help.https://github.com/tusharbudhe0302/dockernode
[2018-03-15 18:42:43] <SISheogorath> First of all, don't use links
[2018-03-15 18:43:29] <SISheogorath> they are deprecated since more than a year now and iirc ignored anyways in docker-compose version 3+
[2018-03-15 18:44:31] <farukhkhan21_twitter>  [<-CODE->] 
[2018-03-15 18:44:48] <farukhkhan21_twitter> does these docker-compose tags still work in version 3 yml files?
[2018-03-15 18:45:07] <SISheogorath> farukhkhan21_twitter: iirc they only work in version 3 or higher
[2018-03-15 18:45:26] <farukhkhan21_twitter> iirc mean?
[2018-03-15 18:45:56] <SISheogorath> iirc -> if I recall correct
[2018-03-15 18:46:09] <farukhkhan21_twitter> ow xD
[2018-03-15 18:46:34] <SISheogorath> Here you go: [<-LINK->] 
[2018-03-15 18:47:04] <farukhkhan21_twitter> SISheogorath: what do you think? should I use these limits in a production php app? Or should I let the app take whatever resources it wants from the host?
[2018-03-15 18:48:04] <SISheogorath> farukhkhan21_twitter: depends on your setup, if you run one VM per service, why not? If you run multiple services per VM you may want to be able to control it a bit
[2018-03-15 18:48:50] <SISheogorath> tusharbudhe0302: also what do you publish the node ports for? There is no need to do this.
[2018-03-15 18:49:37] <farukhkhan21_twitter> SISheogorath: running one processes per container. apache in one, php-fpm in one and mysql in one. total 3 containers.
[2018-03-15 18:49:41] <SISheogorath> tusharbudhe0302: last but not least, please run inspect on your docker network and/or your node containers to see ifnode1is even  a network alias
[2018-03-15 18:50:36] <SISheogorath> farukhkhan21_twitter: yes, that's how it should be, but I was actually talking about running one VM per container. But seems to be not the case, as you use docker swarm and why should you want to do this then? So yes, use ressource limits
[2018-03-15 18:51:05] <SISheogorath> if you want to prevent overcommitment, then you may even want to set reservations = limits
[2018-03-15 18:51:23] <SISheogorath> But that highly depends on what you are about to sell
[2018-03-15 18:51:47] <farukhkhan21_twitter> I am not using docker swarm. Just a coreos baremetal and trying to host a cricket news codeigniter blog for production.
[2018-03-15 18:53:59] <farukhkhan21_twitter> and seems like my php script is having some good amount of memory leak. Bad code by one of my colleague. that's why was thinking to restrict the resources in every container so that the host remains safe
[2018-03-15 19:08:44] <adrice727> I'm having an issue running ansbtapp in a docker container.  The app starts running, but then crashes after serving a single request.  The container remains running.  I've built my image a few different ways,sbt-pack,sbt-assembly,sbt-native-packager, but there's no difference.  Does anyone have any idea what might be going on?
[2018-03-15 19:14:42] <farukhkhan21_twitter>  [<-CODE->] Can I use these API json calls out of the box? or need to enable docker api manually? And how to use these api calls from outside the host from another desktop application?
[2018-03-16 00:15:25] <tusharbudhe0302> SISheogorath: Thanks. I have fix it. I will share you guys the updated code
[2018-03-16 08:12:21] <SISheogorath> farukhkhan21_twitter: locally you can use them out of the box, if you want to do it remote, you have to enable remote access to the docker socket. See: [<-LINK->] 
[2018-03-16 08:40:07] <loicdescotte> Hi,Just a small question, if I need to define a docker network through several physical machines, is it easier to do it with Swarm or Kubernetes?
[2018-03-16 08:46:37] <SISheogorath> loicdescotte: My personal suggestion is: For small setups (less than 50 machines) go for swarm. For middle size setups (50-500) machines, use either K8s or swarm. Everything bigger I suggest to use K8s only
[2018-03-16 08:46:59] <loicdescotte> Ok thanks!
[2018-03-16 08:47:30] <loicdescotte> It's a 3 physical machines with 20 docker images setup
[2018-03-16 08:47:42] <loicdescotte> so I'll go with swarm :)
[2018-03-16 10:10:57] <Leeaandrob> hello@SISheogorath
[2018-03-16 10:11:01] <Leeaandrob> how are you?
[2018-03-16 10:23:09] <loicdescotte> I need to run docker images on a machine that has no internet connection
[2018-03-16 10:23:40] <loicdescotte> is there a way to build the images (with the pull part) from another machine and then to copy the images?
[2018-03-16 10:25:51] <loicdescotte> small twist : the only other machine I have with internet connection is a windows one (but I can install virtualbox on it if needed)
[2018-03-16 10:31:49] <loicdescotte> I will go with docker save
[2018-03-16 13:09:35] <farukhkhan21_twitter> Thanks@SISheogorathreally helpful doc you linked.
[2018-03-16 17:44:39] <tusharbudhe0302> environment:REDIS_POST: 6379REDIS_HOST: redisIt\'s coming as undefiend rocess.env.REDIS_PORT,This is docker-compose.yml file.version: "3.1"services:        nginx:            container_name: dokernode_nginx            image: dockernode_nginx            build:                context: .                dockerfile: .docker/nginx.dockerfile            links: [<-CODE->] networks:    dockernode-network:      driver: bridge
[2018-03-16 17:45:30] <tusharbudhe0302> What should I do to get env variable with out running .sh file. Is there a way to do it ?
[2018-03-16 17:45:39] <tusharbudhe0302> Please help me
[2018-03-16 21:15:35] <adrice727> tusharbudhe0302: Any luck?  I'm having a similar issue with redis.
[2018-03-16 22:46:33] <Francososa> I am having trouble installing docker-ce. I tried installing using the repository and manually with the .deb file, but the installation never finishes
[2018-03-16 23:36:05] <MattLongCode> loicdescotte: Did you manage to solve this, sounds like an interesting problem!
[2018-03-17 00:27:00] <tusharbudhe0302> adrice727: . No man still looking. I think we should have to run .sh file to get it. Or I have to look How I can set up this on env. variable of containers.!
[2018-03-17 20:01:10] <SISheogorath> Francososa: any error messages?
[2018-03-17 20:02:39] <SISheogorath> tusharbudhe0302: if the software inside doesn't allow configuration by environment variables, no.
[2018-03-17 20:02:56] <SISheogorath> at least when it's about inside the container
[2018-03-17 23:12:03] <tusharbudhe0302> ok thanks@SISheogorath
[2018-03-18 08:52:55] <geekyharshal> Hi everyone
[2018-03-18 08:54:22] <geekyharshal> I'm new to docker, please some help in getting started.
[2018-03-18 08:55:10] <johannwagner> Just ask your question.
[2018-03-18 09:01:37] <geekyharshal> what is docker ?
[2018-03-18 09:02:51] <farukhkhan21_twitter> try some googling mate. [<-LINK->] 
[2018-03-18 09:03:04] <johannwagner> You can just google this question. It is a container engine, which allows you to deploy applications in their own separate environment without sideeffects to your current system.
[2018-03-18 09:03:22] <johannwagner> I am not sure, if I picked the correct words.
[2018-03-18 09:04:04] <geekyharshal> ok, is community version enough for an individual developer ?
[2018-03-18 09:04:56] <farukhkhan21_twitter> even enough for production in many cases
[2018-03-18 09:06:37] <johannwagner> We use the Community Version for production, yes.
[2018-03-18 09:42:31] <geekyharshal> thanks, also, Which OS will be best suited for docker? Ubuntu or Windows ?
[2018-03-18 09:43:35] <johannwagner> It works for development on all OS.
[2018-03-18 09:43:44] <johannwagner> Production should be a Linux distro.
[2018-03-18 09:45:49] <geekyharshal> I can see that it works on all OS. But, I wanna know your experience. Which OS lets it run more efficiently? I work on ubuntu and windows and confused which OS to start docker with.
[2018-03-18 09:46:55] <johannwagner> I don’t think, there is a performance difference, which you can experience.
[2018-03-18 09:48:08] <geekyharshal> ok, cool... thanks :)
[2018-03-18 13:01:53] <deepio> Hi gang, new to this room. I’m having some issues spinning up gunicorn inside of docker when I’d like the project to be loaded up as a volume in the compose file. Also, I think my issue is escaping special characters but I can’t wrap my head around why my env_file doesn’t work on “example” the SECRET_KEY in Django?
[2018-03-18 13:04:46] <deepio> Ideally I’d like to use the latest versions of all these things. Specifically I’m starting from the latest alpine image.
[2018-03-18 13:06:39] <deepio> Once this works, I’d like to spin it all up (and nginx) with supervisord, is that ok?
[2018-03-18 13:20:19] <badape-net> Hello, i am trying to build a very basic Dockerfile that copies in some static content, however i am using windows
[2018-03-18 13:20:52] <badape-net> docker build -t abc . just seems to hang
[2018-03-18 13:26:19] <deepio> badape-net: can you post your dockerfile somewhere?
[2018-03-18 13:26:38] <deepio> First place I’d look is any commands or entry points
[2018-03-18 13:27:01] <badape-net> FROM nginx COPY ./dist /usr/share/nginx/html
[2018-03-18 13:34:27] <badape-net> oh i just didn't wait long enough
[2018-03-18 13:34:51] <badape-net> wow i had to wait 10 minutes
[2018-03-18 15:30:44] <Leeaandrob> hello everyone
[2018-03-18 15:31:00] <Leeaandrob> I am trying to set a ip static and access on chrome but i am receiving connection refused :(
[2018-03-18 15:42:21] <johannwagner> Did you expose the ports correctly ?
[2018-03-18 15:42:31] <Leeaandrob> yes
[2018-03-18 15:42:40] <Leeaandrob> but I don't to use the localhost from host machine but the ip of docker container
[2018-03-18 15:42:58] <Leeaandrob> I am trying to do the same usingnetwork_mode:hostbut doesn't works too!
[2018-03-18 15:52:13] <johannwagner> Did you try the ip from the host machine?
[2018-03-18 15:54:28] <Leeaandrob> yes i am trying now :)
[2018-03-18 15:54:34] <Leeaandrob> it's works using network_mode: host :D :D
[2018-03-18 15:57:06] <Leeaandrob> do you know is it possible set ip static onnetwork_mode: "bridge"@johannwagner?
[2018-03-18 16:09:10] <johannwagner> Leeaandrob: I think, this Stack Overflow link should help.
[2018-03-18 16:09:10] <johannwagner>  [<-LINK->] 
[2018-03-18 16:09:25] <johannwagner> I couldn't explain it better.
[2018-03-18 16:10:40] <Leeaandrob> but I think that this away I couldn't access from chrome using my host local ip
[2018-03-18 16:11:53] <johannwagner> Yeah, you have to create a redirect. You can do this with iptables, but I dunno how. iptables is black magic.
[2018-03-18 16:17:22] <Leeaandrob> yeah ip tables would be a hammer of thor!
[2018-03-18 16:17:39] <johannwagner> I dunno, why you would do this.
[2018-03-18 16:17:59] <Leeaandrob> lonnnngg history hehe
[2018-03-18 16:18:17] <Leeaandrob> I will work with my local host ip thanks@johannwagnerby your time!
[2018-03-18 16:18:38] <johannwagner> ssh -L 5000:localhost:4999 user@machinewould link the port 4999 from the machine, you ssh into, to your local port 5000.
[2018-03-18 16:18:43] <johannwagner> Maybe this helps.
[2018-03-18 16:19:00] <Leeaandrob> ssh tunnel
[2018-03-18 16:19:03] <johannwagner> Yep
[2018-03-18 16:19:03] <Leeaandrob> nice!!
[2018-03-18 16:19:22] <johannwagner> If you only use this for development purposes, this could work :)
[2018-03-18 16:42:27] <deepio> “Still waiting for any and all assistance with my gunicorn/docker issue”
[2018-03-19 10:41:14] <CarlosAmaral> hey bros
[2018-03-19 10:41:27] <CarlosAmaral> "Secure multi-tenancy with node-based isolation", can anyone tell me what this is?
[2018-03-19 10:45:08] <CarlosAmaral> for docker EE
[2018-03-19 12:32:56] <farukhkhan21_twitter> is it possible to connect to mysql port 3306 from another container without exposing the 3306 port from the mysql container docker file? exposing is exposing the port to host for outside connection or also for docker bridge network I need to expose certain port?
[2018-03-19 13:07:36] <deepio> Farukh: 1) why don’t you want to expose the port? 2) I think you can if you set it as a network?
[2018-03-19 13:09:14] <farukhkhan21_twitter> I have a bridge network setup up on all my containers with static ip. I don't want to expose the mysql port to outside world through the host. I only want the httpd container to be able to access the mysql container to access databases.
[2018-03-19 13:12:26] <deepio> Farukh: I’m not sure, but if you find out I’d like to know too
[2018-03-19 13:13:33] <farukhkhan21_twitter> alright@deepio
[2018-03-19 13:14:03] <Nario560> farukhkhan21_twitter: what about linking?
[2018-03-19 13:14:36] <farukhkhan21_twitter> Nario560: not sure about the linking tag and what it actually does.
[2018-03-19 13:14:58] <Nario560> links 2 container without exposing ports. To make them communicate with each other
[2018-03-19 13:15:05] <farukhkhan21_twitter> by default when a container is spun up they all connect to default bridge0 network and gets an ip address assigned to them
[2018-03-19 13:15:34] <farukhkhan21_twitter> docker documentation have the links tag description there?
[2018-03-19 13:15:50] <Nario560>  [<-LINK->] 
[2018-03-19 13:15:56] <Nario560> it's legacy but still works
[2018-03-19 13:16:16] <farukhkhan21_twitter> Warning: The --link flag is a legacy feature of Docker. It may eventually be removed.
[2018-03-19 13:16:25] <farukhkhan21_twitter> but eventually it will get turned off
[2018-03-19 13:16:31] <farukhkhan21_twitter> so no point using this I guess
[2018-03-19 13:17:00] <farukhkhan21_twitter> and I think they have already deprecated the tag on version 3 yml file
[2018-03-19 13:21:07] <Nario560> generally
[2018-03-19 13:21:10] <Nario560> you can communicate
[2018-03-19 13:21:18] <Nario560> via docker network
[2018-03-19 13:21:26] <Nario560> just get internal ip
[2018-03-19 13:21:53] <Nario560> try running docker network inspect bridge
[2018-03-19 13:22:03] <Nario560> or whatever your network is called
[2018-03-19 13:22:38] <Nario560> you'll get container ips. Then you can try to attach to container & check connection to necessary ip manually
[2018-03-19 13:22:45] <farukhkhan21_twitter> but if I dont use the expose command on the mysql docker file will the port 3006 still be accessible from another container under the same bridge network?
[2018-03-19 13:26:30] <Nario560> it should be available
[2018-03-19 13:26:35] <Nario560> you can try it
[2018-03-19 13:28:43] <farukhkhan21_twitter> yeah I will be trying it now
[2018-03-19 14:29:33] <SISheogorath> yes, all ports of containers are accessible when they are on the same network
[2018-03-19 14:29:43] <SISheogorath> exposing is only needed for external services
[2018-03-19 14:31:00] <farukhkhan21_twitter> thanks@SISheogorathgood to know
[2018-03-19 14:31:40] <SISheogorath> and don't uselinksbecause you expose all environment variables of container A to container B which is from a security perspective pretty ugly
[2018-03-19 14:32:07] <farukhkhan21_twitter> that's why being deprecated I guess
[2018-03-19 14:34:43] <SISheogorath> that's one of many reasons, yes
[2018-03-19 17:25:02] <farukhkhan21_twitter> deepio: here is your answer   > yes, all ports of containers are accessible when they are on the same network
[2018-03-20 00:15:43] <deepio> farukh: cool man! Thanks. Glad my guess was on track. I’m gonna need this soon enough
[2018-03-20 13:43:08] <loicdescotte> Hi ,I have a network issue with docker, I can't nderstand what is happening
[2018-03-20 13:43:28] <loicdescotte> I have a developpement machine , I 've made a small cluster of docker hadoop images
[2018-03-20 13:43:49] <loicdescotte> I've created a network, and the images can communicate through several ports
[2018-03-20 13:43:53] <loicdescotte> I's working perfectly
[2018-03-20 13:44:07] <loicdescotte> I've taken the same images, put them on another server
[2018-03-20 13:44:21] <loicdescotte> and there are communication issues between the images
[2018-03-20 13:44:31] <loicdescotte> I have  the same docker CE version on both machines
[2018-03-20 13:44:47] <loicdescotte> I have disabled selinux, firewalld, iptables...
[2018-03-20 13:45:35] <loicdescotte> Example of error : [<-CODE->] 
[2018-03-20 13:54:11] <loicdescotte> do you know what kind of configuration issue it can be?
[2018-03-20 13:55:22] <farukhkhan21_twitter> does anyone know the difference between rancheros and coreos and racherserver?
[2018-03-20 13:56:16] <loicdescotte> oups, no the Ip are NOT OK
[2018-03-20 13:56:35] <loicdescotte> the connection is denied with 172.18.0.1
[2018-03-20 13:56:58] <loicdescotte> and if I look at the Ip addresses : [<-CODE->] 
[2018-03-20 13:57:24] <loicdescotte> but it's all dynamically generated, I don't know why it tries to connect on 172.18.0.1 ...
[2018-03-20 14:02:29] <loicdescotte> all ips in confugration files are defined as 0.0.0.0
[2018-03-20 14:22:44] <loicdescotte> or is 172.18.0.1 used by docker itself for orchestration / bridge?
[2018-03-20 14:23:29] <SISheogorath> farukhkhan21_twitter: RancherOS and CoreOS, as the name indicates, are operating systems. They are optimized for container setups but I wouldn't use them at small scale. Rancher server is a management and orchestration solution for Docker. A bit like Portainer but integrated with an own orchestration solution called cattle as well as Swarm and K8s. Don't know if you want to use it… That's up to you
[2018-03-20 14:30:01] <farukhkhan21_twitter> So, how the rancheros and coreos basically differs? I know that rancher os have a system docker for system services. But in terms of lightweight, security and stability which one you think wins? rancheros or coreos?
[2018-03-20 14:30:12] <farukhkhan21_twitter> and the rancher server I can compare to K8s right?
[2018-03-20 14:56:48] <SISheogorath> I would say CoreOS, when you want to do it correct, is a bit more difficult to setup. But afterwards it does everything automated and you have almost no problems.RancherOS is more beginner friendly. I'm not complete aware of their update process so can't say much about stability, but CoreOS coordinates with other cluster member (if configured correctly) so never all go down at the same time.Comparing Rancher server with K8s is like comparing a Multi-tool with a good knife. Rancher server can actually setup K8s for you. As well as it can setup Swarm for you. But these setups are maybe oversimplified which make them cause a lot of problems when you really want to scale (a few hundred nodes). And when you run into problems, you have to reverse engineer what the Rancher guys did. Cattle (rancher's own orchestrator) is fine to use but less feature rich than K8s
[2018-03-20 14:56:55] <SISheogorath> farukhkhan21_twitter: ^
[2018-03-20 14:59:07] <farukhkhan21_twitter> understood. Thanks a lot@SISheogorathfor the info
[2018-03-20 15:17:33] <farukhkhan21_twitter> after following this doc, still cannot make the docker remote api work. [<-LINK->] 
[2018-03-20 15:18:23] <farukhkhan21_twitter>  [<-CODE->] 
[2018-03-20 15:50:41] <farukhkhan21_twitter> how to solve this?
[2018-03-21 03:01:16] <comeUpWithItLater>  [<-LINK->] 
[2018-03-21 03:01:23] <comeUpWithItLater> why ?
[2018-03-21 03:07:41] <Francososa> docker-ce installation gets stuck at this step: [<-CODE->] 
[2018-03-21 03:07:53] <Francososa> I don't get any error messages
[2018-03-21 03:08:32] <Francososa> I ransudo apt-get install docker-ceafter following the previous steps in the installation instructions page
[2018-03-21 10:16:49] <narendramannam> Francososa: I think even I faced some error while installing docker-ce on Centos, i just ran "yum install docker" and it was successful, not sure why though
[2018-03-21 14:58:20] <Francososa> narendramannam: So I should try installingdockerinstead ofdocker-ce?
[2018-03-21 15:00:09] <deepio> Francososa: yes
[2018-03-21 15:03:59] <CiprianBeldean> HY, I am trying to connect to my postgres docker container using DBeaver and I am receiving the following error.FATAL: password authentication failed for user "redmine"FATAL: password authentication failed for user "redmine"FATAL: password authentication failed for user "redmine"docker run -d --name some-postgres -e POSTGRES_PASSWORD=secret -e POSTGRES_USER=redmine postgres
[2018-03-21 15:04:07] <IsuraNimalasri> Hey francisco, try this
[2018-03-21 15:04:17] <IsuraNimalasri>  [<-LINK->] 
[2018-03-21 19:13:40] <jmunson> I have a multistage build file that currently produces one final image containing 3 different binaries from  the same sourcecode. Is it possible to instead create 3 different final images, reusing the earlier stage?
[2018-03-21 19:21:53] <SISheogorath> yes
[2018-03-21 19:22:32] <SISheogorath> iirc you can use the names you set withFROM xy:tag AS foo
[2018-03-21 19:23:05] <jmunson> Do you just keep them in separate dockerfiles and ensure the right one is built first with some kind of build script?
[2018-03-21 19:31:37] <Francososa> IsuraNimalasri: thanks I did, but same problem. The installation gets stuck in the same step as before. I get no errors or other output so I don't know how to solve it.
[2018-03-21 19:56:10] <SISheogorath> jmunson: yes, you can do that, that's an easy and maybe also the only way, I guessed that you can simply reuse earlier build stages as I mentioned, by real multi-staged builds, but I'm actually not sure
[2018-03-21 20:24:08] <farukhkhan21_twitter> Hey@SISheogorathcan you please check and tell me if I am doing anything wrong with this docker-compose file.
[2018-03-21 20:24:24] <farukhkhan21_twitter>  [<-CODE->] 
[2018-03-21 20:37:54] <SISheogorath> farukhkhan21_twitter: ._. To be honest: First of all I'm not a parser… Then   again I don't know your setup and I don't know your goal and neither do I know any of your images… I can't tell you anything about this compose file, besides it looks like a compose file and that it wastes a lot of space with banners
[2018-03-22 03:35:23] <libp> hi，大家好
[2018-03-22 05:25:57] <prashant7july> Hi all, as per below command, after execution working fine, but I don't understand how to deploy on the other local development box or even in production? [<-CODE->] 
[2018-03-22 09:03:21] <loicdescotte> Hi all,
[2018-03-22 09:03:32] <loicdescotte> I have a small question about docker services and networks
[2018-03-22 09:03:47] <loicdescotte> I have a docker compose file like this
[2018-03-22 09:03:58] <loicdescotte>  [<-CODE->] 
[2018-03-22 09:04:31] <loicdescotte> I've done this :docker network create --driver overlay hadoop
[2018-03-22 09:05:01] <loicdescotte> When I run my docker compose file with swarm :docker stack deploy --compose-file namenode/docker-compose-3.yml namenode
[2018-03-22 09:05:48] <loicdescotte> I have this error : [<-CODE->] 
[2018-03-22 09:06:47] <loicdescotte> But when I rundocker network lsI can see it : [<-CODE->] 
[2018-03-22 09:06:57] <loicdescotte> Is it normal? How could I fix this?
[2018-03-22 09:06:59] <loicdescotte> Thanks :)
[2018-03-22 09:07:45] <MaximZavitaev> loicdescotte: try configure network creating in composer file
[2018-03-22 09:09:48] <loicdescotte> MaximZavitaev: do you have an example?
[2018-03-22 09:12:08] <loicdescotte> I have this in my compose file : [<-CODE->] 
[2018-03-22 09:15:42] <MaximZavitaev>  [<-CODE->] 
[2018-03-22 09:28:39] <loicdescotte> It fails with a new error :)
[2018-03-22 09:28:48] <loicdescotte> services.namenode.networks.hadoop Additional property driver is not allowed
[2018-03-22 09:29:45] <MaximZavitaev> loicdescotte: networkssetting not for services!
[2018-03-22 09:30:25] <MaximZavitaev>  [<-CODE->] 
[2018-03-22 09:31:33] <MaximZavitaev> for service [<-CODE->] leave
[2018-03-22 09:32:20] <MaximZavitaev>  [<-CODE->] 
[2018-03-22 09:32:22] <MaximZavitaev> try
[2018-03-22 09:32:25] <loicdescotte> Ok I understand!
[2018-03-22 09:32:28] <loicdescotte> thanks :)
[2018-03-22 09:33:03] <loicdescotte> Seems better, thanks a lot@MaximZavitaev!
[2018-03-22 09:34:30] <MaximZavitaev> loicdescotte: You're welcome
[2018-03-22 10:02:18] <loicdescotte> I don't understand something about ports redirection though
[2018-03-22 10:02:39] <loicdescotte>  [<-CODE->] 
[2018-03-22 10:02:54] <loicdescotte> we can see that hadoop_namenode      has 2 ports redirected
[2018-03-22 10:03:06] <loicdescotte> But if a do a PS :
[2018-03-22 10:03:20] <loicdescotte>  [<-CODE->] 
[2018-03-22 10:03:34] <loicdescotte> No port seems to be open
[2018-03-22 10:03:51] <loicdescotte> If I go on SRV-HADOOP-2  (physical machine) :
[2018-03-22 10:04:03] <loicdescotte>  [<-CODE->] 
[2018-03-22 10:04:15] <loicdescotte> no port open indeed :(
[2018-03-22 10:05:32] <loicdescotte> It may be related, my hadoop_datanode  service is not able to connect to hadoop_namenode even if they are in the same network (and defined in the same docker-compose.yml file)
[2018-03-22 10:06:23] <loicdescotte>  [<-CODE->] 
[2018-03-22 10:15:06] <loicdescotte> ooops just seen "This chat is intended for contributors new to the Docker project or new to open source. For user help, please goto #docker on freenode"
[2018-03-22 10:15:14] <loicdescotte> sorry...
[2018-03-22 14:24:55] <r2d2leboss> Hello. An idea of what could cause random GCC or Clang segmentation fault in various computers / Docker images ?
[2018-03-22 15:51:34] <Leeaandrob> hello everyone
[2018-03-22 15:51:47] <Leeaandrob> is it possible docker-compose exec ifconfig the host to get the local ip?
[2018-03-22 17:50:26] <babaorum> I don't think it rely on it, or it can switch to something else. I use docker-compose without ifconfig install
[2018-03-22 17:51:14] <babaorum> Or maybe it depends on your usage ...
[2018-03-22 19:37:44] <panosru> could anyone point me on a good guide on how to use xdebug with phpstorm and docker? I haven't used docker before, and I have hard time on getting xdebug to work with docker
[2018-03-22 19:39:10] <babaorum> panosru: I just configured it a few days ago.
[2018-03-22 19:39:27] <babaorum> Let me a minute to find you what you need
[2018-03-22 19:40:01] <panosru> babaorum: thanks mate!
[2018-03-22 19:40:46] <panosru> I try to debug that repository [<-LINK->] and so far my attempts wasn't successful :/
[2018-03-22 20:11:03] <babaorum> panosru: I sent you a few private messages. I hope you received it, tell me if you need anything else.
[2018-03-22 20:29:16] <tusharbudhe0302> Hi Guys,Below is my docker-compose.yml file node-server:        container_name: powerbi-server        image: powerbi-server        environment: [<-CODE->] This is my docker file :Expose portEXPOSE  ${NODE_PORT}I am sure I am doing something wring but I want to use env from yml file while building image and containers too. Please help me with corrections
[2018-03-22 21:47:32] <killerspaz> Hey guys, I have 2 docker-compose configs that i need ONE container from each config to communicate on a network... I have the following definition in BOTH configs (more on that later): [<-CODE->]  [<-CODE->]  [<-CODE->] So... the question? Well, on initial launch, this works flawlessly... Both compose connect to the network fine. The problem is on subsequent runs, I then get errors telling me the network name is ambiguous.Am I doing this just completely wrong, or is this a bug?
[2018-03-22 21:49:10] <killerspaz> tusharbudhe0302: you want to look at build args, but alas you cannot use your.envfile for that, they must be either set in the env for real or used on theENV_VAR=blah docker-compose buildline
[2018-03-22 21:55:14] <killerspaz> hmmmm i think i may have found my problem.... I might be starting the second compose before the first network is even fully realized...
[2018-03-23 00:33:45] <chrisgbaker> hello! super noob question for y'all:Currently writing a Dockerfile for a dotnetcore SPA app. I can successfully copy my files to the image, build the dotnet project, cd to the folder containing the react app, run my webpack build, and (i assume) create the dist folder. However, I cannot figure out how to copy the /dist folder to the root of the image, so [<-LINK->] can be served by Kestrel.
[2018-03-23 00:34:58] <chrisgbaker>  [<-CODE->] 
[2018-03-23 00:38:04] <chrisgbaker> COPY failed: stat /var/lib/docker/tmp/docker-builder327684633/ui/dist: no such file or directoryis the specific error
[2018-03-23 10:05:59] <Acidfabric> chrisgbaker: try COPY ./ui/dist ../../
[2018-03-23 10:22:32] <SISheogorath> chrisgbaker: use thecpcommand in aRUNstatement.COPYis only used between Host and image or between images
[2018-03-23 16:31:04] <metamet> Hey all. Trying to figure out a best practice here. Wanting to use S3 to serve up some images on our containers. I've seen a couple routes to go, but it's not clear which is best practice. 1) Use S3FS on the host, then mount the path as a volume on the container, or 2) use S3FS directly on the container, mounting it there. Anyone have experience here?
[2018-03-23 20:33:39] <arnabkd> Edit: wrong gitter
[2018-03-24 10:35:58] <wangshihuyue> [root@iZ4sxlly852vwpZ~]# docker network rm multihostError response from daemon: network multihost id 75928679971b45b65eefbcb8023d89dc1a23284890bcfc3d778cfb65741f3798 has active endpoints[root@iZ4sxlly852vwpZ~]# docker network inspect multihost[{"Name": "multihost","Id": "75928679971b45b65eefbcb8023d89dc1a23284890bcfc3d778cfb65741f3798","Created": "2018-03-23T21:07:01.568894965+08:00","Scope": "global","Driver": "overlay","EnableIPv6": false,"IPAM": {"Driver": "default","Options": {},"Config": [{"Subnet": "172.28.0.1/21","IPRange": "172.28.0.0/21","Gateway": "172.28.0.1"}]},"Internal": false,"Attachable": false,"Ingress": false,"ConfigFrom": {"Network": ""},"ConfigOnly": false,"Containers": {"ep-c7b25a596e9c85ac6b0865ae3937d7337a6d5391d7e38b75c49cdb6a46afef7c": {"Name": "registry","EndpointID": "c7b25a596e9c85ac6b0865ae3937d7337a6d5391d7e38b75c49cdb6a46afef7c","MacAddress": "","IPv4Address": "172.28.0.11/21","IPv6Address": ""}},"Options": {},"Labels": {}}][root@iZ4sxlly852vwpZ~]# docker network disconnect multihost  registryError response from daemon: No such container: registry
[2018-03-24 10:36:35] <wangshihuyue> Excuse me to your friends, what's the reason for this?
[2018-03-24 10:49:52] <wangshihuyue> find the season ,docker network disconnect -f {network-name} {endpoint-name}
[2018-03-26 07:00:02] <eugenepark1> how do you guys version control Dockerfiles and associating them with docker image version/tag?  and conduct some CI to verify that image built from the latest Dockerfile changes is sane
[2018-03-26 07:12:07] <jdickey> Version control is straightforward for us; we include the Dockerfile(s) as part of the source code repository in Git, and use Git tags to match aversionLABEL in the Dockerfile. E.g., what I'm working on now will be tagged, pushed, and deployed this afternoon asv0.11.1. That's distinct from the tags used by e.g. hub.docker.com, which are entirely separate
[2018-03-26 07:20:54] <eugenepark1> jdickey: thank you my understanding is that docker tags arent mutable so how do you prevent someone pushing their Dockerfile and building their image with the tag name v0.11.1?
[2018-03-26 07:21:09] <eugenepark1> is it because git version is unique?
[2018-03-26 07:50:38] <mohamedaittaleb> any docker Certified guy here §
[2018-03-26 09:23:18] <TiagoMRodrigues> one simple question if i have a folder called fake_root for instance with files that I need in my docker following the same folder structer as the image loaded how do I DO what intuitively should be "ADD fake_root/* /"
[2018-03-26 11:02:55] <azghar07> how to do wget inside a container
[2018-03-26 11:13:09] <azghar07> anyone?
[2018-03-26 11:46:08] <TiagoMRodrigues> wget with wget installed???
[2018-03-26 12:45:42] <alukos> Hello, try deploy to swarm from bitbucket-pipeline and received err:
[2018-03-26 12:46:04] <alukos>  [<-CODE->] 
[2018-03-26 12:46:40] <alukos> On manager: Client: API version: 1.37
[2018-03-26 13:25:27] <velp> azghar07: CMD wget http://some_url?
[2018-03-26 13:58:44] <tvsjke> Hello guys, does someone know how i can run two mysql databases with docker-compose? I seem to get an issue with the fact that they both use the same 3306 port (even when using separate networks). thanks in advance!
[2018-03-26 14:16:41] <azghar07> velp: i tried to download jdk9 into a docker container but it says wget command not found. and i tried yum install then it throws error
[2018-03-26 14:18:56] <arnabkd> azghar07: : what is the error?
[2018-03-26 14:19:39] <arnabkd> Have you tried yum update before running yum install?
[2018-03-26 14:20:04] <azghar07> nope
[2018-03-26 14:21:52] <azghar07> well now i have trying yum update
[2018-03-26 14:21:54] <azghar07> failure: repodata/repomd.xml from ol7-latest: [Errno 256] No more mirrors to try
[2018-03-26 14:22:00] <azghar07> same error
[2018-03-26 14:22:25] <azghar07> and yum doesn\'t have enough cached data to continue. At this point the onlysafe thing yum can do is fail. There are a few ways to work "fix" this:
[2018-03-26 14:22:30] <azghar07> Contact the upstream for the repository and get them to fix the problem.
[2018-03-26 14:22:36] <azghar07> Reconfigure the baseurl/etc. for the repository, to point to a workingupstream. This is most often useful if you are using a newerdistribution release than is supported by the repository (and thepackages for the previous distribution release still work).
[2018-03-26 14:22:45] <azghar07> . Configure the failing repository to be skipped, if it is unavailable.Note that yum will try to contact the repo. when it runs most commands,so will have to try and fail each time (and thus. yum will be be muchslower). If it is a very temporary problem though, this is often a nicecompromise:
[2018-03-26 14:22:57] <azghar07> [Errno 14] curl [<-ISSUE->] - "Could not resolve host
[2018-03-26 14:23:02] <azghar07> Unknown error"
[2018-03-26 14:40:52] <velp> azghar07: Do you have any connection? Try to run something likeping 8.8.8.8and if you have connection, see resolve config in file /etc/resolv.conf
[2018-03-27 05:51:07] <azghar07> i did. i added nameserver 8.8.8.8
[2018-03-27 14:00:29] <azghar07> can we do wget inside a container? how is it going to talk to outside world (internet)
[2018-03-27 16:37:12] <tusharbudhe0302> Hi Guys,I am nodejs developer. I would like to build HAproxy on 2 nodejs instance. Once had ui and other has api. Both are on different ports. Can some one help me with haproxy configuration ? Please reply me.
[2018-03-28 00:58:49] <ifelsemonkey_twitter> we can do wget inside a container
[2018-03-28 07:16:38] <comeUpWithItLater> docker ask for upgrade and :
[2018-03-28 07:16:50] <comeUpWithItLater>  [<-LINK->] 
[2018-03-28 07:19:24] <comeUpWithItLater> after finished
[2018-03-28 07:19:31] <comeUpWithItLater> what's wrong ?
[2018-03-28 07:21:09] <joshuamanns> Question: I'm setting up a Docker project with TypeORM and have dev & production modes, and I'm using the officialpostgres:alpineimage for db. Everything is fine when the app first launches bc postgres runsinitdbwithmydb_developmentdatabase name I pass in. However, if I switch NODE_ENVs and want to use a different database likemydb_production, obviously TypeORM complains because that database doesn't exist and postgres won't auto create it because the initdb script already ran the first time. I'm not sure the best way to solve this.
[2018-03-28 07:21:21] <joshuamanns> Is this something that you think should be handled on the typeorm service, or should I delegate this to thepostgresservice somehow?
[2018-03-28 08:05:19] <comeUpWithItLater> run a 2nd   pg  image for prod db
[2018-03-28 09:02:59] <ThomasVdBerge> Quick question. Imagine I am running docker om AWS ECS on a machine with 4 cores. If I give my docker 2048 CPU, would the docker container see that as two cores, or combine them as one?
[2018-03-28 09:36:20] <kaharlichenko> Hi. I'm trying to follow the tutorial and got stuck at the part4. I decided to use the AWS EC2 driver instead of the Virtualbox one.I managed to provision the machine, it does show up in AWS EC2 console. But whenever I try to init swarm on that machine I get a permission error.These are the commands I ran: [<-CODE->] And this is what I got: [<-CODE->]  [<-CODE->] 
[2018-03-28 12:07:10] <denizs> Try to rundocker swarm initassudo
[2018-03-28 12:08:22] <kaharlichenko> that's what I ended up doing, but I expected the tutorial to be consistent with the rest of the drivers
[2018-03-28 15:40:15] <ankitm123> Any ideas, how one can get unused volumes, docker inspect volume <volumeID> doesn't have that info, one can always do a docker inspect <container-name>, check names under mount but that is an expensive operation imo
[2018-03-29 05:39:32] <bloodcarter> Onyone managed to make awslogs work on windows?
[2018-03-29 06:11:32] <azghar07> does yum inside a docker depends on host machine
[2018-03-29 07:18:41] <hrt031293> does anyone have any idea about this problem
[2018-03-29 07:18:45] <hrt031293> Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get [<-LINK->] : dial unix /var/run/docker.sock: connect: permission denied
[2018-03-29 07:19:06] <hrt031293> while running the command     curl -sSL [<-LINK->] | bash -s 1.1.0
[2018-03-29 08:07:49] <velp> hrt031293: what do you do? add information
[2018-03-29 08:14:30] <hrt031293> velp: As I am new here as well as in hyperledger, I just watched a video in youtube to build my first network in hyperledger, it asked to install the prerequisites, Hyperledger Fabric Samples and download Platform-specific Binaries from the above mentioned "curl -sSL [<-LINK->] | bash -s 1.1.0" command. As I ran this command, I got this error  "Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get [<-LINK->] : dial unix /var/run/docker.sock: connect: permission denied"
[2018-03-29 09:04:36] <velp> hrt031293: see source code of this script [<-LINK->] , it has somedocker ...commands and if you run this script with standard user permissions you will see this error. It's correct, because you must usesudofor running docker commands. You can try download this script without pipe and bash commands, and run it manually with sudo.
[2018-03-29 09:12:48] <hrt031293> velp: tried with the sudo command, but that too failed
[2018-03-29 09:20:29] <velp> hrt031293: Any other docker command works? Try run for examplesudo docker  image list. Do you see anything?
[2018-03-29 09:21:33] <velp> maybe docker service not running?
[2018-03-29 09:22:44] <hrt031293> velp: yes, they are responding back with respective resultslike sudo docker --version, sudo docker images
[2018-03-29 09:25:57] <hrt031293> velp: even this command in responding back, withREPOSITORY            TAG                 IMAGE ID            CREATED             SIZE\nfinid/ubuntu-nodejs   latest              1e179321d916        27 hours ago        201MB\nubuntu                latest              f975c5035748        3 weeks ago         112MB\ncentos                latest              2d194b392dd1        3 weeks ago         195MB
[2018-03-29 09:26:13] <hrt031293> such result
[2018-03-29 09:30:31] <velp> Hm, it's strange. Ok, currently you download script [<-LINK->] right? Try to run this script with bash debugging option like `sudo bash -x <path_to_donwloaded_script>'. After that, you must see all running commands and see last command which will fail. Maybe it will add some information
[2018-03-29 11:17:36] <hrt031293> velp: Thanks for the help, it worked, but is this the permanent solution?
[2018-03-29 11:21:03] <ugorur> hi I create a apllication and use it with docker-compose but our costumers network infrastructure use docker's internal network ip addresses  ( 172.17.x.x). I try bip settings in json file but deamon always start with 172.17 ips. How can I change this in Centos 7?
[2018-03-29 11:30:50] <velp> hrt031293: Generally, I don't think that running some unknown scripts with sudo is normal, but in this case it is the only one way. The better way will be addingsudocommands into the script when it needs.
[2018-03-29 11:38:29] <hrt031293> velp: OK, can you help me with problems of hyperledger?
[2018-03-29 11:56:46] <velp> hrt031293: I didn't use hyperledger :( You can try to ask your questions in the chat of this project
[2018-03-29 12:01:36] <velp> ugorur: Did you change file daemon.json? How about starup command? What do you see inps aux | grep docker?
[2018-03-29 12:03:02] <ugorur> velp: yes. i have changed deamon.json and restarted my service. When docker started it used old ip.
[2018-03-29 12:04:57] <ugorur>  [<-CODE->] 
[2018-03-29 12:30:45] <velp> ugorur: Hm, can you try to run the docker daemon manually with option--fixed-cidr=<your_new_netwrok>?  Will it work? And you can try to add"debug": trueto daemon.json file and see  to the docker log.
[2018-03-29 13:20:33] <hrt031293> velp: OK
[2018-03-29 13:21:06] <hrt031293> Can anyone help me with hyperledger?
[2018-03-29 13:25:10] <hrt031293> velp: How to check whether docker is running or not,and if running , then how to stop and restart it?
[2018-03-29 13:25:21] <ugorur> velp: I am out for to day, I will be our costumers office to try this. I hope I can resolve this tomarrov
[2018-03-29 14:51:11] <velp> @velp  How to check whether docker is running or not,  and if running , then how to stop and restart it? [<-CODE->] 
[2018-03-29 17:25:41] <patientplatypus> hey guys - i have a very dumb question [<-LINK->] 
[2018-03-29 17:25:52] <patientplatypus> If anyone knows how to solve this can you let me know? I think im stuck.
[2018-03-29 17:35:30] <mcarpenterjr> I can't help you, but  on your website!
[2018-03-29 17:58:07] <stephendolan> Is there anyone who can help me figure out what's going on with this error while doing adocker image pull ruby:2.5.1:Error response from daemon: manifest for ruby:2.5.1 not found. I'm running docker on a Mac, I've tried resetting the app data to clear out all images/containers, I've tried logging out/in again, I've restarted my terminal, and I've verified that the new tag is on Docker Hub here: [<-LINK->] 
[2018-03-29 17:58:53] <stephendolan> The command line still allows me to do adocker image pull ruby:2.5.0, and the Image ID matches the Image ID ofdocker image pull ruby:latest
[2018-03-29 18:11:00] <stephendolan> Annnnd I just read the Gitter channel description... my bad. Taking this to the freenode.
[2018-03-29 18:48:13] <alanauckland86> Hi. I am trying to get snipe-it to work with docker-compose.I am getting php_network_getaddress: failed: Temporary failure in name resolution.Can anyone explain what this might mean.I used docker inspect and set the snipe.envMYSQL_PORT_3306_TCP_ADDR=XXX.XXX.XXX.XXXBut I dont think I need thatI also set env_file: ./snipe-it.env in both the snipie-it service and the snipe-it-mysql service alsoI exec into mysql container it creates the db, user but i can't use the username and password i set in the env to loginto the mysql db.when i run containers I just get woops something went wrong.
[2018-03-29 20:07:18] <davidmichaelkarr> In docker 1.12.6 on Centos, how do I set the proxy for docker login?  The doc page for this is ambiguous.
[2018-03-29 20:07:30] <davidmichaelkarr> The ambiguity has to do with the fact that the doc page at [<-LINK->] refers to running images, but my issue is with "docker login".  Will it just look for the normal "http_proxy" environment variable?
[2018-03-30 05:50:28] <hrt031293> @velp  How to check whether docker is running or not,  and if running , then how to stop and restart it? [<-CODE->] 
[2018-03-30 13:45:02] <patientplatypus> hey guys
[2018-03-30 13:48:36] <patientplatypus> I've got a dumb question. I was looking into how to spin up a docker container when you are already in a docker container. People were mentioning using the docker socket (I'm not all that worried about security so this is fine). Are there any good tutorials on doing this? I've only seen a couple Stackoverflow posts, and I've never done something so silly before.
[2018-03-30 19:41:55] <hadirsa> Hi guys!
[2018-03-30 19:41:59] <hadirsa> I had set my docker private registry and i'm trying to push an tagged image. When i run command bellow i get infinitely error Retrying in X seconds
[2018-03-30 19:43:33] <hadirsa> I have a [<-LINK->] 
[2018-03-30 19:44:27] <hadirsa> Any one faced problem 'Retrying in X seconds' when pushing an image to private registry:2?
[2018-03-30 19:46:30] <hadirsa> nephilimboy: 
[2018-03-30 21:01:41] <hadirsa> I changed my nginx.conf not to use upstream on proxy_pass. i worked. It cause  DNS lookup error.
[2018-03-30 21:03:45] <etherealjoy> Hi fellows! I need some assist. How do I access container folder as a on my host without being root. Just hints . Also no write permission from container to host.
[2018-03-30 21:16:49] <edumserrano> Hi guys, I'm having a problem with docker for windows. After installing latest version 18.03.0-ce docker does nto start. The docker icon in the taskbar never shows up.Whenever I try to start it nothing happens and in AppData\\Local\\Docker the log says:[22:16:11.706][GUI            ][Info   ] Starting...[22:16:11.721][GUI            ][Error  ] An instance is already running. Exiting.
[2018-03-30 21:17:02] <edumserrano> When I type docker version I get:
[2018-03-30 21:17:13] <edumserrano> Client:Version:       18.03.0-ceAPI version:   1.37Go version:    go1.9.4Git commit:    0520e24Built: Wed Mar 21 23:06:28 2018OS/Arch:       windows/amd64Experimental:  falseOrchestrator:  swarmerror during connect: Get [<-LINK->] : open //./pipe/docker_engine: The system cannot find the file specified. In the default daemon configuration on Windows, the docker client must be run elevated to connect. This error may also indicate that the docker daemon is not running.
[2018-03-30 21:17:47] <edumserrano> Any tip how to find out a bit more about why I'm having this error? is there any other directory with logs that I can look for more info?
[2018-03-30 21:33:16] <matjazmav> patientplatypus: Yes there is [<-LINK->] Docker-in-docker image
[2018-03-30 21:35:03] <matjazmav> Guys what distributed storage do you recommend for relational database? Im using swarm and was rhinkibg about glusterfs or ceph?
[2018-03-30 21:35:19] <davidmichaelkarr> I\'m getting an error with docker login trying to connect to AWS ECR.  I\'m not sure if I\'m doing something wrong, or the instructions I have are wrong. I\'m running behind a corp proxy.  I first verified I can build an image locally, talking to our private registry.  I\'m then using the result from "aws ecr get-login", which produces a "docker login" command line to run for the AWS ECR. This command line uses a specific userid and a long password with a server url pointing to amazonaws.com. When I run it, I see something like this: "Error response from daemon: Get [<-LINK->] : dial tcp 54.69.179.5:443: i/o timeout".  I verified that I could curl directly to the url, but it gets a 401 back (unsurprisingly).  I verified that nslookup of the fqhn returns that IP address (and two other IP addresses).
[2018-03-31 10:22:51] <chan_seeker_twitter> how to host docker container in azure vm and expose port so that the end user hits [<-LINK->] gets his content without exposing port in the url like [<-LINK->] in advance any help will be appreciated
[2018-03-31 11:32:52] <PhilippHeuer> I had a pretty cool idea for a simple cli tool that allows you to define a project-specific command to docker image mapping (npm install -> redirect and run with npm:9-alpine/auto map project dir and change directory/auto expose ports) - maybe someone is interested in helping or has futher ideas? [<-LINK->] We're already using docker a lot for ci / tests / to build app artifacts - but its still missing in local development to provide node/golang/... itself.
[2018-04-01 22:05:37] <wesleyguirra> Hi guys
[2018-04-01 22:05:41] <wesleyguirra> Good evening
[2018-04-01 22:05:56] <wesleyguirra> ```
[2018-04-01 22:06:06] <wesleyguirra>  [<-CODE->] 
[2018-04-01 22:06:26] <wesleyguirra> there's something wrong with this docker-compose file?
[2018-04-01 22:07:04] <wesleyguirra>  [<-LINK->] 
[2018-04-01 22:08:58] <wesleyguirra> I'm trying to dockerize a project for development and production
[2018-04-01 22:09:25] <wesleyguirra> I tried to do that with Vagrant + Docker but I'm not get working
[2018-04-01 22:10:22] <wesleyguirra> now I'm trying to do that with Docker for production (when the app is ready for) and Docker Compose for development with shared project folder with live editing
[2018-04-01 22:10:34] <wesleyguirra> someone can help me with this?
[2018-04-01 22:11:28] <davidmichaelkarr> you haven't said what your problem is.
[2018-04-01 22:11:56] <wesleyguirra>  [<-CODE->] 
[2018-04-01 22:13:07] <wesleyguirra> I'm not sure if it's the right way to create a dev/production environment
[2018-04-01 22:14:02] <davidmichaelkarr> check compose file syntax. image specifies an image, not a dockerfile.
[2018-04-01 22:14:09] <wesleyguirra> for dev I want isolate node and its dependencies
[2018-04-01 22:15:26] <wesleyguirra> I tried with build
[2018-04-01 22:15:33] <wesleyguirra> I get this
[2018-04-01 22:15:37] <wesleyguirra>  [<-CODE->] 
[2018-04-01 22:16:29] <davidmichaelkarr>  [<-LINK->] 
[2018-04-01 22:17:20] <wesleyguirra> I'm reading the docs
[2018-04-01 22:17:26] <wesleyguirra> but my question is
[2018-04-01 22:17:48] <wesleyguirra> what's the better way to have project for dev and production
[2018-04-01 22:18:29] <wesleyguirra> I'm not sure if this structure is correct
[2018-04-01 22:18:43] <davidmichaelkarr> construct the same image, with parameters for env config.
[2018-04-01 22:19:00] <wesleyguirra> have some example, repository?
[2018-04-01 22:19:14] <davidmichaelkarr> no. general guideline.
[2018-04-01 22:21:07] <wesleyguirra> when I'm in dev I need to do compose up every once I change something in the code
[2018-04-01 22:21:24] <wesleyguirra> even setting volumes
[2018-04-02 00:14:23] <wesleyguirra> someone can help?
[2018-04-02 00:15:40] <davidmichaelkarr> build takes a dir, not a file.
[2018-04-02 02:50:14] <rimantoro> Hi
[2018-04-02 02:50:28] <rimantoro> Just curious, there is a performance issue when installing Laravel within docker. This is actually Docker For Mac issue as describe in https://docs.docker.com/docker-for-mac/osxfs/#performance-issues-solutions-and-roadmap. [<-CODE->] Is it someone here have another tips to a better performance when installing Laravel with docker ?many thanks.
[2018-04-02 07:52:04] <azghar07> COPY failed: stat /scratch/docker/tmp/docker-builder853626188/outB: no such file or directory
[2018-04-02 07:52:09] <azghar07> copy is failing
[2018-04-02 07:52:18] <azghar07> i dont understand why
[2018-04-02 07:52:26] <azghar07> can anyone help me in this
[2018-04-02 08:45:56] <velp> azghar07: Do you try copying some files when the docker image build? Are you sure thatstatdirectory exists in root directory where Dockerfile places?
[2018-04-02 11:25:49] <videnovnebojsa> Hi, I see that latest release 18.02 will usepigzfor parallel decompression of the layers, but not sure if it is working out of box or one has to change some configuration(or provide parameters)?
[2018-04-02 11:42:22] <prashant7july> Hi All, Please help me out.What is the difference between these 2 different script [<-LINK->] & [<-LINK->] for SWARM and how would be able to run below docker-compose.yml in SWARM? [<-CODE->] 
[2018-04-02 19:34:43] <FlorinAsavoaie> Hi. I am developing a Docker Plugin (IPAM Driver) and I have a curiosity. Does Docker guarantee command execution consistency or should I handle such special cases? For example: will Docker ever call ReleasePool while waiting for a response on a RequestAddress request?
[2018-04-03 08:48:03] <robbyoconnor>  [<-LINK->] @prashant7julyI don't see much of a difference  -- Why not try them and see? Rather than asking things like this -- experiment -- nothing will break...it's not like you're working with production systems...
[2018-04-03 10:43:31] <farukhkhan21_twitter> rancher vs portainer vs shipyard. which container management gui you guys suggest?
[2018-04-03 13:22:43] <sebastjan-hribar> Hi all, I have an issue with copying files from server to docker container. I used to do it withsudo docker cp my_filepath my_docker:/path_to_filebut now the command runs but doesn't copy the file. When going to container bash and cd to the folder I can't create a new file or edit an existing one. It's like I have no authorization. I'm copying some csv files for rake tasks.
[2018-04-03 13:45:17] <sebastjan-hribar> I found out that the server provider has performed some updates to the server and that must have caused some glitches. After stoping and starting containers everything works.
[2018-04-03 21:38:48] <FlorinAsavoaie> Any Docker developer around that could answer my question?
[2018-04-04 08:41:56] <farukhkhan21_twitter> does docker swarm automatically use certified TLS connections to communicate between each other?
[2018-04-04 13:31:15] <campbs> does anyone know why im getting  this errordb_1      |     Connection matched pg_hba.conf line 95: "host all all all md5”with postgres database
[2018-04-04 14:26:18] <matjazmav> campbs: Can you give us compose file?
[2018-04-04 14:27:38] <campbs> Hey i got it working thanks tho,, it was that my database wasn’t set up properly so the server couldn’t access it.
[2018-04-04 16:53:14] <josecolella> anyone used Dockerfile with private npm packages?
[2018-04-05 01:34:20] <mitchcapper> anyone using docker on windows have it just terminate a container sitting idle? for example if I docker run -t -i image powershell (or command) and let it sit there for a few minutes the container will get killed off
[2018-04-05 11:37:30] <carrowheap> Hello everyone, I want to learn docker can you suggest me a tutorial for the real beginner.Thank you
[2018-04-05 11:47:50] <IsuraNimalasri> carrowheap:  [<-LINK->] 
[2018-04-05 11:48:09] <carrowheap> IsuraNimalasri: thanks
[2018-04-06 13:59:06] <natefoo> If I get a 500 "context deadline exceeded" can I assume that the operation (e.g. container or service creation) has failed, or should I check?
[2018-04-06 14:21:22] <campbs> has any body got this error
[2018-04-06 14:21:23] <campbs> EXDEV: cross-device link not permitted,
[2018-04-06 14:21:25] <campbs> with docker
[2018-04-06 14:21:29] <campbs> and npm
[2018-04-06 15:11:58] <mitchcapper> do you have two different mounts in the container?
[2018-04-08 08:11:34] <matjazmav> Hey is it possible to run docker swarm service one time and then exit it without automatic rescheduling? Use case : Deployment initialization script.
[2018-04-08 13:27:33] <uzayr> Hi,,
[2018-04-08 13:29:03] <uzayr> I want to connect different network container to different network container1 with "Gateway": "172.17.0.1"2 with "Gateway": "172.18.0.1"
[2018-04-08 13:29:26] <uzayr> anyone can help me with this
[2018-04-08 19:07:12] <Huholoman> Hello, I am preparing docker for my project.. I have extended php:7.2.4-fpm-stretch image to install pdo_pgsql, but when i run php script it still tells me i dont have any extension lik PgSQL or PDO_PgSQL. [<-LINK->] Can anyone help me, please?
[2018-04-09 18:32:29] <tusharbudhe0302> Hi Guys,I am having issue in haproxy with nodejs costume images. I would appreciate your help. [<-LINK->] 
[2018-04-10 09:38:11] <cebor> In docker-compose.yml, doesversion: '3'point to the latest 3.x or to 3.0 ?
[2018-04-10 09:43:27] <mateothegreat> 3.1 iirc
[2018-04-10 09:48:29] <cebor> Ty
[2018-04-10 18:57:56] <olivier-mauras> Evening folks
[2018-04-10 18:58:15] <olivier-mauras> I've updated to latest Moby release and since then can't build any image anymore
[2018-04-10 18:58:38] <olivier-mauras> fails on me with: Error response from daemon: Error processing tar file(exit status 1): unexpected EOF
[2018-04-10 18:58:42] <olivier-mauras> any idea?
[2018-04-10 20:42:39] <gaggle> Evening (?) all
[2018-04-10 20:45:54] <gaggle> I\'ve smashed my head against this for 6 hours, where Docker says error of "ERROR: Preparation failed: API error (500): Get https://....amazonaws.com/v2/.../manifests/latest: no basic auth credentials" (it\'s a GitLab CI Runner pulling an AWS ECS image). But everything works when I SSH into the runner, I candocker pullthat same image no problem. Can anyone explain what "no basic auth credentials" actually refer to?
[2018-04-10 20:52:04] <gaggle> I put Docker host into debug mode, but all I see there are entries like "Handler for POST /v1.18/images/create returned error: Get https://....amazonaws.com/v2/.../manifests/latest: no basic auth credentials"It\'s been frustrating to debug because SSH just works, and the runner is fine pulling publicly available images. Not sure what that basic auth refers to... is the Docker host expecting auth but not getting them? Or that it doesn\'t want them? Is it the host itself that has credentials or the caller?
[2018-04-10 20:54:42] <gaggle> (Since this is ECS I\'ve made sure to get login to it viaaws ecr get-login, and everything works brilliantly from SSH.. I\'ve almost given up but if someone knows what "no basic auth" refers to maybe I can think of more things to try)
[2018-04-10 20:56:01] <gaggle> Oh if its relevant this is AWS EC2 Linux, w. docker.x86_64 17.12.1ce-1.135.amzn1 installed according to yum.
[2018-04-11 10:03:27] <r2d2leboss> Hey. How to expose a different port to other linked containers than the one exposed ? (For example: A service exposes port 22 but I want other containers to use port 2222).
[2018-04-11 10:23:11] <elcolie> Hi
[2018-04-11 10:23:33] <elcolie> I would like to read myIP. But when I implement my own I got different one.
[2018-04-11 10:23:34] <elcolie>  [<-LINK->] 
[2018-04-11 10:23:38] <elcolie> Where am I wrong?
[2018-04-11 16:12:33] <matjazmav> r2d2leboss: just make sure that both service run in a same network
[2018-04-11 16:12:46] <matjazmav> You dont need to expose nothing
[2018-04-11 17:42:35] <MohanJagadheeswaran> Hi Guys
[2018-04-11 17:43:23] <MohanJagadheeswaran> Iam new to Docker and all what i did was, installed Docker and created a docker-machine in my VM
[2018-04-11 17:43:45] <MohanJagadheeswaran> created a docker image out of a java jar. it got successfully created
[2018-04-11 17:44:03] <MohanJagadheeswaran> If i tried docker pull imagename:version am getting
[2018-04-11 17:44:18] <MohanJagadheeswaran> Error response from daemon:pull access denied
[2018-04-11 17:44:31] <MohanJagadheeswaran> I tried [<-LINK->] 
[2018-04-11 17:44:43] <MohanJagadheeswaran> And no luck getting the same error
[2018-04-11 17:45:26] <MohanJagadheeswaran> Currently am running un windows
[2018-04-11 17:45:58] <MohanJagadheeswaran> Any suggestions? I got the whole day with the issue
[2018-04-11 17:46:05] <MohanJagadheeswaran> got struck
[2018-04-11 19:13:39] <Eslam-Naser> Hello guys
[2018-04-11 19:14:14] <Eslam-Naser> anyone used Docker API with Ruby ?!  it's good but i'm having an issue
[2018-04-12 00:27:56] <stephenchu> Q: using Docker for Mac, and knowing first hand about [<-ISSUE->] , why would my container be able to bind mount-v /var/run/docker.sockin anddockercli works, but not when i bind mount$SSH_AUTH_SOCKin? aren't they just sockets?
[2018-04-12 04:19:53] <mjbright> Has anyone tried using kubernetes functionality in the docker-ce linux builds such as docker-ce-18.04?   I tried yesterday, got as far as enabling experimental mode on client and server side but then couldn't see anyway to create a usable .kube/config to be able to deploy a stack.  Any idea?
[2018-04-12 09:42:44] <azghar07> what does it mean when someone says docker image without shell??
[2018-04-12 09:52:31] <azghar07> anyone??
[2018-04-12 13:21:48] <conkerant> stephenchu: check your user ID into container (you must be root to use docker socket)
[2018-04-12 13:22:17] <conkerant> stephenchu: or any user who authorised to use docker socket.
[2018-04-12 13:38:01] <FlorinAsavoaie> stephenchu: that's because /var/run/docker.sock is from Moby VM which is running the Docker daemon and SSH_AUTH_SOCK is from OSX.
[2018-04-12 13:39:00] <FlorinAsavoaie> On OSX, Docker runs in a virtual machine created with HyperKit over the OSX  Hypervisor, not natively like in Linux.
[2018-04-12 20:15:51] <avifatal> Hi,Please help, why docker exit with code 0 even if I havetty:true [<-CODE->] 
[2018-04-12 20:16:42] <avifatal> I getmautic2_api_1 exited with code 0also when I docommand: installI still get it.
[2018-04-12 20:39:14] <gerges> Is there any mechanism to get insight into ongoing volume sync?
[2018-04-12 20:45:37] <gerges> Many different members of our dev team consistently get in a state where no docker command responds, hyperkit pegs cpu, and the container grinds to a halt
[2018-04-13 08:42:13] <nischay30> HI, could anyone help me with kubernetes cluster? I have some queries.
[2018-04-13 13:58:39] <siulkilulki> How to remove docker bind mount volume? I don;t have sudo
[2018-04-13 14:23:25] <SISheogorath> From inside a container, no way, from outside: recreate thr container without the mount. No other way advised
[2018-04-13 14:23:42] <SISheogorath> siulkilulki: ^
[2018-04-13 14:24:14] <siulkilulki> hah, that what im trying to do
[2018-04-13 14:24:24] <siulkilulki> thanks!
[2018-04-13 14:25:42] <siulkilulki> actually i m trying to recreate it with named volume mounted in the same location, should also work, right?
[2018-04-13 14:40:44] <SISheogorath> Yes
[2018-04-13 19:54:35] <rightisleft> Question: why does the docker process continue to run when i execute something likedocker-compose run my-node npm install- i would expect it to terminate after npm install is completed
[2018-04-14 09:36:02] <chwba> how can i effectively update a docker container like this?
[2018-04-14 09:36:07] <chwba>  [<-LINK->] 
[2018-04-14 09:36:46] <chwba> i simply want it to rerun the dockerfile, so that it will download the most recent version of lms through the flexible link embedded in it
[2018-04-14 09:53:29] <SISheogorath> looks fine, yes
[2018-04-14 12:09:20] <babaorum> I do not think you can "update" a container per say. You have to kill it and recreate it using the updated image
[2018-04-14 13:49:52] <PhilippHeuer> ye, just make sure to store your critical data outside of the container with mounts - so that you can recreate them at any time and keep your data
[2018-04-14 13:51:07] <chwba> so if I wanted to make sure the container is always up to date I would have to schedule an external script that regularly kills the container and then recreates it?
[2018-04-14 13:51:55] <PhilippHeuer> yes
[2018-04-14 13:53:04] <babaorum> I thnik you should schedule a pull of the image and be able to catch a change. This way you will avoid killing / recreating the container for nothing
[2018-04-14 13:53:56] <PhilippHeuer> yepp that should be part of this external script
[2018-04-14 13:55:23] <PhilippHeuer> what do you use? cli commands, docker compose or some orchestrator?
[2018-04-14 13:55:33] <chwba> cli commands
[2018-04-14 13:56:36] <chwba> so if i only had this one container runing i would do something like: docker stop $(docker ps -a -q) docker rm $(docker ps -a -q)  docker rmi $(docker images -q) and then docker pull 'name'
[2018-04-14 13:58:51] <PhilippHeuer> you can give your container a name with --name hello and then use that when you stop/kill
[2018-04-14 13:59:04] <PhilippHeuer> and you don't have to call rmi before pulling
[2018-04-14 14:02:48] <PhilippHeuer> if you only have a single server you could use docker swarm and replace your docker run command with a compose yml file, then you would only pull the new image and redeploy the service withdocker stack deploy --compose-file mediaserver.yml- if you post your run command i can give you a example
[2018-04-14 14:03:24] <PhilippHeuer> but you should never write a cronjob that stops all containers like that, at some point when you add others you'r gonna be in for a surprise - always name them
[2018-04-14 14:08:22] <nephilimboy> Hi guysIm using docker api to execute command in container https://docs.docker.com/engine/api/v1.24/#4-going-further here is my post body [<-CODE->] I can see the ping result in my response output but how can I terminate this command? (I know I can execute kill command in the container) but is there any way to terminate the running command with docker api?
[2018-04-14 18:20:34] <moisesrodriguez> Hey!I’m working on a Wordpress site and I followed this tutorial [<-LINK->] . I have everything running, but I still haven’t figured out how can I connect to my database using a program like [<-LINK->] .  What would be the host url? How can I connect to the database in the volume directly from the host computer?
[2018-04-14 19:00:43] <babaorum> Under your db service. You need to add a port mapping for mysql.
[2018-04-14 19:01:12] <babaorum> It should look like this :
[2018-04-14 19:01:25] <babaorum> ports:
[2018-04-14 19:02:11] <babaorum> {YourDesiredPort}:{TheDefaultMysqlPort}
[2018-04-14 19:06:26] <moisesrodriguez> babaorum: so for example I would do something like3306:3306And I should be able to connect to it through my management app using the host url localhost:3306?
[2018-04-14 21:18:22] <mateothegreat> moisesrodriguez: yes
[2018-04-14 21:19:04] <mateothegreat> moisesrodriguez: if you're wanting to connect to it from another host make sure you check your firewall ;)
[2018-04-15 02:31:46] <moisesrodriguez> mateothegreat: @babaorumthat worked, thanks very much!
[2018-04-15 16:30:19] <nspaeth> Hi. I am trying to move a container to a different host. At first I trieddocker exportanddocker import, but I discovered that this method removes meta data about e.g., theRUN, and trying to run it givesno command specified. I found out aboutdocker save, which is supposed to save that meta data, but that appears to save the image, not the container. What if I have data I want to preserve in the container and preserve the meta data?
[2018-04-15 19:39:58] <matjazmav> Is there any tool/image to benchmark (cpu, mem, network, disk) docker swarm infrastructure?
[2018-04-15 21:52:00] <haribageski> Hi, I am getting the following error: issue withPhysical memory usage is too high: physicalBytes = 972M > maxPhysicalBytes=966M.I noticed that themaxPhysicalBytesgets set to exactly half of the amount of docker daemon memory (Docker for Mac). Is there a way to increase themaxPhysicalByteswithout increasing the docker daemon memory?
[2018-04-16 10:21:31] <robertmusil> Hey, I\'m trying to grab a list of labels of my container,docker inspect 09ae7d4a81ce --format "{{.Config.Labels }}", how can I unpackmap[]into a list of keys?
[2018-04-16 10:23:04] <robertmusil> Nvm, it was bash that was stopping me from using range with variables, sorry.
[2018-04-16 16:23:48] <MohanJagadheeswaran> Hi
[2018-04-16 16:24:54] <MohanJagadheeswaran> Iam struggling with a small issue. Iam trying to install a software called ImageMagick to access in my java application.
[2018-04-16 16:25:56] <MohanJagadheeswaran> \'\'\'FROM openjdk:8ADD target/eureka-server-1.0.0-RELEASE.jar eureka-server-1.0.0-RELEASE.jarEXPOSE 9991RUN ["yum","install","ImageMagick"]RUN [COMMAND TO SET env Variable]ENTRYPOINT ["java","-jar","eureka-server-1.0.0-RELEASE.jar"]\'\'\'
[2018-04-16 16:26:56] <MohanJagadheeswaran> Iam not sure whether, how to set my application directory as a environmental variable
[2018-04-16 16:27:18] <MohanJagadheeswaran> Once i set, in my java application, i will be using it
[2018-04-16 16:27:33] <MohanJagadheeswaran> Suggest a solution for my problem
[2018-04-16 16:28:22] <MohanJagadheeswaran> I found whereis command helps to find installation directory of ImagaMagick
[2018-04-16 16:35:31] <babaorum> If you only need within your dockerfile consider using ARG ( [<-LINK->] ).If you need it while running you application, you can use ENV ( [<-LINK->] )
[2018-04-16 16:39:18] <MohanJagadheeswaran> Thank for your reply
[2018-04-16 16:39:21] <MohanJagadheeswaran> Hope env safes me
[2018-04-16 16:39:50] <MohanJagadheeswaran> But what am scared is, i need to get the installation directory of my yum install command
[2018-04-16 16:39:52] <babaorum> But I am not sure if you can surcharge the value of ENV during the build.
[2018-04-16 16:39:56] <MohanJagadheeswaran> then set to my env dynamically
[2018-04-16 16:40:26] <MohanJagadheeswaran> Guess whereis helps in getting installation directory
[2018-04-16 16:40:33] <babaorum> I think you can do that.
[2018-04-16 16:40:38] <MohanJagadheeswaran> but can i save it in a variable, some thing like that?
[2018-04-16 16:41:37] <babaorum> something like that should work I think ENV INSTALL_PATH = $(which my-soft)
[2018-04-16 16:42:35] <MohanJagadheeswaran> Guess exact solution i needed. can i try with $(whereis my-soft)?
[2018-04-16 16:43:31] <babaorum> Give it a try. In both cases, I am interested in the result
[2018-04-16 16:46:25] <MohanJagadheeswaran> Lest give a shot!!
[2018-04-16 18:38:38] <MohanJagadheeswaran> babaorum: Iam facing this error
[2018-04-16 18:38:38] <MohanJagadheeswaran> OCI runtime create failed: conatiner_linux.go: starting conatiner process caused "exec": "\\yum": executable file not found in $PATH: unknow.
[2018-04-16 18:39:07] <MohanJagadheeswaran> Please refer the link for more info
[2018-04-16 18:39:08] <MohanJagadheeswaran>  [<-LINK->] 
[2018-04-16 19:23:42] <babaorum> From what I saw, the tag you are refering is not an image which use yum as it's package manager. It use apt-get.
[2018-04-16 19:24:25] <babaorum> You should either change your tag. Or use apt-get instead of yum
[2018-04-16 19:25:43] <babaorum> Also do not forget to pass an option to avoid a prompt before the install. For apt-get it is achieve with -y
[2018-04-16 23:50:54] <kminevskiy> Hey folks, hope y\'all having great day/evening! I\'m working on configuring dev env for my team and I\'m packaging several services into Docker containers. It looks like I\'m almost there, but the problem I\'m having is the following: I have 3 services (app, db and redis). The last 2 will need to be accessible from the first one (app). As far as I understand, by default all of them live on the same virtual network and be able to communicate. So I use <links> directive under the app service to explicitly define that fact. However, when I try to ping / connect to the database container, I get "could not translate host name "postgres.local" to address: Name or service not known". Is there something I\'m missing?
[2018-04-16 23:52:17] <kminevskiy> My assumption was that Docker will automatically add postgres.local (alias I defined in the Docker Compose file) to my app service and that container will be able to resolve the hostname.
[2018-04-17 04:53:03] <MohanJagadheeswaran> babaorum: you are right. I changed my DockerFile as below
[2018-04-17 04:53:12] <MohanJagadheeswaran> '''FROM openjdk:8downloading imagemagick dependenciesRUN apt-get install build-essential checkinstall && apt-get build-dep imagemagick -ydownloading imagemagick and configuringRUN wget http://www.imagemagick.org/download/ImageMagick.tar.gz'''
[2018-04-17 04:54:26] <MohanJagadheeswaran> Now am getting unable to locate package build essential and check essential
[2018-04-17 04:54:39] <MohanJagadheeswaran> returned a non zero code-100
[2018-04-17 04:54:49] <MohanJagadheeswaran> Checking the issue.
[2018-04-17 12:11:04] <babaorum> kminevskiy: can you show us what your docker-compose file looks like
[2018-04-17 14:25:41] <kminevskiy> babaorum: I just realized that I was expecting hostnames to be available during container (Dockerfile) creation. And obviously that's not the case.
[2018-04-17 14:26:03] <kminevskiy> So I guess my question is resolved :)
[2018-04-17 18:43:08] <rightisleft> why did they remove scale from docker-compose?
[2018-04-17 18:43:16] <rightisleft> just upgraded from v2 -> v3
[2018-04-17 19:36:36] <babaorum> Did you saw the documentation ? :// [<-LINK->] 
[2018-04-17 19:36:47] <babaorum>  [<-LINK->] 
[2018-04-17 19:36:56] <babaorum> (sorry)
[2018-04-18 10:18:09] <akso-ak> Hi. I am trying to run a container that has an environment variable which is a password that contains special characters. Is there any documentation on how to properly escape these chars?
[2018-04-18 16:32:38] <SISheogorath> @akso-akThat depends on how you want to use them. In general you have to escape them for your shell when you put them in using the docker command or for yaml when you use docker-compose. Also you may use a third format later on in your image, where you may have to escape it differently. But that's something only you know
[2018-04-18 16:33:11] <SISheogorath> Also keep in mind that some characters may cause problems when you don't use UTF-8 or different locales in general
[2018-04-18 18:46:08] <farukhkhan21_twitter> is it ok to create a docker swarm cluster with one swarm manager on docker version 18.03 and 5 worker nodes on docker version 17.12.1? The manager is only manager and not working on the cluster.
[2018-04-18 19:22:46] <rusbob> farukhkhan21_twitter: Not a reliable option, but possible one. You need just to make sure, there is nothing could break compatibility between these two versions. Check diff of two versions release notes:v. 17.12.1: [<-LINK->] v. 18.03: [<-LINK->] 
[2018-04-18 19:29:33] <rusbob> kminevskiy: ,linksare deprecated. See [<-LINK->] in more details of how to use service name in reference of youapp
[2018-04-18 22:45:51] <intellix> am I right in thinking that Docker reads.gitignoreand doesn't copy stuff across that are defined there?
[2018-04-18 22:47:09] <intellix> because if that's so, I'm so mad. Spent hours to realise that it reads something that has nothing to do with Docker
[2018-04-18 22:48:18] <davidmichaelkarr> intellix: I doubt that. I believe there's a different file with a similar purpose.
[2018-04-18 22:48:44] <intellix> I know there's a.dockerignore, I'm doing multi-stage builds and when I copy across from the multi-stage, the output isn't in the second step
[2018-04-18 22:50:05] <intellix>  [<-CODE->] 
[2018-04-18 22:50:22] <intellix> the yarn in the first step runs lerna bootstrap, which compiles my code. In the 2nd step, the dist folders are just not there
[2018-04-18 22:50:23] <davidmichaelkarr> intellix: docket isn't going to look at that. it would use .dockerignore, so something else is going on.
[2018-04-18 22:50:39] <intellix> so confused :'(
[2018-04-19 07:49:43] <Alikhll> Hi, I have a really strange problem with docker for windows and it's driving me crazy, after restarting computer I got this error and my running container does not work at alldocker run -p 8585:5432 postgres -d\nC:\\Program Files\\Docker\\Docker\\Resources\\bin\\docker.exe: Error response from daemon: driver failed programming external connectivity on endpoint happy_brattain (af53403286b2732c8510a2b2feb1ed7adff9fd664afe8048ee184e43ef400327): Error starting userland proxy: mkdir /port/tcp:0.0.0.0:8585:tcp:172.17.0.2:5432: input/output error.(8585 port is not used and I tried another one too!)I have to restart docker and after that everything works fine, do you have any idea?
[2018-04-19 07:53:17] <Alikhll> by the way, I've tried docker edge too, same happened!
[2018-04-19 09:49:15] <padhyakash> intellix: can you help me here please [<-LINK->] 
[2018-04-19 09:50:14] <intellix> not sure why you tagged me in particular but :D what's the problem you're having?
[2018-04-19 09:55:43] <padhyakash> anyone having a nice nodejs npm gulp docker image?
[2018-04-19 17:54:19] <rusbob> Alikhll: , there is opened ticket for such kind of issue. See [<-ISSUE->] 
[2018-04-20 06:34:36] <sambagadipudi_twitter> I am getting this error while doing docker buildThis is because of COPYING Files from the Dockerfile Parent Directory
[2018-04-20 06:34:40] <sambagadipudi_twitter> COPY failed: Forbidden path outside the build context: ../../ ()
[2018-04-20 06:34:50] <sambagadipudi_twitter> Any help on this is appreciated
[2018-04-20 06:59:47] <Maxdu92> Hi guys. I am running a docker container in a gitlab pipeline. My problem is now, that I have to make a lot of check-ins. But the pipeline aborts, because there is already a running instance of a container, i previously checked in.Are there any options for thedocker runcommand, that i could use? I already tried--restart always
[2018-04-20 07:03:21] <Maxdu92> $ docker run --detach --publish 3002:3002 --restart always --name juice-shop bkimminich/juice-shop\ndocker: Error response from daemon: Conflict. The container name "/juice-shop" is already in use by container "1098cb9b34e05106f94f6d03f66a0dbee667ea617ac74084dc4d7d48c24704b2". You have to remove (or rename) that container to be able to reuse that name.\nSee \'docker run --help\'.
[2018-04-20 07:03:33] <Maxdu92> Here is the arrow message btw
[2018-04-20 13:48:52] <davidmichaelkarr> Maxdu92: do you need it to have a particular name?
[2018-04-21 19:58:17] <rusbob> Hi@Maxdu92, not clear what you're trying to achieve with this pipeline. It looks like the pipeline job tries to run container instead to make sure the container is down before running it.
[2018-04-21 22:59:06] <PhilippHeuer> He prob. wants to deploy his container in the pipeline. You will have to remove your old container first before you use docker run
[2018-04-22 00:36:51] <justinhj> Maxdu92: if you want to remove the container before  making a new one with the same name you can do that like thisdocker rm -f juice-shop || true
[2018-04-22 12:10:51] <campbs> Hey, I have a question,if i have a container say app and another container called platform and in the platform i want to call an api defined in app . app is displayed on port 3000inside platform i want to callex. [<-LINK->] how do i do it? i have tried [<-LINK->] but its saying address not found
[2018-04-22 12:14:02] <ghost~5ada0e40d73408ce4f967473> Try to replace localhost by the IP address of the machine l
[2018-04-22 12:14:49] <campbs> of the docker machine?
[2018-04-22 12:17:33] <ghost~5ada0e40d73408ce4f967473> Yes
[2018-04-22 12:17:48] <ghost~5ada0e40d73408ce4f967473> Or try 0.0.0.0
[2018-04-22 12:17:56] <campbs> okay will try thanks
[2018-04-22 16:10:05] <MichaelrMentele> Hey gang, I'm trying to spin up multiple instances of the same django web app on different ports (all with separate dbs) to simulate a gossip protocol.
[2018-04-22 16:10:37] <MichaelrMentele> Is there a way I can run my services in 'host' network mode while having each service still construct it's own db?
[2018-04-22 16:14:59] <MichaelrMentele>  [<-LINK->] 
[2018-04-22 21:09:43] <xximjasonxx> Hey guys, I am having some networking trouble with Docker, I think. I have a container running expressjs serving a simple Login API
[2018-04-22 21:10:25] <xximjasonxx> In another container I have a React app running, I get a CORS error every time I try to hit the server (tried both the service name [name unresolved] and localhost:port [CORS error])
[2018-04-22 21:11:06] <xximjasonxx> I have turned on CORS in ExpressJS but I still get the CORS error. Postman confirms the endpoint is there and accessible. Anyone have any ideas what ExpressJS magic I might be missing?
[2018-04-23 08:23:55] <rusbob> MichaelrMentele: I think you need to havewebentries with different ports and then you'll be able to run multiple containers inhostnetworking.
[2018-04-23 08:42:10] <rusbob> Hi@xximjasonxx, why not run bothexpress.jsandReactframework atNodeJSon single container?In case you need a separate solution,  you can add a reverse proxy (nginx) in front of external requests and it will dispatches all those requests to the corresponding container, eitherLogin(express.js) orWebReact.
[2018-04-23 09:46:46] <akso-ak> SISheogorath: Thanks. I have resolved the issue now
[2018-04-23 17:29:06] <MohanJagadheeswaran> Hi
[2018-04-23 17:29:44] <MohanJagadheeswaran> I have a container which runs the registry image(Private registry)
[2018-04-23 17:29:58] <MohanJagadheeswaran> Now i want to push a image from another machine
[2018-04-23 17:30:42] <MohanJagadheeswaran> I dont added any additional certificates in my registry host machine nor registry contatiner or clientg
[2018-04-23 17:31:09] <MohanJagadheeswaran> I have tagged my image with hostname:port/imagename:tag
[2018-04-23 17:31:29] <MohanJagadheeswaran> $ docker push docker.registry:5000/eureka-server:2The push refers to a repository [docker.registry:5000/eureka-server]Get [<-LINK->] : dial tcp: lookup docker.registry on xx no such host
[2018-04-23 17:32:07] <MohanJagadheeswaran> can anyone let me know, how can we set up certificated to access the machine
[2018-04-23 17:40:20] <FlorinAsavoaie> For user help, please goto #docker on freenode.
[2018-04-24 11:22:10] <hrt031293> Hello everyone,Can someone tell me about  "docker mount volume"?Thanks.
[2018-04-24 13:56:21] <rusbob> See in more details [<-LINK->] 
[2018-04-24 17:30:10] <odwrotnie> Are you able to run docker publish from Docker container? I want to build a version and publish it to docker bysbt docker:publish. Unfortunately i getjava.io.IOException: Cannot run program "docker"
[2018-04-24 18:51:02] <maceacherndjh> Is it possible to have a live reload development environment without utilising host binded data volumes, I am blocked at work from sharing my C: drive  with docker?
[2018-04-24 20:04:34] <Tokynet> im trying to get UCP to an HA status, its currently only 2 UCP hosts
[2018-04-24 20:05:22] <Tokynet> when i added the 2nd UCP host as a manager, i got a banner about needed 3 hosts and lost access to the ucp interface
[2018-04-24 20:05:51] <Tokynet> is it going to be inaccessible until i get the 3rd host in there?
[2018-04-25 05:30:25] <matjazmav> Is this true... if I dont use volume io performance is not optimum?
[2018-04-25 05:33:09] <matjazmav> In my scenario I’m running benchmarks on database, after each test I just remove container and start new one
[2018-04-25 07:08:42] <kjetilmjos> I found an irritating little problem when using docker volume with NFS storage. Creation of the volume works fine, but when I start a docker container and mount a folder inside to the NFS volume I get a operation not permitted if the NFS directory is empty. As soon as I add a file or folder to the NFS directory and try a container start everything works fine. Anybody else experienced the same issue when using docker volumes with NFS storage?
[2018-04-25 08:35:40] <SofianeB> Please can some help, I have issue contacting host server from my container.  I just run a server on host (python -m http.server 9999) butcurl http://127.0.0.1:9999returnscurl: (7) Failed to connect to localhost port 9999: Connection refusedIs there a way to solve this without passing the --network 'host'?
[2018-04-25 09:35:58] <antonedvard> anyone here that could give me a small assist with a docker network?
[2018-04-26 22:14:06] <ianseyer> Hi all. Have an interesting use case. I would like to run docker swarm in such a way that allows nodes to have a mounted volume in a running container, that the manager isnotable to access. Is this possible?
[2018-04-26 22:38:30] <briantyr> hey guys, does anyone use ECR for an easy to setup registry without using ECS?   I have my own Swarm cluster setup on Ec2 instances, provisioned with tform and will bootstrap on launch to join an existing cluster of EC2 instances.  Just wondering if anyone has experience or recommendation on a registry for a 6-12 node cluster to pull from. ECR backed by AWS S3 seems to be the easiest solution at first
[2018-04-26 22:40:01] <briantyr> Another option is to run the official registry backed by S3 on multiple nodes in the cluster, or something like gitlab maybe
[2018-04-26 22:45:27] <ianseyer> artifactory
[2018-04-26 22:45:43] <ianseyer>  [<-LINK->] 
[2018-04-26 22:55:00] <ianseyer> ECR will give you trouble because it rotates the password every few hours
[2018-04-26 22:55:12] <ianseyer> so you have to use theawsclito generate a new one
[2018-04-26 23:25:50] <justinhj> You can use a cron job to renew it, but since it's a fast operation we just make$(aws ecr get-login --no-include-email)part of the deploy script
[2018-04-26 23:26:35] <justinhj> We use ECR without ECS, pretty happy with it
[2018-04-27 01:50:29] <farukhkhan21_twitter> Hey Guys, for a docker production bare metal if I have the option to from any of these processors which one I should take? What you guys recommend? Intel  Xeon-D 1540 - 8c/16t - 2.1GHz /2.6GHz     /      Intel  Xeon E3-1270v6 - 4c/8t - 3.8GHz /4.2GHz     /     Intel  i7-7700K - 4c/8t - 4.2GHz /4.5GHz
[2018-04-27 03:57:21] <zebralight> hello. I was wondering if I have port 5432 already used for my system postgresql server and I want to use the same port for one of my docker containers as specified in my docker-compose.yml, would I be able to configure it such that an available port can be selected automatically without breaking the compose?
[2018-04-27 08:14:25] <Tochemey> Hello Geeks. I am having some challenges running netcore on docker. Any time I run the docker build command I got the following error: [<-CODE->] Please assist I am battling with this for two days now. I am new to docker
[2018-04-27 11:44:44] <roychri> farukhkhan21_twitter: That really depends on the kind if load you will need, and your budget.
[2018-04-27 11:46:30] <roychri> zebralight: You can have different containers listening on the same port internally since they are isolated with namespace. However, you cannot map a container to a port on your host which is already being used on your host. So if you have postgres running in your host and listening to port 5432, you cannot have a containers which have its internal port mapped to port 5432 on your host at the same time.
[2018-04-27 11:52:24] <farukhkhan21_twitter> roychri: planning to host web servers. So containers like nginx, mysql, httpd, php-fpm etc.
[2018-04-27 16:16:22] <thymbahutymba> Hi guys
[2018-04-27 19:42:03] <roychri> farukhkhan21_twitter: It depends on so much factors like (are you going to run one container per machine? Are you expecting much traffic? What's your budget? Did you benchmark your app to see if its more CPU or Memory hungry?).  In the end, you have to make the call. I certainly wont pick the hardware for you! :)
[2018-04-27 22:12:28] <thymbahutymba> Someone can help me with adb inside docker? When i'm running container sometimes smartphone it's detected and sometimes no.
[2018-04-28 02:23:53] <farukhkhan21_twitter> roychri: I got your point. will certainly do these before selecting. Thanks man.
[2018-04-28 08:37:47] <farukhkhan21_twitter> Guys is there any news about the docker engine support for latest Ubuntu Server 18.04 LTS?. Is there any docker LTS version? or just stable and edge releases? And is there any performance, stability and security improvements of using 18.03 over 17.12?
[2018-04-28 16:01:29] <zacharycarter> good morning - I had a docker daemon running on a digital ocean droplet and uh, it kind of just crapped out on me after a while... I was unable to get the docker service running again through systemd
[2018-04-28 16:01:52] <zacharycarter> if I run a systemctl status on the service, I see logs like - [<-CODE->] 
[2018-04-28 16:02:13] <zacharycarter> is there a way to troubleshoot this issue?
[2018-04-28 16:02:34] <zacharycarter> I don't really have much other information about how / why it died - or know how to get at that data
[2018-04-29 16:36:09] <campbs> hey i have a question, I am using postgres in docker for development and i was wondering is there a way i can run migrations ?
[2018-04-29 21:23:35] <nb9791_twitter> Hello everyone, I would like to ask if it is possible to build a docker infrastructure and allow my friends to run their containers? Do I need to give them admin access or is there a way to do it without giving them full access to my machine
[2018-04-30 00:20:58] <mateothegreat> nb9791_twitter: you could give them remote access to the docker API using TLS certificates
[2018-04-30 06:30:12] <nb9791_twitter> mateothegreat: Thank you very much
[2018-04-30 07:37:51] <nb9791_twitter> I have a use case in which I have installed Docker and I want to allow users to run their containers without having the root access. Each user should be able to have access only to their container. I will be acting as a docker engine provider and the users will act as clients that run their containers. Do you think that this is possible? If so can you please direct me to some examples. Thank you
[2018-04-30 10:40:17] <Mohanrajcr> Hi everyone
[2018-04-30 12:00:28] <ldacey> I have a folder on my host machine with files - can I shutil those to another folder on my host machine
[2018-04-30 18:40:00] <SOSC20_twitter> Yes you can  ive seen examples of this on Docker forums online. Particulary between Windows dockers
[2018-04-30 18:44:10] <SOSC20_twitter> I've seen a great app on android store called docker tutorial it mentions docker volumes on there too
[2018-05-02 05:15:32] <zebralight> hello. I don't fully understand what a container is, since I initially imagined it to be something that only exists when running an image and goes away upon stopping it.  That's why the idea of a stopped container is confusing.
[2018-05-02 06:21:48] <babaorum> zebralight: there is a little more to it. Compared to your image, your container can have special "configuration" like extra environment variables or a custom run command, or a volume, etc. Stopping a container, is keeping all those informations.
[2018-05-02 15:58:27] <zebralight> babaorum: thank you
[2018-05-02 16:00:56] <zebralight> I'm trying to deploy a containerized node app onto heroku following the tutorial here: [<-LINK->] and working off of my previous experience with using docker locally and I was wondering if there are any heroku specific params I need to account for in my Dockerfile, such as the ports to expose
[2018-05-02 19:20:43] <davi578> Hello Guys!!
[2018-05-02 19:21:03] <webertrlz> using docker-compose, how do I run a contianer in an external bridge network with fixed IPV4 + an "external" host network?
[2018-05-02 19:39:02] <davi578> Hello Guys,I'm looking for American developers, those who wanna listening the idea contact to me. I appreciate.
[2018-05-03 04:07:02] <harshana5> anyone here played with docker-machine and vsphier
[2018-05-03 17:07:24] <maceacherndjh> How do I rebuild this image [<-LINK->] with latest mutillidae?
[2018-05-03 17:13:20] <tbugfinder> docker build
[2018-05-04 09:04:50] <backendr>  [<-CODE->]  [<-CODE->]  [<-CODE->] Is this due to the read-only layer below the uppermost write layer?
[2018-05-04 10:15:23] <pedroparraortega> hi guys!!! one question…. is it possible to define a different name for a .dockerignore file name???? i mean, set an option to choose the dockerignore file to use
[2018-05-04 10:15:38] <pedroparraortega> i can not find any reference and it would be nice….
[2018-05-04 18:03:56] <webertrlz> anyone has hints of exploring serf capabilities with docker for micro services architecture?
[2018-05-04 18:09:28] <deepio> backendr: have you tried copy instead of add? Can you do ‘docker exec -it <container> bash’ change it, and then try accessing it? Do an ‘ls -al’ too
[2018-05-04 18:11:24] <deepio> pedroparraortega: as far as I know, you can not.
[2018-05-05 18:13:24] <rizanamic_twitter> How to cache layers in Docker multistage build?
[2018-05-07 06:51:15] <jasperf> Does anyone have an example how to load an ssl cert off a volume?
[2018-05-07 06:52:41] <johannwagner> jasperf: Build or Execution Time?
[2018-05-07 06:54:57] <jasperf> johannwagner: well, for a new production setup with commercial wildcard I would like the nginx container to load the cert off the host when possible. So I am looking for the best way to do this is the nginx Docker file. Thought of connecting host to container and store cert on the host, but not sure if that is the best way and how I would do this
[2018-05-07 06:56:02] <johannwagner> You can mount in the folder with the certificate anywhere in the nginx-Container and load it from file system as normal with the nginx.conf.
[2018-05-07 06:56:46] <johannwagner> I can give you an example in 30m, on mobile right now.
[2018-05-07 06:58:06] <jasperf> Aha. Yeah, an example would be great. I also understood mounting is not the same as using volumes and that the latter might be better? Still learning.. Anyways. Look forward to example so I can understand it all better.
[2018-05-07 07:00:12] <jasperf> See also my remarks on it at [<-ISSUE->] where they were discussing a similar setup..
[2018-05-07 07:04:28] <johannwagner> Mounting a volume into a Docker container means using a volume. Sorry for Inconvenience.
[2018-05-07 07:17:10] <jasperf> Aha OK. Thanks@johannwagner. Looking forward to the example
[2018-05-07 07:40:21] <jasperf> johannwagner: tinkering here now with it [<-LINK->] 
[2018-05-07 09:38:06] <jasperf> Also was wondering how everyone installs app packages in workspace.. in /var/www/ Do you create a non root user for this? Seems like the best way especially when running stuff such as composer in web root..
[2018-05-07 09:53:41] <jasperf>  [<-LINK->] 
[2018-05-07 12:57:08] <matrixbot> michioneHi guys, does anybody know how to build an executable with pyinstaller in a windows docker container? Is it possible to start a windows container in Linux?
[2018-05-08 14:04:41] <webertrlz> just to confirm
[2018-05-08 14:05:08] <webertrlz> I can't have a container running simultaneously on a HOST and on a OVERLAY network, right?
[2018-05-08 15:08:11] <LachlanGunn> Hello.  Is there some way to get make a device node accessible within a container at build time?
[2018-05-08 15:09:19] <LachlanGunn> --deviceseems to only with when I dodocker run, not withdocker build.
[2018-05-08 22:10:08] <mohamedaittaleb> Help !Can I sshroot@ip_container ? I need it to test ansible playbooks
[2018-05-09 01:58:01] <justinhj> docker exec -it containername bash
[2018-05-09 01:58:43] <justinhj> will that work for you@mohamedaittaleb
[2018-05-09 07:10:24] <Ahmadbaba> Hello guys, I just want a solution in order to manage the branches through bitbucket and test every branch on its own image. Please can you help
[2018-05-09 07:31:45] <mohamedaittaleb> justinhj: unfortunately not ! I need to use containers like machines
[2018-05-09 08:40:26] <yuetianle> compose
[2018-05-09 08:43:41] <power-man> I don't like your avatar@yuetianle。
[2018-05-09 09:19:29] <empwilli> Hi folks, I ran into some trouble with my setup (which usually works quite fine), hope someone can help me
[2018-05-09 09:20:25] <empwilli> In a nutshell, I've got a virtual bridge device with some containers and a single container with apache which plays as a reverse proxy to these containers
[2018-05-09 09:20:34] <empwilli> This container is bound to the hosts ports
[2018-05-09 09:21:09] <empwilli> In my setup I rely on the fact that (in principle) all containers may reach themselves via their hostnames
[2018-05-09 09:21:48] <empwilli> However, I've ran into trouble with one specific container now from time to time and as i've found after some restarts, docker inspect shows that it has another IP than a ping from the apache container
[2018-05-09 09:21:49] <empwilli> :/
[2018-05-09 09:22:10] <empwilli> I hope this was clear enough, otherwise I'm glad to clarify some details ;)
[2018-05-09 09:24:26] <empwilli> Strange enough, the other containers seem to resolve the address correctly (docker exec A ping -c 3 Target vs. docker exec apache2 ping -c 3 Target)
[2018-05-09 09:29:08] <empwilli> If I query docker network inspect I get the IP address, returned by docker inspect Target (not the one apache2 tries to ping to)
[2018-05-09 09:39:23] <empwilli> Aaah, I might have found the error. I copy-paste-reused my docker-compose files and the service names of the unreachable container and another container (the one whos IP address is wrongly resolved) match.. idk why both compose files work after all
[2018-05-09 09:39:24] <empwilli> :/
[2018-05-09 10:36:38] <carlosjgp> mohamedaittaleb: Then you have to install an ssh server and configure your keys on it, like you would do with a VM.
[2018-05-09 10:42:01] <iamfrntdv> Hi everyone! Recently we have built small tool called Pocok [<-LINK->] . and i thought it might be interesting for docker users
[2018-05-09 11:01:46] <mohamedaittaleb> carlosjgp: I managed to do it :D  thanks
[2018-05-09 14:09:53] <UNIcodeX> hello. I have never used docker before and am trying to pull in the diginc/pi-hole docker container. It keeps saying Tag {tag} not found in repository diginc/pi-hole. How can I find out which tag to use?
[2018-05-09 16:27:58] <hadirsa> Hi guys!. I have an issue about running  mysql on docker, MySQL extremely slow. is there any one faced this issue?
[2018-05-09 16:28:20] <hadirsa> Any solution?
[2018-05-09 16:29:15] <hadirsa> Environment: Ubuntu 16.04 and Docker 17.12.0-ce, build c97c6d6
[2018-05-09 16:29:24] <carlosjgp> UNIcodeX:  [<-LINK->] ?
[2018-05-09 16:31:11] <carlosjgp> hadirsa: I don't think that is related to Docker. But check how much memory/cpu is using and if it's enough for your MySql config requirements
[2018-05-09 16:31:42] <carlosjgp> hadirsa:  [<-LINK->] 
[2018-05-09 16:32:19] <hadirsa> iamfrntdv: Pocokwas great. 
[2018-05-09 17:23:33] <hadirsa> carlosjgp: Thanks. I try and share results. 
[2018-05-10 00:20:20] <dishankmehta> Hey Guys, I have to use dotnet for the compilation of a library where my base image inside the dockerfile is python:2.7 any ideas how can i compile this library using this single dockerfile?  I am relatively new to the docker.
[2018-05-10 15:24:39] <carrowheap> Hello EveryOne,I am a beginner with docker and am on a project with php on ubuntu but there is imcopatibility version php, I thought used docker, someone can guide me to have a development environment php on docker (PHP, MYSQL, LAMP) or suck me a tutorial
[2018-05-10 15:46:30] <Jeyanthinath> carrowheap: PM me
[2018-05-10 17:32:17] <carrowheap> Jeyanthinath: Do you have a suggestion for my problem?
[2018-05-11 05:19:39] <Jeyanthinath> carrowheap: I need to see your docker file and your setup before commenting on thta
[2018-05-11 10:13:49] <alex-ppg> Hello all, I need help with a Dockerfile that constantly fails.
[2018-05-11 10:16:03] <alex-ppg> The error is "Illegal Instruction (core dumped)" and it happens when I try to callnpm install -g grunt-cli. I have installed npm through [<-LINK->] and the commandscommand -v nodeandcommand -v npmactually do have output (/usr/local/bin/node & /usr/local/bin/npm perspectively).
[2018-05-11 10:17:05] <alex-ppg> The error actually happens even if I callnpm -vornode -vwhich is strange. I have also tried runningapt-get update --fix-missingto no avail.
[2018-05-11 10:35:32] <babaorum> If you execute your command from an official node image, does it work ?
[2018-05-11 10:38:41] <babaorum> If it does, your install is not good, if it does not your command is not good
[2018-05-11 11:22:21] <carrowheap> hello everyone, i\'ve a problem when i execute my container with " sudo docker exec -it php7dev bash  "i\'ve  Error response from daemon: Container b5b2cc2c7959fd64eb0962b601d7f44b357c3feb7f64065755146c49ae1ecc21 is not running
[2018-05-11 11:22:57] <empwilli> carrowheap: well, is your php7dev container running?
[2018-05-11 11:22:58] <empwilli> :)
[2018-05-11 11:23:17] <empwilli> if you want to keep it running you have to have there a process in it which doesn't die
[2018-05-11 11:23:25] <empwilli> ```
[2018-05-11 11:23:41] <empwilli>  [<-CODE->] 
[2018-05-11 11:24:28] <carrowheap> empwilli: how to run ? i'm verry beginner with docker world
[2018-05-11 11:25:09] <empwilli> There are some ways of doing that, it depends on what you want to use the container for
[2018-05-11 11:25:20] <empwilli> What do you want to do with your container?
[2018-05-11 11:25:40] <Jeyanthinath> which command you used to run the docker ?
[2018-05-11 11:26:46] <empwilli> stackoverflow has some advises on this: [<-LINK->] 
[2018-05-11 11:26:51] <empwilli> however this seems crude :D
[2018-05-11 11:27:07] <carrowheap> i want to clone on a php project
[2018-05-11 11:28:19] <empwilli> i think then the option specified on stackoverlow might be sufficient
[2018-05-11 11:29:52] <carrowheap> thanks
[2018-05-11 11:32:00] <carrowheap> empwilli: you save my time, thanks
[2018-05-11 11:32:16] <empwilli> :)
[2018-05-11 12:31:44] <ptink> is baking code into an image(s) generally better than using volumes? I have a repo that contains both static files (that I'd like to bake into the nginx image) and webserver code (that I'd like to bake into the webapp image) but I'm struggling to think of a good way to create two images from one command (and be able to tag them with the same release)
[2018-05-11 12:32:14] <ptink> i was looking at multi-stage builds but that just creates one image at the end
[2018-05-11 12:32:41] <ptink> and I'll have an app container and an nginx container
[2018-05-11 12:33:27] <kelley999> Hi, there is a way to set mounted volumes as writable?
[2018-05-11 13:19:14] <mohamedaittaleb> Any Certified guy in  Docker here ? :)
[2018-05-11 13:22:51] <empwilli> ptink: : as usual: It depends ;). I think for deploying it's better to have the static code baked into an image, for working on the code volumes are fine
[2018-05-11 13:22:56] <empwilli> (imho)
[2018-05-11 22:11:10] <Ako92> hi there . i want to add wordpress container in [<-LINK->] route and django app in api.example.com and example.com for serve react app. but i have problem with serving wordpress app in /mag what kind of stack should is use to this. i try jwilder/nginx and even traefik but i cant find any solution to do this. is there anyone that can help me to find the right solution ?
[2018-05-13 02:51:45] <vwzv> Hello ?
[2018-05-13 02:52:33] <vwzv> I need help from pro coder .. please pm me
[2018-05-13 09:59:49] <Deviad>  [<-ISSUE->] 
[2018-05-13 09:59:55] <Deviad> Could anyone please help me with this?
[2018-05-13 10:00:27] <Deviad> I managed to find all of the workarounds to get till there, but when I restart the container it forgets the vhost.conf that I save
[2018-05-13 10:00:34] <Deviad> I am using a volume to persist data.
[2018-05-15 01:02:34] <philipmoniaga> Hi anyone has experience ssh from inside docker to other subnetwork in gcp?
[2018-05-15 01:02:55] <philipmoniaga> i always got public key denied but i already add to authorized_keys
[2018-05-15 02:24:19] <jasperf> Found [<-LINK->] that prepares the playground for Docker using an Ansible playgroup. Very useful. But what it misses is an example Ansible setup and the playbook to push Docker files into the host machine after the preparation. Anyone found playbooks for that?
[2018-05-15 02:25:50] <jasperf> Also working on a production setup at [<-LINK->] based on Laradock for Laravel which I may combine with Ansible Docker. Anyone knows of a github or bitbucket repo where ports were set and network done properly for a production environment? Seems 99% of the information out there is development only
[2018-05-15 02:33:20] <jasperf> @Deviad  can you show the code to see how vhost.conf is saved? Laradock uses [<-CODE->]  [<-CODE->] 
[2018-05-15 02:37:24] <jasperf> You seem to be adding it with a node script.  But in what volume are you storing it?
[2018-05-15 12:02:14] <ptink> if I have a collection of static files to serve via nginx, but I also wish to use nginx as a reverse proxy for my webapp (potentially in a different repository) is it best to have 2 separate nginx images and therefore containers running?
[2018-05-15 12:02:50] <ptink> otherwise I worry that I have to store e.g. the config for the webapp portion of nginx in the repo with the static files
[2018-05-15 12:07:02] <marcko> I use nginx as a reverse proxy and nginx or apache in the container. works for me.
[2018-05-15 12:15:59] <ptink> I'm not sure I follow, so you have two separate nginx images/containers?
[2018-05-15 12:21:43] <marcko> yes. I think it's better to have each service in a container and use nginx as a reverse proxy. but I'm probably wrong
[2018-05-15 16:29:53] <revisualize> Greetings, Does anyone know of a good intro to Docker video course? I learn best by watching and doing. (not by reading) ... and hopefully, free. Thanks in advance.
[2018-05-16 06:38:37] <ManikantThakur> Greetings Everyone! I am stuck with the common problem that a dockerized nginx running in the proxied mode, does not pass client's real IP to subsequent containers.
[2018-05-16 06:41:13] <ManikantThakur> Deviad: How about mapping your vhost.conf as well? I mean make use of volume, and mark the file as ReadOnly(RO). So the file modification can be only one way. Containers consuming vhost.conf cannot modify the files content, it can only read it. Make the changes on the host machine, restart the web container, and your web container will spin up with new conf.
[2018-05-16 14:11:46] <brjadams> trying to get a centos7, python 2.7, apache2.4 docker image set up
[2018-05-16 14:12:09] <brjadams> having issues with apache and the best way to get compose working
[2018-05-16 16:34:44] <ShazIndia> Hi..I am creating conatiner with non-root user , and I want to assign previliage same as root user. Is any way to achieve it
[2018-05-16 17:34:35] <davi578> revisualize: Nanosai.comcontact with them. Very good team which are very interesting to help everyone.
[2018-05-16 18:07:30] <ivarec> I'm trying to configure AWS CloudWatch logging on my Docker Swarm stack using the .aws/credentials strategy, but it is not working: the files are in place in all nodes, but I get the following error: [<-CODE->] Do I need to restart the Docker daemon? How can I debug this further?
[2018-05-16 18:11:35] <ivarec> Oh, well, it seems I do need to restart the Docker daemon and also make changes to my systemd setup: [<-LINK->] 
[2018-05-16 19:26:04] <ivarec> The above solution worked, in case anyone bumps into this in the future
[2018-05-17 08:25:34] <ParasRocks> minio distibuted on diff machine how i do this ??
[2018-05-17 08:32:49] <Alek2012> Hi All! Please help,  How can I add a proxy to all images at once ?
[2018-05-17 08:33:40] <Alek2012>  [<-LINK->] not work
[2018-05-17 08:55:20] <longlivefreddymercury_gitlab>  [<-LINK->] 
[2018-05-17 15:54:08] <deepio> Within a dockerfile, if you just declareVOLUME /some/pathand no other path (eg:VOLUME /local/path /container/path), what is the local folder that gets attached inside the container?
[2018-05-17 17:35:02] <jdgiotta> How does docker distribute to nodes in swarm mode? Is there a strategy?
[2018-05-17 17:35:56] <jdgiotta> Is it simply round robin or does stats come into play?
[2018-05-17 22:19:48] <pavel-sindelka> Hey guys! I have a problem... I cant connect to my node app from browser! What is wrong? [<-CODE->]  [<-CODE->] 
[2018-05-17 23:31:56] <pavel-sindelka> From container bash viacurlit works fine but from browser not 
[2018-05-18 00:16:07] <pavel-sindelka> ouu I must use publish flag-p 3000:3000but I dont understant why to writeEXPOSE 3000
[2018-05-18 02:09:43] <brjadams> i need an image with centos7, python2.7 and httpd. Anyone got a good starting image? Suggestions?
[2018-05-19 06:14:51] <zhuhuizhan> how to stop a container which was created with "restart=always” ?   docker stop  ,docker rm -f , doesn’t work ,it always created a new container after a few seconds , could someone give any tips  plz ?
[2018-05-19 17:27:27] <ParasRocks> hey guys, how to give absolute path in minio volume configuration in docker swarm??
[2018-05-19 17:29:15] <ParasRocks> Please help me on this, i need to connect two diffrent docker network to run migration and connect it to running cassanda instance both on diff network ?
[2018-05-20 16:07:09] <dstockhammer>  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] Does anybody have an idea what I could be doing wrong? I'm on latest Docker for Windows.
[2018-05-20 16:15:43] <dstockhammer> oops, just read that this chat is meant to be contributor only. sorry!
[2018-05-21 09:40:54] <ManikantThakur> pavel-sindelka: EXPOSE 3000 just run the service to accept the connection on the said port, but it doesn't exposes to the external network.-pflag does expose the port to external network. Docker Network and System/Host network are two completely different network. Try creating one more container and front this container, access you new container, assuming you have named the new container as node_container, like curl [<-LINK->] . You should see the response because both are running on the same network, docker network.
[2018-05-21 09:43:11] <ManikantThakur> dstockhammer: Is nginx installed on your container ?
[2018-05-21 09:46:27] <ManikantThakur> zhuhuizhan: Try withdocker update --restart=no <container_id OR container_name>
[2018-05-22 05:44:03] <ParasRocks> ??
[2018-05-23 08:54:07] <s17t> Hello, does anybody know if is possible to flush internal dns server (127.0.0.11), is there something rndc for bind ?
[2018-05-23 14:03:38] <dmi3zkm> Does anyone have experience running akka cluster on top of docker swarm cluster ?I see weird things happening after docker upgrade from17.09to18.03.Akka cluster sometimes fails to bootstrap as long as akka cluster node which has configurationakka.remote.netty.tcp.hostnamespecified fails to start and goes to endless restart loop.
[2018-05-24 06:37:22] <rowild> Good morning! Is this the place to ask question about docker? (I am a newbie...) Or is this just for contributors? If the latter, could you recommend a place, where I could ask for beginner's help? Thank you!
[2018-05-24 06:40:15] <comeUpWithItLater> hello ,   I mapped a volume in stack.yml file (marked in red ) .  afterdocker stack delpoy **I can see the some files inside container dir (marked in orange) , but no files in my host machine dir (marked in orange). what am i missing?
[2018-05-24 06:40:24] <comeUpWithItLater>  [<-LINK->] 
[2018-05-24 10:00:33] <SofianeB> Hi, does anyone know if it is possible to sync docker volumes to DropBox-like services (ownCloud/NextCloud)?
[2018-05-24 10:19:51] <comeUpWithItLater>  [<-LINK->] run a dropbox container as well , and make it share the same volume with  your main service
[2018-05-24 10:42:28] <SofianeB> Thank you@comeUpWithItLater. Actually, we don't want to deploy an instance of DropBox in-premise. We have a shared repository (NextCloud) and I want that containers volume can be synced to that repository.
[2018-05-24 10:44:31] <hrt031293> Hello everyone,Can anyone here, tell me how to copy a file from my local storage to a docker container..Thanks in advance, for your answer.
[2018-05-24 10:46:09] <SofianeB> hrt031293: docker cp file container:filewhen container is running. Of course you can copy files using Dockerfile when you build the image.
[2018-05-24 10:49:13] <hrt031293> SofianeB: OK, and how to create a container?Help me with this also
[2018-05-24 10:49:56] <SofianeB>  [<-LINK->] 
[2018-05-24 10:59:26] <hrt031293> SofianeB: Thanks for the help
[2018-05-24 12:00:12] <deepio> General question, I’m training a CNN in a specific docker service, the service crashes as the swap memory gets full. It’s like if it stores everything from each epoch of the CNN instead of automatically deleting what isn’t used anymore. Are there settings I need to expose for a sort of autoclean to happen?
[2018-05-24 23:02:09] <kongakong> If you run your CNN trainning on your host directly, does the same problem happen? (it is the first step to identify the root cause)
[2018-05-25 03:33:39] <i5uhail> Hi All, Just curious to know why the celery official image in docker is marked as deprecated. Any one aware of it ?
[2018-05-25 06:28:44] <trinathtiru> how to remove the dead containers?
[2018-05-25 06:29:34] <NaveedSaleem_twitter> trinathtiru: docker container rm <container id> will remove it
[2018-05-25 06:30:10] <NaveedSaleem_twitter> or ideally you should pass—rmwhile running container, it will be autometically removed on exit
[2018-05-25 06:30:33] <trinathtiru> yes it works but after restart of docker service( service docker restart)
[2018-05-25 06:30:38] <trinathtiru> again it is showing under docker ps -a
[2018-05-25 06:30:43] <trinathtiru> with dead state
[2018-05-25 06:31:10] <NaveedSaleem_twitter> strange it never happend to me
[2018-05-25 06:31:31] <trinathtiru>  [<-LINK->] 
[2018-05-25 06:31:44] <trinathtiru> people accross the same situation
[2018-05-25 06:31:56] <trinathtiru> i just googled and find this
[2018-05-25 06:32:44] <NaveedSaleem_twitter> interesting…..
[2018-05-25 06:37:18] <trinathtiru> i tried diff ways
[2018-05-25 06:37:23] <trinathtiru> its not working for me
[2018-05-25 06:37:50] <trinathtiru> docker rm $(docker ps --all -q -f status=dead)
[2018-05-25 06:40:40] <trinathtiru> Thanks@NaveedSaleem_twitterfor the info
[2018-05-25 06:40:46] <trinathtiru> after deleting the process id
[2018-05-25 06:40:53] <trinathtiru> i dont see the issue any more
[2018-05-25 06:42:16] <NaveedSaleem_twitter> trinathtiru: I did nothing…you solved it yourself :), thanks to you for sharing interesting problem
[2018-05-25 07:19:27] <rowild> Hi! I am a beginner, working through the "Getting started" on docker.com. In part 4 I try to make myvm2 to join the swarm, but I keep getting an error message: [<-CODE->] If I immediately repeat the join, the Terminal responds with another error: [<-CODE->] So myvm2 actually was added to the swarm. But what happened in step 1? Why is it not possible to add it to the swarm? Do I have to increase a timeout value anywhere?Would like to understand, what is going on here... thank you for your tips!
[2018-05-25 07:32:04] <trinathtiru> Are you able to see the myvm2 under docker node ls
[2018-05-25 07:32:05] <trinathtiru> ?
[2018-05-25 07:32:25] <trinathtiru> rowild: 
[2018-05-25 07:35:43] <rowild> trinathtiru: there I only see one line, and it does not say neither myvm1 nor myvm2...
[2018-05-25 07:36:01] <rowild>  [<-CODE->] 
[2018-05-25 07:36:38] <trinathtiru> in which machine you ran this command?
[2018-05-25 07:45:44] <rowild> directly on the command line: [<-CODE->] Do I have to do sth like [<-CODE->] ?It does not say so on the tutorial site...
[2018-05-25 07:45:56] <rowild> BTW: thank you for helping me!!!!
[2018-05-25 08:40:11] <rowild> Did you meandocker-machine ls?
[2018-05-25 08:40:31] <rowild> trinathtiru: because there I can see my machines...
[2018-05-26 17:26:47] <WolfspiritM> I have a very strange behaviour and was wondering if that\'s supposed to happen. I have a docker-compose project that contains a service called "identity" and a service called "api". They both are linked via an internal network. Also I have an external network called "proxy" for a reverse proxy which is also connected to both of them. Then I do a "docker stack deploy ... dev" and a "docker stack deploy ... prod" which results in dev_api and prod_api. When I then do a call to " [<-LINK->] " from within dev_identity I sometimes end up on the prod_api container so the service discovery is cross-stack somehow through the proxy network. Any idea how I can fix that without having to explicitly call dev_api from within the container?
[2018-05-27 06:25:03] <Datazource> guys, kubernetes inside docker or docker inside kubernetes ?kubernetes manage docker isn't it ?
[2018-05-27 17:07:54] <justinhj> There's a nice diagram here [<-LINK->] Docker has integration with Kubernetes so it can run on top of Kubernetes just like it runs on top of Swarm
[2018-05-27 23:54:08] <DinoSourcesRex> Does anyone know if Docker for Windows supports Windows and Linux containers side by side yet? I've got the latest version of Windows 10 and Docker for Windows and I successfully pulled down a linux image using--platform linux, however the container just exists as soon as I start it.
[2018-05-28 03:05:02] <wlopez-enkoding> Hey people ! I'm trying to run a container that works on my Mac but on my Raspberry Pi, it's sending me an error about processor architecture arm/x64... so... is not that simple to accomplish it ?
[2018-05-28 03:05:22] <wlopez-enkoding> or is it imposible ?
[2018-05-28 16:51:14] <deepio> kongakong: yes the CNN works fine outside of docker.
[2018-05-28 16:51:59] <deepio> Swap memory fills up and the docker container crashes
[2018-05-28 16:53:24] <badape-net> i am using a very simple docker-compose to start postgres and pgadmin i am on windows if that makes a difference, but the error i get is ERROR: for postgres  Cannot start service postgres: b'driver failed programming external connectivity on endpoint aresws_postgres_1 (4e86fbb08676f9226254f84aecba071abf6f1004c886f65104c0e449ed80dd4c): Error starting userland proxy: mkdir /port/tcp:0.0.0.0:5432:tcp:172.19.0.2:5432: input/output error'
[2018-05-28 16:53:34] <badape-net> weird mkdir /port?
[2018-05-28 16:56:43] <deepio> You have something else using that port@badape-net
[2018-05-28 16:57:01] <badape-net> pretty sure i don't
[2018-05-28 16:57:58] <deepio> You don’t have progres installed or running on your windows machine at all
[2018-05-28 16:57:59] <badape-net> netstat doesn't show anything
[2018-05-28 16:58:19] <badape-net> that is the first thing i thought, did i install psql and forget, but no i didn't
[2018-05-28 16:59:26] <badape-net> i thought maybe, the network being setup as bridge
[2018-05-28 17:00:14] <deepio> Provide your docker-compose file
[2018-05-28 17:01:09] <badape-net>  [<-LINK->] 
[2018-05-28 17:09:36] <badape-net> hmm it really doesn't like the ports directive
[2018-05-28 17:26:24] <badape-net> i wonder could it be the windows firewall doing this?
[2018-05-28 17:33:41] <badape-net> weird everything fails, even normal docker, i wonder if things broke on the last update
[2018-05-28 18:49:21] <deepio> I’m on latest docker, no issues today. Must be specific to your working environment@badape-net
[2018-05-28 18:54:21] <badape-net> i fixed it by reinstalling docker
[2018-05-28 18:54:29] <badape-net> not idea what caused the problem
[2018-05-28 18:54:42] <badape-net> i thought i had a default install
[2018-05-29 00:34:06] <deepio> Guys, inside a docker service, I have a celery job that runs a CNN. The service crashes every time I run it, but it runs a little longer when I give it more swap memory. Solutions? Yes, the CNN works fine outside of docker.
[2018-05-29 11:18:28] <SkyNetDZ> Hi , I have a error to build image with maven plugin to docker I get this errorFailed to execute goal com.spotify:docker-maven-plugin:0.4.3:build (build-and-tag) on project oscar-back: Exception caught: ADD failed: no source files were specified -> [Help 1]
[2018-05-29 13:01:12] <nickvermeer> Hey all. Quick question. Is Docker Compose considered acceptable for deploying production groups of containers when they all reside on a single server?
[2018-05-29 13:01:54] <nickvermeer> I don't really need a whole swarm solution as I only have one machine for the foreseeable future.
[2018-05-29 14:29:10] <zillerium> I am new to docker. Can docker be used to deploy a UI (react) onto different machines?
[2018-05-29 14:51:10] <justinhj> There’s no reason I can think of that isn’t a good idea Nick. We run our prod and staging as swarms but development and qa environments are single machine docker compose
[2018-05-29 20:57:14] <deepio> nickvermeer: use docker-compose. Definitely recommended. As you grow, use Kubernetes instead of swarm. That will allow you to orchestrate turning down machines for 24/7 up-time.
[2018-05-29 20:57:58] <deepio> zillerium: short answer, yes.
[2018-05-29 21:00:13] <deepio> Can anyone help with my memory leak issue? Using keras/theano inside of a celery service, inside docker.
[2018-05-29 23:53:34] <nickvermeer> deepio: thanks
[2018-05-30 00:37:45] <hwkd> deepio: how's Kuberbetes
[2018-05-30 00:38:06] <hwkd> better than swarm?
[2018-05-30 00:40:55] <hwkd> swarm also has a mechanism called "desired state reconciliation" to ensure that your containers are in the desired state (according to your specs) which means your containers will be up 24/7 unless you specify otherwise.
[2018-05-30 00:46:36] <deepio> hwkd: I never said it was better or worst. Kubernetes is more of an industry standard. It will be more helpful job wise if you work with that one anyway. Many companies are backing it, being open sourced from google after all.
[2018-05-30 00:50:38] <hwkd> Well you did mention to use Kubernetes instead of swarm. Just wanted to clear that out.
[2018-05-30 03:35:59] <rightisleft> is it possible to sethost.docker.internalto resolve to a local domain?
[2018-05-30 03:36:15] <rightisleft> IE: if i havelocal.fish.comon my host - i'd add an entry to/etc/hosts
[2018-05-30 03:37:32] <rightisleft> theextra_hostsparam seems to only allow IP addresses
[2018-05-30 06:51:56] <vladislavkovaliov> hi all,Is is possible to pass arguments when i am runningdocker runand gettin it in dockerfile?
[2018-05-30 06:52:54] <ManikantThakur> vladislavkovaliov: Question not clear.gettin it in dockerfile?means ?
[2018-05-30 06:55:35] <vladislavkovaliov> I mean I am running docker with arguments and i need to get these arguments in Dockerfile.So far so good? 
[2018-05-30 06:56:16] <ManikantThakur> what your docker arguments ?
[2018-05-30 06:58:55] <vladislavkovaliov> docker run --rm -it myImage "QA"
[2018-05-30 06:59:00] <vladislavkovaliov> like this
[2018-05-30 07:02:02] <vladislavkovaliov> and i need to get "QA"
[2018-05-30 08:29:19] <trinathtiru> HI all
[2018-05-30 08:29:41] <trinathtiru> after giving docker ps in my machine
[2018-05-30 08:29:45] <trinathtiru> i am not able to see the versin
[2018-05-30 08:30:25] <trinathtiru> sorry tag
[2018-05-30 09:46:07] <trinathtiru> Hello any inputs?
[2018-05-30 09:46:55] <empwilli> trinathtiru: : You see the running container with container ID and image ID?
[2018-05-30 09:47:30] <trinathtiru> yes i am able to see the container running and there i can see the tag as well
[2018-05-30 09:47:41] <trinathtiru> but when i am giving docker images
[2018-05-30 09:47:44] <trinathtiru> it is not showing
[2018-05-30 09:48:40] <empwilli> I'm sorry, I don't quite understand your problem? What information do you want to retrieve how?
[2018-05-30 10:05:17] <trinathtiru>  [<-LINK->] 
[2018-05-30 10:05:26] <trinathtiru> when i am giving docker images
[2018-05-30 10:05:30] <trinathtiru> i could see none
[2018-05-30 10:06:10] <trinathtiru> empwilli: 
[2018-05-30 10:06:33] <trinathtiru> it was supposed to be tag
[2018-05-30 10:06:35] <trinathtiru> id
[2018-05-30 10:40:53] <empwilli> are you certain that you have assigned a tag on building?
[2018-05-30 10:40:59] <empwilli> i've got a couple of images without tags
[2018-05-30 15:08:08] <trinathtiru> in my dockerfile
[2018-05-30 15:08:11] <trinathtiru> i have given
[2018-05-30 15:08:12] <trinathtiru> FROM confluentinc/cp-schema-registry:3.3.1
[2018-05-30 15:08:21] <trinathtiru> empwilli: 
[2018-05-30 22:08:13] <ghost~597346d7d73408ce4f6e4c8f> Hi everyone I developed spring rest api.I used spring boot mysql and redis(for session).I deployed my app to digital ocean droplet.I installed mysql and redis in droplet and run spring boot app.App is working properly.Now I want to containerize my app.Is this process necessary for you?What is the best scenario?I am new to the Docker.Thanks for everything.
[2018-05-31 16:06:02] <rightisleft> is there a way to make 'extra_hosts' available to all services in a stack?
[2018-05-31 17:15:41] <sangam14> hi everyone I'm started blog on docker  codexplus.in. those who wanted to learn and trending updates or basics of docker please visit to codex plus.in   #docker
[2018-05-31 23:24:13] <fridgerator> has anyone experienced/var/lib/docker/aufsexploding with disk space?Docker version 17.03.2-ce, build f5ec1e2
[2018-06-01 07:19:33] <kayvanbree> Hello everybody!
[2018-06-01 07:20:42] <kayvanbree> I have a declarative pipeline for testing Angular in Jenkins, but I get no logs in Jenkins: [<-CODE->] 
[2018-06-01 07:21:04] <kayvanbree> How can I get logs from both stages? Unit tests are now failing, but I don't know why
[2018-06-01 07:21:12] <kayvanbree> hmmmm
[2018-06-01 07:21:48] <kayvanbree> seeing it wth actual syntax highlighting I see --browsers CHromiumHeadless is outside the '
[2018-06-01 07:21:56] <kayvanbree> But still, how can I get logs?
[2018-06-01 16:30:26] <deepio> Where can I find SysOps best practices for migrating, backing up, and maintaining docker volumes (not bind mounts). I'm using it to hold my postgres data, as described in the docs.https://docs.docker.com/storage/volumes/
[2018-06-02 20:56:31] <challapradyumna> How to add username and password to docker-compose.yml private image
[2018-06-02 22:13:41] <dragon9783> Environment?
[2018-06-04 13:13:37] <puxos> use secret
[2018-06-04 14:30:13] <papaiatis> Hi guys. Any idea why creating the layers takes way too much time?Even the WORKDIR command takes around 60 seconds to finish.Is it because my build context is 282MB?
[2018-06-05 03:58:32] <mateothegreat> that's kinda big
[2018-06-05 03:58:53] <mateothegreat> try changing to a remote daemon for giggles and see
[2018-06-05 21:38:06] <SalathielGenese> Hi everyone,
[2018-06-05 21:38:29] <SalathielGenese> I'm glad to join this room
[2018-06-05 21:38:57] <SalathielGenese> So, naturally I'm coming with a question
[2018-06-05 21:41:37] <SalathielGenese>  [<-CODE->]  [<-CODE->]  [<-CODE->] with... [<-CODE->] ...and remove... [<-CODE->] ???
[2018-06-05 22:45:01] <stantonxu> withcd /ci-cd-build-pubsub, you just move to that folder for following commands in the Dockerfile. if you don’t setWORKDIR, by default it is/
[2018-06-06 00:17:43] <lukepighetti> Hey guys, where's the best place to ask beginner questions?
[2018-06-06 00:19:57] <lukepighetti> I have an express app that runs fine withnode app.json port 8081, but when I launch it with docker-compose and expose port 8081 I cannot access it
[2018-06-06 00:20:11] <lukepighetti> I have tried explicitly listening on0.0.0.0and no luck
[2018-06-06 03:49:54] <puxos> try ports instead of expose [<-CODE->] 
[2018-06-06 06:03:46] <jdevillard> Hello guys , have you some best practices or framework to manage docker container from a container ( to create new container instance depending functionnal requirement or to start small process with small duration and with specific configuration ) (like poll a specific queue for 5 min)
[2018-06-06 06:32:48] <puxos> jdevillard: 3 suggestions.try out some container orchestration tools, like portainer, shipyard, kubernetes, etc. Those tools could run as a container to manage other containers, see if it satisfies you.\nFor only small and specific tasks like start several containers to queue for 5 mins, you could use some automation system, such as Rundeck, create your scheduler and fire the task towards docker’s api to get things done.\nif 1 & 2 cannot solve the problem, you might need to write some plugins stuff on existing orchestration tools or on your own system, and likely need more efforts.
[2018-06-06 06:37:26] <aliuk2012> hi, I seem to have a lot of /var/lib/docker/aufs/mnt and /var/lib/docker/containers using up a lot of space. They seem to be from previous older containers that no longer available. How do I remove these old mounted volumes?
[2018-06-06 06:37:33] <jdevillard> puxos: , thanks for the answer,  I know certains of this tools and it could be usefull to not have to reimplement RBAC to deploy new container.  But indeed, I've to implement my own logic, so now I can launch my dev! thx
[2018-06-06 06:39:56] <ShazIndia> aliuk2012: have you deleted the old container
[2018-06-06 06:40:18] <ShazIndia> using docker rm -f conatiner-id
[2018-06-06 06:40:53] <aliuk2012> ShazIndia: unfortunately yes 
[2018-06-06 06:41:17] <aliuk2012> # df\nFilesystem     1K-blocks    Used Available Use% Mounted on\nudev             1018964      12   1018952   1% /dev\ntmpfs             204836     600    204236   1% /run\n/dev/xvda1       8115168 7915052         0 100% /\nnone                   4       0         4   0% /sys/fs/cgroup\nnone                5120       0      5120   0% /run/lock\nnone             1024172    2328   1021844   1% /run/shm\nnone              102400       0    102400   0% /run/user\nnone             8115168 7915052         0 100% /var/lib/docker/aufs/mnt/2bbca927ca8e4d0b89a63ebdb0ebef0ad19f78e49ac135f30797af17424ffcdc\nshm                65536       0     65536   0% /var/lib/docker/containers/1d2cd0bc2da00c589e4689b1a4adea7cbaf1f35790eb795c0e823e3de6219809/shm\nnone             8115168 7915052         0 100% /var/lib/docker/aufs/mnt/2a8d9da166159a2839ac7ef7e939e5ef40487123419e1db10d9004983b8c25b2\nshm                65536       0     65536   0% /var/lib/docker/containers/7c1eb60abd09283b9d60caf1531ab031251a1411b2d2540971a4643d1aa7ef3f/shm\nnone             8115168 7915052         0 100% /var/lib/docker/aufs/mnt/51ace26d65f3f689a432597ef534f14c655b7663a287c6172a863eb7666b190a\nshm                65536       0     65536   0% /var/lib/docker/containers/dbcbd190ed44fe06211ca637ad603d7b55762256f3b92d48936cb7168b10a053/shm\nnone             8115168 7915052         0 100% /var/lib/docker/aufs/mnt/a20b4a94a1e545e6070e4cfd7815977f27110524e3ab6c756f72bbed043319b4\nshm                65536       0     65536   0% /var/lib/docker/containers/9607a6d1b85c6620e33ab7173fba7b7cb73fc20c1d7999112d983c5734cf952f/shm\nnone             8115168 7915052         0 100% /var/lib/docker/aufs/mnt/4e63db77b58d342e8cbec6b4424f0a0a25a5ddff5e2f4e03a0a21ddde42e65b2\nshm                65536       0     65536   0% /var/lib/docker/containers/de2f55e7069d0347776dee5242b1e3470364b1a7a92f802fcbfe17a903242230/shm
[2018-06-06 06:42:30] <ShazIndia> can you run this command
[2018-06-06 06:42:31] <ShazIndia> docker volume ls -qf dangling=true
[2018-06-06 06:42:55] <aliuk2012> that returns nothing
[2018-06-06 06:43:19] <ShazIndia> docker volume rm $(docker volume ls -qf dangling=true)
[2018-06-06 06:43:21] <ShazIndia> try this
[2018-06-06 06:43:37] <ShazIndia> or docker prune
[2018-06-06 06:43:46] <ShazIndia> docker volume prune
[2018-06-06 06:46:32] <aliuk2012> first command fails: ""docker volume rm" requires at least 1 argument(s)"
[2018-06-06 06:46:51] <aliuk2012> I'm assuming because $() is returning null
[2018-06-06 06:47:46] <aliuk2012> second command: prune is not a command
[2018-06-06 06:48:14] <aliuk2012> third command
[2018-06-06 06:48:19] <aliuk2012> ```# docker volume pruneUsage:    docker volume COMMANDManage Docker volumesOptions:      --help   Print usageCommands:  create      Create a volume  inspect     Display detailed information on one or more volumes  ls          List volumes  rm          Remove one or more volumesRun 'docker volume COMMAND --help' for more information on a command.```
[2018-06-06 06:49:40] <ShazIndia> can you paste output of this
[2018-06-06 06:49:43] <ShazIndia> sudo df -h /var/lib/docker/aufs
[2018-06-06 06:50:24] <ShazIndia> sudo du -sh /var/lib/docker/aufs/mnt
[2018-06-06 06:51:04] <aliuk2012> first command
[2018-06-06 06:51:10] <aliuk2012> Filesystem      Size  Used Avail Use% Mounted on\n/dev/xvda1      7.8G  7.6G     0 100% /var/lib/docker/aufs
[2018-06-06 06:51:38] <aliuk2012> second
[2018-06-06 06:51:42] <aliuk2012> 2.1G    /var/lib/docker/aufs/mnt
[2018-06-06 06:52:45] <ShazIndia> sudo ls /var/lib/docker/aufs/mnt|wc -l
[2018-06-06 06:53:20] <ShazIndia> sudo ls /var/lib/docker/aufs/mnt|head
[2018-06-06 06:53:23] <aliuk2012> 154
[2018-06-06 06:53:30] <ShazIndia> hmmmm
[2018-06-06 06:53:58] <aliuk2012>  [<-CODE->] 
[2018-06-06 06:54:47] <ShazIndia> okay
[2018-06-06 06:54:57] <ShazIndia> this is on amazon right ?
[2018-06-06 06:55:15] <ShazIndia> Can you restart the ec2 instance
[2018-06-06 06:55:27] <aliuk2012> could do
[2018-06-06 06:55:29] <aliuk2012> one sec
[2018-06-06 06:56:26] <aliuk2012> are you thinking that prehaps a process is still holding on to the space?
[2018-06-06 06:56:37] <ShazIndia> yes
[2018-06-06 06:56:42] <ShazIndia> high chance
[2018-06-06 06:58:11] <ShazIndia> Is this production
[2018-06-06 06:58:24] <ShazIndia> or any plaground
[2018-06-06 07:00:10] <aliuk2012> just staging at the moment.
[2018-06-06 07:00:14] <aliuk2012> WOW that looks better
[2018-06-06 07:00:23] <aliuk2012> # df\nFilesystem     1K-blocks    Used Available Use% Mounted on\nudev             1018964      12   1018952   1% /dev\ntmpfs             204836     472    204364   1% /run\n/dev/xvda1      16369496 7795072   7804148  50% /\nnone                   4       0         4   0% /sys/fs/cgroup\nnone                5120       0      5120   0% /run/lock\nnone             1024164     252   1023912   1% /run/shm\nnone              102400       0    102400   0% /run/user\noverflow            1024       0      1024   0% /tmp\nnone            16369496 7795072   7804148  50% /var/lib/docker/aufs/mnt/c048d573662f4d6af98354fcc00e2a672294744e705b0e4f9990395ba50600ab\nshm                65536       0     65536   0% /var/lib/docker/containers/b829878baa69cf56477f2ebe7ecae823968b95b20dfe1c08cccd88b670ad6e6d/shm\nnone            16369496 7795072   7804148  50% /var/lib/docker/aufs/mnt/dc1d64b81a09b0fdeb3ed73a4621bddcaf4a76e00bc1fd0e545c75eca3d99c86\nshm                65536       0     65536   0% /var/lib/docker/containers/d0649bb0df392437b738941bb367417e9b3c69443c1d8d51ec6279a79a00a539/shm\nnone            16369496 7795072   7804148  50% /var/lib/docker/aufs/mnt/4ffd3f41936aa4368613a0ed3dd0464697da51fd32d323f5c67ca00a20d9f5ea\nshm                65536       0     65536   0% /var/lib/docker/containers/956435206ca29223e5e4d6ce378410060a4190ddfb293749aa3419c24f8d2849/shm
[2018-06-06 07:01:04] <ShazIndia> can you run this sudo ls /var/lib/docker/aufs/mnt|wc -l
[2018-06-06 07:01:25] <ShazIndia> sudo du -sh /var/lib/docker/aufs/mnt
[2018-06-06 07:01:28] <aliuk2012> 171
[2018-06-06 07:02:05] <aliuk2012> 2.4G    /var/lib/docker/aufs/mnt
[2018-06-06 07:02:10] <ShazIndia> fuck
[2018-06-06 07:02:19] <ShazIndia> okay
[2018-06-06 07:03:21] <ShazIndia> ubuntu machine or centos ?
[2018-06-06 07:05:35] <aliuk2012> ubuntu
[2018-06-06 07:05:44] <ShazIndia> 14.04
[2018-06-06 07:06:04] <aliuk2012> yes
[2018-06-06 07:06:23] <aliuk2012> what do you think is the issue?
[2018-06-06 07:08:24] <ShazIndia> sudo docker rm $(docker ps -a -q)sudo docker rmi --force $(docker images -q)sudo docker system prune --forcesudo service docker stopsudo rm -rf /var/lib/docker/aufssudo apt-get autocleansudo apt-get autoremovesudo service docker start
[2018-06-06 07:08:52] <ShazIndia> I think it's not able to free up the space
[2018-06-06 07:08:59] <ShazIndia> try this
[2018-06-06 07:12:10] <aliuk2012> first command cant remove running container
[2018-06-06 07:12:38] <aliuk2012> same with the second
[2018-06-06 07:12:42] <ShazIndia> run this
[2018-06-06 07:12:45] <ShazIndia> only
[2018-06-06 07:12:46] <ShazIndia> sudo service docker stopsudo rm -rf /var/lib/docker/aufssudo apt-get autocleansudo apt-get autoremovesudo service docker start
[2018-06-06 07:13:15] <aliuk2012> sorry the second command did clear out some images
[2018-06-06 07:13:29] <ShazIndia> sudo rm -rf /var/lib/docker/aufs
[2018-06-06 07:13:32] <ShazIndia> this one
[2018-06-06 07:15:23] <aliuk2012> sudo service docker stopsudo rm -rf /var/lib/docker/aufssudo apt-get autocleansudo apt-get autoremovesudo service docker start
[2018-06-06 07:15:33] <aliuk2012> i've run all this
[2018-06-06 07:15:55] <ShazIndia> still space not freed up
[2018-06-06 07:19:03] <aliuk2012> it worked :-)
[2018-06-06 07:19:14] <aliuk2012> thank you so much for you time
[2018-06-06 07:19:14] <ShazIndia> cool
[2018-06-07 11:24:14] <DinoSourcesRex> Hey everyone. [<-CODE->] 
[2018-06-07 14:51:09] <DrMabuse23> hello
[2018-06-07 14:51:26] <DrMabuse23> anyone maybe knows a cantos6 armv7 image ?
[2018-06-07 14:51:34] <DrMabuse23> centos6
[2018-06-07 15:12:59] <papaiatis>  [<-LINK->] check this out
[2018-06-07 15:13:38] <papaiatis>  [<-LINK->] 
[2018-06-07 15:14:04] <papaiatis> that's the closest I found
[2018-06-07 15:16:48] <DrMabuse23> thx a lot
[2018-06-08 01:35:36] <gching> who here has ran into problems withmultipart/form-databetween containers with a network bridge
[2018-06-08 01:35:45] <gching> right now connections are being dropped
[2018-06-08 01:42:25] <gching> or specifically the docker network doesn't like chunked data
[2018-06-08 13:43:14] <kelley999> Hi, anyone know how use host variable or command result in Dockerfile?
[2018-06-08 13:44:04] <kelley999> i want to add same user as host while building
[2018-06-09 02:16:55] <puxos> @kelley999 Try —build-argIn Dockerfile, write ARGs you want to pass in like below: [<-CODE->] and then build the image with —build-arg as following: [<-CODE->] 
[2018-06-09 02:18:25] <puxos> you can use myVar in Dockerfile as ${myVar}
[2018-06-12 18:14:39] <QubitGG> Hey all! I'm trying to create a new container and connect it to an existing container, but I can't seem to get it right... [<-CODE->] I'm trying to get the new container to talk to the mongo container that is already running on the 'app-net' network, but I can't seem to get it right... What am I doing wrong here?
[2018-06-12 18:17:29] <QubitGG> I can connect to the mongo container from the host terminal, so I don't think that is the issue.
[2018-06-12 19:09:35] <papaiatis> Hi all! I\'d like to automate a docker build process to run every day that creates fresh images from our software.How can I make sure that docker build always pulls down the latest base image? It\'s tagged  "ubuntu:rolling".Should I just delete this image before calling docker build ?
[2018-06-12 20:17:09] <QubitGG> alternatively (and preferably) how might I do it in a docker-compose.yml? [<-CODE->] still didn't work... [<-CODE->] is what I end up.
[2018-06-12 20:17:35] <QubitGG> And yes, setting the local port to 37017 is intentional
[2018-06-12 22:54:26] <DinoSourcesRex>  [<-CODE->] That's a docker-compose I have that builds an image to seed my mongodb.@QubitGG
[2018-06-12 22:57:39] <justinhj> papaiatis: our work flow for this is to just destroy the container if it is running and start it again. Docker should download the updated image if it has changed
[2018-06-12 23:19:10] <QubitGG> DinoSourcesRex: I'm not sure what you mean by seed. Could you explain?
[2018-06-12 23:26:13] <DinoSourcesRex> QubitGG: The purpose of the image isn't really relevant to the example of interconnectability however it basically calls mongorestore and restores an existing backup into an empty mongodb
[2018-06-12 23:32:38] <QubitGG> after reading through [<-LINK->] I understand a little better. But I'm still left a little curious, is seeding required to make the link work?
[2018-06-13 05:30:22] <bboyle1234> QubitGG: , here is an example docker-compose.yml file that I use successfully with mongo. Some notes:MongoExpress lets you view the mongo db (very helpful)\nI think your problem probably lies in not specifying the correct port in your mongodb connection string, since you're using a non-standard port. See my example of a correctly-formatted connecdtion string and use it, just modify the port.\nNo need for you to specify the external default networks. The compose file will run well without the networks section. I use it because I have a couple of docker-compose files that I like to run during dev that need to talk to each others' containers, so I put both on the external dev network. [<-CODE->] 
[2018-06-13 12:33:35] <QubitGG> bboyle1234: thank you! The problem was that I was actually using the wrong container name for my mongo container. This is an excellent piece of reference though, thanks!
[2018-06-13 18:01:31] <brjadams> so I have an image, it's building and pushing to my private registry. Now I want to run an instance of that image/container on another linux host. This is where I'm having some hangups about the best way to do this. I have a dockerfile, as well as a docker compose that works when I run on my local machine.
[2018-06-14 09:24:45] <papaiatis> so that dockerfile should work just fine on your another linux host if the image is correctly defined in the FROM clause
[2018-06-14 09:25:33] <papaiatis> like  FROM myprivateregistry/my-own-imagewhere myprivateregistry points to your host where the registry runs
[2018-06-14 09:49:18] <bboyle1234> it's my dev machine docker file ;)
[2018-06-14 13:25:46] <alex-ppg> Hey guys, quick question.
[2018-06-14 13:26:01] <alex-ppg> I'm having an issue with executing a command inside a container.
[2018-06-14 13:28:36] <alex-ppg> If I run: [<-CODE->] And then on the bash shell of the container I run my command it works correctly with no issues. However, if I do this: [<-CODE->] It fails to execute correctly. I have even tried using a workaround in the following way: [<-CODE->] and [<-CODE->] With both failing because the container is not TTY while executing the standalone command works.Any ideas?
[2018-06-14 13:30:39] <alex-ppg> To clarify, the command itself is not failing, it throws an error that otherwise does not appear by executing it directly. [<-CODE->] 
[2018-06-14 14:50:34] <brjadams> so, are compose files only really meant for local machines?
[2018-06-14 14:50:52] <brjadams> I have a compose, which runs my app, memcached, and postgres server locally, just fine.
[2018-06-14 14:51:17] <brjadams> I've got the build process figured out, and I'm pushing an image to a private remote registry.
[2018-06-14 14:51:34] <brjadams> I want to now have another remote machine run that image as a container.
[2018-06-14 15:00:53] <papaiatis> a compose file is used to run multiple containers in one stepyou can copy this file anywhere you want and execute it there
[2018-06-14 15:33:18] <brjadams> problem is, it's in the project path, and uses sh files and such to build and execute.
[2018-06-15 03:03:59] <mateothegreat> brjadams: you could set your DOCKER_HOST environment variable and communicate with the remote machines docker daemon directly.
[2018-06-15 07:19:28] <dekaisekai_twitter> hi
[2018-06-15 07:28:33] <frankablat> alex-ppg: I think you can post specific commands .Becausebash -cis running normally on my machine .
[2018-06-15 07:41:11] <dekaisekai_twitter> @alex-ppg try something like thisdocker run -it busybox sh -c "pwd; ls -lrt"
[2018-06-15 07:41:58] <dekaisekai_twitter> to get the current directory and list up/total 36drwxr-xr-x    2 root     root         12288 May 22 17:00 bindrwxr-xr-x    4 root     root          4096 May 22 17:00 vardrwxr-xr-x    3 root     root          4096 May 22 17:00 usrdrwxrwxrwt    2 root     root          4096 May 22 17:00 tmpdrwx------    2 root     root          4096 May 22 17:00 rootdrwxr-xr-x    2 nobody   nogroup       4096 May 22 17:00 homedr-xr-xr-x   13 root     root             0 Jun 15 07:40 sysdr-xr-xr-x  163 root     root             0 Jun 15 07:40 procdrwxr-xr-x    1 root     root          4096 Jun 15 07:40 etcdrwxr-xr-x    5 root     root           360 Jun 15 07:40 dev
[2018-06-15 07:51:38] <dekaisekai_twitter> @brjadams  As @mateothegreat have mentioned already,try to write all external variables and host information in a file names .envFor the images, suppose your private repository have it as dtr.example.com/brjadams/memcashed name, so accordingly change the image name in the docker-compose file.
[2018-06-15 10:24:11] <s8sachin>  [<-CODE->]  [<-CODE->]  [<-CODE->] please help, thanks :)
[2018-06-15 11:17:20] <coachdonhigh_twitter> So did anyone answer the question what’s the difference between bash -c, I’m really curious , I see bash -c and sh -c a lot in Docker and Kubernetes
[2018-06-15 20:30:51] <CuddleBunny> hey folks, I am getting started with docker today with Windows containers and can't figure out why loop back isn't working. Apparently it was fixed in the Windows 10 April update, which I have (v 17134.112) but I can only access my containers via ip and not localhost.
[2018-06-15 20:31:22] <CuddleBunny> docker itself is v 18.03.1-ce-win65
[2018-06-15 20:56:49] <CuddleBunny> eh, looks like this is a "known issue" even if it\'s fixed in Windows... does anyone have insight on this?
[2018-06-16 06:31:40] <Aravindios> I'm using Jenkins inside the docker so its get Xcode path error                                                                                           when I'm build my project its falls error.FATAL: Cannot find xcodebuild with the configured path /usr/bin/xcodebuild.FATAL: Cannot find xcodebuild with the configured path /usr/bin/xcodebuild.Build step 'Xcode' marked build as failureFinished: FAILURE
[2018-06-16 21:29:21] <DinoSourcesRex> A very basic question: if I start a container what happens when I:a) exit dockerb) turn off / restart the host machineDo the containers restart when docker starts up again the next time, data intact?
[2018-06-17 10:41:07] <christhomas> anybody here know much about nginx/phpfpm setups?
[2018-06-17 10:41:47] <christhomas> I’ve got my phpfpm container with all my source code in it but I’m getting a Primary script unknown from the nginx container, does this mean I need to mount my phpcode into the nginx container too?
[2018-06-17 15:18:50] <kylegordon_twitter> DinoSourcesRex: if you exit docker, as in stop the docker process, your containers will exit
[2018-06-17 15:19:10] <kylegordon_twitter> if you restart the machine, the behaviour of the container will depend on the restart policy applied to the container
[2018-06-17 15:19:25] <kylegordon_twitter> I often have 'unless-stopped' as my restart policy, so they will start back up automatically
[2018-06-17 15:19:35] <kylegordon_twitter> unless, of course, I have manually stopped them with docker stop foo
[2018-06-17 16:07:29] <DinoSourcesRex> kylegordon_twitter: Thanks for the info. I'll probably have to play around a little to check the behaviour myself. I've got a DB container and a DB seed container and want to know how it will behave under certain circumstances.
[2018-06-17 23:49:00] <deepio> I’m having a memory issue with docker
[2018-06-17 23:49:54] <deepio> CPU is running hot, df isn’t showing anything growing inside the container, but running docker status I see the memory growing on a container
[2018-06-17 23:50:12] <deepio> *specific service sorry
[2018-06-17 23:50:50] <deepio> Eventually I think the memory will just hit a sealing and crash, but I don’t know why it’s not being flushed
[2018-06-17 23:52:05] <deepio> I’m also getting multiple 906 errors messages from the celery/Django app within docker
[2018-06-18 03:32:14] <Muishadi9_twitter> I want to loading this site free from malware spam and bug thanks
[2018-06-18 14:27:39] <rcjsuen> IfmyimageDockerfile already containsEXPOSE 80. Is$ docker run --expose 80 myimagethen redundant/unnecessary?
[2018-06-19 06:27:31] <trinathtiru> what is the diff between organization and repositories in dockerhub
[2018-06-19 06:38:27] <trinathtiru> is repository nothing but as image?
[2018-06-19 07:22:37] <trinathtiru> Any inputs?
[2018-06-19 10:13:41] <trinathtiru> Hello All
[2018-06-19 10:14:00] <trinathtiru> can i run the kitematic using vmware workstation?
[2018-06-19 12:29:26] <rcjsuen> trinathtiru: maybe this will help [<-LINK->] 
[2018-06-19 13:48:02] <trinathtiru> rcjsuen: thanks
[2018-06-20 09:31:03] <papayuca> Hey guys, I just started with docker and would have very dumm beginner question. When I make an image for my app, how do I go about after updating the app code? Do I build the image again or what is a common practice for this process? Generally how to go about with docker when developing?
[2018-06-20 09:53:04] <rcjsuen> papayuca: YMMV > should includedocker buildin your CI pipeline.
[2018-06-20 09:53:19] <rcjsuen> when you release changes to your branch, it'll build > tag > push
[2018-06-20 09:53:49] <rcjsuen> what I do is tag every build with my Git commit SHA-1 (and of course also tagginglatest)
[2018-06-20 09:53:57] <rcjsuen> Although of courselatestis not the greatest of tags
[2018-06-20 09:54:14] <rcjsuen> when I finally release a version I manually tag and push (of course that can be CI-automated also)
[2018-06-20 14:58:16] <danielo515> Hello everyone!
[2018-06-20 14:58:48] <danielo515> Does anybody know if I can install a package on a early stage on a multi stage build and use it on the next stages ?
[2018-06-20 15:11:43] <rcjsuen> Almost sounds like you should use that as the base stage of the other ones...
[2018-06-20 15:12:10] <danielo515> I was thinking that
[2018-06-20 15:12:36] <danielo515> In fact if I use it for copying files it works perfectly, files are persisted
[2018-06-20 15:13:05] <danielo515> But, I want certain packages available on the final image without all the overhead and temp files that apt-get update generates
[2018-06-21 15:45:03] <liwenjun1988> Hi everyone, I'm new to docker world. I want to use gitlab to build a docker image. May I ask if anyone knows if multiple docker files can be hosted in the same project or need to be kept in different project? Thanks!
[2018-06-21 15:46:04] <rcjsuen> Dockerfiles are just files, you can have as many of them as you want
[2018-06-21 15:46:16] <rcjsuen> I think you might want to rephrase your question or state what you want to achieve.
[2018-06-21 15:54:05] <liwenjun1988> Sorry my question is a little bit vague. Basically I put a dockerfile in a gitlab project, and use a gitlab-ci.yaml to build the image. so I can use gitlab.com:[port][/path]:master as docker image. Now I want to create a second docker image, and not sure if i can put it in the same project.
[2018-06-21 16:13:33] <rcjsuen> Hm, sounds like you are using GitLab as your registry for Docker images instead of Docker Hub, correct?
[2018-06-21 16:57:51] <liwenjun1988> Right.
[2018-06-21 17:05:36] <rcjsuen> Well, I feel like a registry and a Git repository shouldn't really be related.
[2018-06-21 17:05:56] <rcjsuen> You could check with the GitLab folks. But certainly I can have a folder of 3 Dockerfiles and build, tag, and push them all to Docker Hub anyway.
[2018-06-21 17:46:28] <liwenjun1988> Sure, i think it might be the possible approach for me to put them in different folders and modify gitlab-ci.yaml file to build/push them all. Thanks!@rcjsuen
[2018-06-21 17:48:17] <rcjsuen> OK, good luck!
[2018-06-22 07:00:54] <fatmatto> Hello everyone! I have a noob question about docker-machine: I configured my first (existing) host (google cloud compute vm instance) with it, the host had a couple containers running on it, after configuring it with docker machine (from my laptop) every container and every image was removed, does docker-machine cause a re-provision of the instance? (volumes were also gone)
[2018-06-22 10:40:59] <SalathielGenese> Hi guys,I'm somehow new to docker, with node stack and microservices - [<-CODE->]  [<-CODE->]  [<-CODE->] I now want to have node_modules/ scoped to container only - not on my host
[2018-06-22 10:42:00] <SalathielGenese> But I don't know how to achieve this, not even if that's possible
[2018-06-22 11:46:13] <SalathielGenese> Hi folks,This stackoverflow answer helped me
[2018-06-22 11:53:01] <SalathielGenese> I want to fix a pixel-like detail now,I'm mounting some GCloud credentials' file in docker-compose volumes. Mounting project folder for reasons above described now have that file in my host project folder. It also hapen that many dev are working on the same project, each having its own Google Service Account credential file, with different credentials. My question is whether I can mount that credential file into docker container and not have it on my host.I know I can git ignore for each of us working on it with each ones disctinct file name but would like to have a higher level and more elegant solution, regardless of who work on the project or rename its credentials' file.Thank You Very Much.
[2018-06-22 12:02:42] <SalathielGenese> May be I ought to provide example - [<-CODE->]  [<-CODE->] 
[2018-06-22 12:22:03] <SalathielGenese> When applying the previous technique, I get that file:empty on host\nfilled in containerThis just not enough
[2018-06-22 17:23:37] <keller0> SalathielGenese: you can't use ../ for volume's path, try absolute path .
[2018-06-22 18:55:48] <venesh0709> I restarted the docker container.......the container started and exited so quick
[2018-06-22 18:55:55] <venesh0709> why is that happening?
[2018-06-22 19:11:54] <rcjsuen> What do you mean
[2018-06-22 19:11:58] <rcjsuen> it restarted "too fast"?
[2018-06-22 19:13:31] <venesh0709> docker restart container id
[2018-06-22 19:13:35] <venesh0709> docker ps
[2018-06-22 19:13:43] <venesh0709> container is up and running
[2018-06-22 19:13:50] <venesh0709> docker ps after some seconds
[2018-06-22 19:13:58] <venesh0709> container exited already
[2018-06-22 20:07:23] <rcjsuen> Can't say I've seen that before
[2018-06-22 20:07:29] <rcjsuen> or when I have the logs told me the error in my ways
[2018-06-22 20:09:28] <SalathielGenese> Hi, @keller0I'm not sure why it does not work on your side, but it have been working great for me -
[2018-06-22 20:30:34] <SalathielGenese> Hello folks,My solution was to mount my file in a container folder out of /app (/lic in my case) [<-CODE->] 
[2018-06-22 20:32:10] <SalathielGenese> It works great and solve my problem, each team member can follow this pattern and we'll avoid filling gitignore with each one's value
[2018-06-23 17:20:38] <dansok> hi everyone, im experimenting with docker. trying to create a container with python and pandas, and mount a few data files that i have in my directory onto the image. I created the following dockerfile and successfully created the image -- [<-CODE->] 
[2018-06-23 17:20:50] <dansok> now im not sure how to procceed
[2018-06-23 19:50:00] <keller0> SalathielGenese: sorry, it'sCOPYthat cant use../as src, I was wrong.
[2018-06-23 19:53:23] <keller0> dansok: Have you read this guid? [<-LINK->] 
[2018-06-24 23:16:26] <danieldram> is registry-1.docker.io down? When I try to pull an image on any machine I get a 503?
[2018-06-24 23:56:37] <romanar> danieldram: its fixed now
[2018-06-25 11:44:58] <etherealjoy> Hello All
[2018-06-25 11:46:05] <etherealjoy> How can I switch  dockerd to fully HTTP operation without setting the registry as insecure. We need this because we are sitting behind a proxy and we don't want to reload the daemon whenever we need to deploy something new from another registry
[2018-06-25 11:46:51] <etherealjoy> We have our own Registry and the proxy is handling the job of authentication and other things
[2018-06-25 13:13:01] <bizmate> hi folks, what are the best metrics to consider for your container footprint in terms of memory, cpu etc
[2018-06-25 13:13:11] <bizmate> how would you measure it?
[2018-06-25 13:21:35] <etherealjoy> Linux or windows?
[2018-06-25 13:21:56] <bizmate> linux
[2018-06-25 13:34:45] <etherealjoy> dops auxhfcheck your app pid
[2018-06-25 13:35:09] <etherealjoy> do /proc/pid/status
[2018-06-25 13:35:58] <etherealjoy> you can check many things there
[2018-06-25 14:55:52] <scheiblr> Hi I just used a docker image with latest and now wanted to use an older version of it. When I run it using docker-compose up, I get [<-CODE->] How can I remove all that old content and start new from 0?
[2018-06-26 08:45:28] <scheiblr> got it, was something different..
[2018-06-26 08:46:39] <gabegm> Hi there!I am trying to create a docker image to run a flask web app but I also need to run a python script on the side which uses a scheduler so the script is always running.From what I’ve seen it’s not possible to have docker run both the flask app and the python scheduler together.Is there a better way to do this?
[2018-06-26 09:25:16] <bhalothia> scheiblr: I'm planning to upgrade too. Please share your solution.
[2018-06-26 09:26:33] <bhalothia> Hello everyone, has anyone added container scanning phase to their pipelines using Clair or similar tool? If it's on gitlab then even better. Please share your experience.
[2018-06-26 09:26:54] <scheiblr> bhalothia: I'm currently developing, thus it wasn't really a 'solution' for any production system. Just removed the volumes on the host and it ran again. Upgrading should work as always.
[2018-06-26 09:28:11] <bhalothia> Okay, I'm currently on gitlab-ee:10.8.4-ee.0 and I'm in no hurry to upgrade. I think I will wait.
[2018-06-26 09:29:50] <scheiblr> Are you using a docker registry together with gitlab? I'm currently trying to get that up and running inside one docker-compose.yml ..
[2018-06-26 09:30:09] <bhalothia> yep
[2018-06-26 09:30:24] <bhalothia> Yeah, i'm using docker registry behind a proxy.
[2018-06-26 09:30:45] <bhalothia> It's the same compose, managing all the components.
[2018-06-26 09:39:37] <bhalothia>  [<-LINK->] 
[2018-06-26 10:39:04] <uzayr> Is there any plugin for docker to give ssh access ?
[2018-06-26 10:39:11] <uzayr> for the container
[2018-06-26 12:15:04] <babaorum> gabegm: why not use 2 docker containers for that ? If you want to execute two different tasks ?
[2018-06-26 12:15:58] <bizmate> two containers is the way
[2018-06-26 12:17:13] <gabegm> how would that work exactly?I currently have a dockerfile which sets everything up and runs gunicorn to start the web serverhow would I be able to have another container which can access the sqlite db file from the first container?
[2018-06-26 12:17:35] <bizmate> you should run three containers then
[2018-06-26 12:17:41] <bizmate> sql lite separately
[2018-06-26 12:17:51] <bizmate> never run two jobs/processes in one container
[2018-06-26 12:18:39] <gabegm> sqlite is just a file tho, so it doesn’t need its own container
[2018-06-26 12:18:45] <bizmate> although sql lite is a file only system if i remember when still abstract it into a separate container
[2018-06-26 12:19:08] <bizmate> then you just mount it through a volume
[2018-06-26 12:19:17] <bizmate> and use the volume in both containers
[2018-06-26 12:19:21] <gabegm> so how would I do this? create a seperate dockerfile and share the same volume between both containers?
[2018-06-26 12:19:28] <bizmate> yes
[2018-06-26 12:19:42] <bizmate> also use docker-compose
[2018-06-26 12:20:00] <bizmate> it is a much nicer way of displaying your microservices components
[2018-06-26 12:20:09] <gabegm> can docker-compose automatically run both dockerfiles?
[2018-06-26 12:20:26] <bizmate> yes
[2018-06-26 12:20:29] <bizmate> thats the point
[2018-06-26 12:20:29] <bizmate>  [<-LINK->] 
[2018-06-26 12:20:56] <bizmate> see how i run all the separate containers for this sample rabbitmq apps powered with php
[2018-06-26 12:21:09] <gabegm> also, since it’s a seperate dockerfile, do I need to recreate the anaconda (python) environment I would have created in the other dockerfile?
[2018-06-26 12:21:36] <gabegm> bizmate: oh cool you can link to the dockerfile!
[2018-06-26 12:21:40] <bizmate> i must say I am not familiar with pythons architecture
[2018-06-26 12:21:47] <bizmate> the docker files are there
[2018-06-26 12:21:49] <babaorum> Only if you need it (not familiar too)
[2018-06-26 12:21:49] <bizmate> see the paths
[2018-06-26 12:22:26] <gabegm> okay I’ll give it a go!thanks for the help guysstill new to docker :)
[2018-06-26 12:23:18] <babaorum> no problem. Start with docker composer (it will be easier to connect everything and tweek it for your tests)
[2018-06-26 12:25:33] <gabegm> Will do! thank you :)
[2018-06-26 15:07:45] <deathgaze> All of docker’s logging options are too complicated — is there a way I can get docker-compose to just dump all my logs to a predefined text file or folder full of text files?
[2018-06-26 15:07:55] <deathgaze> Can anyone point me in the right direction?
[2018-06-26 15:39:36] <rcjsuen> Docker Compose if not in detached mode should just log to the terminal IIRC
[2018-06-26 15:39:42] <rcjsuen> You can redirect stdout/err to a file then I suppose
[2018-06-26 15:41:23] <bizmate> deathgaze: dont be depressed and just do it right
[2018-06-26 15:42:21] <deathgaze> Don’t have time to do it right, user wants log files
[2018-06-26 15:42:32] <deathgaze> Should be easy, but docker is making it very complicated
[2018-06-26 15:42:44] <deathgaze> user doesn’t want to have to type docker commands to view logs
[2018-06-26 15:43:02] <bizmate> manual logs just the way you want it wont scale
[2018-06-26 15:43:05] <bizmate> logging is not simple
[2018-06-26 15:43:17] <bizmate> it will work for a few minutes
[2018-06-26 15:43:25] <bizmate> you will have to do it again
[2018-06-26 15:43:41] <bizmate> just use syslog or something similar
[2018-06-26 15:44:00] <bizmate> the so called user doesnt need to know where the application is running on
[2018-06-26 15:44:47] <deathgaze> so I would have to run a syslog server on the host machine (for example) and then let the user use some tool to connect to it?
[2018-06-26 15:46:46] <bizmate> or better use an hosted service
[2018-06-26 15:46:56] <bizmate> so you dont even need to manage it
[2018-06-26 16:42:04] <deathgaze> not possible - code is going onto an embedded server. :/ It needs to handle everything itself
[2018-06-26 16:42:20] <deathgaze> logging is apparently a huge topic I wasn’t prepared for
[2018-06-26 16:42:56] <deathgaze> it looks like ‘doing it right’ involves spinning up three separate services to handle logs… one for dumping, one as an outlet, and one as a log server
[2018-06-26 18:42:20] <mcarpenterjr> Anyone build a kolide fleet stack using docker?
[2018-06-26 18:42:57] <mcarpenterjr> And/Or is it possible to execute a set of commands when a container first starts?
[2018-06-26 18:59:13] <bizmate> deathgaze: not sure where you have seen all this but the outlet is usually just a configuration in the container, ie the syslog driver. And of course a syslog server. To extract intelligence from logs is another matter but that is external and unrelated to your requirements
[2018-06-26 18:59:50] <bizmate> also not sure what the difference between the dumping and outlet one is .... dumping as in an element of storage is your log server
[2018-06-26 19:01:12] <bizmate> so just pick a way to receive logs .... for instance a syslog server or managed solution and then run the containers to point the logs to it
[2018-06-26 19:01:21] <bizmate> example with papertrail [<-LINK->] 
[2018-06-26 19:01:25] <bizmate> it is not that complex
[2018-06-26 23:21:29] <kanatsultan> Hi all, i am new to docker. Need expertise help
[2018-06-26 23:22:01] <kanatsultan> I am trying to run node.js app on docker, specific version is node-8.11.2
[2018-06-27 10:17:27] <elizar> hi
[2018-06-27 11:25:24] <bhalothia> Hello everyone, has anyone tried to implement Clair or similar toolset for container scanning in their pipelines?
[2018-06-27 14:02:47] <scott_sword_twitter> Trying to figure out the best way to design an image. I would like to use the official Ubuntu image and Python 3 image together, is it considered bad form to use docker compose in production?
[2018-06-27 14:06:08] <rcjsuen> What gave you impression Docker Compose is not ready for production?
[2018-06-27 14:11:03] <scott_sword_twitter> I see lots of examples where people use docker compose for local dev, just was curious what best practice is.
[2018-06-27 14:15:09] <scott_sword_twitter> just didn't know if there is some way to use multi-stage builds to pipe everything over from the base python image to the ubuntu image or just use compose.
[2018-06-27 14:59:22] <LukeVideo> Hy, i'm new to docker. First impressions are really good. But ... I don't understand how to pass .env variables. I have a django project for wich i put variables in a .env file.folowing this article https://staxmanade.com/2016/05/how-to-get-environment-variables-passed-through-docker-compose-to-the-containers/i understood i put my .env next to docker-compose .yml and feed the environement field like so [<-CODE->] but i get an uggly [<-CODE->] If anyone has some advise it mould be more than welcome. Thanks.
[2018-06-27 15:10:46] <rcjsuen> "but i get an uggly "...ugly what?
[2018-06-27 15:11:29] <rcjsuen> scott_sword_twitter: I think multi-stage builds could probably do what you want. Though I'm surprised there isn't already a Python image that is based off of Ubuntu...?
[2018-06-27 15:12:26] <rcjsuen> I guess they're built off of Debian instead...?
[2018-06-27 15:12:43] <rcjsuen> Or you could go super slim with Alpine...but I imagine you want Ubuntu for good reasons
[2018-06-27 15:20:34] <LukeVideo> rcjsuen: sorry I pasted the wrong thing. It's an error about environment that isn't a string or an array... If I remember well. I'm commuting right now. I'll resend the exact message as I get home.
[2018-06-27 15:48:32] <scott_sword_twitter> rcjsuen: thanks for the insight. As far as I can tell it would be more work to make sure I get everything I need over from the Python3 image to the ubuntu image than just using compose. With compose I can have my base docker image be the python image that I want and then I can just declare the distro that I want in the compose file.
[2018-06-27 17:18:13] <roelzkie15> Hi there
[2018-06-27 17:18:58] <roelzkie15> Do we really need to run$ docker build -t app-name .every time changes has been made to our development environment?
[2018-06-27 17:31:23] <scott_sword_twitter> If you want to build a new image w/ your changes and give it a new tag to push to Docker Hub I believe the answer is yes.
[2018-06-27 17:32:23] <roelzkie15> What if you don't need a new image?
[2018-06-27 17:32:47] <rcjsuen> Then you don't need to build a new image
[2018-06-27 17:32:57] <rcjsuen> Although if nothing truly changed Docker will know
[2018-06-27 17:33:02] <rcjsuen> and the build will be done in seconds
[2018-06-27 17:33:06] <rcjsuen> because the cached layer
[2018-06-27 17:33:16] <roelzkie15> Then how to reflect file changes to the existing image?
[2018-06-27 17:33:19] <roelzkie15> alright then
[2018-06-27 17:33:20] <rcjsuen> but I guess your CI probably spins something fresh everytime, so ignore what i said lol... :P
[2018-06-27 17:34:01] <rcjsuen> I mean, if your files change you need to build a new image I feel like, based on that question just now
[2018-06-27 17:34:09] <rcjsuen> But we probably don't have full context on what's going on here
[2018-06-27 17:36:40] <roelzkie15> Here is the scenario:build an image (supposing everything is ok)\nrunning the image as container.\nfound out there was an error. A TYPO.\nWhat to do? build the image again.
[2018-06-27 17:42:47] <rcjsuen> Yeah, pretty much
[2018-06-27 17:43:31] <rcjsuen> so say you had likeCOPY myapp /home/deploy/myap
[2018-06-27 17:43:35] <rcjsuen> and oh no wrong folder,
[2018-06-27 17:43:41] <rcjsuen> you have no choice but to fix the Dockerfile typo and rebuild
[2018-06-27 17:43:56] <rcjsuen> Maybe that answers your question...?
[2018-06-27 17:44:24] <roelzkie15> alright then i observed that building became fast after several tries.
[2018-06-27 17:44:38] <roelzkie15> lot of thanks man
[2018-06-27 17:44:53] <rcjsuen> yeah, so it depends where your typo is
[2018-06-27 17:45:08] <rcjsuen> if in the top, it's gotta rebuild everything (depends, at least usually)
[2018-06-27 17:45:20] <rcjsuen> if at the bottom, it'll skip all that (assuming Docker feels the state is the same) until that step
[2018-06-27 17:45:24] <rcjsuen> Good luck with your project@badcoder28!
[2018-06-27 17:57:34] <roelzkie15> rcjsuen: 
[2018-06-28 03:23:29] <roelzkie15> Got a problem running my image to a container  an issue is being resolve one by one but here comes the trouble some part. I  cant connect to the redis server. im building an expressjs application
[2018-06-28 03:24:09] <roelzkie15> Lot of thanks
[2018-06-28 07:35:10] <LukeVideo> Ok so i missspelled my message yesterday (serial copy pasting gone wrong)so i get this message [<-CODE->] As i said yesterday i'm trying to populate env variables with a .env file in the same directory as docker-compose.yml in wich i try to set [<-CODE->] 
[2018-06-28 07:53:31] <LukeVideo> OK solved ! "-ENV" != "- ENV". Just a missing space.
[2018-06-28 08:14:16] <TwanoO67> Hello all :)
[2018-06-28 08:14:29] <TwanoO67> I'm trying to install docker-ce on Ubuntu 14.04
[2018-06-28 08:14:36] <TwanoO67> docker daemon is up
[2018-06-28 08:14:44] <TwanoO67> but I can't connect to host
[2018-06-28 08:15:02] <TwanoO67> (I'm using root user, and it is in the docker group )
[2018-06-28 08:15:49] <TwanoO67> anyone have an idea for me ?
[2018-06-28 08:17:43] <TwanoO67> dockerd --debuggave me that
[2018-06-28 08:17:50] <TwanoO67> ERRO[2018-06-28T10:16:55.687356619+02:00] [graphdriver] prior storage driver devicemapper failed: exit status 1 \nDEBU[2018-06-28T10:16:55.687616585+02:00] Cleaning up old mountid : start.             \nError starting daemon: error initializing graphdriver: exit status 1
[2018-06-28 08:18:40] <TwanoO67> unfortunetaly I searched for this error online and it lead me nowhere :/
[2018-06-28 11:15:15] <Kwinby1_twitter> Hi everyone!  Anyone can give me idea about Data Mining?  Im planning to data mining on my thesis. I really would appreciate
[2018-06-28 11:15:51] <Kwinby1_twitter> If someone could help me with this. Thankyou
[2018-06-28 11:31:23] <474846718> how to check a docker container's rootfs ?
[2018-06-28 12:26:54] <TwanoO67> 474846718: what do you want to check ?
[2018-06-28 12:27:42] <TwanoO67> 474846718: df -h ?
[2018-06-28 15:49:17] <phanhoang06> TwanoO67: you should install the latest version
[2018-06-28 15:50:00] <phanhoang06> also check your kernel version
[2018-06-28 17:37:26] <galvesribeiro> hello folks!
[2018-06-28 17:37:40] <galvesribeiro> we have a system that manage resources today for our game and whenever a player ask to create a multiplayer session, this system creates a process (the game server) in a VM which has enough room to host itI was thinking on migrate it to use kubernetes and containersso the actual game server process would become a container, and our system would just ask kube to create itthe problem is, when running multiple processes in the current scenario, I share A LOT of memory (essentially the binary image) with other processes, so it save a lot of memory for us and in the end of the day, it will save us moneyso, if we migrate to containers, that would mean the memory for the process is duplicated on every containerso the question is, is there a way to share this memory across multiple containers in the same worker node in kube?for example, today if I have 10 processes on the same machine, each one has 500mb at runtime but, 100mb is the binary image which is shared, that led me to 4100mb at runtime to everything. Meaning that I save 900mb because of the shared image... Is there a way to achieve that with kube? thanks!
[2018-06-28 20:01:04] <SISheogorath> galvesribeiro: Have a look at: [<-ISSUE->] 
[2018-06-28 20:03:27] <galvesribeiro> SISheogorath: yeah, after I posted the question I saw that issue...
[2018-06-28 20:03:44] <galvesribeiro> it looks like there isn't much support for that unfortunatelly :(
[2018-06-28 20:04:00] <galvesribeiro> it is such a big waste of memory :/
[2018-06-28 20:04:07] <SISheogorath> Well, it says it's supported when you use the right storage types
[2018-06-28 20:04:13] <galvesribeiro> no no
[2018-06-28 20:04:17] <galvesribeiro> that is for FILE sharing
[2018-06-28 20:04:23] <galvesribeiro> I'm talking about Memory sharing
[2018-06-28 20:04:36] <galvesribeiro> I mean, the issue asked for memory as well
[2018-06-28 20:04:51] <galvesribeiro> but people who saidit worksare talking about file sharing
[2018-06-28 20:06:31] <SISheogorath> Well, they were talking about page sharing which needs the filesystem. but yes, there is no complete memory de-duplication
[2018-06-28 20:06:54] <galvesribeiro> the closest I found was [<-LINK->] 
[2018-06-28 20:13:11] <SISheogorath> This looks good and like an easy thing, just add a cronjob on your host
[2018-06-28 20:13:17] <SISheogorath> to trigger a KSMd run
[2018-06-28 20:24:16] <galvesribeiro> I can't do that on hosted kubernetes
[2018-06-28 20:24:27] <galvesribeiro> like AWS EKS or Azure AKS
[2018-06-28 20:25:54] <bizmate> is AWS EKS a new toy?
[2018-06-28 20:26:06] <galvesribeiro> was recently made GA
[2018-06-28 20:26:07] <bizmate> i think last time i used ECS
[2018-06-28 20:26:20] <galvesribeiro> ECS == VMs, EKS == Hosted Kubernetes
[2018-06-28 20:26:22] <bizmate> interesting
[2018-06-28 20:26:56] <bizmate> i wonder how it compares to GCP, but first i need to get started with kubernetes
[2018-06-28 20:27:22] <galvesribeiro> we use Azure AKS for a while and we are pretty happy with it
[2018-06-28 20:27:46] <bizmate> mh ok
[2018-06-28 20:27:59] <bizmate> i dont even have a login for Azure :)
[2018-06-28 20:28:01] <bogeylnj> AWS Fargate == serverless container orchestration(to complete the re:invent 2017 container announcements)
[2018-06-28 20:28:20] <bizmate> so you have 3 different ways on AWS
[2018-06-28 20:28:22] <bizmate> cool
[2018-06-28 20:28:25] <galvesribeiro>  [<-LINK->] 
[2018-06-28 20:28:35] <galvesribeiro> yeah, but Fargate has several limitations
[2018-06-28 20:28:43] <galvesribeiro> anyway, it is for simple things
[2018-06-28 20:28:49] <bogeylnj> yeah, gain less management, lose flexibility
[2018-06-28 20:28:56] <galvesribeiro> just like Azure Container Instances
[2018-06-28 20:29:16] <galvesribeiro> it is good for scheduled jobs for example
[2018-06-28 20:29:34] <bizmate> You simply provision worker nodes and connect them to the provided Amazon EKS endpoint.
[2018-06-28 20:29:40] <bizmate> sounds similar to ECS
[2018-06-28 20:29:48] <bizmate> you have to provision the VMs and link them to it
[2018-06-28 20:31:30] <galvesribeiro> in azure u just tell how many nodes u want to start
[2018-06-28 20:31:39] <galvesribeiro> then u can define the autoscale rules and be happy
[2018-06-28 20:31:41] <bogeylnj> what\'s the best "get up and go" resource you guys have come across for starting and finalizing a good movement to containerization?
[2018-06-28 20:32:09] <bizmate> depends at what level
[2018-06-28 20:32:25] <bizmate> i have not deployed to production yet
[2018-06-28 20:32:34] <bizmate> but i dont use VMs locally in general anymore
[2018-06-28 20:32:43] <bizmate> still leaves me with some parity problems
[2018-06-28 20:32:56] <bizmate> but it is much better than waiting for virtualbox
[2018-06-28 20:33:32] <bizmate> also i forgot in some cases i just spin some container instances in prod for some very simple services with simple docker-compose
[2018-06-28 20:33:39] <bizmate> obviously not the best thing to do
[2018-06-28 20:33:50] <bogeylnj> getting started level, for sure.but, the levels beyond that always comes quick
[2018-06-28 20:33:52] <bizmate> time to use some of my AWS credits for EKS
[2018-06-28 20:34:25] <bizmate> bogeylnj: the company I am consulting for is all scared about containers
[2018-06-28 20:34:36] <bizmate> they think it will take them at least 1 year before moving
[2018-06-28 20:34:42] <bizmate> it can be complex
[2018-06-28 20:35:32] <bogeylnj> we don't use any now, and are just starting with vendor images.  But, we plan to get rolling these last 2 quarters...and, I want to move as fast as possible.  But, we are at ground level now
[2018-06-28 20:36:18] <bizmate> start converting all the dev envs and up to some sort of CI/Test environments
[2018-06-28 20:36:50] <bogeylnj> once we know a bit more, I have some research to do on deploying an enterprise custom app stack
[2018-06-28 20:37:16] <bogeylnj> we'll definitely be starting local, then sandbox env, then lower environment accounts
[2018-06-28 20:37:43] <bizmate> here is a sample stack [<-LINK->] 
[2018-06-28 20:37:48] <bogeylnj> But, I feel we have a lot of reading to do the get our heads into the arena first.
[2018-06-28 20:37:58] <bogeylnj>   thanks!
[2018-06-28 20:38:01] <bizmate> just build the containers, use docker-compose and convert everything
[2018-06-28 20:38:10] <bizmate> the above is php + rabbitmq sample
[2018-06-28 20:38:28] <bizmate> it is the fully automated version of what they have on their (rabbitmq) get started page for php apps
[2018-06-28 20:38:47] <bogeylnj> cool, once i understand that enough, i'll come back and ask some dumb questions :)
[2018-06-29 02:32:36] <ppLorins>  [<-LINK->] 
[2018-06-29 02:33:51] <ppLorins> hi all  , I encountered the above issue . My container is running normally , but its  exposed port cannot be connected to . This problem appears occasionally.centos7 , docker version:Docker version 18.03.1-ce, build 9ee9f40
[2018-06-29 02:35:45] <ppLorins> After some certain period of time , it recovers itself. And I can't see any abnormal logs fromdocker logs containerid.
[2018-06-29 02:37:11] <ppLorins> "NetworkSettings": {\n      "Bridge": "",\n      "SandboxID": "a1a33225349084021d84ce5411d3e9c304eaff4646ce3afe5b222e431f0246d7",\n      "HairpinMode": false,\n      "LinkLocalIPv6Address": "",\n      "LinkLocalIPv6PrefixLen": 0,\n      "Ports": {\n        "8888/tcp": [\n          {\n            "HostIp": "127.0.0.1",\n            "HostPort": "32930"\n          }\n        ]\n      },\n      "SandboxKey": "/var/run/docker/netns/a1a332253490",\n      "SecondaryIPAddresses": null,\n      "SecondaryIPv6Addresses": null,\n      "EndpointID": "b69793b1d4e8618f48056026aac5362cc7c3d120c3dfbd97356711d6b1a072dd",\n      "Gateway": "172.17.0.1",\n      "GlobalIPv6Address": "",\n      "GlobalIPv6PrefixLen": 0,\n      "IPAddress": "172.17.0.5",\n      "IPPrefixLen": 16,\n      "IPv6Gateway": "",\n      "MacAddress": "02:42:ac:11:00:05",\n      "Networks": {\n        "bridge": {\n          "IPAMConfig": null,\n          "Links": null,\n          "Aliases": null,\n          "NetworkID": "cc1f979087cd4423457619ea092c7c6a86c1412576d5186b75b8337b41b0d63f",\n          "EndpointID": "b69793b1d4e8618f48056026aac5362cc7c3d120c3dfbd97356711d6b1a072dd",\n          "Gateway": "172.17.0.1",\n          "IPAddress": "172.17.0.5",\n          "IPPrefixLen": 16,\n          "IPv6Gateway": "",\n          "GlobalIPv6Address": "",\n          "GlobalIPv6PrefixLen": 0,\n          "MacAddress": "02:42:ac:11:00:05",\n          "DriverOpts": null\n        }\n      }\n    }\n  }This is the network setting for that container.
[2018-06-29 02:38:39] <ppLorins> Is there anyone who ever met the same problem ?
[2018-06-29 09:32:55] <trinathtiru> how to create the organisation
[2018-06-29 09:33:02] <trinathtiru> in enterprise docker hub
[2018-06-29 09:33:02] <trinathtiru> ?
[2018-06-29 10:46:06] <go4cas>  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2018-06-29 10:46:11] <go4cas> Any ideas?
[2018-06-29 11:05:31] <go4cas> Fixed ... was running node:alpine, which excludes curl .. so simpleRUN apk add --no-cache curladdition to the Dockerfile sorted this out!
[2018-06-29 11:05:54] <rcjsuen> That's Alpine for ya :)
[2018-06-29 15:52:45] <deepio> go4cas: @rcjsuenI was under the impression that having curl in production was a bad idea.
[2018-06-29 15:53:48] <jaybyrrd> Hey really quick, I had docker community edition force my system into bsod reboot loops. I'm not sure if that is an issue that needs a github issue or not since I have seen multiple similar issues posted
[2018-06-29 15:54:57] <deepio> jaybyrrd: i'm not a moderator or anything, but I think visibility of an issue like this should important. I'd post an issue.
[2018-06-29 15:56:00] <jaybyrrd> Okay. I'll do. So when I get home. Hyper v is supported on an i7 6850k right?
[2018-06-29 15:59:51] <deepio> You're certain its (bsod) docker related? It's a similar chip to the E5-1650 so ... i think yes?
[2018-06-29 16:00:11] <deepio> again, not an expert
[2018-06-29 16:02:24] <deepio> Regardless, you can make docker toolbox work on Xeon 5500's so ...
[2018-06-29 16:45:09] <jaybyrrd> Yes, to fix it I had to disable hyper v, and run registry commands to fix. Let me see if I can find it.
[2018-06-29 16:46:21] <jaybyrrd>  [<-LINK->] 
[2018-06-29 16:46:38] <jaybyrrd> ended up disable hyperv and running: [<-CODE->] 
[2018-06-29 16:46:45] <jaybyrrd> from safe mode
[2018-06-29 18:05:50] <deathgaze> bizmate: Thank you for the very complete answer. :3
[2018-06-29 19:01:46] <deepio> Well, it's a good thing there is asolution, but ideally we shouldn't have to do this...
[2018-06-29 21:06:15] <rcjsuen> deepio: I agree. You might not always wantcurland it can be a security issue. I just meant Alpine is lightweight and used by many for a reason and sometimes it doesn't have what you might expect
[2018-06-29 21:30:32] <jaybyrrd> I agree, I am going to reformat my machine this Saturday and install docker first thing to confirm it is an issue on docker  and not my OS
[2018-06-30 09:42:24] <go4cas> deepio: ... what would be a better alternative to curl forHEALTHCHECK?
[2018-06-30 09:54:41] <rcjsuen> go4cas:  [<-LINK->] 
[2018-06-30 09:57:19] <go4cas> Thanks,@rcjsuen! Fairly simple solution. Thanks for the link!
[2018-06-30 09:58:12] <rcjsuen> go4cas: Good luck with your project!
[2018-07-01 02:32:35] <avierax> hi all, does anyone knows where the docker for windows sources are?
[2018-07-01 02:33:07] <avierax> I'm having an issue with the configuration interface that is accessed via the tray icon context menu
[2018-07-01 02:33:51] <avierax> I need to fix this to unblock one of our testers
[2018-07-01 02:39:43] <avierax> every time I open the settings window it closes immediately
[2018-07-01 02:39:46] <avierax> only logging the following
[2018-07-01 02:39:56] <avierax> failed to track event actionMenuSettings
[2018-07-01 02:40:40] <avierax> I have tried to locate where's the code of this window, so see if I can find a workaround to show it
[2018-07-01 02:41:18] <avierax> I need this because is critical for my job to make one of our chief testers happy and comfortable with docker
[2018-07-01 02:41:34] <avierax> and this is hot helping
[2018-07-01 15:58:38] <scott_sword_twitter> Hey all, I'm using docker compose to run my web app locally. I want to now run this on my remote webserver. Is there a way I can package this up as an image and run remotely with just docker? Or do I need to clone my git repo remotely and run docker-compose remotely?
[2018-07-01 20:22:20] <avierax> specially those for the tray icon and the configuration interface???
[2018-07-01 20:22:24] <avierax> hi all, does anyone knows where the sources of the docker-ce for windows are?
[2018-07-01 20:37:27] <avierax> hi, everyone, this is the link to the forum discussion
[2018-07-01 20:37:34] <avierax>  [<-LINK->] 
[2018-07-01 21:07:38] <OgecuT> guys help me with docker, i have three containers:nginxphp-fpm-1php-fpm-2 [<-CODE->]  [<-CODE->] first container start correct,second container throw a error "FastCGI sent in stderr: "Primary script unknown" while reading response header from upstream"
[2018-07-02 09:56:56] <trinathtiru> hie all
[2018-07-02 09:57:23] <trinathtiru> i am facing the below error message
[2018-07-02 09:57:24] <trinathtiru> Error response from daemon: rpc error: code = 4 desc = context deadline exceeded
[2018-07-02 09:57:29] <trinathtiru> can anyone help on this?
[2018-07-02 09:58:49] <trinathtiru> i am encountered with this issue while giving docker service ls
[2018-07-02 09:59:17] <trinathtiru> or docker node ls
[2018-07-03 01:30:07] <talus46> Greetings, everyone, I’m trying to expose a container to local network using a macvlan network, but some how isn’t working for me. I’m tryeing to run it from an OSX host, could anyone give me a hint if there’s any procedure specific to OSX or the macvlan only works in Linux host ?
[2018-07-03 05:58:05] <vinaykumarvvs> Hello Everyone, can anyone pls share the good reference for this "How to create the docker file for Appium-Android Tests that uses  gradle as build tool". Thanks in advance.
[2018-07-03 06:03:31] <Ruegen> hi everyone, just a basic question - when you are using docker-compose.yml do you need to reference a dockerfile?
[2018-07-03 06:04:09] <Ruegen> can\'t I just reference the image? e.g. image: "node:10"
[2018-07-03 06:06:53] <go4cas>  [<-CODE->]  [<-CODE->] Some are files and some directories
[2018-07-03 06:14:25] <Ruegen> solved by not passing -D
[2018-07-03 10:49:43] <user2301> Hi, I installed docker tool box on windows 7, 64 bit OS. When I try  to run, I get this error message [<-CODE->] 
[2018-07-03 12:34:22] <Fuco1> Is there some way to get just the build context tarball?  Or even better, just a list of files, I don't actually need the archive... but both are fine as I can get the list from the archive
[2018-07-03 13:51:39] <LukeVideo> hy on my docker volume i just checked [<-CODE->] but i get [<-CODE->] 
[2018-07-03 13:52:51] <LukeVideo> so 192.168.1.5 is my machine (where the browser lives) and 192.168.1.6 is the server where docker lives with a django project.
[2018-07-03 13:55:08] <LukeVideo> this is my nginx config : [<-CODE->] 
[2018-07-03 13:55:33] <LukeVideo> web is the django container
[2018-07-03 13:56:19] <LukeVideo> i get the different pages of the site so i guess the proxy pass is doing ok but static files is dying on me.
[2018-07-03 14:27:51] <diegoquintanav> Hey, can you check this SO post I've made here [<-LINK->] 
[2018-07-03 14:28:11] <diegoquintanav> I lost my internet connection after installing docker in a fresh machine
[2018-07-03 21:42:52] <juslintek> Hi, I get [<-CODE->] on [<-CODE->]  [<-CODE->] 
[2018-07-04 06:01:41] <empwilli> Hi folks, I've been using docker for quite some time now, mainly for managing several web applications (redmine, gitlab, ..) on a server (single instance, no load balancing or any fancy stuff). I've got an docker image for almost every application and also separate docker-compose scripts for every application (mainly to store the startup settings)
[2018-07-04 06:02:32] <empwilli> This works quite well but I've got the feeling that most of this is very basic, are there any advanced resources on this subject you can recomend me?
[2018-07-04 07:36:08] <education-ever> .
[2018-07-04 08:02:57] <m4d3bug> empwilli: u mean there are so many scripts for each container?
[2018-07-04 08:07:42] <tellanad> @empwillimy suggetion is try to use docker swarm …you will exposed how to add multiple nodes under swarm also check out securing by using manajor and worker join tokens
[2018-07-04 08:12:56] <m4d3bug> my friend and I have discussed the k8s already take down the swarm.
[2018-07-04 08:13:48] <m4d3bug> so we might going to depoly the k8s in the furture.
[2018-07-04 08:19:42] <tellanad> Cool, Good, i am guiding to make his hands durty for next level, Swarm is there in and after docker v1.2 so no need of further installations and resources
[2018-07-04 08:21:43] <hoobean1996> hello everyone ,i am wondering if i want to run go binary program in docker(it means i have exec go build ..), which base image should i use ??? Thanks f
[2018-07-04 09:23:11] <m4d3bug> hoobean1996: 不懂你的问题
[2018-07-04 10:16:33] <rcjsuen> Maybe one of the officialgolangimages? [<-LINK->] 
[2018-07-04 10:18:55] <hoobean1996> THANKS@rcjsuen
[2018-07-04 11:01:25] <empwilli> admin0day: : Yeah, I've got a docker-compose script per container, this helps me especially to recreate single containers fast
[2018-07-04 11:01:38] <empwilli> maybe i've been using docker-compose wrong all the time, that's why I ask
[2018-07-04 11:01:47] <empwilli> but thanks on the tip with docker swarm I will have alook into it
[2018-07-04 11:08:21] <rcjsuen> empwilli: Yes, I suggest looking at Swarm or Kubernetes for the "next level"
[2018-07-04 12:00:28] <m4d3bug> empwilli: it seems one script will be ok when u need to manager so many containers
[2018-07-04 12:01:12] <empwilli> can I then restart (as in destroy the container and recreate it) single containers individually ?
[2018-07-04 12:01:34] <m4d3bug> yes
[2018-07-04 12:01:45] <empwilli> uh nice, didn't know that was an option!
[2018-07-04 12:03:38] <m4d3bug> u just need to docker-compose up -d YOURSERVICE(it means your container name)
[2018-07-04 12:03:56] <empwilli> ah great
[2018-07-04 12:04:27] <m4d3bug> so you can recreate the container which u want
[2018-07-04 12:05:09] <m4d3bug> without affect the other container
[2018-07-04 12:05:57] <m4d3bug> destroy the container just need to docker rm -f containerid
[2018-07-04 12:06:53] <m4d3bug> It will not affect the other containers without using the docker-compose
[2018-07-04 12:08:04] <empwilli> :)
[2018-07-04 12:13:12] <m4d3bug> empwilli: docker-compose restart YOURSERVICE it will restart as you want
[2018-07-04 13:54:06] <zearaujo07> Hello all, good morning. I am a developer from brazil and i am facing a problem which i dont know how to solve. How do you guys deal with docker and shared volumes? i saw a solution with sshfs, but all examples i saw were flawed. Any  suggestion?
[2018-07-04 16:17:09] <m4d3bug> zearaujo07: u mean each container I/O the same volumes on the same time?or just shared?
[2018-07-04 17:13:41] <tellanad> checkout [<-LINK->] 
[2018-07-04 17:13:48] <tellanad> which might be helpful
[2018-07-04 20:09:43] <empwilli> so kind of related to my previous question: What's a best practice for databases with docker? Currently I have a database (in a container) shared among some containers. When I add new software, I manually add an account to the database
[2018-07-04 20:10:08] <empwilli> now I've seen some docker-compose files which ship own databases dedicated to the application
[2018-07-04 20:10:20] <empwilli> is there a best practice? One database per app?
[2018-07-05 03:31:16] <oknixus> hi,guys
[2018-07-05 03:31:39] <oknixus> i have a problem with docker and ffmpeg
[2018-07-05 03:32:40] <oknixus> I am coding a feature that getting some infos from mp3
[2018-07-05 03:33:48] <oknixus> I wanner link a docker container of ffmpeg to other one with php
[2018-07-05 03:35:32] <oknixus> I use a built image named opencoconut/ffmpeg, but the container of  ffmpeg stops after runningdocker-compose up -d
[2018-07-05 03:35:44] <oknixus> how can fix it ?
[2018-07-05 03:35:50] <oknixus> thanks
[2018-07-05 06:55:23] <m4d3bug> maybe u should print out the log of this container@oknixus?
[2018-07-05 11:36:27] <user2301> My gitlab-ci.yml file contains the build script and path to build tools to use such as curl.exe, jfrog etc. The build generates artifacts. The artifact contains libraries/binaries and .exe application in ZIP format. These artifacts are delivered to artifactory. How can I dockerize this build? Can I create images for the build tools? I am using gitlab ci/cd and windows server 2012. the build tools are installed manually on this windows server. The gitlab runner uses shell as executor. How can I generate artifacts using docker build?
[2018-07-05 12:17:24] <deniz946> Hello, im reading thie DockerFile [<-LINK->] 
[2018-07-05 12:17:41] <deniz946> and I don't understand the line 11
[2018-07-05 12:18:14] <deniz946> How it prevents having to npm install each time?=
[2018-07-05 12:26:20] <rcjsuen> deniz946: That really depends what they mean by "each time"
[2018-07-05 12:26:41] <rcjsuen> perhaps afterCOPY . .annpm installis needed but it's not
[2018-07-05 12:42:50] <TrickyDoodle> Hi!I use docker on windows 10. I want to save an image and then load in on another machine.I can make it via docker save command, but is it possible to find this image? In windows all docker files are stored in .vhdx file and I have no idea how to movemy saved image from it to my w10 host.
[2018-07-05 14:34:06] <user2301> Is docker  or docker tool box supported on Windows server 2012 R2?
[2018-07-05 14:35:53] <venesh0709> how to make "systemctl" work in the CentOS container?
[2018-07-05 15:03:33] <user2301> Where can I find official docker image for windows server 2012 R2?
[2018-07-06 01:52:53] <m4d3bug> venesh0709: this is different bewteen the container and the machine
[2018-07-06 03:31:51] <m4d3bug> user2301: how about using the docker in linux command such as "docker commit"?
[2018-07-06 03:32:24] <m4d3bug> TrickyDoodle: 
[2018-07-06 03:33:19] <m4d3bug> i really off my hand about the docker in windows(no matter which version : )
[2018-07-06 05:17:04] <stalkerg> Hello all! Why docker stats andcat /proc/$CONTAINER_PID/net/devreturn different results?
[2018-07-06 06:23:37] <user2301> Is docker stable on WIndows 7 64 bit OS? Can I use docker development enviornment?
[2018-07-06 06:29:52] <m4d3bug> in my option docker work in the Linux will be better more than Windows
[2018-07-06 06:30:01] <m4d3bug> user2301: 
[2018-07-06 06:49:01] <user2301> admin0day: Oh okay thank you !
[2018-07-06 09:16:54] <CharcoGreen> hi!
[2018-07-06 09:17:01] <CharcoGreen> I need know if have any tool or idea for take metrics, I want know how many hours, each container is up . This is possible actuality?
[2018-07-06 09:25:36] <matrixbot> waveywavesCharcoGreen : depends in your container and there are a lot of monitoring tool check out EFK stack
[2018-07-06 09:27:07] <matrixbot> waveywavesYury Zhuravlev (Gitter): /proc/net/Dev stats are not something you should follow, they are deprecated. We still ahve it around coz ifconfig ends up using it. Net stats are usually checked through ethtool
[2018-07-06 09:33:42] <CharcoGreen> matrixbot: oK! thanks i go to research about the monitoring tools than can help me.  thanks
[2018-07-06 12:56:56] <WolfspiritM> I'm trying to make multiple independend stacks with the same config both having their own network. In there I've a web container and an api container. The web- container accesses the api container by calling [<-LINK->] . That works as expected. Now I want the webcontainer be available to another container which is a reverse proxy so I created a proxy network and added the web container of the stacks to it. That works aswell. But once I start more then one stack and call [<-LINK->] from the web container it now access the api of another stack randomly through the proxy network.
[2018-07-06 12:57:22] <WolfspiritM> Any idea how to fix this without having to call stackname_api directly?
[2018-07-06 14:56:12] <venesh0709> admin0day: Thanks for replying, I would like to know is there in document, displaying the list of things that we cannot perform on container as we do in VM.
[2018-07-06 22:55:10] <joshuamanns> hi - when I runCOPY .  /my/appin my Dockerfile usingnode:8image, files that are supposed to have an uppercase first letter are being changes to have a lowercase first letter... any ideas on how I can prevent that?
[2018-07-06 22:56:21] <joshuamanns> i.e,./src/MyComponent.jsis changed to/my/app/src/myComponent.jswhich breaks my import statements
[2018-07-07 10:27:20] <rcjsuen> joshuamanns: That sounds like a major bug. Are you on Win/OSX/Linux?
[2018-07-09 08:06:30] <LukeVideo> HY all i need to pass [<-CODE->] to my nginx.conf in a docker nginx image. I didn't find an easy way to do this. I have my site setting in the /etc/nginx/conf.d/site.conf but editing /etc/nginx/nginx.conf is a bit trickier.
[2018-07-09 08:40:56] <LukeVideo> So i'm trying to [<-CODE->] but i get a [<-CODE->] 
[2018-07-09 08:44:18] <LukeVideo> Ok the cp command refers to the wrong filesystem... The host not the container. I'll change that first
[2018-07-09 08:51:12] <LukeVideo> So i tried [<-CODE->] but that just gives a [<-CODE->] 
[2018-07-09 12:19:21] <LukeVideo> So, i put fastcgi settings in the site.conf as it goes in the location or http context, and added a timeout to the gunicorn command docker-compose invokes. All seems good.
[2018-07-09 12:22:31] <pkropp> Hi everyone. Is there a way to use the docker composer container for doing composer install in a subfolder of the given docker-compose project? tried docker run --rm -w /var/www/html/first/second/third -v $PWD:/app composer installComposer could not find a composer.json file in /var/www/html/first/second/third
[2018-07-09 12:23:56] <pkropp> I know I could just change to the folder containing the composer.json, but I wanna use a makefile to get everything done. Thats while I need subfolder mapping into the . composer docker container.
[2018-07-10 08:28:45] <user2301> Hi, where can I find the official image for Qt library from [<-LINK->] ?
[2018-07-10 08:29:19] <user2301> In docker hub there are few..but which is the latest and which one to choose?
[2018-07-10 11:26:45] <rcjsuen> user2301: It's possible there isn't one then
[2018-07-10 11:26:51] <rcjsuen> If it's not immediately clear which is the official one
[2018-07-10 13:02:34] <Hamelina> Hi there :) I have some trouble connecting redis in python using a docker container. When I do it in a simple programm it works but when I connect to redis an another programm via in a docker image, it doesn't work anymore. I run : docker-compose up , and it doesn't work. Actually the programm establish a mqtt connection and listen for message and then it should connect to redis, to store data. I really don't know what's going on there. Did someone have an issue like this one ? Thanks in advance
[2018-07-10 13:05:49] <rcjsuen> What do you mean "it works in a simple program"
[2018-07-10 13:06:10] <rcjsuen> So when youdocker psyou see your Redis container running?
[2018-07-10 13:06:23] <rcjsuen> And when you runpython app.pyfrom the command line of your Docker host it works?
[2018-07-10 13:07:21] <Hamelina> I mean that if I just run a python programm that connects to redis and insert data like this : python programm.py , it works
[2018-07-10 13:08:23] <Hamelina> apparently Redis container is running, and when I run python app.py it doesn't works
[2018-07-10 13:13:12] <rcjsuen> "apparently"?
[2018-07-10 13:25:29] <Hamelina> I mean it is running
[2018-07-10 13:36:58] <rcjsuen> So your Python app works when you connect to Redis locally
[2018-07-10 13:37:06] <rcjsuen> but not when Redis is running on a containr?
[2018-07-10 13:37:19] <rcjsuen> I mean, Redis locally as in, you start Redis from the CLI and not from a Docker image
[2018-07-10 14:21:17] <Hamelina> I can connect redis from a docker image in a programm running like this : python myapp.py. But when I use the same piece of code to connect in my other programm running : docker-compose up, it doesn't work. The mqtt client stops listening to new messages ;?
[2018-07-10 14:21:27] <Hamelina> :/
[2018-07-10 14:23:06] <rcjsuen> Is the MQTT the problem or the Redis?
[2018-07-10 14:41:32] <Hamelina> I think it's the combination of the both because if I just print the message received from the MQTT it prints it, and if I add a timeout as a parameter when creating the connection to redis, here is what it says : redis.exceptions.TimeoutError: Timeout connecting to server
[2018-07-10 14:42:57] <Hamelina> and the MQTT stops receiving receiving messages event if messages are sent
[2018-07-10 21:13:58] <corlinp> Hi everyone! If you don't mind me plugging a product real quick, I'm an engineer on [<-LINK->] and we've developed a super streamlined method of running Docker containers on the cloud. You can spin up a deployment with your image and data in just one line with the [<-LINK->] . Check it out!
[2018-07-11 08:13:44] <user2301> How can I dockerize this build? This is gitlab-ci.yml file. I want to create a docker build for this. ANy suggestions on how to go about it?
[2018-07-11 08:13:51] <user2301>  [<-CODE->] 
[2018-07-11 12:30:42] <user2301> Hi, I used this [<-LINK->] as a reference to setup the docker on Windows server 2016. But, I am not able to do docker run  . I get this error. How to setup proxy for docker on windows  server 2016? [<-CODE->] 
[2018-07-11 21:19:26] <AnthonyWC> user2301: that means it can’t pull from docker registry to find that image (since it doesn’t exist locally) so u need to setup connection to a registry like docker hub
[2018-07-12 06:51:23] <user2301> AnthonyWC: how would I setup that connection? [<-LINK->] according to this, My docker version 17.06, I used enviornment variable in the commanddocker run --env HTTP_PROXY="http://127.0.0.1:3001" microsoft/sample-dotnet
[2018-07-12 07:23:06] <user2301>  [<-CODE->] 
[2018-07-12 11:05:16] <user2301> Hi, How to set Proxy Authentication  in Docker EE Windows Server 2016?
[2018-07-12 12:11:08] <empwilli> Are there any builtins to clone volumes / volume containers?
[2018-07-12 17:53:10] <marshmn> hi all; I have "restart: unless-stopped" set in my docker-compose.yml, and somehow that seems to work... and yet it doesn\'t seem to be an option that\'s referred to in docs?
[2018-07-12 18:04:32] <robertsj-vmware> marshmn: I see it listed here [<-LINK->]  [<-CODE->] 
[2018-07-12 19:44:35] <marshmn> robertsj-vmware: : ahhh, I see - it's allowed in version 3; I was reading the docs for version 2... many thanks
[2018-07-12 19:47:58] <dondre> Is there anyway to connect ahost processto adocker network?
[2018-07-12 19:48:33] <nafg> dondre: it has an ip address, e.g. use docker inspect to find it. Not sure how recommended that is though ;)
[2018-07-12 19:48:39] <nafg> What's the exact use case?
[2018-07-12 19:48:56] <dondre> I have Kubectl proxy running on my host on port 8001
[2018-07-12 19:49:06] <dondre> I have nginx running in a container
[2018-07-12 19:49:17] <dondre> under the docker networkproxy
[2018-07-12 19:49:58] <dondre> i'd like the host process forkubectlwhich is listening on host port 8001 to be included into the dockerproxynetwork
[2018-07-12 19:50:38] <dondre> I'd like to avoid bridging with host because there'd be several port conflicts.
[2018-07-12 19:51:15] <nafg> wait, nginx is not running inside k8s?
[2018-07-12 19:51:32] <nafg> wdym "included," in what practical sense?
[2018-07-12 19:51:50] <dondre> you can run nginx in k8s
[2018-07-12 19:51:57] <dondre> and i will eventually
[2018-07-12 19:52:20] <dondre> but for the host im using nginx in docker to reverse proxy my subdomains.
[2018-07-12 19:57:43] <dondre> I'll just bite the bullet and bridge with host network.
[2018-07-13 00:20:54] <ivarec> My service runs in a container that needs to use a HTTP proxy. If I run my service outside of docker, everything works out just fine. If I run my service inside of a docker container, my HTTP requests get stuck somewhere. It seems that the proxy receives the requests, but the responses somehow won't reach my container. I'm using --net host in the container. Any ideas on how to debug this?
[2018-07-13 02:40:36] <chopnut> Is there a room here dedicated for Docker newbies? Im a newb in the site too :)
[2018-07-13 02:54:31] <chopnut> I will just ask away, in docker-compose, image: redis pretty much same as  from: redis in dockerfile? very noob question..
[2018-07-13 02:55:40] <sujaypillai> yes its the same
[2018-07-13 02:56:33] <chopnut> Awesome thanks for that. I was hesitant to ask =) really noobish q . cheers!
[2018-07-13 02:57:19] <sujaypillai> :) no worries
[2018-07-13 14:06:54] <user2301> I s docker suitable to build GUI (C++ application)?
[2018-07-13 14:46:21] <lucascnr> user2301: you can build whatever a linux machine can build
[2018-07-13 14:54:09] <rcjsuen> There are also Windows images to build Windows applications.
[2018-07-13 22:43:11] <Sevistuo> morning
[2018-07-15 00:34:05] <cs-cordero> hello, docker noob here.  i have a quick question -- is it true that i should avoid running databases inside of a docker container?
[2018-07-15 00:34:34] <cs-cordero> if so, i keep seeing tutorials online that uses docker-compose to start up two containers, an app container and a postgres container and connects the two
[2018-07-15 00:35:06] <cs-cordero> but how does that work if you're supposed to avoid containerizing the db?
[2018-07-15 01:56:26] <rcjsuen> I'm assuming you find this information from online articles
[2018-07-15 01:56:31] <rcjsuen> What cons have they listed?
[2018-07-15 03:58:03] <nlevchuk> Hi Christopher. You can run db in container, but you should not keep  db's data folder inside it. Keep them in host OS. You can bind data folder to db container using Volumes in docker. Please read about Volumes in docs.
[2018-07-15 04:19:17] <soumithx> how to get start for a Devops Engineer ?
[2018-07-15 10:01:23] <rcjsuen> soumithx: Your question is very open ended
[2018-07-15 11:43:56] <leonprou> Hey guys, I define my volumes in docker-compose file like: [<-CODE->] But then in Dockerfile seems like I can't use that volume
[2018-07-16 02:37:44] <comeUpWithItLater>  [<-LINK->] 
[2018-07-16 02:38:13] <comeUpWithItLater> what does  "new * hours" means here?
[2018-07-16 02:38:30] <comeUpWithItLater> docker  stack  ps
[2018-07-16 02:43:48] <sujaypillai> That task was initialized 9 hours ago
[2018-07-16 02:43:50] <sujaypillai>  [<-LINK->] 
[2018-07-16 02:44:07] <sujaypillai> check here for different states of swarm task
[2018-07-16 02:48:32] <comeUpWithItLater> so how to figure out why it not running after 9 hours?
[2018-07-16 02:50:16] <sujaypillai> docker service ps <service-name>
[2018-07-16 02:50:28] <sujaypillai> There should be a ERROR column at last
[2018-07-16 02:50:37] <sujaypillai> does it show anything?
[2018-07-16 02:53:14] <comeUpWithItLater>  [<-LINK->] 
[2018-07-16 02:53:20] <comeUpWithItLater> but no useful info in error column
[2018-07-16 02:55:36] <sujaypillai> docker service logs <service-name>
[2018-07-16 02:58:20] <comeUpWithItLater> nothing
[2018-07-16 02:58:49] <comeUpWithItLater> no output
[2018-07-16 03:15:34] <sujaypillai> how do you handle logging in that container?
[2018-07-16 03:15:46] <sujaypillai> is it the default STDOUT/STDERR?
[2018-07-16 03:22:39] <larsdesigns> Can you describe the container?
[2018-07-16 03:22:44] <larsdesigns> sujaypillai: inside the container? Would depend on the container.
[2018-07-16 03:26:18] <sujaypillai> docker service logs - shows information logged by all containers participating in the service
[2018-07-16 03:29:55] <sujaypillai>  [<-LINK->] 
[2018-07-16 03:32:35] <larsdesigns> sujaypillai: oh okay, it looked like you were searching for the Linux logs within a container.
[2018-07-16 03:33:11] <larsdesigns> Like ‘/var/log/somelog'
[2018-07-16 03:33:19] <larsdesigns> carry on then ;-)
[2018-07-16 03:35:44] <sujaypillai> btw I was helping@comeUpWithItLater:D
[2018-07-16 03:35:49] <sujaypillai> with his questions
[2018-07-16 03:36:30] <comeUpWithItLater> thx
[2018-07-16 03:37:03] <comeUpWithItLater> I justdocker stack deploy **again  and  it works now
[2018-07-16 03:37:51] <sujaypillai> great
[2018-07-16 11:54:41] <freemo> hello
[2018-07-16 19:39:00] <Webmyself> hi guys
[2018-07-16 21:03:59] <chopnut> Hi guys, just learning docker. When I stopped a container and wants to restart and execute a command in it how do I do that?
[2018-07-16 21:46:34] <wrightMatthew> To start the container back up,docker start <container ID>then to execute a command in it,docker exec <container name> <command>
[2018-07-16 21:47:05] <wrightMatthew> If you want an interactive shell going, go withdocker exec -it <container name> bash
[2018-07-17 08:38:59] <mohamedaittaleb> Hey !I'm having an issue, no internet inside the container :(
[2018-07-17 12:49:24] <hello1wolrd> is there any good book about docker
[2018-07-17 13:00:58] <Karmenzind> hello1wolrd: trythe docker book
[2018-07-17 16:35:41] <shashank292> Hey !! Any one tried installing msbuild 2017 on windows docker? I have trouble adding the individual components(Microsoft.VisualStudio.Component.NuGet.BuildTools) into container.. When i tried with start-process on vs_buildtools.exe , process is getting stuck.. Am not finding a way to debug/fix.. Please help..
[2018-07-17 16:36:07] <shashank292> mohamedaittaleb: Are you using docker for windows?
[2018-07-18 12:46:00] <ldacey> A lot of my docker-compose files would start up a Postgres database to store some data (airflow, jupyterhub, etc). Is it fine to have so many separate Postgres containers running? They are all somewhat small and unrelated
[2018-07-18 12:46:40] <ldacey> Or would it be better to create a database and schema on actual Postgres container server and point the containers to that?
[2018-07-18 15:26:11] <mateothegreat> ldacey: I’d boil it down to how much a pia it will be if you have to move/migrate/rollout with all of your instances
[2018-07-18 15:26:44] <mateothegreat> if you don’t have any HA needs I don’t see a problem .. it’s when managing your instances, the actual db engine itself, becomes more time consuming than running a single soup’ed up instance
[2018-07-18 16:52:28] <ldacey> Yeah, most of these would be simple configuration databases which I am not regularly interacting with.
[2018-07-19 03:30:49] <gerome0123> i have problem when i runnung docker ps said permission denied
[2018-07-19 03:31:00] <gerome0123> so i run sudo docker ps so its work
[2018-07-19 03:31:13] <gerome0123> how can i run by just typing docker ps without sudo
[2018-07-19 07:57:55] <Webmyself> gerome0123: what platform are you running docker on ?
[2018-07-19 08:13:40] <Webmyself> gerome0123: my guess would be check if you have a docker group already created and if you do just add your user to it, if you don't create a docker group and add your user to it.
[2018-07-19 11:49:22] <mixja> As per [<-ISSUE->] - has Docker for AWS/Azure been discontinued?
[2018-07-19 12:36:03] <rcjsuen> Sure looks like it
[2018-07-19 12:36:29] <rcjsuen> They probably want you to use Docker EE for that
[2018-07-19 16:22:40] <Boltblaster_twitter> Hello all - has anyone managed to run a spring boot appilication with https enabled using a self signed cert in a local keystore to the application without having to turn of hostname validation in the cert ?
[2018-07-19 23:52:56] <matheussilvasantos> what is debian:stretch-slim?
[2018-07-20 10:04:32] <thanhdongnguyen> Hey, Guys. What is tool or command run Docker in Production?
[2018-07-20 10:04:49] <rcjsuen> You can run Docker CE in production
[2018-07-20 10:05:33] <rcjsuen> Although frankly your question is rather vague, perhaps you should provide some mor econtext
[2018-07-20 10:07:42] <thanhdongnguyen> rcjsuen: Yes, Current, I running docker in local, I don’t understand at big company, what is tool they use run docker at Prod?
[2018-07-20 10:08:06] <rcjsuen> you can run Docker in prod
[2018-07-20 10:08:38] <rcjsuen> you may want to "level up" and use Docker Compose, Docker Swarm, Kubernetes, and so on if desired
[2018-07-20 10:08:44] <rcjsuen> but there is nothing stopping you from running Docker in prod
[2018-07-20 10:26:40] <thanhdongnguyen>  [<-CODE->] 
[2018-07-20 10:27:11] <rcjsuen> No, I just mean those are some different types of software to make your life easier/better.
[2018-07-20 10:27:23] <thanhdongnguyen> Oh. :))
[2018-07-20 10:27:26] <rcjsuen> But again, you can run Docker as-is in production if you want and if it satisfies your use case.
[2018-07-20 10:28:10] <thanhdongnguyen> Yess. I am understanded. But i would it stable
[2018-07-20 10:28:24] <rcjsuen> as stable as open source software goes
[2018-07-20 10:28:50] <rcjsuen> not to imply that proprietary software is more or less stable than open source software :)
[2018-07-20 10:30:44] <thanhdongnguyen> Hahaa. Yesss. But I'm still wondering, Prior toDocker Swarm,Docker Compose,Kubernetes. At big company, What is tool they use with docker at Prod?
[2018-07-20 10:33:17] <rcjsuen> They probably just ran it as-is
[2018-07-20 10:34:25] <rcjsuen> Docker came out in 2013 and both Compose and K8s came out in 2014, Docker was still very young
[2018-07-20 10:35:11] <rcjsuen> I wouldn't be surprised if they tried to build their own container orchestration system. I mean, consider that Kubernetes was started by Google...
[2018-07-20 10:43:38] <thanhdongnguyen> yess. Prior to, Google use container, but not publickubernetes
[2018-07-20 10:43:49] <thanhdongnguyen> 2013, Google public kubernetes
[2018-07-20 10:44:14] <thanhdongnguyen> I think, Prior they useLXC
[2018-07-20 11:25:34] <himanshurajput__twitter> Hi, I am running docker 17.03.2-ce on RHEL 7.5. I have setup a docker registry on another instance. When I try to pull docker images from that registry it gives an error of  "Error response from daemon: Get [<-LINK->] : http: server gave HTTP response to HTTPS client".I have also added a flag in “/usr/lib/systemd/system/docker.service” with ExecStart=/usr/bin/dockerd –insecure-registry docker-repo.example.com:5000. But it doesn\'t work for me. Can anyone help for the same?
[2018-07-20 12:42:30] <user2301> Hi, Anyone tried to build QT applications using docker?
[2018-07-20 12:47:10] <user2301> I have a desktop GUI application developed using (C++/ QT IFW). The repository for this application is in gitlab. Gitlab CI/CD is configured using gitlab-ci.yml file. The gitlab runner installed on windows server 2012, will build the desktop application. The output of the build (.exe application) is compressed to zip format and delivered to artifactory server. The end user downloads the artifact (.ZIP file) and installs the application on their Windows 7/10 system. Suppose, I want to build on new windows server 2016, I have to install all the build tools along with the gitlab runner. How can I use docker in this scenario? I want to use docker to create or reproduce build enviornment.
[2018-07-20 14:37:06] <rcjsuen> Sounds like you need a base Windows image to start and then install the necessary C/C++ libraries/dependencies and then kick off your build
[2018-07-22 11:34:01] <andern>  [<-CODE->] /bin/sh: /proj/srv: not foundI can even open a terminal and see that the file is there. run it manually and I get the same error! Any ideas why?
[2018-07-22 11:36:53] <andern>  [<-LINK->] 
[2018-07-22 11:37:00] <andern> That's mydocker-compose.yml
[2018-07-22 12:00:29] <rcjsuen> What does the full output look like?
[2018-07-22 12:03:34] <andern> without the ls command it's literally onlyapi_1  | /bin/sh: /proj/srv: not foundDo you want the full ls output?
[2018-07-22 12:05:37] <andern>  [<-LINK->] 
[2018-07-22 12:06:49] <andern> that's with the docker-compose file exactly like i pasted it earlier
[2018-07-22 12:08:27] <rcjsuen> Did you try writing a Dockerfile that does what you described?
[2018-07-22 12:09:00] <andern> Yes. The Dockerfile it uses actually puts srv in /proj and runs just fine
[2018-07-22 12:09:37] <andern> so if i use the exact same docker-compose file and just remove the "volumes" under api, it works
[2018-07-22 12:11:40] <rcjsuen> Did you try removing yourVOLUMEinstruction in yourDockerfile?
[2018-07-22 12:13:12] <andern> oh then I misunderstood your earlier question. My Dockerfile doesn't have aVOLUMEinstruction. It simply copies the srv file to /proj.WORKDIR /projCOPY --from=build /go/bin/srv .
[2018-07-22 21:32:41] <fulvi0> Hi, I’m facing a rare issue trying to deploy a container, I’m getting the following error. [<-CODE->] 
[2018-07-22 21:36:07] <fulvi0> is a custome images btw
[2018-07-22 22:06:21] <ofabricio> I'm compiling a go executable with docker like this: [<-CODE->] I'd like to take this binary file from the container and copy it to the host.. how can I do that?
[2018-07-23 01:30:03] <rcjsuen> If you perform a volume mount then your container and host can access the same stuff
[2018-07-23 07:28:45] <user2301> Hi, I have installed gitlab runner on 4 Virtual Machines to build each application on each Virtual Machine. Is it possible to have 4 instances of gitlab runner to build 4 applications on single VM using docker?
[2018-07-24 04:16:07] <kopax> I have this error when I login during a CI process: "WARNING! Using --password via the CLI is insecure. Use --password-stdin." should I just replace "--password" with "--password-stdin\' ?
[2018-07-24 10:53:23] <user2301> Hi, I am getting this error message when I try to install Chocolatey using docker... [<-CODE->] 
[2018-07-24 10:53:56] <user2301> When I try to install directly using powershell or command i wont get any error
[2018-07-24 15:23:06] <venesh0709> how docker works on windows?
[2018-07-24 15:29:45] <rcjsuen> What do you mean?
[2018-07-24 15:30:41] <venesh0709> can we install on the native windows
[2018-07-24 15:30:54] <venesh0709> as I do on the linux machine
[2018-07-24 15:30:55] <venesh0709> ?
[2018-07-24 15:31:13] <rcjsuen> Yes
[2018-07-24 15:31:21] <rcjsuen> Are you asking if you need a Linux VM to run Docker on Windows?
[2018-07-24 15:31:52] <venesh0709> Yeah
[2018-07-24 15:32:13] <rcjsuen> No, you don't
[2018-07-24 15:32:39] <venesh0709> I can install a linux on hypervisor in windows and run docker on that linux but can we directly install on windows?
[2018-07-24 15:33:38] <venesh0709> and rundocker commands in the powershell
[2018-07-24 16:05:18] <rcjsuen> Yes you can run Docker directly from Windows
[2018-07-24 16:49:33] <venesh0709> thank you :)
[2018-07-24 16:50:04] <venesh0709> working on it will back if I have queries
[2018-07-25 07:01:06] <yueyouth> docker  container  use  "docker stop containerID"commend isnot work
[2018-07-25 07:01:37] <yueyouth> how to kill this  container
[2018-07-25 08:55:58] <harshana-rav> Hello we are in the baby stage of our container journey and i'm here to ask if anyone of you have any advice on the following. We got 16 odd microsvcs and we have deployed them usingdocker-composeacross 3 docker hosts. So in our CI pipeline we deploy todevtestandpreprodenvironments then once release they go to production. So my question is there a tool out there we can use to deploy containers to above environment. at the moment we have a python script to pull specific containers to the said envs but wondering if there is a better way to do this
[2018-07-25 11:16:39] <rcjsuen> yueyouth: Did you try usingdocker kill?
[2018-07-25 13:38:22] <guslep> harshana-rav: you could try using ansible,  you could run the script against one or all your environment, and it would pull the docker, you could also have the script restart automatically the container. [<-LINK->] 
[2018-07-25 14:28:24] <venesh0709> how to manage docker containers with ansible? Any special document? In fact I want to make a small project in combination of both ansible and docker.
[2018-07-25 15:33:43] <chibby0ne> Hi guys, so I have a very specific question:In a docker-compose.yml I have this:build:\n        context: .\n        dockerfile: ./tests/test_network/DockerfileAnd in that Dockerfile:COPY ../../common/requirements.txt .I get afailed to build: COPY failed: Forbidden path outside the build context: ../../common/requirements.txt ()But isn't the docker-compose specifying that everything is in context?
[2018-07-25 15:42:27] <guslep> venesh0709: do you have a specific question ? the doc details how the ansible docker plugin works, than it depends on your usecase, you could do a playbook and create task with tags like pull, start, stop, refresh than use the ansible-docker module to do your task
[2018-07-25 16:17:54] <chibby0ne>  [<-CODE->]  [<-CODE->] 
[2018-07-25 18:32:48] <abdulhaleem> Hi Ya\'ll,  I have written a service using akka-http and dockerized the service. Upon running docker-compose up I noticed I get the following error "Exception in thread "main" java.lang.NoClassDefFoundError: akka/http/scaladsl/model/HttpMethod"The problem I think is since Akka HTTP has 2 modules akka-http and akka-http-core one of them has the class "akka/http/scaladsl/model/HttpMethod" while the other one doesn\'t and both the modules have the same namespace
[2018-07-25 18:33:12] <abdulhaleem> I will really appreciate any help
[2018-07-25 18:51:39] <MoBattah> Hello, anyone here familiar with how to start a stopped container in Azure?
[2018-07-25 21:43:35] <harshana5> guslep: Yeah I was reading up about puppet or ansible, I feared if it would be an over kill :D
[2018-07-26 12:06:41] <managerger>  [<-CODE->]  [<-CODE->] Any thoughts?
[2018-07-26 12:51:41] <theobouwman>  [<-LINK->] 
[2018-07-26 12:51:46] <theobouwman> Can some one help me?
[2018-07-26 15:03:09] <roelzkie15> Just wanna ask something here concerning database access inside a docker container
[2018-07-26 15:06:44] <roelzkie15> I was able to successfully run a postgres database using docker-compose, my problem is how can i view all the tables of the database inside docker container using pgadmin? the port was expose as 5432:5432 then in my pgadmin i used the 127.0.0.1:5432 host port address no password and postgres user. The connection is successful however i can find any tables.
[2018-07-26 17:00:48] <gmohanrajcse> Hi
[2018-07-27 10:33:12] <MaxNevermind> Can anyone tell me, whether not showing all containers is a feature or a bug for commanddocker ps -all?I run it once, it show only one container, I remove it, run the command again, and there is another stopped container, I remove it and it goes on and on and on
[2018-07-27 10:33:47] <rcjsuen> "I remove it". You remove "what"
[2018-07-27 10:34:05] <MaxNevermind> Removed a stopped container
[2018-07-27 10:34:05] <rcjsuen> or rather, perhaps sharing your exact terminal inputs and outputs would be more clear
[2018-07-27 10:36:42] <MaxNevermind>  [<-CODE->] 
[2018-07-27 10:38:35] <MaxNevermind> I expect thatdocker ps -allwould show all containers not just one.
[2018-07-27 10:39:01] <rcjsuen> But you removed it
[2018-07-27 10:39:17] <rcjsuen> er wait hang on
[2018-07-27 10:39:34] <rcjsuen> nm, I'm an idiot
[2018-07-27 10:39:43] <MaxNevermind> I mean stopped, I know there are 3 of them
[2018-07-27 10:40:01] <rcjsuen> It should show them all. It does look strange
[2018-07-27 10:40:05] <MaxNevermind> Why does it show it one by one?
[2018-07-27 10:40:25] <JoeSSS> hey, I have a small question :) Is there a way to useRUNin Dockerfile in the same way asbash -l -cworks? My problem is that I need.profileto be the source in the moment I execute the command because it contains info about rbenv
[2018-07-27 10:40:50] <rcjsuen> ah
[2018-07-27 10:40:59] <MaxNevermind> I've first encountered that behavior years ago, didn't have time to figure it all out
[2018-07-27 10:40:59] <rcjsuen> MaxNevermind: I see now. You need to use--allor-a
[2018-07-27 10:41:10] <rcjsuen> you are using-allwhich is not actually a flag
[2018-07-27 10:41:46] <rcjsuen> I suppose it should show warning/err instead but anyway
[2018-07-27 10:42:30] <MaxNevermind> oh yeahyour are right, thanks!though this behavior is kinda strange
[2018-07-27 10:42:57] <rcjsuen> no problem
[2018-07-27 10:43:01] <rcjsuen> Good luck with your project!
[2018-07-27 11:00:17] <empwilli> hi folks, just wanted to try out the gitlab runners with a ldap database as a service for testing purposes. Any ideas how to fill the ldap database conviniently? My current solution is to use a custom image with the data already loaded …
[2018-07-27 11:25:15] <managerger>  [<-CODE->]  [<-CODE->] Any thoughts?
[2018-07-27 13:51:58] <jmc265> I am having an issue whereby Docker Compose is creating 2 volumes when I have asked it to create one. [<-CODE->]  [<-CODE->] 
[2018-07-28 03:12:16] <faressoft> Hello Guys, I've just published a new open source project that is coded in Node.js [<-LINK->] Start just if you like it :D
[2018-07-29 17:53:36] <jsign> Hi
[2018-07-29 17:55:06] <jsign>  [<-CODE->] Why does making:docker run --rm thisimageterminates immediately?
[2018-07-29 17:57:13] <rcjsuen> jsign: Hm, maybe try-it
[2018-07-29 17:57:50] <jsign> rcjsuen: , yes, with-tiworks ok.. but why doesn't withCMD? :/
[2018-07-29 17:59:23] <rcjsuen> Well, what does-itsay in the docs
[2018-07-29 17:59:53] <jsign> That would run a shell and redirect stdin and stdout.
[2018-07-29 18:00:12] <rcjsuen> So there you have it
[2018-07-29 18:00:21] <rcjsuen> Otherwise yourbashjust terminates immediately
[2018-07-29 18:01:35] <jsign> ButCMD ["bash"]doesn\'t runbash, anddocker runshould start the container and keep it alive until thebashprocess terminates? (which is whenexitis fired)
[2018-07-29 18:01:41] <jsign> Or am I getting something wrong here?
[2018-07-29 18:02:11] <jsign> To be shorter: the container should stop when the CMD exits.
[2018-07-29 18:02:32] <rcjsuen> And thebashterminated immediately
[2018-07-29 18:02:50] <jsign> butbashdoesn`t terminate when theexitcomand is used?
[2018-07-29 18:03:05] <rcjsuen> Sorry, I don't understand your question.
[2018-07-29 18:03:58] <rcjsuen> if youdocker run alpineit will also die immediately, butdocker run -it alpinewill let you use Alpine
[2018-07-29 18:04:29] <jsign> What happens if you runbashin your terminal?. Does it finish immediately?
[2018-07-29 18:04:56] <rcjsuen> No, but that's because I have a terminal
[2018-07-29 18:05:23] <rcjsuen> In Docker's case it doesn't have one, sobashdies
[2018-07-29 18:05:48] <jsign> Ok, so I guess there is my confusion. Why does that makes a difference?.bashdoesnt keep reading stdin until theexitcommand is executed?
[2018-07-29 18:09:28] <rcjsuen> That I'm not sure about it. But there is nothing in itsstdinanyway
[2018-07-29 18:10:41] <rcjsuen> For interactive processes (like a shell), you must use -i -t together in order to allocate a tty for the container process.
[2018-07-29 18:13:47] <jsign> Yeah, I use-ita lot, but in this case a want to make a docker image that runs abash. Then if I want to interact, I coulddocker attachafterwards.I know I could do it withdocker run -d -ti, but is that theonlyway?
[2018-07-29 18:20:43] <rcjsuen> I'm not sure ifdocker attachis what you want. After you attach and you're done how do you detach?
[2018-07-29 18:20:52] <rcjsuen> When you detach your container's bash dies, doesn't it?
[2018-07-29 18:21:39] <jsign> You can detach withctrl-p ctrl-q
[2018-07-29 18:21:49] <jsign>  [<-LINK->] 
[2018-07-29 18:22:03] <rcjsuen> Ah
[2018-07-29 18:22:05] <rcjsuen> Alright, you got me
[2018-07-29 19:11:38] <tbugfinder> Does anybody know a good intro into Openshift and jenkins based deployment across dev/qa/prod?
[2018-07-29 20:09:04] <DinoSourcesRex>  [<-CODE->] If I have the following in my compose file [<-CODE->]  [<-CODE->] 
[2018-07-29 20:20:30] <jsign> seems to work for me.
[2018-07-29 20:23:16] <jsign>  [<-CODE->] docker-compose startThen I used NoSQLBooster for MongoDB, and connected tomongodb://localhost:27018withAuthentication=None
[2018-07-29 20:26:01] <DinoSourcesRex> jsign: I think I wasn't clear.mongodb://localhost:#works when connecting with an app that isn't containerised. However I have another container attempting to link the db, here's the full compose [<-CODE->] 
[2018-07-29 20:27:03] <DinoSourcesRex> So themongodb://localhost:#won't letdomain_apiconnect to the mongodb. I am after the connectionstring that will let the api connect to the db
[2018-07-29 21:29:48] <DinoSourcesRex> Well. Ignore me. I'm an absolute idiot. My ip address was pointing to the host port rather than the container port.
[2018-07-30 00:52:33] <jsign> DinoSourcesRex: yeah, happens to everyone :)
[2018-07-30 02:21:53] <hehailong5> Hi, how to forward signal to container process from outside? I was using the CMD exec format in my Docker file but none was caught inside when I run docker stop.
[2018-07-30 16:27:01] <Jacob_Bogers_twitter> hI
[2018-07-30 16:27:17] <Jacob_Bogers_twitter>  [<-CODE->] 
[2018-07-30 16:28:29] <Jacob_Bogers_twitter> service telegraf is accessing the host "pc132" that is running the docker this normally works, but within docker-compose it doesnt work why i sthat?
[2018-07-30 20:33:08] <rightisleft> Hi folks - im trying to pause a containers default boot sequence - below is the Dockerfile in question - it is my understand that i should be able to override the command entry docker-compose file likecommand: sleep 6000to allow my to exec into the container. Is there some reason why the service keeps starting anyway? [<-LINK->] 
[2018-07-30 20:34:32] <rightisleft> the default container hasCMD ["-b", "0.0.0.0"]- i should either be able to use docker-compose run keycloak bash OR in docker-compose.yml - for the keycloak entry- provide command: sleep 6000
[2018-07-30 20:34:38] <rightisleft> am i missing something?
[2018-07-30 21:34:56] <rcjsuen> rightisleft: So you mean you don't want it to start JBoss?
[2018-07-31 19:36:00] <AnthonyWC> rightisleft: cmd is applied AFTER entrypoint
[2018-08-02 01:29:55] <hehailong5> hi, how to get the container id/name according to the container process pid on the host?
[2018-08-02 04:23:24] <harshana5> ps -ef | grep docker
[2018-08-02 05:32:07] <mairelin> Hi, I'm trying to run a docker container but it's dying inmediatly and is not any log about the reason. Someone knows this situation?
[2018-08-02 06:55:24] <manueldeveloper> mairelin: Maybe there is no command/execution which let's the container still executing
[2018-08-02 09:58:34] <rcjsuen> How are you starting/running the container?
[2018-08-02 13:26:39] <mairelin> manueldeveloper: I\'m executing a command, I\'m running a binary generared with go CMD [". /go binary"]
[2018-08-02 13:30:42] <mairelin> rcjsuen: I'm running this commanddocker run -d -p 8080:8080 --name nmrk --link nmrk-db-container  --net api_nmrk-network  nmrkapi
[2018-08-02 14:42:46] <pantherqin_gitlab> HI All,Want to ask a question about the different between docker-compose and docker run (individual service) [<-CODE->]  [<-CODE->] 
[2018-08-02 14:43:14] <pantherqin_gitlab> I also tried using a customized network. Same issue. WOrks find in docker-compose, but same error using docker run
[2018-08-02 14:43:48] <pantherqin_gitlab> docker run --rm --network market-bridge  my-image-nginxdocker run --rm -p 80:80 -p 443:443 --network market-bridge my-image-spa
[2018-08-02 14:44:00] <pantherqin_gitlab> Any help is greatly appreciated! Tks
[2018-08-02 15:22:18] <pantherqin_gitlab> nvm, just need to set --network-alias :)
[2018-08-02 15:30:11] <rcjsuen> mairelin: If you use-dthen you're detached. Maybe try with-ainstead.
[2018-08-02 15:47:24] <mairelin> rcjsuen: I couldn't pass -a to the docker run command but I put in foreground  and nothing still happen :(, I'm almost crying
[2018-08-02 15:49:29] <rcjsuen> That's strange. What happens when you use-a
[2018-08-02 15:50:05] <rcjsuen> Or just drop the-dand see what happens and don't even use-a
[2018-08-02 15:51:17] <mairelin> rcjsuen: ok
[2018-08-02 15:55:56] <manueldeveloper> mairelin: I think that the error could be the way that your are using CMD command
[2018-08-02 15:56:34] <manueldeveloper> personally, I prefer to use ENTRYPOINT
[2018-08-02 15:57:34] <manueldeveloper> could you change it like this:ENTRYPOINT ["go", "./binary"]?
[2018-08-02 16:00:56] <mairelin> rcjsuen: I was using the -a flag in the wrong way,  I just fixed it, but I also still with the same issue
[2018-08-02 16:01:43] <mairelin> manueldeveloper: I changed to the ENTRYPOINT,  and still having the same issue
[2018-08-02 16:02:39] <manueldeveloper> mairelin: which FROM are you using?
[2018-08-02 16:03:05] <mairelin> This is what happen after  CMD or ENTRYPOINT,
[2018-08-02 16:04:25] <mairelin>  [<-LINK->] 
[2018-08-02 16:04:50] <mairelin> manueldeveloper: I\'m using  "golang:1.8-alpine"
[2018-08-02 16:05:20] <manueldeveloper> perfect
[2018-08-02 16:06:17] <manueldeveloper> Maybe your problem is related to the location of the executable/binary
[2018-08-02 16:06:28] <rcjsuen> Yes, what is yourWORKDIR
[2018-08-02 16:06:36] <manueldeveloper> exactly
[2018-08-02 16:07:01] <rcjsuen> though really, when youdocker runit should give you some errors as by default it should attach tostdoutand so on
[2018-08-02 16:07:37] <rcjsuen> You can also of course give the absolute path to yourENTRYPOINT
[2018-08-02 16:07:47] <rcjsuen> That would be a good quick way to see if your build binary output is good
[2018-08-02 16:07:54] <rcjsuen> Then you can think about restructuringWORKDIRand so on perhaps
[2018-08-02 16:08:10] <manueldeveloper> I agree with@rcjsuen
[2018-08-02 16:08:49] <mairelin> I will give you my docker ifle
[2018-08-02 16:08:51] <mairelin> file
[2018-08-02 16:10:14] <manueldeveloper> whatever you want
[2018-08-02 16:10:33] <mairelin>  [<-CODE->] 
[2018-08-02 16:11:39] <rcjsuen> holy mackerel
[2018-08-02 16:12:48] <rcjsuen> I see some strangeness...but I don't know how Go builds things so...
[2018-08-02 16:14:38] <manueldeveloper> first, it could be better expose the port before the entrypoint
[2018-08-02 16:15:43] <manueldeveloper> second, you need to include the "go" command into ENTRYPOINT
[2018-08-02 16:16:18] <manueldeveloper> as followsENTRYPOINT ["go", "./pecuniaapi"]
[2018-08-02 16:17:03] <manueldeveloper> entrypoint command paste each element of the array  in a shell command
[2018-08-02 16:18:13] <manueldeveloper> but as@rcjsuensaid... there several weird things related to the build of the final executable
[2018-08-02 16:19:51] <manueldeveloper> and I'm not an expert of Go (I'd want to but not yet)
[2018-08-02 16:19:53] <manueldeveloper> :p
[2018-08-02 16:56:11] <mairelin> I also tried running the same binary that works fine without docker
[2018-08-02 17:02:06] <rcjsuen> OK. And what happened with the investigative steps we suggested
[2018-08-02 17:54:04] <mairelin> rcjsuen: nothing, I'm creating now an empty new project.
[2018-08-02 17:56:46] <mairelin> because the most weird that the docker file started to fail after I have renamed the project, and the name of some folders. and if i compare the last one and the older have the same struct, only change the dep part and the folders name
[2018-08-02 20:52:17] <mairelin> Helloooooo@rcjsuen@manueldeveloperI found the problem, was that I was calling localhost and not to the ip or container name to connect to database container inside the  app. I also was redirecting wrong the stdout. Now I will to take off some bad practice on my docker file. Thanks too much for you help. :). I'm so happy :D
[2018-08-02 20:52:39] <rcjsuen> OK
[2018-08-02 20:52:46] <rcjsuen> Well, I dunno what you were doing that redirected stdout badly
[2018-08-02 20:52:55] <rcjsuen> Oh, unless your app itself wasn't writing to stdout/stderr...then yeah..............
[2018-08-02 20:53:17] <rcjsuen> mairelin: Anyway, good to hear you're fine and thank you for sharing your mistake/solution (helps everyone in the channel learn!).
[2018-08-02 20:53:21] <rcjsuen> mairelin: Good luck with your project!
[2018-08-02 20:58:51] <mairelin> rcjsuen: Thanks :D
[2018-08-02 23:28:40] <danieldram> does anyone know why this will not launch the instance on aws?docker-machine create --driver amazonec2 \\--amazonec2-ami ami-116d857a \\--amazonec2-instance-type t2.medium \\--amazonec2-ssh-user rootdeb-test
[2018-08-02 23:28:55] <danieldram> I also tried with ssh-user set to admin
[2018-08-02 23:29:10] <danieldram> trying to launch the debian jessie AMI
[2018-08-02 23:31:01] <danieldram> The instance launches but terminates on SSH
[2018-08-03 02:47:48] <harshana5> try running that with --debug
[2018-08-03 02:47:57] <harshana5> danieldram: 
[2018-08-03 06:47:54] <manueldeveloper> mairelin: yes?! Cool! :D
[2018-08-03 18:00:47] <mcarpenterjr> just firerd up a container got this:WARNING: IPv4 forwarding is disabled. Networking will not workinstance has ran for almost 15 months had a power failure today.
[2018-08-03 18:02:00] <mcarpenterjr> What/where would I start with this?
[2018-08-03 19:08:50] <mcarpenterjr> Got it, gave the server another reboot
[2018-08-03 19:32:42] <tipra34> launching python file with command gives different command line arguments and running the same program with entrypoint gives different command line argument. Any idea about this?with command I get command line args as: ['main.py', 'python3', 'main.py', 'followed_by_arguments_passed']with entrypoint I get: ['main.py', 'followed_by_arguments_passed']
[2018-08-04 10:45:16] <rcjsuen> You mean yoursys.argv?
[2018-08-06 11:27:42] <samspired> Hi guys
[2018-08-06 11:28:08] <samspired> Can anyone tell me how to mount host volume from external drive onto a docker container?
[2018-08-06 11:29:00] <samspired> the command -docker run -v /usb-drive/projects/app:/usr/local/app --rm -it image_name bashdoesnt work, the container directory -/usr/local/appis empty.
[2018-08-06 11:29:55] <samspired> when the same projects/app is saved in my mac hard drive and mounted using-vfrom there, then it does work.
[2018-08-06 11:31:01] <samspired> docker containers cannot read host volumes with-vfrom external hard drives?
[2018-08-06 11:34:56] <babaorum> I think this may help you
[2018-08-06 11:34:56] <babaorum>  [<-LINK->] 
[2018-08-06 11:35:34] <babaorum> the first answer seems to talk about a config path to add for docker to know the mounted paths
[2018-08-06 11:41:25] <samspired> thank you sir
[2018-08-06 11:47:31] <samspired> oh the solution seems only for -Docker-for-macdoesn't answer if i am using docker-machine?
[2018-08-06 11:50:07] <samspired> this might work - [<-LINK->] 
[2018-08-06 12:38:48] <babaorum> Do tell me if this fix your issue, I'm interested. Sorry for the bad link, I think the issue might be similar (your link is better in your case)
[2018-08-06 13:35:23] <samspired> ok i am not trying right now since it involves doing some extra steps to mount usb to docker-machine each time its restarted
[2018-08-06 13:35:38] <samspired> but i suppose it should work
[2018-08-07 17:18:22] <mosoriob> Hi, I have a question.The manifest of an image gives the layers of the image and the base image. Is there any method to filter the layers of the base image?
[2018-08-07 17:44:21] <freppn_twitter> Getting a coffee with any open source buddy whom you havent talked and going to music concerts with Bill Gates or any one of the 100+ activities is that easy now. As you can see the plans are completely anonymous, secure unless both of you agree. Freppn (Friends Happen) . Make plans with literally anyone.Start using Freppn App, live on play store at https://play.google.com/store/apps/details?id=com.freppn.codeiatio.freppnWEBSITE:- www.freppn.comWe are a new idea app that is reducing the distance between different social media and support 9+ Verified logins (Facebook, Twitter, Google+, Github , Pinterest , Tumblr , Phone , Codeforces , Linkedin) at the moment Plus chat apps like Whatsapp , Snapchat , Hangouts , Messenger , KiK , Telegram etc). We are working on patenting , trademarking and adding all other websites and removing bugs at the moment . Please share our app so that we can take this to many people as possible as we are currently working on marketing, patenting and trademarking this unique idea.Please help us in Sharing this app as this helps to meet your open source buddies and maybe learn open source over a cup of coffee . No need to Directly ask. Just anonymously use Freppn.It's completely safe and secure.
[2018-08-07 18:04:35] <danieldram> @harshana5 when I run with debug I get this: Error creating machine: [<-CODE->] 
[2018-08-07 18:04:53] <danieldram> I can create ubuntu default instances on aws, but any AMI I use produces this error
[2018-08-07 18:05:04] <danieldram> when using this command:
[2018-08-07 18:05:31] <danieldram> docker-machine --debug create --driver amazonec2 --amazonec2-ami  ami-116d857a testdeb
[2018-08-07 18:39:49] <danieldram> In another instance on another AWS account, it will create the machine but will fail even if I provide the --amazonec2-ssh-user to admin for debian OS
[2018-08-07 19:45:21] <danieldram> anyone there?
[2018-08-07 20:39:36] <tbugfinder> danieldram: Could you check your instance limits (ec2->limits) in the first account?
[2018-08-08 04:06:28] <danieldram> tbugfinder: thanks for the reply, I had resolved that issue.. But still if I try to run a docker-machine with the driver for aws and use a debian AMI with the ssh-user set to admin, ssh process hangs and then the instance stops.
[2018-08-09 05:48:10] <maityneil> Hi All, can anyone help me figure out how to connect with different node in docker swarm but one is on cloud like AWS and one is on local. I could connect between local nodes and between cloud nodes
[2018-08-09 05:48:27] <maityneil> But not local and cloud
[2018-08-09 07:26:14] <danieldram> you most likely need to open up the UDP, TCP ports required for swarm, did you try this already?
[2018-08-09 07:26:22] <danieldram> maityneil: 
[2018-08-09 21:47:13] <Sheikh14494999_twitter> .
[2018-08-09 21:47:28] <Sheikh14494999_twitter> .
[2018-08-10 01:31:24] <andrecavallari> Hi, I am trying to run docker with the elasticsearch image: elasticsearch:5.1
[2018-08-10 01:32:10] <andrecavallari> But I am getting this error: [<-CODE->] 
[2018-08-10 01:32:18] <andrecavallari> How to fix??
[2018-08-10 06:44:42] <replicadse> looks like the wrong java version?
[2018-08-10 08:50:24] <panthorn> Hello,Is anyone here?I am completely new with gitter and quiet new when it comes to coding as well. Currently stuck on a minor thing in cygwin terminal. What room should I join for this matter?tar: this does not look like a tar-directoryFAILED: The downloaded lab bundle is not a tar archive. You may check for errorsThanks in advanceRobin
[2018-08-10 09:06:11] <brendonco> anyone know about micro frontend
[2018-08-10 12:18:21] <andrecavallari> HeikoAlexanderWeber: , using docker? I found what was the error... there is a bug on linux using the version 5.1.2 of elasticsearch, fixed on 5.4
[2018-08-10 12:18:24] <andrecavallari> ops, 5.3
[2018-08-10 12:22:49] <andrecavallari> This is the issue: [<-ISSUE->] 
[2018-08-10 12:52:02] <manueldeveloper> Thanks for sharing!
[2018-08-10 14:35:45] <slim-hmidi> Hi I'm trying to add an extension to my postgres docker container which is contained under a kubernetes pod.Dockerfile: [<-CODE->]  [<-CODE->] 
[2018-08-13 10:55:48] <user2301> not able to access the github.com from docker container when i try to access golang packages
[2018-08-13 10:56:20] <user2301> Should I set username and password within dockerfile?
[2018-08-13 11:47:27] <basz> does any of you use something like \'docker run --rm --volume $(pwd):/app --volume $SSH_AUTH_SOCK:/ssh-auth.sock --env SSH_AUTH_SOCK=/ssh-auth.sock --volume "$HOME"/.ssh/known_hosts:/etc/ssh/ssh_known_hosts:ro composer install\' to install dependencies inside a gitlab-ci WITH private repositories? I can\'t get it to work... (googlingdocker composeryields results all over the place). Note that a simple git clone private-repo-url works without issue, so my keys and hosts stuff should work. I keep getting "Host key verification failed."
[2018-08-14 05:39:38] <dalau6> Hey guys, for Docker Compose command option, how would I cd into a folder inside my container before running a port?
[2018-08-14 18:51:17] <mateothegreat> dalau6: use theCWD /some/dirbefore yourRUN ..
[2018-08-14 18:51:43] <mateothegreat> or have your ENTRYPOINT (script?) do it
[2018-08-15 09:47:48] <DinoSourcesRex> Can I pass variables to a dockerfile at runtime?What I want: I have a dockerfile for mongorestoring, but we have multiple environments. I don't want to have to create an image per environment. [<-CODE->]  [<-CODE->] 
[2018-08-15 09:47:55] <DinoSourcesRex> Anyone got any ideas?
[2018-08-15 10:08:22] <rcjsuen> DinoSourcesRex: Read up onARGand the idea of "build args"
[2018-08-15 10:10:11] <DinoSourcesRex> rcjsuen: I have, however args are on build which means it would create a new image each time
[2018-08-15 10:10:16] <DinoSourcesRex> Or have I misunderstood?
[2018-08-15 10:10:45] <rcjsuen> I think I misunderstood your question.
[2018-08-15 10:10:48] <DinoSourcesRex> For example if I have 3 environments, dev, stage and prod - each with different credentials I would have 3 images instead of 1.
[2018-08-15 10:11:02] <rcjsuen> you say they are not "picking up the variables I am passing"
[2018-08-15 10:11:04] <rcjsuen> What do you mean
[2018-08-15 10:11:15] <rcjsuen> in your shell you setmongo_host=blah
[2018-08-15 10:11:19] <DinoSourcesRex> Yeah, that's right. Can I use environment variables in aDockerfile?
[2018-08-15 10:11:22] <rcjsuen> but in Docker when you build it still says--host host?
[2018-08-15 10:11:52] <DinoSourcesRex>  [<-CODE->] 
[2018-08-15 10:12:07] <DinoSourcesRex> That's the compose file I am using. Different credentials of course
[2018-08-15 10:12:24] <rcjsuen> Sounds to me like you should use a config file instead
[2018-08-15 10:12:44] <DinoSourcesRex> Would that let me pass in variables into a dockerfile?
[2018-08-15 10:12:53] <rcjsuen> well
[2018-08-15 10:12:57] <rcjsuen> MongoDB would read the config
[2018-08-15 10:13:00] <rcjsuen> and then figure out how to connect
[2018-08-15 10:14:33] <DinoSourcesRex> Wouldn't I still end up with 3 images there though?
[2018-08-15 10:15:15] <DinoSourcesRex> An image with a mongo config file per environment, in which case it doesn't really beat using arguments
[2018-08-15 10:15:24] <rcjsuen> No
[2018-08-15 10:15:30] <rcjsuen> Because you would volume mount the config file
[2018-08-15 10:16:25] <DinoSourcesRex> That makes sense.
[2018-08-15 10:16:58] <DinoSourcesRex> So, to be clear, there is no way to pass in environment variables to be used within my dockerfile?
[2018-08-15 10:17:02] <DinoSourcesRex> Only within the container?
[2018-08-15 10:17:57] <rcjsuen> Not that I know of. That wouldn't make sense in the context of how Docker images work.
[2018-08-15 10:18:35] <rcjsuen> Otherwise you use anENTRYPOINT
[2018-08-15 10:18:39] <rcjsuen> and then pass all that stuff in yourself by hand
[2018-08-15 10:19:14] <rcjsuen> ENTRYPOINT [ "mongorestore" ]and then whatever comes after you pass through on the CLI
[2018-08-15 10:19:22] <rcjsuen> I suppose that would be an alternative (in your particular scenario)
[2018-08-15 10:20:41] <DinoSourcesRex> I'll have to read up on how entrypoint's work. I'm still a docker novice so I'm not entirely sure on the ins and outs of these things.
[2018-08-15 10:20:44] <DinoSourcesRex> Appreciate the help!
[2018-08-15 10:21:18] <rcjsuen> Good luck@DinoSourcesRex
[2018-08-15 10:21:40] <DinoSourcesRex> Thanks@rcjsuen
[2018-08-15 11:41:34] <DinoSourcesRex> rcjsuen: Oh man...you're never going to guess how stupid I am.
[2018-08-15 11:42:20] <DinoSourcesRex> So. the issue with the environment variables was that I had a space in my docker-compose file when I was setting them. So something like$mongo_hostwould not work because the variable actually included a space
[2018-08-15 11:46:13] <rcjsuen> interesting
[2018-08-15 11:46:14] <rcjsuen> well then
[2018-08-15 11:52:05] <DinoSourcesRex> My original idea works, though, which is good.
[2018-08-15 12:49:01] <DinoSourcesRex> What is the ideal way to open a shell into a running container? Or to set my container up so that the entrypoint is a shell
[2018-08-15 12:52:56] <rcjsuen> DinoSourcesRex: The trick (?) we use at work is to usedocker exec
[2018-08-15 12:53:07] <rcjsuen> docker exec -it container_name /bin/bash(or/bin/ashif Alpine)
[2018-08-15 12:53:11] <rcjsuen> Does that work for you?
[2018-08-15 12:53:51] <rcjsuen> Of course if your container has no name you can use the ID
[2018-08-15 12:53:57] <rcjsuen> get fromdocker ps
[2018-08-15 12:54:11] <rcjsuen> But on that note I recommend having a name for the sake of sanity
[2018-08-15 13:23:36] <DinoSourcesRex> rcjsuen: My container is a short lived container, and I becauseexecrequires a running container I wouldn't be able to run that command (without a script) quickly enough. Is there an alternative, such as swappingexecforrun? If so, then that fails.
[2018-08-15 13:48:28] <rcjsuen> DinoSourcesRex: So instead of having your image run mongorestore, you want it to NOT do that but just open a shell?
[2018-08-15 19:10:56] <bicabone> Hi guys I am having an issue with docker-compose
[2018-08-15 19:11:00] <bicabone>  [<-CODE->] 
[2018-08-15 19:11:49] <bicabone> When i rundocker-compose upI get the following errors
[2018-08-15 19:12:00] <bicabone>  [<-CODE->] 
[2018-08-15 19:35:47] <bicabone> figured it out -- can't run 64 bit containers on a 32 bit VM
[2018-08-16 11:39:06] <hemachandsai> hello everyone
[2018-08-16 11:39:35] <hemachandsai> i had to use bind mount in my node project to track realtime changes in files
[2018-08-16 11:39:55] <hemachandsai> but how to mention the mount in dokcer file
[2018-08-16 11:40:13] <hemachandsai> because i have to execute some commands after mount
[2018-08-16 12:06:59] <hemachandsai> anybody to help?
[2018-08-16 12:38:03] <rcjsuen> Bind mounts are specific to a host so they don't belong in aDockerfile
[2018-08-16 14:28:55] <Dinodanio> Hallo all,i have some container in compose running and want to stop a single one with its volume [<-CODE->]  [<-CODE->]  [<-CODE->] the service is displayed
[2018-08-17 16:29:02] <adamretter> In a multi-stage docker file, does eachFROMcreate an intermediate image? In the docs, it seems to say no, or is confusing at best, but in experimentation here it seems to create an intermediate image for each stage
[2018-08-17 16:31:36] <adamretter> Ah crap. it looks like I was meant to ask this on FreeNode
[2018-08-17 16:32:58] <EnisG> adamretter: I also experienced that. It leaves dangling images for every stage
[2018-08-17 16:33:44] <adamretter> EnisG: right. Did you find any solution?
[2018-08-17 16:50:11] <aripim> Hi All, apologies if this isn't the correct venue.Ariel Pimentel from Manning Publications here. You may know us for books such as Docker in Action or Kubernetes in Action.Our readers have suggested they would like more Docker content, and we'd love to hear your perspective on what topics would be most valuable to the community at this pointWould anyone mind chatting to one of our acquisitions editors about this? It would be a huge help!In addition, anyone interested in creating content for books or video, please feel free to get in touch! You can DM me or reach out to arpi@manning.com
[2018-08-17 17:05:47] <adamretter> EnisG: I was suggested to usedocker image prune
[2018-08-17 17:07:08] <EnisG> adamretter: yes that will clean dangling images. Not sure if there is OOB solution to periodically clean these images
[2018-08-19 15:45:54] <patientplatypus> hi everyone
[2018-08-19 15:46:05] <patientplatypus> I am having this really horrible stackoverflow problem: [<-LINK->] 
[2018-08-19 15:46:26] <patientplatypus> if anyone has any suggestions or ways I can fix this please let me know on SO - thank you very much.
[2018-08-19 18:14:12] <eymriseFrance> Hello  look in for something to learn  here thanks I'm new...
[2018-08-21 13:53:57] <diegoquintanav> I need help with a docker-compose file [<-CODE->] 'Is there something I should be doing if I want to use this file with docker-toolbox in windows10 home? I've set COMPOSE_CONVERT_WINDOWS_PATHS=1, COMPOSE_FORCE_WINDOWS_HOST=1, and added these folders to shared folders as per this gist https://gist.github.com/first087/2214c81114f190271d26c3e88da36104also [<-CODE->] 
[2018-08-22 06:12:21] <pete013> Hello!Need some help here.I have hosted a docker container in a windows 10 enterprise system. The issue is that the Docker for Windows was run using a windows user account. After a few hours, the windows user logs out automatically, also the docker daemon is shutdown. However the system is still on.I need the docker daemon to remain running even after the user logs out.How to do that?Thanks
[2018-08-22 06:14:58] <mantoshelis> Hi, it's impossible because on user log out everything related with user (processes and etc.) is shut down.
[2018-08-22 06:17:11] <mantoshelis> Docker daemon should be as a service so it does not depend on user started it.
[2018-08-22 06:17:36] <pete013> Is there some way to run the docker daemon as system process?
[2018-08-22 06:17:49] <mantoshelis>  [<-LINK->] 
[2018-08-22 06:20:12] <pete013> Are there no configuration options in Docker?
[2018-08-22 06:21:40] <mantoshelis> I think is not Docker scope how you run it (process or system service).
[2018-08-22 06:23:47] <mantoshelis> As I see there should be registered Docker service in service list on Windows. You could change it to Autostart (delayed).
[2018-08-22 07:11:44] <albercuba__twitter> Hello everyone. Can someone please help me configure a docker compose file so i connects to a mysql database in a differnte host? I have never used Docker before and I've been looking for a solution to this for 2 days now.this is the DB part in the docker-compose file [<-CODE->] 
[2018-08-22 07:15:37] <MCPDanilovich> albercuba__twitter: As i undestood true, you want expose ports to host for this db running in docker ?
[2018-08-22 07:20:15] <albercuba__twitter> MCPDanilovich: no. I have a DB server installed in my network. Not in a docker container. Then I need my docker container to connect to this external DB server
[2018-08-22 07:21:55] <albercuba__twitter> So, if I understand correctly, this section of the docker compose file, creates a MySQL instance with that data
[2018-08-22 07:22:01] <albercuba__twitter> but I dont want that.
[2018-08-22 07:22:14] <albercuba__twitter> I want to connect to a different DB server
[2018-08-22 07:23:27] <albercuba__twitter> then I think this section connects to the database [<-CODE->] 
[2018-08-22 07:23:54] <MCPDanilovich> Why you want connect db in docker to external db ?
[2018-08-22 07:24:49] <albercuba__twitter> I don't want to connect a DB in docker to an external DB. I want my docker containers' apps to use an external DB
[2018-08-22 07:29:43] <MCPDanilovich> where ralf store db setting. ?
[2018-08-22 07:31:03] <albercuba__twitter> I have no idea. This guys have a very bad documentation
[2018-08-22 07:31:46] <albercuba__twitter> somewhere in here [<-LINK->] 
[2018-08-22 07:34:08] <albercuba__twitter> Can I do this?: [<-CODE->] 
[2018-08-22 07:37:49] <albercuba__twitter> OO I found it
[2018-08-22 07:38:15] <albercuba__twitter> the env file
[2018-08-22 07:38:41] <albercuba__twitter> right there in front of my eyes :p
[2018-08-22 07:39:06] <MCPDanilovich> Good. You should changes this vars to your real db data
[2018-08-22 07:39:33] <albercuba__twitter> and then delete the db section from the docker-compose file?
[2018-08-22 07:39:42] <MCPDanilovich> yes.
[2018-08-22 07:39:58] <MCPDanilovich> And you can delete db from links section in web service
[2018-08-22 07:40:08] <albercuba__twitter> ok thanks, gonna try that
[2018-08-22 18:37:05] <kirk86>  [<-CODE->] Thanks and again apologies!
[2018-08-22 19:29:18] <rcjsuen> T hey'll still be there.
[2018-08-22 19:29:24] <rcjsuen> Yes, they're a goner AFAIK.
[2018-08-22 19:29:48] <rcjsuen>  [<-ISSUE->] Uh...maybe you should explain what you're trying to do :)
[2018-08-22 19:30:03] <rcjsuen> kirk86: It sounds in a way like you're trying to use Docker as a reusable VM.
[2018-08-22 20:02:35] <kirk86> @rcjsuen thanks for replying. As  I said kind of new in the docker thing trying to wrap my head around it. So when you stop a container the newly installed stuff will still be there, right? Does a stopped container still consume system resources. I presume yes? [<-CODE->] 
[2018-08-22 20:16:57] <rcjsuen> kirk86: It shouldn't consume system resources.
[2018-08-22 20:17:27] <rcjsuen> rmiis for images,rmis  for containers
[2018-08-22 20:33:19] <kirk86> rcjsuen: cool thanks! so in general if avoidrmand just stop the container I should be safe restart and resume where I left off?
[2018-08-22 21:56:54] <obeyda> Hello,
[2018-08-22 21:57:27] <rcjsuen> kirk86: Yes. But again, I feel you should try to explain what you're trying to do...
[2018-08-22 21:57:41] <obeyda> I need to deploy an aspnet app on a docker
[2018-08-22 21:57:42] <rcjsuen> Without more context it's hard to say if you're using the right tool for the job
[2018-08-22 21:58:58] <obeyda> I need to deploy an aspnet app on a docker image, and I have a problem with certificate
[2018-08-22 21:59:17] <rcjsuen> kirk86: I would consider an "image" to be a blueprint and the "container" to be a built house. Perhaps that analogy will help. You can abandon the house (stop it) but if you destroy it it\'s lost forever (no you can\'t salvage the table legs or wood and brick)
[2018-08-22 22:12:42] <obeyda> Could anyone point me to a tutorial on how to install a certificate for aspnet core on a Linux container?
[2018-08-22 22:20:34] <kirk86> rcjsuen: Nice explanation thank you! Now things make more sense 
[2018-08-23 02:03:55] <Ishaan28malik> Hello everyone I am here to contribute
[2018-08-23 02:04:18] <Ishaan28malik> Can anyone pls send the link to join the org on github for contribution
[2018-08-23 02:12:16] <rcjsuen> Ishaan28malik: You don't need to join the organization to contribute to projects.
[2018-08-23 02:12:41] <rcjsuen> Make your changes, commit, push them to your fork on GitHub, and then open a pull request
[2018-08-23 08:07:44] <Ishaan28malik> Is there any direct link to be a member of org at github and then contribute to it
[2018-08-23 08:07:55] <Ishaan28malik> Or any guide pls let me know ...
[2018-08-23 11:52:18] <rcjsuen> Ishaan28malik: As I said, you don't need to be an org member
[2018-08-23 11:52:42] <rcjsuen> this might help get you started [<-LINK->] 
[2018-08-23 11:53:01] <rcjsuen> I assume you know Go, but even if you don't you can help with other things such as documentation or simply filing bugs!
[2018-08-23 13:06:02] <DinoSourcesRex> How do I build a docker image "on top" of another docker image? [<-CODE->] 
[2018-08-23 13:11:24] <LanderU> DinoSourcesRex: you can build your image on top of another image using in your Dockerfile the FROM of that image. FROM <the image that you want to base on>
[2018-08-23 13:22:09] <DinoSourcesRex> LanderU: Right but how do I run the docker image I am building on top of?
[2018-08-23 13:30:17] <rcjsuen> Well after you build it you can run it
[2018-08-23 13:30:30] <rcjsuen> So if you did likedocker build -t abc .
[2018-08-23 13:30:34] <rcjsuen> then you can now run yourabcimage
[2018-08-23 13:34:01] <DinoSourcesRex> @rcjsuen What would I set my entry point  to?If I have [<-CODE->] How do i start the root image using the saved files?
[2018-08-23 13:34:43] <rcjsuen> You would set your entrypoint...to what you want it to be #zing
[2018-08-23 13:34:57] <rcjsuen> for example a Linux image might be set to run/bin/bashor whatever
[2018-08-23 13:35:05] <rcjsuen> but your app might be configured to run your app
[2018-08-23 13:35:08] <DinoSourcesRex> Currently I executedocker run -p 8501:8501 -v /c/path:/models/mode -e MODEL_NAME=mode -t tensorflow/serving- I just want to have the directory within an image
[2018-08-23 13:35:09] <DinoSourcesRex> if that makes sense
[2018-08-23 13:35:36] <rcjsuen> Not really...or I'm just not reading it properly
[2018-08-23 13:35:44] <rcjsuen> But perhaps it sounds like you want the same entrypoint as thetensorflow/servingimage
[2018-08-23 13:35:52] <rcjsuen> So you can check its Dockerfile (assuming it is open source and all that good stuff)
[2018-08-23 13:46:19] <DinoSourcesRex> @rcjsuen I think it is open source, yes. [<-CODE->]  [<-CODE->] Does that make sense? Is it possible to somehow "save" a running container?
[2018-08-23 13:46:27] <DinoSourcesRex> Because that would basically give me what I need.
[2018-08-23 13:46:49] <DinoSourcesRex> I've trieddocker commitbut it doesn't seem to be saving the mounted files
[2018-08-23 14:58:36] <DinoSourcesRex>  [<-CODE->] Looks like that did the trick
[2018-08-23 19:00:38] <rcjsuen> It sounds to me like you should just use the same entrypoint that yourtensorflow/servingbase image is using then
[2018-08-23 21:53:00] <rcjsuen> I guess it inherited the original image's ENTRYPOINT then
[2018-08-23 22:07:51] <jamesalbert> I've never had this problem before. For some reason, I can't make any ssl requests on any container (alpine, ubuntu, etc). It just stopped working for some reason. I have the openssl packages installed. Anyone else have this problem before? Not a single so answer has helped me yet and I'm ripping my hair out at this point :)
[2018-08-23 22:11:28] <jamesalbert> In my fluster, forgot to post the actual errors. I've gotten a couple, so far I've seencurl failed to verify the legitimacy of the server and therefore could not establish a secure connection to it.andSSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed
[2018-08-23 22:11:52] <jamesalbert> I've seen these errors before, but usually installing openssl is enough to call it a day
[2018-08-23 22:14:07] <MCPDanilovich> try to use curl with -k key
[2018-08-23 22:14:19] <MCPDanilovich> -k, --insecure(TLS) By default, every SSL connection curl makes is verified to be secure. This option allows curl to proceed and operate even for server connections otherwise considered insecure.The server connection is verified by making sure the server's certificate contains the right name and verifies successfully using the cert store.See this online resource for further details:  https://curl.haxx.se/docs/sslcerts.htmlSee also --proxy-insecure and --cacert.
[2018-08-23 22:14:53] <jamesalbert> MCPDanilovich: thanks for the response, but I need a secure response
[2018-08-23 22:15:30] <jamesalbert> I'm not sure why this is happening, I've never wasted so much time on this error
[2018-08-23 22:15:57] <jamesalbert> I've also tried --cacert, same error
[2018-08-23 22:16:54] <MCPDanilovich> This is mean that remote server cert has issues
[2018-08-23 22:19:18] <jamesalbert> but no ssl requests are successful. Google, Amazon. All don't seem to work. I'm sure it's on my side, I just don't know what
[2018-08-23 22:19:46] <jamesalbert> host works just fine
[2018-08-23 22:23:38] <jamesalbert> throws computer
[2018-08-24 08:42:12] <Ishaan28malik> rcjsuen: thanks and how to join it on github ?
[2018-08-24 08:42:17] <Ishaan28malik> Like
[2018-08-24 08:42:39] <Ishaan28malik> Others have an option for contributers to join
[2018-08-24 10:01:18] <rcjsuen> Ishaan28malik: I don't think you can randomly join an organization. You can only be invite.d
[2018-08-24 13:07:36] <Ishaan28malik> Oh okay I will solve the issues
[2018-08-24 13:07:45] <Ishaan28malik> Pls provide the link for issues
[2018-08-24 13:08:12] <rcjsuen> Just look forhelp wantedissues
[2018-08-24 13:08:50] <rcjsuen> Never mind, I guess moby/moby doesn't actually use that tag lol
[2018-08-24 13:09:01] <rcjsuen>  [<-LINK->] 
[2018-08-24 13:09:08] <rcjsuen> Find something that interests you, make a comment and see how you can help
[2018-08-24 13:09:22] <Ishaan28malik> Ok let me chk thanks
[2018-08-24 13:11:44] <Ishaan28malik> error setting label on mount source '': no such file or directory [<-ISSUE->] 
[2018-08-24 13:11:52] <Ishaan28malik> I think I can work on this one
[2018-08-24 13:12:12] <Ishaan28malik> But what do I need to do for it like pls can u explain a little bit
[2018-08-24 13:12:18] <rcjsuen> Ask on the issue
[2018-08-24 13:12:26] <Ishaan28malik> Ok
[2018-08-24 13:12:30] <rcjsuen> express your interest on the issue and you want to help fix it, then ask for guidance/pointers
[2018-08-24 13:13:42] <Ishaan28malik> Ok I will do this thing thanks
[2018-08-24 13:15:17] <rcjsuen> Great! Thank you for helping making Docker better
[2018-08-24 16:42:36] <Ishaan28malik> My pleasure
[2018-08-25 01:30:16] <salman-ca> Hi, when using docker compose, i'm confused how I have 1 Dockerfile but inside of the docker-compose.yml I have multiple service definitions.
[2018-08-25 01:30:23] <salman-ca> do they all use the same Dockerfile?
[2018-08-25 01:31:03] <salman-ca> or what  if I need to customize the image for multiple services?
[2018-08-25 09:36:22] <mixja> If you reference the same Dockerfile in the service definition then they are using the same Dockerfile.  If you need to customise the image for different use cases your options are:Supply different command arguments and/or entrypoint to the same image\nCreate a different Dockerfile for each service\nUse a multi-stage build (see https://docs.docker.com/develop/develop-images/multistage-build/) which allows you to create images based upon named targets in your DockerfileIt really depends on your use case as to which option you should choose - they are all valid depending on the scenario.
[2018-08-25 19:02:13] <DinoSourcesRex> Has anyone got experience with digitalocean droplets and docker? I'm looking for the best way to pull an image from my local dev machine into a docker droplet.
[2018-08-26 11:42:02] <jdickey> Never done it from my local dev machine; just never investigated what all needs to be done to set up a Docker image registry there. I have two private images hosted on Docker Hub. They'll let you have one with a free account; more, you need to pay a few bucks a month
[2018-08-26 11:44:20] <jdickey> but I use Ansible to install and configure the Droplet; the image itself is as simple as runningdocker loginfrom the Droplet and thendocker pulland done
[2018-08-26 11:45:11] <jdickey> and of course they'll let you host as manypublicimages as you like on a free account
[2018-08-27 02:23:27] <mterron> Hi team, I run into a behaviour I don't understand with tmpfs. I create a dockerfile where I create a directory in /run and set some permissions. Then I docker run with a tmpfs over /run and my directory is gone. I expected the existing directory would still exist.
[2018-08-27 02:23:53] <mterron> Is my understanding wrong or is it just as designed? I can't see a way to use tmpfs the way it is since only root can write to it.
[2018-08-27 02:26:43] <mterron> The example give where you use mount does not work either, the mode is always 755 no matter what tmpfs-mode is set to
[2018-08-27 02:27:35] <mterron> My docker version is:
[2018-08-27 02:27:36] <mterron> Client: Version:           18.06.0-ce API version:       1.38 Go version:        go1.10.3 Git commit:        0ffa825 Built:             Wed Jul 18 19:09:33 2018 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          18.06.0-ce  API version:      1.38 (minimum version 1.12)  Go version:       go1.10.3  Git commit:       0ffa825  Built:            Wed Jul 18 19:13:46 2018  OS/Arch:          linux/amd64  Experimental:     false
[2018-08-27 03:15:13] <mterron> Is there any way to use tmpfs mounts without being root?
[2018-08-27 20:03:20] <mterron> Hi
[2018-08-27 20:03:23] <mterron> anyone home?
[2018-08-27 20:06:45] <rcjsuen> I've never usedtmpfsbefore. What are you trying to achieve and why are you choosing to usetmpfs?
[2018-08-27 20:09:18] <mterron> I want to run with read-only fs and use tmpfs for things like /run and /tmp
[2018-08-27 20:10:01] <mterron> So that the system can actually do something useful, but I found that tmpfs has 750 permissions for root only, so that means that you either run as root OR use tmpfs, but not both
[2018-08-27 20:10:55] <mterron> That'd be fine if Docker recreated the existing directories within /run with the correct permissions, but it just mounts an empty dir
[2018-08-27 21:05:55] <StevenSalazarM> Hello, i'm pretty new to the docker world and i have a question i hope it to dont get consider stupid :/
[2018-08-27 21:06:59] <StevenSalazarM> i just started mosquitto on docker virtual machine if i'm correct it is not possible to connect to it from outside right? (i mean from a device connected to my wifi lan)
[2018-08-27 21:10:57] <rcjsuen> That depends on your port binds
[2018-08-27 21:11:23] <rcjsuen> assuming you exposed ports that is also
[2018-08-27 21:11:56] <StevenSalazarM> mmm when i start mosquitto on windows i can connect to my windows machine
[2018-08-27 21:12:34] <StevenSalazarM> i think i need to map the ports of the virtual machine or something like that idk if i'm correct
[2018-08-27 21:12:39] <rcjsuen> Maybe this will help [<-LINK->] 
[2018-08-27 21:12:52] <rcjsuen> Assuming I understood your original question
[2018-08-27 21:13:55] <StevenSalazarM> yeah thats my question
[2018-08-27 21:14:03] <StevenSalazarM> i'm using docker toolbox does it change anything?
[2018-08-27 21:14:12] <rcjsuen> wow that sounds old
[2018-08-27 21:14:16] <rcjsuen> Are you like on Windows 7 or something
[2018-08-27 21:14:21] <StevenSalazarM> no
[2018-08-27 21:14:25] <StevenSalazarM> windows 10
[2018-08-27 21:14:30] <StevenSalazarM> but with home edition
[2018-08-27 21:14:39] <rcjsuen>  [<-LINK->] 
[2018-08-27 21:14:41] <rcjsuen> read the big bold letters
[2018-08-27 21:17:06] <StevenSalazarM> yeah in the requirements it says The current version of Docker for Windows runs on 64bit Windows 10 Pro, Enterprise and Education (1607 Anniversary Update, Build 14393 or later).
[2018-08-27 21:17:26] <StevenSalazarM> i'm using windows 10 home edition
[2018-08-27 21:55:48] <StevenSalazarM> i found this [<-LINK->] thank you anyway
[2018-08-28 18:55:09] <ctrado18> hey guys
[2018-08-28 18:55:36] <ctrado18> I am doing this intro here [<-LINK->] 
[2018-08-28 18:56:07] <ctrado18> But typing in [<-LINK->] in my browser doesn't work...
[2018-08-28 18:56:24] <ctrado18> after running docker run -p 4000:80 friendlyhello
[2018-08-28 18:56:32] <ctrado18> I use docker toolbox under windows 10 home
[2018-08-28 18:57:00] <ctrado18> building worked but not running
[2018-08-28 19:03:06] <tstackhouse> Toolbox does not use localhost, it creates a VM using virtualbox
[2018-08-28 19:03:48] <tstackhouse> Use the IP of that box (usually 192.168.99.100) and that should work, e.g. [<-LINK->] 
[2018-08-28 19:04:56] <ctrado18> thanks!
[2018-08-28 19:05:52] <tstackhouse> no prob!
[2018-08-28 19:07:02] <tstackhouse> I'm running into an issue withdocker-compose upI have all my services (around 10-15) consolidated under a compose file and when I rundocker-compose up -dit often fails and complains about COMPOSE_HTTP_TIMEOUT
[2018-08-28 19:07:33] <tstackhouse> it's set to 60s by default, should I just increase that value?
[2018-08-28 19:32:02] <ctrado18> hey again
[2018-08-28 19:32:19] <ctrado18> I get in my toolbox such an error
[2018-08-28 19:32:34] <ctrado18>  [<-CODE->] 
[2018-08-28 20:18:16] <webertrlz> hey
[2018-08-28 20:18:45] <webertrlz> I see VXLAN packets sent to the wrong host when ping from one container to another, using overlay networks and consul as cluster-store
[2018-08-28 20:19:27] <webertrlz> ping from host A to B results in the VXLAN package beeing set from A to C instead of A to B
[2018-08-28 23:48:16] <brentarias> I want to pull a specific WordPress image (4.9.8).  I'm using Docker for Windows.   When I visit the Docker WordPress page, it gives me dozens of tags (100+) that are listed as pertinent to the major categories of apache, fpm, fpm-alpine, or cli.  I have no idea which of these applies to Docker on Windows.  I don't know if I shoulddocker pull wordpress:4.9.8-fpmordocker pull wordpress:4.9.8-apache.  I don't even know if that is how tags are meant to be supplied.  Help! :)
[2018-08-29 00:50:20] <jrbrowny> I've a small survey about agile methods, it takes a minute, could you please help me with it? [<-LINK->] 
[2018-08-29 10:57:24] <rcjsuen> brentarias: That is how tags are supplied, yes
[2018-08-29 13:44:30] <webertrlz> how can I force docker to refresh/reload the VXLAN fdb entries?
[2018-08-29 14:07:25] <dhanupreeth_twitter> Hi Folks
[2018-08-29 14:07:41] <dhanupreeth_twitter> am looking for Docker-compose.yml for Ruby + Postgres
[2018-08-29 14:08:20] <dhanupreeth_twitter> here is my docker-compose.yml code
[2018-08-29 14:08:54] <dhanupreeth_twitter> Docker Compose to setup development environment```version: '2'services:  db:    image: postgres    environment: [<-CODE->] web:    image: ruby-2.4.1    environment: [<-CODE->] 
[2018-08-29 14:09:45] <dhanupreeth_twitter> am not able to use Production database
[2018-08-29 14:09:56] <dhanupreeth_twitter> please help
[2018-08-29 15:26:15] <renatop7> Hello everyone
[2018-08-29 15:26:20] <ctrado18> I have build an image listed also in registry but run it gives just a string like66bd0574cd6f96e1c46fea77d3a133d47c05e105a6e890ac6b391227c5707723and looking indocker container lsthere is no container?
[2018-08-29 15:26:45] <ctrado18> I use dokcer toolbox in windows
[2018-08-29 15:27:18] <renatop7> The docker's doc says that I can run docker on my yosemite, but when I try to run it, it says I need a new version for my mac
[2018-08-29 15:27:49] <renatop7> Do I need some config or other package to make it work?
[2018-08-29 15:32:19] <ctrado18> also within toolbox I get for my python script:
[2018-08-29 15:32:22] <ctrado18> python: can't open file 'bot.py': [Errno 2] No such file or directory
[2018-08-29 15:32:31] <ctrado18> for
[2018-08-29 15:32:34] <ctrado18> docker run -p 4000:4000 bot
[2018-08-29 15:32:54] <ctrado18> i am in same dir when running like bot.py
[2018-08-29 16:57:52] <rcjsuen> ctrado18: Perhaps you should launch your Docker container with a custom entrypoint to/bin/bashor something so you can inspects its contents
[2018-08-29 17:43:19] <webertrlz> anyone familiar on how docker manages vxlan fdb entries?
[2018-08-29 18:58:39] <brentarias> Using Docker for Windows, I typeddocker pull wordpress:4.9.4.  Because that "4.9.4" tag does not exist, I get "incorrect user name or password".  How do I find the proper 4.9.4 tag?  Currently the docker wordpress repository shows only tags for 4.9.8.
[2018-08-29 18:59:40] <rcjsuen> It's not listed [<-LINK->] 
[2018-08-29 18:59:43] <rcjsuen> maybe they d eleted it?
[2018-08-29 19:18:46] <brentarias> I can't imagine they would ever delete such tags.  In fact, there is no point in having a tag system if they simply delete all the old ones as soon as they have new ones.
[2018-08-29 19:22:02] <rcjsuen> Devil's advocate, I would delete my tag if it has a security issue or whatever
[2018-08-29 21:22:26] <brentarias> I figured it out.  I was logged into my docker account with my e-mail instead of my user name.  Both point to the same account, but if I'm logged in with my e-mail I have a very limited range of repositories i can reach.  I was able todocker pull hello-worldbut nothing from wordpress would pull.  Now I'm logged in with my username, and everything is fine.
[2018-08-29 22:52:45] <rcjsuen> interesting
[2018-08-30 00:24:11] <rachel-coder> hey :) in case anyone is interested we're hiring US Residents (relocation to Austin TX covered) for Golang Backend positions :) this is the job link: [<-LINK->] our website: [<-LINK->] 
[2018-08-30 09:31:37] <katsar0v> Hey guys, is there a simple tutorial on the web where I can link two physicals servers running docker? I've read about overlay networking and key-value storage like Consul, but seems really complicated for a beginner. Is there something well explained on the web I can use?
[2018-08-30 10:21:00] <katsar0v> Also I do not want to use docker in swarm mode, just normal as usual.
[2018-08-30 12:09:16] <kayvanbree> Hey guys
[2018-08-30 12:09:29] <kayvanbree> I'm trying to follow a tutorial at [<-LINK->] 
[2018-08-30 12:11:57] <kayvanbree> I'm stuck. I bought a VPS a few days ago.docker-compose up -dshould run three containers: nginx, nginx-letsencrypt and nginx-gen
[2018-08-30 12:12:13] <kayvanbree> when I rundocker psI don't see nginx-gen
[2018-08-30 12:12:51] <kayvanbree> I did create another container to run a website on. The code is at [<-LINK->] 
[2018-08-30 12:13:38] <kayvanbree> When I set the virtual port inautomated_nginx_demoto 3000, I could actually reach the Angular page running on that container.
[2018-08-30 12:14:32] <kayvanbree> When I rundocker psI see thatautomated_nginx_demohas exposed port 80, butnginxdidn't. Still, I can't reach my demo site
[2018-08-30 12:15:08] <tim-klug> have you checkeddocker-compose psanddocker-compose logs <NameOfYourService>. Do you get any information why one container might crash?
[2018-08-30 12:29:03] <kayvanbree> I trieddocker-compose logsbut I didn't know you could do that per service. Also didn't know about thedocker-compose pscommand
[2018-08-30 12:30:07] <tim-klug> you can run most of the docker-compose commands per service, like restart, stop, etc
[2018-08-30 12:30:33] <kayvanbree> docker-compose pssays the state of nginx-gen is Exit 1
[2018-08-30 12:30:53] <kayvanbree> So I guess I should rundocker-compose up nginx-genand see what it logs?
[2018-08-30 12:31:30] <tim-klug> you can even rundocker-compose logs nginx-gento see why it crahsed
[2018-08-30 12:31:52] <kayvanbree> it saysunable to parse template: read /etc/docker-gen/templates/nginx.tmpl: is a directory
[2018-08-30 12:31:55] <kayvanbree> thats a big clue
[2018-08-30 12:32:02] <kayvanbree> let me check some stuff
[2018-08-30 12:32:13] <kayvanbree> and it crashed instantly
[2018-08-30 12:34:56] <kayvanbree> On the host,/etc/docker-genisn't even a directory. I guess this is inside the nginx-gen container. Can I use docker-compose to run likedocker exec?
[2018-08-30 12:39:40] <kayvanbree> docker-compose exec nginx-gen /bin/shdoesn't work because the container is constantly restarting.
[2018-08-30 12:42:06] <tim-klug> /srv/www/nginx-proxy/nginx.tmplshould be a file or folde on your host system
[2018-08-30 12:43:06] <tim-klug> nginx.tmplInside /nginx-proxy/, create a nginx.tmpl file and copy the content from this file. This is the used by the nginx-gen container to create the nginx configuration file for each website / container added to the network.
[2018-08-30 12:46:25] <kayvanbree> There's a folder in that location indeed :D
[2018-08-30 13:40:29] <kayvanbree> I copy my nginx.tmpl to the correct location in my Jenkins pipeline now. It works for my main domain. Gonna check if it works for a subdomain now
[2018-08-30 13:40:31] <kayvanbree> Thanks!
[2018-08-30 14:04:31] <amirensit> I get this error while trying to run docker quickstart terminal on windows 10
[2018-08-30 14:04:39] <amirensit>  [<-LINK->] 
[2018-08-30 14:05:06] <amirensit> I followed many instructions from here but It didn't work
[2018-08-30 14:05:07] <amirensit>  [<-ISSUE->] 
[2018-08-30 14:15:06] <kayvanbree> Hmmmm. Subdomains still don't work.
[2018-08-30 15:01:40] <kristoffer.johansson_gitlab> when creating a Dockerfile for an image to run on kubernetes with a volume, do i need to specify volume in the Dockerfile or will kubernetes automatically mount in the volume for me? thanks
[2018-08-30 18:14:15] <jmunson> For some reason the overlay network does not seem to be working for me in swarm mode. I have 3 nodes and if I create a service with --publish mode=host,  it listens fine, but if I just --publish with the default mode, none of the nodes start listening on the port on any interface (tested via sshing in and usingss -ntpl)
[2018-09-02 07:41:43] <thecyberd3m0n_gitlab> HI everyone
[2018-09-02 07:43:20] <thecyberd3m0n_gitlab> I'm trying to build image at bitcoin-core base, using Dockerfile with commandFROM kylemanna/bitcoindor others, but getting errors that manifest not found
[2018-09-02 07:44:09] <thecyberd3m0n_gitlab> it's little wierd that one of images actually works
[2018-09-02 07:46:18] <thecyberd3m0n_gitlab> https://hub.docker.com/r/felixweis/bitcoind/this docker, and simple docker pull also not working
[2018-09-02 07:55:51] <thecyberd3m0n_gitlab> I must do something wrong
[2018-09-03 07:00:15] <babaorum> thecyberd3m0n_gitlab: have you tried with a specific tag ? Like this : kylemanna/bicoind:0.14
[2018-09-03 07:00:47] <babaorum> By defaut docker try with the default tag "latest" but it may not be set by the image
[2018-09-03 08:04:00] <katsar0v> Hello guys, did anyone saw this issue already? [<-ISSUE->] I found no documentation about it
[2018-09-03 08:14:39] <babaorum> katsar0v: I think it's related to this : [<-ISSUE->] 
[2018-09-03 08:16:03] <babaorum> specially this one : [<-LINK->] 
[2018-09-03 08:19:08] <katsar0v> Where are this 125 layers defined? No documentation found. I know the layers are a lot, but inheriting in another image with "FROM" does not help
[2018-09-03 08:23:05] <katsar0v> And is there any solution / recommendation to the problem provided? I mean what should I do if I have lot of layers which cannot be really optimized much. Is this an officialdockerlimitation?
[2018-09-03 08:26:50] <babaorum> have you seen this : [<-LINK->] ?
[2018-09-03 08:27:28] <babaorum> but I feel like it's not a recommanded way to go ...
[2018-09-03 08:27:39] <babaorum> but it can help you understand it better
[2018-09-03 08:30:11] <babaorum> I think you should experiment some ways to optimize you dockerfile either by creating sub images, or by fusionning some layers
[2018-09-03 08:30:54] <katsar0v> Also read this https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#minimize-the-number-of-layersI think it is a bit more clear now. Maybe it is better to encapsulate a set of 50 instructions into a shell script and just run it.The problem is that also sub-images do not help, it is the total amount 125 layers from base image that count...
[2018-09-03 08:31:40] <katsar0v> If I have an image that has non-sudo user which has its own apps with own settings and permissions, maybe I should not set all this in theDockerfile, as it takes too much layers
[2018-09-03 08:33:14] <babaorum> I think the best way to think about dockerfile layers are in terms of caching. You will generally fusion some instructions this way.
[2018-09-03 08:36:11] <katsar0v> Okay, I guess the issue I opened in github required just some more clarification and documentation, why docker has this limits and what can be done.
[2018-09-03 14:30:22] <HusainMirahmadi_twitter> Hi
[2018-09-03 14:30:32] <HusainMirahmadi_twitter> Is Docker on windows reliable ?
[2018-09-03 14:32:13] <roelzkie15> Good day!I have a postgres that runs on docker container. And I define my docker-compose.yml [<-CODE->]  [<-CODE->] host: 0.0.0.0port: 5432maintenance db: postgresusername: postgresThere is no password in the development server database.The connection was successful however I can't view a single table from the database.Did anyone came across this issue?  I highly appreciate all information. Thank you
[2018-09-03 14:46:34] <jrbrowny> I know this is out of topic here but trying to get as much as data we can. Can you please help me understand your use of agile methods by completing this one minute survey [<-LINK->] If you are from Africa, that would be double winThank you
[2018-09-03 17:52:20] <guiguetz> hiya!
[2018-09-03 17:54:09] <guiguetz> Can you guys help me on a stuff i couldn't found with Google-Fu? I'm using docker with python and my IDE shows the dependencies/imports on the image as not found in the host. To use properly that feature do i need to install it on the host, or there is a remote way to get this deps? :(
[2018-09-04 02:37:58] <milkylee> Good day! I want to ask something about my laravel application using datatable ajax. Running locally, it works and displays all the content of my data but as I run it with docker-compose, it's experiencing 500 error on network console and upon looking on the data, it displays the error SQLSTATE[42000]: Syntax error or access violation: 1064 You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'offset 0' at line 10. What could be the possible issue?
[2018-09-04 08:27:36] <OOPMan> Hey all, I have a quick question about volumes, binds and docker-compose. I have a project where I want to bind a specific directory to mount in my container  in read-only mode and then mount writeable volumes in certain sub-directories of the mounted read-only directory. I tried setting this up but got a complaint about the specific location I was mounting the volume to being RO. Is there a way around this?
[2018-09-05 11:05:38] <darrenstarr> HusainMirahmadi_twitter: I know this is a bit late, but yeh... I have absolute faith in Docker on Windows (even though I'm hosting on Linux). It will be even more impressive once Docker for Windows can host both Windows and Linux containers simultaneously using WSL as a replacement for the Linux kernel. I've noticed some action on cgroups emulation in recent WSL builds.
[2018-09-05 11:08:00] <darrenstarr> roelzkie15: This is a strange request. I would imagine that you should use localhost for your destination connection. 0.0.0.0 means IP_ANY which means that your container is bound to all interfaces (within the same routing context) on that port. 127.0.0.1 is the loopback for local host you'd like to attach to. Beyond that, you'll want to view the logs for both applications.
[2018-09-05 11:10:50] <darrenstarr> guiguetz: I'm pretty confused on many levels about the question. Are you referring to dependencies for an image? Or are you talking about Python dependencies (I.E. stuff pip would fetch)? ... please be more specific. :) As for handling things in Docker remotely,  have you configured TLS connectivity properly and are you using the right certificates?
[2018-09-05 11:14:01] <darrenstarr> OOPMan: You were trying to do precisely what I was planning to do as well, so I tried to lab it. I have a strong suspicion that we are both trying to use Docker inappropriately. I think the readonly volumes should be exclusively readonly... then simply make a read-write volume in parallel. There's no real limitation to how large of a scale you can work with here. Also, you're not really trying to make something that looks pretty when you manage it. It's something for software to use. As such, you can make as big of a mess as you'd like and so long as it doesn't make things hard to manage, it's all good. Of course, I realized after the fact that trying to simulate permissions within a tree the way you and I both had hoped would actually make things more difficult to manage and secure.
[2018-09-05 15:58:04] <guiguetz> darrenstarr: 
[2018-09-05 15:59:47] <guiguetz> I'm sorry. My English doesn't work so well after two days up and some coffee. As soon as I get in the office I'll try to rephrase it! (I'm already on my way! :) But thanks in advance!)
[2018-09-05 16:39:44] <guiguetz> Well. let me explain a bit of my setup. I started at a company, and I was assigned to a current project, where we are using Docker to build a chatbot, and as it\'s an experimental project, we are kinda of "go-horseing", trying to follow good practices and such, but neither me or my coworker are WELL VERSED on the tech. We are learning stuff as we build it.For local development, we use 2 Windows laptops, with the Docker Quickstart (@ home i got arch with docker) set up. We try to keep the machine as clean as possible of dependencies and other stuff, to avoid having dependency conflicts and any other stuff.Our docker setup is currently made of a compose with images:Django backend;\nPython3 (pika+tornado) websocket\nPython3 (rasa core) NLU/NLP\nNode.js frontend.The idea is to make them all separate to make it easier if need to scale and/or replace any part of our workflow (we currently use kubernetes too, to send them to the cloud).We are using vscode as our main IDE, and it\'s where our problems start.As on our hosts machines we got only python + pip, for instance, any of the - for example - Py3Rasa image dependencies show up in our local code with "red snakes" on our from statements, ctrl clicking stuff to get into the classes isn\'t available and such, which is expected, since our deps which provide that info are all on our image/containers.Our question is if there is a proper way to connect our image dependencies to the IDE, so we can improve our debugging overall, could you understand me? Maybe it\'s something simple, guess maybe I couldn\'t find the proper search keywords/phrasing to explain...There is also, as we\'re on topic of host-image communication: we\'re using different techs in separate images. What is the good practice/way of generating documentation for it? For now, I\'m thinking on have readme.md files in all folders with detailed instruction, but it\'s kinda "manual". Is there any way to wrap our images/compose and try to autodoc them all in a single stuff, or should I focus instead on making something manually?Thanks, friend! :)
[2018-09-05 17:38:37] <alexspence> I'm working on a .net framework app that I want to fully dockerize the build process.  I have a WebApp and a console app that need separate containers.  I currently have dockerfiles that will build the correct docker images once the source is built, but I'm struggling to find the best way to compile the sources inside of a docker container, then build out the other two containers.
[2018-09-05 17:40:42] <alexspence> Does anyone have any suggestions here?  I've considered making a root image that compiles the sources as a base image for the other containers, but I'm looking for ideas on best practices here
[2018-09-05 20:47:09] <rcjsuen> alexspence: Perhaps build stages would help?
[2018-09-06 04:35:23] <darrenstarr> guiguetz: Wow... this is a really common problem I run into all the time with VSCode. I code almost exclusively on a Surface Book 2 running Windows and WSL. I recently wrote a Linux kernel module in C and also I work almost entirely with C# for the rest of my code... I see a lot of red snakes. There are a few options you have (I'm not a Python expert AT ALL) but one option I can think of is to mount your Python pip cache as a volume to the Docker container which contains your platform. The better option of course is to simply pip as many dependencies as possible to your development machine. If you're using Visual Studio Code with WSL, you can do it pretty much all within the bash shell within Code. However, this is something I think would be extremely good to ask in the Visual Studio Code forums as this is a very common problem for anyone developing server side code.
[2018-09-06 04:37:37] <darrenstarr> alexspence: Visual Studio Alex Ellis started the ball rolling a while back on multi-stage building. I'm starting work on that today myself. I'm actually quite bored of building for multiple architectures and having to wait for dotnet restore to complete on each one.
[2018-09-06 04:41:18] <darrenstarr> alexspence: Alternatively, Visual Studio with Docker Compose can perform progressive compiles for debugging on Docker. I've looked into this as well, it seems a promising option. It maintains a monster of a container which you pretty much work inside of and every time you compile (even when you just save a file) it rebuilds the container on the fly. That container should never be used in production, so you'd want to properly docker-compose build it instead. But you should seriously be using docker-compose for as much of the work as possible. If you want to connect everything together, you can have a separate composer file which deploys everything with networks and such. In that case, I recommend having a little more robust environment like a Swarm. VS also has support natively for K8S, though I decided K8S is slowly devolving into a mess of trying to be everything to everyone and eventually nothing to anyone. (purely a person and emotional feeling)
[2018-09-06 09:30:56] <tonyx> morning: I have a web app based on postgres and mono, and when I run it in the real machine, it can detects printers. I can dockerize the app, using docker-compose, but I haven't been able to use the printer from the dockerized app, yet, and I am looking for some suggestion, if someone can  kind enough to give me some. Grazie.
[2018-09-06 13:08:52] <happyhaha>  [<-CODE->]  [<-CODE->] Why does it fire up 2 requests when I visit my website from the browser? [<-CODE->] 
[2018-09-06 13:09:53] <happyhaha>  [<-LINK->] 
[2018-09-06 14:36:17] <darrenstarr> tonyx: I would need more information to provide any useful response. Printer discovery happens in many different ways. The most common method in recent times is to make use of Apple Bonjour also known as ZeroConf or in more advanced terms mDNS. mDNS makes use of an enhanced multicast version of DNS with TXT records containing SDP information (If I understand it correctly). The issue you're having is that since you're not within a domain which is routing multicast as though it's on the same site, the mDNS/ZeroConf/Bonjour messages are being squashed between the virtual and the physical networks. On Linux, typically we use Avahi as the mDNS tools. You may want to consider researching how you might create an mDNS proxy between the two networks to allow for printer service discovery.
[2018-09-06 14:38:14] <darrenstarr> happyhaha: There's nothing wrong with your configuration so far as I can tell.  Have you tried deleting the stack and redeploying it?
[2018-09-07 08:44:21] <darrenstarr> Does anyone know if there's a good way that I can take a container I deployed using deployment mode global and have it both on the overlay network and also expose a port on the physical device? I've written a syslog server which operates on UDP port 514, I want it in a container. And when it receives a syslog message, it relays it to the app server over the overlay network. Any thoughts?
[2018-09-08 12:43:08] <jrbrowny> Hi all, I'm trying to get responses for a small survey about agile methodologies. I would be very happy if you can participate. It's a one minute survey and would be great to have more data points. [<-LINK->] 
[2018-09-09 07:22:06] <tonyx> thanks @darrenstarrI\'d like to find the simplest solution that may work, with the simplest steps.For example:First step could be: at least being able to emulate a printer in the "docker virtual machine", changing thedocker-compose.yml file at it, in that way at least when the program try to discover the printer, then it will find something instead of giving an error.Second step would be making the the real printer visible from the "docker virtual machine", and from the app that runs in it (and I know that the discovery printers works if I run the app in the "real" machine).
[2018-09-10 01:04:22] <Ne0nx3r0> Hey could anyone recommend me a simple web-based reporting tool to show basic stats (containers up/down, CPU/RAM/HD usage, etc.) for a group of three standalone docker servers?
[2018-09-10 01:04:30] <Ne0nx3r0> Kind of like Portainer, but I don't care as much about administration as reporting
[2018-09-10 01:05:24] <harshana5> Ne0nx3r0: tried datadog
[2018-09-10 01:05:42] <harshana5> ?
[2018-09-10 01:06:59] <Ne0nx3r0> That does look pretty cool
[2018-09-10 01:08:34] <Alexander1984z> O
[2018-09-10 02:56:24] <darrenstarr> tonyx: I'll still point you towards Avahi which you can run as a docker image. Once you do that, you can configure it as a client which advertises services. The principle would be the same as if you were setting up a web server to pretend to be a web controlled device, but mDNS is its own protocol. If you're using Kubernetes, you should be mindful of the network overlay you're using since I believe (though I'm not sure) that layer-2 solutions such as Flannel can cause excessive flooding on a switch if IGMP snooping isn't properly configured. And layer-3 solutions like Calico may require the underlying network to support multicast, though I believe I've read that in both cases, multicast might be handled through unicast replication. I haven't figured out yet that level of detail about Swarm networks, but I'll have to soon as I'm using Swarm now that it's pretty much surpassed K8S for DIY clouds.
[2018-09-10 08:55:11] <MonXBZH> Hello there ! o/Is there a way to find which container is using an AUFS ?Docker-ce 17.05
[2018-09-10 10:52:41] <rcjsuen> Ne0nx3r0: You can try DataDog or ServerDensity. SD is cheaper but not as popular.
[2018-09-10 10:54:41] <rcjsuen> And of course, cAdvisor/Prometheus/Grafana is always an option. You should keep auth in mind if you are using cAdvisor though (especially if your host is accessible via the public).
[2018-09-10 21:52:53] <james-shoemaker> I'm having problems with docker for windows [<-ISSUE->] 
[2018-09-10 22:02:50] <james-shoemaker> it prompts to share C when I run docker-compose, but it doesn't seem to work
[2018-09-11 03:25:42] <tusharbudhe0302> james-shoemaker: what command you are using ?
[2018-09-11 04:50:59] <darrenstarr> MonXBZH: I don\'t have anything that old to test on, but you should be able to use AUFS tools to get the AUFS tree and then use "docker volume ls | grep -i aufs" to link AUFS volumes to volume names and then use docker inspect... it\'ll be a script more than a one-liner but it shouldn\'t be too bad
[2018-09-11 04:52:20] <darrenstarr> rcjsuen: OUcH!!! I just looked at the pricing on ServerDensity, I pay less for my servers than I would pay for server density after 3 months :(
[2018-09-11 04:53:38] <darrenstarr> james-shoemaker: have you tried setting it from the GUI manually?
[2018-09-11 10:35:50] <rcjsuen> darrenstarr: Yeah, that's their pricing scheme unfortunately
[2018-09-11 10:36:17] <rcjsuen> I guess it's working out for them though
[2018-09-11 13:38:54] <alagane> Hi, I just wonder why is there nodocker containerscommand, becausedocker imagesexists? (and then, is it a good idea to add it?)
[2018-09-11 13:40:13] <rcjsuen> alagane: Maybe you wantdocker ps?
[2018-09-11 13:40:40] <alagane> Yes, I found it, but was wondering why notdocker containers:)
[2018-09-11 13:41:18] <rcjsuen> The Lord works in mysterious ways
[2018-09-11 13:43:22] <alagane> Is it worth it to create an issue to add this command?
[2018-09-11 13:45:19] <alagane> (oh ok, I think I can directly make a PR)
[2018-09-11 15:10:35] <james-shoemaker>  [<-LINK->] 
[2018-09-11 15:10:39] <james-shoemaker>  [<-LINK->] 
[2018-09-11 15:10:49] <james-shoemaker> darrenstarr: when I try and set it from the gui it crashes docker.
[2018-09-11 15:13:11] <darrenstarr> alagane: I'm not sure what I would expect to see fromdocker containersif it were a command. There'sdocker psanddocker ps -a. Whatever containers docker knows about are pretty much there. Of course, I sometimes wish there were better commands for filtering.
[2018-09-11 15:14:01] <rcjsuen> I think@alaganemeant as an alias maybe
[2018-09-11 15:14:06] <alagane> An alias yes
[2018-09-11 15:14:25] <rcjsuen> I'm not sure a PR would fly as you can just alias that yourself in yourbashrc
[2018-09-11 15:14:40] <darrenstarr> james-shoemaker: That\'s a huge "ouch". I haven\'t tried debugging docker issues like this on Windows for a LONG time. I think I found most of the information of interest in event viewer though since the issue is generally with docker as a service on Windows.
[2018-09-11 15:15:47] <james-shoemaker>  [<-LINK->] 
[2018-09-11 15:15:50] <james-shoemaker> diagnose and feedback crashes with
[2018-09-11 15:16:08] <darrenstarr> rcjsuen: and@alaganehmm... I agree with remy with the bashrc solution. And to be honest, thanks to the stack extensions, docker is already beginning to get a little bit cluttered on the command line options. Doing adocker --helpis almost scary now :)
[2018-09-11 15:17:08] <alagane> Okok
[2018-09-11 15:17:22] <denchp> I am dying here... Does anyone know how you set up a dockerfile to enable a nodejs app connect to anexternalSQL Server instance?  I\'ve tried in windowsservercore and nanoserver, neither seems to like whatI\'mdoing...  And all instructions on Google are "how to containerize your SQL server"... I\'m at my wits end with this...
[2018-09-11 15:18:47] <james-shoemaker> darrenstarr: "Application: Docker for Windows.exeFramework Version: v4.0.30319Description: The process was terminated due to an unhandled exception.Exception Info: System.TypeLoadExceptionat System.Reflection.RuntimeAssembly.GetType(System.Reflection.RuntimeAssembly, System.String, Boolean, Boolean, System.Runtime.CompilerServices.ObjectHandleOnStack)at System.Reflection.RuntimeAssembly.GetType(System.String, Boolean, Boolean)at System.Activator.CreateInstance(System.String, System.String, Boolean, System.Reflection.BindingFlags, System.Reflection.Binder, System.Object[], System.Globalization.CultureInfo, System.Object[], System.Security.Policy.Evidence, System.Threading.StackCrawlMark ByRef)at System.Activator.CreateInstance(System.String, System.String)at MS.Internal.AssemblyHelper.LoadExtensionFor(System.String)at MS.Internal.AssemblyHelper.ExtensionsForSystemData(Boolean)at MS.Internal.SystemDataHelper.IsDataSetCollectionProperty(System.ComponentModel.PropertyDescriptor)at MS.Internal.Data.ValueTable.ShouldCache(System.Object, System.ComponentModel.PropertyDescriptor)at MS.Internal.Data.DataBindEngine.RegisterForCacheChanges(System.Object, System.Object)at MS.Internal.Data.PropertyPathWorker.ReplaceItem(Int32, System.Object, System.Object)at MS.Internal.Data.PropertyPathWorker.UpdateSourceValueState(Int32, System.ComponentModel.ICollectionView, System.Object, Boolean)at MS.Internal.Data.ClrBindingWorker.AttachDataItem()at System.Windows.Data.BindingExpression.Activate(System.Object)at System.Windows.Data.BindingExpression.AttachToContext(AttachAttempt)at System.Windows.Data.BindingExpression.AttachOverride(System.Windows.DependencyObject, System.Windows.DependencyProperty)at System.Windows.Data.BindingExpressionBase.OnAttach(System.Windows.DependencyObject, System.Windows.DependencyProperty)at System.Windows.DependencyObject.SetValueCommon(System.Windows.DependencyProperty, System.Object, System.Windows.PropertyMetadata, Boolean, Boolean, System.Windows.OperationType, Boolean)at System.Windows.Data.BindingOperations.SetBinding(System.Windows.DependencyObject, System.Windows.DependencyProperty, System.Windows.Data.BindingBase)at System.Windows.Controls.GridViewRowPresenter.CreateCell(System.Windows.Controls.GridViewColumn)at System.Windows.Controls.GridViewRowPresenter.OnPreApplyTemplate()at System.Windows.FrameworkElement.ApplyTemplate()at System.Windows.FrameworkElement.MeasureCore(System.Windows.Size)at System.Windows.UIElement.Measure(System.Windows.Size)at System.Windows.Controls.Grid.MeasureCell(Int32, Boolean)at System.Windows.Controls.Grid.MeasureCellsGroup(Int32, System.Windows.Size, Boolean, Boolean, Boolean ByRef)at System.Windows.Controls.Grid.MeasureOverride(System.Windows.Size)at System.Windows.FrameworkElement.MeasureCore(System.Windows.Size)at System.Windows.UIElement.Measure(System.Windows.Size)at System.Windows.Controls.Border.MeasureOverride(System.Windows.Size)at System.Windows.FrameworkElement.MeasureCore(System.Windows.Size)at System.Windows.UIElement.Measure(System.Windows.Size)at System.Windows.Controls.Border.MeasureOverride(System.Windows.Size)at System.Windows.FrameworkElement.MeasureCore(System.Windows.Size)at System.Windows.UIElement.Measure(System.Windows.Size)at System.Windows.Controls.Control.MeasureOverride(System.Windows.Size)at System.Windows.FrameworkElement.MeasureCore(System.Windows.Size)at System.Windows.UIElement.Measure(System.Windows.Size)at System.Windows.Controls.VirtualizingStackPanel.MeasureChild(System.Windows.Controls.Primitives.IItemContainerGenerator ByRef, System.Windows.Controls.Primitives.IContainItemStorage ByRef, System.Windows.Controls.Primitives.IContainItemStorage ByRef, System.Object ByRef, Boolean ByRef, Double ByRef, Double ByRef, Boolean ByRef, Boolean ByRef, System.Collections.IList ByRef, System.Object ByRef, System.Collections.IList ByRef, Int32 ByRef, Boolean ByRef, Boolean ByRef, System.Windows.Size
[2018-09-11 15:21:35] <james-shoemaker> what .net library does it expect?
[2018-09-11 15:25:10] <darrenstarr> james-shoemaker: This is an issue with WPF's grid element. I couldn't possibly imagine what it could be trying to load the type for. Is this happening when you attempt to open the panel allowing you to choose what to share or after you've clicked it and applied it?
[2018-09-11 15:26:40] <darrenstarr> james-shoemaker: I also can't find the source in the docker repository for the taskbar app
[2018-09-11 15:27:49] <darrenstarr> james-shoemaker: It also seems that the only way to enable shares is from the UI
[2018-09-11 15:28:17] <james-shoemaker> darrenstarr: when I try and open the panel.
[2018-09-11 15:29:03] <darrenstarr> denchp: I'll bite... I'm not sure I'm the pro on the topic, but can you clarify? Are you trying to run SQL server as a container or do you have an application that you'd like to run in a container?
[2018-09-11 15:29:35] <darrenstarr> james-shoemaker: Do you have any weird drives mounted on your machine? Something like a network share as a drive?
[2018-09-11 15:36:54] <james-shoemaker> darrenstarr: nothing odd drive wise that I know of.  I'm on a corporate network with the associated policies, but other users in my group have no issues with docker.  I just upgraded to windows 10 and installed the newer docker and now nothing works.  about to install docker toolbox so I can get back to work (assuming it works with windows 10).
[2018-09-11 15:39:23] <denchp> darrenstarr: I've got the app containerized, but the SQL Server instance is running on a separate server.  Right now it's a development database, but it's 'run' by our enterprise DBAs, and they aren't... uh... forward thinking... so it's unlikely to be containerized any time soon.
[2018-09-11 15:41:54] <darrenstarr> james-shoemaker: I wish you luck. Sadly I struggled with a similar issue when I started using Docker on Windows 10 and I'm sorry I can't recall how I managed to finally solve it. I have no idea why they felt the need to add that GUI anyway, I haven't used it for anything other than to share the drive and kill the app
[2018-09-11 15:45:35] <darrenstarr> denchp: Well, to be honest, SQL server is not the best thing to run virtualized... too many people do that and all it does is waste money in the end. MSSQL is a dying thing anyway as it's not really a scale-out platform for scaling. There are real limits to how many customers they could put on a single cluster in the cloud. Azure Tables is their hot thing now... so while MS probably makes billions on SQL server these days, I would be shocked if the top level management cares whether it lives or dies in the future as it's legacy technology compared to tables.
[2018-09-11 15:45:44] <darrenstarr> denchp: What's the problem you're having?
[2018-09-11 15:46:04] <darrenstarr> You should be able to simply provide a connection string to the application and let it run as it would have outside of a container
[2018-09-11 15:46:18] <darrenstarr> Is the issue with connection strings and authentication information?
[2018-09-11 15:47:38] <denchp> In windowsservercore i'm getting Microsoft][ODBC Driver Manager] Data source name not found and n default driver specified.
[2018-09-11 15:52:42] <darrenstarr> Hmmm... ok... so the issue is that you either need to install the MSSQL ODBC driver or find a container with it preinstalled. This is NOT the best article... but it's the best I've found so far and it explains how to do it with postgresql.... let's see if I can find mssql [<-LINK->] 
[2018-09-11 15:57:38] <darrenstarr> denchp: Ok... this is probably what you need.... I would recommend making two docker images. The first would be your platform and the second would be your application. So think of it as your own base image. Create a dockerfile that uses the base image of Windows Server Core or Windows Nano Server... then download the driver and install it by using ADD and RUN commands to do what's seen here [<-LINK->] 
[2018-09-11 15:58:04] <darrenstarr> denchp: Then make your application point to that image as its base. You should be ok then.
[2018-09-11 17:04:45] <denchp> darrenstarr: Thanks for the ideas, I'll give it a go and see how it... uhm... goes...
[2018-09-11 17:32:27] <james-shoemaker> darrenstarr: running some more windows updates resolved the issue
[2018-09-11 18:38:01] <AnderssonPeter> Hi I'm trying to start a container that uses port 8200, but i get a error that it is already bound, and when i usesudo netstat -lptu | grep 8200it seems623/docker-proxyis using it? but no of my other containers use 8200?
[2018-09-12 05:26:00] <darrenstarr> AnderssonPeter: yesterday, I solved a problem someone else had been struggling on for hours by rebooting a Windows 7 machine... it seemed silly, but it these were highly technical people sometimes ignore the obvious. Can I ask you what it says if you kill all copies of the container (remove the service) and then run the netstat command again. Does it show the same result? I've had this problem so many times and it ends up being something silly like I forgot I was already running another copy.
[2018-09-12 09:48:15] <tomkralidis> hi all: unrelated: is this a good place for docker hub questions?
[2018-09-12 09:52:59] <rcjsuen> Ask and see what happens
[2018-09-12 09:57:25] <tomkralidis> I am trying to create an automated build against a GitHub repo.  This has worked for me before.  In the last few months, when selecting 'Create / Create Automated Build', I get a screen with a (big) link 'Create Auto-build GitHub'.  I click it and nothing happens
[2018-09-12 09:58:22] <tomkralidis> looking at Web Console in FF 62: [<-CODE->] 
[2018-09-12 10:00:02] <rcjsuen> Maybe you can check at [<-LINK->] 
[2018-09-12 10:02:10] <tomkralidis> thanks@rcjsuenlooks like [<-ISSUE->] 
[2018-09-12 10:16:15] <AnderssonPeter> darrenstarr: I found the cause, I removed the container and restarted my pi, then tried to run the container, but it seems my pi does not save any changes to the SD card... So the old container was back. Going to do a full reinstall on a new SD card
[2018-09-12 16:01:01] <AnderssonPeter> When using docker compose how does one supply arguments? when using [<-LINK->] I\'m instructed to supply-u "example1;badpass"as a argument but i don\'t know where to write that in docker-compose
[2018-09-12 16:06:48] <AnderssonPeter> commandis the closes thing i have found but it seems to replace theENTRYPOINT?
[2018-09-12 16:58:23] <BetKingIO> Hi. Does anyone know if it's possible to copy a whole gcloud project? Not only the vms but the vpc and load balancer with ip and firewalls etc?
[2018-09-13 05:45:54] <Ritin> //-------------  THIS WORKS [<-CODE->] mon container is started and is ready for connectionsmon-exp service cannot connect.. connection refusedWhy does it work in the 1st compose file?on Ubuntu 18.04 and docker 18.06 and docker-compose version 1.21.2
[2018-09-13 05:59:28] <Ritin> MongoError: failed to connect to server [mongo:27017] on first connect
[2018-09-13 07:06:22] <Dinodanio> Hey all. Container using their name as hostname by default and the docker documentation says, we should use underscores in the name for readability. But underscores in hostnames are not allowed by RFC.
[2018-09-13 07:06:41] <Dinodanio> That seems weird
[2018-09-13 14:22:10] <tstackhouse_gitlab> Ritin: check your config for mon-exp. That error message says it's trying to connect to the host 'mongo', but you've renamed your mongo instance to 'mon', so the container name will be mon and that will be the hostname that you'll need to connect to from the mon-exp container
[2018-09-13 14:23:30] <tstackhouse_gitlab> So there are 2 solutions: Edit the config that themon-expservice uses to connect tomoninstead ofmongoor addcontainer_name: mongoto your compose file under themonservice.
[2018-09-13 14:26:02] <tstackhouse_gitlab> Is there a way to recover from the zombie reaping problem without rebooting?  I've got 900 zombies and 600 D state processes indocker-runc...
[2018-09-13 14:26:44] <tstackhouse_gitlab> and any attempt to interface with docker just hangs, including doing asudo service docker restart
[2018-09-13 17:40:48] <Ritin> thanks@tstackhouse_gitlabthat workedI tried the -these options that did not worklink: mon\nnetworks: mynetwork\ndepends_on: monI guess the mongo-express image will need to be rebuilt or configured so it can connect to the mon service name when starting those services
[2018-09-15 22:03:30] <mvilera> hey there
[2018-09-15 22:06:39] <mvilera> im trying to deploy an app over a docker swarm cluster, currently having an issue, my containers can't comunicate between them on overlay network, if they're deployed on the same host there is no problem, but on different host they just won't comunicate, i have opened all necessary ports on all the hosts, they are joining the overlay network and show as peers, they're showing on the gossip service
[2018-09-15 22:06:57] <mvilera> but if i try to curl a service or ping a service name it just times out.
[2018-09-16 07:13:58] <AnderssonPeter> What does a the health check do more than change the status? is there any way to make it restart when it happens?
[2018-09-17 12:55:13] <languitar> Hi, we have an additional docker daemon running on a host to use for build slaves of a jenkins server. Whenever jenkins spawns new containers, we observe short DNS problems in already running containers running on the same daemon. A pcap dump looks like the forwarding of the DNS UDP packages from the custom bridge interface to the public interface of the server doesn't work at that time. Does anyone have an idea what could be causing this?
[2018-09-18 14:58:34] <samspired> hey guys, i have rails using puma running on a docker container.
[2018-09-18 14:58:44] <samspired> port exposed -3088/tcp -> 0.0.0.0:8080
[2018-09-18 14:59:00] <samspired> but i cant access it from the browser.
[2018-09-18 14:59:18] <samspired> it works when i do a curl in docker container
[2018-09-18 14:59:27] <samspired> but outside just connection refused
[2018-09-18 15:00:07] <rcjsuen> You mean from your localhost youcan't connect to it on3088or8080?
[2018-09-18 15:00:17] <rcjsuen> When you say "outside" you mean localhost or some other machine in the wild?
[2018-09-18 15:00:46] <samspired> sorry should've been clear.
[2018-09-18 15:01:02] <samspired> from inside container i can do curllocalhost:3088
[2018-09-18 15:01:32] <samspired> but on host running  -curl <docker-ip>:8080doesnt work.
[2018-09-18 15:01:47] <samspired> i'm using  docker-machine
[2018-09-18 15:02:43] <samspired> docker port container-namegives me:3088/tcp -> 0.0.0.0:8080
[2018-09-18 15:02:52] <samspired> which seems correct right?
[2018-09-18 15:08:46] <samspired> uh got it working.
[2018-09-18 15:09:41] <samspired> this helped in case anyone is interested: [<-LINK->] 
[2018-09-18 15:10:03] <samspired> looks like:localhost:3088and0.0.0.0:3088are not the same thing.
[2018-09-18 15:10:06] <samspired> and the latter was needed.
[2018-09-18 15:11:32] <rcjsuen> samspired: Thank you for sharing your solution!
[2018-09-19 00:44:06] <Jukoo> hello everyone I test docker I can persist changes but my only problem: I want to communicate several containersby explem a PHP container that communicates with a SQL container  need tip advice or recommendation
[2018-09-19 13:45:56] <mario947> Jukoo: I guess using docker-compose to be simplest way to configure how containers communicate to each other for testing purposes.
[2018-09-19 16:30:06] <hanyoloren_twitter> mario947: and also to maintain
[2018-09-19 17:19:21] <Bsunny> why this command does not workdocker rm $(docker ps -a -q)
[2018-09-19 17:22:13] <Bsunny> sorry please ignore, earlier it didn't worked , now it worked suddenly
[2018-09-19 20:10:04] <popsUlfr> Hello everyone, is it not possible to have a squashfs volume ?docker volume create -d local -o type=squashfs -o device=$(pwd)/pia.squashfsand then mounting the volume inside a container fails withblock device required
[2018-09-20 10:14:43] <OOPMan> Hi, can I asked questions about Docker Swarm in here or is there another channel?
[2018-09-20 10:14:58] <OOPMan> By Docker Swarm, I mean the new integrated swarm-mode, not the old standalone system
[2018-09-20 18:07:42] <mochi-co> Hi guys, trying to use Docker with ECR but when I go to push I get "no basic auth credentials" error.. I\'m on OSX, none of the solutions I\'ve found work. Any ideas?
[2018-09-21 02:54:42] <thanhdongnguyen> Ritin: you should check network in docker compose
[2018-09-21 09:35:18] <zseikyocho> Build docker image and push to ecr, how to check it finished pushing by shell script?
[2018-09-21 14:05:45] <paupenin> Hi! I'm quite new to docker but I'm trying to login into a container and is asking me for user/pass wich I didn't configure. Could you give me any hint about this?
[2018-09-21 14:30:10] <moritzschaefer> Hi Pau. Which image do you use? How did you start the container?
[2018-09-21 14:37:54] <paupenin> Just followed this [<-LINK->] 
[2018-09-21 14:54:44] <moritzschaefer> Can you send a screen shot or so of your terminal inputs/outputs?
[2018-09-21 15:18:18] <paupenin> moritzschaefer: Since I'm on windows I downloaded Kitematic-Windows and seems I can login this way with powershell. I'm going to toy arround to get more comfortable before bothering anyone else. Thank you a lot ;)
[2018-09-21 20:17:50] <mochi-co> I don't suppose anyone has any tips on making watchtower work with docker.io private repos? I'm getting access denied errors
[2018-09-21 20:28:30] <mochi-co> nevermindI figured it out, thanks all!
[2018-09-23 04:10:52] <findpritish> how to containerise a windows .net/asp applications , any good urls to refer
[2018-09-23 18:56:29] <rsegecin> Can anybody please tell me what parameters I should pass to subjectAltName when creating a external cnf file for hardening the security with TLS in my docker deamon?
[2018-09-23 18:56:41] <rsegecin>  [<-LINK->] 
[2018-09-23 18:58:37] <rsegecin> I think I should add my own Domain Name and ipaddress of my host but it's not explicitly written
[2018-09-23 19:08:37] <rsegecin> except by the $Host
[2018-09-24 04:04:56] <ericsmalling> findpritish: I'm not a .net developer, but you might find this a good place to start: [<-LINK->] 
[2018-09-24 06:01:40] <rsegecin> NW
[2018-09-24 06:04:01] <rsegecin> Ops, nerver mind my question the hostname followed by IP address
[2018-09-25 03:25:19] <findpritish> ericsmalling: thankyou
[2018-09-25 03:32:02] <co2nut> good day guys
[2018-09-25 09:41:08] <managerger> just a regular day, dude
[2018-09-25 13:24:58] <aaron-gesmer> Hello, can anyone explain what could be going on here? I have a base image and I'm trying to start a container, but every time I run eitherdocker run { imageId }ordocker start { containerId }, the container immediately exits process
[2018-09-25 13:26:56] <bicabone> Sounds like a broken image / broken container. What do the logs say?
[2018-09-25 13:32:18] <aaron-gesmer> I didn't see anything :/
[2018-09-25 13:32:41] <aaron-gesmer> This is consistent and I'm pulling from an official image on docker hub so idk what else could be happening
[2018-09-25 14:54:34] <Martijngripp_gitlab> Hey people, I\'m new to docker, and I\'m at a loss :|I think that what I want to do should be simple, but it\'s confusing me to death.Case:I have an application, I want to run some unit tests against a database, but I want to make sure that the unit tests don\'t affect the "real" database. So my idea was: create a mysql dockerfile, initialize my schema in the db, and destroy&restart the container after every unit test to start with a fresh db.Of course, this means that the whole thing needs to be fast. [<-CODE->] 
[2018-09-25 14:57:41] <adaliszk> Hmm, what you could do is to save the actual database into the image so every time when you run it it's already has the data without initialization
[2018-09-25 14:58:16] <Martijngripp_gitlab> I thought I should be able to do this: [<-CODE->] But then when I restart it, the image will just run all the scripts in /docker-entrypoint-initdb.d again
[2018-09-25 14:58:28] <Martijngripp_gitlab> adaliszk: Yeah that's my goal, I don't know how :x
[2018-09-25 15:00:09] <adaliszk> I would run the containerinitialize the databasesave out the files in mysql case/var/lib/mysqlcreate a dockerfile with a COPY so I have the dband build that as an image
[2018-09-25 15:00:51] <adaliszk> It should working with commit though
[2018-09-25 15:00:58] <Martijngripp_gitlab> While I think that'd work, that doesn't sound very convenient
[2018-09-25 15:01:05] <Martijngripp_gitlab> Our db schema changes every now and then
[2018-09-25 15:01:13] <Martijngripp_gitlab> And I'd have to do that manually every time
[2018-09-25 15:01:31] <adaliszk> but when you commit then it doesn't commit into the main image, it creates a new image to my knowledge
[2018-09-25 15:01:37] <Martijngripp_gitlab> yeah that's fine
[2018-09-25 15:01:51] <Martijngripp_gitlab> But it just reinitializes the db
[2018-09-25 15:02:01] <Martijngripp_gitlab> It doesn't take into account that the db is already initialized
[2018-09-25 15:02:08] <Martijngripp_gitlab> Which is super weird
[2018-09-25 15:02:36] <Martijngripp_gitlab> I'll try this again
[2018-09-25 15:02:44] <Martijngripp_gitlab> And look into preventing the initialization script this time
[2018-09-25 15:02:51] <Martijngripp_gitlab> but I don't have high hopes
[2018-09-25 15:02:57] <adaliszk> weird :/ normally a db image uses a volume so it does not need the reinitialize itself
[2018-09-25 15:03:15] <Martijngripp_gitlab> It's like I tried 6 different things, and everything I try ends up not working because of something I don't understand
[2018-09-25 15:03:16] <Martijngripp_gitlab> :((
[2018-09-25 15:04:08] <adaliszk> I know that feeling :)
[2018-09-25 15:04:27] <Martijngripp_gitlab> Dev tears
[2018-09-25 15:06:30] <babaorum> I am not sure I followed all the conversation. But I think it is an interesting topic. If you want to initialize your db this way. You would need to make sure all "initial" set up si done in your image, and only starting the database remain in your container starting
[2018-09-25 15:07:28] <Martijngripp_gitlab> Another thing I tried was to simply initialize the database in the dockerfile itself, withmysql -u root -proot < /myinitfile.sql
[2018-09-25 15:07:34] <adaliszk> oh, soo the reinitialization could be because the image still have files in the/docker-entrypoint-initdb.d/
[2018-09-25 15:07:41] <Martijngripp_gitlab> But that just doesn't do anythingat all
[2018-09-25 15:08:04] <Martijngripp_gitlab> Like I attach a terminal to the container, and the database is not even there
[2018-09-25 15:08:09] <Martijngripp_gitlab> so weird
[2018-09-25 15:08:17] <adaliszk> its normally in a volume
[2018-09-25 15:08:39] <adaliszk> hmm, try to configure mysql to use a different db location
[2018-09-25 15:09:21] <Martijngripp_gitlab> @babaorumI tried this in my dockerfile [<-CODE->] 
[2018-09-25 15:09:24] <adaliszk> datadirinmysqld.cnf
[2018-09-25 15:10:41] <Martijngripp_gitlab>  [<-CODE->] That would make sense, I can add a script that empties that folder after initializing, and then use commit
[2018-09-25 15:12:30] <Martijngripp_gitlab>  [<-CODE->] I\'m also still a bit confused about volumes, I don\'t really have a solid understanding of them whatsoever, best I understand them is a vague feeling of "Somewhat like a mount except not a mount that floats around somewhere in the docker-aether"
[2018-09-25 15:18:49] <Martijngripp_gitlab> Lol, something's got to be off here
[2018-09-25 15:18:56] <Martijngripp_gitlab>  [<-CODE->] 
[2018-09-25 15:19:16] <Martijngripp_gitlab> I added a script that clears the init folder
[2018-09-25 15:28:30] <Martijngripp_gitlab> Ok ... wait, whatever it is that's going wrong now, I'm using weird workarounds to clear the folder after initialization which it apparently doesn't like because it's giving me permissions errors; it's a hack anyway.Can you do something like this with volumes?Bind a volume to the container\nLet the container init\nFreeze the volume somehow, copy it/store it/name it/whatever\nStart a container with a copy of that volume
[2018-09-25 15:29:50] <Martijngripp_gitlab> Because supposedly, the init scripts should run only once... [<-CODE->] 
[2018-09-25 15:30:05] <Martijngripp_gitlab> ;_;
[2018-09-25 15:36:46] <adaliszk> you can mount the volume for the first run to initialize
[2018-09-25 15:36:53] <adaliszk> then mount it as readonly
[2018-09-25 15:37:27] <adaliszk> the datadir move would make sure that the database is not stored in a volume
[2018-09-25 15:38:15] <Martijngripp_gitlab> Would that imply that I can't write to the db?
[2018-09-25 15:39:21] <adaliszk> with the readonly yeah :D
[2018-09-25 15:39:37] <adaliszk> but the location could be like /tmp
[2018-09-25 15:39:55] <adaliszk> normally the docker container processes run as root in their container
[2018-09-25 15:39:57] <Martijngripp_gitlab> Hmm.. I need to be able to modify the db tho ;p
[2018-09-25 15:42:39] <adaliszk> A question though, wouldn't be more effective to initialize a database and create a copy from that database for the tests?
[2018-09-25 15:43:34] <Martijngripp_gitlab> .. how? ;_;
[2018-09-25 15:43:55] <adaliszk> like amysqldump base_database | mysql test1command before you start your tests
[2018-09-25 15:44:03] <Martijngripp_gitlab> I don't care what steps I have to take, I just want it to work without it being super super complicated
[2018-09-25 15:44:18] <Martijngripp_gitlab> initializing the db takes 15 seconds on my host pc
[2018-09-25 15:44:31] <Martijngripp_gitlab> Considering I'd have to reset the db for every unit test suite
[2018-09-25 15:44:37] <Martijngripp_gitlab> That'd be a huge waste of time
[2018-09-25 15:44:40] <Martijngripp_gitlab> That's why I want to use docker
[2018-09-25 15:45:03] <Martijngripp_gitlab> Have some kind of restartable image/container that will just give me a fresh database every time I run some random command
[2018-09-25 15:45:42] <adaliszk> It still needs to start so a 3-5s will be there anyway
[2018-09-25 15:45:58] <Martijngripp_gitlab> Well, not necessarily, there's  this thing for example: [<-LINK->] 
[2018-09-25 15:46:05] <Martijngripp_gitlab> It starts very quickly
[2018-09-25 15:50:59] <babaorum> I didn't know this docker image, did you tried it ?
[2018-09-25 15:51:11] <babaorum> seems to be what you want to do ...
[2018-09-25 15:54:03] <Martijngripp_gitlab> Yeah I'm trying it out right now
[2018-09-25 15:55:17] <babaorum> I personaly would not use it on the long term because it seems a bit too custom for me.But for a first approach of the functionality; it seems to be a good start :)
[2018-09-25 15:55:38] <Martijngripp_gitlab> Yeah it's a bit obscure if you ask me
[2018-09-25 15:55:45] <Martijngripp_gitlab> but atm, seems the right choice if I can get it working
[2018-09-25 15:55:56] <Martijngripp_gitlab> Alright, so itisat least running
[2018-09-25 15:56:05] <Martijngripp_gitlab> and my database is even initialised correctly
[2018-09-25 15:56:11] <Martijngripp_gitlab> but it still takes like 4 seconds to start up
[2018-09-25 15:56:18] <Martijngripp_gitlab> Which is somewhat ok for now, our testsuite is not super large
[2018-09-25 15:56:26] <Martijngripp_gitlab> But that'll get annoying really, really quickly
[2018-09-25 15:56:33] <Martijngripp_gitlab> Should really be sub-second
[2018-09-25 15:57:34] <Martijngripp_gitlab> And the repo promises to be sub-second as well
[2018-09-25 15:57:35] <Martijngripp_gitlab> So eh
[2018-09-25 15:57:36] <Martijngripp_gitlab> hm
[2018-09-25 16:00:52] <adaliszk> depends on machine, I have an NVME SSD and that makes way bigger images start bellow a second ;)
[2018-09-25 16:01:30] <Martijngripp_gitlab> Haha, my desktop has a samsung 950 pro NVME SSD as well
[2018-09-25 16:01:36] <Martijngripp_gitlab> Buuuttt.. that's my personal desktop
[2018-09-25 16:01:36] <babaorum> Wait to use it on a CI system or something
[2018-09-25 16:01:46] <Martijngripp_gitlab> This pc has a regular ssd
[2018-09-25 16:02:11] <Martijngripp_gitlab> But this pc shouldn't be anywhere near slow, it's fairly beefy
[2018-09-25 16:03:11] <babaorum> If you want to have a new database for each functional tests. it is quite normal to have these kind of issues
[2018-09-25 16:03:41] <adaliszk> yeah, but on a CI server you can just put them parallel to each other
[2018-09-25 16:03:54] <adaliszk> so the test is just as long as your biggest test
[2018-09-25 16:04:37] <Martijngripp_gitlab> babaorum: I think I can live with 3-4 seconds startup time for now though
[2018-09-25 16:05:03] <Martijngripp_gitlab> Our test-suite is so small atm that I can get away with only starting it up once, at the very beginning
[2018-09-25 16:05:23] <Martijngripp_gitlab> And once we get to the point where it gets a bit bigger, I can spend some more time trying to optimize this image
[2018-09-25 16:05:32] <Martijngripp_gitlab> 3-4 seconds is already so, so much better than 15
[2018-09-25 16:06:05] <Martijngripp_gitlab> A major point of unit tests is that they give immediate feedback, and 3-4 seconds is "immediate" enough for me
[2018-09-25 16:06:18] <Martijngripp_gitlab> 15 is definitely not, you might as well not have unit tests at that point
[2018-09-25 16:07:12] <Martijngripp_gitlab> And I'm pretty sure there has to be something simple right now I can do to speed it up a bit more
[2018-09-25 16:08:14] <adaliszk> unit tests should not spin up database though, the current project where I work on we have over 800 tests and only a few actually need a database to validate that the framework was able to connect and the migrated database is ok
[2018-09-25 16:09:15] <Martijngripp_gitlab> Well.. our codebase is such a big mess, it makes more sense to spin up a database than to even pretend it's worth our time to hold our testing code to high standards
[2018-09-25 16:09:43] <Martijngripp_gitlab> Our code is not exactly "mock-friendly"
[2018-09-25 16:10:28] <Martijngripp_gitlab> And I cannot change like 90% of the architecture, because it is generated by some kind of a custom scaffolding tool made by the CTO
[2018-09-25 16:10:36] <Martijngripp_gitlab> I just want to be able to run tests ASAP
[2018-09-25 16:10:45] <Martijngripp_gitlab> So I can refactor some stuff where it is more than extremely necessary
[2018-09-25 16:11:04] <Martijngripp_gitlab> Clients are complaining that features that we've been working on formonthskeep breaking due to regressions all over the place
[2018-09-25 16:11:10] <Martijngripp_gitlab> And I can try my best to refactor the code
[2018-09-25 16:11:29] <Martijngripp_gitlab> But it's basically guaranteed that I breaksomething..somewherewhenever I do something
[2018-09-25 16:11:42] <Martijngripp_gitlab> Which I'll hear about a week later, because a client is complaining
[2018-09-25 16:12:13] <Martijngripp_gitlab> And the cto & boss don't really give a fuck about code stability, CTO doesn't believe in tests
[2018-09-25 16:12:28] <Martijngripp_gitlab> But I just need something to cover my own ass, because if I break stuff it's my fault again, lol
[2018-09-25 16:12:30] <Martijngripp_gitlab> So yeah
[2018-09-25 16:12:34] <Martijngripp_gitlab> That's my life story
[2018-09-25 16:13:16] <Martijngripp_gitlab> Yeah...It's my life...In my own words, I guess...
[2018-09-25 16:14:32] <Martijngripp_gitlab> Have you ever loved a codebase so much you'd give an arm for?Not the expressionNo, literally give an arm forWhen they know they're your income and you know you were their developerAnd you will destroy anyone who would try to harm herBut what happens when regression-errorsTurn right around and bite youAnd everything you committed turns on you despite youWhat happens when you become the main source of bugs
[2018-09-25 16:16:49] <adaliszk> one sec, I need to read it XD
[2018-09-25 16:17:30] <adaliszk> Wow you got an interesting CTO there :D
[2018-09-25 16:17:43] <Martijngripp_gitlab> He's a bit stuck in his ways
[2018-09-25 16:17:59] <Martijngripp_gitlab> The scaffolding thing makes sense for their business, or at least, it used to
[2018-09-25 16:18:20] <Martijngripp_gitlab> They used to make custom applications for a whole bunch of different clietns
[2018-09-25 16:18:32] <Martijngripp_gitlab> So they could use it to prototype applciations super quickly using it
[2018-09-25 16:18:32] <adaliszk> happens, but I can understand when the customers are complaining the focus is not on the tests
[2018-09-25 16:19:01] <Martijngripp_gitlab> I think they're just too used to their way of working and that their application is like in a state of being 60-70% stable
[2018-09-25 16:19:07] <Martijngripp_gitlab> Most of it works most of the times for most customers
[2018-09-25 16:19:20] <Martijngripp_gitlab> And they let us fix bugs whenever something goes wrong I guess
[2018-09-25 16:19:41] <Martijngripp_gitlab> But.. if the three of us add a unit test or three each week, wherever it is important
[2018-09-25 16:19:56] <adaliszk> yeah, but in the mean time we should not span this channel though ;)
[2018-09-25 16:20:02] <Martijngripp_gitlab> oh yeah
[2018-09-25 16:20:02] <Martijngripp_gitlab> lol
[2018-09-25 16:20:20] <adaliszk> :D
[2018-09-26 00:15:32] <davidmichaelkarr> I\'m trying to help another team with a container problem. Their Dockerfile is exposing port 8080. When they do a docker inspect, the "NetworkSettings.Ports" is null.  What sort of thing should we look at for troubleshooting?
[2018-09-26 10:05:22] <darrenstarr> David... dumb question here... you're both exposing the port from the container and also from the system right? So when launching the container, you're specifying the port should be exposed and that's the same port you expose when building the container right?
[2018-09-26 12:34:39] <user2301> Hi , How to correctly add new path in windows docker container? I tried various combinations but not working. How to verify if the path is added to the enviornment variable inside docker container?
[2018-09-26 12:38:30] <user2301>  [<-CODE->] 
[2018-09-26 16:04:12] <denchp> So I asked this a few weeks ago, but am just now able to come back to the skunkworks project we're trying to do (which is general containerization).Here's the short version: expressjs app that uses mssql/msnodesqlv8 to connect to an external MSSQL instance.The app work running locally - but won't work in the container, and I'm getting the following message:(node:1356) UnhandledPromiseRejectionWarning: ConnectionError: [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified    at msnodesql.open (C:\\usr\\node_modules\\mssql\\lib\\msnodesqlv8.js:178:17)    at Immediate._onImmediate (C:\\usr\\node_modules\\msnodesqlv8\\lib\\connection.js:358:15)    at runCallback (timers.js:810:20)    at tryOnImmediate (timers.js:768:5)    at processImmediate [as _immediateCallback] (timers.js:745:5)I can't figure this out for the life of me...
[2018-09-26 16:30:13] <adaliszk> what host do you use in order to connect?
[2018-09-26 16:54:06] <denchp> the image is built off of windowsservercore:1708
[2018-09-26 17:10:29] <denchp> OK!!! I got it to work - kind of!
[2018-09-26 17:12:14] <denchp> I\'m now getting ":ogin failed for user \'NT AUTHORITY\\ANONYMOUS LOGON\'."  Which is an improvement.
[2018-09-26 17:35:14] <denchp> So my new challenge is to get a container to run as a specific user...  Any ideas on how to achieve that?
[2018-09-26 17:56:50] <denchp> Or more accurately, I need the process inside of the container to run as a specific user...
[2018-09-26 18:02:04] <rcjsuen> denchp: TheUSERDockerfile instruction does not help?
[2018-09-26 18:03:37] <denchp> That's actually what I'm investigating right now
[2018-09-26 18:03:52] <denchp> Trying to figure out if/how to connect up to the AD...
[2018-09-26 18:34:37] <denchp> So it looks like I might be able to get this working by using USER 'LocalService' in the DockerFile and --user 'domain/username' in the run command...  can anyone confirm?
[2018-09-27 07:56:17] <adaliszk> if I know right--userflag will copy your local user details into the container. I'm not sure if it handles the kerberos tokens though :D
[2018-09-27 10:22:58] <limpep> Hi all, I have version:  18.06.1-ce installed on a arm box, I am having an issue pushing the image to a private register for someone reason it hangs pushing to the registry, I have logged in and restarted the docker service but with no luck
[2018-09-27 10:23:04] <limpep> not sure what i am doing wrong
[2018-09-27 11:30:20] <darrenstarr> limpep: not sure if I can help... but I've done this a lot. Just so you know... the whole pushing to a private registry tends to go completely crappy when your certificates aren't valid
[2018-09-27 11:35:40] <adaliszk> ^ in that regard it usually clearly throws an error that it is a certificate error, hanging is a weird issue, I only experienced it when my registry had a proxy
[2018-09-27 11:38:47] <adaliszk> try use the registry:2 instead latest
[2018-09-27 11:39:02] <adaliszk> I've had some error with the latest recently
[2018-09-27 11:40:24] <darrenstarr> I haven't tried that... but I found that simply getting a properly signed certificate in place fixes pretty much everything
[2018-09-27 16:02:33] <denchp> From what I'm reading the only solution to getting a container to connect to an MSSQL instance using integrated security (Windows Authentication) is through setting up a gMSA.  Is this really the only way?
[2018-09-27 19:45:39] <elcolie> Hi
[2018-09-27 19:45:58] <elcolie> After I use remote python interpreter inPyCharm
[2018-09-27 19:46:31] <elcolie> My test break and I have to do manually run the test without docker
[2018-09-27 19:46:50] <elcolie> ThenPyCharm_helpercontainer is exited.
[2018-09-27 19:47:09] <elcolie>  [<-CODE->] What should I do with them?kill/jump to the container?
[2018-09-28 03:09:13] <elcolie> docker system prunesolve for me
[2018-09-28 11:56:58] <katsar0v> Any docker dev (for linux), please take a look, as I think this is important - [<-ISSUE->] 
[2018-09-28 11:58:03] <katsar0v> ping to the contributors@thaJeztah@tiborvass
[2018-09-28 12:58:52] <adaliszk> can you attach your Dockerfile too? :)
[2018-09-28 12:59:26] <adaliszk> Step 91/95 smells a bit :D
[2018-09-28 13:04:18] <katsar0v> Step 91/95 : WORKDIR /var/www/html/it is just a workdir
[2018-09-28 13:07:51] <rcjsuen> katsar0v: But there are 90 other steps before it
[2018-09-28 13:08:27] <rcjsuen> I think that's what Adam is getting at
[2018-09-28 13:58:44] <adaliszk> Yes. Even with multistage build the max number was what I as able to hit is 40, aand that's a really huge project.
[2018-09-28 14:05:16] <adaliszk> Not saying that your 95 steps it not needed, but hard to pinpoint out why is a chmod slow without knowing what do you do before that.For example you could chmod the sources and change the user before a composer install and that's helps a lot.
[2018-09-28 14:19:56] <rcjsuen> It sounds like it should be possible to reproduce bytouching a bajillion files, ortouch100 files and thencp -ra thousand times.
[2018-09-28 14:20:04] <rcjsuen> Are a bajilliion files in one folder the problem or many folders with many files?
[2018-09-28 14:22:24] <adaliszk> Usually the many folder many files takes a lot of time, if you have a folder with bajillion files that's not a huge problem
[2018-09-28 14:22:27] <katsar0v> Use this file fore testing, it is also slow: [<-CODE->] 
[2018-09-28 14:22:42] <katsar0v> I cannot post my fullDockerfile, but the above is a good example
[2018-09-28 14:23:29] <katsar0v> You can count the files, etc.. this is just not normal, whatever happens withchown, on the host machine it lasts less than0,001s
[2018-09-28 14:24:22] <adaliszk> Have you considered using [<-LINK->] and composer for your plugins and the wordpress to install? That way you don't need to copy and chown everything, only your theme and maybe your static files (if stored on the same container)
[2018-09-28 14:25:13] <katsar0v> What about local ones which are private and with changes?
[2018-09-28 14:25:27] <katsar0v> However, that's just an example with Wordpress plugins, use any other files
[2018-09-28 14:25:47] <adaliszk> composer gives you configurable repositories, that's how I work with my WP containers :)
[2018-09-28 14:26:19] <katsar0v> Cool, will take a look at it :)
[2018-09-28 14:28:25] <adaliszk> A sample composer.json: [<-CODE->] With that you only need to copy your config and custom theme into the container which should not take too much time to chmod :)
[2018-09-28 14:29:13] <katsar0v> That's a cool workaround! But what if I do not want to use wpackagist, I have my private gitlab and github repos for example where my plugins are sorted
[2018-09-28 14:32:30] <adaliszk>  [<-CODE->] 
[2018-09-28 14:32:59] <adaliszk> in your repos you just choose the type to bewordpress-themeorwordpress-plugin
[2018-09-28 14:33:09] <adaliszk> aand your 95 steps could be reduced to about 20 :)
[2018-09-28 14:34:13] <adaliszk> but we should discuss the composer details in a separate channel or in private so we won't spam the docker channel with it ;)
[2018-09-28 14:34:44] <katsar0v> Yeah, that's nice! But in similar cases you always need additional setups for authentication
[2018-09-28 14:34:50] <katsar0v> to the private repos.. etc
[2018-09-28 14:35:43] <katsar0v> Of course I could also just put a/start.shscript that does everything at the end and my Dockerfile is just 2 lines. Dockerfile should not be really limited to 100 or 1000 lines
[2018-09-28 14:37:55] <katsar0v> But thanks for the tips! Will for sure take this in mind.If any technical limitations from the Dockerfile exist, they need to be documented (e.g. cannot be more than around 120 lines)Also similar documentation like - https://success.docker.com/article/mta-best-practices - would be nice for creating nice Dockerfiles
[2018-09-28 14:40:54] <adaliszk> Yeah true that there is no limitation, but a container should encapsulate "one process" , I often seens this huge files to encapsulate a project and not one service. After the official repos has any database you want, any cache mechanism, any webserver and in this case you only need to setup a php-fpm and put your files into it.
[2018-09-28 14:41:03] <adaliszk> *seen
[2018-09-28 14:41:21] <adaliszk> -After
[2018-09-28 14:41:26] <adaliszk> I cannot write on Friday XD
[2018-09-28 14:45:03] <adaliszk> I've played around with [<-LINK->] before which might help with that many files, If I know right it's basically masking your files to look like what you permission needed to be
[2018-09-28 14:45:24] <adaliszk> that way you don't even need to modify permissions
[2018-09-28 14:45:52] <katsar0v> Thanks for the link!
[2018-09-28 14:46:01] <adaliszk> but that doesn't help if you are not on linux
[2018-09-28 14:46:03] <adaliszk> :D
[2018-09-28 14:46:37] <katsar0v> But don't you think, chown inside docker and chown on host machine, they are just not comparable
[2018-09-28 14:46:55] <rcjsuen> I agree it should not be that different
[2018-09-28 14:47:38] <adaliszk> depends on your volume configuration I guess, if it tries to rsync in the background that's not a small overhead
[2018-09-28 14:47:52] <katsar0v> I mean everything you said is true@adaliszk, but such a simple operation (well maybe not that simple at all) should not take that long onNVMe SSDwith RAID 0 :)
[2018-09-28 14:48:01] <katsar0v> Mine is default, clear docker config, no idea honestly
[2018-09-28 14:49:15] <adaliszk> Hmm, an interesting test could be to work with alpine instead of ubuntu as a base image. I've noticed significant differences between them before
[2018-09-28 14:49:40] <rcjsuen> I just ran your file inplay-with-docker.com
[2018-09-28 14:49:41] <rcjsuen> Already finished
[2018-09-28 14:49:53] <rcjsuen> chown test:test . -Rprobably took less than five seconds
[2018-09-28 14:49:56] <rcjsuen> rcjsuen: shrugs.
[2018-09-28 14:50:09] <rcjsuen> But I don't know what cloud infra PWD is run on so...
[2018-09-28 14:52:14] <katsar0v> That would be a cool try I guess, I will try switching the image, so instead of ubuntu I try alpine or something else. Which images can I use as base?
[2018-09-28 14:54:07] <rcjsuen> alpine:3.8perhaps
[2018-09-28 14:59:56] <katsar0v> ahh it is all different with adding the user and so on.. maybe the repos are also different for all the apps..
[2018-09-28 15:00:24] <rcjsuen> Alpine doesn't useapt, so yes you will need to massage your Dockerfile accordingly
[2018-09-28 15:03:14] <katsar0v> Around 5-7 seconds onAlpine
[2018-09-28 15:05:02] <katsar0v> Alpine: [<-CODE->] Debian: [<-CODE->] 
[2018-09-28 15:07:23] <katsar0v> Ubuntu 18.04: [<-CODE->] 
[2018-09-28 15:08:10] <adaliszk> somewhat better :D
[2018-09-28 15:10:21] <katsar0v> :D
[2018-09-28 15:12:54] <katsar0v> Your tips helped me though, thank you for which :)
[2018-09-28 15:16:39] <denchp> I'm getting an error when trying to use a docker-compose file...:ERROR: for mongo  Cannot create container for service mongo: invalid volume specification: 'C:_projects\\discovery-service\\mongodb\\data:/data/db:rw'
[2018-09-28 15:16:52] <denchp> Anyone have any ideas (the windows path is valid)
[2018-09-28 15:17:20] <denchp> (using the official mongodb dockerfile)
[2018-09-28 15:18:41] <katsar0v> denchp: can you separate the windows path from /data and :rw
[2018-09-28 15:19:23] <katsar0v> I do it like this ['c:/..path..','/mount-path/','rw'] (in python)
[2018-09-28 15:19:32] <denchp> Hmm...
[2018-09-28 15:19:34] <denchp> I'll try
[2018-09-28 15:20:38] <denchp> volumes: [<-CODE->] 
[2018-09-28 15:20:41] <denchp> fails
[2018-09-28 15:20:52] <katsar0v> without [ and ] ?
[2018-09-28 15:20:53] <denchp> services.mongo.volumes contains an invalid type, it should be a string, or an object
[2018-09-28 15:21:01] <katsar0v> 'path', 'mount', 'rw' ?
[2018-09-28 15:21:22] <denchp> yaml parser error then.
[2018-09-28 15:21:36] <denchp> expected <block end>, but found ','
[2018-09-28 15:21:49] <adaliszk> ./only works for me if I write the whole config as a string. At some point docker-compose (and docker) started to require absolute path
[2018-09-28 15:22:32] <katsar0v> 'path':'mount path':'rw'? hm, strange
[2018-09-28 15:24:04] <denchp> It seems to be resolving the ./mongodb/data properly to c:_projects\\etc...
[2018-09-28 16:06:20] <fridgerator> I ran docker-compose with some missing dot files as volumes (.eslintrc), I've added those missing files in but now my container thinks those volumes are folders.  How can I fix this?
[2018-09-28 17:29:44] <fridgerator> nvmd, I pruned everything and still get the error, I have to be doing something wrong
[2018-10-01 19:34:31] <jmunson> I have two stacks deployed to a docker swarm, but I can't seem to get DNS to resolve a container on the other stack. The documentation mentions that containername.stackname should work, but its documentation for docker-cloud so it might just not apply to swarm mode? I can't seem to find any swarm-mode specific documentation on how to do this. Does anyone know how?
[2018-10-02 01:58:37] <venesh0709> 76ea097a4f8b        manageiq/manageiq:gaprindashvili-5   "/usr/local/bin/dumb…"   2 weeks ago         Up 6 seconds               22/tcp, 80/tcp, 0.0.0.0:8443->443/tcp   priceless_euler76ea097a4f8b        manageiq/manageiq:gaprindashvili-5   "/usr/local/bin/dumb…"   2 weeks ago         Exited (1) 4 seconds ago                       priceless_euler
[2018-10-02 01:59:31] <venesh0709> docker container was restarted and immediately going to exit state in just few seconds
[2018-10-02 02:00:12] <venesh0709> what is going wrong?
[2018-10-02 13:31:47] <pgreisen> I have built a docker image which generates some data which I would like to transfer to host. I generate some data inside the container and I would like to copy them to ./data after the run. Could someone give a hint or link to how to do this. Thanks
[2018-10-02 13:41:18] <adaliszk> you have two generic direction@pgreisen, one is to usedocker cpwhich enables you copy files from the container to the host, the second is to use avolumeand essentially work on your host with your container.
[2018-10-02 14:38:55] <pgreisen> thanks - so what is the most sustainable solution here. At some point I would like to wrap singularity around the container but I am bit uncertain what is the design for this
[2018-10-02 14:46:05] <adaliszk> volume is the most commonly used solution, you can point that into your given workdir and then you can process stuff in your container and get the results in your host machine. The cp is mostly used if you need some state like default configs to later copy back with your configuration (in Dockerfile).
[2018-10-02 18:54:40] <dragonpiper> for some reason my network performance in a docker container is extremly slow 20 KB / s . Cpu and memory usage for the container is pretty low. Anyone know if this is normal ?
[2018-10-03 08:24:36] <lanycrost> dragonpiper: can you sharedocker inspectoutput, I think it is because of cgroups.
[2018-10-03 10:43:25] <sumanchowdare> How can we access docker cli from inside container ??
[2018-10-03 10:47:35] <CharcoGreen> maybe you want say for example?" : docker exec -ti "nameofcontainer" bash
[2018-10-03 11:02:34] <lanycrost> sumanchowdare: You can mount root directory, or just mount docker.sock for control docker inside container, but I think you can find more graceful solution :)
[2018-10-03 16:37:57] <MRDO5> Hi all! I am a partly new in docker but i have question. After when i up 3 container from ansible in other nod i have problem
[2018-10-03 16:40:27] <MRDO5> name: Display IP address and port mapping for docker containerdebug: msg=app:{{item['HostConfig']['PortBindings']['80/tcp'][0]['HostPort']}}with_items: docker_containers
[2018-10-03 16:41:54] <MRDO5> My playlist error in msg .
[2018-10-04 03:26:07] <AlexITC> Hi, I remember that once I was interacting with my local docker using cURL but I can't find how, does anyone remember the details?
[2018-10-04 03:59:50] <AlexITC> finally  found it
[2018-10-04 15:06:48] <IncMillora_twitter> Hi, when I tried to see logs with "docker logs container-name" it gives that error for stoped containers. " Text file busy"  I am trying to find why container is exit
[2018-10-04 15:07:30] <mdedetrich> I am currently having issues in setting up a redis sentinel using docker-compose here [<-LINK->] 
[2018-10-04 15:07:56] <mdedetrich> The issue is that I can't actually seem to connect to the sentinel
[2018-10-04 15:08:02] <mdedetrich> I am running Docker on MacOSX
[2018-10-04 15:10:48] <mdedetrich> (actually in general I am trying to get some redis-sentinel setup working with docker/docker-compose. Have tried many of them and can't seem to get them working)
[2018-10-05 18:39:46] <Royi_Namir_twitter> Hi. I have a question please. ( Im new to docker)Looking at this docker file : [<-CODE->]  [<-CODE->] 
[2018-10-05 20:19:32] <dragonpiper> Hello, I have a question about multistage builds
[2018-10-05 20:21:25] <dragonpiper> does it mean instead of having a 1Gb that includes the tooling needed for compiling my code i can just have a stage that creates build artifacts and just have those build artifacts copied over to final image from base from alphine  that doen't have the language compilation dependencies  ?
[2018-10-05 20:42:38] <stephansnyt> is there a way to do uid mapping between a host and container so that the id of the user running the container  is equal to the last USER defined in the corresponding Dockerfile?
[2018-10-05 22:07:16] <tbugfinder> dragonpiper: "from python" is a Linux container.
[2018-10-05 22:07:45] <tbugfinder> Royi_Namir_twitter: 
[2018-10-05 22:08:00] <tbugfinder> "from python" is a Linux container.
[2018-10-05 23:11:17] <spdevhub07> dragonpiper: I believe your assumption is right per my reading
[2018-10-05 23:12:07] <spdevhub07> If you do two from blocks you can copy from first stage artifacts to second stage without carrying all of it
[2018-10-06 13:48:17] <MRDO5> I folk! I am new in docker. ) Have anyone know good course in inet or book for learning. Or baets way book with exercise?
[2018-10-06 14:14:02] <mateothegreat> MRDO5: do you have a web app that you’ve developed? start by docker-izing that ;)
[2018-10-06 14:14:09] <mateothegreat> the rest will fall in place
[2018-10-06 14:29:02] <schrepfler> is minikube needed if I have docker for mac with kubernetes enabled?
[2018-10-06 21:33:57] <pbaderia01> Hey..any idea how I can execute mongodb tasks as a cron job in a docker image?
[2018-10-06 21:34:14] <pbaderia01> I have pulled the latest ubuntu image
[2018-10-06 21:34:33] <bizmate> you dont, you run a cron that runs a container
[2018-10-06 21:35:16] <pbaderia01> But that would mean I have to reset the mongo connection every single time
[2018-10-06 21:35:44] <pbaderia01> I won't be able to execute the same queries on the same command
[2018-10-06 21:35:52] <pbaderia01> *connection
[2018-10-06 21:36:58] <bizmate> I dont see the benefit of keeping a connection open if it is not running a query
[2018-10-06 21:37:10] <bizmate> could you clarify what you are trying to achieve?
[2018-10-06 21:37:54] <pbaderia01> I am trying to run a cleanup query for my db but since I don't wanna block the production db for a very long time in a single go
[2018-10-06 21:38:25] <pbaderia01> I am trying to retrieve a limited number of documents every 10 seconds and deleting them
[2018-10-06 21:38:52] <pbaderia01> In batches
[2018-10-06 21:39:11] <pbaderia01> For this I am trying to build a docker image that I can expose to kube to execute
[2018-10-06 21:39:46] <pbaderia01> But I can't get my head around as to how I can execute queries on the mongo terminal using a cron job in a container
[2018-10-06 21:40:14] <bizmate> then you dont need a cron job, just run an app that does the queries with a 10 second sleep for ever
[2018-10-06 21:40:38] <bizmate> thought the approach feels like you should fix what causes the garbage data in the first place with something built in in mongo
[2018-10-06 21:40:51] <bizmate> rather than running queries later
[2018-10-06 21:40:59] <pbaderia01> Also trying to do that with a TTL index
[2018-10-06 21:41:09] <pbaderia01> But since the data is too much right now
[2018-10-06 21:41:28] <pbaderia01> Can't really because it will throttle the DB and would cause havoc
[2018-10-06 21:42:11] <pbaderia01> Thanks for the help@bizmate. Really appreciate it
[2018-10-06 21:42:27] <bizmate> no problem, does the sleep approach make sense? you dont need a cron
[2018-10-06 21:42:37] <bizmate> in my opinion
[2018-10-06 21:42:54] <pbaderia01> Yup..it does as a matter of fact
[2018-10-06 21:43:07] <bizmate> cool
[2018-10-08 05:41:37] <mateothegreat> I’d recommend using a cron based job so you don’t have to worry about maintaining a stateful connection for a long running job
[2018-10-08 05:41:53] <mateothegreat> piyush-insider: 
[2018-10-08 05:42:18] <mateothegreat> though cron is almost an anti-pattern of ephemerability
[2018-10-08 10:35:31] <devMonkey87> hi everyone! got a little issue , hope maybe someone could help
[2018-10-08 10:38:51] <devMonkey87> the situation is: working with a physical device running an ubuntu server via VirtualBox. The ubuntu server is executing a jenkins container. Before the issue  I was running virtualBox on Bridge mode with no problems of finding every machine but when I switched to my work office environment and changed the connection to NAT, can't reach  any IP apart from the virtualised Ubuntu Server machine...
[2018-10-08 10:40:35] <devMonkey87> I did some  port mapping within configuration mode in Virtualbox with no successful results
[2018-10-08 10:41:09] <schrepfler> sorry for re-posting my question, is minikube needed if one has the docker for mac with kubernetes enabled?
[2018-10-08 13:49:13] <dragonpiper> Anyone know the reason for extremely slow network connection on mac ? i get 25KB/s on a 1Gbps network when downloading from the internet.  Jenkin's repository for example
[2018-10-08 14:55:37] <schrepfler> Ah, it seems so, I was following a guide and it was using this ingress plugin
[2018-10-08 23:07:09] <mateothegreat> You can technically deploy an ingress-controller without any “plugin”.. as with [<-LINK->] 
[2018-10-08 23:21:15] <schrepfler> @mateothegreatI’m getting educated on this ingress situation
[2018-10-08 23:21:58] <mateothegreat> all good
[2018-10-08 23:22:02] <mateothegreat> what troubles you my friend
[2018-10-08 23:23:07] <dragonpiper> Hey guys, i'm running jenkins in a container i have it up and running and conneted to a repo but when i try to do a build it says the label docker doesn't exist
[2018-10-08 23:23:33] <dragonpiper> Am i not able to run a docker job on jenkins master ?
[2018-10-08 23:23:47] <mateothegreat> “what” says the “label docker” doesn’t exist?
[2018-10-08 23:24:22] <dragonpiper> Jenkins in the console  output
[2018-10-08 23:25:55] <dragonpiper>  [<-CODE->] 
[2018-10-08 23:25:57] <dragonpiper> to be exact
[2018-10-08 23:26:23] <mateothegreat> Are you trying to run adocker ..command from within your Jenkins Job/Jenkinsfile?
[2018-10-08 23:26:56] <dragonpiper> My jenkins file is [<-CODE->] 
[2018-10-08 23:26:59] <mateothegreat> Better yet, you’re using aJensinsfileright
[2018-10-08 23:27:06] <mateothegreat> comment out line [<-ISSUE->] 
[2018-10-08 23:27:22] <dragonpiper> i added it thinking that would  help. I get the same error
[2018-10-08 23:27:49] <mateothegreat> my bad
[2018-10-08 23:27:53] <mateothegreat> line 1 is the culprit
[2018-10-08 23:28:30] <dragonpiper> I know thatnodespecifies the build agent as node,  but doesn't the docker label tell it to run the pipeline in docker ?
[2018-10-08 23:30:40] <mateothegreat>  [<-CODE->] 
[2018-10-08 23:32:07] <dragonpiper> Yea , i've seen that syntax as well, buts it's confusing. What does it change in the execution ?
[2018-10-08 23:32:39] <dragonpiper> Is what i have before older syntax ?
[2018-10-08 23:52:03] <mateothegreat> It’s a Declarative Pipeline
[2018-10-09 00:04:18] <dragonpiper> Right, but does jenkins execute differently from what i previously had minus thedockerlabel ?
[2018-10-09 00:06:29] <dragonpiper> Jenkins says [<-CODE->] 
[2018-10-09 00:15:29] <dragonpiper> And if i specify an agent i get the docker label error again
[2018-10-09 00:15:43] <dragonpiper> The docks says label is required for node build agent
[2018-10-09 00:15:48] <dragonpiper> but i don't understand how you define it
[2018-10-09 07:18:20] <darrenstarr> I've just visited [<-LINK->] which says that the docker powershell client is deprecated. It recommends that I use the docker cli or Docker.DotNet directly. I'd prefer to use Docker.DotNet as it would vastly simplify parsing command output. Does anyone have an example of doing this?
[2018-10-09 13:57:18] <farhanahmedsyed> Can we run windows container in Mac?
[2018-10-09 17:37:44] <parisnakitakejser> i’m trying to learn Docker and the concept, what i want is build a linux-ubuntu inside a docker so i can make configs public, is it posibule or are im thinking on Docker wrong?
[2018-10-09 19:57:44] <rcjsuen> farhanahmedsyed: I believe you cannot run Windows containers on Linux or Mac.
[2018-10-09 19:58:29] <rcjsuen> parisnakitakejser: I think you need to further elaborate on your use case.
[2018-10-09 20:27:44] <dragonpiper> Hello i seem to be confused at how 'RUN' works
[2018-10-09 20:28:35] <dragonpiper> Are the artifacts  created during its execution gone afterwards
[2018-10-09 20:29:15] <dragonpiper>  [<-CODE->] 
[2018-10-09 20:30:11] <dragonpiper>  [<-CODE->] the dependancies are no longer there.
[2018-10-10 04:41:10] <matrixbot> tlacaelelIs docker backdoored by NSA?
[2018-10-10 06:30:11] <hsowan> hello everyone
[2018-10-10 09:44:45] <yashpl> matrixbot: yeah , there are few rumours and theories that NSA along with syrian govt. did try to backdoor docker.
[2018-10-10 10:38:18] <darrenstarr> I'm pretty sure that it would be hardly a challenge to get a backdoor into the docker ecosystem. Security people always focus on hacking the wrong things. For example, if you want to hack a firewall, don't have the secure code, go after things like the device drivers. VMXNET3 is a great place to start, Cisco's VIC network adapters are good too... those two code bases look like they were written by gorillas bashing keys until it did something. If you want to go after Docker, attack Portainer or something similar... or basically anything which requires access to docker.sock which is commonly used. Docker could be secure as a fortress but hijaaking Flannel or Weave would be a golden ticket. Attacking Weave would probably buy you 100 different ways to hack the network as well. I've noticed that hacking Resin.io might be pretty straight forward these days thanks to aufs. I don't use these tools because they're secure... that would be hopeless.
[2018-10-10 10:43:28] <darrenstarr> My personal opinion (not that it matters) is that what makes Linux a security disaster is that once a company starts shipping kernel modules as part of the kernel, it overcomplicates the crap out of auditing the kernel. It also means that no one ever upgrades their drivers because it would be pointless to upgrade a linux driver which is already included in Linux. I wrote a Cisco CDP module for Linux a few months back and the state of the kernel network stack is total shambles these days. sk_buff has become such a massive disgusting example of all that's wrong with the kernel that you should never ever trust Linux for security... and no... I'm not suggesting there's something better... I'm not comparing. It's just that the kernel as it is now is a mess.
[2018-10-10 11:26:05] <Huholoman> Hello! I have two containers, one with php and second with supervisor.  And I would like to be possible to manage my rabbitmq queues running in the php container by the supervisor container (using some web ui). I have a problem with running command in php container from the supervisor container. Can anyone help me, please? :)
[2018-10-10 22:33:27] <rcjsuen> dragonpiper: What do you mean "when I go to execute"
[2018-10-11 01:29:56] <mateothegreat> Huholoman: why are you running a container with supervisord?
[2018-10-11 01:49:31] <dragonpiper> rcjsuen: I figured it out. Docker inside mounts /var/jenkins_home and overrides the working directory to that so what I was seeing wasnt the directory that was built inside the container .
[2018-10-11 01:49:46] <dragonpiper> Wish the Jenkins docs were more detailed :/
[2018-10-11 01:51:13] <scott_sword_twitter> is there any way to start a container that isn't running some sort of process like a server and just use it as a dev sandbox?
[2018-10-11 02:06:06] <mateothegreat> ENTRYPOINT [“tail”, “-f”, “/dev/null”]
[2018-10-11 02:10:48] <scott_sword_twitter> I ended up using -dit which provides a pseudo tty rather than manually creating a random process [<-LINK->] 
[2018-10-11 08:10:19] <Huholoman> mateothegreat: it is our development enviroment, some of us have windows, some linux and some mac, also on test enviroment we run our applications for docker too
[2018-10-11 08:23:48] <Huholoman> *from
[2018-10-11 15:03:20] <dragonpiper> Is docker stack suppose to eventually replace docker-compose or meant to exist side by side ?
[2018-10-11 15:05:36] <LukeVideo> Hy all. I guess it's an easy one but still i'm struggling with my static files with a django+nginx setup. [<-CODE->] 
[2018-10-11 15:08:07] <LukeVideo> I want to get static files that are presnet in the dg01 container to be shared with the  ng01 container. But at the time being, the static folder in the ng01 container is empty.
[2018-10-12 06:55:30] <dejanvuj_gitlab> Hi guys, I am having issue with making connection between two dockers. I need to do the api request from one docker to another, but i get connection refused. Anyone had something like this?
[2018-10-12 08:54:05] <LukeVideo> ok i just had to change the static volumes to /static:/static.
[2018-10-12 08:54:47] <LukeVideo> dejanvuj_gitlab: do you have a nginx docker to connect both apps?
[2018-10-12 08:56:14] <dejanvuj_gitlab> LukeVideo: Thanks, I found another solution, by inspecting docker and finding gateway ip address.
[2018-10-12 08:57:05] <LukeVideo> dejanvuj_gitlab: good :)
[2018-10-12 11:00:29] <user2301>  [<-CODE->] 
[2018-10-12 11:02:54] <user2301> This command should set the enviornment variables. "RUN ["C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\vcvarsall.bat", "x86_amd64"]" , WHen I run docker build I dont see any enviornment set by this command. The enviornment set by this should be available for all other RUN commands .
[2018-10-12 11:04:16] <user2301> Can please somebody correct me if I am wrong with the execution of commands?
[2018-10-12 14:31:53] <drumbeg> Does anyone know if the--log-levelflag actually works indocker-compose up? I'm trying to suppress non errors.
[2018-10-12 15:53:05] <briancaffey_gitlab> dejanvuj_gitlab: Hi Dejan, is it an issue with CORS?
[2018-10-12 15:54:26] <briancaffey_gitlab> I have a Docker project with Django ReST Framework, NGINX and a VueJS frontend. In order for Vue to be able to make request to my backend, I needed to enable CORS in my Django app, otherwise I would get a connection_refused error
[2018-10-12 19:43:39] <mateothegreat> How would CORs cause aconnection refused?
[2018-10-12 19:43:44] <mateothegreat> Must be some SUPER CORS!
[2018-10-12 21:29:59] <hsowan> Must use aliases to get connected to other containers? can I use localhost???
[2018-10-13 01:26:27] <mateothegreat> hsowan:  [<-LINK->] 
[2018-10-13 20:43:16] <patientplatypus> hi
[2018-10-13 20:43:21] <patientplatypus> anyone alive inside?
[2018-10-14 22:29:32] <mateothegreat> patientplatypus: whats up
[2018-10-15 12:04:59] <qait-tarundwivedi> I need to setup Docker  for automation testing. What is best way to implement this ?
[2018-10-15 12:46:41] <rcjsuen> qait-tarundwivedi: That is a very vague and open-ended question
[2018-10-15 14:23:56] <SalathielGenese> qait-tarundwivedi: What is your stack (language, framework, testing tools, etc...)
[2018-10-15 14:58:07] <drumbeg> qait-tarundwivedi: Copy your tests into the container and hit GO!
[2018-10-15 15:37:33] <kevinsunny1996> “Docker for Selenium test automation?”@CStefani91 [<-LINK->] 
[2018-10-15 15:38:10] <kevinsunny1996> This article might help@qait-tarundwivedi
[2018-10-16 03:01:45] <qait-tarundwivedi> SalathielGenese: JAVA, Selenium, Maven and cucumber-jvm are the tools
[2018-10-16 03:02:50] <qait-tarundwivedi> kevinsunny1996: will try to setup and let you know. Thanks
[2018-10-16 08:26:18] <hsowan> mateothegreat: I hava read the docs, but it seems that it can be visited by aliases between two containers not by 'localhost'
[2018-10-16 08:28:23] <hsowan> what I mean is that inside a docker container I want to visit other docker containers by localhost + port
[2018-10-16 08:28:29] <hsowan> can it be  done?
[2018-10-16 12:08:14] <kevinsunny1996> qait-tarundwivedi: it was pure luck I stumbled upon this article and thought it matched ur reqs...you are welcome
[2018-10-17 02:57:31] <lanycrost> Hi guys, Can someone share good FTP image link?
[2018-10-17 05:37:23] <userljw> hi
[2018-10-17 05:37:35] <userljw> 有没有
[2018-10-17 08:19:13] <mateothegreat> hai2u2
[2018-10-17 15:16:09] <lisacopeland> can anyone help with docker  for windows
[2018-10-17 15:16:56] <drumbeg> lisacopeland: Am using Docker on a Windows VM. What's up?
[2018-10-17 15:19:45] <lisacopeland> I have been hired to help out on an angularJS project which runs on docker. I think the other devs are using macs. I am running a make file to run the build - it gets to the step 'RUN npm install' and then seems to hang - I don't see any output from NPM at all
[2018-10-17 15:20:36] <lisacopeland> drumbeg: It then exits after a few minutes with  encountered an error during CreateProcess: failure in a Windows system call: The compute system exited unexpectedly. (0xc0370106)
[2018-10-17 15:21:04] <drumbeg> By "make file" do you mean Dockerfile?
[2018-10-17 15:22:02] <lisacopeland> There is a makefile which runs the 'docker build' command and then the 'docker run' command
[2018-10-17 15:22:08] <joshuaalm> lisacopeland: Does the Dockerfile specify to install the node and npm packages prior to that step?
[2018-10-17 15:22:59] <lisacopeland> It looks like it does it in the dockerfile
[2018-10-17 15:23:25] <lisacopeland> it starts with 'FROM node:10.5.0'
[2018-10-17 15:23:42] <joshuaalm> OK, so it's using the node docker image as a base
[2018-10-17 15:24:13] <lisacopeland> yeah I gathered that - I am not sure why they are using that version
[2018-10-17 15:24:47] <rcjsuen> lisacopeland: Is there something with 10.5.0 that concerns you?
[2018-10-17 15:25:03] <joshuaalm> That is certainly an unstable build.  Maybe verify with the team building the app that they're testing on that.
[2018-10-17 15:25:08] <lisacopeland> no - I was just curious about it
[2018-10-17 15:25:50] <rcjsuen> joshuaalm: Oh, hm, it's unstable?
[2018-10-17 15:25:51] <lisacopeland> Maybe I'll try a different one - any suggestions?
[2018-10-17 15:26:02] <rcjsuen> or you mean it's not LTS yet?
[2018-10-17 15:26:45] <lisacopeland> I guess the reason I was wondering about it is that I am running 10.4.1
[2018-10-17 15:27:10] <joshuaalm> I do of course mean that because it's recent - not LTS - it may be  unstable.  Of course, if the devs are using the features in a more recent version, that's up to them to decide.
[2018-10-17 15:27:41] <joshuaalm> And if you're using 10.4.1 on your system, Lisa, then it stands to reason they are.
[2018-10-17 15:29:27] <drumbeg> My team have had issues with Node v10 and some of the node modules we use, so I would concur.
[2018-10-17 15:29:54] <lisacopeland> joshuaalm: I just started with this team - I don't know what they are running for node - I am going to reach out about this
[2018-10-17 15:32:28] <rcjsuen> lisacopeland: Perhaps you can also trynpm install --verbosefor more output maybe?
[2018-10-17 15:32:51] <lisacopeland> rcjsuen: Thanks - I'll try that
[2018-10-17 15:33:57] <rcjsuen> lisacopeland: I don't know how complicated the build is. But if we assume a basicpackage.json, then you can always try doingnpm installon your own computer instead of through the Docker image. Does that work?
[2018-10-17 15:35:04] <lisacopeland> rcjsuen: Yep - that is no problem -  I regularly do npm install, but the version I am using is 10.4.1
[2018-10-17 15:37:57] <rcjsuen> I suppose you can also change toFROM node:10.4.1if you feel that's an issue
[2018-10-17 15:39:55] <lisacopeland> Looks like the -v switch didn't make a difference - looks like it is hanging and then it errored out the same way
[2018-10-17 15:40:56] <rcjsuen> That's too bad.
[2018-10-17 15:41:17] <rcjsuen> There are no log output files?
[2018-10-17 15:43:55] <rcjsuen> I would suggest removing everything from and including yourRUN npm installthen changing it to start a shell instead, then start that container and from the shell runnpm install --verbosemanually and see what happens out of the shell and for any debug/log output files from Node.js
[2018-10-17 15:45:37] <lisacopeland> rcjsuen: Ooh -  good idea - I am going to try that. I did just download a sample dockerized angular app  and it starts with FROM node:9-alpine as builder and it seemed to run npm just fine
[2018-10-17 15:53:06] <rcjsuen> I would consider Node 9.x series even more unstable than the Node v10 series
[2018-10-17 15:53:25] <rcjsuen> But irregardless, it's good that a sample Dockerfile you found online ran
[2018-10-17 15:53:31] <rcjsuen> If that didn't run you have other problems probably ;)
[2018-10-17 16:16:01] <mateothegreat> lisacopeland: is your container able to reach [<-LINK->] ?
[2018-10-17 21:25:16] <hillct> Good evening. Can someone clarify for me whether or not the docker official (repo) mydqld container is meant to bind to the container IP by default? The mysql.cnf appears to suggest it listens only to the local unix socket, not port 3306, unless an external mysql.cnf is used. Is this accurate?
[2018-10-17 23:23:35] <lisacopeland> Hey All - I have got a sample Angular 6 app to build and run in docker - how do I see it?
[2018-10-18 01:00:25] <mateothegreat> lisacopeland: see it? have you built your image yet?
[2018-10-18 01:06:29] <mateothegreat> lisacopeland:  [<-LINK->] might help ya out
[2018-10-18 02:37:07] <lisacopeland> mateothegreat: Thank you so much - I figured out the port to view - but I am getting 403 Forbidden
[2018-10-18 02:37:46] <mateothegreat> lisacopeland: most likely your dist dir isn’t in the right place, i.e.: no index.html so it’s 403
[2018-10-18 02:38:16] <lisacopeland> mateothegreat: thank you for that - how do I see stuff in the container?
[2018-10-18 02:38:36] <mateothegreat> get the container name (docker ps)
[2018-10-18 02:38:45] <mateothegreat> thendocker exec -it <container name> sh
[2018-10-18 02:38:54] <mateothegreat> that’ll drop you into a shell inside of the running container
[2018-10-18 02:39:06] <lisacopeland> ok - thanks I'll try that
[2018-10-18 02:40:15] <lisacopeland> So I am following the tutorial at [<-LINK->] 
[2018-10-18 02:41:12] <brendonco> lisacopeland: please check my tutorial [<-LINK->] 
[2018-10-18 02:41:36] <lisacopeland> mateothegreat: yes - the files are not where they are supposed to be
[2018-10-18 02:41:44] <lisacopeland> brendonco: Thank you I will look at it
[2018-10-18 02:41:52] <brendonco> although the JS framework is in ReactJS, any JS framework will do
[2018-10-18 02:41:53] <mateothegreat> figures heh
[2018-10-18 02:44:22] <lisacopeland> brendonco: It looks like your tutorial is for the mac - I am on windows - are there any differences that I should be aware of?
[2018-10-18 02:45:06] <mateothegreat> brendonco: should show the user how to use a nginx web server and build distribution rather than depending onnpm start.. but good work
[2018-10-18 02:45:22] <mateothegreat> and maybe add-fto thedocker logs ..command :P
[2018-10-18 02:45:43] <mateothegreat> lisacopeland: did you even try myDockerfile?? :(
[2018-10-18 02:46:00] <lisacopeland> mateothegreat: what do you mean?
[2018-10-18 02:46:06] <brendonco> I'll take note of that@mateothegreat. my next thing for my next project.
[2018-10-18 02:46:37] <mateothegreat> lisacopeland:  [<-LINK->] is all you need my friend
[2018-10-18 02:47:03] <lisacopeland> mateothegreat: Thank you I will get that
[2018-10-18 02:49:35] <lisacopeland> mateothegreat: And I still do docker build . -t myapp
[2018-10-18 02:49:37] <lisacopeland> right?
[2018-10-18 02:49:42] <mateothegreat> yes mam
[2018-10-18 02:50:02] <mateothegreat> docker build -t myapp .
[2018-10-18 02:50:12] <lisacopeland> ok - building
[2018-10-18 02:50:13] <mateothegreat> docker run -d -p 80:80 —name myapp myapp
[2018-10-18 02:55:59] <lisacopeland> It can't find the package.json file:
[2018-10-18 02:56:39] <mateothegreat> brew install tmate
[2018-10-18 02:56:53] <mateothegreat> thentmateand PM me your ssh session info and I’ll help ya out
[2018-10-18 02:57:06] <mateothegreat> err you’re on windows n/m
[2018-10-18 02:57:15] <lisacopeland> Is this a way of screen sharing?
[2018-10-18 02:57:31] <mateothegreat> Kinda, but your ssh terminal
[2018-10-18 02:57:45] <mateothegreat> if you wanna hop on a screenshare I got some time
[2018-10-18 02:57:46] <lisacopeland> ok hang on...
[2018-10-18 02:58:26] <lisacopeland> uh oh I don't think that runs on windows
[2018-10-18 02:58:45] <lisacopeland> I can skype or do google hangouts
[2018-10-18 02:58:47] <mateothegreat> I’ll PM you a link :P
[2018-10-18 02:58:53] <lisacopeland> thanks
[2018-10-18 03:03:58] <474846718> docker for windows cann't download kubernetes component?
[2018-10-18 03:04:35] <474846718> have not receive any data download stream data...
[2018-10-18 03:05:01] <474846718> stucking...
[2018-10-18 03:17:52] <SimonLeeee> Hi everyone
[2018-10-18 03:18:04] <SimonLeeee>  [<-LINK->] 
[2018-10-18 03:18:41] <SimonLeeee> What is full name of Bins and Libs?
[2018-10-18 03:19:26] <SimonLeeee> I'm a newbie, could someone tell me that ?
[2018-10-18 03:23:47] <kevinsunny1996> Binaries and libraries@SimonLeeee
[2018-10-18 03:24:11] <SimonLeeee> kevinsunny1996: Oh got it, thanks
[2018-10-18 03:24:25] <474846718> 讲中文
[2018-10-18 04:32:48] <kevinsunny1996> Pull a kubernetes image from dockerhub if there's one@474846718
[2018-10-18 15:02:36] <dragonpiper> if i do a docker run and start and application inside that container. how do i kill the running application without exiting the container
[2018-10-18 17:20:43] <kevinsunny1996> I think maybe u can find the process id (pid) of that application and kill it.
[2018-10-18 17:20:49] <kevinsunny1996> dragonpiper: 
[2018-10-18 22:49:34] <dragonpiper> I was able to install docker-compose with pip but is there a way i can also install inspect ?
[2018-10-19 10:37:25] <rcjsuen> dragonpiper: I don't understand.docker inspectis a core part of Docker
[2018-10-19 18:38:06] <dragonpiper> here: What do you guys think about [<-LINK->] 
[2018-10-21 01:42:07] <vinnyvoo> here: i'm new to docker. how to keep autostart a service when i start a container with 'docker run -t -d $id. I didn't build the image from Dockerfile..its a committed container.
[2018-10-21 07:04:17] <mateothegreat> vinnyvoo: add—restart=alwaysto your run docmmand
[2018-10-22 07:09:26] <krarpitgupta_twitter> Hi Team I am running UI test cases (nightwatch + js) inside docker image but getting below exception, Can anyone help me with this ? [<-CODE->] 
[2018-10-22 16:34:24] <katsar0v> Hello guys, have any of you usedsupervisorwithcronandnginx? I cannot setup nginx and cron to output to the supervisor log for docker
[2018-10-23 07:17:16] <prashanth-sams> Why entrypoint.sh is not aware about the environment variables that I set on the Docker image?
[2018-10-23 07:18:08] <adaliszk> Weird, it should be most of my images are built using that :/
[2018-10-23 07:18:34] <mateothegreat> prashanth-sams: how are you passing the env vars?
[2018-10-23 07:19:21] <prashanth-sams> in Dockerfile [<-CODE->] 
[2018-10-23 07:19:27] <prashanth-sams>  [<-LINK->] 
[2018-10-23 07:20:02] <prashanth-sams> mateothegreat: 
[2018-10-23 07:20:21] <adaliszk> I think that shold only work if you switching to bash before you ran your commands via the entrypoint script
[2018-10-23 07:20:41] <mateothegreat> no where in that docker file does it pass environment variables
[2018-10-23 07:20:45] <mateothegreat> useENV
[2018-10-23 07:21:32] <prashanth-sams> sure; will do that... I just pass the location in bashrc
[2018-10-23 07:21:41] <prashanth-sams> let me tryENV
[2018-10-23 07:22:18] <m4d3bug> RUN for install
[2018-10-23 07:24:40] <mateothegreat> ?
[2018-10-23 07:36:19] <katsar0v>  [<-CODE->]  [<-CODE->] this is my cron : [<-CODE->]  [<-CODE->] 
[2018-10-23 09:13:13] <rcjsuen> Do you see the output indocker logs?
[2018-10-23 09:30:48] <katsar0v> nope
[2018-10-23 09:31:05] <katsar0v> but with docker exec i see the file has contents (/var/log.log)
[2018-10-23 09:31:28] <katsar0v> A workaround is to write directly to/proc/1/fd/1
[2018-10-23 09:31:53] <katsar0v> e.g. [<-CODE->] 
[2018-10-23 09:32:20] <rcjsuen> I guess the stdout/stderr output is lost
[2018-10-23 09:36:05] <katsar0v> In order to see the output in docker logs,cron -fshould output stuff in stderr/stdout. This is not the case, I don't know why.
[2018-10-23 17:44:21] <dragonpiper> Anyone know file i/o is so slow on mac when not using a vm ? or if there is a way to improve it ?
[2018-10-23 19:19:16] <dragonpiper> is there a way to copy data to a volume outside of a dockerfile ?
[2018-10-23 19:20:06] <mateothegreat> usedoker cp
[2018-10-23 19:26:16] <dragonpiper> Well the the issue is my build image and my source are in separate repositories. I was just specifying a normal bind mounted volume in my compose file but file i/o is just to slow.  Is the best method to create a named volume copy source then run docker-compose ?
[2018-10-23 19:28:51] <dragonpiper> or is there a way to disable syncing on a bind mount
[2018-10-23 23:15:33] <mterron> Hi group, I'm trying to figure out the way to pass mount options to an anonymous volume to no avail, does anyone have any pointers?
[2018-10-23 23:16:29] <mterron> with tmpfs I can do: /foo/bar:mode=770,uid=1000,gid=10000 and it does what you expect, with a volume it fails
[2018-10-24 02:27:23] <briancaffey_gitlab> Has anyone seen this error? I started seeing it all of the sudden. Docker hub status has operational [<-CODE->] 
[2018-10-24 02:36:12] <mterron> docker-hub is down? connectivity problems at your end?
[2018-10-24 02:36:44] <thanhdongnguyen> no. i see no problem :D
[2018-10-24 02:38:05] <mterron> Seems it's something on your end@briancaffey_gitlab
[2018-10-24 02:38:21] <mterron>  [<-CODE->] 
[2018-10-24 02:41:24] <thanhdongnguyen> Downloaded newer image. is this updated?
[2018-10-24 06:54:53] <mateothegreat> or just use kubespray
[2018-10-24 06:55:12] <mateothegreat> using “AKS” is far from “scratch"
[2018-10-24 06:55:12] <mateothegreat> lol
[2018-10-24 06:55:20] <mateothegreat> but glad you’re excited
[2018-10-24 06:56:21] <mateothegreat> that’s a lot to cover
[2018-10-24 06:56:35] <mateothegreat>  [<-LINK->] .. a real world example
[2018-10-24 12:28:46] <lnys> hello
[2018-10-24 17:53:00] <manooojmanu> Hi..Can anyone please guide me how to integrate docker compose and run integration tests in it?
[2018-10-24 17:53:17] <manooojmanu> For an sbt project
[2018-10-25 06:14:00] <kevinsunny1996> Which combo is better? Docker-Kubernetes or Docker-Ansible?
[2018-10-25 12:48:40] <katsar0v> Docker-Ansible, IMO
[2018-10-25 12:59:20] <rcjsuen> We use both at work but I think the dream would be to replace Ansible with Kubernetes or to use Ansible to tell Kubernetes to start. That's not to say we are using one or both tools incorrectly... :)
[2018-10-25 12:59:47] <rcjsuen> Or rather, we may be using one or both correctly...or incorrectly :)
[2018-10-25 14:08:03] <briancaffey_gitlab> mterron: thanks, I think I had a slow network and it was timing out just as the error message said
[2018-10-25 14:55:31] <kevinsunny1996> Thanks@rcjsuen@katsar0v
[2018-10-25 22:25:35] <realrunner> Can anyone here explain why, in Linux, using local bind mounts results in all files in the mounted directory owned bynobody:nobody. I expectedroot:root?
[2018-10-25 22:25:44] <realrunner>  [<-CODE->] 
[2018-10-26 09:59:35] <rajnalla_gitlab> how to run webpack in watch mode in a docker container?
[2018-10-26 10:00:08] <rajnalla_gitlab> any one please help me resolve this
[2018-10-26 11:42:04] <adaliszk> rajnalla_gitlab:  [<-CODE->] 
[2018-10-26 11:42:14] <adaliszk>  [<-ISSUE->] 
[2018-10-26 14:44:55] <thymbahutymba> Hi, someone have some guide that explain how to develop some app POSIX on windows using docker?I want use docker for develop (with clion) build and test my project with a linux container, in this way i can use something like pthread.I already have docker image but i don't know which are the steps that i have to follow for develop project and then build it on docker container.
[2018-10-26 14:51:32] <rcjsuen> thymbahutymba: Have you been successful compiling a hello world on it?
[2018-10-26 14:53:26] <thymbahutymba> rcjsuen: i don't know which are the process that i have to follow for deploy and build it
[2018-10-26 15:27:36] <thymbahutymba> The beaviour that i wish is something like this: develop with clion that compile the code in docker container and then run the binary on it.
[2018-10-26 15:29:51] <mateothegreat> thymbahutymba: so where are you stuck exactly?
[2018-10-26 15:31:21] <thymbahutymba> mateothegreat: to the start? I've still created the linux image with develop tool, then what i have to do? Before start it's possible doing something like this?
[2018-10-26 15:45:00] <mateothegreat> after youdocker build.. you typicallydocker runyour image
[2018-10-26 15:49:35] <thymbahutymba> mateothegreat: of course but what is the steps that i have to follow to develop my code on docker and then test it?
[2018-10-26 15:50:00] <mateothegreat> youCOPY . /appyour code into the docker image
[2018-10-26 15:50:32] <mateothegreat> follow this example: [<-LINK->] 
[2018-10-26 15:56:56] <scottdillon_gitlab> Reading the docker tutorial would help too.
[2018-10-27 08:21:31] <thymbahutymba> mateothegreat: so each time i change the code i have to make image again for copy all source into docker image, then i can run it and test my app?
[2018-10-27 08:22:13] <mateothegreat> thymbahutymba: correctamundo
[2018-10-27 08:24:20] <mateothegreat> So think of a “build” (docker build ..) as a means to affect the desired state expressed in yourDockerfile.
[2018-10-27 08:24:58] <mateothegreat> It should be assumed that a build will succeed, or retry until successful, and will achieve your desired state.
[2018-10-27 08:25:30] <mateothegreat> Therefore rendering an image that is deployment ready, without dependencies.
[2018-10-27 08:27:10] <mateothegreat> Another by-product of running your builds (and tests!) in a docker image is that you get a pristine environment where your tests cannot be negatively influenced by environment variables like your local version of globally installed packages.
[2018-10-27 08:29:13] <thymbahutymba> so every time i have to build and then run the container. I thought that i have just to run because the image was still created
[2018-10-27 08:29:49] <mateothegreat> I don’t understand the question :/
[2018-10-27 08:30:21] <mateothegreat> Are you saying you build your image and then youdocker runthe new image to execute your tests?
[2018-10-27 10:01:43] <qait-tarundwivedi> I have tried but finding error :unable to prepare context: unable to evaluate symlinks in Dockerfile path: GetFileAttributesEx C:\\Users\\tarundwivedi\\Dockerfile: The system cannot find the filespecified.
[2018-10-27 10:01:43] <qait-tarundwivedi> Hey how i will create Dockerfile in Window OS
[2018-10-28 01:48:33] <c0ze> @mateothegreat so each time i change the code i have to make image again for copy all source into docker image, then i can run it and test my app?Essentially yes. But docker is smart enough to cache build steps in your previous builds. Every line in your dockerfile corresponds to an image layer. If you don't change your line, previously generated layer will be used. Therefore, if you don't change your deps, only the lines after your COPY command should be run, others will be used from layer cache.You can find more about docker layers herehttps://stackoverflow.com/questions/31222377/what-are-docker-image-layers
[2018-10-28 10:07:19] <rossanoua> hello everyoneeny russian speaking?
[2018-10-28 10:08:11] <rossanoua> how i can use file from another path in docker-compose.yml ?
[2018-10-28 10:08:52] <rossanoua> I'm tryingsearchingbut no success...
[2018-10-28 11:57:23] <RicoToothless> you can trydocker-compose -f  {firstpath/secondpath/docker-compose.yml}  up
[2018-10-28 11:59:45] <RicoToothless> you can use relate directory too.  likedocker-compose -f  {../../hahapath/docker-compose.yml}  up
[2018-10-28 14:20:56] <rossanoua> okthankyoui will trybut if i want to have another one docker-compose.ymlwith all needed options for get up and running all my env2 or moredo the docker-compose understand thefile: ../myproject/docker-compose.ymlsyntax...???
[2018-10-28 14:21:14] <rossanoua> thankyou in advance
[2018-10-29 06:05:59] <qait-tarundwivedi> How to create Dockerfile in Window OS ? and execute ...(OS version 8.1)
[2018-10-29 07:01:55] <mateothegreat> qait-tarundwivedi: aDockerfileis just a plain text file
[2018-10-29 07:13:27] <mateothegreat> You can find an exampleDockerfileand commands on how to build it at [<-LINK->] 
[2018-10-29 11:49:13] <ghost~5bc98094d73408ce4fabf741> combo Consul for Service Discovery and distributed KV store, Ocelot for Gateway load balancing, Identity Server 4 for authentication and RabbitMQ as a Service Bus hosted on premises in a private network running Docker Containers orchestrated with Kubernetes. How realistic is this? I am especially referring to the docker integration, are there any issues I should be aware of? What you guys think? I can see IS4 and Ocelot have nice integrations with Consul but I am not sure if I will not run into accessability problems inside of the containers. I would be running a set of .NET Core 2.1 Services inside the containers. Anyone tried a similar setup?
[2018-10-29 14:39:49] <chiragg6_gitlab> Getting this error - docker: Error response from daemon: driver failed programming external connectivity on endpoint cranky_austin (76882569bfafcfc357552905bc61f66709275804e66f58b25cf49d2ddff16569): Error starting userland proxy: Bind for 0.0.0.0:3000 failed: port is already allocated.
[2018-10-29 17:25:23] <kevinsunny1996> Allocate another port for that container
[2018-10-29 17:31:07] <adaliszk> or kill the running container/process on  that port (OwO)
[2018-10-30 13:58:52] <phiter> Hey guys!I'm running metabase and I ran it without docker-compose. Now I want to link it to an existing container so I don't need to change the IP every time if it changes. I want to use it as an alias, and in order to do that, these containers must be linked, right? So, how do I link two (or more) existing containers trough a docker-compose?
[2018-10-31 08:57:23] <larsdesigns> phiterf: The good news is that docker-compose automatically makes a docker network for you.
[2018-10-31 08:57:44] <larsdesigns> So there is no need to us the the depreciated —link option.
[2018-10-31 08:58:50] <larsdesigns> It is optional to define your own user-defined network within the docker-compose file but usually not nessesary if the default works.
[2018-10-31 08:59:26] <larsdesigns> By default the container name is the host name and all the containers within the docker-compose file can access each other using that name.
[2018-10-31 09:00:20] <larsdesigns> phiterf: I hope that helps.
[2018-10-31 09:13:51] <katsar0v> I have a docker image with ssh server (open ssh). Runs on a non-default port 9911. First login succeeds, but when I try second login with the same user I getssh_exchange_identification: Connection closed by remote host. I think this issue exists only when ssh runs in docker
[2018-10-31 09:14:07] <katsar0v> Maybe somebody know more info about this
[2018-10-31 10:10:49] <larsdesigns> katsar0v: , it is usally discouraged to run ssh within a container. Because the containers are availble using docker exec. However, you can debug the authentication using ssh -v and examining the output.
[2018-10-31 10:11:37] <larsdesigns> Can I ask why you would opt to use ssh?
[2018-10-31 10:13:29] <katsar0v> I have a wp system that has a folder insidewp-content. This folder is a docker volume, which is also mounted in an ssh container, so users can upload stuff with WinSCP
[2018-10-31 10:13:47] <katsar0v> I dont want users to access the host machine, they just access the isolated docker container with sftp / ssh
[2018-10-31 10:14:39] <larsdesigns> Okay, then looks like you should debug the handshake using ssh -v.
[2018-10-31 10:15:00] <larsdesigns> The output should show you where the authentication process is failing.
[2018-10-31 10:15:58] <larsdesigns> ssh -v -l username host/ip
[2018-10-31 10:16:01] <katsar0v> and in ssh only one user is allowed. Problem is that only one machine can be logged at the same time for this user
[2018-10-31 10:16:08] <katsar0v> I will post output now
[2018-10-31 10:16:50] <katsar0v>  [<-CODE->] 
[2018-10-31 10:17:18] <katsar0v> Seems the port 9911 is already taken from the first login, so I cannot login twice
[2018-10-31 10:19:13] <larsdesigns> hhmm
[2018-10-31 10:20:14] <larsdesigns> Looks in /etc/sshd_config. I there is an option to restrict the number of connection.
[2018-10-31 10:20:21] <larsdesigns> yes, the “MaxSessions" option
[2018-10-31 10:20:37] <katsar0v> I tried with standardsshd_configon port 22. Here is my config [<-CODE->] 
[2018-10-31 10:20:44] <katsar0v> MaxSessions defaults to 10
[2018-10-31 10:20:50] <katsar0v> I try to login twice only
[2018-10-31 10:22:01] <larsdesigns> Try setting: MaxSessions 100
[2018-10-31 10:23:18] <larsdesigns> or higher
[2018-10-31 10:23:34] <katsar0v>  [<-CODE->] 
[2018-10-31 10:23:37] <katsar0v> strange
[2018-10-31 10:24:34] <katsar0v> myDockerfileis also really simple [<-CODE->] 
[2018-10-31 10:26:20] <larsdesigns> katsar0v: Let me know when you try setting: MaxSessions 100 in sshd_config.
[2018-10-31 10:27:28] <larsdesigns> I will need to go offline for a while. But you are in good hands in this channel.
[2018-10-31 10:29:17] <katsar0v> I did this, last output was with this setting
[2018-10-31 10:30:23] <larsdesigns> I do not think it is related but you will want to make sure to expose the port in the DockerFile.
[2018-10-31 10:31:37] <larsdesigns> if not exposed in the build, then I have found unpredictable behaviour for port connections depending on the docker version.
[2018-10-31 10:32:59] <katsar0v> just tried - https://docs.docker.com/engine/examples/running_ssh_service/it works with multiple logins
[2018-10-31 10:42:57] <larsdesigns> Excellent
[2018-10-31 11:01:34] <SalathielGenese> Hi folks,I've been overriding CMD in docker-compose to run with nodemon and other dev stuff, but to test graceful shutdown, I removed the CMD override from docker-compose.yaml file and my container isn't output to terminal. I tried : [<-CODE->] Here is my Dockerfile [<-CODE->] Here's an except from docker-compose.yaml [<-CODE->] And finally, an excerpt from package.json [<-CODE->] 
[2018-10-31 11:04:47] <SalathielGenese> My problem is to havemy container output to terminalwhen Idocker-compose up --build
[2018-10-31 11:05:06] <SalathielGenese> Thanks beforehand !
[2018-10-31 11:13:00] <SalathielGenese> PS: Yes, I ran it withdocker run- Same misbehavior
[2018-10-31 11:37:49] <katsar0v>  [<-CODE->]  [<-CODE->] 
[2018-10-31 11:37:58] <katsar0v> the node image should have default CMD in case you deleted yours
[2018-10-31 11:39:00] <katsar0v> cmd in dockerfile and docker compose is different I see
[2018-10-31 11:45:02] <SalathielGenese> @katsar0v , [<-CODE->] 
[2018-10-31 11:52:11] <rcjsuen> Did you try running in detached mode with-dthen?
[2018-10-31 11:55:52] <SalathielGenese> The DevOps I work with just got up and found it - [<-CODE->]  [<-CODE->] Thanks unto you guys, @rcjsuen , @katsar0v !
[2018-10-31 11:58:30] <SalathielGenese> So the fix is to add environment in docker-compose.yaml [<-CODE->] 
[2018-10-31 12:02:15] <katsar0v> you meanDEBUGenv variable for the container? (because there is log level for docker which is a separate thing). Just to clarify this
[2018-10-31 12:03:20] <SalathielGenese> Yes, for the container -The other services were just running fine (redis, pubsub emulator, etc...)
[2018-10-31 12:03:35] <katsar0v>   glad you solved this
[2018-10-31 12:03:42] <SalathielGenese> running fine and logging just fine -
[2018-10-31 12:07:36] <SalathielGenese> Thanks for your endeavor
[2018-10-31 12:51:17] <katsar0v> Hello, has somebody made benchmarks with HDD I/O on volumes mounted at the same time on different containers vs. I/O on host HDD?
[2018-10-31 12:51:32] <katsar0v> I think performance might be a bit lower on mounted volumes with docker
[2018-10-31 21:59:08] <sabrehagen> Hi, I'm having trouble with mounts. I want to have adocker-composecontainer which starts mydocker-compose.yamlfile. I'm usingdocker run --rm  --mount type=bind,source=$HOME,target=/root,bind-propagation=shared wernight/docker-composebut when my containers in mydocker-compose.yamlfile are started, the mounted directories contain no files
[2018-10-31 21:59:34] <sabrehagen> volume mounts:host -> docker-compose -> compose-stack-container
[2018-10-31 22:00:14] <sabrehagen> Fromhost -> docker-composethe mount works, but fromdocker-compose -> compose-stack-containerit doesn't
[2018-10-31 22:01:46] <sabrehagen> My compose file has [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2018-11-01 01:18:15] <sabrehagen> The first question I need clarified is: Is it possible to create anewcontainer with a mounted volume fromwithina container with that volume mounted.
[2018-11-01 09:06:43] <vella-nicholas> I am using Docker on Windows and when I boot up my laptop, Docker starts but mu MongoDb instance does not work. I have to restart Docker everytime. Is this a known issue or am I doing osmething wrong?
[2018-11-01 09:21:50] <mateothegreat> nvella88: do you mean your mongo container does not automatically start?
[2018-11-01 09:26:23] <vella-nicholas> yes
[2018-11-01 09:33:55] <vella-nicholas> it should start automatically no? Or did I miss some setup config?
[2018-11-01 10:02:37] <mateothegreat> you need to use—restart=alwaysif you useddocker run ..
[2018-11-01 10:02:56] <mateothegreat> if you used docker-compose you will need to use [<-CODE->] 
[2018-11-01 10:25:14] <vella-nicholas> thank you, I will have a look
[2018-11-01 12:17:36] <sabrehagen> mateothegreat: Do you have any idea about my issue above?
[2018-11-01 12:35:46] <mateothegreat> sabrehagen: why not use use-v $HOME:/root?
[2018-11-01 12:36:08] <mateothegreat> also, I don’t think overwriting /root is a good idea
[2018-11-01 12:36:32] <sabrehagen> True, but this is just a dev environment
[2018-11-01 12:36:57] <sabrehagen> What would your volume recommendation achieve? I'm not understanding it
[2018-11-01 12:37:40] <mateothegreat> what are you trying to accomplish?
[2018-11-01 12:37:59] <mateothegreat> I took that from your post, "I\'m using docker run --rm --mount type=bind,source=$HOME,target=/root,bind-propagation=shared "
[2018-11-01 23:27:28] <AlexITC> Hi, is there a simple guide on how to use the docker REST API while working on windows?
[2018-11-02 00:59:14] <sabrehagen> mateothegreat: The full--mountargument rather than-vis so I can set thebind-propagationargument. I found my aforementioned 'empty mounts' when I used-v.
[2018-11-02 11:21:32] <iosven> hi, I am hoping to get some hints here, we have a plain vanilla setup with a dockerized nginx acting as http Reverse Proxy and a dockerized microservice with a http REST API behind it... usually when we restart the microservice (we do that withdocker-compose downanddocker-compose up -d) we also need to restart the nginx, otherwise it will tell the outside world that our URL path is HTTP Status 502 Bad Gateway. Any hints to that?  Does nginx somehow cache aspects of TCP connections it uses to forward requests, or can this be a Docker-specific problem/behavior?
[2018-11-02 11:33:05] <adaliszk> try out [<-LINK->] 
[2018-11-02 12:28:18] <adaliszk> or have a look at how jwilder and the contributors solve the same issue
[2018-11-02 12:28:20] <adaliszk> :P
[2018-11-02 13:36:41] <iosven> adaliszk: thanks, having a look
[2018-11-02 13:37:27] <adaliszk> what that image does it listens to docker events and automatically updates and creates reverse proxy on the network where it's deployed
[2018-11-04 05:53:36] <royswastik> If I dockerize my existing application with single node and two replicas, how do I maintain persistent user session in those two replicas?
[2018-11-04 05:53:52] <royswastik> I have looked at sticky session on docker docs ( [<-LINK->] ) . But, do I have to setup this everytime I dockerize an application which maintains user session?
[2018-11-04 06:25:51] <mateothegreat> royswastik: usually you have a reverse proxy like haproxy or nginx in front
[2018-11-04 06:49:43] <ramireles> Isn’t a user session and Authentication gonna be dependent on the backend framework?
[2018-11-04 07:15:49] <mateothegreat> most session data is stored on the filesystem by default .. so pinning a user to a specific node it the only logical choice otherwise you’re rolling redis/memcache/etc as a session store
[2018-11-04 15:18:43] <fahman> Hi guys, question about golang docker client:client.CopyFromContainer(dockerCtx, dockerContainerId, "/tmp/roles.json") produces a io.ReadCloser that has some weird (atleast to me) content:roles.json                                                                                           0100644 0000000 0000000 00000000015 13367605423 011137  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        {"roles": []}It looks as if reader is returning directory (or mebbe tar?) of a file instead of file content.So question is - is this expected behavior and if yes, is there a golang example on how to actually get the file content from CopyFromContainer()?
[2018-11-04 15:27:06] <sebastjan-hribar> Hi all, I have a more high level docker question. I currently have one dockerized app running on a custom server with dedicated DB container. This was more or less my learning project and a POC of the app. Now I'd like to scale and I'd advice where to look for further learning material and best practices how to do this with docker. I imagine it would be best to have the same APP/DB container par for each new customer. Am I right?
[2018-11-04 18:33:58] <royswastik> mateothegreat: That was helpful. I am exploring on how to pin the user to specific nodes.
[2018-11-05 00:55:03] <royswastik> @‘a
[2018-11-05 00:55:57] <royswastik> @mateothegreat can you give a little explanation on why reverse proxy will solve the session problem?
[2018-11-06 02:42:49] <DavidMoura07> hi guys, i have a doubt with docker-compose and yours ambient variables, the situation is: I have one container that runs a shellscript and this sh use a lot of ambient variables, so I pass this variables by docker-compose, but my shellscript don\'t see that! if I run "echo $VAR" it prints "" even setting this on composeThis is my compose piece: [<-CODE->] Can one help me? Thanks!
[2018-11-06 02:58:50] <mateothegreat> DavidMoura07: try something like: [<-CODE->] 
[2018-11-06 03:06:03] <DavidMoura07> like this @mateothegreat ? [<-CODE->] I had tried this type but got the same problem :/
[2018-11-06 03:07:30] <mateothegreat> DavidMoura07: what does yourDockerfilelook like?
[2018-11-06 03:09:16] <DavidMoura07> mateothegreat:  [<-CODE->] 
[2018-11-06 03:09:44] <mateothegreat> grab a shell, runenv.. do you see any of your vars?
[2018-11-06 03:13:46] <DavidMoura07> nops, I have to export this locally first?
[2018-11-06 03:56:47] <mateothegreat> fahman: shouldn’t need to .. do you happen to have a file named.envin your directory when building the image? if so, this is overriding your env vars
[2018-11-06 09:03:56] <PerArneng> In windows containers is it possible to become another user?
[2018-11-06 09:04:22] <PerArneng> the --user param just gives me invalid username or password. i have created the user in the Dockerfile
[2018-11-06 12:18:49] <PerArneng> solved it
[2018-11-06 20:39:43] <APiercey> Hello everyone! I am wondering if someone would be kind enough to point me to some resources. I am trying to have a fast TDD development style and am trying to speed up the execution of my tests. I am a node and ruby dev.
[2018-11-06 20:40:15] <APiercey> Currently, I running my tests inside of a docket container with docker-compose run
[2018-11-06 20:40:56] <APiercey> And I apologize if this is not the correct room  ! If it isn’t, just point me in another direction and I’ll be fine!
[2018-11-06 20:52:46] <ghost~5bc98094d73408ce4fabf741> Considering the network in compose is closed and managed internally by the docker daemon, is there any point of running https inside of the individual microservices in the containers? I am not talking frontend app which is obviously ssl to protect from user->browser request hijacking, just the backend services. I see quite alot of people running port 80 on compose
[2018-11-07 10:11:32] <elcolie> Hi
[2018-11-07 10:11:34] <elcolie> Help
[2018-11-07 10:11:34] <elcolie>  [<-LINK->] 
[2018-11-07 15:14:29] <ghost~5bc98094d73408ce4fabf741> elcolie: shouldn't it be just context: .
[2018-11-07 15:14:29] <ghost~5bc98094d73408ce4fabf741> ?
[2018-11-07 15:14:34] <ghost~5bc98094d73408ce4fabf741> in compose
[2018-11-07 15:15:57] <dragonpiper> Can you use multipleFROMto combine full images  ?
[2018-11-07 15:16:25] <ghost~5bc98094d73408ce4fabf741> yes@dragonpiperbut you need to copy and use intermediary containers
[2018-11-07 15:18:25] <dragonpiper> For example i'm trying to combinegolangrastasheep/ubuntu-sshd. I declared the golang image as base, but how do i know what i have to copy from the golang stage ?
[2018-11-07 15:18:33] <ghost~5bc98094d73408ce4fabf741> when declaring the initial image use "AS" so "FROM node:alpine AS first_image"
[2018-11-07 15:19:48] <ghost~5bc98094d73408ce4fabf741> and then after declaration of the second image tell it to use that alias like so: "COPY --from=first_image /app/dir /app/dir
[2018-11-07 15:21:13] <ghost~5bc98094d73408ce4fabf741> COPY --from=first_image src_folder dir_folder
[2018-11-07 15:22:52] <ghost~5bc98094d73408ce4fabf741> dragonpiper: 
[2018-11-07 15:25:40] <dragonpiper> So if the base image apk installs some programs, and make certain directories. I have to know where all the artifacts are of all those processes and manually specify a copy from path ?
[2018-11-07 15:28:24] <dragonpiper> piotr-mamenas: 
[2018-11-07 15:29:24] <ghost~5bc98094d73408ce4fabf741> you don't, you specify the path yourself by using the workspace@dragonpiper, if they come pre-installed in the image then yes you have to know the path like usr/share/nginx/html for the distribution folder of nginx
[2018-11-07 15:29:32] <ghost~5bc98094d73408ce4fabf741> dragonpiper: 
[2018-11-07 15:30:40] <dragonpiper> What about environmental variables the base image creates ?
[2018-11-07 15:32:04] <ghost~5bc98094d73408ce4fabf741> what do you mean by environmental variables?\\
[2018-11-07 15:32:58] <ghost~5bc98094d73408ce4fabf741> you mean the %PATH% variables to run from console in windows or something else?
[2018-11-07 15:33:50] <dragonpiper> Yea that as well and env  vairbales the base image exports . ex [<-CODE->] 
[2018-11-07 15:39:30] <ghost~5bc98094d73408ce4fabf741> that I don't know. You need  to google, but you should be able to set them the same way from the same file though
[2018-11-07 17:45:31] <JoshECarmoji> I have a few questions about Docker. Does anybody have some time to help me out?
[2018-11-07 18:14:46] <rcjsuen> Better to just ask the question
[2018-11-07 18:14:47] <rcjsuen> and see if someone can help
[2018-11-07 18:21:12] <JoshECarmoji> I have a few questions
[2018-11-07 18:21:40] <JoshECarmoji> I'm trying to set up a wordpress stack (Wordpress, mySQL, NGINX)
[2018-11-07 18:22:29] <JoshECarmoji> I'm wondering if I can define everything in one docker-compose.yml and deploy each service to their own server using docker hub
[2018-11-07 18:23:51] <rcjsuen> I\'m not sure I understand what you mean by "deploy each service to their own server using docker hub"
[2018-11-07 18:24:07] <rcjsuen> You push Docker images to Docker Hub. You don't deploy live services to Docker Hub.
[2018-11-07 18:24:45] <JoshECarmoji> Another question is how can I combine Dockerfile and docker-compose.yml so that I can set up each of my containers before deploying
[2018-11-07 18:25:19] <JoshECarmoji> Docker Hub deploys your image to a cloud server no?
[2018-11-07 18:25:42] <rcjsuen> Think of Docker Hub as something like a Dropbox
[2018-11-07 18:25:50] <rcjsuen> It stores images for other people to download
[2018-11-07 18:25:57] <JoshECarmoji> Maybe I'm thinking of docker cloud then
[2018-11-07 18:26:31] <rcjsuen> Possibly. I have never used Docker Cloud so I can't comment there.
[2018-11-07 18:26:47] <JoshECarmoji> Ok what about my second question?
[2018-11-07 18:27:31] <JoshECarmoji> Thanks for the help by the way
[2018-11-07 18:27:51] <rcjsuen> For your second question, it sounds like you should read some tutorials.
[2018-11-07 18:28:14] <rcjsuen>  [<-LINK->] 
[2018-11-07 18:29:24] <JoshECarmoji> Ok I'll try that thank you
[2018-11-08 10:07:28] <elcolie> piotr-mamenas: Thanks for your attention. I got the answer already.
[2018-11-08 16:08:29] <dragonpiper> dragonpiper: How do i stop knex from gettingER_NOT_SUPPORTED_AUTH_MODE?i have mysql configured to use the native password plugin--default-authentication-plugin=mysql_native_passwordis there something i'm missing  ?
[2018-11-09 11:49:10] <argeas> Hi all !
[2018-11-09 11:49:27] <argeas> anyone know how to get the size of each layer from an image ?
[2018-11-09 11:49:52] <argeas> say I have an image... and I want to know the exact size of each layer that compiles that image
[2018-11-09 18:04:54] <jmunson> I just cloned a disk that contained /var/lib/docker and attached it to another VM. I'm trying to have it join the same docker swarm that the node i copied it from is in, but it seems like there is some kind of id number that came with it, so when I bring up the new node it takes the same slot as the old worker..  does anyone know what I need to do to re-generate whatever id its using there?
[2018-11-09 18:06:42] <jmunson> argeas: I thinkdocker history $IMAGENAMEis what you want
[2018-11-09 18:10:55] <royswastik> Hi I trying to implement sticky session on dockers-swarm with traefik, but I could not achieve session persistence over two replicas on same machine.In my docker-compose.yml, I have added labels for traefik and added the loadbalancer as well. Am I missing anything?I have a PHP backend and taking about maintaining same PHP session variables across replicas
[2018-11-09 19:21:02] <jmunson> also nevermind, I fixed my issue by just re-installing docker without the volume mounted, and copying over everything it created on to the pre-existing volume
[2018-11-09 19:21:40] <jmunson> now I'm just struggling with trying to figure out why docker keeps shutting down my services and bringing new ones up despite no failing healthchecks or any indication of why it is doing it
[2018-11-09 19:23:32] <jmunson> I wish there was some kind ofdocker swarm statusthat could tell me what its trying to do and why. looking at the logs of the individual services doesn't tell me anything, they all seem fine up to the point that docker kills the service and tries to start another one
[2018-11-09 19:25:06] <jmunson> nor is there any indication why there are 12 replicas running of a service that is scaled to 8 replicas..  or why it would then complain about not enough resources when, you know, its wasting them all on replicas that it was never told to launch
[2018-11-10 16:39:55] <erwinheitzman> has anyone here ever ran sonatype/nexus on a docker container?
[2018-11-11 09:57:41] <SalathielGenese> Hi folks,I'm new to security stuffs, not that new to programming nor NodeJS and relatively beginner in docker and its compose correlate. I'm digging into NodeJS HTTP2 and have to go through SSH. What I want is to generate custom key/certificate and setup my containers to use those. I've reading articles here and there since Friday and constantly find new words, new approaches, and it is turning too much.What I Succeeded until nowUse custom key/cert to start my http2 serverWhat I need help forUse the key (or maybe cert - not sure which one) to query the server container.Some factsnode:carbon-alpineThanks in advance
[2018-11-12 18:35:08] <matrixbot> xcafebabeSalathiel Genèse Yimga Yimga (Gitter): read about traefik. Maybe start with this example [<-LINK->] Good luck.
[2018-11-12 21:35:18] <JoshECarmoji> How do you publish an image that was built in docker-compose
[2018-11-12 21:36:37] <JoshECarmoji> Im trying to deploy a swarm and it can't download the containers from the public repo because they're not tagged and uploaded I guess
[2018-11-12 21:37:01] <JoshECarmoji> I\'m getting "no suck image:" on my nodes
[2018-11-12 21:39:07] <SalathielGenese> Hi @matrixbotIt is not exactly what I expected but thanks for your endeavour.
[2018-11-13 12:26:07] <salamsoliman> ?
[2018-11-13 12:29:08] <rcjsuen> JoshECarmoji: Sounds like you should push them then
[2018-11-13 13:58:32] <SalathielGenese> Hi folks,Anyone knows which way to go for emulating Firebase in Datastore mode for NodeJS API ?
[2018-11-13 14:17:04] <JoshECarmoji> rcjsuen: haha yup. docker-compose push was the answer!
[2018-11-13 14:17:23] <JoshECarmoji> Anybody here use Docker for an Nginx + Wordpress stack?
[2018-11-13 14:35:32] <SalathielGenese> PREVIOUSLYAnyone knows which way to go for emulating Firebase in Datastore mode for NodeJS API ?CURRENTLYIt is kinda mess and often misleading - Cloud functions, Firebase, Firestore, Datastore, etc...What I want is emulating firestore, if that it possible at all
[2018-11-13 15:46:48] <JoshECarmoji> Is Docker Cloud unable to add Service Providers?
[2018-11-13 15:47:23] <JoshECarmoji> I sign in, Go to Account Settings, Click the Service providers tab and nothing happens?
[2018-11-13 15:47:32] <JoshECarmoji> I'm trying to deploy to AWS
[2018-11-13 15:51:12] <JoshECarmoji> This instruction in the documentation doesn't work [<-LINK->] 
[2018-11-13 17:14:09] <briancaffey> Quick question. I have 2,000 Excel files that I need to access from one of my containers. I'll put them inside of a folder calledbackend/datathat is used to build my REST API service using Django. In my Dockerfile i doADD . /code/, which would add all of the files to the image, which I don't want. Should I put a.dockerignorefile in the data folder and ignore everything in the folder? I would then do- ./backend/data:/code/backend/datain my docker compose file. Does this make sense? Is there a better way?
[2018-11-13 17:26:25] <SalathielGenese> Do you start you containers with compose ? (docker-compose)
[2018-11-13 17:27:03] <briancaffey> yes@SalathielGenese
[2018-11-13 17:27:37] <SalathielGenese> Then, you may not need to do it from Dockerfile
[2018-11-13 17:28:05] <SalathielGenese> In your dokcer-compose.yaml file, mount it as volume
[2018-11-13 17:29:29] <SalathielGenese>  [<-CODE->] 
[2018-11-13 17:29:32] <briancaffey> OK, that's what I'm thinking. I'm just not sure what will be sent to the docker daemon in compose when specifying a volume.
[2018-11-13 17:30:14] <briancaffey> OK, yes that's what I have in my docker compose file. So this will not send./backend/datato the docker daemon, is that correct?@SalathielGenese
[2018-11-13 17:31:15] <SalathielGenese> The general practice for Dockerfile is to copy only mandatory file you have -Everything else is customized and thus, provided when the container starts
[2018-11-13 17:33:43] <briancaffey> Right, but I have lots of data files that are nested inside of a mandatory folder. In this case I would think using a.dockerignorefile would be appropriate. I'm wondering if the.dockerignorefile would interfere with folders I'm trying to mount in a volume. I guess I should try it out
[2018-11-13 17:47:57] <SalathielGenese> When I said mandatory, I specifically meant anything the image consumer cannot provide at runtime.
[2018-11-13 17:48:01] <SalathielGenese> But...
[2018-11-13 17:53:30] <SalathielGenese> Let's say you have [<-CODE->]  [<-CODE->] 
[2018-11-13 17:53:37] <briancaffey> OK,
[2018-11-13 17:55:31] <SalathielGenese> Still in docker-compose.yaml [<-CODE->] 
[2018-11-13 17:56:55] <briancaffey> OK, interesting. I have seen this pattern in other places. I'll try it. Thank you for your advice
[2018-11-13 17:57:00] <SalathielGenese> This way you\'re turning/code/b/and/code/c"persistent", i.e available only within the container
[2018-11-13 17:58:05] <SalathielGenese> Dockercompose will actually create an empty folder in that container
[2018-11-13 17:58:45] <SalathielGenese> And your HOST inodes./band./cwill be excluded from mounting
[2018-11-13 17:59:42] <briancaffey> So the order does matter when specifying volumes in compose?
[2018-11-13 18:01:09] <rcjsuen> No
[2018-11-13 18:01:26] <rcjsuen> or wait, I misread your question
[2018-11-13 18:03:01] <SalathielGenese> briancaffey: - The order matters - peristent folders first
[2018-11-13 18:03:13] <briancaffey> OK, thanks for clarifying
[2018-11-13 18:04:22] <SalathielGenese> As you may have noticed, unlike other volume definition,${ host_path }:${ container_path }, persistent folders are just${ container_path }
[2018-11-13 18:05:20] <SalathielGenese> and when I say the order matters, I just meanthe persistent endpoint MUST be defined BEFORE the volume that may use that path
[2018-11-13 18:05:26] <briancaffey> Right, that has been confusing for me, but I think I see how it works when there is only one "term" in the volume declaration
[2018-11-13 18:16:04] <JoshECarmoji> Anybody here available for some Docker consulting?
[2018-11-13 18:16:54] <nafg> JoshECarmoji: what sort?
[2018-11-13 20:38:01] <JoshECarmoji> nafg: I want to create a deployment pipeline for a Nginx, Wordpress, MySQL stack
[2018-11-13 22:20:11] <nafg> JoshECarmoji: I could probably afford to give about a half hour, if that's worth anything
[2018-11-13 22:20:29] <nafg> if it's today
[2018-11-14 04:35:20] <JoshECarmoji> nafg: 30 mins would be amazing! Can we do anything tomorrow?
[2018-11-14 04:38:49] <nafg> JoshECarmoji: ok, let's be in touch. Around 3 est is usually good but earlier might also work
[2018-11-14 05:43:17] <JoshECarmoji> Thank you so much!
[2018-11-14 05:45:02] <nafg> JoshECarmoji: can you DM me an outline of what you want to achieve
[2018-11-14 06:46:42] <JoshECarmoji> absolutely
[2018-11-14 08:56:11] <sysdevopsCC> hi all
[2018-11-14 08:58:13] <sysdevopsCC> Am facing an issue when i try to connect DB container and app container am getting the error "Unhandled rejection SequelizeHostNotReachableError" can anyone help?
[2018-11-14 09:15:37] <matrixbot> xcafebabeSysDevops (Gitter): either your app container runs before your db container  or your db hostname in your app container is wrong
[2018-11-14 15:55:26] <thestift> Hi AllI am facing a problem: I want to start a script with CMD ["sh","startApp.sh"]. But the problem is that all environment variables are not available in the script.If I start my program directly via CMD they are present. Are this a known problem? Thank you!
[2018-11-14 16:24:38] <SalathielGenese> thestift: - It is a desired behaviour
[2018-11-14 16:25:02] <SalathielGenese> You may consider reading this article that explains the how-to- [<-LINK->] 
[2018-11-14 16:42:36] <thestift> SalathielGenese: thanks I will read it
[2018-11-14 21:54:59] <barpr01_twitter> i have entrypoint instructino executing pgbench exe..which asks for a password prompt
[2018-11-14 21:55:15] <barpr01_twitter> how to i pass this value?
[2018-11-15 08:50:58] <thestift> ok know the reason: I use environment env variables with dot (for spring boot) . These are only allowed with underscore in sh environment
[2018-11-15 12:05:29] <SalathielGenese> thestift: If I do remember well, Spring have init vars inside a .property or alike fileYou can still read that file from your shell script and extract just the value you wantTake a look at - [<-LINK->] 
[2018-11-15 22:42:06] <3lpsy_twitter> Greetings. Is there an easy way to allow inbound connections to docker container but block outbound connections?
[2018-11-15 22:42:15] <3lpsy_twitter> I'm using docker-compose. For the webapp, I used a proxy container that has two interfaces, one for a public docker bridge network, the other for an internal docker bridge network. But I don't want to the same for the other network services.
[2018-11-15 22:43:35] <3lpsy_twitter> I could setup a squid proxy container in the same fashion, but I was hoping their was an easier way. I tried setting iptables rules on the host, but docker doesn't respect host rules unless you use a host adapter (i think?). And I do not want to use a host adapter.
[2018-11-16 11:09:00] <gaelSy> HI guys. There is a thing I don't understand with docker and docker-compose. I Have a server and I can deploy an application with docker-compose for two containers : app and db
[2018-11-16 11:09:56] <gaelSy> Now I want to use this server to deploy an other application with an other docker-compose file for two containers webapp and db2
[2018-11-16 11:14:58] <gaelSy> But when I use these two docker-compose files with traefik it doesn't work
[2018-11-16 11:15:19] <gaelSy> to make it work I have to put all the 4 containers into a single docker-compose file
[2018-11-16 11:16:13] <gaelSy> somebody has an idea ?
[2018-11-17 04:09:10] <royswastik> I haven't done this. But, did you try mapping port 80 of your internal network to some other network for the second app?
[2018-11-17 04:09:14] <royswastik> gaelSy: 
[2018-11-17 04:10:55] <royswastik> I was wondering if someone knows any opensource & simpler tool than promestheus, grafana to monitor services/containers/nodes in docker swarm?
[2018-11-17 06:11:39] <sysdevopsCC> Hi guys
[2018-11-17 06:12:08] <sysdevopsCC> here i want to edit one existing docker image in docker hub
[2018-11-17 06:13:25] <sysdevopsCC> after editing the docker image how can i push that image to docker hub
[2018-11-17 11:55:23] <rcjsuen> I'm not sure I understand your question.
[2018-11-17 11:55:34] <rcjsuen> Is this your own repository on Docker Hub?
[2018-11-17 11:55:54] <rcjsuen> You can't just randomly edit and push a Docker image to Docker Hub.
[2018-11-17 12:48:36] <Jacob_Bogers_twitter> hi
[2018-11-17 12:48:58] <Jacob_Bogers_twitter> docker refuses to bind my windows dir to a  container dir
[2018-11-17 12:49:16] <Jacob_Bogers_twitter> strange thing i needed to set some environment parameter
[2018-11-17 12:49:28] <Jacob_Bogers_twitter> i cant find ongoogle what that was
[2018-11-17 12:57:29] <Jacob_Bogers_twitter> this is dumb shit
[2018-11-17 12:57:31] <Jacob_Bogers_twitter> COMPOSE_CONVERT_WINDOWS_PATHS=1
[2018-11-17 12:57:37] <Jacob_Bogers_twitter> can someone put thisin the docs
[2018-11-17 12:57:53] <Jacob_Bogers_twitter> its stupid if it is not in the docs in the "volumes" section
[2018-11-17 13:00:28] <Jacob_Bogers_twitter> yup that did the trick
[2018-11-19 09:01:34] <chandru1989_gitlab> Hi All
[2018-11-19 09:03:06] <chandru1989_gitlab> I tried to change permission of sys as rw with sudo but it gives permossion denied ..How to change sys/ as reas and write permissn in docker container
[2018-11-19 09:03:22] <chandru1989_gitlab> root@704977de690f:/# sudo mount -o ro,remount /sys/mount: permission denied
[2018-11-19 09:03:32] <chandru1989_gitlab> root@704977de690f:/# cat /proc/mounts | grep syssysfs /sys sysfs ro,nosuid,nodev,noexec,relatime 0 0
[2018-11-20 08:39:50] <chandru1989_gitlab> how to stary container in rw mode
[2018-11-20 16:11:23] <Egahras> i have a vps. running docker. started e.g. the wordpress:latest on it. Volumes ./html to the container html dir.The user i used to start the container is not allowed to change files within this dir. Due to the fact it belongs "www-data" now.How should i use this exactly? I want to use phpstorm on my local machine to work via sftp on the vps (changing files in the container volume.)
[2018-11-20 16:12:07] <bbbenji> evening
[2018-11-20 16:12:16] <bbbenji> im experiencing a problem when installing the docker image: [<-LINK->] after i run the docker command to get the image, something happens, idk what, and i cant do anything, just errors. if leave ssh and try to login again i keep getting auth denied errorsi have to physically restart my server to regain controlsometimes it actually start downloading the image, sometimes it does not, as in the log. I can install other containers no problem, such as portaineranyone can point me to a solution?
[2018-11-20 16:16:13] <bbbenji> Egahras: why not add the user to the www-data group?
[2018-11-20 16:16:33] <Egahras> i did but still cant edit files in there...
[2018-11-20 16:17:09] <Egahras> and i chmod 775 the whole folder to make sure www-data group is able to write...
[2018-11-20 16:17:12] <bbbenji> what are the file permissions? perhaps you dont have group write
[2018-11-20 16:17:17] <bbbenji> ok :)
[2018-11-20 16:17:21] <Egahras> :p
[2018-11-20 16:17:56] <bbbenji> sudo chmod -R g+w /srv/www
[2018-11-20 16:18:05] <bbbenji> or whatever dir
[2018-11-20 16:19:09] <Egahras> duh.... i found my mistake
[2018-11-20 16:19:37] <Egahras> i changed the permissions inside the folder html/* .... but not the permissions of the folder itseld...
[2018-11-20 16:19:55] <Egahras> itself*
[2018-11-20 20:54:43] <chandru1989_gitlab> Hi everyoneI just copied image from one PC as tar file and loaded it as image in my PCThen I started container in privileged modelivirt is not running ..libvirt*Anyidea why libvirt is not running in privileged moderoot@chandru-OptiPlex-790:/home/chandru# docker run -it --privileged c3470860d469 bash [<-CODE->] libvirt.pid and libvirt.sock is not created_
[2018-11-20 20:55:18] <chandru1989_gitlab> Please help me with solution
[2018-11-21 12:35:52] <JonnyPtn> Using docker on windows with windows containers, I'm wondering if there's a way to make the containers use all available CPUs by default?
[2018-11-21 12:36:07] <JonnyPtn> Currently I have to pass the --cpu-count otherwise it only uses one core
[2018-11-21 15:40:54] <ArnCarveris> Hi all
[2018-11-21 15:41:27] <ArnCarveris> I have problem with accessing intranet from container
[2018-11-21 15:42:00] <ArnCarveris> But have no problems accessing extranet from container
[2018-11-21 15:42:43] <ArnCarveris> In host machine I can access intranet successfully
[2018-11-21 15:43:11] <ArnCarveris> Any ideas how to debug & fix this?
[2018-11-22 10:04:58] <MattLongCode> It is probably to do with the proxy settings
[2018-11-22 10:05:24] <MattLongCode> Do you have access to the proxy settings on the host machine? And can the docker container access those proxy settings>
[2018-11-22 10:05:26] <MattLongCode> ?*
[2018-11-22 10:19:49] <ArnCarveris> Any cmd to check this?
[2018-11-23 05:15:46] <royswastik> Hi,I am setting the DO_AUTH_TOKEN for let's encrypt in docker-compose file. But, storing it in version control does not seem like a good idea. Can anyone tell me what could be a better way to pass that?
[2018-11-23 07:39:46] <mateothegreat> royswastik: as an environment variablre
[2018-11-23 08:00:35] <royswastik> Does that sound safe to have secrets as environment variable? [<-LINK->] This blogs sums up few reasons not to use environment variables.
[2018-11-23 16:04:11] <tbugfinder> I might have to setup a multiuser environment incl. mapped shared NFS storage. Which options do I have to limit "root" access while providing docker to users?
[2018-11-24 14:46:37] <Phinneas> Is advertizing allowed in this channel. Seems someone is using it to promote Udemy and thought this was for questions only
[2018-11-25 12:09:58] <thymbahutymba> I'm tring to execute pthread application into docker container that fail if i try to change scheduler. The code that i'm tring to fix is this: [<-LINK->] . This code works in virtual machine, could it works in docker container?
[2018-11-25 12:10:31] <thymbahutymba> the problem is the explicit scheduler (that i need) if i run it without explicit scheduler it works fine
[2018-11-26 01:26:14] <dancruznyc> trying to install  on mac I bought in 2015... Im getting a circle with a strikethrough over the logo
[2018-11-26 12:33:09] <rapitkan> Hi all! I’m trying to access a url of another container (workspace) from another container (pdf_center). This is the code: [<-CODE->] The code is not working. Photos are not fetched. Could you say what is wrong?
[2018-11-26 12:35:02] <rapitkan> If I use the line that is commended out the code is working. But I can’t point to the local machine.
[2018-11-26 13:45:42] <rapitkan> I resolved the problem by usingnginxin the url:http://nginx/storage/${url}.
[2018-11-26 17:05:23] <keithh_gitlab> Hi,  I'm sure this issue has already been asked countless times, but could anyone steer me in the right direction for a docker-compose config for a mysql service that runs on a different host to a web container?  Previously I had a similar configuration but was using 'ambassador' images, but I've since found out that they're now obsolete.My oldcomposefile is along these lines: [<-CODE->] 
[2018-11-26 21:53:35] <mateothegreat> keithh_gitlab: just point your app to your mysql.instance.com .. don’t use docker links for non-docker-compos’ed containers
[2018-11-27 09:10:17] <keithh_gitlab> mateothegreat: thanks for that.  That will save lots of hassle.  Final obstacle is the rabbitmq.  Getting connection refused.  Not sure if this is aws security group-related or config-related.
[2018-11-27 10:39:00] <narendramannam> Docker compose 1.23 onwards adding new hash at the end of container_name, is there a way to disable this behaviour?
[2018-11-27 16:51:04] <thymbahutymba> How i can solve this error: C:\\Program Files\\Docker\\Docker\\Resources\\bin\\docker.exe: Error response from daemon: OCI runtime create failed: container_linux.go:348: starting container process caused "process_linux.go:279: applying cgroup configuration for process caused \\"failed to write 820000 to cpu.rt_runtime_us: write /sys/fs/cgroup/cpu/docker/25916f72b9772cec6be646f400e4744ef835a6b990e77e50dd467662ce19a808/cpu.rt_runtime_us: invalid argument\\"": unknown. ????
[2018-11-28 18:31:44] <amrit3701> Hello devs, I am trying to build my docker but due to some error it stuck atStep 22. Is there any way that I openbashshell of docker container before runningStep 22?
[2018-11-28 19:30:20] <marcguilera> is docker a good thing to set up a dev environment? i use dart and java mainly and it would be nice to be able to have some dockerfiles to run and get a consistent devenv everywhere. is docker good for this? (newebe)
[2018-11-28 20:22:41] <davidmichaelkarr> marcguilera: yes, this is a common strategy. docker is used for much more than production environments.
[2018-11-29 00:55:20] <dragonpiper> when using extend how do i stop the child services from exposing ports from the parent service ?
[2018-11-29 08:10:29] <timrosede> good morning!
[2018-11-29 08:36:52] <meliboo> amrit3701: can you please share the url of the article you are using?
[2018-11-29 15:39:54] <marcguilera> davidmichaelkarr: any good tutorials? i know there are a ton out there but..
[2018-11-29 21:10:12] <revisualize> Greetings friends, I need a good bit of help. I recently had a recruiter reach out to me about an amazing opportunity with a company here in Seattle. The staffing agency recruiter is asking me to come up with a project to showcase some "DevOps" tools knowledge by the weekend. However, I\'m a bit stuck. I\'ve been a traditional mid-sr Network Systems Administrator working mostly on in-house IT projects and doing a bit of automation. (It\'s sad because working on in-house IT projects automation isn\'t always pushed for one-off projects or issues.) Because I\'ve worked in Windows server environments, I\'ve used quite a bit of PowerShell. I also have a good bit of Linux knowledge and I could easily be a jr-mid Linux systems admin in a more Windows environment. (And I feel that\'s what they\'re looking for.)However, this staffing agency recruiter really wants to submit my resume with a simple example project to showcase with my application.I\'m stuck as to what to do here and how to showcase myself with a project to push my application forward.The job description states that they\'d like someone with a familiarity using automated deployment tools such as Jenkins, Chef, Ansible, or equivalent and scripting knowledge with PowerShell or Python and of course Docker knowledge.I have the PowerShell experience. I\'ve worked through the Microsoft Virtual Academy courses on PowerShell. I\'ve even written several scripts and automated several processes with PowerShell. I can easily talk about my PoSh projects.I\'m hoping to get a good project put together that I can use to showcase a basic familiarity with this whole \'DevOps\' toolchain. Any recommendations are greatly appreciated.
[2018-11-30 01:51:36] <mitchcapper> revisualize: why not a powershell script that automatically deploys an azure machine sets up docker then spins up some docker deployment on that machine a custom build or something using powershell to control and monitor the progress of the containers.
[2018-11-30 03:37:06] <btrepp> is there a way to configure docker pull to ignore certificate errors?
[2018-11-30 03:37:46] <btrepp> all the environment variables talk about turning TLS on, it seems to already be on. I would like to disable the TLS verification in my dev/test/vm environment
[2018-11-30 16:12:20] <dragonpiper> If i want to change the command of a container started from docker-compose, do i have to do a down and up ?
[2018-12-03 02:24:36] <royswastik> Hi,  is it normal to use a mounted volume for MySQL database in production?
[2018-12-03 02:41:16] <davidmichaelkarr> royswastik: it really depends on what the db is used for. if the db contents need to be preserved, then it's likely.
[2018-12-03 02:47:41] <royswastik> davidmichaelkarr: ...the DB content needs to be preserved. My concern is mainly because I see people saying not to use 'volumes' in production. Not sure if this is true or if it makes the application slower.
[2018-12-03 02:49:46] <davidmichaelkarr> royswastik: no idea what is meant by that.
[2018-12-03 02:51:30] <royswastik> Thanks. I think I got the answer. I will probably use volumes to persist the data.
[2018-12-03 02:55:31] <royswastik> I had just one more quick question. I am using a private container registry from a cloud provider, and I do not want to push the production image containing DB credentials to the registry. What is the standard way to pass the credentials to the production image?Is it using environment variables passed through docker-compose file and access env vars from application,or, using docker-entrypoint.sh to set those files with credentials inside the container?I am sorry if it's a noob question.
[2018-12-03 12:06:36] <rcjsuen> We use secrets in Kubernetes and then they get injected as environment variables
[2018-12-03 16:44:21] <gujri> Hi is there any one works with cloud ?
[2018-12-03 16:44:32] <rcjsuen> That's a very open ended question
[2018-12-03 16:45:07] <gujri> i need any one try this code pattern does it works or not
[2018-12-03 16:45:11] <gujri>  [<-LINK->] 
[2018-12-03 16:45:21] <gujri> it seems that it gets me many issues
[2018-12-03 17:21:06] <royswastik> Using docker secrets for database.php file in my Codigniter application, which contains DB credentials... Is this a standard thing?
[2018-12-03 17:23:46] <royswastik> rcjsuen: Hi, how do you inject a secret as environment variable? One way I can think of is to use docker-entrypoint.sh to read the secret files and set it as environment variable. Although, I would consider having the [<-LINK->] containing the cred safer instead of environment variable.
[2018-12-03 17:24:40] <rcjsuen> Well, we use Kubernetes
[2018-12-03 17:25:00] <rcjsuen>  [<-LINK->] 
[2018-12-03 17:25:58] <rcjsuen>  [<-CODE->] 
[2018-12-03 17:27:50] <royswastik> Oh got it. I am actually using it with swarm. I just got the idea of copying the secret as DB config file to target application folder. But, not sure if that is a standard way or if there is a better/simpler alternative.
[2018-12-03 17:32:08] <royswastik> and thanks@rcjsuen
[2018-12-03 17:47:28] <RobertKielty> royswastik: Have you checked [<-LINK->] ?
[2018-12-03 17:58:58] <royswastik> RobertKielty: Hi Robert,, yes.. I know how to do it.. I was wondering if  that is a standard way of managing db config files
[2018-12-03 17:59:34] <royswastik> Or if there are better alternatives
[2018-12-03 19:51:23] <royswastik> To make my question simpler, here is an easy explanation -"PHP frameworks like Codigniter read DB credentials from files like database.php", \n"The DB credentials for production can not be stored in container registry or version control", \n"So, there needs to be a way to pass the credential files(like database.php) when a service is started"My question is what is the correct way to do it?
[2018-12-04 07:47:28] <Genysys> Hi All, [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] Here is a copy of the package.json file copied to this folder: [<-CODE->] Unfortunately, I keep getting this error: [<-CODE->] I would be deeply appreciative of any pointers on this
[2018-12-04 08:09:59] <babaorum> I do not see where your installing your project dependencies
[2018-12-04 08:10:56] <babaorum> Your installing truffle. But I do not see an npm i on /usr/src/app/backend
[2018-12-04 12:30:05] <bilak> Hello,this is my docker-compose: [<-CODE->]  [<-CODE->]  [<-CODE->] Is there way how to disable pulling the latest image? Or do I have something missconfigured? [<-CODE->] Thanks
[2018-12-04 12:37:39] <bilak> Hmm, I've upgraded to compose1.23.1and it's working
[2018-12-04 14:43:41] <marcinmaruszewski> Hey is there any k8s channel on gitter or we can talk here? I have an error installing Prometheus using helm provided by GitLab on my kubeadm cluster.Error: error validating "": error validating data: field spec.dataSource for v1.PersistentVolumeClaimSpec is requiredCan you help me with it?
[2018-12-04 15:05:46] <rcjsuen> There's a Kubernetes slack channel [<-LINK->] 
[2018-12-04 15:06:12] <marcinmaruszewski> Ok, thanks@rcjsuen!
[2018-12-05 13:34:06] <abhisek1318> Hey guys how do I create a file outside the conatiners and use that file inside a container?
[2018-12-05 13:35:21] <abhisek1318> I want to create directory for a db which should lie outside the container since I want to persist it and use it inside my node container as volumes maybe?
[2018-12-05 15:21:44] <dragonpiper> how do i escape double quotes in docker file ?
[2018-12-05 15:22:18] <dragonpiper> trying to set command tobash -c "/usr/sbin/sshd -D -e "$@" -p 1025"
[2018-12-05 15:22:55] <pjetr> \\should do the trick
[2018-12-05 15:23:04] <ZelphirKaltstahl> And normal escaping using backslash does not work?
[2018-12-05 15:24:23] <dragonpiper> No, it says. [<-CODE->] 
[2018-12-05 15:25:27] <pjetr> you could try single-quotes...
[2018-12-05 15:25:52] <zukamedia> escape the $ symbol
[2018-12-05 15:26:04] <zukamedia> dragonpiper: ^^
[2018-12-05 15:26:38] <zukamedia>  [<-LINK->] 
[2018-12-05 15:27:29] <dragonpiper> ah x.x
[2018-12-05 15:27:42] <zukamedia> yw
[2018-12-05 15:27:59] <dragonpiper> forgot interpolation overides everything
[2018-12-05 20:46:43] <royswastik> abhisek1318: Do you want to create a new file from within the container?
[2018-12-05 20:47:23] <royswastik> If you just bind volume the entire directory, it should work
[2018-12-06 01:09:46] <joeyfigaro> Hey guys
[2018-12-06 01:10:52] <joeyfigaro> I have a container running on machine A that exposes a handful of ports (3001, 3002, 3003, ..., 3009) and am accessing my app on machine B viahttp://machine_A_ip:3000in my browser
[2018-12-06 01:11:02] <joeyfigaro> all of the requests to our apis are hittinglocalhost:300x
[2018-12-06 01:11:14] <joeyfigaro> And are failing/timing out
[2018-12-06 01:11:42] <joeyfigaro> What am I missing here? Is machine B attempting to hit port300xon itself to resolve the request?
[2018-12-06 04:23:03] <RobertKielty> joeyfigaro: when you start the container you need to publish the EXPOSED ports to the docker host with -p . You could use p option
[2018-12-06 04:23:11] <RobertKielty> apols
[2018-12-06 04:23:26] <RobertKielty> on phone
[2018-12-06 04:23:45] <RobertKielty> -p 3000:3000
[2018-12-06 04:23:58] <RobertKielty> should sort you out.
[2018-12-06 15:36:23] <phiter> hello
[2018-12-06 15:37:21] <phiter> I'm having a small issue with docker. I made a container that has a mounted volume, and this container creates files. The files it creates are not editable  from the host because they have a read-only status. How do I make it so the files created can be changed from the host?
[2018-12-06 16:01:08] <joeyfigaro> RobertKielty: thanks! I should've mentioned that weareexposing the ports currently—I ended up changing the urls in the app fromlocalhostto the machine ip and it worked. Not a longterm solution, but yeah.
[2018-12-06 16:01:23] <joeyfigaro> Accessing the app on a different machine makes those calls to localhost hit the visiting machine
[2018-12-07 22:11:59] <ghost~5bc98094d73408ce4fabf741> Sup
[2018-12-07 22:12:12] <ghost~5bc98094d73408ce4fabf741> I have a very simple container like so:
[2018-12-07 22:12:34] <ghost~5bc98094d73408ce4fabf741>  [<-CODE->] 
[2018-12-07 22:12:53] <ghost~5bc98094d73408ce4fabf741> simple react app pretty much
[2018-12-07 22:13:14] <ghost~5bc98094d73408ce4fabf741> when I try running docker-compose up with this dockerfile I get:
[2018-12-07 22:13:47] <ghost~5bc98094d73408ce4fabf741> Can't resolve 'react-router-dom' in docker compose /usr/app/src/components
[2018-12-07 22:14:05] <ghost~5bc98094d73408ce4fabf741> which is pointing to one of the components which imports react-router-dom
[2018-12-07 22:15:09] <ghost~5bc98094d73408ce4fabf741> if I npm start the app it runs oke, I have volumes pointing to node_modules
[2018-12-07 22:15:39] <ghost~5bc98094d73408ce4fabf741> all the other packages don't throw
[2018-12-08 01:07:32] <nirtal85> how can i specify a link to an existing docker on port 4444 on my localhost inside a dockerfile?
[2018-12-08 13:59:58] <mateothegreat> piotr-mamenas: npm install -S react-router-domlocally first so you get it added to yourpackage.json.. has nothing to do with docker
[2018-12-08 14:00:41] <mateothegreat> nirtal85: you can’t “link” things in aDockerfile.. networking related configuration is done primarily at thedocker-compose/swarm levels
[2018-12-08 14:07:35] <ghost~5bc98094d73408ce4fabf741> mateothegreat: >.> I did not mention it because I thought its pretty obvious... but yes I do have it installed lol
[2018-12-08 14:08:30] <mateothegreat> piotr-mamenas: heh .. did youdocker exec -it <continer name> sh.. and cd into/usr/app/src/components.. then see if the import path is proper?
[2018-12-08 14:09:11] <mateothegreat> I’m guessing this package is installed globally locally perhaps
[2018-12-08 14:17:36] <ghost~5bc98094d73408ce4fabf741> --save always for packages which should be copied with webpack to static folder, the path is not proper and I don't need to check it because I have it clearly stated in the error, the question is why is npm trying to look for this packages in the src folder instead of node_modules, when I npm run start manually it works just fine, it fails only on docker-compose up
[2018-12-08 15:01:51] <mateothegreat> piotr-mamenas: maybe a dumb question.. but shouldnode_modulesbe under/usr/appor/usr/app/src?
[2018-12-08 15:02:09] <mateothegreat> also, if you a public repo shoot me the link and I’ll help go down the rabbit hole with ya :D
[2018-12-08 15:03:59] <ghost~5bc98094d73408ce4fabf741> they are not xD@mateothegreatthats the thing
[2018-12-08 15:04:17] <ghost~5bc98094d73408ce4fabf741>  [<-LINK->] 
[2018-12-08 15:07:54] <mateothegreat>  [<-CODE->] … the last line is going tooverwrite/usr/appheh
[2018-12-08 15:09:12] <ghost~5bc98094d73408ce4fabf741> to me it was to map the local client folder to /usr/app inside of the container
[2018-12-08 15:09:27] <ghost~5bc98094d73408ce4fabf741> and inside of the client you have node_modules which should also be copied
[2018-12-08 15:09:41] <ghost~5bc98094d73408ce4fabf741> i.e not copied but referenced
[2018-12-08 15:11:17] <ghost~5bc98094d73408ce4fabf741> I removed the line but I get exactly the same error@mateothegreat
[2018-12-08 15:12:35] <mateothegreat> I would never copynode_modulesinto a docker container .. you’re going to definitely run into weird issues .. unless your host OS is alpine linux too
[2018-12-08 15:12:45] <mateothegreat> piotr-mamenas: pulling your code down now .. standby
[2018-12-08 15:14:32] <ghost~5bc98094d73408ce4fabf741> alpine linux it is :), it was just considered as an optimization not to have to redownload into container on every npm install
[2018-12-08 15:16:34] <mateothegreat>  [<-LINK->] 
[2018-12-08 15:16:44] <mateothegreat> You have some serious package.json issues :P
[2018-12-08 15:17:13] <mateothegreat> you should always install/maintain your npm packages in your local working directory rather than globally … if you want repeatable build processes
[2018-12-08 15:19:44] <ghost~5bc98094d73408ce4fabf741> could you please pull in the code again, i had slight modifications so i might be seeing something completely else
[2018-12-08 15:19:53] <ghost~5bc98094d73408ce4fabf741> i just threw a commit
[2018-12-08 15:21:44] <ghost~5bc98094d73408ce4fabf741> the package json is just whats created from create-react-app with some npm installs on top of it. I don't understand what you mean by globally? there are 2 apps, 2 dockerfiles and 2 package.json running under 1 compose
[2018-12-08 15:25:46] <mateothegreat> use this to start your server:
[2018-12-08 15:25:52] <mateothegreat>  [<-CODE->] 
[2018-12-08 15:26:17] <mateothegreat> yourpackage.jsonis trying to runreact-scripts ..as if it is a globally installed program
[2018-12-08 15:26:49] <mateothegreat> npxwill run the locally installed executable in the localnode_modulesdirectory
[2018-12-08 15:28:55] <ghost~5bc98094d73408ce4fabf741> so what you are saying is that i should replace my start/build scripts in package.json with "npx react-scripts start" instead of currently just "react-scripts start"?
[2018-12-08 15:29:27] <ghost~5bc98094d73408ce4fabf741> shouldn't npm-install on the react packages add the relevant env variables on linux?
[2018-12-08 15:29:36] <ghost~5bc98094d73408ce4fabf741> lemme check if that do the trick
[2018-12-08 15:32:23] <ghost~5bc98094d73408ce4fabf741> yeah, it seems that's it. Kind thanks for assisting ;)@mateothegreat
[2018-12-08 15:36:08] <ghost~5bc98094d73408ce4fabf741> Isn't it morning in the US?
[2018-12-08 15:36:49] <mateothegreat> 10:30am @ NY
[2018-12-08 15:37:04] <ghost~5bc98094d73408ce4fabf741> ye, 4:30pm @ Zurich
[2018-12-08 15:37:04] <mateothegreat> np .. glad you got it sorted
[2018-12-08 15:37:20] <mateothegreat> pulled an all-nighter.. it’s all a blur anyway :D
[2018-12-08 15:38:30] <ghost~5bc98094d73408ce4fabf741> I do the same pretty much every Friday ; p so I understand : D
[2018-12-08 15:38:37] <hspaans> One question. Why do you use/usr/app?
[2018-12-08 15:40:25] <ghost~5bc98094d73408ce4fabf741> Why not? This way I have a smaller chance of having file conflicts with any of the folders coming by default with the alpine node linux image
[2018-12-08 15:41:54] <hspaans> Just try to find the reasoning (there is no good or bad). For me as an old school Unix dude it looks weird ;-)
[2018-12-08 15:44:28] <ghost~5bc98094d73408ce4fabf741> Depends on the setup, the containers are pretty lightweight and do not have all the kernel logic on the filestore so it doesn't matter that much where you place the app in the container, unless of course it needs to go into some concrete folder like the nginx/iis/whatever publish folder and its a standard
[2018-12-08 15:44:36] <ghost~5bc98094d73408ce4fabf741> but in this case it doesn't really matter that much
[2018-12-08 16:47:56] <MRDO5> Hi all! Have anyone use openshift origin ?
[2018-12-09 11:52:16] <karneaud> hello
[2018-12-09 11:52:24] <karneaud> i have used open shift
[2018-12-09 11:52:37] <karneaud> but not specifically the origin
[2018-12-09 11:52:47] <karneaud> I'm trying to run a container with a domain name that can be accessed from other computers in my network how can I do this?
[2018-12-09 11:59:31] <mateothegreat> karneaud: Setup the DNS to point your domain name to the external IP address that the docker service is running on.
[2018-12-09 13:25:31] <karneaud> mateothegreat: not that knowledgable with understanding how to set this up. I was trying to use the dns-proxy-server but does not seem to work.....
[2018-12-09 13:27:23] <mateothegreat> Well if you don’t have a DNS server to resolve your domain name to an ip address you’re going to have to edit thehostsfile on each machine and manually define that host —> ip maps to what
[2018-12-09 14:29:04] <karneaud> well this is what I'm doing with dns-proxy-server@mateothegreatI'm spinning up a docker based instance and using that to automatically add dynamic containers to it
[2018-12-09 14:29:18] <karneaud> not sure why it still wasn't working
[2018-12-09 14:29:25] <karneaud> i can access the container fine
[2018-12-09 14:29:28] <karneaud> via ip
[2018-12-09 14:29:35] <karneaud> but not domain name
[2018-12-09 23:58:10] <karneaud>  [<-LINK->] 
[2018-12-10 16:27:01] <ahmehri> HelloIs there any way to copy only all of the package.json files illustrated in the following structure using theCOPYcommand and keep the same structure in the image? [<-CODE->] 
[2018-12-10 17:23:00] <rcjsuen> I don't think so because you're forced to specify one directory. You'd have to use multipleCOPYcommands
[2018-12-10 17:35:17] <ahmehri> This instructionCOPY ["projects/*/package.json", "./"]will result in having at the end inside the image onlyprojects/project2/package.jsonfile. This is because all the files have been copied but they override each other, so the last one wins. Any idea how to solve this?
[2018-12-10 17:58:27] <kbeaugrand> Hi guys, I've got some troubles with iptables and docker
[2018-12-10 17:58:35] <kbeaugrand> could someone help me with it ?
[2018-12-11 11:23:23] <ramazantufekci> Selam
[2018-12-11 11:25:44] <mateothegreat> mateothegreat: nods
[2018-12-12 00:06:42] <stephenchu> Hi guys. In mydocker-compose.yml, I want from within a container to hit a DNS cname record of my choice (e.g.db-replicas.example.com) and be able to change the ip(s) returned by that record at run time. I think I might need to add into my docker-compose.yml a DNS server, and tell it to modify the backing ip(s) for the record. Does anyone know of a good Dockerized DNS server that allows dynamic changes to its records like that?
[2018-12-12 03:58:13] <DavidDLucas_twitter> stephenchu: consider consul.io ?
[2018-12-12 13:48:18] <irundaia> Hi! I've got a container that needs to access some services on the local network. Does anyone know how I can do this with docker for windows?
[2018-12-12 14:18:59] <irundaia> I've tried running with--network hostbut that didn't help either
[2018-12-12 18:15:14] <Huholoman> Hello, is there possibility to mount volume in dockerfile (like mount, not copy) or delay the command starting angulars server after docker-compose mounts the source code?
[2018-12-13 11:47:57] <phiter> hey guys
[2018-12-13 11:49:12] <phiter> I have a container, and this container must access another container in my machine. Is it possible to make my container see that container using its name? Currently, I'm using its IP address but it changes every time I start the computer
[2018-12-13 11:49:23] <phiter> the container uses network-mode="host" btw
[2018-12-13 11:51:07] <phiter> also I don't want to use networks because the container can also access databases that are not in actual containers
[2018-12-13 13:00:22] <phiter> ok I added both of them to a network and removed host network mode
[2018-12-13 15:36:12] <roychri> Would a docker image with 42 layers suffer from a performance issue (at runtime as a container) compared with an image with only a few layers? Or is the number of layers in a docker image only affect build time and image size but not runtime performance of the container? (with benchmark hopefully)
[2018-12-13 15:45:26] <Genysys> Huholoman: can you please post your docker file so we can get an understanding of what you are trying to achieve?
[2018-12-13 15:46:19] <Genysys> have to tried using docker compose anddepends on(this might be naively assuming that you are trying to run a multi container instance)
[2018-12-13 15:57:55] <MRDO5> phiterf: HI if i understand all what you need maybe  it [<-LINK->] --link         Add link to another container    in option
[2018-12-15 20:11:25] <vbabiy> Hey, is there a way to use zfs snapshoting on mounted volumes with in docker
[2018-12-15 20:11:46] <vbabiy> Example, I have a postgresql db with a volume, I want to try something and revert the snapshot to before that change
[2018-12-16 12:53:25] <MRDO5> HI all! Have anyone start origin in docker its gone down after 9 second . I do how write in site [<-LINK->] 
[2018-12-16 13:37:26] <saleemepoch> Hi all, I am new to docker and I need some help with setting static IPs to my containers using docker-compose.  Here is my yaml config: https://paste.ofcode.org/WpwR8h4zaHjiWWTk97RDcY.So doing docker-compose up -d starts up fine and I can see the network created and containers attached. However, when I run a command like so: $ docker-compose run wordpress lsI get:Error response from daemon: Address already in useI am using docker toolbox on Windows 10 (Don't want to enable Hyper-V, I want to keep vagrant).Any idea what's the problem here? It goes without saying the containers are unreachable.
[2018-12-16 14:18:06] <saleemepoch> someone from freenode explained to me that docker-compose run creates a new container to run a command, and since a container with that IP already exists it throws Address already in use error.
[2018-12-16 14:18:19] <saleemepoch> To run a command in an existing container I should use exec
[2018-12-16 14:18:45] <saleemepoch> So this is sorted. The original issue remains: why am I not able to reach the container?
[2018-12-16 14:18:47] <saleemepoch> $ curl 10.5.0.5curl: (7) Failed to connect to 10.5.0.5 port 80: Timed out
[2018-12-16 15:48:33] <mateothegreat> saleemepoch: try localhost
[2018-12-17 08:08:47] <gofighting123> hi there, i got a problem when build this docker on the github ( https://github.com/nicbet/docker-phoenix )here is my issue report on the github as bellow:hi, i got a problem when following the readme, but i can't finish the build step. here are the result as bellow:$ ./mix phx.new . --app helloPulling db (postgres:10)...10: Pulling from library/postgresa5a6f2f73cd8: Already existse50fbea8af5a: Already exists73b4855ad326: Already exists39616673f22b: Already exists94e1b79f69ee: Downloading [==========>                                        ]  1.359MB/6.183MBi can't finish this downloading.so, what can i do , switch to another mirror ?
[2018-12-17 08:12:18] <gofighting123> is there anything wrong? i am in a win10 and i use docker-terminal mode to excute the readme guild.
[2018-12-17 08:19:11] <gofighting123> i am trying use it's mix command with docker-compose with verbose. hope it helps.
[2018-12-17 12:09:47] <sandeepkumarsahoo> I am running a spring boot docker container . The job of the app is to clone a gitlab(https)  repo.  its working fine without creating docker container but from docker container it is unable to clone the repo even after bypassing ssl verification. Getting the below error..
[2018-12-17 12:10:12] <sandeepkumarsahoo> cannot open git-upload-pack
[2018-12-17 12:10:30] <sandeepkumarsahoo> Please help me .Thanks in advance
[2018-12-18 10:56:48] <managerger> hi, folks!Does anyone know how to assign permissions to an application that runs inside linux docker container? I need chmod +x aspnetcore.app. How can I do that? Thanks)
[2018-12-18 12:51:51] <mateothegreat> managerger: just add aRUN chmod +x aspnetcore.appin yourDockerfile
[2018-12-18 12:52:18] <mateothegreat> gofighting123: restart docker
[2018-12-19 00:14:57] <joeyfigaro> hey all
[2018-12-19 00:15:41] <joeyfigaro> Anyone here running a container on a machine and using smb/rsync + editor on another machine (all local network)
[2018-12-19 00:16:32] <joeyfigaro> Trying to run a container on my thinkpad and use my imac as my dev environment. I can hit the app in my browser fine, but now the biggest issue is that everything starts to slide downhill when I mount the fs on my imac.
[2018-12-19 00:17:22] <joeyfigaro> earlier I tried to install an npm module and node_modules/ became corrupted/unstable. I tried to blow it away and reinstall but it wouldn't let me remove empty folders (despite using -f/--force)
[2018-12-19 00:18:10] <joeyfigaro> on the imac side, anything I tried to unmount the volume would just freeze-ejecting from finder, umount/diskutil on command line, cd'ing into /Volumes/<name_of_volume> etc.
[2018-12-19 00:39:01] <mateothegreat> joeyfigaro: use an sshfs .. but either way sounds message .. you may be best using nfs tbh
[2018-12-19 00:44:08] <kellyprankin> OK, so one thing I found is: $> rails s -b 'ssl://localhost:3000?key=path/to/file/localhost.key&cert=path/to/file/localhost.crt'
[2018-12-19 00:44:16] <kellyprankin> however, I'm not sure how to translate to my docker file
[2018-12-19 00:44:39] <kellyprankin> which simply has: CMD ["rails", "server", "--binding", "0.0.0.0"]
[2018-12-19 00:46:29] <mateothegreat> CMD ["rails", "server", "--binding", “0.0.0.0”, “-b”, "ssl://localhost:3000?key=path/to/file/localhost.key&cert=path/to/file/localhost.crt”]
[2018-12-19 00:46:41] <kellyprankin> Thank you
[2018-12-19 00:52:17] <kellyprankin> should I be changing the port to 443 instead of 3000?
[2018-12-19 00:53:15] <mateothegreat> no idea, not a rails guy
[2018-12-19 01:25:46] <joeyfigaro> thanks@mateothegreat
[2018-12-19 01:26:04] <mateothegreat> mateothegreat: bows
[2018-12-19 06:45:59] <sandeepkumarsahoo> how can I call a https url from docker container ?
[2018-12-19 06:46:26] <kellyprankin> do you mean you want to connect to a web server inside the container over https?
[2018-12-19 06:47:54] <sandeepkumarsahoo> Actually I am calling gitlab(https) from docker container .
[2018-12-19 06:48:05] <kellyprankin> ah, from inside the container
[2018-12-19 06:48:11] <sandeepkumarsahoo> yes
[2018-12-19 06:48:58] <mateothegreat> sandeepkumarsahoo: I don’t understand the problem
[2018-12-19 06:50:57] <sandeepkumarsahoo> Ok let me explain it again,  one service is running inside a docker container, whose job is to push code to gitlab.  gitlab is outside of the container. My question is how can i make a https call to gitlab from inside the container ?
[2018-12-19 06:51:24] <mateothegreat> just call it
[2018-12-19 06:51:31] <mateothegreat> docker will use your underlying networking
[2018-12-19 06:51:38] <mateothegreat> like a bridge
[2018-12-19 06:53:01] <sandeepkumarsahoo> Its not working . Also I have tried by loading gitlab certificate. but the same is working without docker I mean in local.
[2018-12-19 06:53:28] <sandeepkumarsahoo> and also bypassing ssl verification.
[2018-12-19 06:57:29] <rahulmlokurte> Can you delete your rsa public and private key and try in local.. it should not work.. this means, when you push the code into gitlab, it is not picking up ssh private key and the certificates
[2018-12-19 07:00:05] <mateothegreat> what do you mean by “it’s not working” .. go in to detail buddy
[2018-12-19 07:02:19] <sandeepkumarsahoo> is ssh private key is required for https call ?? if yes am missing this trick...
[2018-12-19 07:03:14] <sandeepkumarsahoo> mateothegreat: not working means am not able to reach to gitlab server..
[2018-12-19 07:04:09] <mateothegreat> can you ping it from within the container?
[2018-12-19 07:04:24] <mateothegreat> can you connect to ports 22,80,443 from within the container?
[2018-12-19 07:05:45] <sandeepkumarsahoo> mateothegreat: let me check..
[2018-12-19 15:51:44] <mikeattara> My PC crashes when I install docker, what do I do?
[2018-12-19 15:52:03] <mikeattara> I use windows 10 Pro
[2018-12-19 15:52:17] <Rubemlrm> insider?
[2018-12-19 15:52:21] <Rubemlrm> ou normal releases
[2018-12-19 15:52:37] <Rubemlrm> do you have the hyper-v running too?
[2018-12-19 19:04:08] <mikeattara> Rubemlrm: Normal release, I have Hyper-v
[2018-12-19 19:05:28] <mikeattara> I the error code is DPC_WATCHDOG_VIOLATION
[2018-12-20 01:12:38] <gofighting123> mateothegreat: i did that about 5 times, and i asked my colluges at HongKong( btw, i am at Taiwan), and they build that github successfully at the first time. they said i hang at downloading the Postgre DB from the official site.i also wroted a issue on the github to author. but i think i ask here will be more easy to get some feedbacks.
[2018-12-20 03:00:36] <hi1027> Version 2.0.0.0-mac81 (29211)      Stop working for no reason
[2018-12-20 03:01:00] <hi1027> I have to restart
[2018-12-20 19:07:42] <johndiego> hi guys
[2018-12-20 19:08:10] <johndiego> someone config sshd in docker image?
[2018-12-20 19:09:15] <johndiego> my dockerfile
[2018-12-20 19:09:21] <johndiego>  [<-CODE->] 
[2018-12-20 19:10:09] <johndiego> How i can acess ssh in container
[2018-12-20 19:10:10] <johndiego> ?
[2018-12-20 19:48:46] <ghost~5bc98094d73408ce4fabf741> Curious, I have a docker-compose with which I run a few services which I register with consul. I am using the consul.NET lib to query consul. Anyone have any idea how do I specify  the address inside of the HTTP prop of the health check?
[2018-12-20 19:49:00] <ghost~5bc98094d73408ce4fabf741>  [<-CODE->] 
[2018-12-20 19:49:11] <ghost~5bc98094d73408ce4fabf741> The thing is within the container I should substitute service address for the name of the container but it doesn\'t make sense to write " [<-LINK->] because how will this be recognized and substituted
[2018-12-20 19:58:12] <ghost~5bc98094d73408ce4fabf741> So the question would probably be, how do you specify concatenated addresses inside of a docker container. I.e do I have to specify whenever its http:// or https://, do I have to explicitly write the port.
[2018-12-21 03:56:58] <hi1027> all: 
[2018-12-21 03:57:00] <hi1027> How to solve this problem
[2018-12-21 03:57:04] <hi1027>  [<-ISSUE->] 
[2018-12-21 06:07:41] <martin-sweeny> How come there's no stable repo for Fedora 29?
[2018-12-21 06:07:57] <martin-sweeny> I'm assuming it's temporarily down
[2018-12-21 12:46:12] <joelunmsm2003> Hi
[2018-12-21 14:19:38] <johndiego> docker dont mapping /etc dirs?
[2018-12-21 14:19:42] <johndiego> inside container?
[2018-12-22 06:12:19] <vinchauhan> Hello - How can I curl from Dockerfile to the host
[2018-12-22 06:13:22] <vinchauhan> I doing a POC build and dont want to curl the installation from internet all the time - I am planning to put the installer locally and host it through apache on localhost
[2018-12-22 06:14:56] <vinchauhan> RUN mkdir /opt/xyz && \\curl [<-LINK->] \\| tar zx --directory /opt/xyz && \\/opt/xyz/install/
[2018-12-22 06:15:00] <vinchauhan> but its not working
[2018-12-22 06:22:38] <vinchauhan> here: @vinchauhanHello - How can I curl from Dockerfile to the hostI doing a POC build and dont want to curl the installation from internet all the time - I am planning to put the installer locally and host it through apache on localhostRUN mkdir /opt/xyz && \\curl [<-LINK->] \\| tar zx --directory /opt/xyz && \\/opt/xyz/install/
[2018-12-22 06:23:22] <vinchauhan> @/here
[2018-12-22 06:51:42] <vinchauhan> Figured it out
[2018-12-22 06:52:03] <vinchauhan> host.docker.internal, which resolves to the internal IP address used by the host. This is for development purpose and will not work in a production environment outside of Docker for Mac.
[2018-12-22 15:23:01] <tbugfinder> johndiego: you have to add such mounts, but it's not the same.
[2018-12-24 03:57:14] <matrixbot> arisbanachi'm a bit new to docker but am a bit confused about something: if i'm running a container in production shouldn't i always set it to restart if there is an error or something?
[2018-12-24 03:57:22] <matrixbot> arisbanachotherwise it would just stop
[2018-12-24 06:30:27] <sarjerav> Hello all
[2018-12-24 06:31:08] <sarjerav> I have to deploy jhipster app with docker & keycloak . can someone help me ?
[2018-12-24 12:27:01] <sandeepkumarsahoo> How can I run 2 services  in a single docker container ? I have addedCMD python -m rasa_core_sdk.endpoint --actions ActionTest && python -m rasa_core.run -d models/dialogue -u test/nlu --endpoints endpoints.yml --enable_api -c rest --cors '*'line in my Dockerfile.  the problem i got is ,only the first server is running ...
[2018-12-24 12:27:26] <Genysys> have you tried using docker compose?@sandeepkumarsahoo
[2018-12-24 12:27:37] <Genysys> alot neater
[2018-12-24 12:29:12] <sandeepkumarsahoo> Genysys: Docker compose is not allowed in my company . is not it possible without docker compose ?
[2018-12-24 12:29:57] <Genysys> can you post a copy of your docker file?
[2018-12-24 12:30:06] <sandeepkumarsahoo> sure
[2018-12-24 12:31:03] <sandeepkumarsahoo>  [<-CODE->] 
[2018-12-24 12:34:58] <Genysys> have a look at rhis : [<-LINK->] 
[2018-12-24 12:36:28] <sandeepkumarsahoo> Genysys: That I already checked but not able to understand what to put for my_first_process and my_second_process.
[2018-12-24 12:36:33] <Genysys> also useCOPYinstead ofADD [<-LINK->] 
[2018-12-24 12:36:39] <sandeepkumarsahoo> Can u help me on that ?
[2018-12-24 12:37:48] <Genysys> its telling you to trigger them from an init script and not from the docker file directly
[2018-12-24 12:38:27] <Genysys>  [<-CODE->] & [<-CODE->] 
[2018-12-24 12:38:42] <Genysys> it would all be in a./my_script.shfile
[2018-12-24 12:38:45] <Genysys> does that make sense?
[2018-12-24 12:39:45] <sandeepkumarsahoo> The problem am getting is in this linepython -m rasa_core_sdk.endpoint --actions ActionTest && python -m rasa_core.run -d models/dialogue -u t
[2018-12-24 12:40:36] <Genysys> have you tried ssh into the box and running those from the command line|?
[2018-12-24 12:42:05] <sandeepkumarsahoo> this line is trying to up 2 servers , once the first service is started running , the second service command is not executing
[2018-12-24 12:42:29] <sandeepkumarsahoo> no i have not tried that one.
[2018-12-24 12:42:57] <Genysys> I would try that
[2018-12-24 12:43:26] <Genysys> then script those service running and save it into./my_script.sh
[2018-12-24 12:43:37] <Genysys> then run script in the command line
[2018-12-24 12:43:55] <sandeepkumarsahoo> So basically what I want is once the first server is up ,it should run in detach mode so that the second server command can run.
[2018-12-24 12:44:14] <Genysys> you would also have to copt the script from your local to your container
[2018-12-24 12:49:03] <sandeepkumarsahoo> what I have tried is , i created 3 sh files ,  1 file executingpython -m rasa_core_sdk.endpoint --actions ActionTest, another file containspython -m rasa_core.run -d models/dialogue -u test/nlu --endpoints endpoints.yml --enable_api -c rest --cors '*'and from the last sh file I have added the below details and calling from Dockerfile
[2018-12-24 12:49:31] <sandeepkumarsahoo>  [<-CODE->] 
[2018-12-24 12:50:08] <sandeepkumarsahoo> But am getting the same issue as before .
[2018-12-24 12:52:46] <sandeepkumarsahoo>  [<-CODE->] 
[2018-12-24 12:53:00] <sandeepkumarsahoo> this is my Dockerfile
[2018-12-25 07:14:49] <jeffycai> Maka.js, a react framework using Microservice Architecture [<-LINK->] 
[2018-12-25 07:41:28] <mateothegreat> jeffycai: at least spam somethinguseful
[2018-12-25 08:17:21] <bugsno> please help me run microsoft sql server 2017 docker image in termux on an android mobile. the mobile has 2 gb ram and no root
[2018-12-25 13:03:17] <pleerock> Hey guys can please someone help me why I can’t access my domain from inside of container, e.g.curl mysite.comworks on host but doesn’t work in my container
[2018-12-25 14:21:37] <serverlessnomad> pleerock: Can you access any domain from within the container?
[2018-12-25 14:30:41] <pleerock> serverlessnomad: yeap
[2018-12-25 14:37:48] <pleerock> mysite.com is running on port 80 and 443 in another nginx container. Site is working and everything is working fine. The only issue that I can’t access site by domain or ip from another container
[2018-12-25 14:52:37] <serverlessnomad> pleerock: might be an iptables issue.  take a look at this: [<-LINK->] 
[2018-12-25 15:15:23] <pleerock> serverlessnomad: sorry Im bad with all those sysadmin/devops tasks, can you point me which section you are referring to? I triediptables -P FORWARD ACCEPTbut it has no effect
[2018-12-26 21:01:20] <ghost~5bc98094d73408ce4fabf741> So I am nearly biting my ears of trying to setup a local kubernetes cluster on windows, apparently k8s minicube always needs to pull images from docker hub instead of using local docker daemon images, so after enough research i figured minikube runs its own docker daemon inside of its vm and this daemon pulls everything from hub and doesn't care about the docker for windows daemon images, ok, I figured out how to connect to that daemon and run build manually on that daemon but it still tries pulling these images from docker hub ignoring that they are available locally and fails (obviously I don't want them on docker hub so they are not there). I am starting to think I need to setup a local image repository in the cluster itself and point to that repository somehow to have this running. This is madness. =.=
[2018-12-26 21:01:34] <ghost~5bc98094d73408ce4fabf741> Merry Christmas
[2018-12-26 21:06:41] <TheoNeUpKid88> piotr-mamenas: I’m still a newby but it looks like you can configure minikube to run using an existing docker daemon by setting up an env variable on your local. Check out the following resources: [<-LINK->] 
[2018-12-26 21:06:48] <TheoNeUpKid88> also check out : [<-LINK->] 
[2018-12-26 21:07:07] <TheoNeUpKid88> though, the example is with Osx it should be relatively similar for windows I gather.
[2018-12-26 21:15:21] <ghost~5bc98094d73408ce4fabf741> TheoNeUpKid88: correct, thats the one I tried, except for windows its:@FOR/f "tokens=*" %i IN (\'minikube docker-env\') DO @%i instead of eval $(minikube docker-env). This switches you over to the k8s minicube daemon. When I run docker ps I see the internal k8s containers. Now when connected you are suppose to be able to navigate to the folder you got your dockerfiles in and build em which will run on that minicube daemon.
[2018-12-26 21:29:16] <ghost~5bc98094d73408ce4fabf741> got it ^__^ Odin is generous tonight
[2018-12-26 21:30:18] <ghost~5bc98094d73408ce4fabf741>  [<-CODE->] 
[2018-12-26 21:30:27] <ghost~5bc98094d73408ce4fabf741> should be added in the spec-containers definition of the deployment.yaml and this will make minikube just use local images
[2018-12-26 21:30:39] <ghost~5bc98094d73408ce4fabf741> heh auto code formatting
[2018-12-27 14:57:24] <deathgaze> i am building containers that are failing, but when Idocker exec -it <container_id> /bin/bashit is only showing me the results of the last build step. am I doing something wrong? why doesn’t it show the other files in the container?
[2018-12-27 15:08:05] <deathgaze> can anyone explain this please? docker exec is only showing the last build step. how can I debug the full container???
[2018-12-27 15:25:33] <dosdebug> deathgaze: docker logs --tail 50 --follow --timestamps CONTAINER_NAME
[2018-12-28 23:56:44] <drorsssssss> Hey guys,I\'m using macOs, and have issues regarding publishing some ports to the host.I\'ve created a docker-compose file which run an Airflow image (puckel/airflow-1.10.1) and it working good.I\'ve defined 2 ports to be published  - and set one of them to the webserver to be listened - so it works.Regarding the other port, i want to use him for remote debugging but it seems like it\'s not open.When running from my host the command "telnet 0.0.0.0 <port_number> " it seems like the connection established, but immediatly after refused.Any idea why it could happen?Thanks a lot
[2018-12-29 10:56:50] <iammatis> hi, so i'm a docker noobie and can't seem to figure out hot reloading in docker container when developing a node.js application. I have a Dockerfile:
[2018-12-29 10:58:25] <iammatis>  [<-CODE->] and docker-compose: [<-CODE->]  [<-CODE->] 
[2018-12-29 10:58:54] <iammatis> what am i doing wrong ?
[2018-12-29 11:19:06] <gofighting123> hi there, i have a question about [<-LINK->] run on win10 docker, it's possible i run that container on win10 docker ?
[2018-12-29 11:22:47] <serverlessnomad> iammatis: this might help: [<-LINK->] 
[2018-12-29 11:24:11] <serverlessnomad> gofighting123: i don’t see why not…. have you tried it?
[2018-12-29 11:24:32] <gofighting123> i did. and i wrote the issue report to the author
[2018-12-29 11:24:53] <serverlessnomad> what was the issue?
[2018-12-29 11:25:11] <gofighting123> i can't run and start the serive on localhost:4000 as README.
[2018-12-29 11:27:56] <gofighting123> i also found the article from and comment in the issue.也因此，底層是使用 Linux API 的 Docker 容器，是不能拿到 Windows 上面跑的。但相同的，使用 Windows API 這種底層的 Docker Container，就可以在上面執行 IIS，SQL Server Express 等等。the document from [<-LINK->] said if the container build from linux API docker can't port and run on the Win10 docker, is that right ?
[2018-12-29 11:29:02] <iammatis> serverlessnomad: yeah, i've got multiple articles and youtube videos opened and you can see that my setup is similar to the one you sent me, but still nothing
[2018-12-29 11:39:11] <serverlessnomad> iammatis: your “start” script is just the command “nodemon index.js”?  Are you seeing any errors and have you checked the container logs?
[2018-12-29 11:42:55] <iammatis> serverlessnomad: yes it is
[2018-12-29 11:43:09] <iammatis> this is the output when i start it [<-CODE->] 
[2018-12-29 11:43:23] <iammatis> (it's a simple express app)
[2018-12-29 11:43:56] <gofighting123> iammatis: it's kinda you need a hot-reload module ?
[2018-12-29 11:44:23] <iammatis> gofighting123: yes i want the hot reload function, that's why the nodemon
[2018-12-29 11:45:25] <gofighting123> iammatis: nodemon just do the things put the process to the background i think, not do the things watching  and reload when code chages in the VS Code
[2018-12-29 11:48:09] <iammatis> gofighting123: it does, it works that way when i run it locally, just not in the container
[2018-12-29 11:48:41] <gofighting123> i see, maybe try use -v (volume) map to the localhost folder ?
[2018-12-29 11:49:45] <gofighting123> docker is hard, ha, i just start to learn it
[2018-12-29 11:54:06] <serverlessnomad> iammatis: so there was an issue with the pstree.remy with nodemon reported less than a month ago.  However it looks like they fixed it in 1.18.8.  What’s your base image?  You’re referencing the node image but does the 11 indicate you’ve made some changes and saved a version?
[2018-12-29 11:55:04] <serverlessnomad> iammatis:  [<-ISSUE->] 
[2018-12-29 11:55:53] <gofighting123> wow, cool
[2018-12-29 11:56:01] <iammatis> serverlessnomad: yeah i read that issue, but you can see i'm running[nodemon] 1.18.9from the log
[2018-12-29 11:56:37] <iammatis> i don\'t get what you mean by this tho "You’re referencing the node image..."
[2018-12-29 11:57:36] <serverlessnomad> iammatis: yeah i saw your updated reference…  frankly everything looks good so the only thing I’m thinking about is your FROM node:11
[2018-12-29 11:57:50] <serverlessnomad> iammatis: have you tried to update that to FROM node:latest and see if that helps?
[2018-12-29 11:59:06] <iammatis> serverlessnomad: just tried, didn't help
[2018-12-29 11:59:39] <iammatis> could volumes have to do sth with it ? I'm looking into it now, what volumes are etc
[2018-12-29 12:00:11] <gofighting123> it's a method to map the host data with the container service.
[2018-12-29 12:01:06] <serverlessnomad> iammatis: well you also have that “COPY . .” in your Dockerfile which I’m not sure I understand.  But I’m also not sure that would be the problem.
[2018-12-29 12:01:40] <iammatis> serverlessnomad: well i followed this video [<-LINK->] 
[2018-12-29 12:02:27] <iammatis> that one doesn't use nodemon just node
[2018-12-29 12:02:58] <iammatis> this one tho [<-LINK->] uses nodemon and he mounts a volume src:src, don't know what that means
[2018-12-29 12:04:47] <serverlessnomad> iammatis: ahh ok… as@gofighting123said it’s a way of taking a folder from your local system and mounting it as a filesystem within your container.  That way when you’re changing your source code for your nodejs app you’re changing it in the /src folder on your local machine, but that folder is mapped inside of your container and nodemon should see those changes.
[2018-12-29 12:05:06] <serverlessnomad> iammatis: how have you been getting changes into your container?
[2018-12-29 12:06:56] <iammatis> serverlessnomad: @gofighting123okay it was actually because of the volume, i found [<-LINK->] and added this line
[2018-12-29 12:07:09] <iammatis>  [<-CODE->] to my docker-compose
[2018-12-29 12:07:10] <gofighting123> great :)
[2018-12-29 12:07:19] <serverlessnomad> iammatis: working now?
[2018-12-29 12:07:25] <iammatis> thanks guys, yeah it's reloading
[2018-12-29 12:07:28] <serverlessnomad> excellent!
[2018-12-29 12:08:06] <iammatis> if that's a development version, should i leave the volumes line in the production version too ?
[2018-12-29 12:08:18] <gofighting123> sure.
[2018-12-29 12:08:44] <gofighting123> i think there are lots of ways to do so.
[2018-12-29 12:09:13] <serverlessnomad> iammatis: not really… you can, but it could create portability problems and end of the day when you’re done building your app the container should be fully baked.  so you shouldn’t be dependent on the underlying host for anything other than the docker runtime.
[2018-12-29 12:10:35] <iammatis> serverlessnomad: oh yeah, in the second video i posted he actually deleted the volumes line from production .yml file
[2018-12-29 12:11:58] <serverlessnomad> gofighting123: i’m checking your Windows 10 issue.  I develop on macOS so I had to update some stuff on my Windows box.
[2018-12-29 12:12:19] <gofighting123> serverlessnomad: thanks lots
[2018-12-29 12:14:48] <gofighting123> i need to grab my dinner by macdonald drive thru :(
[2018-12-29 12:14:59] <gofighting123> see you soon :)
[2018-12-29 12:15:06] <serverlessnomad> gofighting123: good luck!
[2018-12-29 12:33:22] <gofighting123> i'm back : )
[2018-12-29 12:35:18] <serverlessnomad> gofighting123: out of the box that solution will not work since it’s mounting a local path.  it assumes you’ll have your elixir/phoenix code in /src.  I don’t have erlang/elixir on this box so I’m installing it.
[2018-12-29 12:36:01] <gofighting123> i see: ) i follow the README and all containers build .
[2018-12-29 12:36:42] <serverlessnomad> You’re doing that from a Windows 10 box currently?
[2018-12-29 12:36:43] <gofighting123> and the preparation u have to add the dev.exs ? in the README
[2018-12-29 12:36:48] <gofighting123> YES
[2018-12-29 12:37:15] <serverlessnomad> Ahh ok, so I guess I did not understand your question.  I thought you wanted to know if it would work on Windows 10.
[2018-12-29 12:37:17] <gofighting123> i can't excute the ./mix part of README.
[2018-12-29 12:37:23] <serverlessnomad> Ahh got it
[2018-12-29 12:37:51] <gofighting123> i try to use navicat to connect to the postgres:10 container service on port 5432 map to host machine port 5432, but i failed QAQ
[2018-12-29 12:39:25] <serverlessnomad> so you modified the configuration to expose the postgres port?
[2018-12-29 12:40:27] <gofighting123> i start the postgres container services, but i can't use navicat to connect to it @@
[2018-12-29 12:41:57] <gofighting123> it will build lots of containers. hello-phoenix,exilir, etc.
[2018-12-29 13:00:54] <serverlessnomad> gofighting123: yeah i’m not having much luck either…  i also don’t use Windows to do a lot of dev work.  Have you thought about trying Ubuntu on Windows?  Or do you have a requirement that would make that a problem?
[2018-12-29 13:01:50] <serverlessnomad> gofighting123: my mix deps.get comes back with errors on the Hex package which prevents anything from going forward.  would take some time to figure that out...
[2018-12-29 13:17:34] <gofighting123> oh my ...
[2018-12-29 13:19:20] <gofighting123> serverlessnomad: so i think i should read the docker book first, it's much better XD thanks anyway.
[2018-12-31 10:52:47] <nicexe> hi people
[2018-12-31 10:52:57] <nicexe> I want to use a docker-compose stack with an external docker network
[2018-12-31 10:53:06] <nicexe> how can I set a specific IP to a docker-compose service?
[2018-12-31 10:53:38] <nicexe> before I was using a docker compose defined network with a custom subnet and I was assigning an ip from that subnet to a docker compose service
[2018-12-31 10:53:44] <nicexe> I want to retain pretty much everything but move the network outside of the docker compose stack
[2019-01-02 07:41:56] <ManikantThakur> Hi, Is there a way to check if the images exists on Dockerhub (via docker python SDK). ?I have tried client.api.images(image), but seems it lists the images available on local system and not on dockerhub.Tried client.images.get_registry_data(image), and it always throws me 'access denied' error, even though I do docker login before making this call.
[2019-01-02 09:11:43] <smfaizalkhan> Hi All,
[2019-01-02 09:16:26] <smfaizalkhan> I have a docker swarm on runningon two different  hosts ,Leader in Ubuntu and worker in Windowson docker network ls i  can see the network getting listedC:\\Users\\Faizal>docker network lsNETWORK ID          NAME                DRIVER              SCOPE18887aba757f        bridge              bridge              local00df062ded65        docker_default      bridge              local1e42220f0b70        docker_gwbridge     bridge              local90c53993c421        host                host                localudozhr1kppne        ingress             overlay             swarm9e08a2fd21fe        none                null                localrtcs20mrhmnt        overnet             overlay             swarmDocker inspect gives the service mysericedocker network inspect overnet[    {        "Name": "overnet",        "Id": "rtcs20mrhmntlmwh02upgk5f2",        "Created": "2019-01-02T06:41:23.5165731Z",        "Scope": "swarm",        "Driver": "overlay",        "EnableIPv6": false,        "IPAM": {            "Driver": "default",            "Options": null,            "Config": [                {                    "Subnet": "10.0.0.0/24",                    "Gateway": "10.0.0.1"                }            ]        },        "Internal": false,        "Attachable": false,        "Ingress": false,        "ConfigFrom": {            "Network": ""        },        "ConfigOnly": false,        "Containers": {            "1e9a962147b2443d41537d98fd91a020d3aa090bf1ea2bacafb7ceacce9df99c": {                "Name": "myservice.2.ydxmr7tb8jlzu4g6jwvnc7ryr",                "EndpointID": "0bd35007868ff220064ddf3fa19f9e36708853b45bc6234635b3f11b45f9660e",                "MacAddress": "02:42:0a:00:00:24",                "IPv4Address": "10.0.0.36/24",                "IPv6Address": ""            },            "lb-overnet": {                "Name": "overnet-endpoint",                "EndpointID": "7ed5fc49f3846b6b80a30a48b43170f7225b2a2210e99ee2219ac14fed6a6182",                "MacAddress": "02:42:0a:00:00:25",                "IPv4Address": "10.0.0.37/24",                "IPv6Address": ""            }        },        "Options": {            "com.docker.network.driver.overlay.vxlanid_list": "4097"        },        "Labels": {},        "Peers": [            {                "Name": "eb0e60ee3298",                "IP": "192.168.0.8"            },            {                "Name": "8b49e41d1df7",                "IP": "192.168.0.7"            }        ]    }]now i enter into conatiner and try to ping another conatiner on ubuntu ,but i dont get inof ,all the data is lost.ping 10.0.0.36PING 10.0.0.36 (10.0.0.36): 56 data bytes64 bytes from 10.0.0.36: seq=0 ttl=64 time=0.068 ms64 bytes from 10.0.0.36: seq=1 ttl=64 time=0.176 ms64 bytes from 10.0.0.36: seq=2 ttl=64 time=0.185 ms64 bytes from 10.0.0.36: seq=3 ttl=64 time=0.176 ms^C--- 10.0.0.36 ping statistics ---4 packets transmitted, 4 packets received, 0% packet lossround-trip min/avg/max = 0.068/0.151/0.185 ms/ # ping 10.0.0.35PING 10.0.0.35 (10.0.0.35): 56 data bytes^C--- 10.0.0.35 ping statistics ---32 packets transmitted, 0 packets received, 100% packet loss
[2019-01-02 09:17:16] <smfaizalkhan> Help needed ...
[2019-01-02 09:24:03] <ManikantThakur> smfaizalkhan: try to ping using service name and see the reponse
[2019-01-02 09:29:02] <smfaizalkhan> ManikantThakur: .vain32 packets transmitted, 0 packets received, 100% packet loss/ # ping myservice.1.jtkj4z1kyc69milz3511dxrrvping: bad address 'myservice.1.jtkj4z1kyc69milz3511dxrrv'
[2019-01-02 09:57:15] <ManikantThakur> Try add a same network to both the service in your stack yaml file. For more info refer: [<-LINK->] 
[2019-01-02 10:12:58] <zhangyanwei> hi, I've met a weird issue when using the dockerized nginx.Will get hanging requests after hundreds if I was using the JMeter to request the backend service through the reverse proxy of nginx.
[2019-01-02 10:13:29] <zhangyanwei> Does anyone has met the same issue before?
[2019-01-02 10:20:32] <smfaizalkhan> @ManikantThakurit is same overlay networkHere are the steps i diddocker swarm init --address-addr-192.168.0.7 in ubuntu machine to make it as leadergot a docker swarm join token ,copied it and pasted into windows macine and it was joined as workerdocker swarm join --token SWMTKN-1-2qzxlwh8ui8hags6f5rls29grk73ucb3j0daltpydescd42sp5-0n7mejovdylaichnqt5ur1hnm --advertise-addr 192.168.0.8 192.168.0.7:2377This node joined a swarm as a worker.the created a network in leader (Ubuntu)docker network create -d overlay overnetand a service in leaderdocker service create --name myservice \\ --network overnet --replicas 2 alpine sleep 1dthen when i did docker network ls on leader and worker i could see overnet network created in worker ,as service need this network and it started the same in worker node.then bashed intoa) worker container to ping leader containerb) leader container to ping worker containerbut no response .and nothing in logs as well
[2019-01-02 10:23:40] <smfaizalkhan>  [<-LINK->] 
[2019-01-02 11:58:09] <aebadian> Hey all, Im very new to Docker, so my apologies if this is far too basic.I run docker pull hello-world and I see this error:docker pull hello-world\nlatest: Pulling from hello-world\n65b27d3bd74d: Download complete \n9f5834b25059: Pulling fs layer \n9f5834b25059: Download complete \nRepository not found
[2019-01-02 11:58:40] <aebadian> am I doing something  seriously silly here?
[2019-01-02 12:01:52] <pedroparraortega> docker pull hello-world
[2019-01-02 12:01:56] <pedroparraortega> should work
[2019-01-02 12:03:25] <aebadian>  [<-LINK->] 
[2019-01-02 12:03:40] <aebadian> pedroparraortega: it looks like it really doesnt like it
[2019-01-02 12:05:12] <pedroparraortega> probably is a firewall issue
[2019-01-02 12:05:31] <aebadian> looking at the/var/log/dockerthis is what I see time="2019-01-02T12:00:54.856828161Z" level=info msg="Docker daemon" commit="786b29d/1.7.1" execdriver=native-0.2 graphdriver=devicemapper version=1.7.1time="2019-01-02T12:01:11.470606031Z" level=info msg="POST /v1.19/images/create?fromImage=hello-world%3Alatest"time="2019-01-02T12:01:11.489054084Z" level=info msg="Trust graph fetch failed: Get [<-LINK->] : dial tcp: lookup dvjy3tqbc323p.cloudfront.net: No address associated with hostname"
[2019-01-02 12:06:45] <pedroparraortega>  [<-LINK->] 
[2019-01-02 12:06:58] <pedroparraortega> just in case you are running behind, firewall/proxy
[2019-01-02 12:08:31] <aebadian> none of those are blocked via our firewall
[2019-01-02 12:09:18] <aebadian> is this address correct?https://dvjy3tqbc323p.cloudfront.net/trust/official.json
[2019-01-02 14:21:48] <aebadian> could this have been caused because I'm using CentOs 6, and so i had to install docker-io ?
[2019-01-03 01:56:03] <stephenchu> Q: islinks:soon to be deprecated in adocker-compose.ymlin favor of using a explicitly created and shared network? what's the latest?
[2019-01-04 04:54:33] <andrewray_twitter> What's the best practice when using docker-compose for running setup scripts like database creation / seeding? Do you have a setup image in the docker-compose yml activated by an env var so you only run setup once?
[2019-01-04 04:54:52] <andrewray_twitter> or do you keep the setup container out of docker compose?
[2019-01-04 07:58:35] <diegocastrum> Hi everyone!I'm facing a problem right now related with volumes on docker. I builded my own image which downloads the last stable version of opencart.I'm using docker-compose to create a stack of services and from there I would like to get access from the host machine to the folder where opencart was downloaded.I know it seems to be an easy one... I'm just started with docker a few weeks ago and I'm trying to redesign my current development environment making use of docker.
[2019-01-04 08:55:27] <gofighting123> hi...i got a problem mapping openkm with my host pc. i can use -P start the container  but i can't access the openkm service on the host.
[2019-01-04 09:07:20] <radiantly> Looks like you might want to try the--network hostflag.
[2019-01-04 09:09:27] <diegocastrum> gofighting123: seems more or less the same problem what I have.
[2019-01-04 09:09:33] <diegocastrum> I must to say that I\'m using as base image "php:7.3.0-fpm". At the docker-compose file under the opencart service I define a volume like: "./opencart:/var/www/html". But when I run docker-compose up that directory is empty
[2019-01-04 11:29:28] <wizardnet972> by this answer:So a running instance of an image is a container.This is mean that container is "node application". and if I have two or more containers I have multi node applications?
[2019-01-04 17:06:29] <vishnuavenudev> hiii ... any one know how to read the stdout
[2019-01-04 17:07:01] <rcjsuen> You probably want to elaborate on your question
[2019-01-04 17:07:39] <vishnuavenudev> RUN ln -sf /dev/stdout /var/log/myapp/services-info.log \\&& ln -sf /dev/stderr /var/log/myapp/services-error.log
[2019-01-04 17:08:02] <vishnuavenudev> i added this in docker
[2019-01-04 17:08:14] <vishnuavenudev> i am running it on aws ecs
[2019-01-04 17:08:43] <vishnuavenudev> i am getting the logs on cloudwatch but cannot tail inside container
[2019-01-04 17:08:59] <vishnuavenudev> tailf  /var/log/myapp/services-info.log
[2019-01-04 17:09:16] <vishnuavenudev> tailf /dev/stdout
[2019-01-04 17:09:25] <vishnuavenudev> both of them not running
[2019-01-04 17:09:39] <vishnuavenudev> not showing any logs
[2019-01-04 17:09:58] <vishnuavenudev> base image for this docker is ubuntu
[2019-01-04 17:11:31] <vishnuavenudev> rcjsuen: any idea ??
[2019-01-04 17:13:55] <rcjsuen> Unfortunately no
[2019-01-04 17:14:27] <vishnuavenudev> hmm ok ...
[2019-01-04 22:12:59] <aaron-gesmer> Is anyone  having trouble with thedockerimage? Trying to get a Dockerfile with docker on it out of the box, instead getting:Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?
[2019-01-04 22:16:15] <aaron-gesmer> I\'m using the "official" docker image, if anyone would be willing to try, run:$ docker run -it --rm docker# docker ps -a
[2019-01-04 22:28:12] <aaron-gesmer> nvm, found solution
[2019-01-06 20:07:14] <smfaizalkhan> Hi All,I have an ubuntu and win10 machine and try to join them using swarmSo on win 10 i did a docker swarm inint and it gave medocker swarm join --token SWMTKN-1-2x0d8gcwdajbjt78xtgnfdgrlggd2yp9sh6t3klcx48bszl7nk-99on3a92ej4pdhgbglfmdychy 192.168.65.3:2377i copied this to ubuntu machine and the response wasError response from daemon: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing dial tcp 192.168.0.8:2377: connect: connection refused"faizal@faizal-K42JA:~/hypledger$  docker swarm join --token SWMTKN-1-5m96ou268r2csm89faroxa4313crw484px8kzyvkthq9ggdixc-8xqlzsnp1w41khm3i84ek5sl8 192.168.0.8:2377i coudnt do a telnet even from my win10 mchine or even ping it.How to make win10 as manager and ubuntu as worked using docker swarm
[2019-01-07 09:41:48] <gofighting123> @diegocastrum....it looks like all mapping problem...i mean file system like problem.
[2019-01-07 15:20:56] <VineethReddy02_twitter> Hi!
[2019-01-07 15:21:56] <VineethReddy02_twitter> does docker provide any API to know whenever the base images are updates.
[2019-01-07 15:23:13] <AllanKlaus> I think you can see it using the tags of the image
[2019-01-07 15:24:38] <VineethReddy02_twitter> My use case is to poll the docker hub and once my base image has been updated i will rebuild the image from the scratch without using the cache feature from docker.
[2019-01-07 15:25:45] <VineethReddy02_twitter> for example if i use FROM node:latest whenever the image is modified i need to take the update.
[2019-01-07 15:26:29] <AllanKlaus> Docker always with start from it's cache, to get this update you need to delete the cached image
[2019-01-07 15:27:07] <VineethReddy02_twitter> AllanKlaus: if an existing image gets a patch or some kind of update i want my application to change accordingly.
[2019-01-07 15:27:34] <VineethReddy02_twitter> but how will i know that particular image has got updated without polling ?
[2019-01-07 15:37:50] <AllanKlaus> maybe usinghistory
[2019-01-07 15:38:05] <AllanKlaus> docker image history repository/image:tag
[2019-01-07 16:58:00] <VineethReddy02_twitter> AllanKlaus: taht command is used for local images running on our system right ? You cannot know the last modified details for tomcat:latest , try running "docker image history bitnami/tomcat:latest"
[2019-01-07 16:58:53] <VineethReddy02_twitter> as you suggested.
[2019-01-07 17:43:31] <jayarc> Any quick ideas why on a default network/docker-compose I can resolve hostnames by the container name with docker exec but on build the same command fails. Hostname resolution works when I docker exec in but not during build...
[2019-01-07 17:44:05] <jayarc> Can post gist
[2019-01-07 17:45:18] <AllanKlaus> VineethReddy02_twitter: the only way I know is usingdocker pull repo/image:latest
[2019-01-07 17:46:25] <jayarc> Nvm, answered my question. Thanks for looking
[2019-01-08 05:09:46] <gofighting123> hi, my docker on win10 has wired problem...someone know what is it?i use start.sh and it auto genrate new veth pair network. in control pannel.is that a issue or what can i do to fix it?i restart my pc and i can get an veth pair, but it generate many veth pairs settings in the control pannel. is that correct ? [<-CODE->] 
[2019-01-08 11:01:35] <smfaizalkhan> Hi All,I treid to make an linux container in Ubuntu 16.04 as swarm manager and tried to connect a linux container in Windows10using docker-swarm join token-manageri get the below error.Error: rpc error: code = Unavailable desc = all SubConns are in TransientFailure,latest connection error: connection error: desc = "transport: authentication handshake failed:read tcp 192.168.0.7:57124->192.168.0.8:2377: read: connection reset by peer"Help appreciated
[2019-01-09 11:44:39] <OOPMan> Hey
[2019-01-09 11:44:41] <OOPMan> Quick question
[2019-01-09 11:45:06] <OOPMan> I have some containers running with docker swarm
[2019-01-09 11:45:21] <OOPMan> Will the overlay network always be bound to eth0 inside the container?
[2019-01-09 12:49:34] <CharcoGreen> eth0
[2019-01-09 12:49:54] <CharcoGreen> if you add a new network eth1
[2019-01-10 17:57:38] <dragonpiper> Is it possible for containers to talk to each other on 127.0.0.1  if they are on the same network, or do you have to use the container name ?
[2019-01-10 18:08:39] <SalathielGenese> Yes there are many ways containers can talk to each other. What container orchestrator are you using? Or how are you bringing them up (for example, using docker-compose)?@dragonpiper
[2019-01-10 19:11:52] <dragonpiper> I'm using docker-compose 2.3@SalathielGenese
[2019-01-10 19:12:23] <SalathielGenese> Yes, I'm looking for docs entries and example from on project
[2019-01-10 19:12:41] <SalathielGenese> Though I am used to docker-compose 2.1
[2019-01-10 19:14:13] <dragonpiper> I could have swore this worked by default before updating docker but could be mistaken
[2019-01-10 19:15:40] <SalathielGenese>  [<-CODE->] Note thelinksentryhttps://docs.docker.com/compose/compose-file/compose-file-v2/#links
[2019-01-10 19:16:46] <dragonpiper> but when using docker-compose services are already placed on the same default bridge network
[2019-01-10 19:18:24] <dragonpiper> Hm, reading over it again
[2019-01-10 19:19:24] <dragonpiper> By default, every container joins an application-wide default network, and is discoverable at a hostname that’s the same as the service name. This means links are largely unnecessary.
[2019-01-10 19:19:34] <SalathielGenese> Within theschedule-to-pubsubcontainer, I can ping the pubsub or redis container I linked usingping redisorping pubsub
[2019-01-10 19:20:04] <dragonpiper> Right  but is it possible to have seperate services share the same ip address ?
[2019-01-10 19:20:32] <SalathielGenese> From within the container that links, you can evencurl POST pubsub:8085/
[2019-01-10 19:22:03] <SalathielGenese> is it possible to have seperate services share the same ip address ?NODocker creates a virtual network in your machine. Each container has its own IP address
[2019-01-10 19:23:44] <dragonpiper> So i have to have a seperte ip:port config for services inside and outside docker then  / override my hosts file ?
[2019-01-10 19:25:14] <SalathielGenese> ??? I am not sure to follow. How do you intend to use that container linking? What is your case?
[2019-01-10 19:26:04] <dragonpiper> say i have 2 containers one a database and one a http server. I want them to point to each other through localhost and the port they are running on
[2019-01-10 19:27:57] <SalathielGenese> I think you are victim of some misconception. Let me explain
[2019-01-10 19:29:36] <SalathielGenese> In my compose file above, my serviceschedule-to-pubsubhas two links to two services, one of which isredis
[2019-01-10 19:30:40] <SalathielGenese> redisrun by default on port6379
[2019-01-10 19:31:23] <SalathielGenese> And trust me, it will be::6379fromrediscontainer viewpoint
[2019-01-10 19:31:59] <SalathielGenese> I don't need to access that port from my host (so no need to expose it)
[2019-01-10 19:34:07] <SalathielGenese>  [<-CODE->]  [<-CODE->] Where : [<-CODE->] 
[2019-01-10 19:35:30] <SalathielGenese> If my redis was hosted atredis.my-app.com, I would setenv.REDIS_HOSTto"redis.my-app.com"
[2019-01-10 19:36:07] <SalathielGenese> Does it help you?Or do you need another example?
[2019-01-10 19:39:29] <SalathielGenese> Look at this other example with PostGres database [<-CODE->] 
[2019-01-10 19:43:39] <SalathielGenese> Does it help,@dragonpiper?
[2019-01-10 19:49:36] <dragonpiper> Yea, that makes sense
[2019-01-10 20:18:04] <son1sid_twitter> Guys what does a healthcheck really do? Can it be use for a selenium / hub and chrome set up ?
[2019-01-10 20:25:22] <SalathielGenese>  [<-CODE->] Container orchestrators use healthcheck commands to determine if the container has crashed so that another instance might be brought up to replace that failing one (which will be forcefully shutdown after some time).Most (if not all) containers orchestrators provide a way for customized healthcheck command because, sometimes (if not most of the time), nothing but an app itself can really tell if everything is OK for it to work as expected. i.e why, for some web app, you may find a healthcheck command looking like [<-CODE->]  [<-CODE->] 
[2019-01-10 20:27:02] <SalathielGenese> The developer is then free to implements whatever code at that request path handler
[2019-01-10 20:29:18] <SalathielGenese> Weithercurlorwget, the exist status will differs from0is the HTTP response status code differs from1XX,2XXor3XX(not sure about this last one 3XX - you may need to check)
[2019-01-11 07:01:56] <SHUB9914> Hey everyone, I am new in docker and facing some issue in deployment using docker swarm
[2019-01-11 07:08:25] <SHUB9914> I have docker-compose file, In which i have defined few services, some of them directly taking image from docker hub and some i am creating  using build.So when I am deploying it using docker swarm , so those images that are available in docker hub , is successfully started in my other nodes but , those images that i created, is running only my manager node because it's a available on manager node, so can any one help how to distrubute or run my other images to the other nodes as well usig docker swarm
[2019-01-11 07:40:06] <SHUB9914> Without pushing it to create own repo
[2019-01-11 08:16:32] <diegocastrum> @diegocastrum ....it looks like all mapping problem...i mean file system like problem.@gofighting123 First of all, sorry for my late answer.Yes you're right, I've read a bit about this point and I solved this using the following volume definition on de docker-compose.yml: [<-CODE->] Thank you very much for your message! :)
[2019-01-11 13:20:50] <dimitar-nikovski> Hi, if you have 1 app composed of two servers using the same image -> for ex. 1 Node server for react and 1 Node server for an api and db connection, would you run in them 1 Node image based docker container or 2 separate Node containers, if the two Node servers are to share the same host.
[2019-01-11 13:24:09] <SalathielGenese> Either will/can work... But due to the reason why people first decided to use microservices, containers and workload balancers, it is better to run them as separate containers.
[2019-01-11 13:24:43] <dimitar-nikovski> many thanks@SalathielGenese
[2019-01-11 13:24:53] <SalathielGenese> My pleasure
[2019-01-11 13:28:20] <dimitar-nikovski> sorry to keep re-asking, if you were to run 1 Node app with more than 1 thread would you: a) run it inside a single container with PM2 clustering b) run a cluster of containers with sequential ports and load-balance between them with Nginx
[2019-01-11 13:35:17] <SalathielGenese> You don't sorry for asking. He won't don't know or is not sure has asks. And Gitter is one the places to ask to.I would go for the second option... But to be honest, it is because I already know docker & kubernetes
[2019-01-11 13:37:24] <dimitar-nikovski> SalathielGenese: many thanks, it just saves you so much time on searching through online resources vs getting a quick answer from a helpful developer, some of the simple stuff aren't written explicitly hence, only someone with experience would know, thanks a lot
[2019-01-11 15:42:36] <roychri> dimitar-nikovski: I agree with@SalathielGeneseon this. If you need more node threads to handle the load, better to increase the number of containers rather than doing the cluster in a single container.
[2019-01-11 17:31:49] <ironchicken> thexvdfilesystem on which docker stores its data has exhausted 93% of its inodes and when i try to build images it complains that there is no space on the device. i can see that/opt/jenkins/docker-data/overlayhas2264418inodes. but i'm not sure how to clean it.docker system prunedoesn't reclaim any space. can i safely delete the contents ofoverlay/?
[2019-01-12 11:33:56] <danielWalker_twitter> hey all, I'm having a bit of a headache connecting to a container built from docker-compose, simply running mysql, my local 3306 port is bound so I've set the posts to map4306:3306, when this builds it says it's available andSocket: '/var/run/mysqld/mysqlx.sock' bind-address: '::' port: 33060pson the host says the machine says33060/tcp, 0.0.0.0:4306->3306/tcpfor my ports but every time I attempt to connect with sequePro I get a timeout, does anyone have any ideas what my be stopping it? I'veit'dinto the container, verified mysql is running, verified the users is in the access table and host is%...I'm thinking there must be some block between host and container? My firewall maybe?
[2019-01-12 11:34:13] <danielWalker_twitter> Any help is hugely appreciated, I've been headbutting this thing for days
[2019-01-12 11:38:49] <SalathielGenese> Are you connecting from HOST or from within another container ?
[2019-01-12 11:38:57] <SalathielGenese> danielWalker_twitter: 
[2019-01-12 11:39:05] <danielWalker_twitter> SalathielGenese: from host
[2019-01-12 11:40:54] <danielWalker_twitter> If you're leading to the assumption I did that I will need to use the containers IP or gateway I did try that, I'll try again now but it seemed to timeout too
[2019-01-12 11:41:57] <SalathielGenese> If you use container IP, also switch to container PORT::3306and let's see
[2019-01-12 11:42:51] <danielWalker_twitter> So when I grep the container gateway and us it\'s IP (docker inspect $1 | grep -aw "Gateway") or interact with the container and query it\'shostname -I?
[2019-01-12 11:44:40] <SalathielGenese> Here how I use to get my containers IP [<-CODE->] 
[2019-01-12 11:45:13] <danielWalker_twitter> both failed for me again, they spin out for ages like they're resolving something, not at all like when I'm hitting a no service ip etc)
[2019-01-12 11:45:15] <SalathielGenese> jqis a shell program that manipulates JSON strings
[2019-01-12 11:46:09] <danielWalker_twitter> ahh that's fine, I got the same resulting ip
[2019-01-12 11:48:38] <SalathielGenese> Let's try to determine is the error might be Sequel Pro itself
[2019-01-12 11:48:55] <SalathielGenese> Do you havemysqlinstalled on your host ?
[2019-01-12 11:49:36] <SalathielGenese> Try connecting the  hostmysqlclient to container mysql server
[2019-01-12 11:50:30] <danielWalker_twitter> I don't, it gave me to many issues running it on host
[2019-01-12 11:50:48] <SalathielGenese> Themysqlclient ?
[2019-01-12 11:51:28] <danielWalker_twitter> yeah I kinda somehow killed it when I tried purging the server
[2019-01-12 11:52:26] <SalathielGenese> Well, run a mysql client from another container, linking the former (server) to later (client) and use the mysql client from the latter to connect to the former
[2019-01-12 11:52:45] <SalathielGenese> Do you get what I mean ?
[2019-01-12 11:52:53] <danielWalker_twitter> sorry I think I'm confusing that issues, my sequalPro client connects to remote db's vagrant machine db's etc al with no problem
[2019-01-12 11:53:38] <danielWalker_twitter> I was about to say would it be just as easy to compose a second service say nginx with an exposed endpoint that links to it and tests the connection
[2019-01-12 11:54:02] <SalathielGenese> Yep
[2019-01-12 11:54:56] <danielWalker_twitter> not sure I get what you mean about linking 2 mysql servers though, you mean start two services, call them A and B, interact with A then use the mysql client there to connect to B?
[2019-01-12 11:55:12] <SalathielGenese> Yes, precisely
[2019-01-12 11:55:36] <danielWalker_twitter> Great I'll give it a go
[2019-01-12 12:02:59] <danielWalker_twitter> Oooookay@SalathielGenese, it connected fine from A to B using it's ip on the internal network
[2019-01-12 12:07:57] <danielWalker_twitter> I'm reinstalling the mysql client on the host machine to test again from there
[2019-01-12 12:08:06] <SalathielGenese> Hehe - Congrats !!!
[2019-01-12 12:14:01] <SalathielGenese> First tolocalhost :: host-portThencontainer :: container-port(Though I am not sure of this one)
[2019-01-12 12:28:29] <danielWalker_twitter> Okay, mysql fixed on the host! 
[2019-01-12 12:29:21] <wizardnet972> I need help with docker and ecs-cli please. I try to runecs-cli compose up --cluster tester-clusterbut its stop and I dont know why.. [<-CODE->] 
[2019-01-12 12:32:39] <SalathielGenese> Did you@wizardnet972tried the  verbose mode to get more logs ?--verboseas per [<-LINK->] .
[2019-01-12 12:34:22] <wizardnet972> SalathielGenese: well, it\'s not "enterprise cloud", it\'s aws ecs cli service...
[2019-01-12 12:35:01] <SalathielGenese> The main idea was to have more logs - I don't know that specific tool
[2019-01-12 12:35:47] <danielWalker_twitter> So I've been testing from HOST using the mysql client and any attempts at localhost get rejected immediately, any attempts to connect to either A or B just hang completely  -_-
[2019-01-12 12:36:09] <wizardnet972> SalathielGenese: There is none.. :(
[2019-01-12 12:36:22] <SalathielGenese> Weird tool
[2019-01-12 12:36:25] <SalathielGenese> wizardnet972: 
[2019-01-12 12:38:32] <SalathielGenese> I see a--verbose, --debugoption [<-LINK->] @wizardnet972
[2019-01-12 12:41:07] <SalathielGenese> danielWalker_twitter: - Let me try it.My machine has a problem and I work using persistent live Ubuntu from my USB flash.Docker don't love my setup, so I'll start a GCloud Compute instance  - It may take a little while.
[2019-01-12 13:20:39] <SalathielGenese> danielWalker_twitter: - Here is what I did
[2019-01-12 13:20:54] <SalathielGenese>  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] Most interesting line being [<-CODE->] 
[2019-01-12 13:21:04] <danielWalker_twitter> Sorry I've been distracted slightly, here's what I get from my local after waiting for ages
[2019-01-12 13:22:08] <danielWalker_twitter> mysql -u test -p -h 172.28.0.3Enter password:ERROR 2003 (HY000): Can't connect to MySQL server on 'XXX.XX.XX.X' (60)
[2019-01-12 13:28:50] <SalathielGenese>  [<-LINK->] 
[2019-01-12 13:29:54] <danielWalker_twitter> I tried yours: [<-CODE->] 
[2019-01-12 13:30:26] <SalathielGenese> I'm exploring [<-LINK->] 
[2019-01-12 13:30:52] <danielWalker_twitter> that links a bit dodgy
[2019-01-12 13:34:39] <SalathielGenese> After I followed @torwy SO answer, I got this [<-CODE->]  [<-CODE->] 
[2019-01-12 13:35:18] <SalathielGenese> But restarting the service worked
[2019-01-12 13:35:35] <SalathielGenese> I'll check atawe_dbhost permissions
[2019-01-12 13:42:50] <SalathielGenese> Rejoyce @danielWalker_twitterIt is a matter of HOST authorization on mysql server (in the container)The following fails [<-CODE->]  [<-CODE->] While the following succeeds [<-CODE->]  [<-CODE->] 
[2019-01-12 13:45:15] <danielWalker_twitter> I get the same!
[2019-01-12 13:46:01] <danielWalker_twitter> but how do I change that?
[2019-01-12 13:46:14] <SalathielGenese> I'm working on that...
[2019-01-12 13:50:31] <danielWalker_twitter> me three
[2019-01-12 13:53:53] <SalathielGenese> I'm trying to run aGRANT ALL PRIVILEGES ON *.* TO 'username'@'localhost' IDENTIFIED BY 'password';at container start
[2019-01-12 13:54:22] <danielWalker_twitter> I'm trying the sha_password caching issue
[2019-01-12 13:54:29] <SalathielGenese>  [<-LINK->] 
[2019-01-12 13:55:56] <SalathielGenese> Oh - Someone even did it already - see [<-LINK->] answer. We just have to automate it
[2019-01-12 14:01:51] <danielWalker_twitter> I tried that solution but it didnt work for me
[2019-01-12 14:03:10] <danielWalker_twitter> are you sure that's the right approach as the OP was getting the error:Host '172.21.0.1' is not allowed to connect to this MySQL server
[2019-01-12 14:04:18] <danielWalker_twitter> and when Iitthe machine, connect to sql as root and do..
[2019-01-12 14:05:30] <SalathielGenese> I am sure because I can connect as root [<-CODE->]  [<-CODE->] 
[2019-01-12 14:07:51] <danielWalker_twitter>  [<-CODE->] 
[2019-01-12 14:09:49] <danielWalker_twitter> try:SELECT User, Host FROM mysql.user;requires root user
[2019-01-12 14:11:47] <danielWalker_twitter>  [<-CODE->] 
[2019-01-12 14:12:21] <SalathielGenese> Hmmmm
[2019-01-12 14:12:27] <danielWalker_twitter> I just realised@SalathielGenesewe might be bloating the channel here, shall we take it private and update the channel if we solve it?
[2019-01-12 14:13:39] <SalathielGenese> Could this help someone else ? No so many people searches Gitter history. But I am of those who do
[2019-01-12 14:14:12] <danielWalker_twitter> haha I don't mind either way, it gives people something to read I guess
[2019-01-12 14:14:38] <SalathielGenese>  Comme s'ils n'ennuyaient !
[2019-01-12 14:15:58] <danielWalker_twitter> haha fair enough :D as for this Hosts issue I can see your line of thinking but I
[2019-01-12 14:17:05] <danielWalker_twitter> maybe you're right
[2019-01-12 14:17:11] <danielWalker_twitter> I'm going to try that again
[2019-01-12 14:20:03] <SalathielGenese> Following [<-ISSUE->] 
[2019-01-12 14:21:28] <SalathielGenese> HeheJust a reminder that any scripts or sql files in /docker-entrypoint-initdb.d/ will only be run if there is no database (usually the first start of the container). Also, if you modify the contents of /docker-entrypoint-initdb.d/ while the entrypoint is looping over the files in there, it will not pick up any new files.
[2019-01-12 14:21:31] <SalathielGenese> brb
[2019-01-12 14:24:27] <danielWalker_twitter> no problem
[2019-01-12 14:25:37] <danielWalker_twitter> as for theinitdb.d/limitations that's fine with me, on first run I'll be backing up data but from that directory so running a script to grant access wont be a bother, I just need to get the access aha
[2019-01-12 14:27:34] <SalathielGenese> b
[2019-01-12 14:28:25] <danielWalker_twitter> wb
[2019-01-12 14:51:36] <SalathielGenese> I think I have something
[2019-01-12 14:57:50] <SalathielGenese>  [<-CODE->] (save the file with Ctrl+D) [<-CODE->]  [<-CODE->] Note I didn't exposed any port
[2019-01-12 15:01:56] <SalathielGenese> I personally take note that/docker-entrypoint-initdb.d/init.shwas executed, despite my default created user.So the above quote was not verified !
[2019-01-12 15:08:44] <SalathielGenese> Even shorter,@danielWalker_twitter, the./mysql/init.shfile
[2019-01-12 15:08:54] <SalathielGenese>  [<-CODE->] 
[2019-01-12 15:09:17] <danielWalker_twitter> trying it now
[2019-01-12 15:15:35] <danielWalker_twitter>  [<-CODE->] 
[2019-01-12 15:15:35] <SalathielGenese> As @adlawson commented,I'd also like to mention that if the query uses backticks, you need to quote the opening label: mysql << 'END'
[2019-01-12 15:15:48] <danielWalker_twitter> :[
[2019-01-12 15:17:00] <SalathielGenese> What ???
[2019-01-12 15:17:06] <SalathielGenese> :(
[2019-01-12 15:17:59] <danielWalker_twitter> I think there must be something stopping my HOST from accessing the docker network, I'm baffled, it clearly makes an attempt, it hangs for AGES!! then gives me that
[2019-01-12 15:18:48] <SalathielGenese> Can you ping172.17.0.2?
[2019-01-12 15:19:13] <danielWalker_twitter> request timeout :/
[2019-01-12 15:19:42] <SalathielGenese> That's a good hint. Isn't it ?
[2019-01-12 15:20:15] <danielWalker_twitter> It is :D
[2019-01-12 15:20:54] <SalathielGenese> Are you on Mac ?
[2019-01-12 15:21:06] <danielWalker_twitter> yes
[2019-01-12 15:21:15] <SalathielGenese> Hehehe
[2019-01-12 15:21:25] <danielWalker_twitter> lol
[2019-01-12 15:21:28] <SalathielGenese>  [<-LINK->] 
[2019-01-12 15:22:13] <danielWalker_twitter> ahhhhhh fml
[2019-01-12 15:22:22] <SalathielGenese> :)
[2019-01-12 15:30:30] <danielWalker_twitter>  [<-LINK->] 
[2019-01-12 15:31:07] <danielWalker_twitter> I tried that by adding [<-CODE->] 
[2019-01-12 15:31:15] <danielWalker_twitter> but no joy still
[2019-01-12 15:32:05] <SalathielGenese> Do you have any strong reason not to containerize your app ?
[2019-01-12 15:34:19] <SalathielGenese> There is also a pretty interesting discussion docker/docker#22753 about why there is no docker0 bridge to access containers directly. This comment suggests a workaround that might be good enough for your needs.https://stackoverflow.com/a/40334646/3748178
[2019-01-12 15:34:57] <danielWalker_twitter> I am in the process of containerizing the app, it\'s currently 4 services being run manually but at the same time I\'m trying rewrite this schema in the db, this is just me trying to make life "easier" (lol) for myself by getting the db service running locally and rewriting ("developing") the schema locally to avoid the constant issues I face with accessing the current service which is behind a firewall and I have a frequently changing ip -_-
[2019-01-12 15:36:21] <danielWalker_twitter> Im thnking at this point just resolving the issues to run it on my host would be simpler, hell a raspberry pi micro service in my pocket would be easier at this point, but docker wasn't working and I'm sure I've accessed other services this way before on previous projects so I really wanted to get to the bottom of it
[2019-01-12 15:37:22] <SalathielGenese> There are two options for you not to deal with changing IPDocker links\nDocker Compose links
[2019-01-12 15:37:30] <SalathielGenese> I would go for the latter
[2019-01-12 15:37:31] <danielWalker_twitter> hmm I tried the -P /--publish option and it failed me
[2019-01-12 15:37:33] <danielWalker_twitter> see the above
[2019-01-12 15:38:27] <danielWalker_twitter> also docker-compose should sort out that mapping automatically and it isn't working for me
[2019-01-12 15:39:30] <danielWalker_twitter>  [<-CODE->] 
[2019-01-12 15:39:54] <SalathielGenese> Try out docker-compose v2.1
[2019-01-12 15:40:22] <SalathielGenese> I was so disapointed when I migrated to 3.X
[2019-01-12 15:41:02] <SalathielGenese> Especially because I uselinksin combination ofdepends_on(and healthcheck along)
[2019-01-12 15:44:20] <danielWalker_twitter> I'll give that a go, if all else fails I'll throw my mac in a river and get a linux box
[2019-01-12 15:45:13] <danielWalker_twitter> I've got to go now Salathiel but you've been an amazing help today! Thank you for all the time you've spent on this and if there's anything I can do to repay you in future let me know
[2019-01-12 15:54:24] <SalathielGenese> I almost said to myselfI now know for sure the reason I never envied a MacBut  I wonder, how others Mac developers do ?
[2019-01-12 23:47:43] <srill-fb99_gitlab> Hello! Did anyone here ever tried to use the checkpoint functionality with an x application running in a docker and communicating with the host x server using something similar to this : [<-LINK->] ? I would be very happy to discuss around this topic
[2019-01-13 19:22:39] <fahman> Hi, in docker for windows I am trying to disable docker-kubernetes which is stuck for ever during boot. Since checkbox is disabled I can't do that and I find only old threads on how to kill the stuck kubernetes. Docker version: 2.0.0.0-win81  If someone could suggest how do disable the kubernetes would be great
[2019-01-14 16:38:03] <brian.kent_gitlab> Hi, is it possible to specifiy an enviornment variable in a docker compose file with periods (.) in the key name?
[2019-01-14 16:38:15] <brian.kent_gitlab> I just wantx.y=hello
[2019-01-14 16:38:47] <brian.kent_gitlab> I cannot get it to work using eitherenvironmentorenv_file.
[2019-01-14 16:43:48] <SalathielGenese>  [<-CODE->] Do you understand ? Did you got your answer ? And the WHY ?
[2019-01-14 16:44:41] <brian.kent_gitlab> I have an image that is expecting an environment variable that has a dot in it.
[2019-01-14 16:45:02] <rcjsuen> Fascinating
[2019-01-14 16:45:14] <brian.kent_gitlab> so I made a.envfile and the ones without a dot are passed fine, but the ones with the dots are just eaten
[2019-01-14 16:46:54] <SalathielGenese> Is it a public image? I am curious...I think however that it might be a typo and an underscore is expected_
[2019-01-14 16:48:48] <brian.kent_gitlab> it’s private unfortunately
[2019-01-14 16:51:01] <brian.kent_gitlab> it’s using a configuration library where the key can be overridden by environment variables
[2019-01-14 16:52:37] <SalathielGenese> OK - Another questionHow do you know it is expecting such a variable ? Any helpful command, screenshot, or is it a readme ?
[2019-01-14 16:53:04] <brian.kent_gitlab> because it works fine outside of docker and I am trying to dockerize it
[2019-01-14 16:53:24] <SalathielGenese> Is it a node JS app ?
[2019-01-14 16:53:49] <SalathielGenese> What's that variable name ?
[2019-01-14 22:24:22] <Caroga> Hi all! Shouldn't docker-compose also resolve variables in labels?
[2019-01-15 00:22:16] <royswastik> Hi, what's the correct way to update a secret in swarm?I know how to rotate it, but the secret name has to be changed after update. Is there a proper way to update the secret and maintain same name after updating?
[2019-01-16 04:05:01] <rdpanek> Hi, my Docker image contains application, which run on background and returns exit 0 and container is stopped. How ignore returned exit 0.
[2019-01-16 04:05:36] <rdpanek> I need the container not stopped.
[2019-01-16 11:16:16] <SalathielGenese> Hi@rdpanek
[2019-01-16 11:17:15] <SalathielGenese> When a docker container starts,The process resulting of CMD or ENTRYPOINT has PID 1
[2019-01-16 11:17:50] <SalathielGenese> When that process is terminated [whatever the reason], your container exits too.
[2019-01-16 11:18:35] <SalathielGenese> i.e If you don't want your container to exit, make sure the command at PID=1 won't die
[2019-01-16 11:26:48] <hochas> Is there a way to specify for which architecture to fetch an image in a Dockerfile?
[2019-01-16 12:44:23] <tim-klug> No I don't think so. Just by providing the specific tag
[2019-01-16 13:51:18] <SalathielGenese> Do you mean something likecode:carbon-alpineforAlpine Linux?
[2019-01-16 13:51:32] <SalathielGenese> hochas: 
[2019-01-16 14:00:29] <hochas> SalathielGenese: Right now I want to simply add jar file to ARM compatible image. I'm doing it like this right now:FROM arm32v7/openjdk:8-jdk-slim, but looking at the OpenJDK repo at docker hub, it seems like there is an official arm32v7 image, whereas the one I'm using is under community images.
[2019-01-16 14:20:47] <SalathielGenese>  [<-LINK->] 
[2019-01-16 14:22:28] <SalathielGenese>  [<-LINK->] 
[2019-01-16 14:23:32] <SalathielGenese> I clearly see what you mean@hochas
[2019-01-16 14:23:38] <SalathielGenese>  [<-LINK->] 
[2019-01-16 14:24:33] <SalathielGenese> But given the definition above, you can be sure the one you are using is the most official one for the peculiar platform you're on
[2019-01-16 14:24:42] <hochas> Exactly, but perhaps that is the intended use when it says that architecture is supported
[2019-01-16 14:41:40] <SalathielGenese> Per what I read, thelibraryrepo at docker serves what is official, or as close as possible if nothing official exists.
[2019-01-16 20:10:01] <roychri> There\'s a "Kubernetes Office Hours" in 50 minutes from now (4pm Eastern) where you can ask questions (in slack) and a group of experts will answer your questions.Live Streaming: https://www.youtube.com/c/KubernetesCommunity/live (4pm Eastern January 16th 2019)Slack to ask the questions: https://kubernetes.slack.com/messages/office-hoursMore information: https://github.com/kubernetes/community/blob/master/events/office-hours.md
[2019-01-16 23:19:44] <rdpanek> Hi, please help with host on OSX. How I can usehost.docker.internal? I can callcurl localhost:3000from container.Now it doesn't workcurl: (7) Failed connect to localhost:3000; Connection refused
[2019-01-17 00:17:38] <SalathielGenese> rdpanek: - I spent a whole Saturday discussing similar issue with@danielWalker_twitter-We landed to the conclusion that what you want to achieve isn't possible on MacOS -You can scroll up to read our discussion along the tries & failures -Or you can start by reading [<-LINK->] -
[2019-01-17 07:42:23] <rdpanek> SalathielGenese: hmmmm, but Thanks :-)
[2019-01-17 09:50:48] <amolnw2778_twitter> Downloaded latestDocker for Windows Installer.exebut it is not even opening the installer window to install the docker. Tried running as administrator as well. But nothing works. Is there any issue in the latestDocker for Windows Installer.exe?
[2019-01-17 10:10:49] <vsilent> danielWalker_twitter: did you check my.cnf  ,   what  bind-address =   option is set to
[2019-01-17 10:17:42] <vsilent> ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock    , through socket ?  you should try  --host=127.0.0.1  (tcp)
[2019-01-17 10:17:51] <vsilent> danielWalker_twitter: 
[2019-01-17 10:32:06] <vsilent> rdpanek: I would check incoming requests inside container,  possibly  connection was refused by your application server.
[2019-01-17 10:47:02] <lorenzocadamuro> Hello, I'm fighting with docker compose because I'm not able to access to wordpress running on my mac from another device. I see the HTML structure but It seems that it can't load resources.http://localhost:8000 works perfectlyhttp://192.168.1.169:8000 from my iPhone doesn't load resources like css, js and images(of course they are in the same network)here my configuration: [<-CODE->] 
[2019-01-17 10:51:01] <vsilent> lorenzocadamuro: ,  IMHO  it has nothing to docker-compose.  Check web server settings
[2019-01-17 10:57:19] <lorenzocadamuro> vsilent: I tried also to exit from the company network and use the hotspot of my iPhone to create an another one but nothing.  Do you think my problem is in my Mac  settings?
[2019-01-17 11:00:14] <vsilent> I am sure problem is not in docker-compose and docker.  In case you don't see static css/images it all related to nginx or apache configuration.
[2019-01-17 11:01:09] <vsilent> or wordpress
[2019-01-17 11:03:27] <lorenzocadamuro> vsilent: yeah but in this case is Docker that run the server and manage the apache configuration
[2019-01-17 11:09:00] <vsilent> in case you have wordpress up and running  (even without static)  means docker and docker-compose did their job.
[2019-01-17 11:11:03] <lorenzocadamuro> vsilent: I agree with you, but I think there's a sort of network problem that has to be handled in the docker compose file.
[2019-01-17 11:15:54] <vsilent> lorenzocadamuro: check this [<-LINK->] 
[2019-01-17 11:16:24] <vsilent> lorenzocadamuro: I guess it's your case
[2019-01-17 11:25:20] <lorenzocadamuro> vsilent: many thanks, it was Wordpress!
[2019-01-17 11:26:03] <vsilent> lorenzocadamuro: cool
[2019-01-17 11:30:37] <steevivo> Hi all, does anyone know launch a setup react native with docker ? any ressources recommend it or best practice ? thx for all
[2019-01-17 11:32:36] <smbss> Hi guys, I'm trying to know the total number of commits in a github organization with 50+ repos. Any idea how I can achieve that?
[2019-01-18 02:18:45] <akash.ma19_gitlab> hi, i am new to docker. i am following this tutorial - [<-LINK->] building using docker compose
[2019-01-18 02:19:02] <akash.ma19_gitlab> but i am getting wordpress access deniend using password yes error
[2019-01-18 02:19:09] <akash.ma19_gitlab> version: '3.3'services:   db:     image: mysql:5.7     volumes: [<-CODE->] wordpress:     depends_on: [<-CODE->] volumes:    db_data: {}
[2019-01-18 02:20:05] <SalathielGenese> You should wrap you code within triple back tick at the first line and three others at last line
[2019-01-18 02:26:09] <TheoNeUpKid88> akso-ak: it seems you’ve tried running the container previously. Try removing all containers and images thereof using ‘docker-compose rm -v’, which would remove mounted volumes and then try running docker-compose up -d again . The ‘d’ flag runs the process in the background and may not be necessary. Hope that helped.
[2019-01-18 02:26:28] <TheoNeUpKid88> Lol, though I was using back ticks
[2019-01-18 02:29:55] <SalathielGenese> I always chaindocker-compose down && docker-compose up --build(on Ubuntu)
[2019-01-18 02:34:39] <TheoNeUpKid88> SalathielGenese: you should usedocker-compose down -v, to bring down any mounted volumes though, I imagine it would depend
[2019-01-18 03:19:57] <akash.ma19_gitlab>  [<-LINK->] 
[2019-01-18 03:20:16] <akash.ma19_gitlab> i tried every above solution u guys provided
[2019-01-18 03:20:29] <akash.ma19_gitlab> is something wrong with office docs
[2019-01-18 03:21:55] <akash.ma19_gitlab> SalathielGenese: @TheoNeUpKid88@SalathielGeneseany one
[2019-01-18 03:22:08] <akash.ma19_gitlab> version: '3.1'services:  db:    image: mysql:5.7    environment:      MYSQL_DATABASE: wordpress      MYSQL_ROOT_PASSWORD: password      MYSQL_USER: admin      MYSQL_PASSWORD: admin123    ports: [<-CODE->] wordpress:    image: wordpress    ports: [<-CODE->] 
[2019-01-18 05:27:23] <TheoNeUpKid88> akash.ma19_gitlab: Looks like your missing a volume.                                                                                  `volumes:db_data:/var/lib/mysql`
[2019-01-18 05:42:13] <akash.ma19_gitlab> thnkx, i solved it...
[2019-01-18 05:42:44] <akash.ma19_gitlab> docker-compose downnot using this command
[2019-01-18 05:43:02] <TheoNeUpKid88> glad to help
[2019-01-20 04:07:48] <dragonpiper> how do i get docker to listen to my local address instead of localhost for docker for windows
[2019-01-20 05:47:02] <akash.ma19_gitlab> hi all,i am new to docker, so i am experimenting with docker.I have docker-compose.yml, in this i have nginx, phpmyadmin, wordpress and mysql image..i have defined all the url in nginx which will act as reverse proxy.for example for phpmyadmin i got to - localhost/phpmyadmin which is working perfect..the problem is with wordpress when i enter localhost/wp  it redirect to localhost/wp-admin.php
[2019-01-20 10:18:28] <akash.ma19_gitlab> how docker can be used between developers??dockerfile is used to create images and dockercompose file used to config multiple container…..now what??
[2019-01-20 11:26:40] <rcjsuen> I'm not sure I understand your question. You can share your Dockerfile with other people so they can build it.
[2019-01-20 11:26:58] <rcjsuen> Alternatively, people can pull your published images and use your image to create and launch a container.
[2019-01-20 14:15:59] <iamgilwell> akash.ma19_gitlab: do you have a repo with your docker files? yaml and dockerfile? if so just run docker-compose up ....  which application are you trying to dockerize?
[2019-01-20 14:52:23] <dragonpiper> Anyone have kubernetes setup experience ?
[2019-01-20 15:09:30] <mateothegreat> dragonpiper: all day long .. what’s the question?
[2019-01-20 15:50:54] <dragonpiper> so decided to jump into kubernetes for the first time. so far, I have a kubernetes cluster running.  I have a windows machine with docker.  docker is configured to run linux containers.   when i start kubelet i get [<-CODE->] 
[2019-01-20 15:52:42] <dragonpiper> @mateothegreatKube config [<-CODE->] 
[2019-01-20 15:53:30] <mateothegreat> did you use docker to setup kubernetes?
[2019-01-20 15:53:40] <mateothegreat> I’d highly recommend minikube at the least
[2019-01-20 15:57:44] <dragonpiper> One thing i was confused about. Is there any less services running on a cluster than a minion ? Would minikube be ran on the cluster manager and the nodes ?
[2019-01-20 15:58:13] <dragonpiper> Yea i enabled kubernetes on both the master and the node. I also have kubeadm
[2019-01-20 16:01:48] <dragonpiper> why doesn't it likeapps/v1and am i missing a key the defines the api server ?
[2019-01-20 16:15:30] <mateothegreat> don’t mix provisioners
[2019-01-20 16:24:32] <dragonpiper> What provisioners am i mixing ?
[2019-01-20 17:44:16] <agrwal.ysh94_gitlab> Does any know how to implement docker logging to s3 as in this [<-LINK->] 
[2019-01-20 23:57:42] <miguelreng> Hi! I'm Miguel Rengifo from Colombia, and with my friends of University, we created Poetri a FaaS workspace where you can deploy your functions and find others created by other developers. We want to get some feedback about our first beta. Would be nice if you help us with some comments/opinions [<-LINK->] 
[2019-01-21 00:35:51] <mateothegreat> miguelreng: you have a typo a the bottom .. "Create digital projects with low budget.” .. should be "Create digital projects with a low budget.
[2019-01-21 00:36:38] <mateothegreat> or “Anyone with an idea can change the world. Launch your project now.."
[2019-01-21 00:37:50] <mateothegreat> "Upload your functions to Poetri and pay for consumption” should say something like “Upload your functions to Poetri and pay only for what you consume."
[2019-01-21 00:44:28] <miguelreng> Thank you so much for this feedback, It will be so important for our product. We appreciate your help
[2019-01-21 06:20:23] <mjbright> Hi@miguelreng, great initiative, nice site too.  I saw that on the "For Developer" page there\'s a typo on the sign up button which says "Sing Up".  I sent an e-mail to the support e-mail address but it didn\'t get delivered.
[2019-01-21 11:30:55] <k318wilcoxa> hi everyone
[2019-01-21 15:03:29] <mcarpenterjr> Is it posible to set the startup order of containers? For instance we have a host that runs a number of caontainers, we have a; crm, gitlab instance, company calendar and a handfull of other document management containers as well as a portainer.io instance that run 24/7. In the case of host restarts all the containers restart at once, the minimal case that would be to have portainer start first and then everything else start second. A more ideal case would be if we could order the start of more important containers first, like portainer then gitlab and then our crm most of the other containers aren't that important and cna take their time starting.
[2019-01-21 16:33:52] <miguelreng> mjbright: Thanks!!!
[2019-01-21 21:31:00] <dragonpiper> is it possible for processes in a container to continue running after docker reports the container stopped  ?
[2019-01-22 03:11:14] <mateothegreat> dragonpiper: no.. what are you trying to accomplish?
[2019-01-22 03:17:30] <mateothegreat> mcarpenterjr: sounds like a good case to use Kubernetes
[2019-01-22 04:41:36] <onFireForGod_gitlab> hello everyone, is it possible to secure the contents of a docker container if I post it on public?
[2019-01-22 06:01:10] <sisimogangg> Post it on public ?
[2019-01-22 06:13:15] <onFireForGod_gitlab> Well like a container registry or somthing like that
[2019-01-22 06:13:35] <onFireForGod_gitlab> so people can use it
[2019-01-22 06:13:46] <onFireForGod_gitlab> but at the same time not see the contents inside of it
[2019-01-22 06:37:50] <mateothegreat> nope
[2019-01-22 06:38:06] <mateothegreat> your best bet is obfuscation of your code
[2019-01-22 06:38:13] <mateothegreat> but no guarantees
[2019-01-22 06:44:02] <dragonpiper> mateothegreat: asked because app seemed to be finding a process with my pid even after a restarting the container but i have to look into it more
[2019-01-22 06:47:32] <dragonpiper> Also I had a question about volume plugins. I started this plugin via the daemon method then created a volume pointing to my ftp server.  After mounting volume to the container and creating files, i expected them to be persisted on my ftp server but they only seem to exist in the local copy of the volume. Is this an issue with the plugin itself ? Are there any other plugins that support an ftp store ?
[2019-01-22 07:00:45] <mateothegreat> not that I know of
[2019-01-22 07:01:05] <mateothegreat> sounds like a good case for NFS eh
[2019-01-22 07:02:19] <dragonpiper> If i go that route whats a good volume plugin for it ?
[2019-01-22 07:05:37] <dragonpiper> Or can i mount a nfs volume without a plugin
[2019-01-22 07:07:56] <mateothegreat> docker has native support for nfs volume types
[2019-01-22 07:08:14] <mateothegreat>  [<-CODE->] 
[2019-01-22 07:08:36] <dragonpiper> ah, nice
[2019-01-22 07:26:21] <dragonpiper> how do i know it's able to connect to it properly ?
[2019-01-22 07:27:45] <mateothegreat> put a file on it
[2019-01-22 07:27:47] <mateothegreat> lol
[2019-01-22 07:27:58] <mateothegreat> or check docker daemon logs
[2019-01-22 07:34:24] <dragonpiper> lol well the other plugins gave no error and it was failing. I guess i will test it out apnar/nfs-ganesha and see what happens
[2019-01-22 07:49:12] <dragonpiper> hm, i getdocker: Error response from daemon: error while mounting volume with options: type='nfs' device=':/' o='addr=localhost': operation not supported.
[2019-01-22 07:49:40] <dragonpiper> How does that mean it got as far as connecting ? if i use my local ip address instead i get connection refused
[2019-01-22 07:50:37] <mateothegreat> are you running an nfs server?
[2019-01-22 07:52:21] <dragonpiper> yea running thisdocker run --name nfs -v /nfs-dir:/export mitcdh/nfs-ganesha
[2019-01-22 07:54:47] <mateothegreat> you’re not exposing the nf server ports?
[2019-01-22 07:55:14] <dragonpiper> only exposing 2049
[2019-01-22 09:36:31] <dragonpiper> Tried a different image. Now i'm getting [<-CODE->] 
[2019-01-22 13:13:42] <mcarpenterjr> mateothegreat: Really? I'll check it out. thanks.
[2019-01-22 14:51:46] <danielWalker_twitter> vsilent: Hey dude, sorry I've been afk for a few days, I haven't tried that, I'll give it a go this evening
[2019-01-22 21:12:16] <robfr77>  [<-CODE->]  [<-CODE->] I read on Stack Overflow that bundler is not included with ruby image
[2019-01-22 21:12:41] <mateothegreat> install rails
[2019-01-22 21:13:25] <robfr77> It is installed locally, the issue is just with docker. Do I haveRUN bundler installin the wrong spot?
[2019-01-22 21:16:46] <mateothegreat> RUN gem install bundler
[2019-01-22 21:17:26] <robfr77> Yeah just found that online :D should work
[2019-01-22 21:17:42] <mateothegreat> woohoo!
[2019-01-22 21:18:48] <mateothegreat>  [<-CODE->] 
[2019-01-22 21:19:30] <robfr77> Still same error :(I putRUN gem install bundler -v 1.17.2before theRUN bundler install
[2019-01-22 21:35:21] <robfr77> I included bothRUN gem install bundlerandRUN gem install railsand then it said it could not find rake...Now tryingRUN gem install bundlerand ??
[2019-01-23 05:54:34] <FranckyU> robfr77: the right command isbundlenot bundler
[2019-01-23 09:39:29] <akash.ma19_gitlab> still i am not getting…i have 2 droplet (digital ocean)to run docker swarm in production…do i have to create vm in one droplet then spin up the container??
[2019-01-23 15:27:46] <mateothegreat> akash.ma19_gitlab: basically
[2019-01-23 15:27:56] <mateothegreat> akash.ma19_gitlab: I’d use kubernetes instead of swarm
[2019-01-23 15:28:09] <mateothegreat> DO has a pretty easy implemntation
[2019-01-24 14:43:26] <tosolveit> Hi everyone,I have a very simple python script, not a web app, it runs based on some arguments and returns something, I run it with “docker run —rm -it my_image:v1 python mydir/app.py”, I see that host folder that I added as a volume can’t be find in the container.To test it, I created a python hello world flask app and run it with docker-compose up, in this case volumes are working fine, changes in the host machine is reflected to the running container. But this  doesn’t look a good solution to me.Is there a way to run the app with “docker run —rm -it my_image:v1 python mydir/app.py” and use volumes so if I change a file in the host, python mydir/app.py will consume the right content.I worked hours on that, tried adding volume on the fly with -v parameter, used docker compose, only Dockerfile with volume description etc.I’ll be appreciated if at least you can share some docs, blogs or ideas.Regards!
[2019-01-24 14:43:58] <rcjsuen> -vshould work...
[2019-01-24 14:44:26] <SalathielGenese> see that host folder that I added as a volume [···]Where did you added that volume ?
[2019-01-24 14:44:28] <rcjsuen> I don't see any-vin your exampledocker runcommand
[2019-01-24 14:45:09] <SalathielGenese> As@rcjsuenemphasises, read docker docs how to mount volumes with-vand mount your volume
[2019-01-24 14:45:36] <SalathielGenese> Supposing you really mean volume AND NOT the result of dockerCOPY/ADD
[2019-01-24 14:45:43] <rcjsuen> Good point
[2019-01-24 14:47:26] <tosolveit> I build the container with docker compose like this, Do I have to define the volume at runtime?
[2019-01-24 14:47:43] <rcjsuen> You should use three backticks, ```
[2019-01-24 14:47:47] <tosolveit> Sorry :)
[2019-01-24 14:47:49] <rcjsuen> or a classic pastebin could work too
[2019-01-24 14:50:12] <SalathielGenese> See this volume usage for NodeJS app [<-CODE->]  [<-CODE->] 
[2019-01-24 14:51:35] <tosolveit> I feel very stupid now, oh god, I couldn’t paste the code :)
[2019-01-24 14:51:46] <tosolveit> Ok, I will check the example, thanks a lot
[2019-01-24 14:52:10] <SalathielGenese> Why using volume in a compose (docker-compose) file ?When one need inodes (files & folders) update on host to be instantly reflect in container
[2019-01-24 14:53:35] <SalathielGenese> For example, during development, I run almost everything with the container but I edit files on hostMy setup use tools like nodedemon to watch inode changes and restart my app or my tests immediatelyIt saves me from restarting my container after each and every change
[2019-01-24 14:54:01] <tosolveit> I got it, thanks for detailed explanation, let me try
[2019-01-24 17:34:51] <stephansnyt> i have docker running on a server. on the server i candocker pull $private. if i then have a remote client, i candocker run $privateas long as the image is already there, but if i have to pull it, does that authentication occur on the client or server side?
[2019-01-24 18:01:29] <c16a> Hi, I'm having a weird issue with using the official Golang docker image.
[2019-01-24 18:01:44] <c16a>  [<-CODE->] 
[2019-01-24 18:02:06] <c16a> The above step gets stuck at the firstgo get -uRUNcommand.
[2019-01-24 18:02:14] <c16a> Am I missing something trivial here?
[2019-01-24 18:02:42] <c16a> Samego get -uworks on my macOS host. I didn't set up any proxies for Docker as well.
[2019-01-24 18:07:25] <c16a> FYI, I also tried aRUN ping www.google.comto confirm the container can access the internet.
[2019-01-24 18:07:40] <c16a> pingseems to work, but notgo get -u
[2019-01-24 21:37:06] <SalathielGenese> stephansnyt: auth occurs on the host which runs the command -And hope this help
[2019-01-25 10:41:04] <vsilent> munukutla:  [<-LINK->] gives 404
[2019-01-25 10:42:04] <vsilent> same for other links
[2019-01-25 18:05:37] <silpack69> silpack69: im tryna figure out eslint extension on vscode with eslint lint installed on a nodejs container in dockeris it possible or do i have to npm install locally in my system?
[2019-01-26 02:03:08] <mateothegreat> silpack69: if you want to run eslint from inside your container, add it to your dependencies
[2019-01-26 07:41:01] <silpack69> ya but is there a way to access that eslint inside the container for eslint extension in vscode running  locally on the system outside the container?
[2019-01-26 07:43:06] <mateothegreat> silpack69: I highly doubt that unless you’re using the node debugger
[2019-01-26 13:05:05] <silpack69> oh okay. thanks anyways
[2019-01-26 13:09:05] <SalathielGenese> silpack69: - [<-LINK->] 
[2019-01-26 13:12:09] <SalathielGenese> And i have to bet you madenode_modules/persistent (i.e not present on host but ONLY in the container)
[2019-01-26 13:15:54] <SalathielGenese>  [<-LINK->] 
[2019-01-26 14:26:43] <silpack69> SalathielGenese: yup thats true.
[2019-01-26 14:37:26] <silpack69> the extension that you mentioned seems to be the right way to go but its only for perl, php, python and/or ruby. no JS
[2019-01-26 16:38:26] <nerdo> Hey peoples
[2019-01-26 16:39:24] <mateothegreat> sup
[2019-01-26 16:39:31] <nerdo> I'm a docker newb, and, I'm probably doing something wrong and not realizing it, but one thing I noticed right away is a weird quirk with running docker commands wihtin a tmux session.
[2019-01-26 16:39:45] <mateothegreat> permission denied? heh
[2019-01-26 16:40:27] <nerdo> No, not permission denied. I built the image and ran it fine within that pane in my session, but if i were to switch panes or even just open a new terminal altogether the image didn't seem to exist. it was weird
[2019-01-26 16:40:33] <nerdo> I'm not really sure why that is
[2019-01-26 16:40:57] <mateothegreat> what dockerdocker imagessay in your other terminal?
[2019-01-26 16:41:00] <mateothegreat> impossible I say!
[2019-01-26 16:42:03] <nerdo> Different results depending on the pane. I would agree if I didn't experience it lol: [<-LINK->] 
[2019-01-26 16:42:31] <nerdo> I actually just ended up building the image i wanted outside of a tmux session but I was looking for an explanation
[2019-01-26 16:42:32] <vsilent> haha :) ,  it's impossible.  Check where you are in both panes with  $>  pwd
[2019-01-26 16:43:02] <nerdo>  [<-LINK->] 
[2019-01-26 16:43:06] <nerdo> same dir
[2019-01-26 16:43:07] <vsilent> but anyway as@mateothegreatsays docker images should show
[2019-01-26 16:43:23] <mateothegreat> cat ~/.docker/config.jsonin both .. see any difference?
[2019-01-26 16:43:26] <nerdo> I agree, but it wasn't. No idea why
[2019-01-26 16:43:35] <mateothegreat> are you using any virtual env’s?
[2019-01-26 16:43:49] <mateothegreat> Also runexport|grep -i dockerin both
[2019-01-26 16:44:05] <nerdo> Nope, samesies: [<-LINK->] 
[2019-01-26 16:44:33] <nerdo> oh wait
[2019-01-26 16:44:43] <mateothegreat> dum dum DUMMMM...
[2019-01-26 16:44:51] <nerdo> my ohmyzsh status line points out the difference
[2019-01-26 16:45:04] <nerdo> Looks like i'm still connected to myvm1 in one of the sessions
[2019-01-26 16:45:14] <nerdo> from when I was going through the tutorial
[2019-01-26 16:45:19] <mateothegreat> Source’in like a boss heh
[2019-01-26 16:45:23] <nerdo> haha
[2019-01-26 16:45:38] <mateothegreat> crisis averted whew
[2019-01-26 16:45:41] <nerdo> Like I said before, I was probably doing something wrong lol
[2019-01-26 16:45:52] <nerdo> that's a docker subtlety I'll need to pay attention to
[2019-01-26 16:46:18] <mateothegreat> all good .. glad you’re back in action
[2019-01-26 16:46:37] <nerdo> Thanks, and thanks for helping troubleshoot :)
[2019-01-26 16:46:39] <vsilent> :)
[2019-01-26 16:46:50] <nerdo> I will have lots more quetsions lol
[2019-01-26 17:37:59] <SalathielGenese> @silpack69 - Well, Here's how I circumvent this. [<-CODE->] As a result, eslint exist on host but other dependencies don't.NOTE : Next time the app image is built eslint will also be added to the container,but on your host's node_modules/ folder, you'll only get eslint and its related dependencies. [<-CODE->] 
[2019-01-26 18:56:02] <nerdo> I'm not sure if this is possible but I have to ask. I'm trying to use docker to set up dev environments for my teammates and I. I know it's simple to map ports, but I'm wondering if there is a way to easily set up dnsmasq using docker so that, for example, pointing my browser towebsite.testwill always point to thexyzwebsite service?
[2019-01-27 02:17:34] <akash.ma19_gitlab> how docker able to scale mysql.....I have to scale mysql service 10...how data is sync btw all the nodes
[2019-01-27 06:42:18] <akash.ma19_gitlab> docker wordpress -
[2019-01-27 06:42:26] <akash.ma19_gitlab> not sharing volume
[2019-01-27 06:42:46] <akash.ma19_gitlab> I want all my upload to docker volume and want to scale
[2019-01-27 15:47:10] <akash.ma19_gitlab> docker swarm persistence storage??Any solution
[2019-01-27 15:47:10] <akash.ma19_gitlab> ?
[2019-01-27 15:49:15] <develroo> Cephfs and proxmox
[2019-01-27 15:49:46] <akash.ma19_gitlab> develroo: thankx
[2019-01-28 07:01:51] <silpack69> SalathielGenese: so the eslint still needs to be on the host  i guess thats what i will go with then until someone comes up with an extension for js similar to one you mentioned earlier. thanks for your time
[2019-01-28 09:24:42] <SalathielGenese> Yep' ESLint need to be on host@silpack69You're welcome !
[2019-01-28 14:31:28] <thegtagamer> Hello Guys, My meteor application takes a lot of time to build inside a container in a production environment, Is there any way i can speed it up
[2019-01-28 14:32:04] <thegtagamer> Using 2 CPU's 4 GB Memory and 1 Gb Swap memory
[2019-01-28 14:32:16] <briancaffey_gitlab> thegtagamer: do you have a.dockerignorefile?
[2019-01-28 14:32:25] <thegtagamer> briancaffey_gitlab: yep
[2019-01-28 14:32:56] <thegtagamer> .meteor/local.build.build..npm.git.build.logDockerfileDockerfile-devserver.reaction/docker/reaction.docsnode_modulespackages//.npmpackages//lib/bower
[2019-01-28 14:33:07] <thegtagamer> contents of my .dockerignore
[2019-01-28 14:33:41] <rcjsuen> How long is "a lot of time"? And what does it look like it\'s spending the most time on? Can you share yourDockerfile?
[2019-01-28 14:33:55] <thegtagamer> More than 45 mins
[2019-01-28 14:34:07] <rcjsuen> Everything is relative, how long does it take you to do it on your computer?
[2019-01-28 14:34:26] <thegtagamer> without Docker it is pretty fast..around 5-7 minutes
[2019-01-28 14:34:26] <rcjsuen> Are you doing anychown? IIRC there is a slowness with recursivechown
[2019-01-28 14:34:31] <thegtagamer> yes
[2019-01-28 14:34:39] <thegtagamer> I am
[2019-01-28 14:35:16] <rcjsuen> ah, here it is >> [<-ISSUE->] 
[2019-01-28 14:35:34] <rcjsuen> I guess you can try...not doingchownand see what happens (though perhaps it makes your build obsolete)
[2019-01-28 14:35:51] <rcjsuen> But again, I would look at the build logs to see where it's taking up time. Unless you are already implying thechownis what is taking up the time
[2019-01-28 14:37:17] <thegtagamer> okay
[2019-01-28 14:37:26] <thegtagamer> Lemme dig out the build logs
[2019-01-28 14:37:31] <rcjsuen> We may be barking up the wrong tree here :)
[2019-01-28 14:37:51] <thegtagamer> Step 15/28 : RUN meteor build ../my-app --directory --architecture os.linux.x86_64 ---> Running in 34513c7fcbb7app/client/plugins.less.css: warn: There are some @import rules those are not taking effect as they are required to be in the beginning of the file.Node#moveTo was deprecated. Use Container#append.app/client/plugins.less.css: warn: There are some @import rules those are not taking effect as they are required to be in the beginning of the file.
[2019-01-28 14:37:59] <thegtagamer> This is where it stucks at
[2019-01-28 14:38:23] <thegtagamer> and sometimes it fails with
[2019-01-28 14:38:37] <thegtagamer> Node#moveTo was deprecated. Use Container#append.app/client/plugins.less.css: warn: There are some@importrules those are not taking effect as they are required to be in the beginning of the file.The command '/bin/sh -c meteor build ../my-app --directory --architecture os.linux.x86_64' returned a non-zero code: 137
[2019-01-28 15:46:17] <robfr77> I am trying to set up bundler to work correctly with docker in a rails app (Right now I have to run bundle exec rails for everything), following this documentation on [<-LINK->] Is GEM_HOME the same as the GEM_HOME returned inrvm info?Also, looking atPATH $GEM_HOME/bin:$GEM_HOME/gems/bin:$PATHbut not sure about how this works because my $GEM_HOME directory has a bunch of gems directories all with distinct bins. Thanks for any advice.
[2019-01-29 14:49:55] <CharcoGreen> Hi mens,  I have a question. For production is better, volume or bind?
[2019-01-30 00:04:01] <roychri> CharcoGreen:  [<-LINK->] 
[2019-01-30 06:13:30] <vamsiaila> helllo
[2019-01-30 06:14:05] <vamsiaila> i have a file named Dockerfile
[2019-01-30 06:14:20] <vamsiaila> i did not have any other files
[2019-01-30 06:14:30] <vamsiaila> i have docker-ce installed
[2019-01-30 06:14:35] <vamsiaila> how to start
[2019-01-30 07:24:59] <appareddyraja> Hi all
[2019-01-30 07:25:47] <appareddyraja> is there any way to pull  images from my private registry without mentioning url ?
[2019-01-30 07:26:21] <appareddyraja> docker pull <host>:<port>/<dockerImage>
[2019-01-30 07:26:43] <appareddyraja> not like the above mentioned command
[2019-01-30 08:40:54] <byakoshiki_twitter> hello, does docker documentation explain more in depth how to make 2 containers see each other in the docker network?
[2019-01-30 08:41:14] <byakoshiki_twitter> i have read about default bridge mode and--linkoption
[2019-01-30 08:41:19] <byakoshiki_twitter> but is it all?
[2019-01-30 08:42:35] <vsilent> vamsiaila: docker build  -t myimage  .
[2019-01-30 08:44:00] <vsilent> byakoshiki_twitter:  [<-LINK->] 
[2019-01-30 13:57:18] <seekheart> hi guys
[2019-01-30 14:41:53] <rcjsuen> Hi
[2019-01-30 14:42:47] <CharcoGreen> roychri: thanks !
[2019-01-30 18:26:55] <byakoshiki_twitter> Hi now time for some docker stuff. Where should i make project dir that i could later use in compose file and hold my dockerfiles?
[2019-01-30 18:56:24] <byakoshiki_twitter> vsilent: are you here maybe?
[2019-01-30 19:15:57] <byakoshiki_twitter> Okay i figured out that directory comes from PC not from docker
[2019-01-30 19:16:48] <byakoshiki_twitter> although, i set up the wordpress as instruction said, but after seeing those docker files i am kinda lost in amount of commands that they require
[2019-01-31 11:33:58] <vsilent> byakoshiki_twitter: depends on your plans on your project. In case you are going to do development or education it\'s better IMHO  to keep config files on host machine and mount it to container.  In "production" case you will need to choose from  "docker config" /consul  etc..  or again mount to host machine
[2019-01-31 11:37:30] <byakoshiki_twitter> vsilent: how can you mount to docker?
[2019-01-31 11:43:31] <vsilent> byakoshiki_twitter:  [<-LINK->] 
[2019-01-31 12:13:40] <akash.ma19_gitlab> I have 7 digital ocean droplet...droplet1 - I made it docker leaderdroplet2 and droplet3 are managerother's are workerwhen I run container such as node server on port 6777 and docker mrphone_visualizer on 8080And when hit ip of leader with port 8080/6777 no response but I hit ip of any worker with port 8080/6777 it works...why leader ip not responding??using docker swarm
[2019-01-31 12:14:43] <akash.ma19_gitlab> anyone ??
[2019-01-31 12:14:56] <mateothegreat> Coughkubernetescough
[2019-01-31 12:15:30] <akash.ma19_gitlab> docker swarm using
[2019-01-31 12:15:54] <akash.ma19_gitlab> please help
[2019-01-31 12:30:26] <mateothegreat> dunno, I ditched swarm a long time ago
[2019-01-31 12:30:38] <mateothegreat> but iirc your services shouldn’t be running on a master node
[2019-01-31 12:48:34] <byakoshiki_twitter> mateothegreat: is kubernetes better than swarm? Also Daremomita here o/
[2019-01-31 12:48:44] <mateothegreat> o hell yea
[2019-01-31 12:48:57] <byakoshiki_twitter> good because i have book of it
[2019-01-31 12:49:00] <mateothegreat> it will replace swarm I’d put money on it
[2019-01-31 12:49:32] <byakoshiki_twitter> okay but in nutshell what does swarm and kuber?
[2019-01-31 12:49:51] <byakoshiki_twitter> mateothegreat: 
[2019-01-31 12:50:49] <mateothegreat> huh?
[2019-01-31 12:54:00] <byakoshiki_twitter> in short what they do?@mateothegreat
[2019-01-31 12:56:45] <mateothegreat> Kubernetes, and swarm, are “docker orchestrators"
[2019-01-31 12:56:53] <mateothegreat> managing the lifecycle of docker containers
[2019-01-31 12:57:02] <mateothegreat> annd scheduling of containers
[2019-01-31 12:59:32] <akash.ma19_gitlab> mateothegreat: problem was with firewall I open the docker swarm port which need to be communicate
[2019-01-31 12:59:40] <akash.ma19_gitlab> kubernet
[2019-01-31 13:02:14] <mateothegreat> swarm has nothing to do with kubernetes
[2019-01-31 16:11:59] <akash.ma19_gitlab> how to serve static file when using docker cluster mode??
[2019-01-31 16:12:09] <akash.ma19_gitlab> 3party is not working
[2019-02-01 22:47:21] <dbjpanda> Hi, Any help on this issue [<-ISSUE->] .  Is it possible to enable ACL on bind mounted volume ?
[2019-02-01 23:13:55] <dbjpanda> thaJeztah: ping
[2019-02-01 23:24:53] <dbjpanda> Hi community members, Here is one interesting event/ activity Google summer of Code  ( [<-LINK->] ) that will surely help Docker  move a step ahead. This activity is hosted by Google every year.  There are many more open source org like Linux, Drupal participate in the same.  In this activity university students are selected to work on a project and mentors from the organisation are assigned to help them.  I have been involved as a mentor with Drupal since 2 years.   I exactly don't know to whom I should contact ? But I would love to see Docker in one of the participating Org this year.  Any docker community volunteer interested for the same ?
[2019-02-01 23:30:44] <dbjpanda> The last date to register as a mentoring organisation is Feb 7 2019 . So lets have some discussion and team up.  Feel free to PM me.
[2019-02-01 23:31:08] <mateothegreat> dbjpanda: are you asking for individual contributors or?
[2019-02-01 23:35:34] <dbjpanda> mateothegreat: Individual contributors are welcome.  As per the guideline  Open source projects apply to be mentor organizations. Once accepted, organizations discuss possible ideas with students and then decide on the proposals they wish to mentor for the summer. They provide mentors to help guide each student through the program.
[2019-02-01 23:36:04] <mateothegreat> I’d be a mentor
[2019-02-01 23:38:41] <dbjpanda> So individual contributors who have contributed to Docker  previously and at least can guide a student are welcome. However we need minimum 5 contributors  to eligible for a mentoring organisation. I would request to go through the details of the FAQ section.
[2019-02-01 23:39:49] <dbjpanda> mateothegreat: Can I pm you ?
[2019-02-01 23:40:20] <mateothegreat> dbjpanda: sure
[2019-02-01 23:49:47] <dbjpanda> Any developer/ contributor involved with Docker  core or related projects can help in this case. :)
[2019-02-02 13:54:20] <nerdo> Please tell me if this is a bad idea or if there is another way to accomplish this, but I am trying to set up a dev environment with docker. In it there are apache virtual hosts on the domain.wordpress.testand so I want to use dnsmasq in a container to resolve all of those (amongst other domains) to the appropriate docker container. When MacOS is a host system, I think I can easily accomplish this by writing to/etc/resolver/*to send specific dns lookups to the dnsmasq container, but I’m wondering if there is a way to set that up for windows im an automated way. I know the docker mantra is write once, run anywhere, but I guess this implies that I would have to make a distinction between host platforms. Is this feasable? Is there a better way? i’m trying to make this as zero-config as possible
[2019-02-02 14:18:28] <mateothegreat> sounds like a DNS problem
[2019-02-02 14:18:36] <mateothegreat> Not a docker problem right
[2019-02-02 14:24:06] <nerdo> Yes, but I am trying to use a docker container running dnsmasq so that once you spin up the dev environment, everything, including dns will work
[2019-02-02 14:24:28] <nerdo> Is that something better left as a manual process?
[2019-02-02 14:27:03] <nerdo> I haven’t fully set it up yet, but I’m confident I can automate it with docker on a linux or mac os host but since windows doesn’t seem to have an equivalent to/etc/resolvers, that’s where I’m looking for a solution
[2019-02-02 14:31:43] <nerdo> I get that this isn’t really a docker issue, but I’m looking for advice on how to approach this. What I’m hearing is that I should probably leave configuring the host dns to the user?
[2019-02-02 15:03:59] <mateothegreat> yep :)
[2019-02-02 16:08:26] <nerdo> Thanks
[2019-02-02 16:38:17] <matrixbot> queen_emmahey
[2019-02-02 17:13:46] <TrevorKS> Still learning docker but i came across a issue trying to get a build to work. I'm trying to install SecurityCenter-5.8.0-el7.x86_64.rpm in a docker CentOS container, which should be launching a webadmin GUI on port 433. Im getting the Security Center to service to start, but it exits immediately (not the container, just the service).
[2019-02-02 17:14:34] <TrevorKS> My Docker file and 'systemctl status SecurityCenter' are supplied here on a stack exchange question, any clue on why this could be?
[2019-02-02 17:14:35] <TrevorKS>  [<-LINK->] 
[2019-02-02 17:18:09] <matrixbot> queen_emmahey guys I dunno if you know this university, but if you do, I would lie to know more about it, if you have info., its the University of Saint Andrews in Scottland.
[2019-02-02 17:19:02] <mateothegreat> TrevorKS: your container is exiting because there is no command left running from either a CMD … or ENTRYPOINT
[2019-02-02 17:19:27] <mateothegreat> add something likeENTRYPOINT [“cat”]to your Dockerfile
[2019-02-02 17:19:40] <mateothegreat> orENTRYPOINT [“tail”, “-f”, “/dev/null”]
[2019-02-02 17:20:01] <mateothegreat> Ideally you would have a script that starts the daemon directly and keeps it from going into the background
[2019-02-02 17:20:06] <mateothegreat> make sense?
[2019-02-02 17:22:04] <TrevorKS> I get what your saying yes, but the container itself it not exiting, just the service (atleast i think it is). Container is still showing running with 'docker ps'.
[2019-02-02 17:22:12] <mateothegreat> ahh
[2019-02-02 17:22:23] <mateothegreat> what does your logs say?
[2019-02-02 17:22:35] <mateothegreat> (inside the container .. /var/log/messages)
[2019-02-02 17:22:57] <TrevorKS> Have never even thought to check, i will take a look.
[2019-02-02 17:23:04] <TrevorKS> Not sure if it matters, but when i run 'docker run secuirycenter' , the container starts but my prompt never returns.
[2019-02-02 17:23:18] <mateothegreat> you can also get stdout and stderr fromdocker logs -f <container name>
[2019-02-02 17:23:50] <mateothegreat> docker run -it <containername> <command>
[2019-02-02 17:23:59] <mateothegreat> -i = interactive and -t = get a tty
[2019-02-02 17:33:44] <TrevorKS> I was hoping by running 'docker run securitycenter' that the image would start and run the security center service and return me back to my host propt. When i mean it doesnt return, looks like this [<-LINK->] . There doesn't seem to be a /var/log/messages in the docker container.
[2019-02-02 17:35:36] <TrevorKS> I was expeting it to return like this [<-LINK->] . Not sure if thats an issue?
[2019-02-02 17:56:43] <byakoshiki_twitter> Okay hmm...if my laptop has in bios only visible option as VT-d can i run docker on vms?
[2019-02-02 18:08:52] <mateothegreat> TrevorKS: use a -d with your docker run
[2019-02-02 18:09:07] <mateothegreat> byakoshiki_twitter: what OS?
[2019-02-02 18:25:05] <TrevorKS> -d did make it return like i expected, Thanks.
[2019-02-02 18:25:17] <TrevorKS> Still trying to figure out why the service is exiting.
[2019-02-02 19:37:40] <TrevorKS> Does comparing a functional 'systemctl status SecurityCenter' to  the container show any light on my problem? Do i need to edit my dockerfile start up a httpd deamon? I feel like that may be the issue, but not sure how to solve.
[2019-02-02 19:37:58] <TrevorKS> Functional (running) - [<-LINK->] 
[2019-02-02 19:38:22] <TrevorKS> Container (exited) - [<-LINK->] 
[2019-02-02 20:24:03] <mateothegreat> TrevorKS: when things are “running” … show me the outputs ofps auxfw
[2019-02-02 21:28:56] <TrevorKS> Sorry, i may have made it unclear make it clear, the "running" was a screenshot from a VM to illustrate what a successful install looks like.
[2019-02-02 21:30:01] <TrevorKS> I made a post here on docker fourms here with lots of detail. [<-LINK->] 
[2019-02-02 21:34:13] <mateothegreat> TrevorKS: add this to the bottom of your dockerfile and try again: `ENTRYPOINT [“tail”, “-f”, “/dev/null”]
[2019-02-03 04:58:35] <nerdo> Question: is there a way to run a command aside from CMD or ENTRYPOINT? I basically want to curl a url whenever some containers start up but don't want to have to create an entirely new dockerfile for a container that i'm using from a public repo
[2019-02-03 04:59:09] <nerdo> It looks like i might be able to get away with using healthcheck, but that would be a hack (because the command I want to run isn't actually a health check), but I'm looking for something along those lines
[2019-02-03 05:29:19] <nerdo> hmm
[2019-02-03 05:45:40] <nerdo> actually, nevermind
[2019-02-03 11:26:28] <byakoshiki_twitter> if i upload image to repo with its tag, can i remove that image from local storage?
[2019-02-03 11:40:52] <byakoshiki_twitter> okay different question...
[2019-02-03 11:42:35] <byakoshiki_twitter> i have official wordpress image installed, but i forgot (or not saved it) password for the admin account (which i kinda need)
[2019-02-03 11:42:48] <byakoshiki_twitter> how can i restore that image to factory 0?
[2019-02-03 11:49:46] <byakoshiki_twitter> okay i found the master password
[2019-02-03 17:19:20] <TrevorKS> mateothegreat: adding the entry point to the existing dockerfile actually made the container exit immediatly :(
[2019-02-03 17:35:30] <nerdo> dangit, I just realized that I can't access containers by their internal IPs on mac :| and I just set up this whole dnsmasq container to handle resolving those. Guess I'm gonna do this with an nginx reverse proxy instead
[2019-02-03 17:40:35] <TrevorKS> should i be running 'yum update' or 'apt upgrade' in a Dockerfile? or is that bad practice
[2019-02-03 17:41:39] <nerdo> I remember reading somewhere in the docker docs  that runningapt upgradeis probably not a good idea, but I'm a newb, so please, take that with a grain of salt and do a little more research :)
[2019-02-03 17:46:36] <TrevorKS> I believe i have read that somewhere also.
[2019-02-03 17:47:11] <nerdo>  [<-LINK->] 
[2019-02-03 17:47:28] <nerdo> Avoid RUN apt-get upgrade and dist-upgrade, as many of the “essential” packages from the parent images cannot upgrade inside an unprivileged container. If a package contained in the parent image is out-of-date, contact its maintainers. If you know there is a particular package, foo, that needs to be updated, use apt-get install -y foo to update automatically.
[2019-02-03 17:48:26] <TrevorKS> This came up in my build logs when running 'yum upgrade'
[2019-02-03 17:48:28] <TrevorKS> Updating   : systemd-219-62.el7_6.3.x86_64                               6/28Failed to get D-Bus connection: Operation not permitted
[2019-02-03 17:48:34] <TrevorKS> so that would be correct ha
[2019-02-03 17:48:37] <nerdo> :)
[2019-02-03 17:59:04] <TrevorKS> mateothegreat: Turns out i should have been looking at the image build logs more closely. The rpm was using the "service" commands to kick off the child services. Adding a "yum install initscripts -y" to make that command avalible resulted in a sucessful image :) Thanks for the help!
[2019-02-04 14:11:10] <petkocfc> Hi guys, do you maybe know how to configure replica set for mongo image with docker-compose, is it MONGO_REPLICA_SET or MONGODB_REPLICA_SET_MODE in environment?
[2019-02-04 14:42:06] <qait-tarundwivedi> i am using Docker in Window and switch to Window containers
[2019-02-04 14:42:40] <qait-tarundwivedi> But when i am trying to docker pull selenium/hub
[2019-02-04 14:43:16] <qait-tarundwivedi> is show error : Image operating system "Linux" cannot be used on this platform
[2019-02-04 14:43:59] <qait-tarundwivedi> Any idea how i will create both Window and Linux containers at same time ?
[2019-02-04 21:03:47] <Genysys> can you useFROMtwice in a docker file? I am trying to pull two images and not sure it works
[2019-02-04 21:10:32] <rcjsuen> Genysys: There are multi-stage builds but not in the way you think
[2019-02-04 21:10:44] <rcjsuen> What would happen though? You pull Ubuntu you pull Redhat, how would you merge it?
[2019-02-04 21:11:02] <Genysys> lol fair enough
[2019-02-04 21:11:23] <Genysys> and the answer to your question? Frankenstien’s monster?
[2019-02-04 21:11:48] <rcjsuen> I mean, you can merge it anyway you want, it's up to your algorithm :)
[2019-02-05 07:48:04] <vipul1231> Hi All, I am using docker for spring boot project which connect's AWS sqs service. But unfortunately I am getting below error
[2019-02-05 07:48:11] <vipul1231> Invocation of init method failed; nested exception is com.amazonaws.SdkClientException: Unable to execute HTTP request: sqs.ap-south-1.amazonaws.com
[2019-02-05 07:48:24] <vipul1231> Can somebody help me out with this problem
[2019-02-05 07:56:53] <vipul1231> Its seems like my container service not able to connect SQS
[2019-02-05 08:01:49] <L04DB4L4NC3R> I'm having some trouble configuring an nginx reverse proxy on docker. It gives 502 gateway error. Can anyone help me out?
[2019-02-05 08:02:04] <L04DB4L4NC3R>  [<-ISSUE->] 
[2019-02-05 14:15:27] <tim-klug> HI@angadsharma1016I think you mustproxy_pass http://event/;instead ofproxy_pass http://event-servers/;. Docker-Compose has a lightweight DNS that will route to the services name.
[2019-02-05 18:52:10] <L04DB4L4NC3R> Hey, it still doesn't seem to work
[2019-02-05 20:38:18] <nerdo> question. I need a service to be fully up (database) before I run another service. I know docker-compose.yml allows you to setdepends_on, but my understanding is that it just ensures that the dependent service container has been started, not that it's fully up... or does it take into account health checks?
[2019-02-05 20:40:57] <nerdo> angadsharma1016: make sure both services are on the same network
[2019-02-05 21:39:30] <Genysys> I am having issues with the docker file below: [<-CODE->]  [<-CODE->] Would appreiciate pointers on this
[2019-02-05 22:23:56] <L04DB4L4NC3R> nerdo: You can set an option to restart on-failure and assign an exit code did there  is a failure while connecting to DB so your service will keep restarting until it connects to the database.
[2019-02-05 22:24:16] <L04DB4L4NC3R> nerdo: They are on the same network. Still it doesn't seem to work
[2019-02-06 00:52:02] <dragonpiper> Why doesn'tnpm install -gpersist when run in dockerfile ?
[2019-02-06 00:52:37] <dragonpiper> when i do a docker run after the build/usr/local/bin/no long has the installed module
[2019-02-06 04:04:15] <L04DB4L4NC3R> dragonpiper: create a volume for node_modules
[2019-02-06 08:11:48] <vsilent> Genysys: what is the sense to use sudo there ?
[2019-02-06 11:45:53] <Genysys> for some reason the image is is reading that as root is generating EACESS errors
[2019-02-06 11:46:20] <Genysys> Had to do this to get it to work: [<-CODE->] 
[2019-02-06 11:46:38] <Genysys> vsilent: 
[2019-02-06 12:20:32] <benydc> which is best to store application source code, docker volume or docker data container?
[2019-02-06 14:12:39] <L04DB4L4NC3R> For persistent data, it's volumes. Best is volume binding
[2019-02-06 17:37:47] <TevoDavis_twitter> if i make changes to my dockerfile whats the best way to rebuild the image?
[2019-02-06 17:53:45] <TevoDavis_twitter> oh thanks everyone i found out
[2019-02-06 22:32:36] <dbjpanda> Calling for potential mentors for Google Summer of Code, a community driven online activity hosted by Google every year. Just completed the application process. Please add some ideas/ Issue which you think should be fixed. Also add your name to the list if you want to be a mentor.  ( [<-LINK->] ) .
[2019-02-07 01:10:43] <JonSalazar>  [<-CODE->] what could be?
[2019-02-07 10:17:28] <vsilent> JonSalazar: you have to add your user to docker group like this: sudo  gpasswd -a youruser  docker
[2019-02-07 11:13:55] <mateothegreat> usermod -aG docker <yourusername>
[2019-02-07 12:07:47] <webertrlz> hey how to prevent docker to loggin to stdout all the commands I type in a shell session in it?
[2019-02-07 12:08:22] <webertrlz> I run a container, dodocker exec -ti  cointainerName shand everything I do there is output if I dodocker logs containerName
[2019-02-07 16:13:01] <JonSalazar> vsilent: I already use that command and it notify me that my user is added to the group. Also I useusermod -aG docker <myusername>and restart the service with the same result, I still need to usesudo.  What else could it be?
[2019-02-07 16:17:39] <dbjpanda> Join our Docker Google Community to take part as a mentor in Google Summer of Code 2019 and help university students get into Docker [<-LINK->] 
[2019-02-09 06:48:56] <akash.ma19_gitlab> I have 6 digital ocean droplet...installed docker on it in swarm mode...one leader2 manager and 3 worker...I have used digital ocean load balancer, to balance between leader and one manager1....I have to run node js server and Nginx....whenever I update docker images. Nginx randomly pick any droplet which is fine...My question is where should I keep my ssl cert so that I can config in Nginx??Ps - I want to use digital ocean bypass certificate
[2019-02-09 06:49:00] <akash.ma19_gitlab> any help??
[2019-02-10 00:55:10] <mateothegreat> why not create a proxy to do ssl termination@akash.ma19_gitlab
[2019-02-10 04:08:15] <nerdo> Question. I've got several mysql containers and I'm trying to connect to them from my mac. I can easily map ports, but trying to remember which port is what server is kind of a pain. I'd like to use the socket to connect and I set up a bind mount exposing it. I can see themysqld.sockfile but when I try to connect using it, I get an error saying mysql can't connect and I have no idea why. I've tried setting permissions on it to 777 from the container, but I don't know what else to do. What am I doing wrong?
[2019-02-10 06:35:14] <mateothegreat> You can’t “mount”  a socket like that
[2019-02-10 06:35:26] <mateothegreat> from two different environments (contexts)
[2019-02-10 17:49:33] <nerdo> Interesting. I was able to do it with docker (/var/run/docker.sock:/var/run/docker.sockso a container can run docker commands on the host), but I guess it doesn't work the same when the socket is created within the container? or maybe docker is just an exception
[2019-02-10 17:51:13] <nerdo> I've got a new dilemma. I was planning to use toolchains installed in containers. Part of my toolchain is git, and I ran a simplegit statusfrom within a container and it took incredibly long. I'm assuming it's because it's within a bind mount
[2019-02-10 17:58:07] <nerdo> Man, this kind of makes it unusable. I wish I knew about this a few weeks ago before I started :|
[2019-02-11 10:52:25] <akash.ma19_gitlab> 502 error while scaling docker container(which runs node server)
[2019-02-11 12:05:08] <railsfactory-suriya> hi, could someone share a ruby on rails production docker on kubernetes example document.
[2019-02-11 12:06:26] <rcjsuen> Maybe this will help [<-LINK->] 
[2019-02-11 12:06:59] <railsfactory-suriya> will check@rcjsuenthanks :)
[2019-02-11 14:54:48] <petkocfc> Hi, could someone help with this problem described [<-LINK->] 
[2019-02-11 16:47:47] <rcjsuen> petkocfc: I can't really tell what the error is
[2019-02-11 16:48:26] <rcjsuen> Perhaps you can try giving the full path toreplicaSet.js?
[2019-02-11 19:33:10] <petkocfc> rcjsuen: tried that also, but it just states that the file does not exists but it's copied
[2019-02-11 19:33:16] <petkocfc> really strange
[2019-02-11 19:34:48] <petkocfc> looked all over the web how other guys implemented this and basically it's the same but for me it ain't working, all the examples i looked where a
[2019-02-11 19:35:28] <petkocfc> several months older, maybe something is changed in the mongo image itself but it's really unreasonable
[2019-02-11 19:39:44] <rcjsuen> I'm still not sure I fully understand the problem
[2019-02-11 19:40:38] <rcjsuen> you say you enter the container and it won't work, but then if youdocker execit works, what?
[2019-02-12 20:33:59] <jbouse> Hey got a question to know if it's possible... If I have adocker:stable-dindcontainer which is running 18.09.x but it's running on top of 18.06.x Docker cluster... can I still make use of the 18.09.x enhancements like buildkit?
[2019-02-12 20:34:56] <SalathielGenese> Yes in the scope of18.09.x
[2019-02-12 20:36:53] <jbouse> SalathielGenese: Yeah... I'm running adocker:stable-dindcontainer on top of AWS ECS which is running 18.06.x still but I want to make use of buildkit for multi-stage Dockerfile builds
[2019-02-12 20:38:14] <jbouse> I am pointing my Jenkins build agents to the instance of thedocker:stable-dindcontainer to do builds inside so they would be running under the 18.09.x scope. I just wanted to confirm before I update the version of Docker CLI I push out to our build agents
[2019-02-12 21:51:23] <SalathielGenese> I'm sorry@jbouse, I think it will just work great... I thought I had wrote it long ago
[2019-02-13 07:08:12] <jbouse> Is there something fundementally different between the manifest of an image built with and without DOCKER_BUILDKIT=1 being used?
[2019-02-13 08:57:57] <Fruzenshtein> Hey docker community!Does anyone faced an issue with docker-compose when one of containers isn't accessible from another one? [<-LINK->] 
[2019-02-13 13:33:25] <dejanvuj_gitlab> Hi, what's the best way to give host user to have written permissions to volume files [<-CODE->] 
[2019-02-13 13:35:16] <dejanvuj_gitlab> Fruzenshtein: did you try to use container ip address. Check with docker inspect container
[2019-02-13 17:06:39] <jbouse> Using the same multi-stage Dockerfile, if I build without using BuildKit our image scanning application can handle the manifest  but if I use BuildKit it suddenly has a problem with the manifest. Trying to determine if there's an actual change in the manifest format if BuildKit is used to build an image
[2019-02-13 17:24:59] <jbouse> doing adocker inspectagainst the 2 images I see the one that was built using BuildKit doesn't have theDockerVersion,ParentorContainervalues set.  Also underContainerConfig, theHostname,User,Env,Cmd,Image,Volumesare not set but theConfigsection matches up between the two... other than those items the only thing different are sizes and hashes obviously
[2019-02-15 16:22:21] <AllanKlaus> If there is any brazilian here and dont know how to use docker hub - [<-LINK->] 
[2019-02-15 17:12:56] <beelzbozo> Greetings all. Docker was upgraded on our Ubuntu systems and  now container creation is failing with "fork/exec /usr/bin/dockerd (deleted): no such file or directory". Is there anyway I can relink or otherwise get container creation working again (without restarting dockerd)? That way I can do a node drain.
[2019-02-18 08:30:36] <akash.ma19_gitlab> docker swarm mode...deploy some node js server
[2019-02-18 08:30:43] <akash.ma19_gitlab> working fine
[2019-02-18 08:30:54] <akash.ma19_gitlab> but sometimes it says
[2019-02-18 08:31:01] <akash.ma19_gitlab> sitecannot be reached
[2019-02-18 10:39:02] <andrefreitas> AllanKlaus: if you still need help ping me
[2019-02-18 10:42:42] <AllanKlaus> andrefreitas: I'm ok. thanks
[2019-02-18 15:16:11] <matrixbot> ralfihi docki\'s, to expand my little docker know-how - at this time i always play with pre-defined images like nextcloud - i try to deploy a container from debian:buster. Image download works, but creating a container fails with "docker run debian:buster /bin/bash" - the conainer always close with error 0. I works fine with "docker run-it debian..." but of course only in the foreground. How can i deplay the container to work in background?
[2019-02-18 15:18:14] <matrixbot> ralfiUuuu really stupid, it seems the -d option ....
[2019-02-18 19:45:56] <ghost~5bc98094d73408ce4fabf741> Howk, curiosity brought me here.
[2019-02-18 19:46:20] <ghost~5bc98094d73408ce4fabf741> I have a docker instance on windows setup with a HyperV host
[2019-02-18 19:46:57] <ghost~5bc98094d73408ce4fabf741> minikube freaks out on a hyperv host every once in a while so I can't run kubernetes locally
[2019-02-18 19:48:26] <ghost~5bc98094d73408ce4fabf741> but if I switch minikube to virtualbox host, the network card etc is already occupied by the hyperv host
[2019-02-18 19:48:45] <ghost~5bc98094d73408ce4fabf741> any way I can switch the docker instance on windows to virtualbox?
[2019-02-19 06:41:44] <Hmerac> Hello@piotr-mamenas,I have also encountered with this problem and after a very very long time, eventually gave up on minikube and Windows. Couldn't find any solution... But if someone has one, I will be a happy happy man.
[2019-02-19 08:41:57] <IdanAdar> Question... I'm creating now a Dockerfile that the container built using it will be used as a Jenkins agent. In this agent there is also Docker installed, and I need to use an image available in it... [<-CODE->] 
[2019-02-19 08:50:18] <IdanAdar> In addition, it seems that the image created, while it has docker installed, doesn't have it running... how can I start docker from within the Dockerfile?
[2019-02-19 09:16:00] <BaVanDuong> Hi,Anyone using nexus for docker registry proxy?$ systemctl show --property=Environment dockerEnvironment=HTTP_PROXY= [<-LINK->] But error bellow:root@ubuntu:~# docker pull ubuntuUsing default tag: latestError response from daemon: Get [<-LINK->] : Not FoundI'm using Nexus for docker proxyPlease help fix this issue
[2019-02-19 10:18:42] <lanycrost> BaVanDuong: are you have logged in to your new registry?
[2019-02-19 10:18:49] <lanycrost> BaVanDuong:  [<-LINK->] 
[2019-02-19 10:23:00] <BaVanDuong> lanycrost: : Thank you, problem solved
[2019-02-19 10:23:19] <BaVanDuong> need to have a /etc/docker/daemon.json, containing{  "registry-mirrors": ["https://<your-nexus-address>"]}
[2019-02-19 11:57:44] <npankaj365>  [<-LINK->] 
[2019-02-19 11:58:09] <npankaj365> Hi everyone,Why is this error popping up in a freshly installed Ubuntu server?
[2019-02-19 11:59:21] <npankaj365> I was working on Arch during the development, and wanted to test my project on an Ubuntu machine.
[2019-02-19 11:59:27] <npankaj365> I keep running into this error.
[2019-02-19 11:59:41] <npankaj365> I tried thedocker-machine create default
[2019-02-19 12:00:40] <npankaj365> results in the following error
[2019-02-19 12:00:46] <npankaj365>  [<-LINK->] 
[2019-02-19 12:05:20] <npankaj365> I do not seem to understand why docker-machine is even required for managing docker containers in Linux.
[2019-02-19 13:49:42] <lanycrost> BaVanDuong: you are welcome :)
[2019-02-19 13:53:55] <lanycrost> @npankaj365 You are should install virtualboxhttps://docs.docker.com/machine/overview/
[2019-02-19 16:07:56] <npankaj365> lanycrost: Installing virtualbox worked.Can anyone explain why docker-machine is required in linux?
[2019-02-19 17:20:42] <gidyon> You mean why it doesn't come bundled with docker during first installation?
[2019-02-20 06:31:28] <lanycrost> npankaj365: are you mean virtualbox is required? docker-machine is not required. I think you are try install minukube right?
[2019-02-20 08:27:46] <npankaj365> What I was confused about wasWhy is docker-machine even required for managing containers in Linux? As per the Docker's reference site, docker-machine is used to manage containers in Windows and MacOS. \nI had nothing to do with docker-machine, if not for resolving the error\nTo resolve it, I had to run `docker-compose create default', which in turn resulted in the following error asking that I install virtualbox.While the problem got resolved after installing virtualbox, my question isn't it a big overhead to simple run docker containers in a Ubuntu Server.
[2019-02-20 08:28:18] <nafg> Who said it's required?
[2019-02-20 08:29:29] <npankaj365> Please look at the point 2.The course of error messages led me to say that.
[2019-02-20 11:17:51] <aebadian> Hey all, My apologies if this is a newbie question. I just couldnt find anything on it on line.We have build a docker image which uses other docker image on docker hub. Our worry is that what happens when the the parent images are no longer available?
[2019-02-20 15:47:47] <kylegordon_twitter> you frantically go looking for a replacement copy or somehow grab a copy that you happen to have stored locally
[2019-02-20 15:47:59] <kylegordon_twitter> case in point, see all the java8 takedowns last month
[2019-02-20 15:49:08] <aebadian> I have just learned Docker and the whole java8 takedowns went past me
[2019-02-20 15:49:17] <kylegordon_twitter>  [<-ISSUE->] 
[2019-02-20 15:49:24] <kylegordon_twitter> s'cool, it's understandable
[2019-02-20 15:49:52] <kylegordon_twitter> but yeah, I don't actually know what safety precautions you could take other than what I've just described. I didn't get hit by that issue, but... one day
[2019-02-20 15:51:52] <aebadian> wow that is scarly
[2019-02-20 15:52:08] <aebadian> I will use docker save and save it somewhere
[2019-02-20 15:52:41] <aebadian> by the sound of things we cant reply on other peoples images
[2019-02-20 15:56:58] <kylegordon_twitter> it's certainly a concern, yeah :-)
[2019-02-21 06:19:57] <vito-c> is it possible to forward logs to a splunk container as well as use docker logs <container>
[2019-02-21 19:57:54] <Sharkbyteprojects> can everyone help me?i need a person the test my docker image. Is an NODE-JS analytics-server they cout the connections and links on the terminal [<-CODE->] 
[2019-02-21 19:58:29] <IdanAdar> I have an Alpine-based Docker image that I am attempting to use as a Jenkins agent. Thus far things are progressing nicely, but one thing that is failing for me is withshsteps, where it keeps failing for me with an error like:syntax error: unexpected "(". Previously on the build machines that are CentOS based, this error did not happen. Any tips how can I solve this? Perhaps an additional step in the Dockerfile, or an environment variable in the "Docker agent template"?
[2019-02-21 20:04:03] <Sharkbyteprojects> IdanAdar: Which os are you using? (WHERE DOCKER RUNS ON)If you use Windows you should not use Hyper-V, instead the Virtual Box. with me the alpine image works like this.Maybe you're using the wrong install command! the right  isdocker pull alpine
[2019-02-22 07:39:49] <guddutopper> To set up memory limit for a docker container we can use-mflag, so i started a container with a 2GB of memory limit using the  -m flag, now i want to know if it is possible to increase the memory limit of this running container ?
[2019-02-22 08:05:15] <guddutopper> i found the answer, using docker update we can achieve this
[2019-02-22 08:50:08] <lanycrost> Hi guys, I have use Arch Linux, [<-CODE->]  [<-CODE->]  [<-CODE->] but... [<-CODE->]  [<-CODE->] 
[2019-02-22 14:16:26] <roychri> lanycrost: I am not familiar with Arch Linux but sounds like it's a DNS issue. You should concentrate there. Did you try to re-install docker from scratch?You should trydocker network listand show us what is there.
[2019-02-22 23:53:35] <deepu9> Hi all, this is Sandeep and I'm a developer trying to build LEMP stack. Nice to meet you all.
[2019-02-23 00:14:55] <deepu9> I'm using docker-compose to build the LEMP stack. Initially I started without a guest OS, just Nginx, PHP and MySQL. When do docker up, everything is working for localhost url, but I did setup a custom url in the nginx config. Also copied site.conf to/etc/nginx/conf.d, but still no use. Can someone help me out. Thanks
[2019-02-23 18:16:50] <ghost~5bc98094d73408ce4fabf741> piotr-mamenas: alohadid you watch lilo and stitch, aloha means family :<I am here regarding the new kubernetes thing with docker for windowsi switched over to it but I can't seem to reach the service inside of the cluster from the browserI was using kubectl describe node docker-for-desktop to get the ipand I am using ingress at the front just routing to relevant services like /identity
[2019-02-24 10:08:19] <lanycrost> roychri: sorry, my bad... I forget configure firewall
[2019-02-24 10:12:20] <ghost~5bc98094d73408ce4fabf741> fcuk
[2019-02-24 10:12:23] <ghost~5bc98094d73408ce4fabf741> someone alive here
[2019-02-24 10:13:04] <ZelphirKaltstahl> ducks
[2019-02-24 10:15:52] <ghost~5bc98094d73408ce4fabf741> dcuk
[2019-02-24 10:15:56] <ghost~5bc98094d73408ce4fabf741> ZelphirKaltstahl: 
[2019-02-25 11:13:00] <IdanAdar> Is there a docker:stable-dind release that uses Alpine 3.8 or 3.9?
[2019-02-25 11:24:19] <vsilent> deepu9: you have to show the source code at least.  Something like for example [<-LINK->] so we know which files and configurations you have there
[2019-02-26 05:44:27] <jbouse> IdanAdar:  [<-CODE->] 
[2019-02-26 06:11:22] <imaffe> Hi every one , is this the place i can ask questions about dockers? I have a question binding volumes. I want to bind a directory to the docker. Documentations said i could dodocker run -v  DIR:DIR. But I have a container already been created using run (no binding in thedocker runcommand). Is there anyway to bind a directory to this container without destroy it and rerun it ?
[2019-02-26 14:22:05] <ghost~5bb3c7fed73408ce4faa2518> Please introduce to the development framework framework: https://docs.hyron.orgAfter a period of work, I realized that the problem of code reuse is still a rather complex issue, most of them only stop at the library level. The packaging and use requires that you still have to intervene deeply. It would be hard if you want to plug a module into your product, especially someone else's, or another project. We, or every company, every project, and around the world often meet the same problems, and we are in general reinventing the wheels of other brothers. A significant waste of resources. What if we could build a community, and people could share their code, services, addons, or plugins that could be easily reused so that it could be plugged into the app. like my jigsaw puzzle? Hyron makes packing and reusing quickly much easier, it can help the product development process become much faster!Besides, managing the modules I see is also a problem to note. With small projects is not a problem, but with a large project size, up to a hundred, thousands of services, why, when products, often have to change and maintain, as with startups. What happens when you are tasked with upgrading and maintaining a long and chaotic list? How to keep my app neat, clean, and easy to manage, easy to edit and upgrade when needed? That is when we need a centralized management model, and packaging, inheritance that the hyron provides.A technology will be hard to succeed, if it becomes difficult to reach people. And that is why I am constantly looking for ways to make it more and more simple, more friendly, to be easy to learn and use. even for a beginner, there is only a little basic knowledge of javascript that can be easily accessed, and create a professional application!There are many things, being a lazy person, I hope that one day, our programming, and our work can become much faster, and simpler, with just a few taps Drop, a few knuckles are we can build a professional application of termHowever, in order to reach that future, it is necessary to help your friends, those who are like-minded, hope to work together and work with you :)A project is also very difficult to succeed, since it has no funds to maintain. With a small amount of support from you, a cup of caffeine can make a difference.If you find it helpful, support yourself byClick watch to watch and star to help the project more popular to the community\nFollow fanpage to get the latest news from Hyron: https://fb.com/hyron.group\nDonate to help Hyron develop products faster and better: https://liberapay.com/thangdjw/donate\nIntroduce Hyron to friends to help hyron more popular\nJoin co-developers with hyron, to develop useful products
[2019-02-26 14:47:42] <rcjsuen> development framework frameworkThat is very meta
[2019-02-26 15:59:55] <ghost~5bb3c7fed73408ce4faa2518> What do you mind ?
[2019-02-26 16:01:34] <SalathielGenese> For God's sake, is that a polite way of expressing yourself?
[2019-02-26 16:04:13] <ghost~5bb3c7fed73408ce4faa2518> I just try to do something great
[2019-02-26 18:56:42] <matrixbot> Mocking MonikerDoes anybody know how to containerize RedHat PAM?
[2019-02-26 18:58:58] <matrixbot> Mocking MonikerThat is, Process Automation Manager (not Plugable Authentication Modules).
[2019-02-26 19:14:14] <vito-c> is it possible to forward logs to a splunk container as well as use docker logs <container>
[2019-02-26 19:14:20] <vito-c> anyone know the answer to that
[2019-02-27 11:30:30] <AsixCompany_gitlab> hello anyone can help me with this error ERROR: for connecta  Cannot start service connecta: CreateComputeSystem 0d00767aefce249157a79461daa69d7d21167db8331f9d228c3fc9799416e3b4: the parameter is not correctly,  it produces when start docker compose
[2019-02-27 11:31:33] <develroo> Look at the file. You probably have a typo.
[2019-02-27 11:32:09] <AsixCompany_gitlab> the docker compose.yml?
[2019-02-27 16:43:17] <cheeku009> hi I am new to docker, i am getting below error, if i have placed my public ip when i start container.
[2019-02-27 16:44:48] <cheeku009> docker: Error response from daemon: driver failed programming external connectivity on endpoint pemportal (9b58eecc215c0e3afe512ac2a4173727a68054b65e5fca1d6f24ad9b8efa9f96): Error starting userland proxy: listen tcp 3.94.51.166:19347: bind: cannot assign requested address.
[2019-02-27 16:44:54] <cheeku009> can anyone help
[2019-02-27 16:45:54] <pedroparraortega> you can not bind the host address by default in docker
[2019-02-27 16:46:10] <pedroparraortega> if you want to do it you can use--net=host
[2019-02-27 16:46:54] <pedroparraortega> that would make the container listen as the host
[2019-02-27 17:15:16] <cheeku009> if i dont put host and specify only port, it's assigning to 0.0.0.0, and i dont know how to access appilication then.
[2019-02-28 07:40:42] <okothkongo1> Hi i want learn to docker where should i start
[2019-02-28 07:41:18] <SalathielGenese> Under which platform are you ?
[2019-02-28 07:41:38] <SalathielGenese> okothkongo1: 
[2019-02-28 07:43:20] <okothkongo1> by platform i guess you mean OS ,if so Linux
[2019-02-28 07:44:16] <SalathielGenese> Ubuntu ? Or just Debian ?
[2019-02-28 07:45:09] <okothkongo1> ubuntu
[2019-02-28 07:45:19] <SalathielGenese> Install for ubuntu
[2019-02-28 07:45:20] <SalathielGenese>  [<-LINK->] 
[2019-02-28 07:46:59] <okothkongo1> SalathielGenese: thank you are there any  good learning resources out there or should i just stick to docs
[2019-02-28 07:47:30] <SalathielGenese> I'd rather go for a guide. I'm not sure there's any great tutorial out there
[2019-02-28 07:48:07] <SalathielGenese> I searched for few years and read many stuffs but the thing about docker kept very abstract to me...
[2019-02-28 07:48:29] <SalathielGenese> Until someone took me by the hand... I tought me want I needed to know
[2019-02-28 07:49:54] <appareddyraja> okothkongo1: check thishttps://www.udemy.com/share/1001eQ/
[2019-02-28 07:50:47] <okothkongo1> SalathielGenese: ooh  ok thank you
[2019-02-28 07:51:20] <okothkongo1> appareddyraja: sure i will thank you
[2019-02-28 08:53:20] <SalathielGenese> PING
[2019-02-28 08:53:53] <SalathielGenese> Any JHipster dev around ?
[2019-02-28 11:20:06] <IdanAdar> I updated the docker:stable-dind image I'm using, and it now uses Alpine 3.9; I'd like to revert to the previous version which runs Alpine 3.6, I think. Which one is that?
[2019-02-28 12:01:35] <IdanAdar> ^@jbouse
[2019-02-28 13:11:22] <IdanAdar> Everything I try to install of dind installs Alpine 3.9. I must revert back...
[2019-02-28 13:11:33] <IdanAdar> To a version that installs Node 8.14
[2019-02-28 13:11:41] <IdanAdar> This upgrade broke our pipeline
[2019-02-28 13:13:53] <IdanAdar> Is it in any way possible to install a different alpine version?
[2019-02-28 15:16:37] <SalathielGenese> HELLO
[2019-02-28 15:16:39] <SalathielGenese>  [<-CODE->]  [<-CODE->] 
[2019-02-28 15:29:06] <IdanAdar> I cannot find the DIND release that is based on alpine 3.8, or just the one that came before Alpine 3.9... how does one pull it??
[2019-02-28 15:31:39] <SalathielGenese> IdanAdar: - [<-LINK->] 
[2019-02-28 15:32:48] <IdanAdar> Thanks.
[2019-02-28 15:32:57] <SalathielGenese> mp
[2019-02-28 15:33:56] <IdanAdar> And where’s the official one by Docker?
[2019-02-28 15:34:15] <SalathielGenese> I couldn't find it
[2019-02-28 15:34:25] <jbouse> IdanAdar: I believe you'd have to find the sha hash for the that version and use it instead of simply docker:stable-dind
[2019-02-28 15:35:10] <SalathielGenese> IdanAdar: - Completely unintuitive
[2019-02-28 15:35:12] <SalathielGenese>  [<-LINK->] 
[2019-02-28 15:35:31] <IdanAdar> Y
[2019-02-28 15:35:51] <IdanAdar> yes looks like they keep there only the latest
[2019-02-28 15:36:48] <SalathielGenese> I was direct by this article - [<-LINK->] 
[2019-02-28 15:39:03] <IdanAdar> I should’ve never pull this new version..
[2019-02-28 15:41:40] <SalathielGenese> :scared: - what happened
[2019-02-28 15:52:10] <IdanAdar> This latest update uses Alpine 3.9. Alpine 3.9 provided only Nodejs 10.14. The ursa package doesn’t work with Node 10.14 and thus our build pipeline breaks.
[2019-02-28 15:53:32] <IdanAdar> And there’s no obvious/simple rollback as the previous version is no where to be found. Hopefully by chance I’ll find the hash value Jeremy mentioned...
[2019-02-28 16:53:10] <IdanAdar> jbouse: Can you run a quick search as well? I was not able to find it...
[2019-02-28 16:53:58] <IdanAdar> aha! This?docker-library/docker@5ca0a1b
[2019-02-28 16:57:32] <IdanAdar> How would I use this in a Dockerfile?
[2019-02-28 17:27:04] <rcjsuen> IdanAdar: Your previous builds don't show a hash?
[2019-02-28 17:31:55] <IdanAdar> Builds of...
[2019-02-28 17:32:24] <rcjsuen> I mean perhaps your pipeline mentioned the hash somewhere
[2019-02-28 17:32:50] <rcjsuen> But maybe I don't understand how your pipeline is usingdindso...
[2019-02-28 17:33:36] <IdanAdar> The resulting image is used as Jenkins docker agent
[2019-02-28 20:56:02] <SalathielGenese> If found THE solution to my problem [<-CODE->] CREDITS : https://stackoverflow.com/a/8579227/3748178
[2019-02-28 22:09:43] <satrapes_gitlab> Do you guys usually put Dockerfiles within  a separate project or do you package it with the application?
[2019-03-01 02:56:29] <SalathielGenese> packaged with app
[2019-03-01 02:57:01] <SalathielGenese> b/c context matters when running ADD and COPY docker commands
[2019-03-01 08:21:53] <alexanderpavlov> Hello! I have 2 web sites in one docker and I need to do request from one site to another site with curl. What address do I need to use for this request?
[2019-03-01 08:22:37] <nafg> They're both in the same container?
[2019-03-01 08:22:44] <alexanderpavlov> Yes
[2019-03-01 08:22:52] <nafg> localhost / 127.0.0.1 should work, no?
[2019-03-01 08:27:26] <alexanderpavlov> I can do requests by domain names to these sites from my host machine because have records in /etc/hosts 127.0.0.1 site1.test and 127.0.0.1 site2.test. I have added these records in /etc/hosts in nginx container but still can't do requests from site1 to site2
[2019-03-01 08:29:50] <alexanderpavlov> 127.0.0.1    localhost::1    localhost ip6-localhost ip6-loopbackfe00::0    ip6-localnetff00::0    ip6-mcastprefixff02::1    ip6-allnodesff02::2    ip6-allrouters172.18.0.3    f98de9ad34e1172.19.0.8    f98de9ad34e1127.0.0.1    site1.test127.0.0.1    site2.test
[2019-03-01 08:30:18] <alexanderpavlov> It's /etc/hosts in my nginx container
[2019-03-01 21:21:05] <nspaeth>  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2019-03-02 16:10:53] <ghost~5bc98094d73408ce4fabf741> anyone been using kubernetes dashboard through docker for windows and managed to skip the authentication locally?
[2019-03-02 16:11:04] <ghost~5bc98094d73408ce4fabf741> I tried using: kubectl apply -f [<-LINK->] but the link is already dead
[2019-03-02 16:17:54] <markyjackson-taulia> piotr-mamenas:  [<-LINK->] 
[2019-03-02 16:39:36] <ghost~5bc98094d73408ce4fabf741> markyjackson-taulia: I tried it but once i kubectl proxy and navigate to [<-LINK->] I don't have the skip authentication button,
[2019-03-02 16:39:45] <ghost~5bc98094d73408ce4fabf741> i apply the following:
[2019-03-02 16:39:48] <ghost~5bc98094d73408ce4fabf741>  [<-CODE->] 
[2019-03-02 16:40:11] <ghost~5bc98094d73408ce4fabf741> I am guessing I might have applied some configuration with the auth requiring dashboard before
[2019-03-02 16:40:23] <markyjackson-taulia> possible
[2019-03-02 16:40:24] <ghost~5bc98094d73408ce4fabf741> but when i kubectl get services I don't see anything except the service I deployed
[2019-03-02 16:41:51] <markyjackson-taulia> What is the test you are trying here? Is it just to build up a cluster? If so, in what type of an env (i.e. linux, windows etc)
[2019-03-02 16:43:57] <markyjackson-taulia> Also why are you trying to skip auth?
[2019-03-02 16:44:32] <markyjackson-taulia> sorry for all the questions. Trying to understand your use case so I can possibly help :-)
[2019-03-02 17:01:14] <ghost~5bc98094d73408ce4fabf741> no worries, I appreciate you spending your valuable time trying to help me ;)
[2019-03-02 17:01:31] <ghost~5bc98094d73408ce4fabf741> I am just trying to setup a local cluster using the kubernetes host embedded inside of docker for windows
[2019-03-02 17:01:48] <ghost~5bc98094d73408ce4fabf741> using linux containers underneath with hyperv host
[2019-03-02 17:02:18] <ghost~5bc98094d73408ce4fabf741> markyjackson-taulia: 
[2019-03-02 17:03:57] <markyjackson-taulia> Ahh. I am not very well versed on windows (haven’t used it in many many years).So you have everything installed and can make kubectl calls successfully correct? If so, have you deployed an admin users?
[2019-03-02 17:06:44] <markyjackson-taulia> If not, lets not worry about skipping auth.. Here is what I would do if you have met the above items
[2019-03-02 17:06:59] <markyjackson-taulia> Lets create an admin user
[2019-03-02 17:07:12] <markyjackson-taulia> We can use a service account for now
[2019-03-02 17:07:38] <markyjackson-taulia> Save the following file as sa.yaml
[2019-03-02 17:07:40] <markyjackson-taulia> apiVersion: v1kind: ServiceAccountmetadata:name: admin-usernamespace: kube-system
[2019-03-02 17:07:59] <markyjackson-taulia> save the following file as crb.yaml
[2019-03-02 17:08:00] <markyjackson-taulia> apiVersion: [<-LINK->] kind: ClusterRoleBindingmetadata:name: admin-userroleRef:apiGroup: rbac.authorization.k8s.iokind: ClusterRolename: cluster-adminsubjects:kind: ServiceAccountname: admin-usernamespace: kube-system
[2019-03-02 17:08:19] <markyjackson-taulia> Once you have deployed the above
[2019-03-02 17:08:25] <markyjackson-taulia> you can run this: kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}')
[2019-03-02 17:08:42] <markyjackson-taulia> This will give you the token so you can login as an admin
[2019-03-02 17:09:07] <markyjackson-taulia> It will print out something similar to this
[2019-03-02 17:09:08] <markyjackson-taulia> Name:         admin-user-token-6gl6lNamespace:    kube-systemLabels:       <none>Annotations:  kubernetes.io/service-account.name=admin-user kubernetes.io/service-account.uid=b16afba9-dfec-11e7-bbb9-901b0e532516Type:  kubernetes.io/service-account-tokenDataca.crt:     1025 bytesnamespace:  11 bytestoken:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLTZnbDZsIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJiMTZhZmJhOS1kZmVjLTExZTctYmJiOS05MDFiMGU1MzI1MTYiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.M70CU3lbu3PP4OjhFms8PVL5pQKj-jj4RNSLA4YmQfTXpPUuxqXjiTf094_Rzr0fgN_IVX6gC4fiNUL5ynx9KU-lkPfk0HnX8scxfJNzypL039mpGt0bbe1IXKSIRaq_9VW59Xz-yBUhycYcKPO9RM2Qa1Ax29nqNVko4vLn1_1wPqJ6XSq3GYI8anTzV8Fku4jasUwjrws6Cn6_sPEGmL54sq5R4Z5afUtv-mItTmqZZdxnkRqcJLlg2Y8WbCPogErbsaCDJoABQ7ppaqHetwfM_0yMun6ABOQbIwwl8pspJhpplKwyo700OSpvTT9zlBsu-b35lzXGBRHzv5g_RA
[2019-03-02 17:09:28] <markyjackson-taulia> Then you just login like this
[2019-03-02 17:10:37] <markyjackson-taulia>  [<-LINK->] 
[2019-03-02 17:11:12] <markyjackson-taulia> You should then be logged in as an admin
[2019-03-02 17:11:23] <markyjackson-taulia> Hope that helps.
[2019-03-02 17:11:39] <markyjackson-taulia> I verified the above using minikube just to be sure it worked locally
[2019-03-02 20:22:26] <ghost~5bc98094d73408ce4fabf741> Hi, Thanks@markyjackson-tauliabut this will not work: kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}') - grep and awk are unix commands so they will not work on windows, I am not exactly sure where these files are held on windows but perhaps I can look it up. I am not using minikube though, I am using inbuilt kubernetes cluster shipping with docker for windows
[2019-03-02 23:37:39] <markyjackson-taulia> You should be able to use a comparable command for windows
[2019-03-03 09:58:04] <ghost~5bc98094d73408ce4fabf741> markyjackson-taulia: yeah, that's what I did, afterwards just fetched the token and can login just fine into the dashboard now
[2019-03-03 09:58:12] <ghost~5bc98094d73408ce4fabf741> thanks ;)
[2019-03-03 12:47:54] <markyjackson-taulia> Yw
[2019-03-03 23:34:01] <rsegecin> I\'ve been trying to run this [ [<-LINK->] ] dockerfile but even though I grant proper permissions to the user _apt I keep getting error message saying "\'/var/cache/apt/archives/partial/[whateverfile].deb\' couldn\'t be accessed by user \'_apt\'"
[2019-03-04 14:47:15] <Shehanka> I cound't log docker on Windows Power shelldocker login --username chamodshehankaPassword:Error response from daemon: Get [<-LINK->] : net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
[2019-03-04 14:48:42] <markyjackson-taulia> This is a total guess on my part (not being a windows person) but possibly the windows firewall blocking something?
[2019-03-04 14:57:00] <rcjsuen> But you can login usingcmd.exe?
[2019-03-05 12:00:05] <Shehanka> rcjsuen: I tried but coudn't
[2019-03-06 02:23:34] <zkenstein> Hi all, I have a docker image for WordPress and Maria DB. Is it possible to combine this into one docker? So it make easier to pull from another server for installation
[2019-03-06 02:27:02] <markyjackson-taulia> no, you would need to combine both those dockerfiles in to one to get what you want
[2019-03-06 12:48:47] <TrickyDoodle> Hi, could anyone suggest the right way to make a thrеad dump from container which does not have jstаck inside? Is it possible to implement on the fly?
[2019-03-06 13:42:40] <naoaai> Hi, could you help me on suggestion for the right way to begin with docker to host a java app used by Vue
[2019-03-06 14:06:39] <ghost~5bc98094d73408ce4fabf741> Hoi, anyone who have been configuring a local k8s cluster with an ingress running on docker for windows, could you have a look here: [<-LINK->] and if you know advise?
[2019-03-06 19:20:06] <roychri> zkenstein: Consider the use of docker-compose which allows you to combine multiple dockerfile into one easy installation.
[2019-03-06 19:34:29] <ghost~5bc98094d73408ce4fabf741>  [<-LINK->] 
[2019-03-07 10:51:49] <abax1> Hi all, can anyone tell me how to ensure that docker daemon has 4G memory?
[2019-03-08 03:00:51] <trajano> Hi can someone guide me to where in github do they store the sources for the API documentation?  I want to make a pull request for the /events API to indicate thatsinceshould be an integer representing the seconds since epoch.  Right now it says its a string.
[2019-03-09 17:05:21] <ramireles> Is the standard python 3 image from the docker hub supposed to startup into the python shell automatically when I run it? It always runs the python shell right away
[2019-03-11 19:25:27] <ecaepp> ramireles: Looking at the Dockerfiles for a few of the Python3 versions it looks like the images are built to startup in a Python shellCMD [“python3”]. See [<-LINK->] for full Dockerfile.
[2019-03-11 20:56:16] <burnzzzz> Hey guys. Anyone used managed Vault service [<-LINK->] 
[2019-03-12 00:28:12] <matrixbot>  [<-CODE->] ELI5?
[2019-03-12 02:40:04] <ramireles> Thanks@ecaepp
[2019-03-12 16:51:18] <wolfspelz> Hi, my TCP connection into a container appears unidirectional. I can telnet into a container on a mapped port, but the container will not send data back on the TCP connection. If I use ENTRYPOINT ["netcat", "-l", "-p", "2000"]  and "telnet localhost 2000", then I see messages from telnet, but messages typed into netcat do no appear in telnet. What am I missing?
[2019-03-12 16:54:39] <SalathielGenese> Have you used GeoSpatial in bothRedisandPostgres?I want to get experience feed back.
[2019-03-12 21:22:52] <jseiser> Is there a way to determine why my service is stuck in 'current stage: starting' ?  This is on a docker swarm cluster.
[2019-03-12 21:23:25] <jseiser> *current state
[2019-03-12 21:24:41] <jseiser> docker stack ps SERVICE --no-trunc shows nothing under ERROR.
[2019-03-12 23:02:42] <gsmafra> Hey could someone give me a little hand? I'm a noob with Docker and I'm trying to make my container print stuff to stdout when I use /bin/bash as the entrypoint
[2019-03-13 01:48:47] <gidyon> Hi. Quick question, can workers communicate with one another in a swarm?
[2019-03-13 01:51:45] <gidyon> gsmafra: How did you run the run the container? I assume you are using linux-like os as image.
[2019-03-13 03:32:41] <gsmafra> gidyon: Yes, it\'s a ubuntu image. Don\'t know what you mean by how I ran the container, but my command is "docker run <image_name>"
[2019-03-13 03:33:38] <gsmafra> With the standard entrypoint it prints everything. When I put the line ENTRYPOINT /bin/bash in my dockerfile it doesn't
[2019-03-13 03:45:35] <gidyon> "it prints everything",  what is everything?
[2019-03-13 12:25:14] <hehailong5> Hi, Anybody knows how docker-proxy handles the REDIRECT packet?
[2019-03-13 12:29:11] <hehailong5> I have a container running in host mode and it can handle the REDIRECT correctly, while I put it in bridge network, it dose not,
[2019-03-13 13:11:29] <gsmafra> gidyon: Everything that would be directed to stdout if I ran the same commands in my machine
[2019-03-13 13:12:54] <gsmafra> Or stderr, I don't really know the difference. What I want is to just docker run and see if there are any errors with the container while running my scripts
[2019-03-13 14:44:12] <TrevorKS> Can someone steer me in the correct direction for giving a docker container an IP on a already exsisting network? Im trying to put a docker continer with a ip such as 192.168.10.5 onto the network. My server (docker host) is 192.168.10.4, so im trying to put it on the same network that the host is on but on its own IP. The plan here is to have users be able to use [<-LINK->] to resolve to the docker IP and be servered the docker application. I was following documentaion for docker-compose version 3 here ( [<-LINK->] ) and reading under "IPV4_ADDRESS, IPV6_ADDRESS" and structured my compose file similarly, however i dont think this is the right way to do it, and i dont think its going to allow other hosts outside my box be able to lookup the container through our intranet. Correct me if im mistake, give me some insight to what i should be looking to do here.
[2019-03-13 15:26:40] <gidyon> gsmafra: make sure you run the container interactively, and assign it pTTY terminal
[2019-03-13 15:27:06] <gidyon> docker run --rm -it YOUR_LINUX_IMAGE
[2019-03-13 17:22:56] <ecaepp> TrevorKS: It is possible to configure a container to use ahostnetwork to get an IP from the local LAN but it is generally not recommended. Instead I would suggest looking into running a reverse proxy Docker service such as [<-LINK->] or [<-LINK->] . Both are pretty easy to get setup and running and configuration is pretty straight forward. Once setup point your DNS record to the Docker host and the reverse proxy will route user traffic the backend Docker service.
[2019-03-14 00:28:08] <gsmafra> gidyon: When I run docker interactively my CMD is being overwritten. How can I avoid that?
[2019-03-14 01:04:25] <deepu9>  [<-CODE->] https://github.com/deepu9/docker-lemp-stackCan anyone help me setting up LEMP stack. I'm newbie to docker. Thanks
[2019-03-14 01:42:19] <gidyon> gsmafra: use ENTRYPOINT - it won't, and CMD to provide default arguments to ENTRYPOINT, and run the container interactively.
[2019-03-14 16:50:54] <naoaai> v
[2019-03-14 18:44:04] <TrevorKS> ecaepp: I was planning to use this solution (nginx) for reverse proxy for websites with only https. However, i also plan to run some apps such as GitLab and would need to have access to SSH. I know i could map my SSH port to a uncommon port on the host machine, but i would like to stick to their 'well known' ports, hence why i would like for it to have its our routable IP.
[2019-03-14 18:46:33] <TrevorKS> How would i configure a container to get a IP from its HOST network.
[2019-03-14 19:09:07] <ecaepp>  [<-CODE->]  [<-CODE->] See Docker Network Host and Docker Compose network_mode for reference.
[2019-03-14 20:00:22] <TrevorKS> ecaepp: Thank you very much! I will read the linked documentation for this option. very helpful
[2019-03-14 20:04:36] <TrevorKS> Does this option allow a seperate IP on the host network? seems like this option just binds the containers ports directly to the hosts IP, but doesnt allow me to asign the container its own seperate IP on the network
[2019-03-14 21:08:54] <deathgaze> Sometimes I see people refer to these docker environment variables that look like{{.Task.ID}}or something like that in docker commands and in docker compose files.  where are these variables documented?
[2019-03-14 23:56:36] <roychri> deathgaze: This looks like go template variable substitution, like what is used in Helm (Kubernetes)
[2019-03-15 05:13:13] <matrixbot> zamzingI have two containers, one is a text editor and the other a browser (Firefox).  How do I link them so that I can display links or HTML pages from the editor in the browser?  Or more generally, how can I execute an application in one container from inside a another container?  The containers are on the same host (Linux).
[2019-03-15 05:31:20] <matrixbot> zamzingKirk Sefchik (Gitter): Typically these are JSON fields from detailed object metadata produced by dockerinspectcommands such asdocker container inspect <container_id>ordocker service inspect <service_name>
[2019-03-15 08:39:36] <gidyon> TrevorKS: You can assign a container an IP address only on user defined networks.
[2019-03-15 08:40:50] <gidyon> create a network, pass the necessary options for subnets, driver or range, then run the container inside the network
[2019-03-15 08:41:31] <gidyon> only then, you can assign the container an IP address.
[2019-03-15 16:25:03] <Jacob_Bogers_twitter> hi
[2019-03-15 16:25:09] <Jacob_Bogers_twitter> if i bring up ubuntu
[2019-03-15 16:25:10] <Jacob_Bogers_twitter> it dies
[2019-03-15 16:25:12] <Jacob_Bogers_twitter> donno why
[2019-03-15 16:26:29] <Jacob_Bogers_twitter>  [<-CODE->] 
[2019-03-15 16:29:25] <Jacob_Bogers_twitter> logs
[2019-03-15 16:29:26] <Jacob_Bogers_twitter> $ docker-compose upCreating ubuntu-bionic ... doneAttaching to ubuntu-bionicubuntu-bionic exited with code 0
[2019-03-15 18:17:40] <iosven> Hi! When I do adocker login my.gitlabdockerregistry.net:5005is it possible to manipulate/configure the address where within this login processdockergets the auth token from? The thing is I need this to be a different port than 443.
[2019-03-15 18:31:47] <TrevorKS> Jacob_Bogers_twitter: I believe this is expected, there is no further instructions for the conatiner to do so its exits with error code 0. Error code 0 is not a real error, its telling you it exited as expected.
[2019-03-15 18:32:28] <TrevorKS> Normally a service will be running in a container, keeping it alive
[2019-03-15 19:49:40] <Jacob_Bogers_twitter> yeah, i need to do ssh deamin ot tty deamon or something
[2019-03-15 19:49:55] <Jacob_Bogers_twitter> i found out
[2019-03-15 19:50:18] <Jacob_Bogers_twitter>  [<-CODE->] 
[2019-03-15 19:50:56] <Jacob_Bogers_twitter> I addedstdin_openandttyand run  withdockercompose run ubuntu
[2019-03-15 19:51:02] <Jacob_Bogers_twitter> then it works
[2019-03-15 20:17:02] <Genysys> I am trying to build an image from the following Dockerfile: [<-CODE->]  [<-CODE->] I will appreciate any pointers on this
[2019-03-15 21:03:55] <Genysys> I have moved past this error
[2019-03-15 21:04:04] <Genysys> I have a new one.
[2019-03-15 21:04:12] <Genysys> I cant get make to work in alpine
[2019-03-15 21:05:22] <Genysys>  [<-CODE->]  [<-CODE->] Here is what my Dockerfile looks like now: [<-CODE->] 
[2019-03-16 21:25:25] <leojonathanoh> why is doing this so slow, compared to on the host? My docker daemon is using cloudflare dns, /etc/resolv.conf has 127.0.1.1docker run --rm -it alpine:3.8 nslookup cloudflare.com
[2019-03-16 21:40:01] <robertmain> hi folksrunning docker in a container with host networkingwhen i start my container, lighthttpd fails to start [<-CODE->]  [<-CODE->] 
[2019-03-16 21:51:20] <leojonathanoh> robertmain: check that you are not forwarding your $DOCKER_HOST variable to another host
[2019-03-16 21:51:50] <robertmain> leojonathanoh: not following what you mean
[2019-03-16 21:52:16] <robertmain> my docker-compose config looks like this: [<-CODE->] 
[2019-03-16 21:53:21] <leojonathanoh> how many docker VMs do you have?  are you using a swarm ?
[2019-03-16 21:53:46] <robertmain> 1 and no
[2019-03-16 21:53:53] <robertmain> by "docker VMs" do you mean containers?
[2019-03-16 21:54:06] <leojonathanoh> i see you r docker-compose config does not publish a port
[2019-03-16 21:54:22] <robertmain> that's because i'm using network_mode: host
[2019-03-16 21:54:44] <robertmain> i need to do that because the docker container is going to be a DHCP server
[2019-03-16 21:54:47] <leojonathanoh> it would be better to define explicitly though, just in case the defaults are a different port
[2019-03-16 21:54:51] <robertmain> see above
[2019-03-16 21:55:39] <robertmain> if you define the ports explicitly the DHCP server doesn't work because you can't simply expose port 67 - it has to be on the actual network because DHCP works by broadcast
[2019-03-16 21:57:06] <robertmain>  [<-LINK->] 
[2019-03-16 22:06:45] <leojonathanoh> robertmain: i can't seem to find the Dockerfile for this, but i assume it runs on tcp 53 and  80 by default
[2019-03-16 22:07:18] <robertmain> leojonathanoh:  [<-LINK->] 
[2019-03-16 22:09:22] <leojonathanoh> robertmain: thanks. Based on the Dockerfile i see no reason for  your docker-compose to not be able to start
[2019-03-16 22:11:35] <leojonathanoh> might want to try docker-compose down && docker-compose up to clean things up
[2019-03-16 22:11:37] <robertmain> same
[2019-03-16 22:11:42] <robertmain> yes, ive done that
[2019-03-16 22:11:45] <robertmain> that's not the problem
[2019-03-16 22:12:10] <leojonathanoh> netstat -antpl doesn't say anything's on port 80 right
[2019-03-16 22:12:56] <leojonathanoh> try listing with netstat -antelup
[2019-03-16 22:13:09] <robertmain> it does not
[2019-03-16 22:13:15] <robertmain> there is nothing listening on port 80
[2019-03-16 22:13:29] <leojonathanoh> maybe there's  bug in the :latest, try an older image
[2019-03-16 22:14:12] <leojonathanoh> as it's always happens for me, :latest is never a good tag
[2019-03-16 22:15:50] <robertmain> more likely a config issue
[2019-03-16 22:20:50] <leojonathanoh> so the older images have the same issue?
[2019-03-16 22:21:06] <robertmain> /shrug
[2019-03-16 22:21:16] <robertmain> a config issue seems more likely than a broken image
[2019-03-16 22:21:40] <leojonathanoh> i see no issue with the config
[2019-03-16 22:22:01] <leojonathanoh> its a monolithic image
[2019-03-16 22:22:20] <leojonathanoh> chances of issues occuring in the image  is higher than if they split that up
[2019-03-16 22:22:48] <robertmain> also
[2019-03-16 22:22:56] <robertmain> that doesn't really address the root cause
[2019-03-16 22:23:07] <robertmain> i.e:WHYis there something apparently listening on port 80?
[2019-03-16 22:23:09] <robertmain> even though there isn't
[2019-03-16 22:23:16] <robertmain> im connected to the container right now
[2019-03-16 22:23:29] <leojonathanoh> it sounds to me that it's something wrong inside in the container
[2019-03-16 22:23:33] <leojonathanoh> it's not a host issue
[2019-03-16 22:23:59] <leojonathanoh> could be a false positive that it's 'already listening on port 80'
[2019-03-16 22:24:04] <leojonathanoh> that's why i said to try an older image
[2019-03-16 22:24:13] <robertmain> lsof -i :80shows nothing
[2019-03-16 22:24:25] <robertmain> so what's generating the false positive
[2019-03-16 22:24:44] <leojonathanoh> i dont know, but it wont harm to try an older image
[2019-03-16 22:24:44] <robertmain> also
[2019-03-16 22:24:50] <robertmain> how do you select an older image?
[2019-03-16 22:24:53] <robertmain> is it by git tag?
[2019-03-16 22:24:58] <leojonathanoh>  [<-LINK->] 
[2019-03-16 22:25:31] <leojonathanoh> try 4.2.1_or even the 4.1
[2019-03-16 22:26:40] <leojonathanoh> if u look though you notice the some tags have the same 'Last update' date, which actually are the same image. :latest now is 18 days ago
[2019-03-16 22:26:53] <leojonathanoh> so you need to select one that is 'Last update'  a month back or more
[2019-03-16 22:33:38] <robertmain> ill give that a shot, thanks
[2019-03-16 22:35:13] <leojonathanoh> robertmain: welcome
[2019-03-16 22:37:13] <robertmain> fixed it
[2019-03-16 22:37:21] <robertmain> turns out you have to specify an environment var with host networking
[2019-03-16 22:39:20] <leojonathanoh> robertmain: good to hear
[2019-03-16 22:39:35] <leojonathanoh> the error message wasn't very helpful though
[2019-03-16 23:00:35] <TrevorKS>  [<-LINK->] I know i asked this a few day ago, but i'm still confused, even with the additional stack exchange questions. Would a macvlan be a solution here? Whats a use case for a macvlan?
[2019-03-17 15:39:00] <robertmain> leojonathanoh: indeed not. Neither was the documentation for the image
[2019-03-17 17:09:44] <Genysys> Hi all
[2019-03-17 17:09:51] <Genysys> I have this docker container
[2019-03-17 17:10:01] <Genysys>  [<-CODE->] 
[2019-03-17 17:10:38] <Genysys> this line keetps failing withno file called config.tomlfound
[2019-03-17 17:10:51] <Genysys> when i ssh into the container, I can see it
[2019-03-17 17:10:57] <Genysys> would appreciate any pointers
[2019-03-18 09:22:24] <BaVanDuong> Genysys: I think should be:RUN     sed -i \'\' \'s/persistent_peers = ""/persistent_peers = "89e4b72625c0a13d6f62e3cd9d40bfc444cbfa77@34.65.6.52:26656"/\' config.toml
[2019-03-18 09:22:32] <BaVanDuong> Instead: RUN     sed -i \'\' \'s/persistent_peers = ""/persistent_peers = "89e4b72625c0a13d6f62e3cd9d40bfc444cbfa77@34.65.6.52:26656"/\' .gaiad/config/config.toml
[2019-03-18 11:53:12] <xlanor> Hi guys
[2019-03-18 11:53:23] <xlanor> I have a docker-compose file that I'm trying to deploy an application on
[2019-03-18 11:53:40] <xlanor> Currently, I have a host postgresql running on my server, but the application itself is dockerised
[2019-03-18 11:54:18] <xlanor> I'm currently trying to connect to the host database from the application, but for some reason, it doesnt seem to be able to find it
[2019-03-18 11:54:38] <xlanor>  [<-CODE->] 
[2019-03-18 11:54:50] <xlanor> can anyone tell me if I'm doing anything wrong here?
[2019-03-18 11:55:05] <xlanor> from there, I attempt to connect to postgres via
[2019-03-18 11:55:23] <xlanor>  [<-CODE->] 
[2019-03-18 11:55:52] <xlanor> I'm repeatedly getting this [<-CODE->] 
[2019-03-18 11:56:15] <xlanor> and I'm really unsure if this is due to an issue with my docker-compose configuration file
[2019-03-18 15:28:54] <ecaepp> xlanor: Have you verified that the database firewall allows connections from the Docker host.
[2019-03-18 15:44:34] <xlanor> yeap, I have
[2019-03-18 18:40:50] <pgrinaway> hey all, I'm having a bit of a strange issue. I'm trying to contact the docker daemon (on Mac OS,  Docker version 18.09.2, build 6247962) via its API + a unix socket. I can use curl to successfully call/container/create, but the same POST from my Rust code yields a 500 error (EOF). I assumed it was just my code, but when I usesocatto redirect a TCP port to the unix socket, the exact same Rust code works fine. Does anyone know (or have a good place to start looking) for why the same code would work with the TCP port but not the unix socket?
[2019-03-19 11:25:33] <Jacob_Bogers_twitter> hi
[2019-03-19 11:25:42] <Jacob_Bogers_twitter> i am having a problem with bind storage
[2019-03-19 11:25:47] <Jacob_Bogers_twitter> maybe someone can help
[2019-03-19 11:27:26] <Jacob_Bogers_twitter> i will make a test repo on git moment
[2019-03-19 11:53:16] <Jacob_Bogers_twitter>  [<-LINK->] 
[2019-03-19 11:53:19] <Jacob_Bogers_twitter> here it is
[2019-03-19 11:53:23] <Jacob_Bogers_twitter> any activity here?
[2019-03-19 11:53:26] <Jacob_Bogers_twitter> )))
[2019-03-19 15:56:01] <rajeshcis> Hi ,I am also getting same error as@xlanoris getting
[2019-03-19 15:57:20] <rajeshcis> same docker file is running on the Ubuntu 16.04 and Mac but not running on theUbuntu 18.04
[2019-03-19 15:57:46] <rajeshcis>  [<-CODE->] 
[2019-03-19 16:00:28] <ecaepp> rajeshcis: This sound like it is either a firewall issue or a premissions issue with the database.
[2019-03-19 16:03:26] <rajeshcis> but when I checked by thedocker logs containername
[2019-03-19 16:03:54] <rajeshcis> postgress container is running
[2019-03-19 16:57:55] <christhomas> hey guys, on mac is there anything special I need to do to bind to my hosts port 53?
[2019-03-19 16:58:46] <christhomas> I can run a docker container, bind it to port 53 and port 10053, then dig@127.0.0.1-p 10053 slashdot.org and it'll return a result, but if I try port 53, I get silence. It's almost like my traffic is being snuffed out silently
[2019-03-19 17:01:07] <ecaepp> christhomas: Just curious why you are trying to bind DNS port to your container?
[2019-03-19 17:01:31] <christhomas> because I want to run a dns server on it
[2019-03-19 17:04:08] <christhomas> is there any reason why running a dns server would be a problem?
[2019-03-19 17:04:23] <ecaepp> christhomas: not at all.
[2019-03-19 17:04:24] <christhomas> cause it's weird how the same software will respond on the 10053 port, but not the 53 port
[2019-03-19 17:04:49] <ecaepp> christhomas: I am digging around seeing if I can find anything.
[2019-03-19 17:05:20] <christhomas> yeah I've spent a while doing the same, it's very odd how nothing in the software configuration is diffenent, except the port is bound different
[2019-03-19 17:08:42] <ecaepp> christhomas: what OS and container are you running if you don’t mind me asking?
[2019-03-19 17:10:03] <christhomas> and I know a version of docker where it will start working again
[2019-03-19 17:10:06] <christhomas> mac os x mojave and I just installed the latest docker today 2.0.3.0
[2019-03-19 17:10:58] <christhomas> it seems if I downgrade, it'll start working again :/
[2019-03-19 17:11:16] <ecaepp> christhomas: thanks, If get some time today I start testing to see if I can a solution.
[2019-03-19 17:12:14] <christhomas> I'm reinstalling docker 29268 from this link: https://download.docker.com/mac/edge/29268/Docker.dmgand this, I'm 100% sure will start working again
[2019-03-19 17:12:29] <christhomas> cause I've done this before, if I use this version it works, if I upgrade, it stops working
[2019-03-19 17:12:53] <ecaepp> possible bug?
[2019-03-19 17:13:09] <christhomas> no ideaw
[2019-03-19 17:24:20] <christhomas> I'm playing around with the versions now and I'll report it if this is something that nobody knows about
[2019-03-20 02:50:16] <Carson-Yu> Hi! How to configure the domain name for nginx in docker???
[2019-03-20 04:22:52] <fullstackcicd_gitlab> How do I configure .gitlab-ci.yml to run my app 100% in DIND? I am trying to find the Gitlab community to ask them, but thought I\'d ask here.  My google fu for "gitlab DIND" gives me the wrong results .. about creating docker registry.  I have an existing docker-compose.yml and I want it to run in its own environment 100% ... and not fail due to some weird one-off issue with the host machine (digital ocean) and so i can run it on my desktop
[2019-03-20 05:04:11] <xlanor> rajeshcis: , when switching over to dockerise postgres mine turned out fine. I'm guessing it was a database setting issue
[2019-03-20 06:01:17] <rajeshcis> xlanor: do I need to set anything into thepostgresql.conffile ?
[2019-03-20 06:01:32] <xlanor> I was using the default postgres from the image
[2019-03-20 06:01:39] <xlanor> didnt modify any configurations
[2019-03-20 06:02:09] <xlanor> maybe you want to post the docker-compose file?
[2019-03-20 06:03:22] <rajeshcis> issue is that same configration is working fine on other system likeUbuntu 16.04andMacbut not inUbuntu 18.04
[2019-03-20 06:03:53] <rajeshcis> ok let me share the docker-compose file
[2019-03-20 06:07:17] <rajeshcis>  [<-CODE->] 
[2019-03-20 06:08:05] <xlanor> I may be wrong
[2019-03-20 06:08:13] <xlanor> try connecting to the db on 4020
[2019-03-20 06:08:38] <rajeshcis> I tryed but not working
[2019-03-20 06:09:15] <xlanor> how about replacing this
[2019-03-20 06:09:21] <xlanor>  [<-CODE->] With [<-CODE->] 
[2019-03-20 06:09:26] <xlanor> then connect to it on 5432
[2019-03-20 06:09:37] <rajeshcis> ok, let me try this
[2019-03-20 08:09:53] <rajeshcis> agan not working  with“5432:5432"
[2019-03-20 19:11:30] <Jacob_Bogers_twitter> hi
[2019-03-20 19:13:17] <Jacob_Bogers_twitter> i am trying to setup a private bind
[2019-03-20 19:13:28] <Jacob_Bogers_twitter> snippert
[2019-03-20 19:13:36] <Jacob_Bogers_twitter>  [<-CODE->] 
[2019-03-20 19:13:48] <Jacob_Bogers_twitter> how do i specify an "rw" bind in this dockercompose snippet
[2019-03-20 20:38:47] <dansok> Hi, I am trying toCOPYa file into~/unsuccessfully thus far..
[2019-03-20 20:39:59] <dansok> but he complainsCOPY failed: stat /var/lib/docker/tmp/docker-builderXXXXXXXXX/~/<MY-FILE>: no such file or directory
[2019-03-20 22:55:48] <Steveiwonder> Hey, Is it possible to override an EXPOSE from a parent image?
[2019-03-20 22:56:04] <Steveiwonder> I can't run an image due to it exposing a port that I have already in use
[2019-03-21 05:44:19] <miguelreng> Hey! What up?!Turns out in these days in Poetri (https://poetri.co) we're building some modules for NGINX that will be part of our architecture, and we realized that little to nothing is written about development for this web server.For that reason, we occurred to release an starter kit that aims to explain a little better the process and delve into the solutions we've found in some of the most frequent problems when building such modules.  https://github.com/CodeIsPoetri/ngx_http_hello_world_module?fbclid=IwAR2JDe1TfScM_Td635SCrM-PD7mIX8LWe17pCcdBJG3c-fYipObX6_zGFuA♀♂You're absolutely welcome to contribute as well as ask us your questions —we'll gladly be answering them—, and we'll be updating the repo as we keep sorting out issues that weren't previously solved yet out there on the internet.
[2019-03-21 16:37:20] <cuisongliu> Hi, i used "containerd" ued k8s cri container. but have some cni error . someone used it ?
[2019-03-21 17:42:13] <vsilent> deepu9: you have duplicates [<-LINK->] 
[2019-03-21 17:45:54] <vsilent> dansok: try absolute path  COPY  somefile.txt  /home/<user>/<otherdir>
[2019-03-21 17:59:13] <vsilent> deepu9: basic example [<-LINK->] 
[2019-03-21 18:24:02] <vsilent> rajeshcis: looks like postgres is not running,  what  "docker logs db" is saying ?
[2019-03-21 19:37:57] <Sharkbyteprojects>  [<-LINK->] 
[2019-03-21 22:19:27] <joshzamor> Is it possible for Docker running on Ubuntu running in a VM on Windows, without any host-shares, to somehow run incredibly slow or be effected by Windows?  I have a dockerized development environment (JDK, Postgres, etc) that runs fine in OSX and on other's Ubuntu installs.  On Docker for Windows it suffers greatly from the CIFS issues.  In the VM on Windows it runs fine outside of docker, but the integration tests come to a crawl when the JDK is in Docker on the VM.  Or in other words, in the VM with dockerized Postgres and JDK, all is well; in the VM with a dockerized JDK and same Postgres, crazy slow (what takes 5m on lesser hardware takes > 5 hours).
[2019-03-22 09:31:36] <jakubsuchybio> Hi guys, does any of you have some reference or example for mounting volume from "Docker for Windows" into Windows Container? Because I tried already bazilion combinations but always getting "ERROR: for <container_name>  Cannot create container for service test: invalid volume specification: \'/c/docker-output:C:\\docker-output:rw\'"
[2019-03-22 09:32:55] <jakubsuchybio> it is for [<-CODE->] 
[2019-03-22 09:33:09] <vsilent> jakubsuchybio: left part is for host machine so should be windows style .  C:\\docker-output: /somevolume_in_container
[2019-03-22 09:33:40] <jakubsuchybio> Oh! I need to have existing volume inside container for it to work?
[2019-03-22 09:34:50] <rajeshcis> vsilent: I checked bydocker logs dbit is  running
[2019-03-22 09:34:50] <vsilent> in case you don't have dir in container an empty dir will be created on host machine
[2019-03-22 09:37:15] <vsilent> rajeshcis: I would check for incoming requests on port 5432 inside container using .  tcpdump -nnvvS -i any port 5432
[2019-03-22 09:38:07] <jakubsuchybio> vsilent: I have that directory already created on host machine. I don't have it pre-created inside container. But with the docker-compose.yml above I get exactly this: [<-CODE->] 
[2019-03-22 09:39:49] <vsilent> try . C:\\docker-output: /anyvolume      ,   I suppose you use a linux container ?
[2019-03-22 09:40:02] <jakubsuchybio> Nope, Windows Container
[2019-03-22 09:41:42] <vsilent> uhm .   you running windows server  I suppose
[2019-03-22 09:44:01] <vsilent> hmm , sorry did not deal with windows containers yet.
[2019-03-22 09:49:49] <jakubsuchybio> vsilent: Do you know anybody who did and could know the answer? Or maybe I should just create issue in docker/compose repo.
[2019-03-22 09:52:13] <vsilent> jakubsuchybio: I don't think so
[2019-03-22 09:52:54] <vsilent> jakubsuchybio: makes sense to ask  maintainers of the image I think
[2019-03-22 09:53:42] <vsilent> did you check this [<-LINK->] ?
[2019-03-22 09:58:49] <jakubsuchybio> vsilent: Not yet, will take a look, thanks
[2019-03-22 10:01:40] <vsilent> jakubsuchybio: I found and example there .    "d:\\content:c:\\inetpub\\wwwroot"
[2019-03-22 10:03:13] <jakubsuchybio> Well the thing is when I run that container without compose bydocker run -it -v C:\\docker-output:C:\\test microsoft/win\ndowsservercoreit runs fine and volume is mounted
[2019-03-22 10:03:30] <jakubsuchybio> But compose doesn't work with the same exact syntax
[2019-03-22 10:06:00] <jakubsuchybio> vsilent: 
[2019-03-22 10:07:42] <rajeshcis> vsilent:  [<-CODE->] 
[2019-03-22 10:08:11] <rajeshcis> and [<-CODE->] 
[2019-03-22 10:08:42] <vsilent> jakubsuchybio: I see.  You can try once again this :     "c:\\wwwroot": "c:\\wwwroot" .   , not sure
[2019-03-22 10:09:29] <jakubsuchybio> I think I found the problem. [<-LINK->] 
[2019-03-22 10:09:42] <jakubsuchybio> It says it cant point to c in container
[2019-03-22 10:11:41] <vsilent> jakubsuchybio: ok, nice
[2019-03-22 10:16:17] <vsilent> rajeshcis: I would mount pg_hba.conf  with  host all all 0.0.0.0/0 trust  and  postgresql.conf with "listen_address = \'*\'"  as a first step
[2019-03-22 10:43:39] <cuisongliu> hi ,i'm build the binary package for lxcfs. the link is [<-LINK->] . thans.
[2019-03-22 12:12:55] <Jacob_Bogers_twitter> hi
[2019-03-22 12:13:02] <Jacob_Bogers_twitter> i have an entry script that looks like this
[2019-03-22 12:13:21] <Jacob_Bogers_twitter>  [<-CODE->] 
[2019-03-22 12:13:32] <Jacob_Bogers_twitter> it works
[2019-03-22 12:13:43] <Jacob_Bogers_twitter> but i get a bash without any prompt
[2019-03-22 12:13:55] <Jacob_Bogers_twitter> andttyreturns "not a tty"
[2019-03-22 12:14:14] <Jacob_Bogers_twitter> anyone here?
[2019-03-22 14:08:55] <Steveiwonder> Hey all, is it possible to override an EXPOSE from a parent image? I can't run an image due to it exposing a port that I have already in use
[2019-03-22 16:24:23] <awilhelmer> Hello!Can i make a Dockerfile build to pass a build arg as array to define specific folders to copy? [<-CODE->]  [<-CODE->] 
[2019-03-22 16:28:38] <jdickey> awilhelmer: Our workaround for a similar problem was to write a small program that, depending on its command-line parameters, would write aDockerfilewith the specialisations we needed for a particular use case and then build an image from that. Our experience has led us to believe that keeping Dockerfiles as simple as possible is a Very Good Thing.
[2019-03-22 16:30:01] <jdickey> tl;drIf you have logic in a Dockerfile, You're Doing It Wrong
[2019-03-22 16:31:08] <awilhelmer> hmm thanks@jdickeyin my opinion that makes a dockerfile much more complex cause its generic :P
[2019-03-22 16:31:32] <awilhelmer> and this isnt a logic
[2019-03-22 16:32:03] <awilhelmer> COPY testa testb /opt/configsworks ...
[2019-03-22 16:32:10] <jdickey> No, the Dockerfile isn't generic; it copies only the folders you want for that particular use case. You tell it what folders to copy via the CLI that builds the Dockerfile
[2019-03-22 16:32:29] <awilhelmer> ahhh okay sorry
[2019-03-22 16:33:58] <awilhelmer> misinterpreted 'a smal programm ... would write a dockerfile ....'
[2019-03-22 19:42:08] <Fakau> Hello, i am new in docker, i use windows 10 pro 64bits, when i execute kitematic in docker i have this messageCONTEXT CANCELEDi need help please
[2019-03-25 12:44:01] <matrixbot> drok1Your problem is your using windows
[2019-03-26 01:19:57] <matrixbot> idanoo^
[2019-03-26 06:20:16] <1jacky> 有没有ｓｐｒｉｎｇ cloud\u3000的
[2019-03-27 09:05:59] <1jacky> 如此沉默
[2019-03-27 09:06:07] <1jacky> so slend
[2019-03-27 09:06:20] <1jacky> r u ok
[2019-03-27 09:06:38] <cuisongliu> no meiyou.
[2019-03-27 09:07:04] <1jacky> wo a 真的有人
[2019-03-27 11:18:51] <ptink> what is best practice when using docker-compose to split up docker files into environments? I need test/dev/prod environments where for example test builds and runs tests on the container, dev mounts local folders instead of building, and prod pulls down archived files and extracts them
[2019-03-27 11:19:19] <ptink> but do I need separate Dockerfiles for each environment? or at what stage do I separate them
[2019-03-27 14:51:05] <vsilent> ptink: create different docker-compose files like docker-compose-dev.yml , docker-compose-prod.yml . etc
[2019-03-27 14:53:18] <vsilent> but do I need separate Dockerfiles for each environment?Normally, there is no need.   In my projects I use different .env files . for dev and prod
[2019-03-28 02:56:12] <maximedubois> i'm using docker inside a .net core 2 solution and when I start debug with two different docker container and one tries to call the api from the other one I get this error:HttpRequestException: Cannot assign requested address
[2019-03-28 08:46:21] <cshiel> I have a similar problem.
[2019-03-28 22:30:09] <Knaledge> What is the best practice for utilizing 'docker-compose' in a multi-app dependent environment?For example:Repo 1 has core code (WebSocket Server~)\nRepo 1 has core tests (Cypress)\nRepo 2 has microservice (some worker attaching to WSS; repo 1)So far, we're thinking we can use compose to initialize the service 'WSS', then initialize the service 'cypress'.But what about the microservice? (repo 2)The goal is to be able to run tests for repo 2 (which depends on WSS/repo 1, using cypress)
[2019-03-28 22:31:11] <nafg> Knaledge: I don't understand the problem. By repo you mean the source code repository? Is a docker image published?
[2019-03-28 22:33:36] <Knaledge> @nafgBy repo you mean the source code repository?Yeah - we have our in-house-ish WSS in repo 1 , Cypress content in repo 1, microservice in repo 2. We're building a compose file in repo 1.Is a docker image published?No. We do have an instance of Harbor available to us - but this has not been required, thus far.
[2019-03-28 22:34:11] <nafg> What is Harbor?
[2019-03-28 22:34:30] <Knaledge> nafg:  [<-LINK->] 
[2019-03-28 22:34:44] <Knaledge> private docker container reg
[2019-03-28 22:35:19] <nafg> ah
[2019-03-28 22:35:29] <nafg> Is this for dev or prod or both?
[2019-03-28 22:36:06] <Knaledge> @nafgIs this for dev or prod or both?Dev, for now. We are trying to avoid any particular hackery that would preclude it from prod, but we're open-minded ;)
[2019-03-28 22:36:38] <nafg> What are you doing for prod so far?
[2019-03-28 22:37:43] <Knaledge> Deploying repos to VMs
[2019-03-28 22:37:55] <Knaledge> (ish)
[2019-03-28 22:37:58] <Knaledge> (rsync)
[2019-03-28 22:38:13] <Knaledge> Very transitional! ;p
[2019-03-28 22:38:40] <nafg> Knaledge: so right now on the server you build and run the image locally?
[2019-03-28 22:40:36] <Knaledge> Right now, we have a dev environment that we're testing out. We want to deploy to that dev environment a set of containers running code from repo 1 + repo 2
[2019-03-28 22:42:14] <nafg> oh when I said dev I meant local dev, not a staging server
[2019-03-28 22:42:43] <nafg> but my question was about prod, you are doing build+run locally?
[2019-03-28 22:45:43] <Knaledge> The full picture:We want to use Jenkins to trigger builds (for testing purposes). Here\'s the lay of the land:\nHoused within "repo 1"\nWSS code\nCypress content (specs, support files, fixtures, etc.)\n\n\nHoused within "repo 2"\nMicroservice (which connects to WSS ^ )We want to have the following occur when a change is committed to repo 1 (we\'d like to utilize \'docker-compose\' to will into existence the following):Jenkins spins up a working directory\nWithin that directory, we want..\nDocker container: WSS (from repo 1)\nDocker container: Cypress + \'contents (from repo 1)\'\nDocker container: microservice (from repo 2)
[2019-03-28 22:47:34] <Knaledge> So, we started drafting a compose file. As "services", we listed \'WSS\' and then \'Cypress\' (which depends on \'WSS\' service).Then...We were like, "Wait... but what about the microservice that is in \'repo 2\'?"
[2019-03-28 22:47:37] <Knaledge> and here we are
[2019-03-28 22:48:05] <nafg> I guess broadly speaking there are two directions. Either (1) jenkins will pull the other repo too, and build/run both, or (2) a separate jenkins build for the other repo
[2019-03-28 22:49:16] <nafg> with (2) if you push to both repos in a short space of time, the image for repo 2 may not be published for the job for repo 1 wants it
[2019-03-28 22:49:28] <nafg> (2) requires a docker registry
[2019-03-28 22:49:47] <nafg> (clearly you aren't using gitlab)
[2019-03-28 22:50:25] <Knaledge> nafg: - to be clear, the scenario would be: "a change is committed to repo 1" (which has WSS + Cypress content). The "other repo" (repo 2, with our microservice), would not be incurring a change. But we do want to run the tests for repo 2
[2019-03-28 22:50:36] <nafg> ever?
[2019-03-28 22:50:46] <Knaledge> Not for the sake of this question, no
[2019-03-28 22:50:55] <Knaledge> one hurdle at a time ;)
[2019-03-28 22:51:16] <nafg> I'm just pointing out that (2) implicitly assumes that a jenkins job for the version of repo 2 that you care about has completed already
[2019-03-28 22:51:55] <Knaledge> I suppose it\'s just not clear why Jenkins would be bothering with anything in "repo 2"
[2019-03-28 22:52:16] <Knaledge> (and that may be on me - I might be missing something. Apologies if so!)
[2019-03-28 22:52:31] <nafg> Well if you would publish repo 2 to a docker registry, it would make sense to do it with jenkins. But you definitely don't have to,
[2019-03-28 22:52:39] <nafg> you can save that hurdle for later :)
[2019-03-28 22:52:58] <nafg> so i'll rephrase
[2019-03-28 22:53:37] <nafg> (1) repo 1 job pulls both repos and does local build+run on both, (2) repo 1 job assumes repo 2 docker image exists and it can just refer to it in docker-compose.yml
[2019-03-28 22:55:42] <nafg> Knaledge: so I would start by choosing between those 2 directions to go in
[2019-03-28 22:58:19] <Knaledge> @nafg - got it! Thank you :)I'm thinking through a few follow-up questions now
[2019-03-29 09:34:15] <ptink> has anyone got a good resource for reading about named volumes and permissions? Im trying to do something pretty basic with docker-compose where I run one container, build a load of static files (as a non-root user), move them to an attached volume, then mount that volume as read only in a following container runtime but i seem to be falling at the  first hurdle- i build my static files, attempt to move them to the volume (mounted at /app/www/) and getmv: cannot create directory '/app/www/access': Permission denied
[2019-03-29 09:49:16] <ptink> it appears to be because the volume gets mounted as root:root despite the folder i've mounted it into on the container being chowned by my non-root user,so I'm looking for a way to mount the volume as my non-root user
[2019-03-29 09:50:47] <jain-neeeraj> hi@ptinkthere is a way of doing it,  use below flag in your conatiner spawning command--user=`id -u`
[2019-03-29 09:51:12] <jain-neeeraj> It will fetch current user of your host OS and pass it to the container.
[2019-03-29 09:51:46] <jain-neeeraj> Ideally, at the time of building the container you should provide the user which you will be using at the time of running the container
[2019-03-29 09:52:50] <ptink> i do that- i have a non-privileged user "python" that I switch to during building the container building
[2019-03-29 09:53:17] <ptink> that user doesn't exist on the host though, just the container
[2019-03-29 09:54:19] <ptink> i'm not sure how to use --user via docker-compose?
[2019-03-29 09:54:42] <ptink> is it justuser: python?
[2019-03-29 09:56:26] <ptink> if  I do a plaindocker run ... --user pythonit still mounts as root
[2019-03-29 10:20:34] <ptink> so the solution currently seems to be: create the mountpoint directory on the image beforehand and chown it before the mount
[2019-03-30 00:48:49] <kylegoetz>  [<-CODE->]  [<-CODE->] Why might this be? Permissions are rwx-r-xr-x for it, so shouldn't be a permissions issue.
[2019-03-30 00:49:44] <kylegoetz> Even when I am in root and type./my_and hit tab, sh completes the line correctly withrust_executableso the OS knows the file is there. Just when I try to run it, it barfs.
[2019-03-30 02:16:41] <kylegoetz> OKlddsuggests it's that alpine doesn't have some shared libraries that Rust assumes I'll have when I compile
[2019-03-30 13:48:37] <LeadQA> Hello, I'm new to dockers.  But need to know can we build selenium grid in docker for desktop applications built using electron framework?
[2019-03-31 04:00:15] <shashankbaluni> Please help me with below questionsHow should we build and share docker projects which have docker-compose files?\nhow to share database images with data?
[2019-03-31 17:54:25] <Sriniva63328880_twitter> Hi all
[2019-04-01 05:59:03] <lanycrost> Sriniva63328880_twitter: Hello
[2019-04-01 10:39:50] <jakubsuchybio> Hi, I have a question about networking, dns and docker. I want to DNS resolve hostname of a PC that is on local network with my host. I can ping it from host by name or IP. I can ping IP from container, but i can't ping it by name from container. Therefore DNS server inside container can't resolve it. I looked at DNS servers assigned to the container and 1st is the container itself and other DNS serveres are the same ones as on Host. So I now need to figure out, how to configure container's DNS server to delegate DNS resolution to the other servers, when the first doesn't find anything. Anyone has any ideas how to do it?
[2019-04-01 15:41:53] <patchie> i installed docker on my windows 10 computer.how do i turn on so that it has internet?
[2019-04-01 16:08:30] <roychri> patchie: What makes you think it does not have internet access?
[2019-04-02 16:09:31] <patchie> Apt install doesnt work. But pip install works. :S
[2019-04-02 19:51:16] <Luiggi13> Hey guys!!! How are you!!!! I already installed GitLab in a docker and all works fine. But when I’m trying to clone the repo from localhost (outside of docker)  I can’t connect and clone it.I tried with url directly localhost:32801/portal/core.git or http://172.17.0.3/portal/core.gitHas anyone encountered this problem? How have you solved it?Thanks a lot
[2019-04-02 19:51:57] <Luiggi13> the image: [<-LINK->] 
[2019-04-02 20:20:41] <Luiggi13> Resolved: Giving users permission
[2019-04-03 08:27:09] <patchie> I am new to docker. I have now setup a docker container on my win10 computer.I now want to create a windows service that runs the docker container. (so that i can start and stop the docker container using services.msc)is this possible?
[2019-04-03 20:18:18] <matrixbot> l_inusI recommend you using Linux.
[2019-04-03 20:18:24] <matrixbot> l_inuspatchie (Gitter):
[2019-04-03 20:19:51] <patchie> ?
[2019-04-04 01:21:15] <atomicdragonranch> I'm pretty new to docker and was trying to figure out why it's so slow.  I'm running it on Windows 10, and used Process Monitor to watch the calls it's making when I do something likedocker images ls -a, it scans my local directories, but it also scansmy_machine_name:5***0 -> an_ip_address:epmap.  These network calls take a significant amount of time, and I'm wondering if they're necessary, or if there's a way to mitigate the performance impact.
[2019-04-04 07:56:32] <zhaohongqun> Hello!
[2019-04-04 07:56:57] <zhaohongqun> container_linux.go:247: starting container process caused "write parent: broken pipe"
[2019-04-04 07:57:56] <zhaohongqun> What should I do to solve this problem?
[2019-04-04 07:58:37] <zhaohongqun> This error ancoured when I start a docker image!
[2019-04-04 10:22:23] <vsilent> zhaohongqun: how do you start your container
[2019-04-04 12:11:09] <gchokeen> Hi , I trying to write simple shell pipeline script using docker container, can someone help me one this. I have EXPORT.sh file in the docker volume for container "mssql-tools". export shell script contains bcp export command. So I want to start the docker container and run the export.sh which is inside the volume and then once this export completed I want rm the container then synchronously need to copy the artefacts from volume to another location and need next docker
[2019-04-04 12:11:25] <gchokeen> So All the action need to work synchronously
[2019-04-04 12:13:16] <gchokeen> docker run --volume=$PWD/csv:/tmp/ --name 'bcp-pipe' -it mcr.microsoft.com/mssql-tools sh /tmp/EXPORT.sh
[2019-04-04 12:13:53] <gchokeen> I tried this but It'sEXPORT.shrunning outside docker container
[2019-04-04 12:14:34] <gchokeen> Can someone tell me how to run immediately once docker ready to execute the sh command inside  container
[2019-04-04 12:41:41] <matrixbot> mkalusWhy do you use -it? An rm-Container schould contain --rm, right? As far as I understood, you want to create a container and run an export script once, right?
[2019-04-04 12:50:16] <gchokeen> I just modified my script bit like this
[2019-04-04 12:50:23] <gchokeen> docker run  -it --rm --volume=$PWD/csv:/tmp/  --name 'bcp-pipe' -it mcr.microsoft.com/mssql-tools /tmp/EXPORT.sh
[2019-04-04 12:51:10] <gchokeen> But I'm getting error like this
[2019-04-04 12:51:14] <gchokeen> docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused "exec: \\"docker\\": executable file not found in $PATH": unknown.\nERRO[0000] error waiting for container: context canceled
[2019-04-04 12:52:55] <gchokeen> I just followed this method : [<-LINK->] 
[2019-04-04 13:40:46] <matrixbot> exarkunHi.  Docker containers on my laptop can't route traffic anywhere outside the container. [<-LINK->] Help?
[2019-04-04 13:45:12] <matrixbot>  [<-CODE->] Hard to say without more info. I would remove -it from the command, since you do not want to run the script interactively. If you want to test, you could execute it with -it and bash or ash instead of /tmp/EXPORT.sh. Once you are on the shell inside the container, try to run the script by hand to check.The error conveys that the exec was not found. Is your script correctly spelled (upper-/lower case?), does the shell have the correct permissions (x) and is the shebang correctly set (which shell do you use)?
[2019-04-04 13:46:13] <matrixbot> mkalusYou should check the environment of [<-LINK->] to see what the container can do and what shell it runs on.
[2019-04-04 13:47:47] <gchokeen> It's shell script defently works when I run it manully in the shell
[2019-04-04 13:48:03] <gchokeen> But I want to make it automatic
[2019-04-04 13:48:42] <gchokeen> docker run  --rm --volume=$PWD/csv:/tmp/  --name \'bcp-pipe\' -it mcr.microsoft.com/mssql-tools /bin/bash -c "/tmp/EXPORT.sh"
[2019-04-04 13:49:12] <gchokeen> I removed -it but the above command trying to run EXPORT.sh outside container
[2019-04-04 13:49:32] <gchokeen> I don't know what I'm doing wrong, this the first time I'm playing with docker
[2019-04-04 13:50:47] <gchokeen> /tmp/EXPORT.sh: line 40: bcp: command not found
[2019-04-04 13:50:47] <vsilent> --rm means container will be removed right after EXPORTED.sh worked out
[2019-04-04 13:51:05] <vsilent> is this what it supposed to do ?
[2019-04-04 13:51:39] <gchokeen> Yeah that's what i want do, because I gonna run this  script once in a day using cron job
[2019-04-04 13:54:38] <gchokeen> I was expecting/bin/bash -c "/tmp/EXPORT.sh"runs inside the container but not happens
[2019-04-04 13:57:53] <vsilent> gchokeen: Are you sure this image contains /tmp/EXPORT.sh ?
[2019-04-04 13:58:46] <vsilent> oh , you mount it
[2019-04-04 13:58:59] <gchokeen> Yes because when I'm attaching  volume and when I run manually in interactive it works well
[2019-04-04 14:05:04] <matrixbot>  [<-CODE->] What do you do to run the container interactively?
[2019-04-04 14:05:12] <matrixbot> mkalusI mean, the command
[2019-04-04 14:05:50] <gchokeen> once containter starts , it's showing cli terminal
[2019-04-04 14:06:01] <gchokeen> then I'm running this command /tmp/EXPORT.sh
[2019-04-04 14:06:17] <vsilent> gchokeen: Not sure you can execute a script  right  at the same time when you mount it from localhost
[2019-04-04 14:09:43] <matrixbot> mkalusMaybe a workaround, but what about excuting something like/bin/bash -c "sleep 1; /bin/bash /tmp/EXPORT.sh". I know, I know, some nasty hack...
[2019-04-04 14:10:24] <vsilent> Not sure,  He needs first to create a container and after that execute script
[2019-04-04 14:12:01] <gchokeen> I tried sleep still same issue
[2019-04-04 14:12:15] <gchokeen> I think script is not even working inside
[2019-04-04 14:25:27] <matrixbot> mkalusHm, do you see the script if you are inside the container? Can you execute it?
[2019-04-04 14:27:57] <gchokeen> main objective of using docker container is use the mssql tool like bcp command,  but simply bcp itself not found in the following example
[2019-04-04 14:28:02] <gchokeen> docker run  --rm --volume=$PWD/csv:/tmp/  --name \'bcp-pipe\' mcr.microsoft.com/mssql-tools /bin/bash -c "bcp"\n/bin/bash: bcp: command not found
[2019-04-04 14:29:11] <vsilent> worked here
[2019-04-04 14:29:26] <gchokeen> really!!!
[2019-04-04 14:29:27] <vsilent> docker run --volume="$PWD/export.sh:/tmp/export.sh"  --name bcp-pipe -it [<-LINK->] bash -c "chmod 0777 /tmp/export.sh;/tmp/export.sh" --rm --user roothello
[2019-04-04 14:30:28] <matrixbot> mkalusThat's what I guessed. Make the script executable :-)
[2019-04-04 14:30:57] <vsilent> refactored in order to remove old container:  docker run --rm  --volume="$PWD/export.sh:/tmp/export.sh"  --name bcp-pipe -it [<-LINK->] bash -c "chmod 0777 /tmp/export.sh;/tmp/export.sh"hello
[2019-04-04 14:32:06] <vsilent> cat export.sh!/bin/bashecho "hello"
[2019-04-04 14:33:28] <gchokeen> just testing it
[2019-04-04 14:40:49] <gchokeen> I think it's not running  command inside container
[2019-04-04 14:40:53] <gchokeen> docker run --rm --volume="$PWD/export.sh:/tmp/export.sh" --name bcp-pipe-x -it mcr.microsoft.com/mssql-tools bash -c "chmod 0777 /tmp/export.sh;/tmp/export.sh" --rm --user root\nhello\n/tmp/export.sh: line 3: bcp: command not found
[2019-04-04 14:41:10] <gchokeen> it saysbcp: command not found
[2019-04-04 14:42:04] <vsilent> line 3: bcp: command not found .    What do you have inside export.sh
[2019-04-04 14:42:17] <vsilent> looks like the problem in script
[2019-04-04 14:42:54] <gchokeen>  [<-CODE->] 
[2019-04-04 14:43:01] <vsilent> what is bcp ?
[2019-04-04 14:43:33] <gchokeen> bcp is the cli tool to export data as csv file from mssql table's
[2019-04-04 14:43:36] <vsilent> try using full path to it
[2019-04-04 14:59:21] <gchokeen> Wow yes that the issue
[2019-04-04 15:03:54] <gchokeen> Thanks@vsilentI will try implement and see how it goes
[2019-04-04 16:57:47] <vsilent> gchokeen: I am happy to help
[2019-04-04 22:26:07] <vsocrates> Hi everyone! I have a Tomcat Docker container running and keep getting a 127.0.0.1:8080 Connection Refused error and am having a lot of trouble understanding this
[2019-04-04 22:26:31] <vsocrates> I have multiple services running in the container and they are unable to communicate with one another, anyone have any clues?
[2019-04-05 02:57:46] <roychri> Multiple services running in the same container? You should not do that. One container per service.
[2019-04-05 03:00:45] <roychri> Make sure the service is binding to the right interface. Bind to all interfaces to make it easier. Usually 0.0.0.0 I think.
[2019-04-05 08:13:40] <vsocrates> okay I actually tried docker-compose with multiple containers and a user defined network and I have the same problem
[2019-04-05 08:13:56] <vsocrates> what do you mean by bind to 0.0.0.0? Thanks for the help!
[2019-04-05 08:14:32] <vsilent> vsocrates: bind  0.0.0.0:8080
[2019-04-05 11:06:21] <jakubsuchybio> vsilent: Hi, have you ever tried setting different env variables for the same docker-compose running multiple times with different -p (project name)?
[2019-04-05 11:09:34] <jakubsuchybio> I tried via "Substitute environment variables" but I am creating those multiple instances in parallel, so it is not thread-safe
[2019-04-05 11:11:12] <jakubsuchybio> I haven't found how to set env variables through docker-compose up command. :/ Is it somehow possible?
[2019-04-05 11:43:49] <jakubsuchybio> Only thing that just came into my mind is to create another docker-compose.yml dynamically where I will override environments for each instance and after stopping I just destroy that override file
[2019-04-05 11:45:13] <jakubsuchybio> And upping the instances with 2 yml files, first static and second dynamic for environment overwritting
[2019-04-05 12:24:32] <roychri> vsocrates: for the different services to connect with docker compose you have to use the service name as the host name.
[2019-04-05 13:45:38] <vsilent> jakubsuchybio: I would simply use different env file names. So for docker-compose-prod.yml  ,  .env-prod  for docker-compose-dev.yml  .env-dev .
[2019-04-07 07:57:22] <yinchaojiaa> what mean it is
[2019-04-08 01:56:19] <vsocrates> vsilent: @roychrithanks for the feedback. I was using the service name and my issue was within the container which is why I was confused. it turns out that I just had to increase the memory limit in docker. I'm not sure how that manifested in a Connection Refused error but thanks for the help. It's been fixed!
[2019-04-08 07:33:44] <jakubsuchybio> vsilent: Well our usecase is something different. :) We are trying to use docker for load testing. With one docker-compose we deploy FakeClient + proxy service and we are load testing our server. And I needed to set different names in env variables for each instance of different -p. But as I mentioned on second post, I figured it out by creating dynamic yaml overriding few env variables that are different between instances and it works just fine :)
[2019-04-08 16:29:27] <vsilent> jakubsuchybio: ok,  it makes sense also to look at Vault  by hashicorp, where you can store  configurations securely for any number of nodes.
[2019-04-08 19:02:07] <zaubara> Hey! Is it possible to increase the shm_size in a docker stack environment to more than 64m? The entry seems to be ignored on deploy, and that's quite the issue I'm afraid. Any known workarounds?
[2019-04-09 13:16:52] <matrixbot> pandryHello there :3
[2019-04-09 14:16:57] <ghost~5bc98094d73408ce4fabf741> Hi, I am trying to connect my client to the endpoint docker-compose, normally ng serve (using angular) works fine but when I do it through compose the client is unreachable from the browser.
[2019-04-09 14:17:09] <ghost~5bc98094d73408ce4fabf741> compose part:
[2019-04-09 14:17:13] <ghost~5bc98094d73408ce4fabf741>  [<-CODE->] 
[2019-04-09 14:17:38] <ghost~5bc98094d73408ce4fabf741> dockerfile:
[2019-04-09 14:17:42] <ghost~5bc98094d73408ce4fabf741>  [<-CODE->] 
[2019-04-09 14:19:07] <ghost~5bc98094d73408ce4fabf741> previously I tried running with ""docker-start": "ng serve --host 0.0.0.0" instead of 127.0.0.1 in ports on compose but it also did not work
[2019-04-09 14:21:24] <ghost~5bc98094d73408ce4fabf741> I can setup a reverse proxy with nginx to bundle the routing together but I want to have a simple connection working first
[2019-04-10 02:53:58] <dangen-effy> Hi. I'm deploying node.js app. To reduce docker image file, i runnpm run buildoutside ofDockerfile. Is it okay? I'm worrying about that this is not fully containerized.
[2019-04-10 02:58:59] <SalathielGenese> No it is not OK
[2019-04-10 02:59:03] <SalathielGenese> dangen-effy: 
[2019-04-10 02:59:36] <SalathielGenese> Some NodeJS build binaries at installation.Binary is highly platform dependent
[2019-04-10 02:59:45] <SalathielGenese> And you're breaking that
[2019-04-10 03:33:08] <dangen-effy> SalathielGenese: Thanks
[2019-04-10 07:31:00] <lanycrost> dangen-effy: this can arise version conflict, as a simple solution you can build in the one container and integrate in another.
[2019-04-10 13:52:56] <ghost~5bc98094d73408ce4fabf741> whoa just whoa,
[2019-04-10 13:53:07] <ghost~5bc98094d73408ce4fabf741> I saw down to the docker-compose thing again today
[2019-04-10 13:53:26] <ghost~5bc98094d73408ce4fabf741> I had a background vpn client listening on 4200 from my old job..
[2019-04-10 13:53:35] <ghost~5bc98094d73408ce4fabf741> sat down*
[2019-04-10 14:57:11] <olipo186> Hi all! Quick question: I'm running a private docker registry with htaccess authentication and multiple users. What prevents user A from overwriting a docker image/tag that is maintained by user B?
[2019-04-11 01:36:05] <strengthen> Summary of all LeetCodes： [<-LINK->] 
[2019-04-11 08:48:06] <1jacky> '''i like this background so
[2019-04-11 08:48:26] <1jacky> ''''i like this background so i make a test'''
[2019-04-11 08:48:44] <1jacky> '''i like this background so i make a test'''
[2019-04-11 08:49:05] <1jacky> i like this background so i make a test
[2019-04-11 08:50:11] <1jacky> haha how can i make a black  background
[2019-04-11 11:41:50] <SalathielGenese> Hello folks, [<-CODE->] 
[2019-04-11 13:01:15] <SalathielGenese> OMG, I was just curious and it seems k8s already inject some variables
[2019-04-11 13:01:20] <SalathielGenese>  [<-LINK->] 
[2019-04-11 13:02:00] <SalathielGenese> But I cannotping $KUBERNETES_SERVICE_HOSTwhich just hangs
[2019-04-11 13:07:51] <AsixCompany_gitlab> It is possible  build a windows docker container  from gitlab ci?
[2019-04-14 11:10:15] <AmanUllah710> Docker totally down my system running on 4 GB RAM, terrible
[2019-04-14 17:47:45] <anikethsaha> Docker Compose question :here is my docker-compose.yml file : [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2019-04-15 04:34:18] <eddyLazar> Hey there guys. Anyone has a nice straightforward solution on how to deploy dockerized web application on remote VM. Host doesn't support docker out of the box
[2019-04-15 08:47:22] <Arkoprabho> eddyLazar: try using ansible? You'd need to setup docker on the remote VM using ansible, and then deploy the docket compose file. Check the web for ansible and docker compose integrations...
[2019-04-15 10:01:32] <eddyLazar> Arkoprabho: so what you are talking about is to put docker-compose on remote server with ansbile? and then run commands also with sensible?
[2019-04-15 11:50:06] <Sifiros> Hi guys, does anyone know an easy solution to deploy a docker running Linux on windows with a bluetooth LE (without a USB dongle) access ?
[2019-04-15 13:16:40] <Arkoprabho> eddyLazar: sorta.
[2019-04-15 13:17:55] <Arkoprabho> Not sure how efficient this would be. But this was something that popped in my head the moment you mentioned the problem statement. Ideally you'd need to simply rundocker-compose upand leave it be...
[2019-04-15 19:31:24] <faraazahmad> I've been trying forever butgo get github.com/docker/docker/clientdoesn't finish downloading the package
[2019-04-17 03:43:22] <josh18> when doingdocker image buildis it possible to specify the a parent directory as the context? E.g. I'm tryingdocker image build -f /somewhere/Dockerfile ../but it seems to hang indefinitely
[2019-04-17 04:52:53] <josh18> nevermind it works fine, it was hanging because I didn't know I had to add node_modules to.dockerignore
[2019-04-17 05:17:22] <dragonStandard123> Hello, guys, My NoxPlayer coflicts with docker. How can I resolve it.
[2019-04-17 10:38:14] <patniharshit> Hi, I was trying to study Docker architecture. I was looking for Docker's design documents or some blogs/articles from docker contributors to understand how Docker evolved as a software. But my searches haven't returned anything other than the Docker architecture page in docs. Would really appreciate if you can point me to some blogs/talks/docs.
[2019-04-17 13:24:15] <ka4ok85> hello everyone. could you please give any advices on how to install SSHFS inside container? It looks like SSHFS needs kernel modules inside container itself. Is it possible to use hosts kernel? What I am missing?
[2019-04-17 13:24:53] <develroo> sshfs is just a fuse layer.. should be accessible to you from in a container ?
[2019-04-17 13:27:34] <ka4ok85> container will contain applications that relies on SSHFS. Container start -> app runs connecting to remote host and doing it's things -> container stop. I don't need to access anything inside container from host.
[2019-04-17 13:28:37] <ka4ok85> I was able to install sshfs inside alpine container just fine. but when it comes time to mount a directory it does not work.
[2019-04-17 13:29:01] <develroo> Hmm then I am not sure.. the fuse modules needs to be loaded and not sure if the host has to load it then
[2019-04-17 13:29:31] <develroo> Yes.. I have just tested it.. you do..
[2019-04-17 13:29:52] <ka4ok85> it givesfuse: device not found, try 'modprobe fuse' first
[2019-04-17 13:30:02] <develroo> The host runining dockerd has to have the fuse modules loaded then you can use SSHFS inside he cotainer
[2019-04-17 13:30:56] <develroo> Ok maybe I am mistaken then. Someone else need to chip in about kernel module access as a CAP
[2019-04-17 13:31:11] <develroo> Yo might need to add the CAP when you start the container..
[2019-04-17 13:31:33] <ka4ok85> my host actually has these modules loaded. Maybe it's a version problem since my host is not alpine
[2019-04-17 13:32:04] <develroo> So for example in order to get the TUN device working you need to add --cap-add=NET_ADMIN
[2019-04-17 13:33:06] <ka4ok85> ah, I have seen similar when was googling. I will try. thanks for help!
[2019-04-17 13:34:07] <develroo> They are listed here
[2019-04-17 13:34:09] <develroo>  [<-LINK->] 
[2019-04-17 13:34:49] <develroo> SYS_MODULE     Load and unload kernel modules. Looks like what you need.
[2019-04-17 13:35:37] <ka4ok85> sounds promising. thank you.
[2019-04-17 13:35:51] <develroo> S'ok..
[2019-04-17 14:05:50] <ka4ok85> Simply adding cap-add did not make a trickdocker run --cap-add=SYS_MODULE -e RUN_JOB=transfer -it --rm --name alpine-app transfers-image. I wonder if I also need to run something inside container before I run mount command
[2019-04-17 15:58:28] <develroo> Not sure.. need a proper docker guru..maybe try IRC ?
[2019-04-17 17:08:29] <rajeshcis> any one can help me on this issue/usr/bin/env: ‘python\\r’: No such file or directory
[2019-04-17 17:08:54] <rajeshcis> I don't know why\\ris appanding on the script
[2019-04-17 17:10:11] <rajeshcis> I have already triedsed -i 's/\\r//' base/*.shanddos2unix
[2019-04-17 17:13:53] <rajeshcis>  [<-CODE->] 
[2019-04-17 19:04:13] <ka4ok85> in case anyone will have same question: SSHFS requires --privileged=true option
[2019-04-18 09:25:57] <guddutopper> I have a question regarding static IP assignment to docker containers, I am giving  static IP to a docker container C1 on network N1, now i stopped this container and joined some other container C2  to the network N1, this new container C2 got the IP of my old container C1 ?HOW IS THIS POSSIBLE? Because I assigned static IP to container C1 ?
[2019-04-18 09:37:37] <matrixbot>  [<-CODE->] Did you assign C1 the first IP in the N1 block?
[2019-04-18 09:39:10] <guddutopper> no
[2019-04-18 09:39:26] <guddutopper> I got some random IP from network N1 and made it a static IP
[2019-04-18 09:40:30] <guddutopper>  [<-LINK->] 
[2019-04-18 09:40:36] <matrixbot>  [<-CODE->] Did you assign it inside the container itself or with the docker run
[2019-04-18 09:41:23] <guddutopper> i am using a java client to deploy my container, there i am giving static IPS
[2019-04-18 09:41:30] <guddutopper> *IPs
[2019-04-18 09:44:17] <matrixbot> @deepit:matrix.orgSo your static IP address is outside the IP range?
[2019-04-18 09:44:45] <guddutopper> i have no specified a IP range while creating network
[2019-04-18 09:44:56] <guddutopper> *not
[2019-04-18 09:47:32] <matrixbot>  [<-CODE->] That's the issue then.  When you stop C1, then C2 sees the first IP address in the network block.
[2019-04-18 09:55:40] <guddutopper> so as given in the link above, i should assign IP address from out side the ip range ?
[2019-04-18 10:21:50] <matrixbot> @deepit:matrix.org> so as given in the link above, i should assign IP address from out side the ip range ?That's correct.  Make an IP range that is smaller than the subnet size.  Then assign the static IP an address outside of the IP range.
[2019-04-18 12:14:48] <anikethsaha> how to structure the dockerfile and expose two ports as I have a project inside a project and which needs to be there and also Its getting deployed to kubernetes cluster and want to use the two ports from that
[2019-04-18 12:16:38] <Arkoprabho>  [<-CODE->] And then map these ports to appropriate ports in Kubernetes service
[2019-04-18 19:00:07] <anikethsaha> Arkoprabho: So Is it possible to have multiple containerPort in service ?
[2019-04-19 22:28:57] <slavajacobson> hey guys,  i used docker composer to setup 2 services from wordpress and ruby images, how do i make ruby command available within wordpress container? my understanding it was possible with "links" but it\'s being deprecated?
[2019-04-20 15:37:39] <matrixbot> Dag StenstadSlava (Gitter): I don't understand what you are trying to accomplish, could you try to explain more in depth?
[2019-04-20 17:06:51] <slavajacobson> Say I have 2 services created from images ruby and wp-cli and I have a ruby script that relies on wp-cli, i have a script.rb that runs wp-cli command, so I can tell the ruby service to run script.rb but it will throw an error saying wp-cli isn't installed because it's in a separate container.
[2019-04-20 17:08:45] <slavajacobson> Is the only solution to create a custom image from ruby image and tell it to install wp-cli within the Dockerfile?
[2019-04-21 08:21:11] <nnddominic> I am getting stuck to run mysql service with docker toolbox, anyone can help me?
[2019-04-22 03:57:17] <Arkoprabho> anikethsaha: yes it is.. Check [<-LINK->] 
[2019-04-22 10:23:59] <aymenbraiek>  [<-LINK->] any solution for this error plz
[2019-04-22 13:58:46] <ghost~5bc98094d73408ce4fabf741> Hoi, the docker-compose generated by visual studio has the : ${DOCKER_REGISTRY-} env variable. Any idea where is that declared?I don't see it in the compose or dockerfiles
[2019-04-22 13:59:07] <ghost~5bc98094d73408ce4fabf741> example:
[2019-04-22 13:59:09] <ghost~5bc98094d73408ce4fabf741>  [<-CODE->] 
[2019-04-22 16:42:12] <nariman.mandi_gitlab> Hi , i maigrate my project to spring-boot v:2.0.9now the problem is when i am trying to build my application via docker , i have the err belowcom.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failurei am using openjdk:8-jre-alpine for running applicationi have a mysql container and a seprate application container but application container cannot see the database containermy docker compose files worked before migrationi think the problem is SPRING_DATASOURCE_URL  environment variableany ideas?
[2019-04-23 17:42:06] <aritomelo> hi all
[2019-04-24 04:22:51] <anikethsaha> Arkoprabho: Thanks
[2019-04-24 08:23:56] <matrixbot>  [<-CODE->] If you are having issuess your can try these fixes Microsoft/DockerTools#130
[2019-04-24 11:57:07] <omiozil> Nhghba
[2019-04-24 12:48:29] <theahmadzai> Hello
[2019-04-24 12:50:26] <theahmadzai> Does docker (switch to windows containers) run windows containers natively in my windows 10 OS without any virtual machine?
[2019-04-24 18:36:11] <matrixbot>  [<-CODE->] It uses Hyper-V by default.  Need Windows 10 Pro or Enterprise edition.  Docker Toolbox for Home edition.
[2019-04-25 03:02:38] <SeptBlast> Hi Matrix,
[2019-04-25 03:03:45] <SeptBlast> In win 10, docker need and virtulization unit to fulfil its requirements if containers. So either hyper -v or orcale virtual box is required for it
[2019-04-25 03:04:20] <SeptBlast> For using oracle virtual box as the virtualizer,
[2019-04-25 03:05:55] <SeptBlast> Use docker toolbox to configure oracle virtual box as the host virtualizer
[2019-04-25 03:06:13] <SeptBlast> matrixbot: it might help u out
[2019-04-25 05:49:35] <migueldiganchi_twitter> Hello! I\'m a software developer who just started with docker...I recently started a new app using this repo https://github.com/mrcoles/node-react-docker-compose.I cloned and I modified it to run (understanding very little) and everything is fine until now.I need right now to implement mysql in that app. And for that, I installed mysql within my machine. But it seems that I need to use mysql container from hub.docker.com (because the application seems that don\'t know about mysql within the containers)...The question is: How can I utilize mysql utilizing the "docker" philosophy?
[2019-04-25 05:50:00] <migueldiganchi_twitter> Thank you for your attention!
[2019-04-25 05:54:19] <Arkoprabho>  [<-CODE->] You can step it up a notch by using docker compose and docker networks that would let you use service names instead of IPs to "discover" the database.If you dont want to use docker container for MySQL, give this link a try... It will let you utilize the MySQL installed on the host machine
[2019-04-25 05:54:35] <thilakrajrk> @migueldiganchi_twitter  you can add [<-CODE->]  [<-CODE->] 
[2019-04-25 06:06:53] <migueldiganchi_twitter> Arkoprabho: Thank you very much for your quick answer.  That is perfect! And based on what@thilakrajrksays too, do I need to first run "docker run...", and then setting up to the docker-compose? Or just configuring the docker-compose file like@thilakrajrksays will work? (sorry about my english)
[2019-04-25 06:09:01] <thilakrajrk> @migueldiganchi_twitterjust adding the service definition in compose is enough. compose will pull and create a container out of it
[2019-04-25 06:10:02] <migueldiganchi_twitter> Well@thilakrajrk, thank you very much for your answer too. Now, I need to know the question that I made to@Arkoprabho...Ijust ran "docker pull mysql". Now, what would the next step to get my app working with the mysql container?
[2019-04-25 06:11:55] <migueldiganchi_twitter> This is my docker-compose file:version: '2'services:  server:    build:      context: ./server/    command: /usr/app/node_modules/.bin/nodemon src/index.js    volumes: [<-CODE->] client:    build:      context: ./client/    command: npm start    volumes: [<-CODE->] Where do I need to put these lines? In the same level that client and server? Or within the server block?mysql:    image: mysql    restart: always    environment:      MYSQL_ROOT_PASSWORD: example
[2019-04-25 06:13:57] <thilakrajrk> migueldiganchi_twitter: now you have mysql image in your local repo. you can verify it by executingdocker images. The next step is to create a container using that image.docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysqlYour compose file should look somthing like this. [<-CODE->] 
[2019-04-25 06:22:20] <migueldiganchi_twitter> Thank you both very much!I have one last question. Based on the code from this repo: https://github.com/mrcoles/node-react-docker-compose. I have a Dockerfile in the server folder, and a Dockerfile in the client folder. So, if I want that who download my cloned repo, runs the app without problems, do I need to change something else?
[2019-04-25 06:29:56] <Arkoprabho> migueldiganchi_twitter: I see@thilakrajrkhas answered your query completely. He provides a rather wholesome solution.Can you elaborate on the last query. I could not understand you completely
[2019-04-25 06:30:26] <migueldiganchi_twitter> OMG, I put the mysql section in my docker-compose. Then I ran 'docker-compose down'. Then I ran 'docker-compose up'. And everything crash. I removed the mysql section, and now the app cannot see the packages
[2019-04-25 06:31:32] <migueldiganchi_twitter> that I installed with this command 'docker-compose exec client'; (Axios for example in client, or Mysql2 in server) :(
[2019-04-25 06:32:10] <thilakrajrk> migueldiganchi_twitter: Can you post some logs ? So that we can analyse the root cause
[2019-04-25 06:33:36] <thilakrajrk> migueldiganchi_twitter: You can customize your mysql container. Refere [<-LINK->] 
[2019-04-25 06:34:56] <migueldiganchi_twitter> Of course: [<-CODE->] 
[2019-04-25 06:35:59] <migueldiganchi_twitter> I was installed axios in my client with this command 'docker-compose exec client npm install --save axios'...and it was worked fine until now...
[2019-04-25 06:39:11] <thilakrajrk> I was installed axios in my client with this command 'docker-compose exec client npm install --save axios'...and it was worked fine until now... [<-CODE->] 
[2019-04-25 06:39:32] <Arkoprabho> migueldiganchi_twitter: I am not very fluent in node and react, but is there a way you can installaxiosandmysql2using the dockerfile?e.g in python we have a requirements.txt file and all all the python depedencies in that folder..
[2019-04-25 06:44:20] <migueldiganchi_twitter> "If you want those changes to be persistent, then you have to commit your changes like docker commit <container name/id> <image name/id>" wow! I didn\'t know that. So I need to reinstall them again, and the, do I need to run the docker commit?
[2019-04-25 06:44:39] <migueldiganchi_twitter> thilakrajrk: ?
[2019-04-25 06:45:46] <migueldiganchi_twitter> or even better? Just like@Arkoprabhosays. There is a way of install those packages through dockerfile on each folder? (client/ and server/)
[2019-04-25 06:47:34] <thilakrajrk> migueldiganchi_twitter: Yes you can follow 2 approaches. [<-CODE->] 
[2019-04-25 06:49:42] <migueldiganchi_twitter> thilakrajrk: , that's great! I prefer to use the first aproach...I will try right now
[2019-04-25 07:15:03] <omiozil> Hey guys I am new to docker, can you suggest me where to start from. Thank you.
[2019-04-25 07:15:59] <thilakrajrk> omiozil: you can start from [<-LINK->] 
[2019-04-25 10:06:14] <theahmadzai> Is there any performance boost of using windows containers over linux containers on windows OS for local development? (And what is this experimental flag thing)
[2019-04-25 10:07:14] <theahmadzai> Can docker containers run on windows 10 pro without virtualization (windows containers on windows pc)? they should run without virtualization because native host is also same or not?
[2019-04-25 15:31:42] <AmanUllah710> Hello docker community, please help me resolving thi issus:
[2019-04-25 15:32:59] <AmanUllah710> I want to share my drive but when I added my login then it shows an error of Invalid login/paaaword
[2019-04-25 15:33:06] <AmanUllah710> password*
[2019-04-25 15:45:56] <rcjsuen> "Share my drive"? And how is this question related to Docker exactly
[2019-04-25 17:09:18] <AmanUllah710> Docker wants to access local drive :D but needs user name and password. I entered both but there is an error in login/password. Don't know which login it's want. I inserted my system login.
[2019-04-25 19:04:10] <computersarecool> How do people handle getting large (like terabyte)image sets onto a docker image to do some image processing?
[2019-04-25 19:07:37] <RomeMoore> Hey all - I am working with some devs that use docker for local development - and we are having some performance issues due to innocent ignorance around the docker processes - any idea how to setup local Mac docker to protect them from themselves? Any good practices?
[2019-04-26 04:38:52] <Arkoprabho> AmanUllah710: by local drive do you mean the host file system?
[2019-04-26 04:58:39] <AmanUllah710> Arkoprabho: @rcjsuen"Docker
[2019-04-26 04:59:36] <AmanUllah710> Arkoprabho: @rcjsuen"Docker needs to access your file system
[2019-04-26 05:00:06] <AmanUllah710> Dockers needs to access your computer's file system
[2019-04-26 05:00:38] <AmanUllah710> That's the docker wants and when I login it shows an error in login/password
[2019-04-26 14:22:39] <robfr77> My frontend app is running locally but getting this error on docker-compose up:Node Sass could not find a binding for your current environment: Linux 64-bit with Node.js 10.xFound bindings for: OS X 64-bit with Node.js 10.x, 11Run npm rebuild node-sass to download the binding for your current environment.Do I need to go into the container and run that rebuild manually in a shell? I could also try running it from a Dockerfile entrypoint script right? Thanks
[2019-04-26 15:49:30] <johnpeeke> robfr77: Not as smart as others, but have you tried to do the build using a RUN command in your dockerfile so it is already built in that layer?
[2019-04-26 16:35:32] <rolong_gitlab> Hi, is there I way to use docker as my development environment? I mean is there a way I can just install a text editor on my machine, and start several docker containers and be able to code a program? What I want to do is to be able for example to execute agular-cli to create a new angular project, npm to install all dependencies for the program and even run the Karma test; all that from  containers. All information I\'ve found talks about "dockerising" your application it means put something you already created into docker, but I\'m looking for a way to create and run all the commands I need from docker that way on my machine I only provide a folder where the code is getting saved and only have to install a text editor(and docker of course).
[2019-04-26 17:52:57] <robfr77> I had success deleting node_modules and re installing everything, now to have the same issue again! Node Sass could not find a binding for your current environment: Linux 64-bit with Node.js 10.x. I went into the container and npm rebuild node-sass says: Cached binary found at /root/.npm/node-sass/4.11.0/linux-x64-64_binding.node. For some reason docker is not using the cached binary but pulling my local machine OSX environment. Okay I got it by running npm rebuild node-sass, so I will try putting that in my entrypoint script.
[2019-04-27 19:25:53] <rflw> I try to develop wordpress theme using docker.The problem is: I don't see my template in admin panel. I use template from [<-LINK->] so I'm sure that it's correct.This is mydocker-compose.ymlconfiguration: [<-CODE->] 
[2019-04-28 10:13:06] <aymenbraiek> hi everybody any doc help me to create docker image in my directory workspace not in docker hub
[2019-04-28 10:42:17] <pedroparraortega> aymenbraiek: do you mean to push the image to your private registry?
[2019-04-28 10:50:10] <aymenbraiek> yes@pedroparraortegai want to deploy angular app or spring boot app with jenkins and docker to ngnix server for ang app and tomcat sever fot java app
[2019-04-29 04:57:40] <webmasterdevlin> Hi. What are the use cases where I should include networks in my docker-compose?
[2019-04-29 09:52:51] <bkannadassan> Trying to run diskimage builder inside docker, Please let me know if anyone tried the same ?. I add device-mapper-event in DockerFile and during build I get D-Bus connection failed..
[2019-04-30 19:19:55] <dragonpiper> Has anyone used docker in a declerative pipeline ?
[2019-05-01 14:18:49] <sudoix> Hi
[2019-05-01 14:21:53] <RomeMoore> rflw: your path in volumes is off. If Wordpress is the base dir, you access like ./wordpress, not .wordpress
[2019-05-01 14:22:25] <sudoix> all: how to create docker compose for install apache and mariadb in a same container?
[2019-05-01 14:23:21] <rcjsuen> I would recommend against using@all...
[2019-05-01 14:23:40] <rcjsuen> In any case, it sounds to me like you should worry about creating a Dockerfile that has both Apache and MariaDB first before you worry about Docker Compose
[2019-05-01 14:26:19] <sudoix> I  create  Dockerfile
[2019-05-01 14:26:35] <sudoix>  [<-CODE->] 
[2019-05-01 14:27:16] <sudoix> And docker compose is:
[2019-05-01 14:27:50] <sudoix>  [<-CODE->] 
[2019-05-01 14:28:11] <sudoix> but not working correctly
[2019-05-01 14:29:21] <sudoix> please help me
[2019-05-01 14:37:08] <sudoix> How can i create docer container
[2019-05-02 04:01:56] <thecfguy_twitter> miladnorouzi1991: what kind of error you receive.
[2019-05-02 11:56:51] <omiozil> Hi Folks, I am Receiving below error when i use docker run command. Kindly suggest.
[2019-05-02 11:57:10] <omiozil>  [<-CODE->] 
[2019-05-02 12:14:51] <thilakrajrk> omiozil: I think you forgot to change the current IP address in your application config file
[2019-05-02 12:49:14] <omiozil> Thanks@thilakrajrk....yes its working now
[2019-05-02 14:38:52] <patchie> i have downloaded and run this docker image. but i nothing happens on port 80 or 8080 as i am using. how should i troubleshoot? [<-LINK->] 
[2019-05-02 15:34:12] <lancelot1969> This is my docker file. Which produces no errors. I use nginx server for port forwarding. It has its own Dockerfile.No errors so far. When I am running bokeh server through docker it loads only html template but not bokeh. Just added cython.What is missing can't figure out. [<-CODE->] 
[2019-05-02 15:46:27] <lancelot1969> I guess it has something to do with not correct configuration for nginx . Weird part is that it does not produce any errors.
[2019-05-02 18:39:54] <rightisleft> Is there anything close toStatefulSetsfrom K8 for Docker Swarm?
[2019-05-02 18:40:21] <rightisleft> I've been tracking the following issue on github [<-ISSUE->] 
[2019-05-02 20:58:59] <matrixbot> foxcrisis there any way to trigger an automated rebuild on hub.docker.com if the baseimage is updated (e.g. the debian or alpine base image)
[2019-05-02 20:59:58] <matrixbot> foxcrisi like to rebuild the image using the infrastrukture of hub.docker.com and not building it myself and uploading it
[2019-05-03 05:44:38] <omiozil> Hello Folks, I have docker images which is build using jar file who's  size is 29 MB, but Docker Image size is around 656 MB. Any idea why docker image size is so much. Thanks.
[2019-05-03 05:47:26] <matrixbot> foxcrisomiozil (Gitter): how big is the base image you are using?
[2019-05-03 05:47:49] <matrixbot> foxcrisPerhaps the used base image is already that big
[2019-05-03 06:26:13] <omiozil> matrixbot: thanks for the response.  but my thinking is that if we create another image with same base image and deploy both this images which are created from same base image on same cluster/machine. the memory utilisation is more here. Am i right to think in this way?
[2019-05-03 09:51:18] <matrixbot> foxcrisas far as i know this really depends on the additional command you applied in your dockerfile. I think it is not always so easy to see which temorary files are created which are not deleted.
[2019-05-03 10:55:40] <guddutopper> what does "/bin/sleep" command does in docker runfor examplesudo docker run -d --name alpine1 --net=none alpine /bin/sleep 1000
[2019-05-03 10:56:10] <SalathielGenese> The same thing it does on your host.
[2019-05-03 10:56:36] <guddutopper> if i run the above command without /bin/sleep, my container is stopped
[2019-05-03 10:56:46] <guddutopper> but by using /bin/sleep it keeps running
[2019-05-03 10:56:51] <SalathielGenese> It pause the script for 1000 seconds
[2019-05-03 10:56:55] <guddutopper> so i am not able to understand
[2019-05-03 10:57:20] <SalathielGenese> Try this :sleep 5 && echo "gudduutopper"
[2019-05-03 10:57:28] <guddutopper> how is that denying docker to stop the container ?
[2019-05-03 10:57:29] <SalathielGenese> In your host
[2019-05-03 10:57:34] <SalathielGenese> OK
[2019-05-03 10:57:38] <SalathielGenese> That's the real quesion
[2019-05-03 10:57:47] <SalathielGenese> So when you start a container
[2019-05-03 10:57:56] <SalathielGenese> You run a task
[2019-05-03 10:58:10] <SalathielGenese> That task you run have PID1
[2019-05-03 10:58:32] <guddutopper> so it is stopping that task having PID 1 ?
[2019-05-03 10:58:37] <SalathielGenese> When that process stops for whatever reason, the container is stopped automatically
[2019-05-03 10:59:15] <SalathielGenese>  [<-CODE->] It will stop after 10 seconds
[2019-05-03 10:59:40] <guddutopper> ok and it is stopping because i am not giving any network ?
[2019-05-03 10:59:53] <SalathielGenese> So with1000,  it will be stopped after 1000 seconds.
[2019-05-03 11:00:19] <SalathielGenese> No, it is not related to network
[2019-05-03 11:00:44] <SalathielGenese> ok and it is stopping because i am not giving any network ? [<-CODE->] 
[2019-05-03 11:00:46] <guddutopper> then why is my container stopping in the first place ?
[2019-05-03 11:00:47] <patrykk21> @guddutopper  the sleep command might be useful if you know that container is dependent on another service and the other service takes some amount of time to spin off.Your container stops because the process of PID 1 stops for whatever reason. Have you tried passing it another command like /bin/bash or something? Maybe 'tail -f /dev/null'
[2019-05-03 11:00:47] <guddutopper> yes
[2019-05-03 11:01:17] <SalathielGenese> I guess the full command is [<-CODE->] 
[2019-05-03 11:01:22] <SalathielGenese> ?
[2019-05-03 11:01:33] <guddutopper> what is 1000 here ?
[2019-05-03 11:01:48] <guddutopper> what is wrong in the commandsudo docker run -d --name alpine1 --net=none alpine
[2019-05-03 11:01:50] <SalathielGenese> I just removed/bin/sleepas  you said
[2019-05-03 11:01:56] <SalathielGenese> Oh
[2019-05-03 11:02:00] <guddutopper> yeah
[2019-05-03 11:02:14] <SalathielGenese> There is no command that the container should run
[2019-05-03 11:02:23] <SalathielGenese> So it starts and stops immediately
[2019-05-03 11:02:40] <SalathielGenese> You asked it to do nothing
[2019-05-03 11:02:51] <SalathielGenese> It does nothing and stops.
[2019-05-03 11:03:09] <SalathielGenese> You don't want dangling containers in running state, right ?
[2019-05-03 11:03:19] <guddutopper> ya
[2019-05-03 11:03:38] <SalathielGenese> Good
[2019-05-03 11:03:51] <SalathielGenese> BONUS
[2019-05-03 11:04:06] <SalathielGenese> Get rid of thesudoprefix to run docker
[2019-05-03 11:04:25] <SalathielGenese>  [<-LINK->] 
[2019-05-03 11:04:53] <patrykk21> If you want a linux container running and play with it in development then you can always run something likesudo docker run -d --name alpine1 --net=none alpine /bin/sh -c "tail -f /dev/null"
[2019-05-03 11:04:55] <guddutopper> thanks
[2019-05-03 11:05:09] <SalathielGenese> BONUS again
[2019-05-03 11:05:39] <SalathielGenese> If you want you container to me removed after it is stopped, use--rm
[2019-05-03 11:05:49] <guddutopper> could i ask azure VNET questions here ?
[2019-05-03 11:06:03] <guddutopper> like i want my docker container to get IP from azure vnet ?
[2019-05-03 11:06:09] <SalathielGenese> I think you can. I'm no Azure expert but I guess some are
[2019-05-03 11:06:56] <patrykk21> Docker containers should be unaware of ip addresses if you're using them as services through kubernetes or something like so
[2019-05-03 11:07:04] <SalathielGenese> BONUS last one [<-CODE->] 
[2019-05-03 11:07:23] <guddutopper> Here is an issue - [<-ISSUE->] someone please look into it, so I am able to give IP to my containers from azure VNETs but they are not able to communicate
[2019-05-03 11:07:24] <patrykk21> In alternative you can always do a get rqeuest to ipinfo.io or something like that in your entrypoint.sh and save that ip into a file
[2019-05-03 11:08:26] <SalathielGenese> Needless to combine-itand-d
[2019-05-03 11:08:41] <patrykk21> Oh, then I have no idea sorry.
[2019-05-03 15:04:13] <Ankit3794> Hello Guys, I am having aws ec2 instance with windows server 2016 on it. I have tried to install Docker for windows. But of no luck. So, Is there a way I can run docker CE on aws with windows server 2016 on it. If No, then Is Docker EE standard edition is free or will it cost.?
[2019-05-03 19:54:11] <lancelot1969> I got this weird error while running docker-compose build. I restarted docker. Did not help. [<-CODE->] 
[2019-05-03 19:54:57] <lancelot1969> I also ran  docker system prune
[2019-05-04 05:45:16] <lancelot1969> I have solved it by uninstalling paramiko for python 2.7.
[2019-05-04 11:29:29] <Kontributer> Having no familiarity with any of that, I’ll humorously say,Add GSSException to gssapi. 
[2019-05-04 18:46:34] <lancelot1969> It was caused by buggy version of glances which somehow depends on docker and paramiko
[2019-05-04 18:47:09] <lancelot1969> I wish there was just one version of python
[2019-05-06 11:29:15] <abdulsmrehman> Is there a way i can set nested values for a environemt-variablefor instance :RTDS :ADS :URL : GOOGLE.comI want to set the above values to a environement variable  say  "RHDS" ?
[2019-05-06 14:18:56] <rightisleft> Is there a good set of command line tools for querying common attributes from the docker hub registry ?
[2019-05-06 22:47:55] <tatitati> guys, begginner in here
[2019-05-06 22:48:33] <tatitati> i want to run a simple python script. I'm using an image with python. Can I run my basic script without mounting it into the image?
[2019-05-06 22:49:11] <tatitati> something like,docker run mypythonimage ./myscript.py
[2019-05-06 22:49:24] <lancelot1969> Does your image containt python distr?
[2019-05-06 22:49:28] <tatitati> yes
[2019-05-06 22:49:56] <lancelot1969> docker run -it mypythonimage
[2019-05-06 22:51:23] <tatitati> jumm.....can be without interactive mode?
[2019-05-06 22:51:25] <lancelot1969> docker run --name="scriptPy" -it image /bin/bash python myscript.py
[2019-05-06 22:51:33] <tatitati> ah ok, that is more my idea
[2019-05-06 22:51:36] <lancelot1969> Yep
[2019-05-06 22:51:36] <tatitati> thanks, I will try
[2019-05-06 22:56:15] <tatitati>  [<-CODE->] myscript.py is in the same folder than my dockerfile
[2019-05-06 22:56:21] <tatitati> something wrong?
[2019-05-06 22:56:49] <lancelot1969> you have to first go inside container and find the path
[2019-05-06 22:57:14] <lancelot1969> script has to be copied inside a container
[2019-05-06 22:57:58] <tatitati> thanks
[2019-05-07 16:32:21] <rcjsuen> You'd have to mount it, why don't you want to mount it
[2019-05-07 16:32:43] <rcjsuen> oh wait, nm, yeah, you can cp it I suppose
[2019-05-07 16:32:46] <rcjsuen> Into the running instance
[2019-05-07 17:00:22] <ghost~5bc98094d73408ce4fabf741> hoi, maybe someone knows, how to redirect the output stream of python scripts ran inside of a container lifted up with docker-compose. Say I print('1') and I want this print to appear on my orchestrator console (windows/visual studio). At the moment I just see:
[2019-05-07 17:00:37] <ghost~5bc98094d73408ce4fabf741>  [<-CODE->] 
[2019-05-07 22:36:00] <tatitati> guys, what is doing this --rm in here? (begginer)docker run --rm ....
[2019-05-08 04:30:45] <matrixbot> foxcrisFrancisco Albert Albusac (Gitter): it directly deletes the container after it is stopped
[2019-05-08 12:13:09] <Logenleedev> Guys Sorry to disturb... Need some help
[2019-05-08 12:13:24] <Logenleedev>  [<-LINK->] 
[2019-05-08 12:13:37] <Logenleedev> My dockerhub has loaded for one hour....What is going on LOL
[2019-05-08 18:57:40] <ghost~5bc98094d73408ce4fabf741> upping last one
[2019-05-08 19:16:16] <deanstef> Hi all, I have a problem in my docker-compose.yml. Here a snap of my file: [<-CODE->]  [<-CODE->] 
[2019-05-08 20:12:57] <stpavinash> Hi Guys!Can someone help me in setting up docker  for my airflow instance?I would like to test run my DAG's in the docker.
[2019-05-08 22:06:36] <tatitati> guys, I have this in my akka project: [<-CODE->] Now im trying to build mysql in a mysql docker container. However, I need the port to be dynamic instead of always 3306someone in the same situation?
[2019-05-09 10:46:38] <chandru1989_gitlab> chandru1989_gitlab: Hi , I have problem in lauching docker conatiner from jenkins ..It throws me error "Key exchange was not finished, connection is closed."I verified that public key of slave or agent is present in master known_hosts file ..Also when I do ssh from master with Strictly host checking enabled it is working ...Only during launching via jenkins it is throwing above errorCan anyone please help meI am using jenkins version 2.121 and ssh slaves pluin 1.17
[2019-05-09 12:50:08] <rmarcandier> Hello all, I am doing a jenkins container installation (inside docker) and im getting "Some plugins failed to install properly, you may retry installing them or continue with the failed plugins" any idea why I am not able to install these plugins inside docker container ?
[2019-05-09 18:29:18] <lancelot1969> Did you install Fortran and C++ libraries too?
[2019-05-09 18:29:35] <lancelot1969> Inside container
[2019-05-10 05:39:14] <joeyhipolito> question:is there an equivalent docker-compose syntax for this [<-CODE->] in a compose file
[2019-05-10 05:39:25] <joeyhipolito> full question: [<-LINK->] 
[2019-05-10 07:38:49] <patrykk21> joeyhipolito: With this merged yeah:docker/compose#6584
[2019-05-10 11:33:00] <sanlog25> Hi Guys, I would like to learn Docker. Any suggestions on where and how to start ?
[2019-05-10 11:33:40] <Demitsuru> don’t want to be rude, but - [<-LINK->] 
[2019-05-10 11:34:12] <Demitsuru> at least start from the high level
[2019-05-10 11:34:25] <Demitsuru> and then go down when you need something specific
[2019-05-10 11:34:59] <appareddyraja> just go with this one [<-LINK->] 
[2019-05-10 13:35:13] <joeyhipolito> all: another question, is there a way to set SSH_AUTH_SOCK when i copy over my ssh keys in Dockerfile and ran ssh-agent?
[2019-05-10 13:35:15] <joeyhipolito>  [<-LINK->] 
[2019-05-10 16:06:25] <deanstef> Guys does the entrypoint specified in the docker-compose overrides the one in the Dockerfile?
[2019-05-10 16:06:36] <Genysys> yes it does
[2019-05-10 16:06:37] <Genysys> always
[2019-05-10 16:07:03] <Genysys> environment varibles, exposed ports and entry points are overwritten by the docker compose options
[2019-05-10 16:07:17] <deanstef> Excellent! Thank you
[2019-05-10 20:30:54] <dugajean> Is this legitimate in Dockerfile: [<-CODE->] 
[2019-05-10 20:31:16] <dugajean> wherePHP_EXTENSIONSisphp-xdebug php-intl
[2019-05-10 20:31:56] <dugajean> the extensions listed above don't show up after the build is finished and I runphp -mwithin the container
[2019-05-10 20:32:02] <dugajean> help would be appreciated
[2019-05-10 20:32:29] <dugajean> I also don't get the difference betweenARGandENV
[2019-05-10 20:45:48] <adrice727>  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2019-05-10 20:55:09] <matrixbot>  [<-CODE->]  [<-CODE->] It's a bug with Yarn.  yarnpkg/yarn#7187
[2019-05-10 20:55:37] <matrixbot> @deepit:matrix.orgHave to change directory and then build
[2019-05-10 21:20:10] <matrixbot> foxcrishas one of you used the docker sdk for python? I am currently searching for a way to get the version of an image from the registry and compare it to the already runnung image version.
[2019-05-10 21:20:13] <matrixbot> foxcris [<-LINK->] 
[2019-05-10 21:24:18] <matrixbot>  [<-CODE->] Just tap into the API.  py:module:: docker.api.image
[2019-05-10 21:28:57] <matrixbot> foxcris@deepit:matrix.org: thx currently taking a look at it
[2019-05-10 21:29:17] <matrixbot> foxcrisis there a way to get the build date of an image?
[2019-05-10 21:29:44] <matrixbot> foxcriscan't find anything for that
[2019-05-10 21:38:27] <matrixbot> @deepit:matrix.orgfoxcris: [<-LINK->] for Image
[2019-05-10 21:40:08] <matrixbot>  [<-CODE->] History might have it.  https://docker-py.readthedocs.io/en/stable/images.html#docker.models.images.Image.history
[2019-05-10 21:40:48] <matrixbot> foxcris@deepit:matrix.org: thx history has is. Just found it.
[2019-05-12 16:17:14] <joeyhipolito> all: is there a way to share SSH_AUTH_SOCK from a windows host to my containers...?
[2019-05-12 17:22:53] <PinkyBrain_gitlab> Hi, beginner here, i was playing around with the redis image, and i noticed i cannot connect to the redis server unless i use the container ip, even though i've mapped the port with -p when starting the server container, why is this? am i missing some network flags? but then why does localhost work for e.g. nginx?
[2019-05-12 19:11:36] <tatitati> PinkyBrain: humm...it should work with something likedocker run <imagename> -p 6379:6379You might be able to connect then to localhost:6379 using any client
[2019-05-12 19:11:43] <tatitati> (that is the theory)
[2019-05-12 19:12:25] <tatitati> did you try that?
[2019-05-12 19:54:46] <PinkyBrain_gitlab> tatitati: thanks, yes it does work when connecting from the host, just not from within another container which is what i was trying. I am an idiot :)
[2019-05-12 20:55:47] <tatitati> aaah
[2019-05-12 20:59:03] <tatitati> PinkyBrain_gitlab: to connect containers you have to "link" them. [<-LINK->] 
[2019-05-12 20:59:46] <tatitati> Once that you link them you won't need to know exactly the ip of every container (something less to think about)
[2019-05-12 21:01:55] <PinkyBrain_gitlab> tatitati: didnt know that, thanks
[2019-05-12 21:04:43] <tatitati> PinkyBrain_gitlab: no problem
[2019-05-13 10:20:05] <Arkoprabho> Is there a way to access a container's file system from the host without popping into a docker container.i.e. I want to read the contents of a file that is inside a docker container (without named volumes) from say something like the host machine's file explorer.
[2019-05-13 10:21:27] <Arkoprabho> The use case I wish to understand is whether an antivirus like ClamAV, will be able to process (by reading) the running containers file system if we mount the host machine's/var/lib/docker/folder (or some other folder) as a volume in the ClamAV container.
[2019-05-13 12:47:14] <tatitati> maybedocker exec <image name> <command>
[2019-05-13 12:47:43] <tatitati> in that way you can execute a command in the container from outside
[2019-05-13 13:09:12] <tatitati> Arkoprabho: ^
[2019-05-13 14:08:52] <joeyhipolito> it should bedocker exec -it <container> /bin/bash
[2019-05-13 16:46:15] <PinkyBrain_gitlab> Arkoprabho: i could be wrong but i think you can see where it's stored on the host withdocker container inspect <container>-> graphdriver object
[2019-05-14 05:17:03] <omiozil> Hi folks is any one here have worked with openshift/Minishift? I have query regarding application deployement. Thanks
[2019-05-14 09:26:54] <Arkoprabho> PinkyBrain_gitlab: That is what I was looking for.. Thanks
[2019-05-15 07:24:08] <Sanji515> Hello everyone, I'm having a issuse actually the django container is not running on my side. When I useddocker-compose restart djangoit gave me error sayingdjango_1  | /usr/bin/env: 'bash\\r': No such file or directory
[2019-05-15 07:24:34] <Genysys> Sanji515: can you share the docker file?
[2019-05-15 07:24:42] <Genysys> or compose file?
[2019-05-15 07:24:53] <Sanji515> sure, wait please
[2019-05-15 07:25:36] <Sanji515>  [<-CODE->] 
[2019-05-15 07:26:42] <vsilent> Sanji515: the error might be in code/docker/dev/django/container-start.sh
[2019-05-15 07:27:55] <Sanji515> vsilent: let me show you thecontainer-start.shfile
[2019-05-15 07:28:33] <Sanji515>  [<-CODE->] 
[2019-05-15 07:51:33] <Sanji515> hey, any idea what might be wrong in it?
[2019-05-15 07:52:15] <Genysys> does the container exit?
[2019-05-15 07:52:25] <Genysys> if no you could ssh into it to diagnose
[2019-05-15 07:53:32] <Sanji515> when I rundocker ps -athen it's shown but when I rundocker psthen it is not shown on the list
[2019-05-15 07:53:44] <vsilent> Sanji515: if possible also put docker-compose.yml
[2019-05-15 07:53:45] <Genysys> so its not running
[2019-05-15 07:55:00] <Sanji515> vsilent: ok
[2019-05-15 07:57:16] <Sanji515> Here's the link of dpaste: [<-LINK->] 
[2019-05-15 07:57:27] <Sanji515> please have a look
[2019-05-15 07:59:52] <vsilent> env_file: [<-CODE->] 
[2019-05-15 08:00:46] <Sanji515> what's wrong in it?
[2019-05-15 08:01:43] <vsilent> I think it may contain error.
[2019-05-15 08:03:15] <vsilent> before placing it to dpaste do not forget to remove sensitive data
[2019-05-15 09:22:52] <bkannadassan> Can we have docker registry working with floating ip ?.
[2019-05-15 09:23:33] <appareddyraja> yup
[2019-05-15 15:11:54] <nerdo> Hey peoples.
[2019-05-15 15:12:23] <patrykk21> Hey?
[2019-05-15 15:12:55] <nerdo> I have a question. I've got docker setup for my dev environment and I'm pretty happy with it, but I want to make it easy to take my dev environment with me. Is there a way to tell docker-compose where to put images so i can keep them on my SSD for example?
[2019-05-15 15:13:09] <nerdo> *external SSD
[2019-05-15 15:14:06] <appareddyraja> use docker registry
[2019-05-15 15:15:33] <nerdo> I won't be able to do that (until we set up a private registry) - right now I'm working on a proof of concept to get buy in
[2019-05-15 15:17:47] <appareddyraja> i think docker registry is only way for storing images.. and setting up a private registry is so easy
[2019-05-15 15:18:16] <patrykk21> nerdo:  [<-LINK->] 
[2019-05-15 15:18:17] <nerdo> hmm, ok, I'll look into it
[2019-05-15 15:18:38] <patrykk21> tl;dr '-g' flag
[2019-05-15 15:18:59] <nerdo> thanks@patrykk21!
[2019-05-15 15:24:34] <nerdo> Docker has changed my dev life lol
[2019-05-15 15:29:55] <Yavorss> I'm building an ERP system and I need to deliver it to the clients with docker, but I need some UI about it. For instance, when we push new updates they need to be able with one click to update it. I think to build electron app which is going to do that. Do you have any suggestions what to use for easy communication with docker from the electron or in general? Thank you!
[2019-05-15 16:10:25] <jdickey> Yavorss: It's very common practice to expose port 443/80 or any other ports you'd need to access from outside the Docker containers, but you really want as much of that orchestrated using docker-compose or similar and communicating inside the Docker constellation (on an internal private network), exposing tcp/443 or tcp/80 as needed for your interface. I've brought up such apps developed in Ruby, in JavaScript, and in Elixir. Electron is bringing an artillery shell to a knife fight
[2019-05-15 16:12:21] <jdickey> It's heavy, it's not as portable as you wish it were, and you often don't realise until you're in the midst of flying metal that you'll be wanting more support than you have right at hand
[2019-05-15 16:24:01] <Yavorss> jdickey: Are not there easy solutions for this problem? I thought it's very common...
[2019-05-15 16:25:22] <Yavorss> I imagine an application that has 4 buttons => Start, Stop, Restart, Check for updates
[2019-05-15 16:31:26] <jdickey> That sounds like all internal logic/UI presentation; I think my point was along the lines of "it really doesn\'t matter what you use to do your UI and the logic backing it within a Docker system, and Electron can be quite useful if it\'s the most appropriate tool for the job under your circumstancesandyou\'re comfortable handling the Ginsu Thermonuclear Chainsaw Scalpel", but today\'s been a long week
[2019-05-15 18:15:39] <rightisleft> Does docker swarm have anything similar to K8 StatefulSets? [<-LINK->] 
[2019-05-15 18:19:50] <rightisleft> Essentially i need to dynamically assign an id to a single task in a swarm service - then figure out a way to route a matching inbound request to that task instance. (for brevity - assume each task will load roughly 10GB of data into memory from S3 based off the assigned ID)
[2019-05-15 18:23:34] <rightisleft> i could create this use dockerode and following the [<-LINK->] - but making sure im not reinventing the wheel
[2019-05-15 23:42:23] <kkallberg> Docker noob here.  I'm starting a few services with a docker compose file.  This works great.  One of those services is a web service.  If that web service healthcheck moves to unhealthy I want all the containers in the compose file to stop.
[2019-05-15 23:43:05] <Genysys> You should be able to do this with a script that runs a cron job in the container
[2019-05-15 23:43:29] <Genysys> Or a cron job on the host os
[2019-05-15 23:43:55] <Genysys> i am not sure docker on its own provides this
[2019-05-15 23:45:01] <kkallberg> Okay, I\'ll go down that route.  I wasn\'t sure if there was a "docker way" to accomplish it.
[2019-05-15 23:45:05] <kkallberg> Thanks!
[2019-05-15 23:45:48] <Genysys> There is a swarm way of ensuring that if the container goes down traffic is redirected to a replica
[2019-05-15 23:45:55] <Genysys> and kubernetes
[2019-05-16 03:31:27] <sameeroath> Hi guys, does anyone knows how to fix this issue? [<-CODE->] 
[2019-05-16 03:31:34] <sameeroath> i am on anyconnect VPN
[2019-05-16 03:31:46] <sameeroath> tried various things when searched online.
[2019-05-16 03:32:16] <sameeroath> removed host-only networks from virtualbox , re-installed vbox,dokcer,docker-machine etc.
[2019-05-16 03:32:26] <sameeroath> but nothing worked :/
[2019-05-16 05:44:57] <matrixbot> @deepit:matrix.orgcan you share your Dockerfile
[2019-05-16 05:56:36] <matrixbot>  [<-CODE->] docker-machine I take it?  What is the  DOCKER_HOST variable set to?  Did you setup a NAT and try a port forward?  What error are you receiving from the Docker daemon?  Can you output the docker-machine config you tried running?
[2019-05-16 06:04:42] <matrixbot>  [<-CODE->] Are you running a split-tunnel?  Are the NAT rules on the firewall preventing SSH from coming through the tunnel?  Have you tried running a tcpdump to see what's happening with the SSH packets?
[2019-05-16 08:06:04] <sameeroath> There was an error validating certificates for host "192.168.99.129:2376": dial tcp 192.168.99.129:2376: connect: network is unreachable
[2019-05-16 08:06:21] <sameeroath> this192.168.99.<num>
[2019-05-16 08:06:47] <sameeroath> this num number keeps incrementing everytime i create a new docker-machine
[2019-05-16 08:06:58] <sameeroath> which is weird i havent experienced that before
[2019-05-16 08:08:02] <sameeroath> Are you running a split-tunneli dont think its split-tunnel, do corporate VPNs allow that, or is it some setting i could do on my system?
[2019-05-16 08:10:58] <sameeroath> When i try to rundocker-machine config <machine-name> [<-CODE->] 
[2019-05-16 11:03:01] <bore.cz_gitlab> Hi guys, someone could be so kind to point me to the most basic docker setup to run webdriverio / Chrome?
[2019-05-16 13:13:30] <matrixbot> @deepit:matrix.orgIt might be incrementing based on the network pool for the bridge. What doesnetstat -nroutput in your terminal.
[2019-05-16 13:33:30] <matrixbot>  [<-CODE->] i dont think its split-tunnel, do corporate VPNs allow that?A lot of companies do allow it.  Only VPN advertised routes in a split tunnel will route to said network.  The rest go out your default routes.
[2019-05-16 13:42:51] <matrixbot>  [<-CODE->]  [<-CODE->] Try running port forwardingOpen VirtualBoxOpen Settings > Network for your 'default' VMSelect the adapter that is 'Attached To': 'NAT' and click 'Port Forwarding'.Add a new rule:Protocol: TCPHost IP: 127.0.0.1Host Port: 5555Guest Port: 2376Set DOCKER_HOST to 'tcp://127.0.0.1:5555'
[2019-05-16 13:48:59] <sameeroath> thanks @matrixbot, how do i do this below step?Set DOCKER_HOST to 'tcp://127.0.0.1:5555'
[2019-05-16 22:17:20] <rolong_gitlab> Hi guys, can anyone help me? I\'m getting this error from a docker container where I run angular 7 "ERROR in No NgModule metadata found for \'AppModule\'."
[2019-05-17 06:08:19] <guddutopper> Hi, I was reading about container security, is there any way to protect the "env variables" of a docker container, my env varibales contains some sensitive key information, now if I dodocker inspect, these env avr are exposed , is there anyway to hide the env var information ?
[2019-05-18 04:22:48] <matrixbot>  [<-CODE->] Set DOCKER_HOST to \'tcp://127.0.0.1:5555\'I\'m not a matrixbot  just set your environment variable DOCKER_HOST="tcp://127.0.0.1:5555"
[2019-05-18 04:23:46] <matrixbot> @deepit:matrix.orgsameeroath (Gitter): See this for environment variable examples [<-LINK->] 
[2019-05-18 04:35:15] <matrixbot>  [<-CODE->] There are a few different ways of handling this.  One is using the docker secret command and using an entrypoint to a bash script.
[2019-05-18 04:36:17] <matrixbot>  [<-CODE->] Another way is using .env files and making sure your .dockerignore and .gitignore files have it included.
[2019-05-18 04:44:19] <matrixbot> @deepit:matrix.orgThen you can pass --env-file=production.env   which reads in a file of environment variables from production.env
[2019-05-18 10:27:02] <goodandrewsoft> Hello guys, i'm newbie. Gow do it manually:ADD https://api.github.com/repos/aria2/aria2/git/refs/heads/master version.jsonfrom shell
[2019-05-18 10:27:09] <goodandrewsoft> *How
[2019-05-18 15:34:38] <matrixbot>  [<-CODE->]  [<-CODE->] Just run a curl or wget
[2019-05-20 11:46:51] <mgarces> hi everyone; quick question: when configuring S3 storage driver for the docker registry, will clients be proxied through the registry to fetch images, or will they fetch directly from S3?
[2019-05-20 12:09:46] <matrixbot>  [<-CODE->] Depends on your deployment.  If you go through a reverse proxy service I would see yes.  Otherwise I would imagine it just lands on the S3 bucket.
[2019-05-20 12:16:30] <mgarces> I do have nginx in front of the registry, on a specific domain with valid SSL
[2019-05-20 12:26:40] <mgarces> so it is going through a rever proxy
[2019-05-20 13:51:59] <deanstef> In my docker-compose file I specified the number of CPUS I want to dedicate for each container. How can I get evidence of such settings? From each container I still have the total amount of cpus of the host machine.
[2019-05-20 15:46:17] <bore.cz_gitlab>  [<-LINK->] 
[2019-05-20 15:46:46] <bore.cz_gitlab> Someone can tell me now how to run the e2e tests inside this container? Usually I ran them asnpm run ...
[2019-05-20 15:47:21] <bore.cz_gitlab>  [<-CODE->] 
[2019-05-20 15:47:41] <bore.cz_gitlab> what command shall I use to run now?
[2019-05-20 15:48:31] <appareddyraja> sudo docker exec -it b9f3 bash
[2019-05-20 15:48:47] <appareddyraja> and execute your commands
[2019-05-20 15:50:31] <bore.cz_gitlab>  [<-CODE->] 
[2019-05-20 15:50:45] <bore.cz_gitlab> shall I write the instructions into a file?
[2019-05-20 15:51:13] <appareddyraja> sudo docker exec -it b9f3 bash
[2019-05-20 15:51:23] <appareddyraja> just run this first
[2019-05-20 15:51:29] <bore.cz_gitlab> ok
[2019-05-20 15:52:29] <bore.cz_gitlab>  [<-CODE->] 
[2019-05-20 15:52:58] <bore.cz_gitlab> perhaps need to use different image?
[2019-05-20 15:53:27] <bore.cz_gitlab> my container has been built fromdocker run -d -p 4444:4444 selenium/standalone-chrome:latest
[2019-05-20 15:53:38] <appareddyraja> i just told you the way of getting inside the container
[2019-05-21 05:31:03] <matrixbot>  [<-CODE->] You could do a multistage build.  Have the first one build NPM and then inject it into the selenium Dockerfile.
[2019-05-21 05:35:32] <matrixbot>  [<-CODE->] Specify how much of the available CPU resources a container can use. For instance, if the host machine has two CPUs and you set --cpus="1.5", the container is guaranteed at most one and a half of the CPUs.--cpuset-cpusLimit the specific CPUs or cores a container can use. A comma-separated list or hyphen-separated range of CPUs a container can use, if you have more than one CPU. The first CPU is numbered 0. A valid value might be 0-3(to use the first, second, third, and fourth CPU) or 1,3 (to use the second and fourth CPU).
[2019-05-21 08:49:43] <Arkoprabho> Is there a way to access a container's file system from the host without popping into a docker container.i.e. I want to read the contents of a file that is inside a docker container (without named volumes) from say something like the host machine's file explorer [<-CODE->] 
[2019-05-21 12:36:05] <matrixbot> @deepit:matrix.orgIt's stores in /var/lib/docker/overlay2/
[2019-05-21 12:52:42] <matrixbot>  [<-CODE->]  [<-CODE->]  [<-CODE->] All images [<-CODE->] shortened layer identifiers as symbolic links [<-CODE->] The lowest one  contains a file called link and diff which contains the layer’s contents. [<-CODE->]  [<-CODE->]  [<-CODE->] The second-lowest layer, and each higher layer, contain a file called lower, which denotes its parent, and a directory called diff which contains its contents. It also contains a merged directory, which contains the unified contents of its parent layer and itself, and a work directory which is used internally by OverlayFS
[2019-05-21 12:53:45] <matrixbot> @deepit:matrix.org [<-LINK->] 
[2019-05-22 06:12:15] <Arkoprabho> matrixbot: Thanks a lot for that. It solves my issue
[2019-05-22 07:10:35] <matrixbot>  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2019-05-22 07:11:17] <matrixbot>  [<-CODE->] Glad I could help.
[2019-05-22 09:45:18] <UniFreak> my company is in subnet 10.70, docker is using 172.26, and the remote cloud db is inside 172.20so what should be done to reach to the cloud db inside docker?
[2019-05-22 09:45:21] <UniFreak> now when visit db hostexample.rds.cloud.com, my php app gives no route to host error
[2019-05-22 10:13:16] <matrixbot>  [<-CODE->] so what should be done to reach to the cloud db inside docker?What's the network topology looking like?
[2019-05-22 10:16:39] <matrixbot> @deepit:matrix.orgIs the remote cloud connected over an IPSec tunnel? Is it a static or dynamic?  How are routes being advertised to each other?
[2019-05-22 10:25:29] <matrixbot> @deepit:matrix.orgWhat kind of docker network did you set up?$ docker network ls
[2019-05-22 10:41:35] <UniFreak> matrixbot: I’m sorry I dont know how the cloud db is set up, that’s maintained by our Ops
[2019-05-22 10:43:41] <UniFreak> but heredocker network lsoutput: [<-CODE->] 
[2019-05-22 10:44:17] <UniFreak> and my host can reach to the mysql server usingexample.rds.cloud.com
[2019-05-22 11:01:34] <matrixbot>  [<-CODE->] https://github.com/nicolaka/netshoot/blob/master/README.md
[2019-05-22 11:05:26] <matrixbot> @deepit:matrix.orgI am heading to REM cycle.  Try running those three different scenarios and see which one make a hit to the DB port.
[2019-05-22 11:29:49] <kayvanbree> Trying to run the commanddocker run --rm -v /mkdocs:/mkdocs nate/mkdocs, getting an error: [<-CODE->] 
[2019-05-22 11:30:32] <kayvanbree> I'm on Windows. I also trieddocker run --rm -v c:/my/folder/mkdocs:/mkdocs nate/mkdocswith the full path
[2019-05-22 11:30:57] <kayvanbree> Googling this doesn't give me any information. Does anybody know if this error is from adding the volume?
[2019-05-22 11:32:11] <kayvanbree> Wait. It might be an error of the mkdocs container. Changed the container folder name of my volume and I'm getting a different error now
[2019-05-22 12:16:28] <konstantinblaesi> if I login to a remote registry, what's the best way to check ifimage:tagexists already?
[2019-05-22 12:17:44] <konstantinblaesi>  [<-CODE->] errors:denied: requested access to the resource is deniedunauthorized: authentication required
[2019-05-22 12:19:34] <konstantinblaesi> I get what I want by querying the docker v2 REST API withcurl -u $USER:$PASS https://name_of_repository.host_of_registry/v2/name_of_image/tags/listbut I'd prefer to use the docker cli
[2019-05-22 12:22:25] <kayvanbree> I have the following file structure: [<-CODE->]  [<-CODE->] 
[2019-05-22 12:23:16] <kayvanbree> Now it places the volume of my host inside the volume on the container, but it should map mkdocs to the workdir folder right?
[2019-05-22 12:31:48] <konstantinblaesi> kayvanbree: it should create/workdirin the container and display the contents ofc:/projects/something/mkdocsthere
[2019-05-22 12:32:46] <kayvanbree> It doesn't :(
[2019-05-22 12:34:01] <kayvanbree> it creates/workdirand places/mkdocsinside it. I created a file on my host machine inside the/mkdocsdir and it appeared in/workdir/mkdocs/filename.asdfasdfso it does actually mount the correct folder. Only it doesn't mount it in the right place.
[2019-05-22 12:34:19] <konstantinblaesi> well it works on linux, I cannot test on my windows machine because the company anti virus prevents mapping my disk to containers :D
[2019-05-22 12:34:30] <kayvanbree> Aaan
[2019-05-22 12:35:17] <kayvanbree> Anti virus bloatware. I got mine removed last week because it was still interfering with the 1803 update of Windows. Freezing the computer whenever it wants to install the update.
[2019-05-22 12:35:47] <kayvanbree> Maybe I should just create a repo, commit stuff and see if Jenkins does it better.
[2019-05-22 12:42:23] <kayvanbree> Ooh, maybe I can try it on WSL
[2019-05-22 12:43:30] <kayvanbree> nope, can't install docker there...
[2019-05-22 12:49:23] <kayvanbree> Don't know whats happening but when I change it todocker run -ti -p 80:8000 -v c:/projects/something/mkdocs:/mkdocs polinux/mkdocsit still mounts under/workdir/mkdocs
[2019-05-22 12:49:24] <kayvanbree> wtf
[2019-05-22 12:53:11] <kayvanbree> WORKDIR /workdirin the Dockerfile. That's probably it
[2019-05-23 01:08:35] <zebralight> hello. after runningdocker-compose buildI see a messageSuccessfully built 6f8a4c052df4\nSuccessfully tagged fusionjs_ci:latest, then when runningdocker-compose run fusionjs_ci:latest, I get this message:ERROR: No such service: fusionjs_ci:latest. I was wondering how I can run this service
[2019-05-23 01:13:02] <alvinhuff> Try runing docker images to list all images, then docker run —rm -it <imageid> /bin/bash this will create a container based on the image specified interactively and put you into the container.   the —rm will remove the container after you exit it
[2019-05-23 01:23:12] <zebralight> alvinhuff: thanks! I found the issue which was that I didn't rundocker-compose up.  Now I'm trying to get into the service's subfolderfooand then runyarn testand was wondering how I might be able to do that. I trieddocker-compose run ci foo/yarn testas well asdocker-compose run cd foo && yarn testto no avail
[2019-05-23 01:24:12] <alvinhuff> zebralight: are you running docker on windows?
[2019-05-23 01:24:30] <zebralight> no. on macos
[2019-05-23 01:28:57] <alvinhuff> zebralight: on linux I would rundocker exec -it <containerid> /bin/bash.  to bring a command line with in the container
[2019-05-23 02:01:23] <zebralight> so this is for docker-compose, not docker
[2019-05-23 03:04:10] <gufi> sup folks... having an issue where i have a container that appears its running in ps, but exec says no container exists, cant kill it cant stop it cant create another with same name because its in use
[2019-05-23 04:02:23] <Logenleedev> Hi folks! A quick question. I am building a simple app and want to deploy it to docker. Everything works okay. But I just cannot see my code on port 4000.
[2019-05-23 04:02:41] <Logenleedev>  [<-LINK->] 
[2019-05-23 04:02:59] <Logenleedev> I am a little bit confused since it should at least return something
[2019-05-23 04:03:51] <gufi> looks like you need to be pointing 4000:3000 since the server started internally on port 3000
[2019-05-23 04:09:56] <Logenleedev> gufi: Okay let me give a shot
[2019-05-23 04:11:37] <Logenleedev> Got it! It work! BTW a random question. How developers can check internal run result?
[2019-05-23 04:17:27] <Logenleedev> In other word, what happened in the image above?
[2019-05-23 04:17:46] <gufi> it was running but you were forwarding to a port that nothing was listening on
[2019-05-23 04:18:14] <gufi> 4000 was going to the internal port of  8080 but the application was listening on 3000
[2019-05-23 21:54:37] <mgarces> matrixbot: hey, I’ve found the solution in the docs: [<-LINK->] 
[2019-05-24 07:35:17] <sllavvicc> Hi, please help me. I use Docker swarm and now i want to close all connections from real host IP. For simple containers i use it 127.0.0.1:3000:3000 and it worked, but not for services ...
[2019-05-26 14:43:56] <rolong_gitlab> Hi guys I need some help, does anyone know how to make node_modules inside docker node 11-alpine image be owned by the user node?...I've tried chwon -R, chmod, running npm install after USER: node but no matter all of that, I keep getting inside the container that almost all folder are owned by node except node_modules which as you imagine would result in npm install EACESS permission errors
[2019-05-26 16:02:34] <romainPrignon> maybe it will help :) [<-ISSUE->] 
[2019-05-26 17:25:40] <rolong_gitlab> thanks, already checked it, but the suggestions didn't worked
[2019-05-26 20:49:22] <krasowskir> Hey is there a way to configure iptables with a docker container?
[2019-05-27 06:10:15] <vsilent> guddutopper: I would recommend using  hashicorp vault for that purpose.
[2019-05-27 06:13:26] <vsilent> rolong_gitlab: which user owns node_modules ?
[2019-05-28 13:52:36] <tomtom125> Hi, In a Dockerfile I'd like to you ENV for node version, but I can't make it work. What is the problem?
[2019-05-28 13:53:27] <tomtom125>  [<-CODE->] 
[2019-05-28 13:57:15] <tomtom125> During the build the 2 commented line won\'t be substituted.As you can see here : Step 25/30 : RUN echo \'nvm use $NODE_VERSION \' >> "$HOME/.profile"
[2019-05-28 14:15:06] <manueldeveloper> env rariables are only injected in "shell" mode
[2019-05-28 14:15:30] <manueldeveloper> check the following link
[2019-05-28 14:15:32] <manueldeveloper>  [<-LINK->] 
[2019-05-29 05:13:04] <tomtom125> ok, I'll look at it. Thanks
[2019-05-29 14:49:15] <ebrimaconta> any one know how to set up lamp on docker using docker toolkit
[2019-05-29 14:56:36] <vsilent> ebrimaconta: are you looking at specific PHP framework or pure php ?
[2019-05-29 15:34:35] <ebrimaconta> for symfony
[2019-05-29 15:35:00] <ebrimaconta> thank you@vsilent
[2019-05-29 18:21:55] <vsilent> ebrimaconta: not sure about docker toolkit for lamp but I'd like to invite to check these two, [<-LINK->] . [<-LINK->] 
[2019-05-30 17:40:06] <alanoteles_twitter> Hi Guys,I\'m trying to connect to a DigitalOcean droplet using docker-machine behind a proxy. Could not make it work. Everything works fine when I\'m not behing a proxy. Just "docker-machine ssh my_node" is enough to connect.The proxy doesn\'t require any authentication. I\'ve already exported http_proxy and https_proxy variables with the ip_address:port but not worked. I\'ve added this information on the config.json file of the machine but still no luck.I\'m on a Mac.Do you have any suggestions ?
[2019-05-30 17:45:12] <alanoteles_twitter> I receive the error : exit status 255
[2019-05-31 09:37:36] <good1uck> i cant visit my container's ip in host.
[2019-05-31 09:37:42] <good1uck> what should i do?
[2019-05-31 09:37:49] <good1uck> i mean Ping
[2019-05-31 09:38:57] <patrykk21> what should i do?Probably add some info to your problem
[2019-05-31 09:40:45] <vsilent> good1uck: I suppose you are looking for docker inspect --format '{{ .NetworkSettings.IPAddress }}' container_name_or_idcheck [<-LINK->] 
[2019-05-31 09:41:29] <good1uck> patrykk21: I set up a nginx web server in my container,Ubuntu.I dodocker inspectin my host and it shows the container's ip : 172.17.0.2.After this i docurl 172.17.0.2in my host and it failed.Neitherping 172.17.0.2
[2019-05-31 09:42:42] <vsilent> good1uck: you are pinging it on the host machine or from your/another computer?
[2019-05-31 09:43:09] <patrykk21> good1uck: You should expose a port of the container to your host via--exposeon the port you want to be pinging
[2019-05-31 09:44:24] <good1uck> vsilent: on the host machine
[2019-05-31 09:46:19] <good1uck> vsilent: @patrykk21 [<-CODE->] 
[2019-05-31 09:47:19] <vsilent> ping 127.0.0.1:32769 ?
[2019-05-31 09:47:58] <good1uck> vsilent: It failed, says cannt find that host
[2019-05-31 09:48:41] <good1uck> also failed
[2019-05-31 09:49:45] <good1uck> vsilent: butcurl 127.0.0.1:32769works..
[2019-05-31 09:49:54] <patrykk21> good1uck: Was about to ask you to do that haha
[2019-05-31 09:50:10] <patrykk21> You probably have no interface for ping command
[2019-05-31 09:50:51] <vsilent> what  curl -i [<-LINK->] saying ?
[2019-05-31 09:51:30] <good1uck> tell me to provide Uri
[2019-05-31 09:52:35] <good1uck> patrykk21: lol i have
[2019-05-31 10:00:32] <patrykk21> @good1uck What I meant was that you should expose the ICMP protocol/port/however it works to your hostPorts are a concept of UDP and TCP. Ping messages are technically referred to as ICMP Echo Request and ICMP Echo Reply which are part of ICMP.But I think you're only exposing port 80 on TCP
[2019-05-31 10:01:57] <good1uck> patrykk21: container side 80 ->  host side 32769
[2019-05-31 10:02:49] <good1uck> patrykk21: but hey,i think i know what's the point..My container and host are not  in the same network..
[2019-05-31 10:03:17] <vsilent> haha
[2019-05-31 10:03:40] <vsilent> just wanted to ask to show net:  in case you using docker-compose
[2019-05-31 10:03:46] <patrykk21> @good1uck from your configuration [<-CODE->] This is my guess. You can try to use a TCP ping toolI dont think its an issue of networks as you can curl the machine via 127.0.0.1
[2019-05-31 10:04:21] <good1uck> patrykk21: Sure dude,after i set put them in the same network
[2019-05-31 10:04:32] <good1uck> lol thanks for ur time..
[2019-05-31 13:31:55] <fletch8527> Im still learning Docker, and Im pretty novice when it comes to Java... but would anyone here be able to assist with setting up a container that would run a single jar file?
[2019-05-31 13:33:42] <fletch8527> could this image be used to run the jar file?image: openjdk:8u212-jre
[2019-05-31 13:33:59] <rcjsuen> It sounds like it should, yes
[2019-05-31 13:34:30] <rcjsuen> A JRE (Java Runtime Environment) should be sufficient to run a regular ol' Java application. Of course, your Docker image would also need to have all your dependencies and so on.
[2019-05-31 13:34:42] <fletch8527> when I try to console into it I get a message that its restarting but it doesnt seem to be constantly restarting
[2019-05-31 13:34:56] <rcjsuen> (Unless you used fatjar or something and put all your deps in your mega mega jar)
[2019-05-31 13:35:51] <fletch8527> The instructions for running the java app from the makers site simply says to install java 1.8 and runjava -jar file.jarI would assume that having java 1.8 would be the only requirement?
[2019-05-31 13:36:09] <rcjsuen> It sounds that way, yes
[2019-05-31 13:36:34] <rcjsuen> when I try to console into it I get a message that its restarting but it doesnt seem to be constantly restartingI don't quite understand this though. Perhaps you could share a) what you are typing, b) what you see, and c) what you expect to see
[2019-05-31 13:36:46] <rcjsuen> Doing A B C is the best way to get help on the Interwebs
[2019-05-31 13:36:54] <rcjsuen> It helps others understand your thought process
[2019-05-31 13:37:16] <fletch8527> im still pretty new to docker so I have been using docker-compose and portainer as crutches.
[2019-05-31 13:38:25] <fletch8527> the container is showing and running in portainer but when i click the console option in that container and attempt to connect it says to wait for it to start.
[2019-05-31 13:38:47] <fletch8527> let me look up the docker exec command again to see if I can do it that way
[2019-05-31 13:38:49] <rcjsuen> Hm, okay, I have not used this Portainer before. So it seems you are more using a GUI instead of the CLI
[2019-05-31 13:38:56] <fletch8527> yea :/
[2019-05-31 13:39:01] <rcjsuen>  [<-CODE->] What do you see?
[2019-05-31 13:39:44] <fletch8527> hmm it does say that its restarting...
[2019-05-31 13:39:58] <fletch8527> a6e0fd1d7214        openjdk:8u212-jre                     "java -jar /config/C…"   15 minutes ago      Restarting (0) 9 seconds ago
[2019-05-31 13:40:02] <rcjsuen> OK, so, without knowing anything, it is odd that it is restarting (or perpetually restarting)
[2019-05-31 13:40:14] <rcjsuen> Perhaps you have your Docker COmpose setup to be like "Run forever and always be up"
[2019-05-31 13:40:16] <vsilent> fletch8527: how do you start it
[2019-05-31 13:40:23] <rcjsuen> Share your Docker Compose file
[2019-05-31 13:40:24] <fletch8527> this is the app im trying to run [<-LINK->] 
[2019-05-31 13:40:51] <fletch8527> `  vera:container_name: verarestart: unless-stoppedimage: openjdk:8u212-jrevolumes: [<-CODE->] 
[2019-05-31 13:42:18] <vsilent> command: java -jar /config/ConciergeServer.jar`  worked out and that's it . seems it's not a daemon
[2019-05-31 13:42:53] <vsilent> or requires configuration
[2019-05-31 13:43:02] <vsilent> imho
[2019-05-31 13:44:12] <vsilent> are you sure you can get into container ?  try docker exec -it vera  bash
[2019-05-31 13:45:05] <fletch8527> command: java -jar /config/ConciergeServer.jar`  worked out and that's it . seems it's not a daemon [<-CODE->] 
[2019-05-31 13:45:36] <fletch8527> I was able to get into the container
[2019-05-31 13:45:54] <fletch8527> now I just have to see why it didnt work lol. But at least there is stuff in the logs now
[2019-05-31 13:48:36] <fletch8527> vsilent: thanks for the help!
[2019-05-31 13:49:03] <vsilent> you are welcome
[2019-05-31 13:55:06] <fletch8527> in the compose file for theports: 1111:2222does that mean forward requests from 1111 to 2222 in the container? or is it forward 2222 to 1111 in the container?
[2019-05-31 13:55:38] <vsilent> host port : container port
[2019-05-31 13:55:50] <fletch8527> thanks again
[2019-06-02 01:06:42] <SalathielGenese> Howdy folks,What is the difference between a docker layer and a docker intermediate container ?
[2019-06-03 07:59:12] <chandru1989_gitlab> Hi AllCurrently Jenkins is launching docker container using Yet another docker plugin present in Jenkins . It takes more time to launch container and also fails to launch sometimes . Now I am looking for some other way to integrate Jenkins and docker ..I found solution as docker swarm but no idea how to launch conatiner via swam plugin from jenkins ...If any material or link available about it with detailed explanation Please let me know
[2019-06-03 14:24:28] <rquinlivan> Hey folks, I am trying to write a Dockerfile that installs the PLPython plugin for Postgres. This appears to work, but the image that it produces is flakey and only sometimes will bind to the port (5432) correctly.
[2019-06-03 14:24:40] <rquinlivan> Here is my file in its entirety:
[2019-06-03 14:24:46] <rquinlivan>  [<-CODE->] 
[2019-06-03 14:26:02] <rquinlivan> That file is in./dockerfiles/database/Dockerfile
[2019-06-03 14:26:16] <rquinlivan> I then have a simple compose file that references the image and exposes the port
[2019-06-03 14:26:27] <rquinlivan>  [<-CODE->] 
[2019-06-03 14:27:12] <rquinlivan> Any idea why Docker would be having a hard time exposing the port? The odd thing about this is that if I exec into the container and check the connection, it works; I can runpsqland get in just fine. It seems like the Docker interface is the problem.
[2019-06-03 14:29:16] <rquinlivan> Do I need toEXPOSE 5432inside the Dockerfile?
[2019-06-03 14:30:16] <rcjsuen> That might depend if your base image (thepostgres:10.4has it written already)
[2019-06-03 14:30:29] <rcjsuen> Which I presume it does
[2019-06-03 14:30:50] <rcjsuen> You can usedocker inspect | lessto look at your created image to see its properties. I suggest taking a look see there
[2019-06-03 14:31:53] <rquinlivan> I didn't know about inspect. Thanks! That looks very helpful
[2019-06-03 14:32:34] <rcjsuen> er...lol, autocomplete
[2019-06-03 14:32:37] <rcjsuen> :P
[2019-06-04 00:20:48] <alvinhuff> Hello I am trying to mount a docker volume withdocker volume create --driver local \\\n  --opt type=nfs \\\n  --opt o=addr=redacted,rw,sync,no_subtree_check,insecure \\\n  --opt device=:/var/nfs \\\n  nfsvolume
[2019-06-04 00:22:36] <alvinhuff> I then reference that volume in my yaml file :volumes:\n  nfsvolume:\n    external: true
[2019-06-04 00:26:50] <alvinhuff> but when I deploy the the stack I get this error:"starting container failed: error while mounting volume \'/var/lib/docker/volumes/nfsvolume/_data\': error while mounting volume with options: type=\'nfs\' device=\':/var/nfs\' o=‘addr=redacted,rw,sync,no_subtree_check,insecure\': invalid argument”.  The thing is that it worked earlier. I was having issues mounting user folders so i tried different ways of creating the volume e.g. different options, but now I can mount the docker volume.  I have looked it every which way I am thinking the issue is small which is why I am missing it
[2019-06-04 00:29:21] <alvinhuff> I am creating the volume independently so that I will not have the name prefixed with the containing folder.  Any insights would be greatly appreciated
[2019-06-04 07:49:26] <Sanji515> Hey everyone, [<-CODE->] 
[2019-06-04 07:52:03] <Sanji515> if anyone have already done that before please help
[2019-06-04 09:10:10] <vsilent> Sanji515: you can see an example how it's done here [<-LINK->] .
[2019-06-04 09:14:59] <Sanji515> I'm getting error [<-CODE->] 
[2019-06-04 09:15:30] <Sanji515> and also
[2019-06-04 09:15:34] <Sanji515> connect() to unix:/home/ubuntu/firstsite/firstsite.sock failed (2: No such file or directory) while connecting to upstream,
[2019-06-04 09:16:14] <Sanji515> actaully thisfirstsite.sockis my previous sock file project when I deployed my blank django project
[2019-06-04 09:16:49] <Sanji515> but now I'm deploying for other one whose root folder name ismy_project
[2019-06-04 14:22:13] <Genysys> I am trying to implement a multistage builder pattern with the following Dockerfile: [<-CODE->] 
[2019-06-04 14:24:28] <Genysys> Unfortunately, it fails at the last stage [<-CODE->] error: [<-CODE->] 
[2019-06-04 14:24:35] <Genysys> what am i doing wrong?
[2019-06-04 18:24:36] <JnMik> Genysys: Are you sure the constellation folder is available in the first build step ?  Try running an ls or something.Are you aware you wrote constellation 2 consecutive times ? (Could be intended, just saying)
[2019-06-04 19:10:14] <Genysys> Thanks yes thanks it is as intended.. the first one is the folder and the second the binary .
[2019-06-04 19:11:17] <Genysys> Can you please expand on what you mean by running it as “is something “
[2019-06-04 20:03:13] <ducle91> quick question, has anyone build docker image for webdriverio?
[2019-06-04 20:06:18] <Genysys>  [<-LINK->] 
[2019-06-04 20:06:36] <Genysys> The repo seems self explanatory
[2019-06-04 20:06:44] <Genysys> “Seems”
[2019-06-04 20:06:53] <ducle91> thanks
[2019-06-04 20:07:15] <ducle91> so it should be as easy as just to run the image right
[2019-06-04 20:07:53] <Genysys>  [<-LINK->] 
[2019-06-04 20:07:59] <Genysys> It’s suggest using compose
[2019-06-04 20:08:42] <ducle91> thanks, i'll give that a try
[2019-06-04 21:41:51] <alvinhuff> Hello is there a reason I would want to use a docker volume (e.g.-v nfsvolume:/home/joyvan/work) vs bind mount (e.g.-v /vol_b/exchange:/home/joyvan/work) for persistent data?
[2019-06-07 14:08:18] <vsilent> alvinhuff:  [<-LINK->] , and  at least for backup it's better to use named volumes
[2019-06-08 08:37:42] <iharshit009> IIT BHU conducting Coding fest (online as well as offline also) which is free of cost + lots of goodiesSome information regarding codefest 2019Just registered yourself .https://codefest.tech/login?referral=qbK0w2UF1.Annual coding fest of CSE Department ,IIT BHU8 events covering almost every domain of Computer Science and Engineering\nGlobal participation from more than 100 countries\nCash prize of nearly 500k ,goodies an other merchandise as well\nNo registeration cost, certificate to all participants\nOnsite events,HaXplore,accomodation,goodies and food will be provided to everyone ,travel reimbursement as wellShare with your buddies also
[2019-06-09 04:54:15] <dlwhitehurst_gitlab> Can someone give me a rough limit of how many containers I might be able to run on a Macbook Pro (16GB)? I have about 12 containers, UAA server, Registry, Gateway, and 2 Microservices with Mongo databases and everything works. I add a third microservice and everything locks up. I do about 450% CPU then when things settle out, the service registry keeps timing out (Eureka).
[2019-06-09 17:02:17] <jdickey> dlwhitehurst_gitlab: I'd guess that you've discovered the upper limit there; I've never tried running that many on a MacBook, or even on an iMac. For my current applications, I've had no need to take it up to five containers. One with 2 to 4 GB of RAM and the others with 1 GB or even less. I'm running Mojave 10.14.6 with 16 GB of host RAM, and I'm pretty sure I was getting better performance before I migrated from High Sierra. That's one anecdotal data point for you
[2019-06-09 17:28:28] <Genysys> I am having issues with openssl even after installing it with an alpine image: [<-CODE->] 
[2019-06-09 17:28:45] <Genysys> I get an error at this line/ [<-CODE->] 
[2019-06-09 17:29:31] <Genysys> this is the error: [<-CODE->] 
[2019-06-09 17:29:49] <Genysys> would appreciate any help on pointing out what i doing wrong here
[2019-06-09 17:41:28] <dlwhitehurst_gitlab> jdickey: I just switched to Mojave. I didn’t use all my memory. I think there’s some tuning I can do but it’s all specific to the containers I need. I have to figure this out.
[2019-06-09 18:53:57] <jdickey> dlwhitehurst_gitlab: Good luck. It would be interesting to find out what you discover. I've solved several problems in the past by allowing containers to use more memory than originally allotted; that's why the one container I mentioned went from 2 to 4 GB; doing so mitigated the memory-management thrashing that had locked up the server app.  Good luck again.
[2019-06-09 19:37:26] <carrowheap>  [<-LINK->] 
[2019-06-09 19:38:16] <carrowheap> Hi everyone , how can I change failed status to active ? can someone help me please
[2019-06-09 19:38:49] <carrowheap> I tried to restart but it doesn't work
[2019-06-09 19:39:04] <Genysys> Trysudo journalctl -r
[2019-06-09 19:39:16] <Genysys> would give you a more verbose reason why its failing
[2019-06-09 19:41:28] <carrowheap>  [<-LINK->] 
[2019-06-09 19:41:52] <carrowheap> after  sudo journalctl -r
[2019-06-09 19:42:46] <Genysys> docker —version
[2019-06-09 19:43:29] <Genysys>  [<-LINK->] 
[2019-06-09 19:43:35] <Genysys>  [<-LINK->] 
[2019-06-09 19:44:00] <Genysys> If you are really lazy and dont care about your stored images: [<-LINK->] 
[2019-06-10 19:15:08] <ducle91> Hi all, I have a question. I'm runnning webdriverio docker container. I'm testing a suite of test (3 tests). I have a dockerfile and docker-compose.yml file. When I do docker-compose up I noticed my test is not running. Is there something I'mmissing?
[2019-06-10 19:15:23] <ducle91>  [<-LINK->] 
[2019-06-10 19:15:46] <ducle91>  [<-LINK->] 
[2019-06-11 01:03:04] <Pagnito> hey i just got a new laptop thats windows. i been a long mac user so im n00b again
[2019-06-11 01:03:20] <Pagnito> im reading articles on toolbox vs native docker
[2019-06-11 01:03:37] <Pagnito> and im wondering is it worth switching to windows 10 pro to use docker native
[2019-06-11 07:36:37] <vsilent> Genysys: looks like you still need libssl-dev   which was commented out
[2019-06-11 12:45:28] <Genysys> ducle91: can you post the docker file and compose files
[2019-06-11 12:52:18] <Genysys> vsilent: thanks!
[2019-06-11 13:08:47] <ducle91> Genysys: I've posted the screenshot
[2019-06-11 14:46:39] <Genysys> Is that it? It usually better to share this as markdown and not png
[2019-06-11 14:46:55] <Genysys> change the contents ofpackage.json
[2019-06-11 14:47:16] <Genysys> specifically thetestnpm script
[2019-06-11 15:34:04] <aymenbraiek>  [<-LINK->] any solution for this problem please i try to install docker tololbox
[2019-06-11 17:05:51] <nerdo> Hey peoples
[2019-06-11 17:06:52] <nerdo> I just did a clean install of docker-ce on ubuntu 18.02 and i can run containers, but i can't seem to access the internet unless i specify the host network
[2019-06-11 17:07:44] <nerdo> e.g.$ docker run -i -t alpine:3.9\n/ # ping 8.8.8.8\nPING 8.8.8.8 (8.8.8.8): 56 data bytes\n^C\n--- 8.8.8.8 ping statistics ---\n7 packets transmitted, 0 packets received, 100% packet loss
[2019-06-11 17:08:26] <nerdo> but using the host network works:$ docker run -i -t --network=host alpine:3.9\n/ # ping 8.8.8.8\nPING 8.8.8.8 (8.8.8.8): 56 data bytes\n64 bytes from 8.8.8.8: seq=0 ttl=56 time=5.265 ms\n64 bytes from 8.8.8.8: seq=1 ttl=56 time=4.558 ms\n64 bytes from 8.8.8.8: seq=2 ttl=56 time=5.193 ms
[2019-06-12 18:09:51] <matrixbot>  [<-CODE->] Enable forwarding from Docker containers to the outside worldBy default, traffic from containers connected to the default bridge network is not forwarded to the outside world. To enable forwarding, you need to change two settings. These are not Docker commands and they affect the Docker host’s kernel.Configure the Linux kernel to allow IP forwarding.$ sysctl net.ipv4.conf.all.forwarding=1Change the policy for the iptables FORWARDpolicy from DROP to ACCEPT.$ sudo iptables -P FORWARD ACCEPTThese settings do not persist across a reboot, so you may need to add them to a start-up script.
[2019-06-12 23:56:59] <matrixbot> @deepit:matrix.orgI would recommend creating a new bridge network, as Docker recommends it.
[2019-06-13 06:19:51] <Ankit3794> Pagnito: , In Docker toolbox you can use only Linux container where as in Docker Native, you will be having option to switch to windows or Linux container. This is one of the advantage. Hope this helps.
[2019-06-13 15:01:43] <rightisleft> I\'m reading the documentation over at [<-LINK->] - when i try and pass in an array of  \'Networks: ["mylab"]\' i get the following error:Error: (HTTP code 400) unexpected - json: cannot unmarshal string into Go struct field ServiceSpec.Networks of type swarm.NetworkAttachmentConfig
[2019-06-13 15:34:43] <trepidacious> Has anyone else tried using a docker container on macOS to compile with gcc? I get really awful performance, maybe a factor of 10 or more slower than a native compile. I believe this is because of the macOS bind mount issues, is there any chance these will get about 10 times better in the near future? Windows performance seems fine, and I believe that just uses an SMB mount, could macOS do something similar?
[2019-06-13 16:52:10] <matrixbot> woblHi, does anyone know how to assign an ip adress to a docker container via dhcp server?
[2019-06-13 17:22:27] <ducle91> Hi all, I have a docker compose that runs an end-to-end test but when I run I get an errorFailed to reserve 524288 bytes for shared memory.: No space left on device
[2019-06-13 17:28:40] <konstantinblaesi> ducle91: linux systems have an in memory/swap filesystem calledtmpfsmounted at/dev/shm. It's default size is usuallyHost RAM / 2, but docker has very low (too low for some applications) defaults. I've never tried, but it looks like  you can set shm size like this [<-LINK->] 
[2019-06-13 17:29:09] <konstantinblaesi> I think mounting any directory/volume at/dev/shmwith enough free space would work, but usually/dev/shmis in memory
[2019-06-13 17:31:00] <ducle91> hmmm ok
[2019-06-13 18:14:55] <dlwhitehurst_gitlab> konstantinblaesi: you just gave me an idea to try for my not being able to run all microservices locally. I have different docker-compose files. My full system docker-compose won’t run on my MacBook Pro 16gb but I still have like 6gb even when it’s thrashing. Thanks for the share!
[2019-06-13 18:45:45] <ducle91> is it possible to have more than one command in a single image?
[2019-06-13 18:46:39] <atarutin> you mean Dockerfile?
[2019-06-13 18:47:14] <ducle91>  [<-CODE->] 
[2019-06-13 18:47:22] <ducle91> docker-compose
[2019-06-13 18:49:39] <atarutin> not sure about compose... doesn't look like it is
[2019-06-13 18:50:10] <ducle91> thanks, I just wanted to make sure
[2019-06-13 18:50:15] <atarutin>  [<-LINK->] 
[2019-06-13 18:51:20] <atarutin> i think you can just do "npm test test2"... why do you need two here?
[2019-06-13 18:51:42] <ducle91> I have a lot of test and want to break it into chunks
[2019-06-13 18:52:03] <ducle91> if I run all of them at once I ran into memory issue as there is not enough memory to run all the tests
[2019-06-13 18:53:14] <atarutin> hmm... i think you should be able to manage that thru npm...
[2019-06-13 18:53:33] <atarutin> but not sure your whole scenario
[2019-06-13 18:56:48] <dlwhitehurst_gitlab> It makes sense that the shared memory size (swap mount) be configurable per container. That way you tune the suite of containers based on need. The docker-compose just makes it easy to start the set really. Also, you’ll probably learn more about Docker in general when you start using these configs. I’ve recently started using docker-compose for a huge startup plan I have and I’m really digging it. I’m generally a MuleSoft architect and they don’t allow us the on-premise freedom to use all this fantastic technology.
[2019-06-13 18:58:02] <ducle91> dlwhitehurst_gitlab: right, i'm fairly new with docker and concept of containerization
[2019-06-13 18:58:37] <ducle91> but so far i have been able to create a container and deploy my app on jenkins
[2019-06-13 18:58:57] <ducle91> although I still have a few issues that needs to iron out
[2019-06-13 19:00:20] <vsilent> dlwhitehurst_gitlab: you can limit it withmem_limit: 1g   in docker-compose
[2019-06-13 19:02:44] <dlwhitehurst_gitlab> vsilent: does the mem_limit apply to all containers? And, I’m assuming it works to increase the mem_limit too? E.g. 4g if you had it and then swap might not need to be utilized.
[2019-06-13 19:02:58] <vsilent> you can set it per service
[2019-06-13 19:04:06] <vsilent> by default docker container has no RAM limits,  limited by physical RAM of host machine
[2019-06-13 19:04:38] <ducle91> i've set shm_size to 2g
[2019-06-13 19:04:44] <vsilent> like thiselasticsearch:build: ./configs/elasticrestart: alwayscontainer_name: elasticsearchenvironment:ES_JAVA_OPTS: "-Xms256m -Xmx256m"discovery.type: "single-node"ulimits:memlock:soft: -1hard: -1mem_limit: 1glinks: [<-CODE->] 
[2019-06-13 19:05:24] <dlwhitehurst_gitlab> Ah, that’s perfect then. When I’m closer to public release, I’ll start testing and tuning. Right now, I can only run 2 micro services with a React/Gateway application (main), a Eureka service registry, and a Uaa identity and auth server, all with databases on my macbook pro. I plan to have 5 microservices in production
[2019-06-13 19:06:58] <dlwhitehurst_gitlab> Excellent! I like the ES_JAVA_OPTS too. I’m guessing Docker pretty much allows all config of executables in a terminal (local) environment in a containerized environment too
[2019-06-13 19:06:59] <vsilent> that's ok, but this will not fix ram issue anyway, you have to fix javascript anyway
[2019-06-13 19:07:38] <vsilent> probably js code not optimized ..
[2019-06-13 19:08:56] <dlwhitehurst_gitlab> I’m learning as I go but I do see that things work out of the box, but real-life application suites will require tuning
[2019-06-13 19:10:44] <vsilent> yep
[2019-06-13 19:16:50] <vsilent> I forgot to mention that "mem_limit" will work for docker-compose version 2 , for version 3 options replaced with "resources".resources:limits:cpus: \'0.50\'memory: 50Mreservations:cpus: \'0.25\'memory: 20M
[2019-06-13 20:01:27] <hiten-h-vinchurkar> Hey,
[2019-06-13 20:02:37] <hiten-h-vinchurkar> Im new on docker. I have question that currently we are using AWS EC2 instance and doing EC2 scaling by creating multiple instances
[2019-06-13 20:03:26] <hiten-h-vinchurkar> So how it will effect if I run multiple containers on one EC2 instance?
[2019-06-13 20:03:55] <patrykk21> its literally like spawning multiple processes of the same application
[2019-06-13 20:03:57] <hiten-h-vinchurkar> I mean by using docker inside EC2 instance how it will perform?
[2019-06-13 20:04:19] <patrykk21> Docker on linux its like native code performance. So dont worry about that
[2019-06-13 20:04:45] <hiten-h-vinchurkar> Is it going to save my cost?
[2019-06-13 20:05:35] <patrykk21> Really depends dude. On how you use your resources. If your instances never actually get to fully using the CPU then spawning multiple containers on the same EC2 instance is better
[2019-06-13 20:05:43] <patrykk21> Its like creating a multithreaded application, kind of
[2019-06-13 20:06:24] <hiten-h-vinchurkar> Currently users on my site are around 30 to 40k. N I'm using 10 EC2 instances.
[2019-06-13 20:07:16] <patrykk21> Dude you can run 10k requests a second on a single EC2 instance with Elixir no problem. It really depends on your aplpication and what resources you're using. Run some analytics and get some data. You can't judge without data
[2019-06-13 20:08:00] <hiten-h-vinchurkar> Ohh. Yes thanks bro
[2019-06-13 23:09:09] <davidmichaelkarr> I\'m getting an unexpected error on "docker build", saying ;invalid argument ".../19-06-18-REL" for "-t, --tag" flag: invalid reference format\', where the "..." is the other stuff at the beginning of the tag.  We recently changed the release name format from "19.06.18.REL" to "19-06-18-REL". Is that the problem?  Where is there a spec for the format of this value?
[2019-06-13 23:55:31] <matrixbot>  [<-CODE->] https://docs.docker.com/engine/reference/commandline/tag/
[2019-06-13 23:55:44] <matrixbot> @deepit:matrix.orgShould work, sounds like a bug
[2019-06-14 01:07:05] <dlwhitehurst_gitlab> Asking here in hopes of an answer lol. After conversion of docker-compose to kube yaml files. I run kompose up and two things fail. 1) my volumes don’t work and 2)  repository does not exist or may require 'docker login’ for my jib-generated containers (all local). Can someone help me understand what is wrong. I’ve been successful running my app suite with docker-compose but I want to switch to kubernetes. And, I want my data to be persisted, hence the volume mapping to my local laptop (host)
[2019-06-14 08:24:37] <DaniGuardiola>  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] When I run the container and inspect the files, I get this: [<-CODE->]  [<-CODE->] What's going on here? Thanks :)
[2019-06-14 08:25:53] <patrykk21> Mhhh this is interesting. Maybe some sort of./**/*.pycould solve the issue, you haven't found anything on the interwebs ?
[2019-06-14 14:37:28] <aymenbraiek>  [<-LINK->] the proxy of my company bloked any job with docker i try all solution in net but always somme error please help me
[2019-06-14 14:39:17] <aymenbraiek>  [<-LINK->] 
[2019-06-14 16:57:36] <davidmichaelkarr> Concerning my issue yesterday with "invalid reference format", I\'m not sure who to reply to for this. Is it certain that the required syntax for "docker build -t ..." is identical to the syntax for "docker tag ..."? There was an implication that this might be a bug. Do you think it\'s likely that changing to "19_06_18_REL" has a better chance of working?
[2019-06-14 17:22:01] <davidmichaelkarr> I've narrowed down my command line to this:
[2019-06-14 17:22:03] <davidmichaelkarr> dk068x@wacdtl03dk068x:~/git/checkoutms$ docker build -f src/main/docker/Dockerfile -t "host:5100/name.space/servicems:dev-latest-release/19.06.18.REL" .invalid argument "host:5100/name.space/servicems:dev-latest-release/19.06.18.REL" for "-t, --tag" flag: invalid reference formatSee \'docker build --help\'.
[2019-06-14 17:22:26] <davidmichaelkarr> I think the problem may be the ":" in the previous name component, but changing that results in even more confusing results.
[2019-06-14 17:23:06] <davidmichaelkarr> $ docker build -f src/main/docker/Dockerfile -t "host:5100/name.space/servicems_dev-latest-release/19.06.18.REL" .invalid argument "host:5100/name.space/servicems_dev-latest-release/19.06.18.REL" for "-t, --tag" flag: invalid reference format: repository name must be lowercase
[2019-06-14 17:39:00] <davidmichaelkarr> I think I found a solution, but I can\'t find a statement in the documentation that confirms this.  The problem was (obviously), the uppercase "REL" at the end.  I changed it to "rel", and it worked.  The doc clearly says that the tag name can have uppercase letters, but this error seems to refer to the last component as the "repository name", and that it must be lowercase.
[2019-06-14 20:30:57] <Pagnito> can i use gitbash with docker for windows?
[2019-06-14 20:34:33] <Pagnito> found this [<-LINK->] 
[2019-06-15 23:47:16] <Pagnito> is there a way to run windows docker from toolbox and forward it to localhost?
[2019-06-16 13:53:30] <usmanranatig> Can mikrotick router os can be run over docker with interfaces to pass traffic in and out the container?
[2019-06-17 09:50:32] <TwanoO67> hello guys! I'm having trouble getting apachemod_statusto work on the image:https://hub.docker.com/_/httpdI don't know where to seek for help, so if any of you have an idea, it would be very great :) thanks
[2019-06-17 09:54:29] <vsilent> TwanoO67: what does docker logs  saying ? Do you have any logs ?
[2019-06-17 10:01:07] <TwanoO67> I will send you this in MP to not flood the channel :)
[2019-06-17 15:21:12] <sourabhsihag16> Swarm or kubernetes?
[2019-06-17 15:21:25] <patrykk21> Swarm sucks
[2019-06-17 15:21:28] <sourabhsihag16> Which one is best
[2019-06-17 15:21:47] <patrykk21> Literally the reason why k8s was born is because swarm is too bad
[2019-06-17 15:38:19] <vsilent> K8s sucks too
[2019-06-17 15:39:21] <rcjsuen> sourabhsihag16: Kubernetes has more buy-in from vendors and you are more likely to fill positions on your team with Kubernetes experience compared to Swarm
[2019-06-17 15:39:39] <gowthamakanthan> Nomad ?
[2019-06-17 20:19:27] <ducle91> Hey all, I have a webdriverio test in a docker container. I'm using docker compose to run my test.  I have the container run in Jenkins, but I noticed that it keep failing and that it would take a very long time to finish. I'm not exactly sure what is the cause. Anyone might have an idea on what could cause this issue?
[2019-06-17 20:20:27] <ducle91> docker-compose.yml [<-CODE->] 
[2019-06-17 20:20:41] <ducle91> dockerfile [<-CODE->] 
[2019-06-18 09:32:44] <Ankit3794> Pagnito: As per documentation, You have to use Docker Machine IP if you are using Docker ToolBox. Default IP would be 192.168.99.100 But You can try with VirtualBox Port Forwarding. Reference - [<-LINK->] 
[2019-06-18 12:51:33] <romainPrignon> Hey all, [<-CODE->] Ideally I'm looking for something like this: [<-CODE->] docker build my_distrib --output=distrib.iso
[2019-06-18 14:29:08] <romainPrignon> Maybe there is something inbuildkitorrunc:/
[2019-06-18 14:29:32] <ducle91> hello all, is it possible to change dpi setting for a docker image?
[2019-06-18 14:29:33] <romainPrignon> Or, I want to do something completely wrong :D
[2019-06-18 14:50:52] <Pagnito> Ankit3794: yea port forwarding with virtual box worked
[2019-06-18 16:59:52] <Ankit3794> Pagnito: :)
[2019-06-19 09:12:19] <chandru1989_gitlab> Hi All ...In pipeline method entrypoint cat is used by jenkins instead of entrypoint mentioned in pipeline script ..Overriding of entrypoint specified is not working
[2019-06-19 09:12:22] <chandru1989_gitlab> $ docker run -t -d -u 1000:1000 --entrypoint  -w /home/chandru/workspace/LTE-OpenWRT-Test-Sanity_test -v /home/chandru/workspace/LTE-OpenWRT-Test-Sanity_test:/home/chandru/workspace/LTE-OpenWRT-Test-Sanity_test:rw -v/home/chandru/workspace/LTE-OpenWRT-Test-Sanity_test@tmp:/home/chandru/workspace/LTE-OpenWRT-Test-Sanity_test@tmp:rw -e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**-e**--entrypoint cat localhost:5000/testing/fruit:latest
[2019-06-19 09:12:55] <chandru1989_gitlab> node(\'LTE_VIRT-O\') {def test = docker.image(\'localhost:5000/testing/fruit:latest\')test.pull()test.inside ("--entrypoint \'\'") {
[2019-06-19 09:13:02] <chandru1989_gitlab> how to fix this issue ?
[2019-06-19 14:22:25] <ducle91> hey all, I have a webdriverio app in a docker container, when I run my test it's not being able to see if a button is visible or not. I ran my test locally and everything passed, but when I execute my docker image it would failed. I'm not sure what is causing the issue. Anyone have any idea?
[2019-06-20 21:48:00] <rightisleft> my docker network started throwing errors when attaching containers
[2019-06-20 21:48:03] <rightisleft>  [<-LINK->] 
[2019-06-20 21:48:14] <rightisleft> im stumped
[2019-06-20 21:50:17] <rightisleft> it cant find the defined network, but im able to inspect the same name or idError response from daemon: network mrunner not found
[2019-06-20 21:50:30] <rightisleft> Any ideas?
[2019-06-21 09:52:23] <sumanchowdare> Hello@allCan anyone help with ansible docker_service module ??I’m running playbook which is executing docker-compose in remote machine ansible running in detach mode just it triggering compose in remote control coming out but i want container logs needs to be printed in ansible-playbook host machine ??
[2019-06-21 09:52:51] <sumanchowdare> How can i enable detach mode in ansible docker-service module ??
[2019-06-21 10:11:18] <KramKroc> sumanchowdare: We use the shell rather than docker_service for reasons like this.
[2019-06-21 10:35:40] <sumanchowdare> Thanks for reply Do you have any sample executing docker-compose using shell ansible ?
[2019-06-21 10:37:36] <sumanchowdare> We have docker-compose file in remote machine and trying to execute ansible playbook from different machine and giving docker compose file path of remote machine in ansible playbook
[2019-06-21 10:38:01] <sumanchowdare> Error saying that docker compose file not found
[2019-06-21 13:20:16] <KramKroc> Do you not use docker-machine to run those commands against the remotee machine?
[2019-06-21 13:27:00] <ducle91> is it possible to change the screen resolution in docker compose?
[2019-06-24 06:42:36] <itziklavon> Hi guys, small question, just started using docker, using java, i'm having few property files which i'm reading from /opt/conf, how do i tell docker image to read those properties when starting up?
[2019-06-24 06:42:40] <itziklavon>  [<-LINK->] 
[2019-06-24 06:43:20] <itziklavon> test is configured to return test1, but i'm always getting my default property value - test
[2019-06-24 06:43:54] <itziklavon> when runnning on a vm as plain java -jar it is working and returning test1
[2019-06-24 10:34:46] <gowthamakanthan> what is the best way to handle "No space left on the device" issue?
[2019-06-24 14:35:12] <nicolas-law> Hey guys, I'm trying to debug one of my tool using the Golang Docker SDK, is there any way to export the query generated by [<-LINK->] ? I'd like to get the CLI equivalent because of a volume mount error
[2019-06-24 14:41:43] <nicolas-law> itziklavon: I suggest you read [<-LINK->] about build arguments, environment variables and environment files ;)
[2019-06-25 08:51:58] <rajeshcis> HiI am getting this error [<-CODE->] 
[2019-06-25 08:52:47] <rajeshcis> Please any one can help me on this
[2019-06-25 08:55:34] <rajeshcis> when I am directly puting thishttp://dl-cdn.alpinelinux.org/alpine/v3.6/main/x86_64/APKINDEX.tar.gzurl it is working but not in the docker
[2019-06-25 16:48:24] <rajeshcis> fixed the above issue , it was firewall issue
[2019-06-25 20:26:22] <benwtks> I\'m developing a rails app and I\'ve been having a problem pushing to dokku, I keep getting "Could not detect rake tasks" with "vendor/bundle/bin/rake:29:inload\': cannot load such file -- /tmp/build/vendor/bundle/ruby/2.6.0/specifications/exe/rake (LoadError)" and "vendor/bundle/bin/rake:29:inload\': cannot load such file -- /tmp/build/vendor/bundle/ruby/2.6.0/specifications/exe/rake (LoadError)", I\'m not sure what I changed that made this start happening, please can somebody help? I\'ve been trying to figure it out for hours but i haven\'t got anywhere...
[2019-06-25 20:26:36] <benwtks> I think the issue started when I ctrl+c'd a deployment and tried deploying again after unlocking the app's deployment. I've tried pushing the commit already on the server and it's not having it, so it looks like the issue is on the serverso I've tried restarting the server and that didn't do anything, I'm not sure what else I can do
[2019-06-26 19:26:41] <matrixbot> l_inusPagnito (Gitter): Just install Linux
[2019-06-27 02:31:59] <gssjericsantos> Hello Guys. Need Help
[2019-06-27 02:32:06] <gssjericsantos> this is my docker compose file.
[2019-06-27 02:36:05] <gssjericsantos>  [<-CODE->] 
[2019-06-27 02:36:27] <gssjericsantos> It Does Say That It Created EverythingCreating docker_db_1 ... doneCreating docker_web_1        ... doneCreating docker_phpmyadmin_1 ... done
[2019-06-27 02:37:11] <gssjericsantos> but i cant access it in the localhost:80
[2019-06-27 02:37:14] <gssjericsantos> any ides?
[2019-06-27 07:59:20] <pedroparraortega> Localhost:8000
[2019-06-27 07:59:25] <pedroparraortega> should work
[2019-06-27 07:59:27] <pedroparraortega> :p
[2019-06-27 08:00:20] <gssjericsantos> i got ir running but now the mysql wont connect with phpmyadmin
[2019-06-27 08:00:38] <gssjericsantos> ```version: '3.3'services:laravel:    build:      context: .      dockerfile: Dockerfile    image: gsslabic/php    tty: true    working_dir: /var/www    command: bash -c 'php artisan migrate && php artisan serve --host 0.0.0.0'    volumes: [<-CODE->] mysql:    image: mysql:8.0    environment: [<-CODE->] phpmyadmin:      image: phpmyadmin/phpmyadmin:4.9      links: [<-CODE->] volumes:  mysql-data:networks:  laravel-net:```
[2019-06-27 08:01:25] <gssjericsantos> `version: '3.3'services:laravel:    build:      context: .      dockerfile: Dockerfile    image: gsslabic/php    tty: true    working_dir: /var/www    command: bash -c 'php artisan migrate && php artisan serve --host 0.0.0.0'    volumes: [<-CODE->] mysql:    image: mysql:8.0    environment: [<-CODE->] phpmyadmin:      image: phpmyadmin/phpmyadmin:4.9      links: [<-CODE->] volumes:  mysql-data:networks:  laravel-net:`
[2019-06-27 08:02:48] <pedroparraortega> according to the docs from phpmyadmin, you are missing [<-CODE->] 
[2019-06-27 08:06:11] <gssjericsantos> so i should be adding it to phpmyadmin?
[2019-06-27 08:06:31] <gssjericsantos> like this [<-CODE->] 
[2019-06-27 08:13:39] <pedroparraortega> looks like
[2019-06-27 08:21:54] <gssjericsantos> seems to be nit working. still having this errors. [<-CODE->] 
[2019-06-27 09:48:13] <vsilent> gssjericsantos: mysql host should be "db"
[2019-06-27 09:49:08] <vsilent> PMA_HOST: db
[2019-06-27 09:50:31] <gssjericsantos> I see.. But This Is My mysql [<-CODE->] 
[2019-06-27 09:51:31] <vsilent> oh, mysql is correct yes .
[2019-06-27 09:52:32] <gssjericsantos> i can't figure out why its not working. this is my whole docker-compose.yml [<-CODE->] 
[2019-06-27 09:53:17] <pedroparraortega> can you try withmysql:5.7
[2019-06-27 09:53:43] <pedroparraortega> i remember there was some changes after that version regarding the auth method
[2019-06-27 09:53:45] <vsilent> wait , in this docker-compose file you have service named "db" . so host should be db
[2019-06-27 09:54:12] <pedroparraortega> and yes, if that is your compose file… host should be db
[2019-06-27 09:54:17] <gssjericsantos> yes i did change it just awhile ago when you told me.;
[2019-06-27 09:54:43] <gssjericsantos> alright ill try 5.7
[2019-06-27 09:55:04] <vsilent> still not working after  docker-compose down && docker-compose up -d  ?
[2019-06-27 09:56:01] <gssjericsantos> yes still not working. still phpmyadmin cant access the user i created in docker-compose
[2019-06-27 09:56:42] <vsilent> can you show docker-compose logs db
[2019-06-27 09:58:13] <pedroparraortega> as i said
[2019-06-27 09:58:16] <pedroparraortega> downgrade the version
[2019-06-27 09:58:20] <pedroparraortega> it is working fine
[2019-06-27 09:58:26] <pedroparraortega> i just tested
[2019-06-27 09:58:53] <pedroparraortega>  [<-CODE->] 
[2019-06-27 09:59:01] <pedroparraortega> test that compose file
[2019-06-27 09:59:21] <pedroparraortega> i just removed the command from mysql and downgrade the version
[2019-06-27 10:00:18] <gssjericsantos> thank you i am building it now.  what do you mean removed the command?
[2019-06-27 10:00:43] <pedroparraortega> command: --default-authentication-plugin=mysql_native_password
[2019-06-27 10:01:11] <gssjericsantos> oh i see. thank you. ill give it a try.
[2019-06-27 10:01:18] <gssjericsantos> i just did a system prune -a
[2019-06-27 10:02:01] <pedroparraortega> that compose file should work, i just tested it
[2019-06-27 10:03:19] <gssjericsantos> i hope so too thank you@pedroparraortegai am still learning how to use docker. my task now is to run laravel and mysql and phpmyadmin on docker and i am having a hard time doing it.
[2019-06-27 10:03:35] <gssjericsantos> thank you also@vsilent
[2019-06-27 10:03:52] <pedroparraortega> no worries
[2019-06-27 10:03:58] <pedroparraortega> that is why we are here
[2019-06-27 10:03:59] <pedroparraortega> :p
[2019-06-27 10:04:21] <vsilent> u r welcome.
[2019-06-27 10:05:01] <gssjericsantos> thank you. i can't find on google a sample if a docker-compose.yml file that has phpmyadmin and mysql and laravel that's why its hard
[2019-06-27 10:05:24] <vsilent> in  case  you want extended laravel example  see [<-LINK->] 
[2019-06-27 10:05:33] <vsilent> but it's without phpmyadmin
[2019-06-27 10:07:00] <gssjericsantos> still not working for me
[2019-06-27 10:07:16] <gssjericsantos> this shows on phpmyadmin [<-CODE->] 
[2019-06-27 10:08:34] <gssjericsantos> this is my whole docker-compose file [<-CODE->] 
[2019-06-27 10:09:40] <gssjericsantos> the mysql container exits
[2019-06-27 10:09:46] <gssjericsantos> this is the log for db
[2019-06-27 10:10:24] <gssjericsantos>  [<-CODE->] 
[2019-06-27 11:06:15] <vsilent> | 2019-06-27T10:04:14.791243Z 0 [ERROR] [FATAL] InnoDB: Table flags are 0 in the data dictionary but the flags in file ./ibdata1 are 0x4800!
[2019-06-27 11:08:00] <vsilent> you can try remove data and try again,  docker-compose down -v     (Please note this will remove all db data and volumes for this project).
[2019-06-27 11:09:37] <vsilent> by the way, why do you have - persistent:/var/lib/mysql   and  - mysql-data:/var/lib/mysql
[2019-06-27 11:15:28] <vsilent> gssjericsantos: try comment out - persistent:/var/lib/mysql and try down/up .
[2019-06-27 12:23:53] <pedroparraortega> it is fixed now@vsilent
[2019-06-27 16:41:20] <jenfredwell>  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2019-06-28 08:28:41] <omiozil> How can i specify Port for my embedded server and API of which the image is created in docker file. Right now i have provided only embedded server port by Expose 8080, but my API is containing another port. due to Which my API is Unable to access
[2019-06-28 08:36:24] <vsilent> omiozil: ports:8080:<api-port>
[2019-06-28 08:41:45] <omiozil> vsilent: Thanks will try that and get back
[2019-06-28 08:54:58] <Baneeishaque> I think still docker is not available for arm, and still there is no plan for it. better ask in their github repository page : [<-LINK->] @jenfredwell
[2019-06-28 09:28:31] <gssjericsantos> hello guys. i am having a problem how to run laravel on docker-compose
[2019-06-28 09:29:10] <gssjericsantos>  [<-CODE->] 
[2019-06-28 09:30:09] <vsilent> gssjericsantos: try this [<-LINK->] 
[2019-06-28 09:41:45] <gssjericsantos> i just couldnt copy my project folder to the dockerfile
[2019-06-28 09:52:10] <vsilent> gssjericsantos: I see you have COPY . /app
[2019-06-28 09:52:41] <gssjericsantos> yes bit it gives me errors that no file found
[2019-06-28 09:52:43] <gssjericsantos> im using mac
[2019-06-28 09:54:07] <vsilent> make sure you have ./app  with project files in the same directory where you trying to build image , where Dockerfile is
[2019-06-28 09:54:53] <gssjericsantos> it is in the same directory but it still does not find it.
[2019-06-28 09:55:23] <vsilent> do you use docker-compose ?
[2019-06-28 09:55:32] <gssjericsantos> yessir.
[2019-06-28 09:55:55] <gssjericsantos>  [<-CODE->] 
[2019-06-28 09:59:47] <vsilent> gssjericsantos: try this  docker-compose exec app  ls -la /app
[2019-06-28 10:01:44] <gssjericsantos> it gives me this error.
[2019-06-28 10:02:00] <gssjericsantos>  [<-CODE->] 
[2019-06-28 10:02:55] <vsilent> in Dockerfile you are copying files to /app  and at the same time you expect them in /var/www
[2019-06-28 10:04:54] <vsilent> may be it should be something likevolumes: [<-CODE->] ?
[2019-06-28 14:47:31] <jenfredwell> Baneeishaque: Thanks.  I'll take a look
[2019-06-30 17:54:03] <an_spage_twitter> Здравейте,на всички които сте обвързани с платформата и начинът за достигане в което ще си бъдем взаимно полезно в управиление на развитие.
[2019-07-02 11:01:45] <Bryksin> Hey guysquick question in relation to Docker in Docker: [<-CODE->]  [<-CODE->] 
[2019-07-03 08:06:08] <lioxor64> Hello, my name is Liora and I am currently hunting open source projects for company NeuraLegion (www.neuralegion.com)We just launched a free annual subscription for open source projects for our AIAST tool NexPloit.If you are interested, please, reach us on opensource@neuralegion.com!Thank you for your time and consideration! If you have any questions, please do not hesitate to contact us!Best,
[2019-07-03 18:33:04] <damienwebdev> Can anyone clarify the following? [<-CODE->] Additionally, if I were to use a compose file like: [<-CODE->]  [<-CODE->] 
[2019-07-03 18:33:16] <damienwebdev> I want to ensure that my assumptions here are correct.
[2019-07-03 18:35:44] <damienwebdev> Because, I have a strange situation where I'm doing the above, and I have two issues: [<-CODE->] 
[2019-07-03 19:39:25] <leojonathanoh_gitlab> docker volumes do not persist when they are removed
[2019-07-03 19:40:21] <leojonathanoh_gitlab> damienwebdev: 
[2019-07-03 19:41:35] <leojonathanoh_gitlab> a docker-compose down removes all docker volumes associated with the Compose definition. To persist data, use a volume driver, or use a bind mount
[2019-07-05 13:11:46] <mcarpenterjr>  [<-CODE->]  [<-CODE->] And my Dockerfile has it's args specified like [<-CODE->]  [<-CODE->] 
[2019-07-05 13:57:44] <nnddominic> getting this ERROR: could not find plugin bridge in v1 plugin registry: plugin not found
[2019-07-05 17:14:34] <inodeman> Hi, I am new to this group and to Docker. I recently experimented deploying to OpenShift (Red Hat Enterprise Kubernetes) but saw that a SpringBoot demo app I did could not get exposed (Routes) since it was executing as root . So I added these two things to 1) Created a user 2) Exposes the Port. After that it worked like a charm, I deployed the app, created a Route (To be accesible) and that did it. Here is the things I added to the Docker File.RUN adduser -D myuserUSER myuserEXPOSE 8080
[2019-07-05 17:14:38] <inodeman> hope it helps
[2019-07-06 05:57:26] <vsilent> inodeman: can you show logs ? I believe user has not enough rights to start something
[2019-07-06 23:25:43] <inodeman> Hi@vsilentall I got was a message on openshift saying that the docker image was executing as root and that it might not be available to the public, but after I added the 3 lines I mentioned everything worked fine :-)
[2019-07-08 06:27:00] <guddutopper> Hi, how do we remove security vulnerabilities from docker images, for examples when I scanned my java project docker images, there are many JARs which are shown to be security vulnerable, how do I removed them from my docker image ?
[2019-07-08 17:32:25] <anthony_g_gitlab> if I have a volume (named) that I created on my host machine (e.g.docker volume create openstreetmap-data) can I access that in a docker-compose script? e.g: [<-CODE->] 
[2019-07-08 18:03:31] <mpictor> Using docker v 18.09.7 on gentoo, I'm able to start dockerd as root and it stays running (so I assume everything's ok). But if I try to start the systemd service, I get [<-CODE->] Any suggestions would be greatly appreciated, as I'm out of ideas.
[2019-07-08 18:26:19] <mpictor> the config checker script is happy; all I'm missing is some optional stuff for encrypted networks and for aufs and zfs. [<-CODE->]  [<-CODE->] 
[2019-07-08 18:27:02] <mpictor> I had this working, and I recall doing a fair amout of work to get it working, but that was on an old computer. Whatever I did, I don't see it in the config files I saved.
[2019-07-08 18:58:46] <holmmi> Is it somehow possible to mount files toWORKDIRwithout replacing the folder withdocker run -voption?
[2019-07-08 21:21:45] <mpictor> Any suggestions would be greatly appreciated, as I'm out of ideas. anyone? 
[2019-07-08 22:55:37] <mpictor> For user help, please goto #docker on freenode.crap, I didn't see that
[2019-07-09 14:40:20] <bronhy> Does anyone understand this error. I do not get it. [<-CODE->] 
[2019-07-09 15:10:09] <bronhy> ok it works in 0.11 and not in 0.12
[2019-07-09 15:10:29] <bronhy> sweet...
[2019-07-10 15:32:34] <dragonpiper> How do i get a swarm service to use an updated version an image whos tag hasn't changed ?
[2019-07-11 09:04:56] <niyaode> I asked a question about Using a custom MySQL configuration file in [<-LINK->] .
[2019-07-11 13:27:00] <katsar0v>  [<-CODE->]  [<-CODE->] Unfortunately this doesn't work and the virtualenv installation is broken [<-CODE->]  [<-CODE->] 
[2019-07-11 13:27:21] <katsar0v> Is maybeVIRTUALENV_VERSIONaspecialword inDockerfile?
[2019-07-11 13:53:37] <mudassir-ahmed> PLEASE HELP
[2019-07-11 13:56:01] <mudassir-ahmed> Localhost for the docker wordpres image keeps redirecting any port to localhosst
[2019-07-11 13:56:24] <mudassir-ahmed> but thi was working a few days ago - honestly have no clue what has happened
[2019-07-11 13:56:53] <mudassir-ahmed> Here's my docker-compose.yml
[2019-07-11 13:59:00] <mudassir-ahmed>  [<-LINK->] 
[2019-07-12 06:07:23] <guddutopper> hi, I am scanning my docker images for vulnerabilities, I found these in my docker image - [<-LINK->] Now i found out that these are part of the base image which i am using in my docker file which isnginx:alpineHow do i remove them , I have tried to upgrade the version of busybox as mentioned in the above pic but it is giving me unsatisfiablity error
[2019-07-12 16:13:26] <develroo> guddutopper: How did you scan them ?
[2019-07-12 19:47:06] <mudassir-ahmed> no such file or directory": unknown
[2019-07-12 19:47:28] <mudassir-ahmed> but when the file exists.. any ideas?
[2019-07-12 21:58:28] <kellyprankin> If the file exists then the path it is using is wrong?
[2019-07-12 22:19:20] <mudassir-ahmed> I found the issue
[2019-07-12 22:19:27] <mudassir-ahmed> I have another question...
[2019-07-12 22:20:25] <mudassir-ahmed> After runningdocker-compose up -din a bash script
[2019-07-12 22:21:10] <mudassir-ahmed> then runningMYSQL_ROOT_PASSWORD=\'somewordpress\'\ndocker exec -i dockerstuff_mysql-database_1 sh -c \'exec mysql -uroot -p"$MYSQL_ROOT_PASSWORD" wordpress\' < ../repository/assets/database.sqlin the same bash script
[2019-07-12 22:21:33] <mudassir-ahmed> I getread unix @->/var/run/docker.sock: read: connection reset by peer
[2019-07-12 22:22:17] <mudassir-ahmed> unless i putsleep 30afterdocker-compose up -dthen everything works fine
[2019-07-12 22:22:31] <mudassir-ahmed> Am I using a bad approach?
[2019-07-13 15:44:18] <rcjsuen> Have you looked at the logs? Perhaps the MySQL container hasn't completed started yet?
[2019-07-13 20:43:19] <laurensvanpoucke> Hi I'm starting an NGINX image which serves a frontend app. On my computer there is a nodejs application running. How can I access that nodejs app/port via the nginx docker image?
[2019-07-13 23:05:17] <dragonpiper> Anyone know how to resolve issues with docker not being able to route container traffic though host vpn on mac?
[2019-07-14 11:42:46] <guddutopper> @guddutopper How did you scan them ?Hi I am using whitesource OSS scanner for this
[2019-07-15 12:33:57] <DSchaffer-_gitlab> hey guys, is someone using wordpress with docker?
[2019-07-15 15:05:04] <matrixbot> FaceI only just started trying to migrate an existing site
[2019-07-15 16:37:29] <stherrienaspnet> Hello guys, I'm building a container with nodejs and nginx, but it is restarting, wich CMD could i call first to make sure the container is not rebooting so I could see my error on console?
[2019-07-15 16:47:55] <matrixbot> FaceKeep the process attached to the console by starting it without -d (if you're not already) it should give you some info about any hitches in startup.
[2019-07-16 14:47:08] <JoeSSS> Hey! I have a question. How do I make container to stop if it becomes unhealthy during the time? We use our containers to run android emulators inside, and sometimes they crash and our HEALTHCHECK spots it, but container stays unhealthy 4ever and make the Jenkins job to stuck. Ideally we want to stop uneahealthy container right away, is that possible?
[2019-07-16 16:40:36] <vsilent> DSchaffer-_gitlab: yes, I do
[2019-07-16 16:48:24] <vsilent> JoeSSS: , makes sense to fix the problem which causes crash. Or just kill containers ? May be try pause them ?
[2019-07-16 16:51:35] <JoeSSS> Well, the google tooling crashes in this case, we cannot fix that. But killing Container actually help, as tests will unstuck and go to rerun. I think I found kinda solution, I kill supervisord in healthcheck with || killall supervisord. It stops the unhealthy container. Thought that there can be more reliable way :h
[2019-07-16 17:51:48] <stherrienaspnet> Hello guys, i need help... how do I run bash command into Docker file? in my case i need to send command to mongo shell
[2019-07-16 18:08:23] <DSchaffer-_gitlab> stherrienaspnet: Try "RUN touch test.txt" so you create a txt file
[2019-07-16 18:24:30] <stherrienaspnet> DSchaffer-_gitlab: I am pretty close... when container is started i can run my bash command and it is working but it is not working inside docker file
[2019-07-16 18:25:18] <stherrienaspnet> inside my docker file i have this: RUN /etc/replicaset.sh
[2019-07-16 18:25:58] <dragonpiper> Man this is fustrating. I have an issue where docker sets up the network work after the host uses internet connection. Last time i fixed it by reset my settings. Anyone know of a alternative ?
[2019-07-16 18:34:31] <stherrienaspnet> bash command inside docker file and inside docker container do not give me the same result...
[2019-07-16 18:39:06] <rcjsuen> stherrienaspnet: So to be clear it sounds more like at build time when you look at the output ofdocker build, it does not match the output when you run the actual (built) Docker container?
[2019-07-16 18:42:51] <stherrienaspnet> sorry for my bad explanation
[2019-07-16 19:34:21] <stherrienaspnet> i have try so many thing to get my bash file called correctly from Dicker file without success
[2019-07-16 19:35:06] <stherrienaspnet> Is is possible to just after my command docker run  call docker exec?
[2019-07-16 19:35:58] <stherrienaspnet> docker run --name k-mongodb -d p:27017:27017docker exec -it k-mongo
[2019-07-16 19:36:54] <stherrienaspnet> it does not seems to work... maybe we need to wait until container is ready?
[2019-07-16 19:54:47] <rcjsuen> Sounds likely
[2019-07-16 19:55:53] <stherrienaspnet> maybe a need to put a delay?
[2019-07-16 19:57:16] <rcjsuen> Can you share yourDockerfile?
[2019-07-16 19:57:24] <stherrienaspnet> yes sure
[2019-07-16 19:58:22] <DSchaffer-_gitlab> stherrienaspnet: if you use "docker exec -it k-mongo bash"
[2019-07-16 19:58:36] <stherrienaspnet> FROM mongo:4.2-rcCOPY etc /etc/chmod +x /etc/replicatset.shRUN apt updateRUN apt install nanoEXPOSE 27017CMD ["mongod", "--replSet", "rs0"]
[2019-07-16 19:58:37] <DSchaffer-_gitlab> so you start a bash session in your docker container
[2019-07-16 19:59:18] <stherrienaspnet> can i do it inside my docker file?
[2019-07-16 19:59:41] <stherrienaspnet> or it need to be called externally?
[2019-07-16 20:00:20] <DSchaffer-_gitlab> vsilent: oh thank you, its okay, i saw my fail, the Wordpress overwrite all of my other files in my container. So i can run my commands like touch test.php, but this will be overwritten by Wordpress
[2019-07-16 20:00:59] <Baneeishaque> Hey! I have a question. How do I make container to stop if it becomes unhealthy during the time? We use our containers to run android emulators inside, and sometimes they crash and our HEALTHCHECK spots it, but container stays unhealthy 4ever and make the Jenkins job to stuck. Ideally we want to stop uneahealthy container right away, is that possible?Can you please share some android emulator images?
[2019-07-16 20:04:30] <stherrienaspnet> Maybe a simpler question...
[2019-07-16 20:05:47] <stherrienaspnet> let say I have a container already running and I can actually connect to it using this command: "docker exec -it k-mongodb bash"
[2019-07-16 20:06:28] <stherrienaspnet> after i need to enter this command: "bash /etc/replicaset.sh"
[2019-07-16 20:06:48] <stherrienaspnet> How can i call it in one line of code?
[2019-07-16 20:07:42] <vsilent> DSchaffer-_gitlab: cool, fyi this might be useful too for Wordpress users [<-LINK->] 
[2019-07-16 20:09:51] <DSchaffer-_gitlab> stherrienaspnet: try:
[2019-07-16 20:10:27] <stherrienaspnet> try what?
[2019-07-16 20:10:28] <DSchaffer-_gitlab> in your dockerfile:
[2019-07-16 20:10:51] <DSchaffer-_gitlab> run sh /etc/relicaset.sh
[2019-07-16 20:11:26] <stherrienaspnet> run sh /etc/relicaset.sh or run bash /etc/relicaset.sh?
[2019-07-16 20:13:26] <DSchaffer-_gitlab> Run sh ....
[2019-07-16 20:13:37] <stherrienaspnet> ok thanks
[2019-07-16 20:13:51] <DSchaffer-_gitlab> Hope it works for you
[2019-07-16 20:15:17] <stherrienaspnet> It cannot build because in any case mongo is not accepting connection yet
[2019-07-16 20:15:42] <stherrienaspnet> maybe the solution is executing the bash file from an external script
[2019-07-16 20:16:16] <DSchaffer-_gitlab> Maybe another container is running
[2019-07-16 20:16:23] <stherrienaspnet> no
[2019-07-16 20:16:58] <stherrienaspnet> i just need to find a way to call the bash file using docker exec -it...
[2019-07-16 20:21:48] <DSchaffer-_gitlab>  [<-LINK->] 
[2019-07-16 20:22:14] <stherrienaspnet> thanks
[2019-07-16 20:25:31] <stherrienaspnet> DSchaffer-_gitlab: you just save me with your last link, thanks!
[2019-07-16 20:26:22] <stherrienaspnet> that is my final solution using an external file.. docker exec k-mongodb /bin/bash /etc/replicatset.sh
[2019-07-16 20:34:21] <DSchaffer-_gitlab> Nice :)
[2019-07-17 12:21:37] <mtippmann> looking for solutions/clarification regarding this issue here: [<-LINK->] 
[2019-07-17 12:22:18] <mtippmann> is this even in the code?
[2019-07-17 14:32:50] <stherrienaspnet> Hello guys I need help on port, I have 2 containers, mongodbContainer, nodejsAppContainer, the  nodejsAppContainer cannot connect to the mongodbContainer, but if I start nodejsAppContainer with --network=host this is working
[2019-07-17 15:37:52] <stherrienaspnet> Is there anyone here that could assist me with docker?
[2019-07-17 15:51:43] <rcjsuen> stherrienaspnet: Do you not want to use a Docker network for your containers?
[2019-07-17 15:52:14] <stherrienaspnet> No, because I do not know anything about it
[2019-07-17 15:52:27] <stherrienaspnet> i know that links are depreciated
[2019-07-17 15:52:53] <stherrienaspnet> How to create a docker network?
[2019-07-17 15:53:22] <rcjsuen>  [<-LINK->] 
[2019-07-17 15:54:41] <stherrienaspnet> just to give you more details about my use case, I have a mongodb container and a nodejs container
[2019-07-17 15:55:32] <stherrienaspnet> The nodejs container cannot connect to 127.0.0.1:27017 but my window 10 can access it
[2019-07-17 15:56:33] <stherrienaspnet> What is the right docker network configuration required in this case?
[2019-07-17 15:57:40] <stherrienaspnet> I am lost because from windows my main OS i can connect to the mongodb container
[2019-07-17 15:58:28] <stherrienaspnet> but container cannot connect to the other container on the same pc
[2019-07-17 16:01:01] <stherrienaspnet> rcjsuen: could you guide me on the setting i need to use for my case
[2019-07-17 16:01:20] <rcjsuen> stherrienaspnet: Most guides online suggest using Docker Compose to bootstrap things
[2019-07-17 16:01:33] <rcjsuen> You are of course welcome otherwise to create Docker networks by hand if you wish
[2019-07-17 16:02:20] <rcjsuen>  [<-LINK->] 
[2019-07-17 16:02:57] <stherrienaspnet> thanks
[2019-07-17 16:03:38] <stherrienaspnet> I saw in the stackoverflow they are using link, is it the link command that is now depricated?
[2019-07-17 16:04:43] <stherrienaspnet> rcjsuen: is it better to use docker compose?
[2019-07-17 16:05:04] <stherrienaspnet> or the stackoverflow way?
[2019-07-17 16:06:53] <rcjsuen> Links as you pointed out are deprecated so I would not use them
[2019-07-17 16:07:05] <rcjsuen> stherrienaspnet: We use Docker Compose and Kubernetes where I work
[2019-07-17 16:07:47] <stherrienaspnet> How do we start with Docker Compose?
[2019-07-17 16:10:06] <stherrienaspnet> Let say I use docker compose and the mongodb container is running 2 years without any change on it but the nodejs container need to be updated several time, is it possible to update only nodejs container when using docker compose in production?
[2019-07-17 16:11:47] <stherrienaspnet> to make it clearer using docker compose can we update a single container ?
[2019-07-17 16:21:02] <rcjsuen> stherrienaspnet:  [<-LINK->] 
[2019-07-17 16:21:33] <stherrienaspnet> thanks :)
[2019-07-17 16:24:53] <stherrienaspnet> Thanks for your help with your stackoverflow links it worked, you save my day!
[2019-07-18 13:05:01] <SenalChen> Hi guys, my container is running but I can\'t  use "curl localhost:9200" to connect elasticsearch, is there anyone knows why it happend?
[2019-07-19 05:32:05] <DSchaffer-_gitlab> You set the port 9200 for elasticsearch?
[2019-07-19 05:32:15] <DSchaffer-_gitlab> SenalChen: ?
[2019-07-19 05:46:32] <SenalChen> yeah,this is my config: [<-CODE->] 
[2019-07-19 05:47:26] <SenalChen> my docker command is :docker run -itd -p 9200:9200 -p 9300:9300 --name elasticsearch -v /elasticsearch/data:/usr/share/elasticsearch/data --restart=always 45ff2ef9a219
[2019-07-19 08:30:25] <Ali-Ghali> hello, guys, I am writing here after  asking all over the internet about a reasonable answer for a strange issue I am in with  docker-composeand Node & npm  if I sync the entire app directory  to one volume it works fine BUT if I sync individual volumes and files like package.json [<-CODE->] Then  I can't install new npm packages propely, npm can't update package.jsonthe error I am getting is : [<-CODE->] 
[2019-07-19 08:32:23] <zhangyanwei> If you list the /app directory in the docker, what will you see?
[2019-07-19 10:26:18] <Ali-Ghali> zhangyanwei: everything in the place even the node package I recently installed is there in thenode_modulesfolder but justpackage.josnis not updated, docker is creating a temporary filepackage.json.3573157296and then try to rewrite it topackage.json
[2019-07-19 13:07:50] <stherrienaspnet> Hello guys, does anyone is using pm2 and docker here?
[2019-07-19 13:25:40] <stherrienaspnet> Anyone could help me with CMD, there is something I cannot understand, I have 2 CMD if I run only one command in the docker file it is working but when running both CMD one is failing
[2019-07-19 13:29:07] <rcjsuen> stherrienaspnet: I don't understand. You're not supposed to have multipleCMDcommands (unless you are using build stages)
[2019-07-19 13:29:21] <rcjsuen>  [<-LINK->] 
[2019-07-19 13:29:29] <rcjsuen>  [<-CODE->] 
[2019-07-19 13:29:36] <stherrienaspnet> thanks I did not know that :)
[2019-07-19 13:32:24] <stherrienaspnet> rcjsuen: I my docker image I had CMD ["nginx", "-g", "daemon off"] and now I need to add pm2-runtime ecosystem.config.js, how do I add this?
[2019-07-19 13:34:59] <stherrienaspnet> rcjsuen: i need to run 2 command how can I do that inside a container?
[2019-07-19 13:35:26] <stherrienaspnet> CMD ... RUN ...?
[2019-07-19 13:35:27] <scramb> stherrienaspnet: u could write a shell script and execute that...
[2019-07-19 13:36:28] <stherrienaspnet> scramb: do you have an example? i mean how make it run forever?
[2019-07-19 13:37:05] <stherrienaspnet> CMD ["myscript.sh"]
[2019-07-19 13:38:03] <stherrienaspnet> I suppose script need to never exit with 0
[2019-07-19 13:39:01] <scramb> or use RUN but what you wunt to reach by keeping the script running?
[2019-07-19 13:39:59] <stherrienaspnet> i just need to start nginx and also start nodejs process using pm2
[2019-07-19 13:41:14] <scramb> you could set nginx as entrypoint  and run everything else as script?
[2019-07-19 13:41:23] <stherrienaspnet> can I just do that? CMD ["nginx", "-g", "daemon off"] RUN ["pm2-runtime", "./ecosystem.config.js"]?
[2019-07-19 13:41:41] <scramb>  [<-LINK->] this could help
[2019-07-19 13:41:55] <stherrienaspnet> thanks
[2019-07-19 13:42:20] <stherrienaspnet> what is the difference between RUN and using a script?
[2019-07-19 14:05:28] <rcjsuen> I suggest you read the documentation
[2019-07-19 14:05:41] <rcjsuen> using [<-CODE->] maybe not give you your expected result
[2019-07-19 14:06:00] <rcjsuen> Depending on ordering and so on
[2019-07-19 14:18:02] <stherrienaspnet> thanks
[2019-07-19 15:37:18] <stherrienaspnet> Guys i need help with script file... when running on my container console pm2 start ecosystem.config.js it is working, but i cannot do it using a bash file??? It always said ecosystem file not found and it is located at the same place as the script
[2019-07-19 18:14:12] <stherrienaspnet> can someone assit me with docker run, I'm really lost...
[2019-07-22 07:53:07] <IceS2388> 有中国人吗？
[2019-07-22 07:54:28] <niyaode> en\\
[2019-07-22 07:55:13] <niyaode> 在这里得不到任何帮助
[2019-07-22 09:20:40] <Bryksin> Hi everyone,I'm having a problem with docker build on Mac, it is ignoring the given contextin the docker file I have the following line: [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] any hints? what am I doing wrong?
[2019-07-22 12:13:59] <SenalChen> 有
[2019-07-22 12:14:15] <SenalChen> IceS2388: @niyaode居然有中国人
[2019-07-22 14:10:18] <IceS2388> 其实有docker的中文教程的
[2019-07-22 14:10:26] <IceS2388> 有需要的话说一声
[2019-07-22 14:10:52] <IceS2388> 要学好不容易
[2019-07-22 14:11:53] <IceS2388> Docker技术入门与实战  第3版
[2019-07-22 14:12:13] <IceS2388> SenalChen: @niyaode
[2019-07-22 14:39:32] <wencheng1994> Hello everyone. I have some trouble about docker when deploy my web app.  java.net.Inet6AddressImpl.lookupAllHostAddr  throws java.net.UnknownHostException.
[2019-07-22 14:40:09] <wencheng1994> Here is the error stack and docker info. [<-LINK->] 
[2019-07-22 14:41:32] <wencheng1994> Does anybody know why?
[2019-07-22 18:25:36] <larryw3i> IceS2388: I prefer to read the English tutorial
[2019-07-23 01:42:25] <zhangyanwei> Ali-architrave: Have you resolved your question?
[2019-07-23 01:43:41] <zhangyanwei> I guess you can directly map the working directory to/appdirectory in docker.
[2019-07-23 05:42:48] <Ankit3794> Hello Everyone, I have Docker EE on Windows Server 2016. I have read that For Windows Server 2016 Docker would be installed as Basic EE and the cost for that is already covered in Windows Server OS licensing.But I can not found anywhere that What support or Features can I expect with Docker EE and How to get License of that. Can I get Universal control panel.
[2019-07-24 04:54:00] <dlwhitehurst_gitlab> Can anyone tell me how to auth with GitLab registry and call for my images in docker-compose? I’m using [<-LINK->] but my docker-compose is having a forbidden issue. I tried logging in with docker client on this machine but I’m running the compose using Rancher on this machine
[2019-07-24 12:50:39] <rcjsuen> dlwhitehurst_gitlab: I don't really understand your question. If you usedocker-composeit works but when you userancher-composeit doesn't?
[2019-07-24 17:16:45] <stherrienaspnet> Hello Guys I have difficulty with network sharing between container located on the same machine, could someone assit me please?
[2019-07-24 18:54:55] <stherrienaspnet> I fixed my issue :)
[2019-07-24 23:24:28] <dlwhitehurst_gitlab> rcjsuen: no. Sorry. I have a Hipster generated docker-compose. I now build and store the docker image on GitLab. I have the right syntax for image: in the compose, but because the registry is not Docker-Hub and it’s private, I can’t authenticate before Docker uses the docker-compose to setup things on Rancher. I need to somehow authenticate with GitLab prior to Rancher/Docker .. using the docker-compose I upload to Rancher.
[2019-07-25 02:04:42] <dlwhitehurst_gitlab> The container tool I’m using, Rancher had a place to authenticate with my private registry. I’m golden now! :-)
[2019-07-25 13:24:05] <stherrienaspnet> Hello guys how do we manage container version when using docker compose?
[2019-07-26 01:09:10] <jbouse> Anyone know if the ability to useagent { docker { image '...' } }in declarative pipeiine works with Windows Docker?
[2019-07-26 05:12:13] <matrixbot> kudasaiclassymom5g.ogg
[2019-07-27 04:23:28] <zzj0402_gitlab> So I am dockerizing a node experess server. I have no clue why I keep getting port occupied.
[2019-07-27 04:23:52] <zzj0402_gitlab>  [<-LINK->] 
[2019-07-27 04:24:36] <zzj0402_gitlab> Help!
[2019-07-27 04:25:25] <matrixbot> kudasaimumble://mumble-ru.cleanvoice.com:25253/Lobby/Politically%20Incorrect?title=Root&version=1.2.0
[2019-07-27 09:32:51] <trepidacious> zzj0402_gitlab: You might want to use a port number above 1023?
[2019-07-27 09:33:29] <trepidacious> zzj0402_gitlab: Then check for running containers?
[2019-07-27 23:55:37] <zzj0402_gitlab> trepidacious: I tried 7777. Same return.
[2019-07-29 04:02:01] <zzj0402_gitlab>  [<-LINK->] 
[2019-07-29 04:02:13] <zzj0402_gitlab> trepidacious: no container is running
[2019-07-29 05:59:51] <matrixbot> jzamorIf I'm inside a container which has the docker socket mounted in, can I start another container from inside the first and mount a volume in?  I can't seem to do it (I always end up with an empty directory).
[2019-07-29 09:26:24] <trepidacious> zzj0402_gitlab: That is very odd. Have you tried running another container that opens a server port? I’ve not used this, but something like [<-LINK->] 
[2019-07-29 09:27:02] <trepidacious> zzj0402_gitlab: that would tell you whether the problem is to do with docker or the specific image you are running
[2019-07-29 09:27:24] <trepidacious> E.g. if for some reason that image tries to start the server twice
[2019-07-29 22:01:50] <zzj0402_gitlab>  [<-LINK->] 
[2019-07-29 22:01:52] <zzj0402_gitlab> trepidacious: 
[2019-07-29 22:03:56] <trepidacious> zzj0402_gitlab: that looks right, can you see it on [<-LINK->] ?
[2019-07-29 22:05:53] <zzj0402_gitlab> What do you mean by see?
[2019-07-29 22:06:19] <zzj0402_gitlab>  [<-LINK->] 
[2019-07-29 22:06:26] <zzj0402_gitlab> trepidacious: 
[2019-07-29 22:07:02] <zzj0402_gitlab> At least container is running.
[2019-07-29 22:07:57] <trepidacious> zzj0402_gitlab: Ah I was expecting it to show a simple page as in the description.
[2019-07-29 22:09:51] <trepidacious> zzj0402_gitlab:  [<-LINK->] should work as well, odd...
[2019-07-29 22:10:25] <trepidacious> Have you had any working servers in a container?
[2019-07-29 22:14:21] <zzj0402_gitlab> No, not yet.@trepidacious
[2019-07-29 22:17:22] <zzj0402_gitlab>  [<-LINK->] 
[2019-07-29 22:17:30] <zzj0402_gitlab>  [<-LINK->] 
[2019-07-29 22:17:34] <zzj0402_gitlab> This one works
[2019-07-29 22:21:06] <trepidacious> zzj0402_gitlab: ah cool, so it’s not a basic docker problem
[2019-07-29 22:26:23] <zzj0402_gitlab> trepidacious: fixed. I deleted the expose command and it runs now! Thank you so much!
[2019-07-29 22:26:48] <zzj0402_gitlab>  [<-CODE->] 
[2019-07-29 22:27:22] <trepidacious> zzj0402_gitlab: ah excellent, glad you got it fixed :)
[2019-07-29 22:27:24] <zzj0402_gitlab>  [<-CODE->] 
[2019-07-29 22:29:13] <trepidacious> zzj0402_gitlab: Yes I’m not sure but I think you should probably have either expose or -p but not both since they have the same result
[2019-07-29 22:29:31] <zzj0402_gitlab> trepidacious: agreed
[2019-07-29 22:30:13] <zzj0402_gitlab> Acutally I tried just EXPOSE in the container
[2019-07-29 22:31:14] <zzj0402_gitlab>  [<-CODE->] 
[2019-07-29 22:31:23] <zzj0402_gitlab> it didn't work
[2019-07-29 22:31:49] <zzj0402_gitlab> So I am not sure what really is going on with the EXPOSE and -p
[2019-07-29 22:33:20] <zzj0402_gitlab>  [<-LINK->] 
[2019-07-29 22:33:48] <zzj0402_gitlab> I need to be more careful with copy n pasted tutorials.
[2019-07-30 17:23:26] <jdickey> What do people use for Docker-based CI and CD workflows? I've been trying everything I can get my hands on; GitHub Actions won't support docker-compose, and GitLab CI requires a mirror (not merely a snapshot) of your source repo if it's hosted elsewhere (e.g., GitHub). I blogged about this at [<-LINK->] out of sheer frustration
[2019-07-30 20:23:36] <rcjsuen> jdickey: for personal stuff on GitHub I use Travis CIat work we use BitBucket + Shippable for old stuff and testing out GitLab (both Git and CI/CD) for new stuff
[2019-07-30 23:10:26] <nafg> Can someone explain how user namespace mapping is supposed to work with host-mounted volumes?
[2019-07-30 23:10:41] <nafg> I thought it would help but it doesn't, maybe it's not its goal?
[2019-07-30 23:11:22] <nafg> Maybe the goal is just to prevent root inside the container from escaping, it's just a security feature nothing more?
[2019-07-30 23:11:43] <nafg> My objective is simply to mount a volume into a container without getting into permission issues
[2019-07-31 05:08:07] <makotoiwakabe> Hey guys.When  I inspect docker volums , below is the result of it.But in my local pc, I cant find this directory/var/lib/docker/. where volume is saved?? [<-CODE->] 
[2019-07-31 10:32:22] <meshde> makotoiwkb: You need to have root access to be able to access that directory. Use sudo to cd into that directory
[2019-08-01 06:58:23] <zzj0402_gitlab>  [<-CODE->] returns [<-CODE->] 
[2019-08-01 06:58:41] <zzj0402_gitlab> Help people!
[2019-08-01 07:00:01] <meshde> Try docker run -it node:alpine /bin/bash
[2019-08-01 07:01:52] <zzj0402_gitlab>  [<-CODE->] 
[2019-08-01 07:02:25] <zzj0402_gitlab> Git Bash on Windows
[2019-08-01 07:18:28] <meshde> This should work docker run -it —entrypoint /bin/sh node:alpine
[2019-08-01 07:39:15] <zzj0402_gitlab> It doesn't
[2019-08-01 07:40:02] <zzj0402_gitlab>  [<-CODE->] 
[2019-08-01 07:40:08] <zzj0402_gitlab> this works however
[2019-08-01 07:40:20] <zzj0402_gitlab> bash just can't start
[2019-08-01 07:41:25] <whitehatK> try sh instead of bash
[2019-08-01 07:41:31] <meshde> The previous command I gave worked for me, what error did you get?
[2019-08-01 07:42:05] <whitehatK> docker run -it node:alpine /bin/sh
[2019-08-01 07:42:40] <zzj0402_gitlab>  [<-CODE->] 
[2019-08-01 07:42:55] <zzj0402_gitlab> this works thanks people
[2019-08-01 09:11:47] <chenzihaojie>  [<-ISSUE->] anybody has the same problem ?
[2019-08-01 09:44:19] <rcjsuen> zzj0402_gitlab: For alpine use/bin/ash
[2019-08-01 10:55:07] <JKostov> Hello guys,I am using travis-ci for building and pushing docker images to dockerhub. Can someone tell me is it safe enough to store passwords in the travis-ci environment variables, such as dockerhub account and password?
[2019-08-01 10:56:10] <rcjsuen> JKostov: I do expose them to Travis CI so it can build and push images to Docker Hub for me.
[2019-08-01 10:57:01] <rcjsuen> As to whether it is "safe" or not, that depends on if you trust Travis CI\'s servers I suppose
[2019-08-01 11:13:43] <JKostov> rcjsuen: Thank you, I am currently doing it too.  :D
[2019-08-01 11:18:57] <omiozil> Hi Folks. I have create a Docker file which is as below. the jar indicated in dockerfile is an  Api developed using apache camel which has port 8036. But the embedded tomcat server has 8076 for this API. Due to this config i am unable to access my API when it is running. Is there any way to access this api by making changes in my dockerfile. Kindly suggest.
[2019-08-01 11:19:27] <omiozil>  [<-CODE->] 
[2019-08-01 11:24:16] <zzj0402_gitlab> delete EXPOSE 8076 and use docker run -p 8036:8036@omiozil
[2019-08-01 11:25:15] <zzj0402_gitlab> or -p whicheverportyouwant:whichever
[2019-08-01 11:46:13] <omiozil> zzj0402_gitlab: thanks for reply, but it din't work. i have use below comand to access to that API.
[2019-08-01 11:46:31] <omiozil> curl -v -H "Content-Type: application/json; charset=UTF-8" -X POST --data \'{"primaryRowID" : "1-7O12VKV"}\' [<-LINK->] 
[2019-08-01 11:46:44] <omiozil> I received below error response:
[2019-08-01 11:46:58] <omiozil>  [<-CODE->] 
[2019-08-01 11:47:22] <zzj0402_gitlab> what's your image log?
[2019-08-01 11:48:27] <omiozil> zzj0402_gitlab: I din't received the hit at image.
[2019-08-01 12:11:08] <rcjsuen> omiozil: From within the image, are you able tocurl8036?
[2019-08-01 12:19:02] <omiozil> Hi R
[2019-08-01 12:20:06] <omiozil> Hi Remy I am new to docker concept. How can I do that. Kindly suggest. Thanks
[2019-08-01 12:21:04] <rcjsuen> What command did you use to run your command?
[2019-08-01 12:21:07] <rcjsuen> Er, run your Docker container
[2019-08-01 12:33:24] <omiozil> docker run  -p 8036:8036 image is
[2019-08-01 12:33:44] <rcjsuen> Can you rundocker exec -it image sh
[2019-08-01 12:33:55] <rcjsuen> Does that let you open a shell inside the running container?
[2019-08-01 12:38:46] <omiozil> Yes I am able to curl from within the image.
[2019-08-01 12:41:08] <omiozil>  [<-CODE->] 
[2019-08-01 12:42:38] <omiozil> rcjsuen: so what next?
[2019-08-01 12:42:44] <rcjsuen> I am out of ideas off-hand then unfortunately
[2019-08-01 12:43:19] <rcjsuen> You see nothing indicated in the logs?
[2019-08-01 12:43:22] <rcjsuen> Not even an attempt to connect?
[2019-08-01 12:43:43] <omiozil> Nope
[2019-08-01 12:45:46] <rcjsuen> Worst case I guess you can try the IP address itself
[2019-08-01 12:46:44] <rcjsuen>  [<-CODE->] 
[2019-08-01 12:46:47] <rcjsuen> Something like that?
[2019-08-01 12:52:42] <omiozil> What does it mean
[2019-08-01 12:52:58] <rcjsuen> Did you get the IP address?
[2019-08-01 12:54:36] <omiozil> Yes
[2019-08-01 12:54:58] <rcjsuen> omiozil: OK, and can youcurl x.x.x.x:8036?
[2019-08-01 12:55:49] <omiozil> I did it says connection refused
[2019-08-01 12:56:06] <rcjsuen> Hm
[2019-08-01 12:56:12] <rcjsuen> I'm out of ideas for you then
[2019-08-01 12:56:19] <rehans516> Hi ! is this room apt for question related to running dockerized application on kubernetes?
[2019-08-01 12:58:01] <omiozil> No problem Remy . thanks for your time. Will keep you posted if I get a solution cheers.
[2019-08-01 12:58:28] <rcjsuen> omiozil: Good luck with your project
[2019-08-01 13:26:56] <gowthamakanthan> Am using docker-compose for an UI app. It’s able to connect from outside without any issue when am having single NIC. Am using bridge network for the same. But when am having 2 nic, The UI is reachable only when firewall is off.
[2019-08-01 13:29:49] <gowthamakanthan> ```cat docker-compose.ymlversion: "2"services:ui:image:  imagecontainer_name: uiports: [<-CODE->] 
[2019-08-01 14:06:00] <omiozil> rcjsuen: I have done changes to my API URL i.e by changing localhost to 0.0.0.0 and it work.
[2019-08-01 14:06:22] <rcjsuen> Hm
[2019-08-01 14:06:27] <rcjsuen> I wonder why the direct IP didn't work though :(
[2019-08-02 03:39:48] <pikeshawn> I am using docker-compose but when I make an ajax request it takes a really long time like 30 seconds for the localhost:9500 to connect to the container and the ajax requests that I make take like 30 seconds to a minute to complete.  why would this take so long to connect?
[2019-08-02 03:54:51] <nnddominic> Can i use virtual box instead Hyper-v for docker window?
[2019-08-02 04:58:42] <nnddominic> Sorry, I already got the answer, thanks all [<-LINK->] 
[2019-08-02 13:45:35] <Gguidini>  [<-CODE->]  [<-CODE->] Does anyone knows why this is happening (and how to fix it)? Thanks!
[2019-08-02 13:58:48] <rcjsuen> Gguidini: How old is yourdocker
[2019-08-02 13:58:50] <rcjsuen> It sounds old
[2019-08-02 13:59:27] <Gguidini> Docker version 17.03.1-ce-rc1, build 3476dbf
[2019-08-02 14:01:18] <rcjsuen> Gguidini: You are using something just a little too old
[2019-08-02 14:01:27] <rcjsuen> multi-stage builds was added in 17.06 I believe...
[2019-08-02 14:02:09] <Gguidini> Hum I see haha thanks. Funny though, I installed it a few weeks ago. So a simple update will do it, nice. Thanks@rcjsuen
[2019-08-03 14:56:19] <IdanAdar> Hi. Is there a Node release that is based on Ubuntu Minimal?
[2019-08-05 14:46:38] <katsar0v> Hello guys, maybe anyone can help me out here. I am running following validation code: [<-CODE->]  [<-CODE->] localhost and staging have both i7 cpus, localhost needs around 40s for the validation, staging needs around 13-14 secondslive (#3) and live (#4) need almost 10 minutes for executing the validation - both of these servers have intel cpus with 48 threads.In order to get more "trustworthy" numbers I dockerized the images and run them on the servers. Anyone has an idea why the speed is so different?
[2019-08-05 16:29:43] <mohammad-khosrojerdi> hi friends. which images of docker is the best image for mail server?
[2019-08-06 10:08:11] <MitaiGit> Hello everyone, as in the Docker to raise a bunch, django rest framework, angular dart, postgresql, sorry if the question is stupid I noob
[2019-08-06 15:46:07] <rcjsuen>  [<-CODE->]  [<-CODE->] Any ideas?
[2019-08-06 20:16:48] <rnburn>  [<-CODE->]  [<-CODE->]  [<-CODE->] (but not sure why since I can run ls from powershell)
[2019-08-06 20:18:45] <rcjsuen> Have you tried other stuff likedirorcd?
[2019-08-06 20:19:25] <rnburn> yes, I get the same issue with dir [<-CODE->] 
[2019-08-06 20:19:54] <rcjsuen> What is the entrypoint of this image?
[2019-08-06 20:24:32] <rnburn> Not sure, but I trying to set up a build container from it like what's described hereI want to run basic commands so I can verify it's working.
[2019-08-06 20:30:23] <rnburn> I guess this worksdocker run mcr.microsoft.com/dotnet/framework/sdk:4.8-windowsservercore-ltsc2019 powershell.exe ls
[2019-08-06 20:30:38] <rcjsuen> OK, that implies the entrypoint is not a shell
[2019-08-06 20:31:14] <rcjsuen> Or rather, hm...
[2019-08-06 20:31:31] <rcjsuen> Well, the entrypoint is something and sending inpowershell.exeas an arg let it do something useful anyway
[2019-08-06 21:59:24] <davidmichaelkarr> I'm experimenting with using encoding/xml to marshal and unmarshal a sample XML file, being a Java logback.xml file. I'm having trouble getting the marshal to omit elements which were empty in the source. I think this is happening because I'm not declaring the elements as slices. I think if I declared it as a slice, it would probably omit them, but that only makes sense for elements where the potential cardinality can be greater than 1.  If the cardinality should either be 0 or 1, that just seems odd.
[2019-08-06 21:59:52] <davidmichaelkarr> Oops, wrong community.
[2019-08-06 22:00:25] <davidmichaelkarr> Too many of these things. :)
[2019-08-07 04:34:14] <zzj0402_gitlab> anyone knows how to print the string "<br/>" in Python?
[2019-08-07 06:40:52] <shubhamsinha47> over cli print(\\n)
[2019-08-07 06:43:19] <shubhamsinha47> or if don’t want line break you want string just use print(“<br />")
[2019-08-07 07:06:42] <nnddominic> Anyone help me? [<-CODE->] 
[2019-08-07 08:10:21] <guddutopper> hi, i have some doubts over mounts or volumes, lets say I have mapped a file on my host to a file in the docker container environment, now when I make changes to the file on my host, it gets updated in the container which is the ideal behaviour, now I want the exact opposite of this, I want the flow of data to happen from container to host, how can i achieve it ?
[2019-08-07 18:20:54] <rnburn> Is there a way to change the storage limit for dockerd on windows? I tried running [<-CODE->] But then I ran into this issue moby/moby#36831 , but all the solutions I'm seeing there say to remove the storage limit -- which doesn't help me since I need the extra disk space
[2019-08-07 19:11:39] <sumanchowdare> Can anyone suggest best way to maintain multiple docker images in single repo ?? eg: maven,python,nodejs etc
[2019-08-07 19:12:57] <sumanchowdare> and maintain all image automation in jenkinsfile jenkins has to build only based on image modified in github not images does anyone have use case similar ??
[2019-08-07 19:13:46] <sumanchowdare> If you find similar let me know best practices and tips and github repo if already available similar
[2019-08-07 19:14:43] <Genysys> nnddominic:  [<-LINK->] 
[2019-08-07 19:57:23] <samholst> Hi guys I have a quick question, If I have container, and I usedocker run ...using the image:tag of that container,  and let's say the image is 200MB, if I usedocker runon the same image copying a tiny file and running it within the image 10 times and look in thedocker ps -adoes that mean that I have 200MB x 10 of disk space being taken up (200MB for eachdocker runexecuted) if I don't usedocker rmon it? Or does it reuse that same 200MB every time and then the only hard disk space that is increasing is how big that file was I copied over and ran inside the container?
[2019-08-08 03:32:53] <prog20901> How to make it as portableI have created a node js web application. Now i want to make it as portable or platform independent i.e need to make it available for windows, linux and macWe need to make it as portable..For example like DocFetcher which runs without any software and just needs JVM. Similarly The user may not know and there should not be a need to install the servers and open the app..Everything should be bundled or portable which should run in any machineMay be executable or portable apps like https://portableapps.com/appsPlease advise which is the best and easiest way to do this.Thanks
[2019-08-08 06:40:22] <gssjericsantos> Hi Guys.  Just Want To Ask Something. I Am Having Trouble In Running Ruby On Docker. It Always Exits The Container.
[2019-08-08 06:40:47] <gssjericsantos> this is my Dockerfile.
[2019-08-08 06:41:00] <gssjericsantos>  [<-CODE->] 
[2019-08-08 06:41:24] <nafg> what doesrails newdo?
[2019-08-08 06:42:00] <nafg> and what do you want the container to do?
[2019-08-08 06:42:23] <gssjericsantos>  [<-CODE->] 
[2019-08-08 06:42:34] <gssjericsantos> this is my docker-compose.yml
[2019-08-08 06:42:56] <nafg> and what output does docker-compose up give?
[2019-08-08 06:42:57] <gssjericsantos> i want to have rails running with postgresql
[2019-08-08 06:43:18] <nafg> you don't needlinks
[2019-08-08 06:43:27] <gssjericsantos>  [<-CODE->] 
[2019-08-08 06:44:11] <nafg> sounds like you need to fix your command
[2019-08-08 06:44:14] <gssjericsantos> sorry wrong yml
[2019-08-08 06:44:21] <gssjericsantos> this is the yml
[2019-08-08 06:44:27] <gssjericsantos>  [<-CODE->] 
[2019-08-08 06:44:56] <nafg> What happens when you run that one?
[2019-08-08 06:45:46] <gssjericsantos> i get that log ang it exits the container for ruby after 10 secs
[2019-08-08 06:46:03] <nafg> samholst: I believe the latter, that's what layers are for
[2019-08-08 06:46:19] <nafg> gssjericsantos: the log says you're usingrails newnotrails server
[2019-08-08 06:50:41] <gssjericsantos> i was able to run it with this same code once. after that when i did a docker-compose down then docker-compose up it doesn't work anymore
[2019-08-08 12:46:24] <soulaimanassikiou> Hello People! This is my 3th try to download and use docker
[2019-08-08 12:46:50] <soulaimanassikiou> How can I use it?
[2019-08-08 12:48:09] <soulaimanassikiou> I am developing 2 laravel projects (one is the API, the other is the front end)
[2019-08-08 12:48:24] <soulaimanassikiou> Which would be the benefits for using docker?
[2019-08-08 12:48:28] <soulaimanassikiou> Thank you :)
[2019-08-08 12:49:58] <rcjsuen> soulaimanassikiou: Docker helps encourage portability of your code and ensures people can run your code without worrying about dependencies.
[2019-08-08 12:50:28] <soulaimanassikiou> for example, the php version?@rcjsuen
[2019-08-08 12:50:39] <rcjsuen> I don't understand your question lol
[2019-08-08 12:50:45] <soulaimanassikiou> hahaha
[2019-08-08 12:51:08] <soulaimanassikiou> mmmh
[2019-08-08 12:51:52] <soulaimanassikiou> it’s just i don’t know so much about it
[2019-08-08 12:52:17] <soulaimanassikiou> and wanted to know if i would have benefits for using it in my specific case
[2019-08-08 12:52:22] <sebastjan-hribar> soulaimanassikiou: yes, like the php version, for example
[2019-08-08 12:52:49] <soulaimanassikiou> Thanks both!
[2019-08-08 12:52:56] <soulaimanassikiou> Just another question
[2019-08-08 12:53:11] <rcjsuen> soulaimanassikiou: It really depends on your project. I personally would suggest learning it as it's taken the software world by storm.
[2019-08-08 12:53:39] <rcjsuen> It means I can run your code without having to worry about any dependency. Of course, you may not be in the business of doing that (depending on your project).
[2019-08-08 12:53:53] <soulaimanassikiou> rcjsuen: Yes, everyone is talking about it, i just didn’t investige much about, but it looks interesting
[2019-08-08 12:54:04] <rcjsuen> However, it still means that you can get it up and running on any arbitrary machine.
[2019-08-08 12:54:14] <rcjsuen> So in the future if you want to run your app on 3 machines, you can do it with ease
[2019-08-08 12:54:28] <rcjsuen> soulaimanassikiou: Without having to install dependencies on all 3 and make super sure they're using the same kernel etc etc
[2019-08-08 12:54:54] <soulaimanassikiou> i see, it looks great
[2019-08-08 12:55:31] <sebastjan-hribar> soulaimanassikiou: I've sent you some references over DM
[2019-08-08 12:55:52] <soulaimanassikiou> how much time do you think I need to set up an environment for (mysql, php, apache) (after instaling docker and before starting to code)
[2019-08-08 12:56:00] <soulaimanassikiou> sebastjan-hribar: Thank you ! ill check it now
[2019-08-08 12:58:23] <rcjsuen> soulaimanassikiou: In these kinds of tri-fecta setups I think people use Docker Compose to hook up the different services together.
[2019-08-08 12:59:15] <soulaimanassikiou> how much time do you think I need to set up an environment for (mysql, php, apache) (after instaling docker and before starting to code)?
[2019-08-08 12:59:31] <soulaimanassikiou> rcjsuen: I’ll investigate more! thank you
[2019-08-08 19:09:15] <urig> Hello. Is there a chat room for docker/compose? I'd like to contribute on an issue and would like to ask for a bit of help.
[2019-08-08 19:10:13] <rcjsuen> urig: I'm not aware of one. Are you discussing the issue with someone on GitHub?
[2019-08-08 19:12:36] <urig> rcjsuen: Err. no. I haven't. But now that I think of it, that sounds like a good idea :D Tx
[2019-08-09 06:57:26] <guddutopper> Hi, I am trying to run my java container as not root user but I am having permission denied issues, my java container has log4j to log any events, I have mounted the location inside the container where logs would be genrated to a location on host but it is giving me permission denied error [<-CODE->] 
[2019-08-09 11:21:46] <matrixbot> @deepit:matrix.orgCan you post the docker command you ran
[2019-08-09 15:24:13] <Genysys> Expose V Ports Docker ComposeI am joining the new project and examing some compose files . I noticed that that are exposing ports and also using the port directive in the compose manifests. e.g. [<-CODE->]  [<-CODE->] 
[2019-08-09 15:53:03] <dragonpiper> in a compose file in the build section. Can the dockerfile and context be in separate directories
[2019-08-09 19:58:46] <milanmaximo> Can anyone help me to understand how to use docker, kubernetes and helm chart to deploy this app to the production.I have to create a dummy docker app (“Hello World!” / Web Server serving some arbitrary file is sufficient) which needs to be deployed to a production environment (min. 3 nodes).Also needs to be able to role out new versions of the application in a zero downtime fasion and there must only be one endpoint to access it. Extra points for deploying your app as a Helm chart.Any solution for it?
[2019-08-12 09:11:37] <darrenstarr> Does anyone have a good solution for managing database versioning via migrations for a Docker project using MySQL? I want to make it so that when a "docker-compose pull" and a "docker-compose up" happens, the database schema should be upgraded to current before any dependent containers run.
[2019-08-12 09:12:37] <darrenstarr> We're using Python and PHP, but so far, the only good solution I've seen is using Entity Framework with Dotnet Core and a health check for the database.
[2019-08-13 06:49:50] <guddutopper> darrenstarr: Gravitee uses Liquibase to manage there schema changes
[2019-08-13 08:06:17] <vishalshivare> I am trying to integrate healthcheck with docker swarm. I have created my own custom health check API to monitor the health of container.I am using following tag for healthcheck in yaml file: [<-CODE->] Here I have tried with different API responses like json object, 200 response, 500 response also tried with 0 and 1 returning value. But in each case docker is not able to understand the response of my health API. The behavior of container totally depends on whatever value I mentioned in test tag's exit code if I set exit 0 container is always healthy or if set exit 1 container is always unhealthy.How the healthcheck will understand my custom API response?Ex: If my custom API returns 500 or 1 then healthcheck should consider this as there is something wrong and need to mark container as unhealthy.Can anyone help me to understand how to use healthcheck with docker-swarm?
[2019-08-13 10:10:37] <kailashyogeshwar85> how can i escape "my@string$$init" i know double notation works for$but what about@in string
[2019-08-13 14:19:46] <dragonpiper> here: anyone aware a of macos bug where the file system inside of a container overtime points to an old version of files ?
[2019-08-13 18:44:27] <Genysys> Is there any advantage to runingdocker-compose  buildoverdocker-compose runif my intention to is run the containers?
[2019-08-14 11:04:42] <pspletinckx> Does anyone have a workable setup for docker in a corporate proxy environment. I've been trying this unsuccessful 3 months ago and now my coworker is having this issue!
[2019-08-15 21:27:09] <zzj0402_gitlab> Hi people, I am working on a machine learning web app platform. Each machine learner server is packaged as Node Express app docker image. Each machine learning task is reporting back console. The issue is that if I run multiple tasks at the same time, each task is reporting back to the same concole and pollutes each other's output. How can I solve this? [<-CODE->] 
[2019-08-15 21:29:04] <zzj0402_gitlab> Which reports: [<-CODE->] The pollution starts with each "learning evaluation instances..." header line
[2019-08-16 13:09:49] <rcjsuen> zzj0402_gitlab: How is this question related to Docker?
[2019-08-16 23:59:49] <zzj0402_gitlab> rcjsuen: Docker Swamp?
[2019-08-17 00:01:04] <zzj0402_gitlab> rcjsuen: And it's configured together with Docker compose. And I need some image isolation.
[2019-08-17 11:34:49] <tenfinney> i am trying to get the URL for the Ethereum client.  Their docs offer this command: [<-CODE->] to be run.  I receive a [<-CODE->] am i missing something simple?  I found this: https://stackoverflow.com/questions/55041231/docker-run-not-working-it-says-requires-at-least-1-argument . but was not able to come up with a solution.the full error [<-CODE->] 
[2019-08-17 11:37:54] <tebeco> anyone usingWSL2/DockerandElasticsearch / Kibana?
[2019-08-17 11:40:23] <tebeco> i got weirdKibanabehavior time to times when i rundocker containers logs -f NAMEon it, nothing seems to log when i try to hit the SPA, and the browser seems to spin forever / neer timeout but nothing ever load
[2019-08-17 11:40:47] <tebeco> i can't teel is the issue is on docker side or kibana since i don't really know where to look at
[2019-08-18 18:36:52] <imajeet>  [<-LINK->] Hi, Please someone help me, docker-compose is running, but I can’t see these ports running in my browser. I am using Mac.
[2019-08-18 18:43:09] <murat-aka> All listening to port 5000?
[2019-08-19 00:55:02] <imajeet> 5000, 5001, 5002, 5003, 5004
[2019-08-19 00:55:20] <imajeet> but can't see the browser
[2019-08-19 06:54:24] <darrenstarr> So, during development I want to mount a directory, but for release, I want to copy that directory into the image. I see there is a RUN if[] condition, is there a COPY if [] condition as well?
[2019-08-19 09:27:55] <murat-aka> imajeet: do you have DOCKERFILE as well check what port is exposed. Just test a single container first. You have 5 listening on 5000 at moment.
[2019-08-19 12:52:56] <rcjsuen> darrenstarr: I feel like aRUN ifis only a by-product of the shell
[2019-08-19 12:53:28] <rcjsuen> If you mount wouldn't you just overwrite stuff anyway, it sounds to me like it is safe to alwaysCOPY
[2019-08-19 14:48:23] <cryocaustik> Hello - wondering if someone could help me figure out what I did wrong here: I am trying to make a volume live on another disk/directory and used the below specification in thedocker-compose.yml, however it does not seem to be using the new drive: [<-CODE->] 
[2019-08-19 14:48:57] <cryocaustik> am I using the right config? is there something I need to add on top of that?
[2019-08-19 14:52:23] <anushamarupudi> HiHow do I convert a lxc container to docker container
[2019-08-19 14:55:42] <anushamarupudi> I have rootfs and config of lxc container  in a tar file
[2019-08-19 16:46:15] <lexnapoles> Hey there, I'm using Ubuntu with a VPN. When I try to run any docker image, the vpn looses connectivity. I've tried host network mode, which doesn't mess with the vpn, but the container doesn't have access somehow to the vpn network. Has anyone had similar experiences?
[2019-08-20 06:22:07] <kailashyogeshwar85> imajeet: Have u defined network_type: host
[2019-08-20 07:10:46] <darrenstarr> rcjsuen: Since the project isn't using any monsterous solutions (like NPM, etc...) I figure it shouldn't be a problem. It's actually what I did. But during development, it's nice to be able to perform rapid iterations where docker-compose build is called often. I'm considering switching to K8S and maybe helm though. But at this point, it will take more time than we're willing to invest.
[2019-08-20 07:43:41] <guddutopper> hi, in the docker run command there is option to drop all linux capabilities using--cap-dropcommandI ransudo docker run <some-image> --cap-drop=allbut it still did not remove the capabilities, any reason why ?
[2019-08-20 14:24:02] <alleryan_gitlab> Hi to all, maybe somebody has a project with webdriverio+selenium in docker-compose, share a link, please.Thank you in advice!
[2019-08-20 19:43:59] <ohwweee> Hi to all.Should I use selenium-standalone service, if I use custom selenium/standalone-chrome in docker-compose, or just use port is enough in docker-compose?
[2019-08-20 20:31:05] <hillct> Good afternoon all. I’m attempting to utilize build-kit to pass keys from local ssh-agent for purposes of authenticating and retrieving from a private git repository. After initial command syntax issues, It now fails silently, seemingly not retrieving the package, but throwing no errors. How can I generate more vorbose output from build-kit?
[2019-08-20 20:32:07] <hillct> To clarify, when I say it fails silently, it builds an image that runs, but absent the key files that were meant to be retrieved from the private git repository
[2019-08-21 00:16:18] <hillct> upon further investigation, the issue seeme to lie within some behavior of the npm package manager, whereby it responds differently within and outside of the docker build enviroment
[2019-08-21 09:23:39] <EDDYMENS>  [<-LINK->] 
[2019-08-21 12:51:24] <hillct> It seems, another issue with build-kit has arisen [<-LINK->] 
[2019-08-21 17:25:40] <jasonbronson> I'm having an issue where dockerfile is saying on a build it's copying the file into the container but then when i run container it's gone. Right above it is a copy of a simple text file and that one works. Any ideas on why this is happening? [<-LINK->] 
[2019-08-21 17:26:26] <minhman0809> hi@all, in ubuntu 18.04, how can i find default path where stores backup  sql postgres file by pgadmin  image docker?
[2019-08-21 17:27:37] <maxpearl> I don't know offhand, but if you're running an ubuntu 18.04 docker image, it should be whatever the default is for PGAdmin.
[2019-08-21 17:27:53] <maxpearl> As long as you're installing PGAdmin in a standard way.
[2019-08-21 17:30:50] <rcjsuen> jasonbronson: yourphp.inifile is missing?
[2019-08-21 17:49:56] <jasonbronson> rcjsuen: it's in the directory and that one works fine the bottom one which is mhsendmail_linux_amd64 does not copy
[2019-08-21 18:50:12] <hillct> Good afternoon all. How do I et docker build-kit to expire/flush all cache and perform subsequent builds in their entirety without any cached content?
[2019-08-21 18:51:05] <rcjsuen> jasonbronson: It "does not copy" but thechmodworks in theRUNinstruction?
[2019-08-22 04:13:51] <zzj0402_gitlab> What's the official docker in docker image with docker-compose installed?
[2019-08-22 08:55:45] <IdanAdar> Is it possible to still find node-slim image that provides Node 8.16.0 instead of 8.16.1? Can't find it here: [<-LINK->] 
[2019-08-22 08:58:23] <babaorum> It still exists even if it does not appear in the documentation. Trydocker pull node:8.16.0-slim
[2019-08-22 08:59:58] <IdanAdar> Thank you Romain.
[2019-08-22 15:44:59] <chinna88> hi there
[2019-08-22 15:45:28] <chinna88> getting below error when pulling imagesError response from daemon: Get [<-LINK->] : net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
[2019-08-23 05:48:12] <cpu100> hello wsl2 + docker
[2019-08-23 09:44:47] <gssjericsantos> Hi Guys. Has  Anyone Tried To Convert An PHP 5.2 App Running In Vagrant and virtualbox to docker?
[2019-08-23 12:30:06] <cpu100> why 5.2
[2019-08-23 14:00:08] <dvdieu> Hi
[2019-08-23 16:29:23] <juliuszfedyk> Hi Guys, im trying to run :docker-compose  -f docker-compose-dev.yml run dev bashit seems though that the run command still runs of the default docker-compose file. is there an issue with using--filewithdocker-compose run?
[2019-08-23 19:16:19] <murat-aka> chinna88: check /etc/resolve.conf actually google for DNS 127.0.0.1 bug in Ubuntu. Some Version of Ubuntu is not pointing to /etc/resolve.conf it instead points to a different file. You need to fix that
[2019-08-24 18:17:58] <alleryan_gitlab> Hi friends, I need your help. I have tests in docker-compose with my app and load-balancer, and my tests are starting before load-balancer is finished to load. I need a way, how to check that the load-balancer is loaded before my tests will start. Is it possible to check it in docker-compose?
[2019-08-25 04:21:01] <mhlic_gitlab> alleryan_gitlab: have you tried usingdepends_on?
[2019-08-25 17:49:26] <alleryan_gitlab> mhlic_gitlab: hi, sure I usingdepends_on, but it is cannot give a guarantee that load-balancer is fully started. It is just checked that container is up
[2019-08-26 11:13:34] <guddutopper> Hi, is it possible to add files to a docker volume which is not attached to any container ?
[2019-08-26 15:31:21] <vroussea> hello, do you guys know about a tutorial about how to integrate diesel (rust lib) into docker ?
[2019-08-27 02:14:20] <Bitllion> hello
[2019-08-28 07:14:09] <BarathKumarDharani> Hi
[2019-08-28 07:15:30] <BarathKumarDharani> while  building bigchaindb i m getting below error could you please help on this
[2019-08-28 07:15:38] <BarathKumarDharani>  [<-LINK->] 
[2019-08-28 07:16:46] <BarathKumarDharani> i am following  the steps mentioned  in  below  link [<-LINK->] 
[2019-08-28 15:41:55] <twaterhouse> hey all, this may not be the right place for this but I'm looking for some advice.  Please point me to a better room if you think this belongs somewhere else.I've been tasked with taking a rather complicated application suite to the cloud (aws) and I'm looking at the current architecture (wannabe microservices).  I'm a fan of immutable infrastructure and I've built other frameworks based on packer/ansible/terraform/ec2.  I'm looking to use docker with the suite because of all the possible build permutations.  Currently the suite has about 20+ backend apis, 8+ frontend apps, elasticache, rabbitmq, sql, and some file storage space (shared).   I'd like to have git commits trigger docker builds per api & use ecr/ecs to deploy the apis / front end apps.  I intended to have every commit in every branch produce a build but after looking at just one api, there are like 20 to 30 branches in the repository and I'm not sure how to manage that scale and still achive CI.  I'd take any thoughts, input, ideas etc anyone has.
[2019-08-28 15:44:29] <matrixbot> @deepit:matrix.orgGit modules perhaps?
[2019-08-28 15:47:26] <rcjsuen> twaterhouse: But technically onlymasterorreleaseor whatever should push to production, right? Unless you are also trying to setup staging and so on?
[2019-08-28 15:47:40] <rcjsuen> Point being if I'm working on a feature branch do you want them deployed somewhere also for testing purposes?
[2019-08-28 15:48:16] <twaterhouse> yeah, it's weird.  currently they will go manually minipulate a teamcity build to build a specific branch
[2019-08-28 15:48:23] <twaterhouse> and then deploy that somewhere
[2019-08-28 15:48:38] <twaterhouse> & test, and it looks like a lot of the branches are release names
[2019-08-28 15:48:49] <twaterhouse> so, perhaps they aren't really using giflow correctly
[2019-08-28 15:49:00] <twaterhouse> but either way, I need to accomidate the madness ;)
[2019-08-28 15:49:31] <twaterhouse> in my other frameworks, I'd build everything always, and you could get any build anytime
[2019-08-28 15:49:41] <twaterhouse> then I had cleanup scripts to delete junk we didn't use
[2019-08-28 15:49:54] <twaterhouse> but that just seems like I'd end up with LOTS of junk
[2019-08-28 15:50:16] <twaterhouse> not to mention really busy build servers, although, I guess not all of these branches are going to be changing all the time
[2019-08-28 15:50:25] <twaterhouse> they may just be sitting there stale
[2019-08-28 15:50:44] <twaterhouse> I'm curious how others solve problems like these
[2019-08-28 15:51:07] <matrixbot> @deepit:matrix.orgWhat CI tools?
[2019-08-28 15:51:42] <matrixbot> @deepit:matrix.orgOh just Teamcity manual builds? Eek
[2019-08-28 15:55:29] <twaterhouse> sorry folks, I have a noon meeting, I'll be back to chat more
[2019-08-28 17:23:55] <twaterhouse> hey all, I'm back
[2019-08-28 17:24:15] <twaterhouse> matrixbot: - they are using teamcity now
[2019-08-28 17:24:27] <twaterhouse> I want to move them to jenkins
[2019-08-28 17:25:13] <twaterhouse> so currently I'm thinking jenkins building java code triggering docker builds (dockerfiles) and pushing those to ecr
[2019-08-28 17:26:07] <twaterhouse> terraform to standup the infrastructure and I'm not sure if I'll use terraform or aws cli to roll the docker builds in ecs
[2019-08-28 21:42:31] <twaterhouse> bump!
[2019-08-29 09:47:35] <gssjericsantos> Hello Guys. im having problems with my db on docker-compose.yml it keeps on restarting after 1sec of being up [<-CODE->] 
[2019-08-29 12:43:33] <twaterhouse> doesn't look like an issue with the compose file, does the container run if you run it with a docker run command?
[2019-08-29 14:09:10] <cart_man_gitlab> Hi everyone. I am looking for a way to list my docker containers by index if it is possible. Similar to "docker ps -a" but one by one
[2019-08-29 14:09:16] <cart_man_gitlab> Is there a way I can do it with Filters perhaps?
[2019-08-30 03:38:16] <gssjericsantos> twaterhouse: Yes It Only Restarts.
[2019-08-30 05:14:28] <swapnil-pandey> is there any way to automatically restart a container if it crashes after say 3-4 minutes and not immediately?
[2019-08-30 06:27:23] <ishtiyaq.husain_gitlab> gssjericsantos: I had a similar issue, in my case, it was a spelling mistake in "settings.ini" inside my python-Django project.
[2019-08-30 06:38:37] <Ankit3794> Hi Guys,Is there any way to copy files from Docker Volume. I want to specify COPY command in my docker file.DockerfileFROM baseimage:v1COPY C:\\ProgramData\\docker\\volumes\\vol1 C:\\TestDirVolumeVolume is created bydocker volume create --name vol1command. My dockerfile would be in different directory. So, I can not give build context of C:\\ProgramData\\docker\\volumes\\ folder.So, Is there any workaround here?
[2019-08-30 11:15:11] <mudit-naithani> Hello everyone, I have recently done some courses on docker and kubernetes. Now I want to work on some real use cases which are being used in Production environments.Could anyone here please tell any POC which I can pick up as a beginner to get a hands-on on both of them.
[2019-08-30 17:27:29] <OnyxTooN_twitter> hi whatsup guys
[2019-08-30 17:27:43] <OnyxTooN_twitter> my name is mazen and  iam delevoper ^_^
[2019-08-30 17:28:10] <OnyxTooN_twitter> any one need help just call 911
[2019-08-30 17:28:12] <OnyxTooN_twitter> hahahaha
[2019-08-30 17:28:17] <OnyxTooN_twitter> iam jucking
[2019-08-30 17:29:10] <OnyxTooN_twitter> this is my whatsapp number if any one need help for developer somthing he need i will help ^_^ number:(+966558871442) thx every body
[2019-08-30 20:25:47] <CassianoSF> Hey there! I'm facing this problem: [<-LINK->] Help please
[2019-09-01 06:57:59] <christhomas> So I\'m having a go at making a satis compatible package manager. It\'s called "Repo Rangler" and its supposed to be a dockerised, modular, service orientated software that will support db/ldap login and store package data in a database instead of the filesystem.You can take a look here and tell me what you think that\'d be great! [<-LINK->] and [<-LINK->] 
[2019-09-03 12:06:13] <haroonhanif> Hi,I'm trying to containerize IIS running on Windows 2008R2 running on vSphere 6.7. My steps are as follows: [<-CODE->] 
[2019-09-03 14:36:38] <matrixbot> @deepit:matrix.orgIt's barking about the : on your mount parameter
[2019-09-03 14:38:19] <matrixbot> @deepit:matrix.orgTry adding-MountPath 'C:\\Image'
[2019-09-03 16:32:57] <haroonhanif> matrixbot: Thanks for that, it worked without any issue
[2019-09-04 14:50:53] <vivek2007> Docker Expert here, looking for remote work
[2019-09-05 08:32:32] <Darshannraval> Hi All, I am trying to containerize gRPC. Can anyone guided me?
[2019-09-05 14:34:05] <andaniel2029> hello, everybody!
[2019-09-05 14:34:10] <andaniel2029> i am first here.
[2019-09-05 14:34:58] <andaniel2029> I gonna run rasa/rasa _nlu server with doc at windows 10.
[2019-09-05 14:35:11] <andaniel2029> but i got error message such like that.
[2019-09-05 14:35:25] <andaniel2029> C:\\WINDOWS\\system32>docker run -p 5000:5000 rasa/rasa_nlu startTraceback (most recent call last):File "/usr/local/lib/python3.6/runpy.py", line 193, in _run_module_as_main"main", mod_spec)File "/usr/local/lib/python3.6/runpy.py", line 85, in _run_codeexec(code, run_globals)File "/app/rasa/core/run.py", line 204, in <module>"Callingrasa.core.rundirectly is "RuntimeError: Callingrasa.core.rundirectly is no longer supported. Please userasa shellinstead.
[2019-09-05 14:35:31] <andaniel2029> help me!!!
[2019-09-06 10:11:28] <alijamshidi96>  [<-LINK->] 
[2019-09-06 10:12:06] <alijamshidi96> hi all! i have a problem when start docker quick start terminal anyone can help me?
[2019-09-06 10:13:12] <swapnil-pandey> disable the hyper v hypervisor
[2019-09-06 10:18:32] <alijamshidi96> when  i disabled hyper-v  i receive above error and when i enable hyper-v then run docker quick terminal i receive this error
[2019-09-06 10:18:53] <alijamshidi96>  [<-LINK->] 
[2019-09-06 10:19:35] <alijamshidi96> I'm really confused
[2019-09-06 10:19:49] <swapnil-pandey> both the errors show that you have enabled hyper v. maybe you did not correctly disable hyper-v? restart your system after disabling it?
[2019-09-06 10:22:18] <alijamshidi96> yes i disable hyper-v in mTurns windows features on or off and the restart system !
[2019-09-06 10:23:51] <alijamshidi96> I have to disable , virtualization in bios?
[2019-09-06 10:29:06] <swapnil-pandey> which version of windows are you using?
[2019-09-06 10:30:28] <alijamshidi96>  [<-LINK->] 
[2019-09-06 13:45:03] <mcarpenterjr> Nginx Proxy Containers, anyone have a favorite? Looking to spin one up to SSL proxy a couple containers, and stream line availability during up and down time.
[2019-09-06 15:54:25] <jdickey> What's the simplest/best startup/hobbyist-level way to make a Ruby app's logging readable from outside the container it's running in? What do people use?
[2019-09-06 17:12:42] <mcarpenterjr> jdickey: I would use a volume. this way you can read the data on the host, with out having to jump through hoops
[2019-09-06 17:13:05] <mcarpenterjr>  [<-LINK->] 
[2019-09-06 17:25:33] <jdickey> Right; I'm using a volume for the app's database, but the log stupidly never occurred to me. Thanks :)
[2019-09-06 17:43:56] <mcarpenterjr> Ha ha, no worries. 
[2019-09-06 18:25:02] <mateothegreat> how do you streamline availability during downtime lol
[2019-09-06 18:25:20] <mateothegreat> mcarpenterjr: I do my ssl termination outside of docker always
[2019-09-06 18:26:20] <mcarpenterjr> Probably just should have said loadbalancing lol
[2019-09-06 19:16:21] <mateothegreat> HAproxy is the shiznit
[2019-09-06 19:48:01] <mcarpenterjr> Ease of configuration on a scale of  1 to 10?
[2019-09-06 23:30:15] <mateothegreat> 6-7
[2019-09-07 03:45:12] <matrixbot> @deepit:matrix.org [<-LINK->] 
[2019-09-07 05:46:03] <kailashyogeshwar85> Is there any alternative for Amazon EFS which is open source and not any cloud provider dependent project ?
[2019-09-07 07:51:38] <matrixbot>  [<-CODE->] GlusterFS or Ceph
[2019-09-09 02:48:08] <EDDYMENS>  [<-LINK->] 
[2019-09-10 09:36:14] <ghost~5b7e36e3d73408ce4fa5848d> hello everyone , I am trying out the experimental feature of docker 18.09 ( -- secret flag) I am trying to use github token for the same , has anyone faced it before
[2019-09-10 09:36:57] <ghost~5b7e36e3d73408ce4fa5848d> I am unable to work with tokens , it usually tends to not pick it
[2019-09-10 18:30:43] <mcarpenterjr> mateothegreat: You were/are right Haproxy is the shiznit!
[2019-09-10 19:00:44] <mateothegreat> :D
[2019-09-11 02:03:20] <1yzo> Hey, I'm trying to add an nginx container to my docker-compose to enable https. Does anyone know if I need to have a registered domain name or can I just use the IP of my digitalocean droplet.
[2019-09-11 05:09:42] <matrixbot> mondei1I think you need a domain if you want to have valid certificate (let's encrypt or something else). But if you only need a self signed certificate a ip is enough.
[2019-09-11 16:30:57] <marcguilera> hi. i am trying to set up consul with my services. when runningdocker run -d -e CONSUL_BIND_INTERFACE=eth0 -p 8500:8500 -p 8600:8600 consuland executing my services manually (gradle run) they get registered and everything works
[2019-09-11 16:31:36] <marcguilera> but i am trying to set up a docker compose to stand up my two services + consul... when services try to connect they fail
[2019-09-11 16:32:28] <marcguilera>  [<-CODE->] 
[2019-09-11 16:32:43] <marcguilera> why would consul not be visible by the services?
[2019-09-12 15:20:19] <dA505819> Did anyone build docker on github?
[2019-09-12 15:20:52] <rcjsuen> dA505819: Can you rephrase your question?
[2019-09-12 15:21:24] <dA505819> Did anyone build github action using docker on github?
[2019-09-12 15:21:38] <dA505819> I think that's straightforward now.
[2019-09-12 17:06:09] <mcarpenterjr> dA505819: Do you mean use github's CI to build a docker image? or Deploy a container?
[2019-09-12 18:28:24] <dA505819> Ya, we can use it too to build a action to automate the workflows. I am simply saying deploying a docker container in a repository to automate workflows.
[2019-09-12 21:02:04] <alex88> Hello everyone, I'm running kubernetes and gitlab CI runner, basically it runs docker containers with docker-in-docker enabled so the build container is privileged and it hasDOCKER_HOST: tcp://localhost:2375as env variable
[2019-09-12 21:03:02] <alex88> I've a problem, the container I use for the build is successfully able to do http/s requests, when I build a docker container instead it's not, most of the time it just timeouts and just sometimes work
[2019-09-12 21:03:09] <alex88>  [<-LINK->] this is an example output
[2019-09-12 21:03:33] <alex88> so from the main privileged container it doesn't miss a request, in the child one when building an image it almost never work
[2019-09-12 21:03:47] <alex88> I've seen [<-LINK->] which is similar but restarting isn't enough
[2019-09-13 07:01:03] <CThuleHansen> Can someone explain to me why curl -sL [<-LINK->] | bash is necessary for nodejs?
[2019-09-14 05:06:52] <CodingCreate101> Hey people, I am  a noob in Docker, trying to set up dev environment with Docker. I am stuck on something.I'd also like to use pre-commit hook during development and that should trigger tests but I don't know how to handle that in Docker context.
[2019-09-15 18:01:10] <Sanji515> Hey guys, actually I'm trying to setup 2 separate containers for my 2 sub angular application but at a time it is running a single container only. [<-CODE->] 
[2019-09-15 18:02:40] <Sanji515>  [<-CODE->] 
[2019-09-15 18:03:33] <Sanji515> Here (^) is my both container docker-compose file
[2019-09-16 08:23:01] <dangen-effy>  [<-CODE->] Could someone tell me solution please?
[2019-09-16 09:38:18] <CodingCreate101> dangen-effy: Share yourDockerfilefiles
[2019-09-16 09:40:30] <CodingCreate101> Sanji515: What error do you see on browser for 2nd container?
[2019-09-17 07:55:08] <pspletinckx> (I can do this with ssh) but is there a reverse to docker --publish port:port ?
[2019-09-17 08:00:23] <ghost~5b7e36e3d73408ce4fa5848d> Hi everyone , [<-LINK->] regaring this , I am trying to build dockerfile inside kubernetes agent on jenkins : I get the following errorErr:3 http://deb.debian.org/debian stretch-updates InRelease\n  Unable to connect to proxy-chain.xxx.com:911:,  Can anyone help me with this issue please
[2019-09-17 12:25:20] <rg-repo> Hi All , added few docker compose stacks on github. If that help’s to anyone and also please contribute to it if anyone has anything. [<-LINK->] 
[2019-09-18 11:42:19] <entvex> Hello everyone :D
[2019-09-18 15:56:51] <helios> Hello. I am using Ubuntu 18.04.3 LTS and docker-compose 1.22.0. I can rundocker-composew/o problem in my home directory. But I can not rundocker-composein any directory outside the$HOME, I am gettingCan't find a suitable configuration ...but thedocker-compose.ymlis there and own by the user. Runningdocker-compose -f $PWD/docker-compose.ymlI getERROR: .IOError: [Errno 2] No such file or directory: '/srv/www/docker/docker-compose.ymlI am struggling understand why.
[2019-09-18 17:55:11] <prog20901> How to convert a java standlone app to web application or access via internet?I come across several beautiful java standalone application..example DocFetcher...However there is no web interface available.Is there a way to make it as web application using any tool or third party plugin or server?Is there a way to launch in the server and access as jnlp from anywhere?What would be the best and easiest way to convert a standalone jar or desktop java application to web server...Not going to be a request and response..Instead wanted to do the same thing which we can do in the standlone......Please kindly advise....
[2019-09-18 17:55:21] <prog20901> i f nothing is possible, is it possible via docker
[2019-09-18 17:55:42] <prog20901> looking for a solution via docker if possible
[2019-09-18 17:58:50] <mateothegreat> you would need tobuildthe user interface yourself
[2019-09-18 18:02:01] <prog20901> is it possible to convert the java app to electron app
[2019-09-18 18:02:14] <rcjsuen> prog20901: That's pretty wild
[2019-09-18 18:02:36] <mateothegreat> probably not
[2019-09-18 18:02:46] <mateothegreat> why not just write your own lol
[2019-09-18 18:02:53] <rcjsuen> I think you'll have an easier time hiring React/Angular developers
[2019-09-18 18:03:05] <rcjsuen> then finding a Java developer that's also a god in React (or vice versa)
[2019-09-18 18:03:18] <mateothegreat> I do java + angular all day everyday for a living :D
[2019-09-18 18:03:31] <mateothegreat> I got an angular t-shirt in teh mail today speaking of the devil
[2019-09-18 18:03:32] <rcjsuen> prog20901: Hire this god, I am but a mere mortal
[2019-09-18 18:03:41] <prog20901> if somebody invents a way to make a standalone java app to web...it would be a great product.....
[2019-09-18 18:03:50] <mateothegreat> for searching documents?
[2019-09-18 18:07:32] <rcjsuen> prog20901: It is non-trivial to make a JavaScript VM run Java
[2019-09-18 18:08:19] <rcjsuen> Though people have done the reverse [<-LINK->] 
[2019-09-18 18:20:12] <prog20901> rcjsuen: oh..why the people doesn't think the vice versa
[2019-09-18 18:20:46] <rcjsuen> prog20901: Probably because a) no one approached them with gobs of money or b) they did not see the business case worth the return on investment
[2019-09-18 18:22:55] <prog20901> you are right
[2019-09-18 18:29:15] <jdickey> If you're talking about Oracle, bet on both; they've done some outrageously stupid things when people were willing to throw enough money at them, especially back in the days before Larry made his third or fourth billion :P
[2019-09-19 09:43:18] <mengfanyin> I have a question.  When ping host ip form  docker containner,  It has no response .  I have logged  the  icmp pack using iptable, but the icmp pack log were only showed in prerouting chanin, not showed in input chain as expected. What is the reason?  Who can help me, thans very  much!
[2019-09-19 09:46:10] <mengfanyin> When ping docker0 ip,  it is ok.
[2019-09-19 09:46:47] <mengfanyin> Ping public ip is too.
[2019-09-19 11:28:57] <combiz_k_twitter> I\'m building a docker image from a dockerfile which installs ~450 R packages with a single command.  I\'ve found this can be problematic if one of the final packages to be installed fails, the entire layer needs to be rebuilt from scratch.  So I\'ve now created a dockerfile which issues a single RUN command for each R package to be installed (e.g. RUN Rscript -e \'install.packages("data.table", dependencies = TRUE, repos = " [<-LINK->] ")\')  Are there any gotchas with this approach?  Ofc the number of layers has increased from ~40 to ~481.  Any issues with this?
[2019-09-19 11:36:59] <combiz_k_twitter> apologies just realised my question is probably a better fit for the freenode channel
[2019-09-19 13:33:13] <combiz_k_twitter> there's a limit of 128 layers.  A suggestion: produce the 'max depth exceeded' error at the beginning instead of at Step 128/481
[2019-09-19 14:26:35] <mcarpenterjr> combiz_k_twitter: I think image size can become a problem with that approach also.
[2019-09-20 07:13:31] <SothyLorn_gitlab> hi everyone I have manager on Ubuntu Server and worker on MacOS do you ever do like this?
[2019-09-20 19:32:31] <avinashdesireddy> SothyLorn_gitlab: I have seen many implementations with mixed node types, but MacOS is not one of them. I don't see any problem why it will not work.
[2019-09-20 23:07:28] <n1ckdm> Anyone have experience setting up a persistent volume for a postgresql database when using a managed storage disk on an azure virtual machine..?My current plan is to alter the docker working directory (using the -g option) so the volumes/images/etc all live on my the mounted disk
[2019-09-22 08:07:56] <SothyLorn_gitlab> avinashdesireddy: now i'm trying to setup like this but it's still not work. Thank for your reply.
[2019-09-24 03:32:37] <SothyLorn_gitlab> anyone know how to allow access port 2377 on mac mini when use it as Worker and ubuntu server as Manager (Docker Swarm)?
[2019-09-24 08:27:39] <vogelfreiheit> hi, what would be the best way to assign an ip from dhcp off an existent (vlan backed) linux bridge in a linux host?
[2019-09-24 14:22:08] <etherealjoy> anyone had an issue with docker exec not using the container namespace?
[2019-09-24 14:22:35] <etherealjoy> Also docker exec returns a shell even when the container does not have a shell
[2019-09-24 16:04:19] <sandrojenny> Hello, I'm new at Docker. First I taught myself bash basics, installed Ubuntu and played around.
[2019-09-24 16:04:45] <sandrojenny> I have installed Docker. I played through the test example. Cloned an existing repo, created a sample image and executed container and pushed it back to Docker Hub. That worked fine.
[2019-09-24 16:04:58] <sandrojenny> Now I have problems creating my own repos.
[2019-09-24 16:05:17] <sandrojenny> I get this error:
[2019-09-24 16:05:29] <sandrojenny> Sandros-iMac:~ sandrojenny$ docker build -t sandrojenny/my-second-repo .error checking context: 'no permission to read from '/Users/sandrojenny/.bitnami/stackman/machines/xampp/volumes/root/licenses/gd.txt''.
[2019-09-24 16:33:02] <sandrojenny> I figured it out for myself. Was a conflict with Xampp
[2019-09-24 21:06:38] <eserkandogan_twitter> Question regards to docker in Jenkins: I would like to start a process in background in a docker image in jenkins pipeline. It seems jenkins automatically stops and removes docker image once the pipeline is done. Is there a way to keep it running?
[2019-09-24 21:27:18] <rgb4268> Hi
[2019-09-25 20:38:25] <damienwebdev> Is anyone on thedocker for macteam in here? I have a sec vulnerability that I need to disclose....
[2019-09-26 10:31:45] <humzams_twitter> Hey everyone,I am new to Docker and I am having some problems with it that I have not been able to solve. I have a Docker entry point script that has this command at the end: [<-CODE->] When the script runs I get the following error: [<-CODE->] I'd be very grateful if someone could guide me to the right solution as I have been trying to solve this for a while without any success.
[2019-09-26 10:38:08] <MarkoShiva> Are you using modified conf it looks like your conf have a characters that shouldn't be in there. Usually conf files do not have ampersands and new lines written as chars. Try with nodaemon = true in that file. Obviously the error is in reading the conf file and starting.
[2019-09-26 11:38:56] <humzams_twitter> in1t3r: Hey thanks a lot!  :) I managed to solve it. This is an open-source project that I was trying to run. I modified the Dockerfile chaining all the RUN commands but I didn't do it properly.
[2019-09-26 13:01:37] <carrowheap> Hi everyone, I've build and run container for vue.js apps, when I try docker inspect container_id IP_ADDRESS is empty and I dont' know to access my container from the browser.
[2019-09-26 13:02:07] <carrowheap> how can I solve this  please?
[2019-09-26 13:02:33] <carrowheap> sorry for bad english
[2019-09-26 15:18:40] <MarkoShiva> what are you tryin to achieve? To enter the container or to inspect the logs of container?
[2019-09-26 15:19:28] <dragonpiper> Hello anyone familiar with docker-gen
[2019-09-26 15:20:27] <MarkoShiva> if you want to enter the container just use docker exec -it nameOfContainer /bin/bash to get the bash shell inside of the container.
[2019-09-26 15:21:12] <MarkoShiva> instead of the name of container you can use container id.
[2019-09-29 07:44:30] <IdanAdar> I've received a notification that my node:8.16.0-slim image is vulnerable to CVE-2019-5094. How can I check if a fix was provided to it in Ubuntu so I can rebuild to receive it?
[2019-09-30 04:26:47] <ktbug4211_twitter> does anyone know about Invision studio for making apps and prototyping
[2019-09-30 04:27:08] <ktbug4211_twitter> and im looking for new friends
[2019-10-01 15:52:09] <mcarpenterjr> Anyone ever swap a running container over to a commit? I have to update my current backup plan for compliance. Current backup plan takes a commit, dumps a database and tars everything together and ships it off. This leaves the backu in an untested state. What I would like to do is create the commit, and then run from the commit, like spin up a container based on the commit and transfer over to it.
[2019-10-01 15:52:20] <mcarpenterjr> anyone ever do anything like this before?
[2019-10-03 15:39:04] <pjetr> So hi guys, I've set up a local development environment using docker-compose, and I've got  all applications in their own containers, for instance, I've got multiple NGINX containers and a Proxy container in front of those in spirit of true containerization. But does this make sense for a development environment? Or would it be more lightweight to only have a single NGINX container, a single mariadb, a single redis, ...
[2019-10-03 15:40:29] <pjetr> And offcourse I think of asking this question at the end of my workday...
[2019-10-03 15:41:02] <pjetr> I'll read and reply tomorrow...
[2019-10-03 15:53:33] <MarkoShiva> It depends  you wnat to scale things.Does the single node scenario works for you?
[2019-10-03 15:55:18] <MarkoShiva> Do you use a docker swarm or no? Do you need to run multiple applications or instances in development. What is your use case and type of application?
[2019-10-03 20:11:49] <kirans9731> Hi all, I have 2 apps running within docker container on 2 different nodes. Both of these register themselves with consul with the hostname / ip and port they are running on for service discovery. One of the apps has to make a http request to other using url obtained from consul. How do I go about making this work since the IP is not accessible within container. I am fairly new to docker and been reading docs. Any help will be much appreciated. Thanks
[2019-10-04 06:03:27] <rg-repo> kirans9731: Are both the containers running in same network means have you declared any network type ?
[2019-10-04 06:04:30] <rg-repo> and if discovery is used so it is in microservice architecture
[2019-10-04 06:04:46] <rg-repo> ?
[2019-10-04 07:19:47] <pjetr> in1t3r: We don't use swarm, hell, we don't use docker for production either. It's purely localhost development. So it doesn't need to scale, since there's usually not more than 1 client active at a time in every application. We have  an ecosystem of 3 angular apps running on an NGINX container, 2 nodeJS backends with Redis and Mongo/mariadb and 1 php application with redis, mariadb and elastic.
[2019-10-04 07:21:15] <pjetr> So I was thinking of using a container for every node application, and then 1 nginx, 1 php, 1 mariadb, 1 elastic and 1 mongo container shared across the applications
[2019-10-04 07:22:02] <pjetr> which isn't the docker way, but it seems to me to be a more resource-friendly solution than what I have now
[2019-10-04 07:22:59] <pjetr> But I wanted to check base with someone with actual experience before I did the work
[2019-10-04 08:37:26] <MarkoShiva> Well you can use that setup for development although you should know that there will be a difference in writing docker-compose for development and production.
[2019-10-04 08:37:49] <MarkoShiva> Also you don't have a failover if you use onlyone instance for each.
[2019-10-04 08:47:57] <MarkoShiva> pjetr: ^
[2019-10-04 09:04:08] <pjetr> yeah, I know, but to be fair, our dev doesn't have failover at the moment@in1t3r, since every dev has his own local stack
[2019-10-04 09:04:25] <pjetr> it's only multi-user when you test something multi-user
[2019-10-04 09:04:38] <pjetr> ie chat capabilities or something like that
[2019-10-04 09:05:09] <pjetr> And since we're not running docker on production (yet)
[2019-10-04 09:05:20] <pjetr> they are completely separate
[2019-10-04 09:14:37] <pjetr> Thanks for your input
[2019-10-04 14:23:32] <kirans9731> rg-repo: correct it's a microservice architecture. No I have not created any user defined network. I tried usingbridgenetwork_mode which seem to work if the docker containers are running on the same host.
[2019-10-04 19:49:02] <MarkoShiva> np in that case I think its totally fine to run single containers and single services.
[2019-10-05 07:57:48] <Naranmandakh> hello everyoneHow does works docker image naming ? my docker image names has 'docker.io' prefix on centos
[2019-10-05 09:27:03] <MarkoShiva> docker --tag reponame/image:tag
[2019-10-05 09:27:36] <MarkoShiva> reponame is actually username you use on dockerhub
[2019-10-07 15:40:40] <Biciato> hello everyone
[2019-10-07 15:41:12] <Biciato> how can i make mysql work on docker. I just can't pass --initialize issue
[2019-10-08 03:26:58] <vivek2007> Iam remote developer available for docker
[2019-10-08 17:50:42] <aljones15_gitlab> hey folks
[2019-10-08 17:50:47] <aljones15_gitlab> I have a small problem
[2019-10-08 17:50:53] <aljones15_gitlab> I have an image built with packer
[2019-10-08 17:51:17] <aljones15_gitlab> I then have an internal process that runs that needs to use post to the published port
[2019-10-08 17:51:25] <aljones15_gitlab> post
[2019-10-08 17:52:13] <aljones15_gitlab> so how can I setup an internal port forwarding or proxy so that my seeder can seed inside the docker container with out messing up my settings that are configured for the published port.
[2019-10-08 17:52:43] <aljones15_gitlab> I've been trying iptables, but no lock so far
[2019-10-08 17:52:56] <aljones15_gitlab> image is ubunut and the app is written in node
[2019-10-08 20:05:07] <MarkoShiva> You didn't really post any of the configuration files so I can only assume from the writting that you have problems with port forwarding in docker.
[2019-10-08 20:06:51] <MarkoShiva> Docker port forwarding is not same as iptables you need to expose ports in docker so that your application is able to communicate with the rest of networking interfaces in cae of iptables on linux docker is making for itself a different ipchain then a default ipchain so basically you should use the -p command to forward ports. If you give some more complete command line or configuration I might be able to help you with specifics.
[2019-10-09 11:43:27] <pjetr> Question, is it possible to have different commands running in your container based on an argument?
[2019-10-09 11:43:48] <pjetr> Still purely development environment
[2019-10-09 11:44:42] <pjetr> I want my nodejs servers to start, unless an exclude option is given, then I simply want them totail -f /dev/null
[2019-10-09 11:45:00] <pjetr> This gives me the option to run my servers with different commands
[2019-10-09 11:46:00] <pjetr> Is such a thing possible? Because I find no mention on this anywhere, or I have no idea how to query google with this.
[2019-10-09 17:16:16] <aljones15_gitlab> pjetr: is possible not sure how.
[2019-10-10 05:50:58] <gssjericsantos> Hello Guys I Just Want To Ask Something. [<-CODE->] I Am Getting This Error In The Application I Am Trying To Run. Is This A PHP Code Error Or A Docker Error?
[2019-10-11 07:14:04] <tripathideepesh> Hi Guys, i have a set of web containers running on a docker host, i need to expose all these web containers using nginx to outerworld , is there any guideline how i one do this ?
[2019-10-11 07:58:04] <dangen-effy> Hello Guys. I wonder when to inject environment variables. Is it build time or run time?For example, [<-CODE->]  [<-CODE->] Is there any best practices?
[2019-10-11 07:59:05] <TwanoO67> it depends what you want to do with those env var
[2019-10-11 07:59:08] <dangen-effy> In my opinion, most build images, which are injected at the time of build, should always be in a static state where the app is turned on and the role can be performed normally, depending on envFor example, libraries that require images of 'prod' environment and libraries that use images of 'dev' environment can be different.In addition, by inserting env into the image, any role member (Developer, QA, DevOps) can execute app by receiving images that are completely isolated to the desired environment and generated in their own local environment.
[2019-10-11 08:00:01] <dangen-effy> TwanoO67: 
[2019-10-11 12:57:27] <blackroosterdev_twitter> Hi everyone - I am a little bit desperate. I am trying to set up memsql/cluster-in-a-box within docker-compose ... memsql reports, that it has initialized successfully and then exits with code 0 => but I wanted to stat the memsql service in full to run the database controller.
[2019-10-11 12:57:46] <blackroosterdev_twitter> Has anyone ever experienced issues like that?
[2019-10-11 12:58:07] <blackroosterdev_twitter> or is there a special command that can be triggered from within the docker-compose file?
[2019-10-11 13:41:07] <sinaowolabi> blackroosterdev_twitter: find out if your container does logs, and follow them. Alternatively when you start the container with compose, you can trydocker-compose start <container>; docker-compose|docker  logs <container>to see whats going on when its run
[2019-10-11 13:54:55] <blackroosterdev_twitter> thanks
[2019-10-12 10:53:25] <marcguilera> hello
[2019-10-12 10:53:49] <marcguilera> i am trying to use consul inside a docker_compose group of services. my compose looks like this:
[2019-10-12 10:54:04] <marcguilera>  [<-CODE->] 
[2019-10-12 10:54:39] <marcguilera> i can access consul atlocalhost:8500from my browser but the services cant register at the same url. what am i missing?
[2019-10-12 10:55:24] <marcguilera> in each service I use the java consul client like this:
[2019-10-12 10:56:16] <marcguilera>  [<-CODE->] 
[2019-10-12 10:57:13] <marcguilera> but i get a connection refused
[2019-10-12 11:00:07] <konstantinblaesi> tryhttp://consul:8500instead ofhttp://localhost:8500
[2019-10-12 11:00:58] <marcguilera> let me try
[2019-10-12 11:02:00] <marcguilera> ah that worked
[2019-10-12 11:03:22] <marcguilera> thanks man
[2019-10-12 11:08:10] <konstantinblaesi> no problem. The reason is that docker containers are in their own local network (seedocker network lsanddocker inspect ...) and docker creates entries in linux' /etc/hosts file of the container instances that will resolve dns/service names from your compose file to the containers ip in that local network.
[2019-10-12 11:10:41] <marcguilera> ah thanks for the extra info
[2019-10-12 12:10:42] <MarkoShiva> marcguilera: the container services and containers see each other via name so for example if you want to access a mysql service that is running inside of the docker-compose or docker swarm you want to use mysql:3306 instead of localhost:3306 as they will see each other by the name of the container or name of a service. :)
[2019-10-12 12:11:39] <MarkoShiva> Its the smae what@konstantinblaesisaid just in different wording. :)
[2019-10-12 17:40:45] <marcguilera> :)
[2019-10-12 17:57:28] <matrixbot> Simó Albert i BeltranHello!
[2019-10-12 17:58:25] <matrixbot> Simó Albert i BeltranWhat is the simplest way to create an encrypted volume?
[2019-10-14 07:02:25] <pjetr> Another question, I have a script mapped to adocker-compose exec. Is there a way to send all output to a file likedocker-compose exec script > var/server.log 2>&1. This works, but hangs my terminal.
[2019-10-14 07:03:07] <pjetr> so, instead of enabling me to check the output as well as starting another script, I'm just looking at an empty terminal
[2019-10-14 07:05:01] <pjetr> And extra question, is there a way to stop that exec once I'm done with it?
[2019-10-14 07:15:22] <MarkoShiva> use tea instead of just redirection
[2019-10-14 07:19:14] <MarkoShiva> docker-compose exec script | tee > var/server.log 2>&1.That will give you the output in terminal as well as send output to the log file.
[2019-10-14 07:20:08] <MarkoShiva> pjetr: If I understand you correctly that is what you want to inspect output and get back the terminal prompt
[2019-10-14 08:00:15] <pjetr> in1t3r: No, I want it in a log file, and me being able to use that terminal window. So no output in the terminal.
[2019-10-14 08:02:51] <MarkoShiva> Why dont you run with -d command for detached then?
[2019-10-14 08:03:46] <MarkoShiva> just adddocker-compose -d exec scriptand you ill have a docker-compose detached from the terminal.@pjetr
[2019-10-14 08:47:34] <pjetr> Yes, I iknow, but I want to be able to check the output if something goes wrong, and I would like to know the PID so I can stop the script :-)
[2019-10-14 08:48:46] <MarkoShiva> you can always attach or inspect docker-compose when its about the pid just do the ps aux | grep docker-compose
[2019-10-14 08:48:52] <pjetr> in1t3r: It's for a dev environment, to start the nodeJS server, but I can't start it with a command, because there isn't a default script, it varies too much for different developers
[2019-10-14 08:49:12] <pjetr> some just need to run the application, and need to be able to check the output
[2019-10-14 08:49:26] <pjetr> while others need to have a debugger connected
[2019-10-14 08:49:30] <pjetr> etc...
[2019-10-14 08:50:03] <pjetr> so the command is simplytail -f /dev/nullso the container doesn't close
[2019-10-14 08:50:41] <pjetr> and people can use a script to run the correct scenario for them
[2019-10-14 08:51:00] <pjetr> so I can't really attach, because then I'll just attach to the tail
[2019-10-14 08:51:17] <pjetr> and I use exec, to which you can't attach AFAIK?
[2019-10-14 08:51:24] <MarkoShiva> dude there is command docker-compose logs
[2019-10-14 08:51:48] <MarkoShiva> which will give you the output of docker compose if that is what you want with logs
[2019-10-14 08:51:54] <pjetr> and I cant use docker-compose logs, since that simply logs mytail -f /dev/null
[2019-10-14 08:52:20] <MarkoShiva> oh so vou have exec command as tail?
[2019-10-14 08:53:03] <pjetr> Well the better solution would be a command that can be altered through .env
[2019-10-14 08:53:39] <MarkoShiva> I think that can be done although I'm not really experienced with npm
[2019-10-14 08:54:05] <pjetr> IF [[ $MODE -eq "inspect" ]]; then Command A; else Command B; FIwould be awesome
[2019-10-14 08:54:17] <pjetr> but I can't get that to work...
[2019-10-14 08:54:49] <pjetr> OOoooh, that could work
[2019-10-14 08:54:52] <MarkoShiva> where are you inserting that bash script?
[2019-10-14 08:55:21] <pjetr> I was thinking of putting that in my command in the docker-compose.yml
[2019-10-14 08:55:29] <pjetr> but I could create a basic script
[2019-10-14 08:55:39] <pjetr> and execute that as command
[2019-10-14 08:55:45] <MarkoShiva> yep
[2019-10-14 08:55:48] <pjetr> in which I do that checking!
[2019-10-14 08:55:52] <pjetr> thanks man!
[2019-10-14 08:56:13] <MarkoShiva> np you solved it yourself :)
[2019-10-14 09:09:22] <pjetr> Yay, that works!
[2019-10-14 09:09:32] <pjetr> such a simple solution, ...
[2019-10-14 09:09:54] <pjetr> KISS, amirite 
[2019-10-16 06:25:52] <ankitsharma07> Hi!
[2019-10-16 06:26:47] <ankitsharma07> I have a Deep Learning application which I have been serving on EC2. Now I want to containerize it using docker and then transfer it to ECS
[2019-10-16 06:28:12] <ankitsharma07> My question is basically if and how I can make use of open source libraries inside a docker container and how to use it in our main program?Say exampleOpen is an open source library and I made a container using Dockerfile now how can I import this into my main program?
[2019-10-16 06:28:31] <ankitsharma07> any help would be appreciated
[2019-10-16 06:54:57] <MarkoShiva> ok so the question is how to use containerized oss libs in the project?
[2019-10-16 06:56:13] <MarkoShiva> Well then you would need to write an app and put it in the container or into docker-compose and start them. Have you read about docker? Do you understand usage?@ankitsharma07
[2019-10-16 06:58:09] <MarkoShiva> You cannot import into main program main program need to run inside of the docker container you can have it running in the same container as the libraries or you can have libraries be used as services if they can interact with your program externally over the network they then can communicate with a program inside of docker compose too. :)
[2019-10-16 07:31:56] <ankitsharma07> in1t3r: I read somewhere that docker images are immutable. My program is in CD stage. So, I wanted to make images for my external modules only.
[2019-10-16 08:14:47] <MarkoShiva> Well that depends how you make the image. The base of the image might be immutable but all of the data that is processed durring the execution of the image can still be accessible if vou leave mounts as volumes and on that way it could be latter accessed and used.
[2019-10-16 20:29:09] <matrixbot> DragetI am wondering: Is there an actual security advantage running processes inside a docker container as a limited user and not as root, assuming I do not use mounts? If I do not mount anything from my host (or only mount an irrelevant directory), does running the process inside the container as a non-root user harden anything?
[2019-10-16 20:30:23] <matrixbot>  [<-CODE->] On the other hand, handling PIDs and permissions is kind of a PITA when limiting a process inside a container.
[2019-10-17 07:28:54] <ankitsharma07> I am installing one module using dockerfile and that requires command line interaction to select Yes/No. How to deal with this?Is there a way where we can RUN apt-install moduleName and for interaction keep to always Yes so that the docker build is not interrupted.
[2019-10-17 11:47:21] <epifanio> Hi@All, I am looking for some advise/help in using docker contaieners  .. is this the righ channel?
[2019-10-17 11:53:37] <epifanio> I currently run a series of services using docker, the services are all starting using docker-compose, the compose file looks like:   https://gist.github.com/epifanio/6617bd97c421c067841e6f785d353deathe  service "pydap" is serving a resource using an network protocol (opedap) and this resource is avaialble on localhost:80 from my host network. I can access it in python from a standard shell with this code: [<-CODE->] my problem is:the \'jupyter\' service (running on localhost:8888) which is a python notebook server, is not able toreach such resource ... how to tell the jupyter service to load the resource served by an other container?
[2019-10-17 19:09:19] <ecaepp> epifanio: Are you able to connect to the Jupyter service from your host machine?
[2019-10-17 19:10:11] <epifanio> ecaepp: yes, I can load the notebook into my browser using 'localhost:port’
[2019-10-17 19:10:24] <ecaepp> hmmm
[2019-10-17 19:12:13] <ecaepp> epifanio: have you checked the logs for the servicedocker-compose logs <service_name>?
[2019-10-17 19:16:45] <epifanio> no i didn’t - I was checking from the shell where I started thedocker-compose up, it seemed everything works as expected
[2019-10-17 19:17:19] <epifanio> Mean, If i load one of the docker services started with docker-compose I can access all of them on localhost with my browser
[2019-10-17 19:18:15] <epifanio> But if i use “localhost:port” in a code-cell of the notebook, it can’t find the service which docker-compose started ….
[2019-10-17 19:18:59] <epifanio> I guess the notebook “localhost” refers to the docker-image running the jupyter server and doesn’t know about the outside docker istances
[2019-10-17 19:19:19] <epifanio> I was trying to read about docker networks, bridge etc ..
[2019-10-17 19:21:42] <epifanio> perhapse in the notebook code cell i should use instead of: [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2019-10-17 20:34:24] <ecaepp> epifanio: Ahh yes, you are correct in your code use the service name you are trying to connect to. Docker runs it's own DNS so it will be able to resolve the service name to the container  you need to connect to.
[2019-10-17 20:35:24] <epifanio> I will be able to test it tomorrow first thing in the morning :)
[2019-10-17 20:35:33] <epifanio> ecaepp: thanks!
[2019-10-21 17:41:26] <guddutopper> I have a Java Docker container C1, I am creating multiple docker containers inside my program logic and connecting them to docker networks, I also join container C1 to some of these docker networks. The entire program logic is running in a single thread. Now a weird thing is happening, If I try to join container C1 to any of the external docker networks, I get a socket timeout exception (The container C1  joins the external network, I can see this using docker inspect but my thread just keeps on waiting).but if I join C1 to internal docker networks everything works fine. Please note that this only happens with container C1 (in which the program logic is executing), all other containers which are created in my program logic are able to join external/internal networks without any exception.I have tried increasing the read timeout and connection timeout of Docker Client to much higher values than the default ones but I still get the same error.I was using spotify Docker client, I also tried using Docker-Java client, I also tried changing my docker versions but nothing is working so far.Java version - 11.0.2Docker version - 18.9.3
[2019-10-21 19:23:09] <rajkiranguvvala> combiz_k_twitter: i would suggest to use multi stage build
[2019-10-22 00:09:42] <Samueljoli> is there anyway to run docker-compose up and publish the ports to my host machine
[2019-10-22 00:09:54] <Samueljoli> Can't seem to be able to hit my api using localhost
[2019-10-22 02:54:01] <rajkiranguvvala> guddutopper: , what kind of program is your logic sits in?
[2019-10-22 07:35:39] <guddutopper> rajkiranguvvala: Its a java rest API from a web interface, the logic is to just create container and join them to networks
[2019-10-22 07:49:26] <guddutopper> @rajkiranguvvala here is the logs of a newly instantiated container when it tries to join a external net [<-CODE->] you can see that i am getting an OK response , now look at the logs when the original container C1 joins an external network [<-CODE->] It keeps on waiting after the last log entry,Idk why this is happening ?
[2019-10-22 10:00:57] <rajkiranguvvala> guddutopper: can you try restarting all  containers, sometimes DNS on docker will resolve the network issues if any?cmd prmt-------service docker restart
[2019-10-22 10:16:33] <rajkiranguvvala> if you can share the command on how you are running the container in your program  that might give a bit of background?any what type of networks are you creating and connecting your containers?
[2019-10-22 13:09:58] <nielspedersen>  [<-CODE->]  [<-CODE->]  [<-CODE->]  [<-CODE->] 
[2019-10-22 20:52:07] <ecaepp> nielspedersen: I was unable to reproduce the the issue. I made aDockerfilewith those couple of lines and it completed aith no errors.
[2019-10-23 04:48:35] <guddutopper> @guddutopper can you try restarting all  containers, sometimes DNS on docker will resolve the network issues if any?cmd prmt-------service docker restart@rajkiranguvvala I have tested this atleast 20-30 times, this issue always occurs
[2019-10-23 08:48:49] <nielspedersen> ecaepp: Thank you for testing it also. I can now also run this locally without problems. But the issue remains when running this on CircleCI as a job. I’ve reached out to CircleCI support instead :) Thanks
[2019-10-24 17:15:45] <talbergs> Hello@here
[2019-10-25 12:19:51] <matrixbot> Simó Albert i BeltranWhat do you think about use cryfs on /var/lib/docker/volumes?
[2019-10-28 20:24:40] <matrixbot> thymbahutymbaHi guys I'm having some trouble with docker logs. It's trucated after 10/15 lines. If I executedocker exec -u 0 -it container bashand then type journalctl I can see the full logs. Someone can help me?
[2019-10-28 22:50:17] <elainegasca> Anyone know how can I deploy an react SSR application in Digital Ocean with load balancing ? (perhaps with Kubernetes,idk) or my application would not be containerized with Docker? regards.
[2019-10-29 01:55:56] <mevric> Hi There.Does anyone know if the Docker Enterprise license cost has increase this year?
[2019-10-29 12:40:58] <thojest> hey guys :D
[2019-10-29 12:41:02] <thojest> so I pulled some docker image
[2019-10-29 12:41:18] <thojest> is there a way to inspect the "aggregated" Dockerfile leading to this image?
[2019-10-29 13:57:26] <rajkiranguvvala> thojest: are u asking this command docker image inspect [OPTIONS] IMAGE [IMAGE...]
[2019-10-29 14:57:20] <thojest> yeah but this is only partially what I want :D
[2019-10-29 14:57:41] <thojest> would like to have a full list of commands including images this images uses and so on
[2019-10-29 14:57:43] <thojest> recursively
[2019-10-29 15:06:05] <rajkiranguvvala> thojest: if you need some diving into layers, i used [<-LINK->] 
[2019-10-29 16:05:47] <thojest> rajkiranguvvala: thx alot this looks very interesting :)
[2019-10-29 17:06:34] <thojest> I have read that running docker containers as some non-root user is advisable in production
[2019-10-29 17:07:41] <thojest> i have also read that priviliges are manged on one single kernel which means that users in docker containers with some uid:gid share the same priviliges of the host user with the same uid:gid
[2019-10-29 17:08:23] <thojest> so theoretically I could create a user adam in docker container which has the same uid and group id as user eva on host machine
[2019-10-29 17:08:40] <thojest> then the process inside the container would have the priviliges of eva on the host system
[2019-10-29 17:08:44] <thojest> is that correct?
[2019-10-29 21:53:20] <thojest> uhm short question
[2019-10-29 21:53:23] <thojest> mounting volumes
[2019-10-29 21:53:37] <thojest>  [<-CODE->] 
[2019-10-29 21:53:51] <thojest> i think you can guess what I want :D
[2019-10-29 21:54:02] <thojest> but wildcard does not work
[2019-10-29 21:54:20] <thojest> I want to mount all files in the respective folders without the folder itsself
[2019-10-29 21:54:23] <thojest> is this possible?
[2019-10-30 04:55:58] <rajkiranguvvala> thojest: can you share the version of the docker-compose and what OS you are tyring to run that , is it Linux or windows
[2019-10-30 10:41:57] <thojest> rajkiranguvvala: thx for your support so far. I just got it working. Stupid me thought it is CONTAINER:HOST but it is HOST:CONTAINER
[2019-10-30 13:55:59] <rajkiranguvvala> thojest: thats great you figured it out, BTW thats the magic of pair programming
[2019-10-30 15:06:41] <zillerium> I want to change a config file for ipfs which is used when the container starts up, can this be done? I have posted in stackoverflow - [<-LINK->] 
[2019-10-31 06:41:50] <rajkiranguvvala> guddutopper: did you use kubernetes to build the cluster? i suspect it is a race condition occurring in DNS look up from multiple containers trying to reach  external webservice.
[2019-10-31 23:09:32] <cmcaine> Hi, I've got a Dockerfile with some long running commands in it. I'm editing the dockerfile and re-running it to try and get it to complete without error. How do I tell docker to cache the intermediate containers rather than running them from scratch every time?
[2019-10-31 23:11:42] <cmcaine> e.g. [<-CODE->]  [<-CODE->] 
[2019-11-01 06:02:30] <rajkiranguvvala> cmcaine: you will have to use onBuild to optimize your build, let me know if you need any more help
[2019-11-01 08:39:40] <MrFCow> cmcaine: , I have had similar issue before.  My scenario copy my python source code as well as setup packages.  Original steps was copy file first and then setup python packages, so the layers cached below is copy file and thus file change might need redo later steps (setup package). What I changed was setup env (package) first and then copy file, that seems work, and together with docker multi stage build, now the rebuild is only change layer related to file update but not reinstall packages.  For your case, I suspect multistage build might help the docker image construct layer better so some earlier more static apk update steps could be already been cached and no need to rebuild
[2019-11-03 02:28:41] <prog20901> I'm going to use Spring Boot for developing portable web-app where the app runs without internet.In such a case which Database is very good for portability ?
[2019-11-05 06:21:59] <rg-repo> Hi , I want to push docker images to Nexus repository (self hosted), anyone has any idea how to do it ? because with dockerhub its straight forward but with self hosted repo it is not working.Thanks
[2019-11-05 06:24:00] <rg-repo> prog20901: with out internet the options you are left with either in-memory databases like - derby, H2 or you can dockerize your app and call mysql inside the container.
[2019-11-05 10:56:02] <phao5814> Hi guys, was wondering if anyone with experience using Cypress with Docker can help me out here? The main problem is that my Cypress container can’t seem to connect to the other container’s port 8080…. More info here: [<-LINK->] 
[2019-11-06 07:32:14] <rg-repo> Hi can anyone please help me with this - docker+MySQl + springboot connection refused error - [<-LINK->] 
[2019-11-06 07:52:36] <wobu> Hey folks, i think i have found a bug in the build cache when building images and i don\'t know where to post an issue. Any hints? WHen using "ENTRYPOINT []" with empty parameter or empty string no build cache is used.
[2019-11-06 09:47:00] <matrixbot> Simó Albert i Beltransee you
[2019-11-06 12:27:46] <gssjericsantos> Hello Guys I'm Having Problem With user_data For AWS_Instance [<-CODE->] This Is What Is Inside My user_data.sh [<-CODE->] It Gives Me This Error When I Run Terraform Plan [<-CODE->] But When I Run It This Way [<-CODE->] It Creates The Files But Anything With $ Is Not Copied Or Is Incomplete. Isn't Terraform Suppose To Treat This Whole File As A StringThis Is The File Created When I Check The EC2 Instance [<-CODE->] 
[2019-11-06 12:35:50] <gssjericsantos> I Am Using Terraform Version 0.12.12
[2019-11-06 17:05:07] <Tomczik76> I'm following a tutorial that has a few docker containers configured using compose and that are using the link feature to communicate. One of the services in a container is binding to its linked IP to so other containers can connect to it. I would like to connect to that service from my host computer. Does anyone know how to configure that?
[2019-11-06 17:08:08] <abhishek246> Yes it very easy remove the ip and give host machine IP.. if you put 127.0.0.1 it has be the lan IP
[2019-11-06 17:09:03] <Tomczik76> Remove the IP from where?
[2019-11-06 17:09:23] <Tomczik76>  [<-CODE->] 
[2019-11-06 17:09:47] <Tomczik76> So I want to connect to kafka from my host computer
[2019-11-06 17:10:05] <Tomczik76> but the connect service still needs to connect to it
[2019-11-06 17:10:44] <abhishek246> I’m working on CDC what a Coincidence
[2019-11-06 17:11:01] <Tomczik76> With Debezium?
[2019-11-06 17:11:24] <abhishek246> Yes I’m try to replicate the data from rds to kinesis
[2019-11-06 17:12:22] <Tomczik76> I'm need to stream our rds data to our data lake in s3
[2019-11-06 17:12:49] <Tomczik76> Do you know what I need to change in my docker compose file so that I can connect to kafka from my host computer?
[2019-11-06 17:13:42] <abhishek246> I’m also experimenting
[2019-11-06 17:14:27] <Tomczik76> If I change theHOST_NAMEparameter to localhost then I can connect to it from my host computer, but then connect can't connect to it
[2019-11-06 17:16:07] <abhishek246> In this case remove the Kafka config from the compose file .. change BOOTSTRAP_SERVERS value to local machine IP 127.0.0.1/local host will not work it has be your local network IP
[2019-11-06 17:17:55] <abhishek246> Let me know if you have any success in replicating the data
[2019-11-06 17:24:31] <Tomczik76> abhishek246: It worked, but only problem with it is anybody that uses this docker compose file will need to set that ip
[2019-11-06 17:32:26] <abhishek246> If they are running in a local machine, Yes they will have to specify the machine IP. If you want to deploy this in production then the value should be Kafka Cluster URL
[2019-11-06 17:42:46] <Tomczik76> Hmm actually it doesn't seem to work using the local ip address
[2019-11-07 11:50:04] <SubhamAshish> i am trying to run postgres in windows 10 base OS,While mounting its data to file system am facing an errordocker command used~~docker container run --name postgres-dev -p5444:5432 -v //c/subham/dockerdata:/var/lib/postgresql/data -e POSTGRESQL_PASSWORD=admin -it postgres:9.5-alpine~~
[2019-11-07 11:50:42] <SubhamAshish> and error is:: data directory /var/lib/postgresql/data has wrong ownership
[2019-11-07 11:50:49] <SubhamAshish> does anybody have any idea
[2019-11-07 11:50:50] <SubhamAshish> ?
[2019-11-07 11:50:55] <SubhamAshish> how to solve this
[2019-11-07 11:50:57] <SubhamAshish> help
[2019-11-07 14:40:05] <rajkiranguvvala> SubhamAshish: try creating a docker volume and then mount it.     docker volume create --name <volume name> -d local.                          Inside your compose file do this.     volumes:-volumename created above:/var/lib/postgresqlvolumes:Volumename created aboveexternal: true                                            Let me if that helps
[2019-11-08 02:16:52] <sumew> I want to source a script that is in an image when I run a container
[2019-11-08 02:17:58] <sumew> Where would I put thesource script.sh? Putting it inENTRYPOINTprevents me to start the container interactively
[2019-11-08 03:58:09] <rajkiranguvvala> s-u-m-e: bash command at the end of docker run command can make your shell interactive. docker run .... bash -c script.. ; bash                 let me know if that helps
[2019-11-08 20:27:01] <sumew> rajkiranguvvala: I am working off an alpine image that only hassh. Also I wanted to source the script outside of my run command
[2019-11-09 00:17:24] <mateothegreat> pass—entrypoint=shtodocker run
[2019-11-09 20:35:08] <matrixbot> Stephen DHow do I go about debugging a Dockerfile in docker compose?
[2019-11-10 07:35:50] <abhishek246> Run the docker image
[2019-11-10 07:36:02] <abhishek246> Using the bash as the command
[2019-11-10 15:01:13] <jdickey> @matrixbot you don't even need to change your Dockerfile as long as you have a shell installed in the image used to create a container. With no instance of that container running (but any support containers you need, like database and so on), run [<-CODE->]  [<-CODE->] 
[2019-11-11 00:28:01] <Srinath-rd> hello
[2019-11-11 05:40:51] <tweet_kum_twitter> Need help for this command:docker build --build-arg PIP_EXTRA_INDEX_URL=${PIP_EXTRA_INDEX_URL} -t ml_api:latestI am stuck with this error: Error response from daemon: Cannot locate specified Dockerfile: DockerfileDockerfile exist in repo. I am beginner to docker and have taken reference of this dockerfile from github repo [<-LINK->] 
[2019-11-11 09:20:10] <MrFCow> tweet_kum_twitter: , first off which folder you are at when you call docker build? You should be at the same level at the Dockerfile? Also there is the context you need to specify I suppose like “docker build <options> .” while the last dot mean using current folder location as context so your Docker file would refer relatively
[2019-11-12 01:16:40] <zzj0402_gitlab>  [<-CODE->] What did I miss? --privilege?
[2019-11-12 15:11:02] <Genysys> Hi,I have the following directory and I am trying to pass a volume from my local machine to my container [<-CODE->]  [<-CODE->] 
[2019-11-12 15:17:22] <Genysys> currently not sure where my application data is although the application seems to be running
[2019-11-14 06:52:25] <mighty_1989_twitter> HI Everyone
[2019-11-14 06:52:54] <mighty_1989_twitter> I am trying to mount a network drive on windows container running on windows server 2016
[2019-11-14 06:53:07] <mighty_1989_twitter> windows container image is of server core
[2019-11-14 06:54:34] <mighty_1989_twitter> when trying do docker run -td --mount type=bind,source=m:\\,target=c:\\data 8c9  it doesn't work while the same command works well if it is C instead of M:
[2019-11-14 06:55:21] <mighty_1989_twitter> any leads will be helpful ..
[2019-11-14 06:55:44] <mighty_1989_twitter> i am using docker version 19.03.3
[2019-11-14 15:45:40] <ecaepp> mighty_1989_twitter: Have you created the drive share in Docker Desktop settingShared Drives?
[2019-11-14 15:47:13] <ecaepp>  [<-LINK->] 
[2019-11-15 05:14:14] <mighty_1989_twitter> ecaepp: Thank You
[2019-11-17 14:33:23] <smitjainsj> Hi All, I wanted to learn more about docker vulnerabilities and things around it. so wanted to implemented a tool which scan docker images for know vuls. I did went thought Clair (Core OS). let me know guys, what are you using and which one u feel is best
[2019-11-17 16:06:29] <stavalfi> What is the syntax to create container with mount (bind) from the new Docker API? [<-LINK->] 
[2019-11-17 21:13:20] <matrixbot> tuxayoSaluton, hola, hi :)Is there a place where one can find all the support docker CE version? I didn't find anything clear until now. Mostly EE stuff...
[2019-11-19 06:52:08] <sukalpomitra> Hi All,  is there a docker command to list all tags of an image from dockerhub registry
[2019-11-19 08:04:34] <jdevillard> Hello@sukalpomitra, have you try to curl the repo? at path /v2/_catalog using basic credentials
[2019-11-19 08:04:50] <jdevillard> (work on Azure Container Registry)
[2019-11-19 09:12:49] <sukalpomitra> yeah it works with the /v2/
[2019-11-19 09:12:51] <sukalpomitra> thanks
[2019-11-20 12:46:33] <FrankenSteinxD_gitlab> guys I have two docker containers running on one server, openvpn container and web app containerI reject all requests except for those coming from openvpn container, but that is not workingthe web app container sees my real IP, how is that possible ?
[2019-11-20 21:27:04] <mateothegreat> check your routes
[2019-11-21 16:18:58] <nikolas.p_gitlab> hey guys i wrote an bash script that is supposed to run whilp/ssh-agent in container so i can later use for ssh forwarding
[2019-11-21 16:19:15] <nikolas.p_gitlab> my bash script looks like this:bash
[2019-11-21 16:20:34] <nikolas.p_gitlab> docker stop ssh-agent\ndocker rm ssh-agent\ndocker run -d --name=ssh-agent whilp/ssh-agent:latest\ndocker run --rm --volumes-from=ssh-agent -v ~/.ssh:/ssh -it whilp/ssh-agent:latest ssh-add /ssh/id_rsa\ndocker run --rm --volumes-from=ssh-agent -v ~/.ssh:/ssh -it whilp/ssh-agent:latest ssh-add -L
[2019-11-21 16:21:05] <nikolas.p_gitlab> but i getError connecting to agent: No such file or directory
[2019-11-21 16:52:09] <sumew> I want to source a script as part of my container build/entrypoint/command so that when users run my container the functions in the script are avaialble. I’m using alpine and sh. The problem is no matter what I try, when I log into the container the script is not sourced. [<-CODE->] 
[2019-11-21 16:54:47] <sumew> what I’d like to do is the equivalent of having done. script.shbeforehand so the user who’s running the container has access to the functions I define in my script
[2019-11-21 17:39:12] <jjoaoclaro> hey! as anyone used the visual studio docker run feature?
[2019-11-21 17:48:28] <stanislasdrg> Hello everyone, do you know how to inject a custom nginx.conf file on docker mac ?
[2019-11-21 17:48:37] <stanislasdrg> Apparently docker is virtualised on mac
[2019-11-21 17:49:34] <stanislasdrg> so the command :docker run --name nginx-test-name -p 80:80 -v ~/Desktop/nginx.conf:/etc/nginx/nginx.conf:ro -d nginx
[2019-11-21 17:49:37] <stanislasdrg> does not work
[2019-11-21 17:50:07] <stanislasdrg> Any idea how I can get my nginx config to work ?
[2019-11-21 18:17:53] <ecaepp>  [<-CODE->]  [<-CODE->]  [<-CODE->] Just re-read your question. [<-CODE->] A way to solve this would to have you script take in arugements. That way when people connect to the container they can just call the script to preform the task that needs to be done.
[2019-11-21 18:43:13] <sumew> ecaepp: so when I want to export commands and scripts on non-docker *nix shells, I just put the script in something likebash_profileand my shell would be pre-initialized at startup.
[2019-11-21 18:44:17] <sumew> what’s more confusing, this is the content of/etc/profilein the container [<-CODE->] 
[2019-11-21 18:45:49] <sumew> but even after putting my script under/etc/profile.d/script.shas part of the build, when I rundocker run -it <my_container> shmy shell doesn’t have my scripts
[2019-11-21 19:28:48] <sumew> I found a workaround. If I putENV ENV=/home/user/.profileand place my script in this location, it will be picked up
[2019-11-21 19:55:10] <ecaepp> s-u-m-e: Nice glad you got it figured out.
[2019-11-22 12:00:30] <angeljohny87> HI ALl, while maven building application with spotify in eclipse getting I/O exception (java.net.SocketException) caught when processing request to {s}-> [<-LINK->] : Connection reset by peer: socket write error how to solve this issue?
[2019-11-22 16:18:54] <najitaleb> Hi. Does anyone know how to increase the stack size in the container through docker-compose? Changing the stack size on my host doesn\'t help, and also adding "RUN ulimit -s unlimited" in the Dockerfile doesn\'t help either. Thanks
[2019-11-22 16:27:30] <matrixbot> kimbNormally Docker does not limit the RAM for containers, it should be some limit of the used program inside of the container.
[2019-11-22 17:38:15] <dr-chews> is this the room for troubleshooting issues with Docker?
[2019-11-22 17:59:33] <dr-chews> i have an error with HyperV
[2019-11-22 17:59:50] <dr-chews> sounds related to this [<-ISSUE->] 
[2019-11-24 12:37:17] <byakoshiki_twitter> hello
[2019-11-24 12:37:21] <byakoshiki_twitter> is anyone here?
[2019-11-25 12:51:50] <tebeco> hello
[2019-11-25 12:52:16] <tebeco> anyone using Windows Terminal + docker4Win ?
[2019-11-25 12:52:33] <tebeco> seems that i have a weird glitch when runningdocker image list
[2019-11-25 12:53:11] <tebeco> i see aCMDpop for like 10ms max actually executing the command but it wont output anything in the terminal itself
[2019-11-25 12:54:05] <tebeco> running from a dedicatedcmdoutside ofWindows TErminalseems to work, but i\'m not sure why there\'s a "ghost" cmd poping outSo far i only have the issue with docker
[2019-11-25 14:30:24] <byakoshiki_twitter> Does anyone here have example of running sonarqube in docker with postgress database? I cant imagine how to make it with dockerfile ...
[2019-11-26 08:16:09] <matrixbot>  [<-CODE->] You should be able to do this with Swarm and docker-compose by assigning labels to docker-hosts and using those labels to 'assign' those 3 services. Note that if one of those docker-hosts goes down this leaves no room for your services (unless you have 2 (or more) docker-hosts for each label.I don't really know why you want this, I generally just let swarm manage where it wants to run stuff. Note that if you start more that 1 replica for each service swarm will try it's best to load-balance them over different hosts
[2019-11-26 21:31:00] <ecaepp> l @byakoshiki_twitter In my mind the simplest way to do it would be to build a Docker image with just Sonarqube and use then the standard postgres image. Once that is done you could use docker-compose to spin up the containers so they are in the same network and can talk to each other.A second way to do it would be to still build your Sonarqube image, but instead of using docker-compose you could spinup the container indivigually just make sure you pubish the database port of the postgres container.
[2019-11-27 01:38:27] <sphinx20> Hi, I would need some help with docker-ce (community edition) installation in ubuntu 16.04. I am trying to install version 17.03 using puppet but always end up with package not found error
[2019-11-27 01:38:59] <sphinx20> Can I get some help regarding that in this forum or anyone knows another forum where I can ask?
[2019-11-27 07:32:49] <bhagyaperera123> hello guys, I'm getting this error with the docker cluster environment. does anyone know how to fix this issue? [<-CODE->] 
[2019-11-27 12:48:50] <CodeAnil> sphinx20: 1. Maybe your APT-GET Repos are not able to contact the upstream repos(Check your repo configurations whether your corporate proxies are added).Try adding Docker official repo and install. For more information please check https://docs.docker.com/install/linux/docker-ce/ubuntu/
[2019-11-27 22:24:54] <matrixbot> mtis someone able to reproduce this problem under linux? [<-LINK->] docker attempts to crash all below pid 1 on thehostif a file with windows line-endings is in the entrypoint (be careful, this kills my xsession and probably more on current arch + plasma): [<-LINK->] 
[2019-11-27 22:24:55] <matrixbot> mt* is someone able to reproduce this problem under linux? [<-LINK->] docker attempts to crash all below pid 1 on thehostif a file with windows line-endings is in the entrypoint (be careful, this kills my xsession and probably more on current arch + plasma):
[2019-11-27 22:38:23] <matrixbot> mtI filed a bug: [<-ISSUE->] 
[2019-11-28 15:16:08] <tebeco> Anyone on Windows using wsl2 backend ?
[2019-11-28 15:16:37] <tebeco> i got a weird routin issue I’m not sure if something is broken or (probably) me being stupid
[2019-11-28 16:43:45] <vroussea> hello, i'm using a docker-compose to start a swarm (with 2 containers, a postgres db and adminer)but when the postgres db won't start because of the following errordatabase files are incompatible with serverThe data directory was initialized by PostgreSQL version 11, which is not compatible with this version 12.1 (Debian 12.1-1.pgdg100+1).
[2019-11-28 16:45:14] <vroussea> every fix i found on internet where for mac os ... i don't know how to upgrade the db on debian
[2019-11-29 14:50:05] <rafael9876> Has sombody any idea to make a continous deployment with aws eks?
[2019-11-30 17:41:55] <Sharkbyteprojects> how can i use docker with windows 10 home (virtualbox)
[2019-11-30 17:43:45] <tebeco> Win10 runs within a vm already ?
[2019-11-30 17:44:26] <tebeco> You needs windows containers or Linux containers ?Docker is just a tool
[2019-11-30 17:44:43] <Sharkbyteprojects> win 10 pro has a vm,win 10 home not
[2019-11-30 17:45:03] <Sharkbyteprojects> i had used docker toolbox, but isn't working longer
[2019-11-30 17:45:18] <tebeco> This is not my question ^^
[2019-11-30 17:46:19] <tebeco> Let me ask it another wayWhen the physical hardware boot ... to the real OS Host
[2019-11-30 17:46:26] <tebeco> What’s that OS ?
[2019-11-30 17:46:36] <tebeco> Straight to win 10 home ?
[2019-11-30 17:46:53] <tebeco> I mean the OS that is NOT virtualized
[2019-11-30 17:49:21] <Sharkbyteprojects> it boot to win 10 home. But only virtualbox is installed. Not windows virtualisation(need for normal docker installation)
[2019-11-30 17:50:06] <tebeco> that's why i asked the host OS first, as you stated VirtualBox out of no where
[2019-11-30 17:50:52] <tebeco> if you're looking for Docker 4 Windows, the stable way is HyperV, meaning as you said Win10 Pro minimum
[2019-11-30 17:51:12] <tebeco> now, if Win10 Home supports insiders edition (no idea if Home is open to that)
[2019-11-30 17:51:41] <tebeco> then if you have Win10 home insider on 20h01, you'll have wsl2
[2019-11-30 17:52:03] <tebeco> activate WSL feature (stable since month/year ... in wsl1),
[2019-11-30 17:52:18] <tebeco> install for example Ubuntu or another, switch it to Wsl2
[2019-11-30 17:52:44] <tebeco> install docker Edge Channel, then force Docker4Win to use wsl2 as a Backend
[2019-11-30 17:52:58] <tebeco> should work on Home edition (at least on the paper)
[2019-11-30 17:56:41] <tebeco> the other way is wondering if 99$ is expensive or not ?
[2019-11-30 17:57:02] <tebeco> :D console game is ~59-79$ ;) you'll get your proper upgrade
[2019-11-30 17:57:21] <tebeco> meh
[2019-11-30 17:59:53] <Sharkbyteprojects> tebeco: i think, i use debian cli on virtualbox and install docker there
[2019-11-30 18:00:40] <tebeco> can't help about weird virtualization aside previous ^^
[2019-11-30 18:00:55] <tebeco> it's kinda the opposite of Docker ;)
[2019-11-30 18:01:50] <tebeco> if you want to do that manually on your own you\'ll need to run the equivalent VM that "stable" docker uses => Moby in HyperV + port mapping / bridge
[2019-11-30 18:02:10] <tebeco> also having to setup docker client on windows and makesure dockerd runs in the VM
[2019-11-30 18:02:15] <tebeco> and then mapping them together
[2019-11-30 18:03:35] <tebeco> can't help on that, that's why i never mentioned VirtualBox or any custom virtualization scenario aside standards oneit's possible but you're mostly on your own (by that i mean that you'll probably have to go throught forum / github etc ... you'll probably find info around there)
[2019-11-30 18:05:41] <tebeco> never tried to do that manually, i'm not competent ^^ i would probably destroy my box :D
[2019-12-02 00:06:27] <deviarchscs> Hello everybody, I would like to present an open source project on which I'm working on: [<-LINK->] It is a simple dockerizable webserver that can serve any kind of files, wherever they are. It abstracts the complexity of storage providers to help you upload, download and operate on your files.If you're interrested, don't hesitate to give me feedbacks
[2019-12-03 07:48:11] <guddutopper> One Basic Question ->  If a file on a host system is owned by a specific user , Can a docker contaienr running  as ROOT access and modify this file if it is mount mapped to it ?
[2019-12-03 09:30:35] <matrixbot> kimbYes, as a root on the host can too.
[2019-12-05 06:15:48] <ahoora08> Hi everyone, how can I create a passwordless sudo user in dockerfile for centos? I could do it in Ubuntu but my command doesn't work in CentOS!
[2019-12-08 07:40:41] <reaganscofield> I think you need to install your docker without sudo priveledge
[2019-12-08 09:51:19] <Ing-Brayan-Martinez> 0
[2019-12-08 11:05:12] <reaganscofield> sphinx20: what command did used on your ubuntu distro ?
[2019-12-08 12:09:38] <vivek2007> Looking for work
[2019-12-08 15:06:31] <mighty_1989_twitter> Hi
[2019-12-08 15:06:56] <mighty_1989_twitter> i want to start windows container with user
[2019-12-08 15:07:32] <mighty_1989_twitter> i am using this : >docker run -d --user mayank 49e
[2019-12-08 15:08:09] <mighty_1989_twitter> d46ddd659ec2f777a263ab3c74edf49c329c4d70fa695329a3e9594a6b651725docker: Error response from daemon: container d46ddd659ec2f777a263ab3c74edf49c329c4d70fa695329a3e9594a6b651725 encountered an error during CreateProcess: failure in a Windows system call: The user name or password is incorrect. (0x52e) extra info: {"CommandLine":"c:\\windows\\system32\\cmd.exe","User":"mayank","WorkingDirectory":"C:\\","CreateStdInPipe":true,"CreateStdOutPipe":true,"CreateStdErrPipe":true,"ConsoleSize":[0,0]}.
[2019-12-08 15:08:18] <mighty_1989_twitter> can anyone help here
[2019-12-12 02:47:57] <phao5814> Hi guys, I’m having an issue with my docker-compose command returning with an exit code of 137 when I expect an exit code of 0. Would appreciate if someone could help me out here: [<-LINK->] 
[2019-12-12 03:17:36] <derekkite> phao5814: can you run your cypress outside of docker to see if it errors out?
[2019-12-12 03:28:26] <phao5814> derekkite: yeah I have no problems running cypress outside of Docker
[2019-12-12 03:29:43] <phao5814> derekkite: whats weirder is that when I run cypress in the container, all the tests pass successfully and the script supposedly exits with a code of 0 but the container still exits with an exit code o 137….
[2019-12-12 03:43:56] <derekkite> phao5814: is there some asynchronous thing going on where a process is running when the container process finishes?
[2019-12-12 03:48:28] <derekkite> It seems that it could be triggered by the os doing a kill as well, for example the linux OOM handler
[2019-12-16 15:39:20] <suarez677> Hi, I need to change the screen size of the container in which the test is run. How can I do it? Thanks
[2019-12-16 15:42:00] <jdickey> suarez677: Have you tried setting theROWSand/orCOLUMNSenvironment variables in yourDockerfileordocker-compose.yml?
[2019-12-16 15:48:26] <suarez677> jdickey: I am using an image of Selenium and I configure in my Dockerfile the variables SCREEN_WIDTH and SCREEN_HEIGHT, the container opens with these dimensions, but when executing tests the screen resolution is 800x600.
[2019-12-16 15:53:54] <jdickey> Ah, ok; I thought you were talking about theterminaldimensions inside the running container for some reason. Which driver are you using. As I recall, the default 'rack-test' driver is unbelievably stupid; it may well not support that. Try using Firefox or Chrome and see if those work better for you
[2019-12-16 15:55:56] <jdickey> Check out [<-LINK->] ; that may help you
[2019-12-16 16:01:29] <suarez677> I use chromedriver to run the tests, and that is one that I did, but since the screen size where the browser is running is 800x600, the browser that opens can only have that maximum size. I'm going to do some more proof with that. Thank you very much
[2019-12-16 16:09:29] <jdickey> You're welcome; sorry I couldn't be more helpful. I've been in back-end shtuff for a few months
[2019-12-17 11:54:41] <jdevillard> Hello guys, Is anyone succeed to create a swarm hybrid cluster with overlay network on Azure? I've got one Manager Linux ubuntu 18.04 (19.03.5 CE) and a Worker Windows 2K19  (19.03.5 EE), When Windows join the Swarm, the node is ready, but when I try to deploy a Service on this node that use overlay network, the node get down and so the service refuse to deploy. Do you have any idea? (I've desactivated the firewall on windows, and the manager was working before with a Windows 2K16)
[2019-12-17 23:05:10] <jdevillard> Hum it seems that the communication stop when I try to use a service with another overlay network , the new overlay network seems to change network config on the VM and then the communication is lost
[2019-12-18 15:43:00] <tatitati> guys, why this format is wrong? [<-CODE->] 
[2019-12-18 15:44:04] <tatitati> Service 's_application' failed to build: invalid reference format
[2019-12-18 16:12:42] <tebeco> Dunno but I would install extension in VsCode for you fileThey are not perfect but often smart
[2019-12-18 16:14:31] <rajeshcis> how I can create my own docker container which is having installed firefox ?
[2019-12-19 06:12:41] <kottackalsulvin> hi,how to open two terminals and run commands using dockerfile?
[2019-12-19 14:45:14] <matrixbot> pwr22Still seems to be working for me ATM
[2019-12-19 15:53:21] <matrixbot> pwr22Did you use --link or put them on a non default network?
[2019-12-20 04:05:48] <kottackalsulvin> Hi,Here I am trying to create private ethereum instance using dockerfile. I want to open two terminals and run command1 in terminal1 and execute command2 in terminal2 only when command1 returns zero(no error).Commands are shown below: [<-CODE->] But I couldn’t get any document related to this. Please help me to resolve this issue.
[2019-12-20 08:40:39] <chpaulin> Hi! This is probably a question that has been asked a million times but is there any best practices on how to organize files and directories on the host that is used by containers? Or is this frowned upon and you should copy these files into the containers? We are mainly talking about configuration files that are defined at deploy and not when creating the image.
[2019-12-20 09:29:49] <matrixbot> pwr22chpaulin (Gitter):  if the configuration is static maybe you could bake it into the container builds?
[2019-12-20 09:30:03] <matrixbot> pwr22* chpaulin (Gitter):  if the configuration is static maybe you could bake it into the image builds?
[2019-12-20 22:33:42] <tatitati> guys i have a doubt. There is an standard about how to test a docker container?. I mean, tests should run during the building process or after the image is built?, there is any kind of better pratice? or interesting link about it?, or suggestion?
[2019-12-21 05:51:53] <aasifkhan7> I am running this docker command: [<-LINK->] and when I connect it using jvisualvm, then it doesn't connect.
[2019-12-21 13:09:52] <bluemind2005_twitter> Any luck with this question?
[2019-12-21 13:09:52] <bluemind2005_twitter>  [<-LINK->] 
[2019-12-21 14:08:47] <desjob> Question: I have a production docker image for my PHP app that i can start and everything works. Now for development, i would like to be able to use a similar image, but have the source code that was put in the image at BUILD TIME be mounted back to my host (as volume?) so i can make changes to the source code, test it out, and create a new image if everything works. However, using a volume this does not seem to be possible, since it works the other way around. Anyone got suggestions on how to do this? Or am i trying to do the wrong thing here?
[2019-12-21 14:10:07] <bluemind2005_twitter> Any luck with installation of skopeo on Amazon Linux 2?
[2019-12-21 17:08:51] <pulkit_gupta88_twitter> desjob: As a general practice we do not change source code in an image. Build your image once and test the same image in all pre-prod envs. Once it is fully tested deploy this image in production. Now if you want to change the source code then change it in your version control system, generate a new image and test it again in pre-prod before deploying it again on prod.
[2019-12-21 17:25:59] <desjob> pulkit_gupta88_twitter: so what does my setup look like while changing the source code? i do need to run /test it while im developing
[2019-12-22 03:38:38] <pulkit_gupta88_twitter> desjob: you can change your source code and then can build a new docker image each time you want to test the changes. Once the image is ready you can then simply run it on your local box to check if it works. With docker the best part is if it works on your local it should work on other systems as well.
[2019-12-22 03:42:32] <HiWilliam> hi guys.i have a problem,i work with  docker desktop ,i cant share my driver and the logs file show me "signing requested but authenticated as guest", but i login my windwos with miscrosoft accout and its  administrator. how to solve this problem?
[2019-12-22 17:57:26] <RoniqueRicketts> Hello World!
[2019-12-24 08:46:53] <Akaame> Hi there,I need to get the host IP within a docker compose file to pass it onto cassandra config yaml. However, getting this from a parameter on the manager machine I do the deployment causes the machine IP to be propogated to all other machines instead of each dockerized cassandra instance having broadcast address of their own "host". How do I pass each container their own host IP address?
[2019-12-24 08:48:44] <Akaame> Sorry, I guess this would be more suitable for Swarm room. Just saw that one.
[2019-12-26 14:26:06] <sssanjaya> hello everyone!i need help with dockerhow do i install private gitlab repositories through npm install in Docker using ssh???
[2019-12-29 05:49:45] <matrixbot> xionboxHi there. I have a docker container which is set up with a specific python library I need. How can I copy a script into that docker container prior to executing it in that environment?
[2019-12-29 05:49:46] <matrixbot> xionboxThanks
[2019-12-29 05:51:42] <matrixbot> pwr22docker cp?
[2019-12-29 05:56:55] <matrixbot> xionboxMaybe but I'm not sure how. The problem is that I'm running the container in interactive mode
[2019-12-29 05:57:02] <matrixbot> xionboxSo I need to copy the file, and then run it
[2019-12-29 05:57:30] <matrixbot> xionboxHmm, actually, I guess the simplest is probably to have a mapped drive, copy the file I want to run there, and then start the container in interactive mode
[2019-12-29 05:57:31] <matrixbot> xionboxRight ?
[2019-12-29 06:11:26] <matrixbot> xionboxThat worked like a charm
